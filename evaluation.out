nohup: ignoring input
2024-12-27 17:13:06,017 - INFO - Logging setup completed successfully
2024-12-27 17:13:06,017 - INFO - Log file created at: /home/brian/Notebooks/ddv2-ws/logs/experiment_20241227_171305.log
2024-12-27 17:13:06,018 - INFO - Starting experiment run
2024-12-27 17:13:06,018 - INFO - Test mode: True
2024-12-27 17:13:06,019 - INFO - 
Processing dataset: GTSRB
2024-12-27 17:13:06,151 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 17:13:06,454 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 17:13:06,898 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 17:13:06,898 - INFO - Dataset type: image
2024-12-27 17:13:06,899 - INFO - Sample size: 39209
2024-12-27 17:13:06,899 - INFO - Using device: cuda
2024-12-27 17:13:06,899 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 17:13:06,900 - INFO - 
Progress: 1.0% - Evaluating GTSRB with SVM (standard mode, iteration 1/1)
2024-12-27 17:13:07,113 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 17:13:07,185 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 17:13:07,279 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 17:13:07,279 - INFO - Dataset type: image
2024-12-27 17:13:07,279 - INFO - Sample size: 39209
2024-12-27 17:13:07,280 - INFO - Using device: cuda
2024-12-27 17:13:07,280 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 17:13:07,280 - INFO - Loading datasets...
2024-12-27 17:13:24,234 - INFO - Dataset loading completed in 16.95s
2024-12-27 17:13:24,234 - INFO - Extracting validation features...
2024-12-27 17:13:24,235 - INFO - Extracting features from 4435 samples using EfficientNetB0...

Archiving previous files...
Archiving logs from: /home/brian/Notebooks/ddv2-ws/logs
Logs archived
Cleanup completed
Archiving finished - starting evaluation

Logging to: /home/brian/Notebooks/ddv2-ws/logs/experiment_20241227_171305.log
Initializing configuration manager...
Getting configurations...

Evaluation Plan:
- Datasets: ['GTSRB', 'GTSRB', 'GTSRB', 'GTSRB', 'CIFAR100', 'CIFAR100', 'CIFAR100', 'CIFAR100', 'ImageNette', 'ImageNette', 'ImageNette', 'ImageNette']
- Classifiers: ['SVM', 'LogisticRegression', 'RandomForest', 'KNeighbors']
- Sample sizes: {'CIFAR100': 5000, 'GTSRB': 39209, 'ImageNette': 5000}
- Modes: ['standard', 'dynadetect']
- Iterations: 1

Starting evaluation...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<01:03,  2.16it/s]Extracting features:   1%|▏         | 2/139 [00:00<00:34,  3.94it/s]Extracting features:   3%|▎         | 4/139 [00:00<00:18,  7.16it/s]Extracting features:   4%|▍         | 6/139 [00:00<00:14,  8.99it/s]Extracting features:   6%|▋         | 9/139 [00:01<00:10, 12.55it/s]Extracting features:   8%|▊         | 11/139 [00:01<00:09, 13.70it/s]Extracting features:  10%|█         | 14/139 [00:01<00:07, 16.66it/s]Extracting features:  12%|█▏        | 17/139 [00:01<00:06, 17.92it/s]Extracting features:  15%|█▌        | 21/139 [00:01<00:05, 20.94it/s]Extracting features:  17%|█▋        | 24/139 [00:01<00:05, 20.05it/s]Extracting features:  19%|█▉        | 27/139 [00:01<00:05, 21.78it/s]Extracting features:  22%|██▏       | 30/139 [00:01<00:04, 22.98it/s]Extracting features:  24%|██▎       | 33/139 [00:02<00:05, 21.07it/s]Extracting features:  26%|██▌       | 36/139 [00:02<00:04, 21.21it/s]Extracting features:  29%|██▉       | 40/139 [00:02<00:04, 21.83it/s]Extracting features:  31%|███       | 43/139 [00:02<00:04, 21.45it/s]Extracting features:  33%|███▎      | 46/139 [00:02<00:04, 19.00it/s]Extracting features:  35%|███▌      | 49/139 [00:02<00:04, 20.14it/s]Extracting features:  37%|███▋      | 52/139 [00:03<00:04, 19.36it/s]Extracting features:  40%|███▉      | 55/139 [00:03<00:04, 18.68it/s]Extracting features:  41%|████      | 57/139 [00:03<00:04, 17.11it/s]Extracting features:  42%|████▏     | 59/139 [00:03<00:05, 14.76it/s]Extracting features:  45%|████▍     | 62/139 [00:03<00:04, 16.18it/s]Extracting features:  46%|████▌     | 64/139 [00:03<00:04, 16.60it/s]Extracting features:  48%|████▊     | 67/139 [00:03<00:04, 17.89it/s]Extracting features:  50%|████▉     | 69/139 [00:04<00:04, 16.74it/s]Extracting features:  51%|█████     | 71/139 [00:04<00:04, 15.90it/s]Extracting features:  53%|█████▎    | 73/139 [00:04<00:03, 16.76it/s]Extracting features:  54%|█████▍    | 75/139 [00:04<00:04, 15.91it/s]Extracting features:  55%|█████▌    | 77/139 [00:04<00:03, 16.68it/s]Extracting features:  58%|█████▊    | 80/139 [00:04<00:03, 17.37it/s]Extracting features:  59%|█████▉    | 82/139 [00:04<00:03, 17.17it/s]Extracting features:  60%|██████    | 84/139 [00:05<00:03, 17.72it/s]Extracting features:  62%|██████▏   | 86/139 [00:05<00:02, 18.17it/s]Extracting features:  63%|██████▎   | 88/139 [00:05<00:02, 17.65it/s]Extracting features:  65%|██████▌   | 91/139 [00:05<00:02, 20.73it/s]Extracting features:  68%|██████▊   | 94/139 [00:05<00:02, 21.04it/s]Extracting features:  70%|██████▉   | 97/139 [00:05<00:02, 19.60it/s]Extracting features:  72%|███████▏  | 100/139 [00:05<00:02, 19.34it/s]Extracting features:  74%|███████▍  | 103/139 [00:05<00:01, 20.06it/s]Extracting features:  76%|███████▋  | 106/139 [00:06<00:01, 21.95it/s]Extracting features:  78%|███████▊  | 109/139 [00:06<00:01, 21.48it/s]Extracting features:  81%|████████  | 112/139 [00:06<00:01, 21.47it/s]Extracting features:  83%|████████▎ | 115/139 [00:06<00:01, 21.58it/s]Extracting features:  85%|████████▍ | 118/139 [00:06<00:01, 20.32it/s]Extracting features:  87%|████████▋ | 121/139 [00:06<00:00, 22.17it/s]Extracting features:  89%|████████▉ | 124/139 [00:06<00:00, 22.54it/s]Extracting features:  92%|█████████▏| 128/139 [00:07<00:00, 25.27it/s]Extracting features:  94%|█████████▍| 131/139 [00:07<00:00, 22.56it/s]Extracting features:  98%|█████████▊| 136/139 [00:07<00:00, 28.23it/s]Extracting features: 100%|██████████| 139/139 [00:07<00:00, 25.58it/s]Extracting features: 100%|██████████| 139/139 [00:07<00:00, 18.61it/s]
2024-12-27 17:13:31,717 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 17:13:31,718 - INFO - Validation feature extraction completed in 7.48s
2024-12-27 17:13:31,718 - INFO - Extracting training features...
2024-12-27 17:13:31,718 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<01:21,  7.57it/s]Extracting features:   1%|          | 5/618 [00:00<00:30, 20.35it/s]Extracting features:   2%|▏         | 10/618 [00:00<00:21, 28.54it/s]Extracting features:   2%|▏         | 15/618 [00:00<00:17, 35.09it/s]Extracting features:   3%|▎         | 19/618 [00:00<00:19, 31.48it/s]Extracting features:   4%|▍         | 24/618 [00:00<00:16, 35.00it/s]Extracting features:   5%|▍         | 28/618 [00:00<00:16, 35.75it/s]Extracting features:   5%|▌         | 32/618 [00:00<00:16, 36.32it/s]Extracting features:   6%|▌         | 36/618 [00:01<00:16, 35.83it/s]Extracting features:   6%|▋         | 40/618 [00:01<00:18, 32.11it/s]Extracting features:   7%|▋         | 44/618 [00:01<00:17, 32.02it/s]Extracting features:   8%|▊         | 48/618 [00:01<00:18, 31.21it/s]Extracting features:   8%|▊         | 52/618 [00:01<00:17, 32.88it/s]Extracting features:   9%|▉         | 56/618 [00:01<00:17, 32.20it/s]Extracting features:  10%|▉         | 60/618 [00:01<00:16, 33.31it/s]Extracting features:  11%|█         | 65/618 [00:01<00:14, 37.10it/s]Extracting features:  11%|█         | 69/618 [00:02<00:15, 35.03it/s]Extracting features:  12%|█▏        | 73/618 [00:02<00:16, 32.57it/s]Extracting features:  12%|█▏        | 77/618 [00:02<00:17, 31.59it/s]Extracting features:  13%|█▎        | 81/618 [00:02<00:17, 30.09it/s]Extracting features:  14%|█▍        | 85/618 [00:02<00:18, 29.05it/s]Extracting features:  14%|█▍        | 89/618 [00:02<00:17, 30.15it/s]Extracting features:  15%|█▌        | 93/618 [00:02<00:16, 32.33it/s]Extracting features:  16%|█▌        | 98/618 [00:03<00:14, 35.56it/s]Extracting features:  17%|█▋        | 103/618 [00:03<00:13, 38.93it/s]Extracting features:  17%|█▋        | 107/618 [00:03<00:13, 38.66it/s]Extracting features:  18%|█▊        | 112/618 [00:03<00:14, 35.54it/s]Extracting features:  19%|█▉        | 116/618 [00:03<00:14, 34.14it/s]Extracting features:  19%|█▉        | 120/618 [00:03<00:15, 32.37it/s]Extracting features:  20%|██        | 124/618 [00:03<00:14, 33.20it/s]Extracting features:  21%|██        | 128/618 [00:03<00:14, 33.89it/s]Extracting features:  21%|██▏       | 132/618 [00:03<00:13, 34.85it/s]Extracting features:  22%|██▏       | 136/618 [00:04<00:13, 35.25it/s]Extracting features:  23%|██▎       | 141/618 [00:04<00:12, 38.07it/s]Extracting features:  23%|██▎       | 145/618 [00:04<00:12, 38.48it/s]Extracting features:  24%|██▍       | 149/618 [00:04<00:13, 33.79it/s]Extracting features:  25%|██▍       | 153/618 [00:04<00:13, 33.54it/s]Extracting features:  25%|██▌       | 157/618 [00:04<00:13, 33.90it/s]Extracting features:  26%|██▌       | 161/618 [00:04<00:15, 30.04it/s]Extracting features:  27%|██▋       | 165/618 [00:05<00:15, 30.00it/s]Extracting features:  27%|██▋       | 169/618 [00:05<00:14, 30.68it/s]Extracting features:  28%|██▊       | 173/618 [00:05<00:13, 32.22it/s]Extracting features:  29%|██▊       | 177/618 [00:05<00:13, 33.71it/s]Extracting features:  29%|██▉       | 182/618 [00:05<00:12, 35.94it/s]Extracting features:  30%|███       | 187/618 [00:05<00:11, 38.39it/s]Extracting features:  31%|███       | 191/618 [00:05<00:12, 35.30it/s]Extracting features:  32%|███▏      | 195/618 [00:05<00:11, 35.81it/s]Extracting features:  33%|███▎      | 201/618 [00:05<00:10, 38.16it/s]Extracting features:  33%|███▎      | 206/618 [00:06<00:10, 38.96it/s]Extracting features:  34%|███▍      | 211/618 [00:06<00:10, 40.65it/s]Extracting features:  35%|███▍      | 216/618 [00:06<00:10, 39.99it/s]Extracting features:  36%|███▌      | 221/618 [00:06<00:09, 41.73it/s]Extracting features:  37%|███▋      | 226/618 [00:06<00:09, 40.70it/s]Extracting features:  37%|███▋      | 231/618 [00:06<00:09, 38.90it/s]Extracting features:  38%|███▊      | 235/618 [00:06<00:10, 36.69it/s]Extracting features:  39%|███▊      | 239/618 [00:06<00:10, 34.78it/s]Extracting features:  39%|███▉      | 243/618 [00:07<00:10, 35.50it/s]Extracting features:  40%|████      | 248/618 [00:07<00:09, 38.27it/s]Extracting features:  41%|████      | 252/618 [00:07<00:10, 34.08it/s]Extracting features:  41%|████▏     | 256/618 [00:07<00:11, 30.67it/s]Extracting features:  42%|████▏     | 260/618 [00:07<00:11, 30.25it/s]Extracting features:  43%|████▎     | 264/618 [00:07<00:12, 27.78it/s]Extracting features:  43%|████▎     | 268/618 [00:07<00:12, 28.95it/s]Extracting features:  44%|████▍     | 272/618 [00:08<00:11, 30.98it/s]Extracting features:  45%|████▍     | 276/618 [00:08<00:11, 30.81it/s]Extracting features:  45%|████▌     | 280/618 [00:08<00:10, 32.34it/s]Extracting features:  46%|████▋     | 286/618 [00:08<00:09, 36.33it/s]Extracting features:  47%|████▋     | 291/618 [00:08<00:08, 37.25it/s]Extracting features:  48%|████▊     | 296/618 [00:08<00:08, 40.08it/s]Extracting features:  49%|████▉     | 303/618 [00:08<00:06, 47.07it/s]Extracting features:  50%|████▉     | 308/618 [00:08<00:07, 40.12it/s]Extracting features:  51%|█████     | 313/618 [00:09<00:07, 40.73it/s]Extracting features:  51%|█████▏    | 318/618 [00:09<00:08, 37.32it/s]Extracting features:  52%|█████▏    | 322/618 [00:09<00:08, 36.53it/s]Extracting features:  53%|█████▎    | 326/618 [00:09<00:09, 31.81it/s]Extracting features:  53%|█████▎    | 330/618 [00:09<00:09, 31.34it/s]Extracting features:  54%|█████▍    | 334/618 [00:09<00:09, 28.78it/s]Extracting features:  55%|█████▍    | 337/618 [00:09<00:09, 28.12it/s]Extracting features:  55%|█████▌    | 340/618 [00:10<00:10, 27.79it/s]Extracting features:  56%|█████▌    | 344/618 [00:10<00:10, 25.99it/s]Extracting features:  56%|█████▌    | 347/618 [00:10<00:11, 24.31it/s]Extracting features:  57%|█████▋    | 350/618 [00:10<00:12, 21.07it/s]Extracting features:  57%|█████▋    | 353/618 [00:10<00:12, 21.66it/s]Extracting features:  58%|█████▊    | 356/618 [00:10<00:11, 23.43it/s]Extracting features:  58%|█████▊    | 360/618 [00:10<00:09, 26.33it/s]Extracting features:  59%|█████▉    | 364/618 [00:10<00:08, 28.79it/s]Extracting features:  59%|█████▉    | 367/618 [00:11<00:08, 28.43it/s]Extracting features:  60%|██████    | 371/618 [00:11<00:08, 29.12it/s]Extracting features:  61%|██████    | 376/618 [00:11<00:07, 32.42it/s]Extracting features:  61%|██████▏   | 380/618 [00:11<00:07, 33.51it/s]Extracting features:  62%|██████▏   | 384/618 [00:11<00:08, 29.04it/s]Extracting features:  63%|██████▎   | 388/618 [00:11<00:08, 27.09it/s]Extracting features:  64%|██████▎   | 393/618 [00:11<00:07, 30.56it/s]Extracting features:  64%|██████▍   | 398/618 [00:12<00:06, 32.41it/s]Extracting features:  65%|██████▌   | 403/618 [00:12<00:06, 34.07it/s]Extracting features:  66%|██████▌   | 407/618 [00:12<00:06, 32.80it/s]Extracting features:  67%|██████▋   | 411/618 [00:12<00:06, 32.84it/s]Extracting features:  67%|██████▋   | 415/618 [00:12<00:06, 31.80it/s]Extracting features:  68%|██████▊   | 419/618 [00:12<00:06, 30.69it/s]Extracting features:  68%|██████▊   | 423/618 [00:12<00:06, 31.02it/s]Extracting features:  69%|██████▉   | 427/618 [00:13<00:06, 27.60it/s]Extracting features:  70%|██████▉   | 430/618 [00:13<00:06, 27.59it/s]Extracting features:  70%|███████   | 433/618 [00:13<00:06, 26.64it/s]Extracting features:  71%|███████   | 436/618 [00:13<00:07, 22.76it/s]Extracting features:  71%|███████   | 439/618 [00:13<00:09, 19.73it/s]Extracting features:  72%|███████▏  | 442/618 [00:13<00:08, 21.37it/s]Extracting features:  72%|███████▏  | 445/618 [00:13<00:07, 22.15it/s]Extracting features:  72%|███████▏  | 448/618 [00:14<00:08, 20.93it/s]Extracting features:  73%|███████▎  | 451/618 [00:14<00:07, 22.74it/s]Extracting features:  74%|███████▎  | 455/618 [00:14<00:06, 25.50it/s]Extracting features:  74%|███████▍  | 458/618 [00:14<00:06, 23.93it/s]Extracting features:  75%|███████▍  | 461/618 [00:14<00:06, 24.14it/s]Extracting features:  75%|███████▌  | 465/618 [00:14<00:05, 27.31it/s]Extracting features:  76%|███████▌  | 470/618 [00:14<00:04, 31.09it/s]Extracting features:  77%|███████▋  | 475/618 [00:14<00:04, 34.31it/s]Extracting features:  78%|███████▊  | 479/618 [00:15<00:04, 32.35it/s]Extracting features:  78%|███████▊  | 483/618 [00:15<00:04, 30.42it/s]Extracting features:  79%|███████▉  | 487/618 [00:15<00:04, 28.48it/s]Extracting features:  79%|███████▉  | 490/618 [00:15<00:05, 24.69it/s]Extracting features:  80%|███████▉  | 493/618 [00:15<00:05, 23.29it/s]Extracting features:  80%|████████  | 497/618 [00:15<00:04, 26.25it/s]Extracting features:  81%|████████  | 501/618 [00:15<00:04, 28.22it/s]Extracting features:  82%|████████▏ | 505/618 [00:16<00:03, 30.65it/s]Extracting features:  83%|████████▎ | 510/618 [00:16<00:03, 33.04it/s]Extracting features:  83%|████████▎ | 514/618 [00:16<00:03, 32.33it/s]Extracting features:  84%|████████▍ | 518/618 [00:16<00:03, 32.42it/s]Extracting features:  85%|████████▍ | 523/618 [00:16<00:02, 35.63it/s]Extracting features:  85%|████████▌ | 527/618 [00:16<00:02, 36.71it/s]Extracting features:  86%|████████▌ | 532/618 [00:16<00:02, 39.48it/s]Extracting features:  87%|████████▋ | 537/618 [00:16<00:01, 41.31it/s]Extracting features:  88%|████████▊ | 542/618 [00:16<00:01, 41.79it/s]Extracting features:  89%|████████▊ | 547/618 [00:17<00:01, 38.65it/s]Extracting features:  89%|████████▉ | 552/618 [00:17<00:01, 37.57it/s]Extracting features:  90%|████████▉ | 556/618 [00:17<00:01, 36.81it/s]Extracting features:  91%|█████████ | 560/618 [00:17<00:01, 37.14it/s]Extracting features:  91%|█████████▏| 565/618 [00:17<00:01, 39.64it/s]Extracting features:  92%|█████████▏| 570/618 [00:17<00:01, 39.60it/s]Extracting features:  93%|█████████▎| 574/618 [00:17<00:01, 34.74it/s]Extracting features:  94%|█████████▎| 578/618 [00:18<00:01, 31.92it/s]Extracting features:  94%|█████████▍| 582/618 [00:18<00:01, 32.97it/s]Extracting features:  95%|█████████▍| 586/618 [00:18<00:01, 31.93it/s]Extracting features:  96%|█████████▌| 591/618 [00:18<00:00, 34.31it/s]Extracting features:  96%|█████████▋| 596/618 [00:18<00:00, 36.06it/s]Extracting features:  97%|█████████▋| 600/618 [00:18<00:00, 34.46it/s]Extracting features:  98%|█████████▊| 604/618 [00:18<00:00, 32.45it/s]Extracting features:  99%|█████████▊| 609/618 [00:18<00:00, 36.28it/s]Extracting features: 100%|█████████▉| 616/618 [00:18<00:00, 44.40it/s]Extracting features: 100%|██████████| 618/618 [00:19<00:00, 32.30it/s]
2024-12-27 17:13:50,879 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 17:13:50,879 - INFO - Training feature extraction completed in 19.16s
2024-12-27 17:13:50,879 - INFO - Creating model for classifier: SVM
2024-12-27 17:13:50,880 - INFO - Using device: cuda
2024-12-27 17:13:50,880 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-27 17:13:50,880 - INFO - 
Processing poison rate: 0.0
2024-12-27 17:13:50,880 - INFO - Training set processing completed in 0.00s
2024-12-27 17:13:50,880 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 17:13:50,882 - INFO - Memory usage at start_fit: CPU 1709.4 MB, GPU 31.0 MB
2024-12-27 17:13:50,883 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:13:50,888 - INFO - Number of unique classes: 43
2024-12-27 17:13:51,265 - INFO - Fitted scaler and transformed data
2024-12-27 17:13:51,265 - INFO - Scaling time: 0.37s
2024-12-27 17:13:52,670 - INFO - Epoch 1/25, Train Loss: 5.1938, Val Loss: 2.0866
2024-12-27 17:13:53,759 - INFO - Epoch 2/25, Train Loss: 0.9637, Val Loss: 1.4994
2024-12-27 17:13:54,893 - INFO - Epoch 3/25, Train Loss: 0.5857, Val Loss: 1.3478
2024-12-27 17:13:55,995 - INFO - Epoch 4/25, Train Loss: 0.4964, Val Loss: 1.2899
2024-12-27 17:13:57,066 - INFO - Epoch 5/25, Train Loss: 0.3958, Val Loss: 1.2374
2024-12-27 17:13:58,349 - INFO - Epoch 6/25, Train Loss: 0.3530, Val Loss: 1.4199
2024-12-27 17:13:59,551 - INFO - Epoch 7/25, Train Loss: 0.3214, Val Loss: 1.2452
2024-12-27 17:13:59,551 - INFO - Early stopping triggered at epoch 7
2024-12-27 17:13:59,551 - INFO - Training completed in 8.67s
2024-12-27 17:13:59,552 - INFO - Final memory usage: CPU 2074.0 MB, GPU 48.4 MB
2024-12-27 17:13:59,553 - INFO - Model training completed in 8.67s
2024-12-27 17:13:59,591 - INFO - Prediction completed in 0.04s
2024-12-27 17:13:59,603 - INFO - Poison rate 0.0 completed in 8.72s
2024-12-27 17:13:59,603 - INFO - 
Processing poison rate: 0.01
2024-12-27 17:13:59,608 - INFO - Total number of labels flipped: 197
2024-12-27 17:13:59,609 - INFO - Label flipping completed in 0.01s
2024-12-27 17:13:59,609 - INFO - Training set processing completed in 0.00s
2024-12-27 17:13:59,609 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 17:13:59,610 - INFO - Memory usage at start_fit: CPU 2000.7 MB, GPU 48.1 MB
2024-12-27 17:13:59,610 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:13:59,610 - INFO - Number of unique classes: 43
2024-12-27 17:13:59,940 - INFO - Fitted scaler and transformed data
2024-12-27 17:13:59,941 - INFO - Scaling time: 0.33s
2024-12-27 17:14:01,165 - INFO - Epoch 1/25, Train Loss: 7.6666, Val Loss: 4.0445
2024-12-27 17:14:02,450 - INFO - Epoch 2/25, Train Loss: 1.4464, Val Loss: 2.8180
2024-12-27 17:14:03,699 - INFO - Epoch 3/25, Train Loss: 0.6954, Val Loss: 2.6213
2024-12-27 17:14:04,886 - INFO - Epoch 4/25, Train Loss: 0.5310, Val Loss: 2.6918
2024-12-27 17:14:06,049 - INFO - Epoch 5/25, Train Loss: 0.4592, Val Loss: 2.4258
2024-12-27 17:14:07,220 - INFO - Epoch 6/25, Train Loss: 0.3850, Val Loss: 2.5489
2024-12-27 17:14:08,340 - INFO - Epoch 7/25, Train Loss: 0.3831, Val Loss: 2.7015
2024-12-27 17:14:08,340 - INFO - Early stopping triggered at epoch 7
2024-12-27 17:14:08,340 - INFO - Training completed in 8.73s
2024-12-27 17:14:08,341 - INFO - Final memory usage: CPU 2105.2 MB, GPU 48.4 MB
2024-12-27 17:14:08,341 - INFO - Model training completed in 8.73s
2024-12-27 17:14:08,385 - INFO - Prediction completed in 0.04s
2024-12-27 17:14:08,396 - INFO - Poison rate 0.01 completed in 8.79s
2024-12-27 17:14:08,396 - INFO - 
Processing poison rate: 0.03
2024-12-27 17:14:08,411 - INFO - Total number of labels flipped: 592
2024-12-27 17:14:08,412 - INFO - Label flipping completed in 0.02s
2024-12-27 17:14:08,412 - INFO - Training set processing completed in 0.00s
2024-12-27 17:14:08,413 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 17:14:08,414 - INFO - Memory usage at start_fit: CPU 2008.7 MB, GPU 48.1 MB
2024-12-27 17:14:08,415 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:14:08,417 - INFO - Number of unique classes: 43
2024-12-27 17:14:08,764 - INFO - Fitted scaler and transformed data
2024-12-27 17:14:08,764 - INFO - Scaling time: 0.34s
2024-12-27 17:14:09,862 - INFO - Epoch 1/25, Train Loss: 11.5458, Val Loss: 7.1562
2024-12-27 17:14:11,100 - INFO - Epoch 2/25, Train Loss: 2.2625, Val Loss: 5.8831
2024-12-27 17:14:12,380 - INFO - Epoch 3/25, Train Loss: 1.0451, Val Loss: 4.9217
2024-12-27 17:14:13,647 - INFO - Epoch 4/25, Train Loss: 0.7044, Val Loss: 4.4358
2024-12-27 17:14:15,050 - INFO - Epoch 5/25, Train Loss: 0.5787, Val Loss: 4.5889
2024-12-27 17:14:16,346 - INFO - Epoch 6/25, Train Loss: 0.5368, Val Loss: 4.6552
2024-12-27 17:14:16,346 - INFO - Early stopping triggered at epoch 6
2024-12-27 17:14:16,346 - INFO - Training completed in 7.93s
2024-12-27 17:14:16,346 - INFO - Final memory usage: CPU 2105.2 MB, GPU 48.4 MB
2024-12-27 17:14:16,347 - INFO - Model training completed in 7.93s
2024-12-27 17:14:16,375 - INFO - Prediction completed in 0.03s
2024-12-27 17:14:16,386 - INFO - Poison rate 0.03 completed in 7.99s
2024-12-27 17:14:16,387 - INFO - 
Processing poison rate: 0.05
2024-12-27 17:14:16,405 - INFO - Total number of labels flipped: 987
2024-12-27 17:14:16,405 - INFO - Label flipping completed in 0.02s
2024-12-27 17:14:16,405 - INFO - Training set processing completed in 0.00s
2024-12-27 17:14:16,406 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 17:14:16,407 - INFO - Memory usage at start_fit: CPU 2008.8 MB, GPU 48.1 MB
2024-12-27 17:14:16,407 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:14:16,409 - INFO - Number of unique classes: 43
2024-12-27 17:14:16,759 - INFO - Fitted scaler and transformed data
2024-12-27 17:14:16,759 - INFO - Scaling time: 0.35s
2024-12-27 17:14:18,029 - INFO - Epoch 1/25, Train Loss: 14.8856, Val Loss: 13.6009
2024-12-27 17:14:19,245 - INFO - Epoch 2/25, Train Loss: 3.1484, Val Loss: 10.6374
2024-12-27 17:14:20,430 - INFO - Epoch 3/25, Train Loss: 1.4027, Val Loss: 10.6155
2024-12-27 17:14:21,779 - INFO - Epoch 4/25, Train Loss: 0.9346, Val Loss: 10.1998
2024-12-27 17:14:22,986 - INFO - Epoch 5/25, Train Loss: 0.7487, Val Loss: 9.9617
2024-12-27 17:14:24,192 - INFO - Epoch 6/25, Train Loss: 0.6735, Val Loss: 10.4653
2024-12-27 17:14:25,419 - INFO - Epoch 7/25, Train Loss: 0.6207, Val Loss: 10.1026
2024-12-27 17:14:25,419 - INFO - Early stopping triggered at epoch 7
2024-12-27 17:14:25,419 - INFO - Training completed in 9.01s
2024-12-27 17:14:25,419 - INFO - Final memory usage: CPU 2110.5 MB, GPU 48.4 MB
2024-12-27 17:14:25,420 - INFO - Model training completed in 9.01s
2024-12-27 17:14:25,449 - INFO - Prediction completed in 0.03s
2024-12-27 17:14:25,460 - INFO - Poison rate 0.05 completed in 9.07s
2024-12-27 17:14:25,460 - INFO - 
Processing poison rate: 0.07
2024-12-27 17:14:25,486 - INFO - Total number of labels flipped: 1382
2024-12-27 17:14:25,486 - INFO - Label flipping completed in 0.03s
2024-12-27 17:14:25,486 - INFO - Training set processing completed in 0.00s
2024-12-27 17:14:25,486 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 17:14:25,487 - INFO - Memory usage at start_fit: CPU 2014.0 MB, GPU 48.1 MB
2024-12-27 17:14:25,487 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:14:25,488 - INFO - Number of unique classes: 43
2024-12-27 17:14:25,841 - INFO - Fitted scaler and transformed data
2024-12-27 17:14:25,841 - INFO - Scaling time: 0.35s
2024-12-27 17:14:27,007 - INFO - Epoch 1/25, Train Loss: 17.9317, Val Loss: 18.3189
2024-12-27 17:14:28,307 - INFO - Epoch 2/25, Train Loss: 4.2200, Val Loss: 14.6422
2024-12-27 17:14:29,629 - INFO - Epoch 3/25, Train Loss: 1.8443, Val Loss: 12.9461
2024-12-27 17:14:30,839 - INFO - Epoch 4/25, Train Loss: 1.1990, Val Loss: 12.8165
2024-12-27 17:14:32,070 - INFO - Epoch 5/25, Train Loss: 0.9217, Val Loss: 12.9393
2024-12-27 17:14:33,350 - INFO - Epoch 6/25, Train Loss: 0.8030, Val Loss: 13.1674
2024-12-27 17:14:33,351 - INFO - Early stopping triggered at epoch 6
2024-12-27 17:14:33,351 - INFO - Training completed in 7.86s
2024-12-27 17:14:33,351 - INFO - Final memory usage: CPU 2114.9 MB, GPU 48.4 MB
2024-12-27 17:14:33,352 - INFO - Model training completed in 7.87s
2024-12-27 17:14:33,380 - INFO - Prediction completed in 0.03s
2024-12-27 17:14:33,391 - INFO - Poison rate 0.07 completed in 7.93s
2024-12-27 17:14:33,391 - INFO - 
Processing poison rate: 0.1
2024-12-27 17:14:33,428 - INFO - Total number of labels flipped: 1975
2024-12-27 17:14:33,428 - INFO - Label flipping completed in 0.04s
2024-12-27 17:14:33,428 - INFO - Training set processing completed in 0.00s
2024-12-27 17:14:33,429 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 17:14:33,429 - INFO - Memory usage at start_fit: CPU 2018.5 MB, GPU 48.1 MB
2024-12-27 17:14:33,430 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:14:33,430 - INFO - Number of unique classes: 43
2024-12-27 17:14:33,778 - INFO - Fitted scaler and transformed data
2024-12-27 17:14:33,778 - INFO - Scaling time: 0.35s
2024-12-27 17:14:34,954 - INFO - Epoch 1/25, Train Loss: 22.5335, Val Loss: 24.8869
2024-12-27 17:14:36,118 - INFO - Epoch 2/25, Train Loss: 5.9966, Val Loss: 19.7770
2024-12-27 17:14:37,410 - INFO - Epoch 3/25, Train Loss: 2.9288, Val Loss: 18.1904
2024-12-27 17:14:38,635 - INFO - Epoch 4/25, Train Loss: 1.8792, Val Loss: 18.6484
2024-12-27 17:14:39,792 - INFO - Epoch 5/25, Train Loss: 1.5141, Val Loss: 17.8848
2024-12-27 17:14:41,001 - INFO - Epoch 6/25, Train Loss: 1.2397, Val Loss: 18.1779
2024-12-27 17:14:42,136 - INFO - Epoch 7/25, Train Loss: 1.1069, Val Loss: 18.2424
2024-12-27 17:14:42,136 - INFO - Early stopping triggered at epoch 7
2024-12-27 17:14:42,136 - INFO - Training completed in 8.71s
2024-12-27 17:14:42,136 - INFO - Final memory usage: CPU 2117.4 MB, GPU 48.4 MB
2024-12-27 17:14:42,137 - INFO - Model training completed in 8.71s
2024-12-27 17:14:42,165 - INFO - Prediction completed in 0.03s
2024-12-27 17:14:42,176 - INFO - Poison rate 0.1 completed in 8.78s
2024-12-27 17:14:42,176 - INFO - 
Processing poison rate: 0.2
2024-12-27 17:14:42,254 - INFO - Total number of labels flipped: 3951
2024-12-27 17:14:42,254 - INFO - Label flipping completed in 0.08s
2024-12-27 17:14:42,255 - INFO - Training set processing completed in 0.00s
2024-12-27 17:14:42,255 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 17:14:42,255 - INFO - Memory usage at start_fit: CPU 2020.9 MB, GPU 48.1 MB
2024-12-27 17:14:42,256 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:14:42,257 - INFO - Number of unique classes: 43
2024-12-27 17:14:42,585 - INFO - Fitted scaler and transformed data
2024-12-27 17:14:42,586 - INFO - Scaling time: 0.33s
2024-12-27 17:14:43,799 - INFO - Epoch 1/25, Train Loss: 35.9756, Val Loss: 37.2493
2024-12-27 17:14:44,966 - INFO - Epoch 2/25, Train Loss: 11.9422, Val Loss: 32.3355
2024-12-27 17:14:46,065 - INFO - Epoch 3/25, Train Loss: 6.8412, Val Loss: 30.9874
2024-12-27 17:14:47,199 - INFO - Epoch 4/25, Train Loss: 4.6720, Val Loss: 29.5866
2024-12-27 17:14:48,456 - INFO - Epoch 5/25, Train Loss: 3.8639, Val Loss: 30.1495
2024-12-27 17:14:49,727 - INFO - Epoch 6/25, Train Loss: 3.2029, Val Loss: 29.9555
2024-12-27 17:14:49,728 - INFO - Early stopping triggered at epoch 6
2024-12-27 17:14:49,728 - INFO - Training completed in 7.47s
2024-12-27 17:14:49,728 - INFO - Final memory usage: CPU 2117.4 MB, GPU 48.4 MB
2024-12-27 17:14:49,729 - INFO - Model training completed in 7.47s
2024-12-27 17:14:49,775 - INFO - Prediction completed in 0.05s
2024-12-27 17:14:49,786 - INFO - Poison rate 0.2 completed in 7.61s
2024-12-27 17:14:49,788 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 17:14:49,788 - INFO - Total evaluation time: 102.51s
2024-12-27 17:14:49,794 - INFO - 
Progress: 2.1% - Evaluating GTSRB with SVM (dynadetect mode, iteration 1/1)
2024-12-27 17:14:49,851 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 17:14:49,924 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 17:14:50,014 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 17:14:50,015 - INFO - Dataset type: image
2024-12-27 17:14:50,015 - INFO - Sample size: 39209
2024-12-27 17:14:50,015 - INFO - Using device: cuda
2024-12-27 17:14:50,015 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 17:14:50,017 - INFO - Loading datasets...
2024-12-27 17:15:07,225 - INFO - Dataset loading completed in 17.21s
2024-12-27 17:15:07,225 - INFO - Extracting validation features...
2024-12-27 17:15:07,225 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:25,  5.50it/s]Extracting features:   2%|▏         | 3/139 [00:00<00:14,  9.19it/s]Extracting features:   4%|▍         | 6/139 [00:00<00:08, 15.63it/s]Extracting features:   8%|▊         | 11/139 [00:00<00:04, 26.29it/s]Extracting features:  12%|█▏        | 16/139 [00:00<00:03, 33.23it/s]Extracting features:  14%|█▍        | 20/139 [00:00<00:03, 33.24it/s]Extracting features:  19%|█▊        | 26/139 [00:00<00:02, 40.75it/s]Extracting features:  22%|██▏       | 31/139 [00:00<00:02, 42.24it/s]Extracting features:  27%|██▋       | 37/139 [00:01<00:02, 45.77it/s]Extracting features:  31%|███       | 43/139 [00:01<00:01, 48.94it/s]Extracting features:  35%|███▍      | 48/139 [00:01<00:01, 49.18it/s]Extracting features:  39%|███▉      | 54/139 [00:01<00:01, 51.67it/s]Extracting features:  43%|████▎     | 60/139 [00:01<00:01, 46.26it/s]Extracting features:  47%|████▋     | 65/139 [00:01<00:01, 42.25it/s]Extracting features:  50%|█████     | 70/139 [00:01<00:01, 39.63it/s]Extracting features:  54%|█████▍    | 75/139 [00:01<00:01, 39.47it/s]Extracting features:  58%|█████▊    | 80/139 [00:02<00:01, 35.46it/s]Extracting features:  60%|██████    | 84/139 [00:02<00:01, 35.98it/s]Extracting features:  63%|██████▎   | 88/139 [00:02<00:01, 34.46it/s]Extracting features:  67%|██████▋   | 93/139 [00:02<00:01, 36.75it/s]Extracting features:  70%|██████▉   | 97/139 [00:02<00:01, 37.13it/s]Extracting features:  74%|███████▍  | 103/139 [00:02<00:00, 41.72it/s]Extracting features:  78%|███████▊  | 109/139 [00:02<00:00, 46.50it/s]Extracting features:  83%|████████▎ | 115/139 [00:02<00:00, 49.36it/s]Extracting features:  87%|████████▋ | 121/139 [00:03<00:00, 48.53it/s]Extracting features:  91%|█████████▏| 127/139 [00:03<00:00, 49.77it/s]Extracting features:  96%|█████████▌| 133/139 [00:03<00:00, 50.89it/s]Extracting features: 100%|██████████| 139/139 [00:03<00:00, 49.99it/s]Extracting features: 100%|██████████| 139/139 [00:03<00:00, 40.03it/s]
2024-12-27 17:15:10,706 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 17:15:10,707 - INFO - Validation feature extraction completed in 3.48s
2024-12-27 17:15:10,707 - INFO - Extracting training features...
2024-12-27 17:15:10,707 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<01:43,  5.97it/s]Extracting features:   1%|          | 6/618 [00:00<00:24, 24.70it/s]Extracting features:   2%|▏         | 12/618 [00:00<00:17, 34.95it/s]Extracting features:   3%|▎         | 18/618 [00:00<00:14, 42.68it/s]Extracting features:   4%|▎         | 23/618 [00:00<00:14, 39.82it/s]Extracting features:   5%|▍         | 29/618 [00:00<00:13, 43.59it/s]Extracting features:   6%|▌         | 34/618 [00:00<00:13, 42.87it/s]Extracting features:   6%|▋         | 39/618 [00:01<00:14, 40.50it/s]Extracting features:   7%|▋         | 46/618 [00:01<00:12, 47.58it/s]Extracting features:   9%|▊         | 53/618 [00:01<00:10, 52.14it/s]Extracting features:  10%|▉         | 59/618 [00:01<00:12, 45.96it/s]Extracting features:  11%|█         | 65/618 [00:01<00:11, 47.52it/s]Extracting features:  11%|█▏        | 70/618 [00:01<00:12, 44.92it/s]Extracting features:  12%|█▏        | 75/618 [00:01<00:11, 45.96it/s]Extracting features:  13%|█▎        | 81/618 [00:01<00:11, 47.29it/s]Extracting features:  14%|█▍        | 86/618 [00:01<00:11, 45.40it/s]Extracting features:  15%|█▍        | 91/618 [00:02<00:11, 44.55it/s]Extracting features:  16%|█▌        | 96/618 [00:02<00:11, 45.37it/s]Extracting features:  16%|█▋        | 101/618 [00:02<00:12, 42.56it/s]Extracting features:  17%|█▋        | 106/618 [00:02<00:11, 44.45it/s]Extracting features:  18%|█▊        | 112/618 [00:02<00:10, 48.21it/s]Extracting features:  19%|█▉        | 117/618 [00:02<00:10, 47.82it/s]Extracting features:  20%|█▉        | 123/618 [00:02<00:10, 49.37it/s]Extracting features:  21%|██        | 128/618 [00:02<00:09, 49.46it/s]Extracting features:  22%|██▏       | 133/618 [00:02<00:09, 48.91it/s]Extracting features:  22%|██▏       | 138/618 [00:03<00:11, 42.97it/s]Extracting features:  23%|██▎       | 144/618 [00:03<00:10, 46.56it/s]Extracting features:  24%|██▍       | 151/618 [00:03<00:08, 51.90it/s]Extracting features:  25%|██▌       | 157/618 [00:03<00:08, 52.88it/s]Extracting features:  26%|██▋       | 163/618 [00:03<00:08, 54.08it/s]Extracting features:  27%|██▋       | 169/618 [00:03<00:08, 53.86it/s]Extracting features:  28%|██▊       | 175/618 [00:03<00:09, 47.65it/s]Extracting features:  29%|██▉       | 181/618 [00:03<00:09, 47.94it/s]Extracting features:  30%|███       | 188/618 [00:04<00:08, 50.82it/s]Extracting features:  31%|███▏      | 194/618 [00:04<00:08, 48.89it/s]Extracting features:  33%|███▎      | 201/618 [00:04<00:07, 54.12it/s]Extracting features:  33%|███▎      | 207/618 [00:04<00:07, 53.25it/s]Extracting features:  34%|███▍      | 213/618 [00:04<00:07, 54.56it/s]Extracting features:  35%|███▌      | 219/618 [00:04<00:07, 55.68it/s]Extracting features:  36%|███▋      | 225/618 [00:04<00:07, 53.34it/s]Extracting features:  37%|███▋      | 231/618 [00:04<00:07, 55.14it/s]Extracting features:  38%|███▊      | 237/618 [00:04<00:06, 55.57it/s]Extracting features:  39%|███▉      | 244/618 [00:05<00:06, 58.33it/s]Extracting features:  40%|████      | 250/618 [00:05<00:06, 56.21it/s]Extracting features:  41%|████▏     | 256/618 [00:05<00:06, 52.15it/s]Extracting features:  42%|████▏     | 262/618 [00:05<00:08, 44.35it/s]Extracting features:  44%|████▎     | 269/618 [00:05<00:07, 48.93it/s]Extracting features:  44%|████▍     | 275/618 [00:05<00:06, 49.72it/s]Extracting features:  45%|████▌     | 281/618 [00:05<00:06, 50.34it/s]Extracting features:  46%|████▋     | 287/618 [00:05<00:06, 51.10it/s]Extracting features:  47%|████▋     | 293/618 [00:06<00:06, 51.10it/s]Extracting features:  48%|████▊     | 299/618 [00:06<00:06, 49.86it/s]Extracting features:  49%|████▉     | 305/618 [00:06<00:06, 47.15it/s]Extracting features:  50%|█████     | 310/618 [00:06<00:06, 44.97it/s]Extracting features:  51%|█████     | 315/618 [00:06<00:07, 43.19it/s]Extracting features:  52%|█████▏    | 320/618 [00:06<00:07, 41.10it/s]Extracting features:  53%|█████▎    | 325/618 [00:06<00:07, 38.45it/s]Extracting features:  53%|█████▎    | 329/618 [00:07<00:07, 38.03it/s]Extracting features:  54%|█████▍    | 333/618 [00:07<00:08, 35.06it/s]Extracting features:  55%|█████▍    | 337/618 [00:07<00:08, 31.65it/s]Extracting features:  55%|█████▌    | 341/618 [00:07<00:08, 32.97it/s]Extracting features:  56%|█████▌    | 345/618 [00:07<00:08, 30.75it/s]Extracting features:  56%|█████▋    | 349/618 [00:07<00:08, 30.19it/s]Extracting features:  57%|█████▋    | 354/618 [00:07<00:08, 32.74it/s]Extracting features:  58%|█████▊    | 358/618 [00:07<00:07, 33.78it/s]Extracting features:  59%|█████▊    | 362/618 [00:08<00:07, 32.71it/s]Extracting features:  59%|█████▉    | 366/618 [00:08<00:07, 32.62it/s]Extracting features:  60%|█████▉    | 370/618 [00:08<00:07, 32.47it/s]Extracting features:  61%|██████    | 374/618 [00:08<00:08, 29.39it/s]Extracting features:  61%|██████    | 378/618 [00:08<00:08, 29.86it/s]Extracting features:  62%|██████▏   | 382/618 [00:08<00:07, 30.58it/s]Extracting features:  62%|██████▏   | 386/618 [00:08<00:07, 31.58it/s]Extracting features:  63%|██████▎   | 390/618 [00:08<00:07, 32.29it/s]Extracting features:  64%|██████▍   | 394/618 [00:09<00:07, 30.51it/s]Extracting features:  64%|██████▍   | 398/618 [00:09<00:06, 31.48it/s]Extracting features:  65%|██████▌   | 403/618 [00:09<00:05, 35.85it/s]Extracting features:  66%|██████▌   | 407/618 [00:09<00:06, 33.27it/s]Extracting features:  67%|██████▋   | 411/618 [00:09<00:06, 33.58it/s]Extracting features:  67%|██████▋   | 415/618 [00:09<00:06, 32.31it/s]Extracting features:  68%|██████▊   | 419/618 [00:09<00:06, 31.62it/s]Extracting features:  69%|██████▉   | 425/618 [00:09<00:05, 37.04it/s]Extracting features:  69%|██████▉   | 429/618 [00:10<00:05, 35.53it/s]Extracting features:  70%|███████   | 435/618 [00:10<00:04, 40.25it/s]Extracting features:  71%|███████   | 440/618 [00:10<00:04, 39.27it/s]Extracting features:  72%|███████▏  | 444/618 [00:10<00:04, 38.73it/s]Extracting features:  72%|███████▏  | 448/618 [00:10<00:04, 38.66it/s]Extracting features:  73%|███████▎  | 452/618 [00:10<00:04, 34.72it/s]Extracting features:  74%|███████▍  | 457/618 [00:10<00:04, 37.37it/s]Extracting features:  75%|███████▍  | 463/618 [00:10<00:03, 42.08it/s]Extracting features:  76%|███████▌  | 469/618 [00:11<00:03, 44.93it/s]Extracting features:  77%|███████▋  | 474/618 [00:11<00:03, 44.99it/s]Extracting features:  78%|███████▊  | 479/618 [00:11<00:03, 44.10it/s]Extracting features:  78%|███████▊  | 484/618 [00:11<00:02, 44.86it/s]Extracting features:  79%|███████▉  | 489/618 [00:11<00:03, 40.96it/s]Extracting features:  80%|███████▉  | 494/618 [00:11<00:02, 42.21it/s]Extracting features:  81%|████████  | 500/618 [00:11<00:02, 44.78it/s]Extracting features:  82%|████████▏ | 506/618 [00:11<00:02, 47.16it/s]Extracting features:  83%|████████▎ | 511/618 [00:11<00:02, 46.99it/s]Extracting features:  84%|████████▎ | 517/618 [00:12<00:02, 48.83it/s]Extracting features:  85%|████████▍ | 524/618 [00:12<00:01, 51.93it/s]Extracting features:  86%|████████▌ | 530/618 [00:12<00:01, 49.91it/s]Extracting features:  87%|████████▋ | 537/618 [00:12<00:01, 52.54it/s]Extracting features:  88%|████████▊ | 543/618 [00:12<00:01, 52.84it/s]Extracting features:  89%|████████▉ | 550/618 [00:12<00:01, 54.23it/s]Extracting features:  90%|████████▉ | 556/618 [00:12<00:01, 50.36it/s]Extracting features:  91%|█████████ | 563/618 [00:12<00:01, 51.75it/s]Extracting features:  92%|█████████▏| 569/618 [00:13<00:00, 51.22it/s]Extracting features:  93%|█████████▎| 575/618 [00:13<00:00, 49.70it/s]Extracting features:  94%|█████████▍| 580/618 [00:13<00:00, 48.23it/s]Extracting features:  95%|█████████▍| 585/618 [00:13<00:00, 46.70it/s]Extracting features:  95%|█████████▌| 590/618 [00:13<00:00, 44.22it/s]Extracting features:  96%|█████████▋| 595/618 [00:13<00:00, 38.39it/s]Extracting features:  97%|█████████▋| 601/618 [00:13<00:00, 41.94it/s]Extracting features:  98%|█████████▊| 608/618 [00:13<00:00, 47.49it/s]Extracting features:  99%|█████████▉| 613/618 [00:14<00:00, 47.76it/s]Extracting features: 100%|██████████| 618/618 [00:14<00:00, 44.35it/s]Extracting features: 100%|██████████| 618/618 [00:14<00:00, 43.32it/s]
2024-12-27 17:15:25,001 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 17:15:25,001 - INFO - Training feature extraction completed in 14.29s
2024-12-27 17:15:25,002 - INFO - Creating model for classifier: SVM
2024-12-27 17:15:25,002 - INFO - Using device: cuda
2024-12-27 17:15:25,002 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-27 17:15:25,002 - INFO - 
Processing poison rate: 0.0
2024-12-27 17:15:25,002 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:15:25,002 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:15:27,044 - INFO - Feature scaling completed in 2.04s
2024-12-27 17:15:27,044 - INFO - Starting feature selection (k=50)
2024-12-27 17:15:27,232 - INFO - Feature selection completed in 0.19s. Output shape: (19755, 50)
2024-12-27 17:15:27,232 - INFO - Starting anomaly detection
2024-12-27 17:15:35,408 - INFO - Anomaly detection completed in 8.18s
2024-12-27 17:15:35,408 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:15:35,408 - INFO - Total fit_transform time: 10.41s
2024-12-27 17:15:35,408 - INFO - Training set processing completed in 10.41s
2024-12-27 17:15:35,409 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 17:15:35,410 - INFO - Memory usage at start_fit: CPU 2404.2 MB, GPU 47.3 MB
2024-12-27 17:15:35,410 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:15:35,410 - INFO - Number of unique classes: 43
2024-12-27 17:15:35,750 - INFO - Fitted scaler and transformed data
2024-12-27 17:15:35,750 - INFO - Scaling time: 0.34s
2024-12-27 17:15:36,946 - INFO - Epoch 1/25, Train Loss: 5.2599, Val Loss: 2.1519
2024-12-27 17:15:38,083 - INFO - Epoch 2/25, Train Loss: 0.8962, Val Loss: 1.5353
2024-12-27 17:15:39,339 - INFO - Epoch 3/25, Train Loss: 0.5703, Val Loss: 1.3273
2024-12-27 17:15:40,639 - INFO - Epoch 4/25, Train Loss: 0.4087, Val Loss: 1.3593
2024-12-27 17:15:41,990 - INFO - Epoch 5/25, Train Loss: 0.4056, Val Loss: 1.4394
2024-12-27 17:15:41,990 - INFO - Early stopping triggered at epoch 5
2024-12-27 17:15:41,990 - INFO - Training completed in 6.58s
2024-12-27 17:15:41,991 - INFO - Final memory usage: CPU 2528.2 MB, GPU 48.4 MB
2024-12-27 17:15:41,991 - INFO - Model training completed in 6.58s
2024-12-27 17:15:42,020 - INFO - Prediction completed in 0.03s
2024-12-27 17:15:42,032 - INFO - Poison rate 0.0 completed in 17.03s
2024-12-27 17:15:42,032 - INFO - 
Processing poison rate: 0.01
2024-12-27 17:15:42,037 - INFO - Total number of labels flipped: 197
2024-12-27 17:15:42,037 - INFO - Label flipping completed in 0.01s
2024-12-27 17:15:42,037 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:15:42,037 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:15:43,890 - INFO - Feature scaling completed in 1.85s
2024-12-27 17:15:43,890 - INFO - Starting feature selection (k=50)
2024-12-27 17:15:43,941 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 17:15:43,941 - INFO - Starting anomaly detection
2024-12-27 17:15:51,936 - INFO - Anomaly detection completed in 7.99s
2024-12-27 17:15:51,937 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:15:51,937 - INFO - Total fit_transform time: 9.90s
2024-12-27 17:15:51,937 - INFO - Training set processing completed in 9.90s
2024-12-27 17:15:51,937 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 17:15:51,938 - INFO - Memory usage at start_fit: CPU 2431.8 MB, GPU 48.1 MB
2024-12-27 17:15:51,939 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:15:51,940 - INFO - Number of unique classes: 43
2024-12-27 17:15:52,294 - INFO - Fitted scaler and transformed data
2024-12-27 17:15:52,295 - INFO - Scaling time: 0.35s
2024-12-27 17:15:53,431 - INFO - Epoch 1/25, Train Loss: 7.2482, Val Loss: 4.9519
2024-12-27 17:15:54,547 - INFO - Epoch 2/25, Train Loss: 1.4637, Val Loss: 3.3637
2024-12-27 17:15:55,673 - INFO - Epoch 3/25, Train Loss: 0.7438, Val Loss: 3.0149
2024-12-27 17:15:56,867 - INFO - Epoch 4/25, Train Loss: 0.5134, Val Loss: 2.7205
2024-12-27 17:15:58,043 - INFO - Epoch 5/25, Train Loss: 0.4365, Val Loss: 2.8167
2024-12-27 17:15:59,187 - INFO - Epoch 6/25, Train Loss: 0.3541, Val Loss: 2.6864
2024-12-27 17:16:00,344 - INFO - Epoch 7/25, Train Loss: 0.3319, Val Loss: 2.8493
2024-12-27 17:16:01,508 - INFO - Epoch 8/25, Train Loss: 0.3509, Val Loss: 2.8589
2024-12-27 17:16:01,508 - INFO - Early stopping triggered at epoch 8
2024-12-27 17:16:01,508 - INFO - Training completed in 9.57s
2024-12-27 17:16:01,509 - INFO - Final memory usage: CPU 2532.0 MB, GPU 48.4 MB
2024-12-27 17:16:01,510 - INFO - Model training completed in 9.57s
2024-12-27 17:16:01,540 - INFO - Prediction completed in 0.03s
2024-12-27 17:16:01,551 - INFO - Poison rate 0.01 completed in 19.52s
2024-12-27 17:16:01,551 - INFO - 
Processing poison rate: 0.03
2024-12-27 17:16:01,563 - INFO - Total number of labels flipped: 592
2024-12-27 17:16:01,563 - INFO - Label flipping completed in 0.01s
2024-12-27 17:16:01,563 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:16:01,563 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:16:03,546 - INFO - Feature scaling completed in 1.98s
2024-12-27 17:16:03,547 - INFO - Starting feature selection (k=50)
2024-12-27 17:16:03,598 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 17:16:03,599 - INFO - Starting anomaly detection
2024-12-27 17:16:11,526 - INFO - Anomaly detection completed in 7.93s
2024-12-27 17:16:11,526 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:16:11,526 - INFO - Total fit_transform time: 9.96s
2024-12-27 17:16:11,527 - INFO - Training set processing completed in 9.96s
2024-12-27 17:16:11,527 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 17:16:11,528 - INFO - Memory usage at start_fit: CPU 2435.5 MB, GPU 48.1 MB
2024-12-27 17:16:11,528 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:16:11,530 - INFO - Number of unique classes: 43
2024-12-27 17:16:11,881 - INFO - Fitted scaler and transformed data
2024-12-27 17:16:11,882 - INFO - Scaling time: 0.35s
2024-12-27 17:16:13,062 - INFO - Epoch 1/25, Train Loss: 10.9829, Val Loss: 8.9970
2024-12-27 17:16:14,294 - INFO - Epoch 2/25, Train Loss: 2.2667, Val Loss: 6.8020
2024-12-27 17:16:15,558 - INFO - Epoch 3/25, Train Loss: 1.0114, Val Loss: 6.1875
2024-12-27 17:16:16,825 - INFO - Epoch 4/25, Train Loss: 0.7074, Val Loss: 6.3429
2024-12-27 17:16:18,123 - INFO - Epoch 5/25, Train Loss: 0.5808, Val Loss: 6.0838
2024-12-27 17:16:19,385 - INFO - Epoch 6/25, Train Loss: 0.5257, Val Loss: 6.3065
2024-12-27 17:16:20,602 - INFO - Epoch 7/25, Train Loss: 0.4787, Val Loss: 6.4370
2024-12-27 17:16:20,602 - INFO - Early stopping triggered at epoch 7
2024-12-27 17:16:20,602 - INFO - Training completed in 9.07s
2024-12-27 17:16:20,602 - INFO - Final memory usage: CPU 2536.3 MB, GPU 48.4 MB
2024-12-27 17:16:20,603 - INFO - Model training completed in 9.08s
2024-12-27 17:16:20,631 - INFO - Prediction completed in 0.03s
2024-12-27 17:16:20,642 - INFO - Poison rate 0.03 completed in 19.09s
2024-12-27 17:16:20,642 - INFO - 
Processing poison rate: 0.05
2024-12-27 17:16:20,660 - INFO - Total number of labels flipped: 987
2024-12-27 17:16:20,661 - INFO - Label flipping completed in 0.02s
2024-12-27 17:16:20,661 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:16:20,661 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:16:22,452 - INFO - Feature scaling completed in 1.79s
2024-12-27 17:16:22,452 - INFO - Starting feature selection (k=50)
2024-12-27 17:16:22,502 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 17:16:22,502 - INFO - Starting anomaly detection
2024-12-27 17:16:28,340 - INFO - Anomaly detection completed in 5.84s
2024-12-27 17:16:28,341 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:16:28,341 - INFO - Total fit_transform time: 7.68s
2024-12-27 17:16:28,341 - INFO - Training set processing completed in 7.68s
2024-12-27 17:16:28,341 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 17:16:28,342 - INFO - Memory usage at start_fit: CPU 2439.8 MB, GPU 48.1 MB
2024-12-27 17:16:28,342 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:16:28,343 - INFO - Number of unique classes: 43
2024-12-27 17:16:28,669 - INFO - Fitted scaler and transformed data
2024-12-27 17:16:28,670 - INFO - Scaling time: 0.33s
2024-12-27 17:16:29,720 - INFO - Epoch 1/25, Train Loss: 14.5002, Val Loss: 13.2594
2024-12-27 17:16:30,731 - INFO - Epoch 2/25, Train Loss: 3.1318, Val Loss: 10.9541
2024-12-27 17:16:31,747 - INFO - Epoch 3/25, Train Loss: 1.3803, Val Loss: 9.5479
2024-12-27 17:16:32,759 - INFO - Epoch 4/25, Train Loss: 0.9728, Val Loss: 8.9912
2024-12-27 17:16:33,794 - INFO - Epoch 5/25, Train Loss: 0.7275, Val Loss: 9.0098
2024-12-27 17:16:34,823 - INFO - Epoch 6/25, Train Loss: 0.6316, Val Loss: 8.8871
2024-12-27 17:16:35,923 - INFO - Epoch 7/25, Train Loss: 0.6014, Val Loss: 9.0794
2024-12-27 17:16:36,978 - INFO - Epoch 8/25, Train Loss: 0.5643, Val Loss: 9.1804
2024-12-27 17:16:36,979 - INFO - Early stopping triggered at epoch 8
2024-12-27 17:16:36,979 - INFO - Training completed in 8.64s
2024-12-27 17:16:36,979 - INFO - Final memory usage: CPU 2536.3 MB, GPU 48.4 MB
2024-12-27 17:16:36,980 - INFO - Model training completed in 8.64s
2024-12-27 17:16:37,009 - INFO - Prediction completed in 0.03s
2024-12-27 17:16:37,020 - INFO - Poison rate 0.05 completed in 16.38s
2024-12-27 17:16:37,020 - INFO - 
Processing poison rate: 0.07
2024-12-27 17:16:37,045 - INFO - Total number of labels flipped: 1382
2024-12-27 17:16:37,045 - INFO - Label flipping completed in 0.03s
2024-12-27 17:16:37,046 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:16:37,046 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:16:38,960 - INFO - Feature scaling completed in 1.91s
2024-12-27 17:16:38,961 - INFO - Starting feature selection (k=50)
2024-12-27 17:16:39,013 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 17:16:39,014 - INFO - Starting anomaly detection
2024-12-27 17:16:46,059 - INFO - Anomaly detection completed in 7.05s
2024-12-27 17:16:46,059 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:16:46,060 - INFO - Total fit_transform time: 9.01s
2024-12-27 17:16:46,060 - INFO - Training set processing completed in 9.01s
2024-12-27 17:16:46,060 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 17:16:46,061 - INFO - Memory usage at start_fit: CPU 2439.8 MB, GPU 48.1 MB
2024-12-27 17:16:46,062 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:16:46,064 - INFO - Number of unique classes: 43
2024-12-27 17:16:46,394 - INFO - Fitted scaler and transformed data
2024-12-27 17:16:46,394 - INFO - Scaling time: 0.33s
2024-12-27 17:16:47,474 - INFO - Epoch 1/25, Train Loss: 17.1839, Val Loss: 16.4851
2024-12-27 17:16:48,617 - INFO - Epoch 2/25, Train Loss: 3.9646, Val Loss: 14.1855
2024-12-27 17:16:49,824 - INFO - Epoch 3/25, Train Loss: 1.7788, Val Loss: 12.8095
2024-12-27 17:16:51,046 - INFO - Epoch 4/25, Train Loss: 1.1336, Val Loss: 12.3543
2024-12-27 17:16:52,382 - INFO - Epoch 5/25, Train Loss: 0.9395, Val Loss: 12.1221
2024-12-27 17:16:53,598 - INFO - Epoch 6/25, Train Loss: 0.8176, Val Loss: 12.1339
2024-12-27 17:16:54,777 - INFO - Epoch 7/25, Train Loss: 0.7178, Val Loss: 12.4669
2024-12-27 17:16:54,778 - INFO - Early stopping triggered at epoch 7
2024-12-27 17:16:54,778 - INFO - Training completed in 8.72s
2024-12-27 17:16:54,778 - INFO - Final memory usage: CPU 2540.1 MB, GPU 48.4 MB
2024-12-27 17:16:54,779 - INFO - Model training completed in 8.72s
2024-12-27 17:16:54,808 - INFO - Prediction completed in 0.03s
2024-12-27 17:16:54,820 - INFO - Poison rate 0.07 completed in 17.80s
2024-12-27 17:16:54,820 - INFO - 
Processing poison rate: 0.1
2024-12-27 17:16:54,856 - INFO - Total number of labels flipped: 1975
2024-12-27 17:16:54,856 - INFO - Label flipping completed in 0.04s
2024-12-27 17:16:54,856 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:16:54,856 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:16:56,708 - INFO - Feature scaling completed in 1.85s
2024-12-27 17:16:56,708 - INFO - Starting feature selection (k=50)
2024-12-27 17:16:56,759 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 17:16:56,759 - INFO - Starting anomaly detection
2024-12-27 17:17:04,718 - INFO - Anomaly detection completed in 7.96s
2024-12-27 17:17:04,718 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:17:04,718 - INFO - Total fit_transform time: 9.86s
2024-12-27 17:17:04,719 - INFO - Training set processing completed in 9.86s
2024-12-27 17:17:04,719 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 17:17:04,720 - INFO - Memory usage at start_fit: CPU 2443.7 MB, GPU 48.1 MB
2024-12-27 17:17:04,720 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:17:04,722 - INFO - Number of unique classes: 43
2024-12-27 17:17:05,067 - INFO - Fitted scaler and transformed data
2024-12-27 17:17:05,067 - INFO - Scaling time: 0.34s
2024-12-27 17:17:06,099 - INFO - Epoch 1/25, Train Loss: 21.7153, Val Loss: 21.9018
2024-12-27 17:17:07,147 - INFO - Epoch 2/25, Train Loss: 5.5760, Val Loss: 18.4916
2024-12-27 17:17:08,212 - INFO - Epoch 3/25, Train Loss: 2.7519, Val Loss: 18.1296
2024-12-27 17:17:09,400 - INFO - Epoch 4/25, Train Loss: 1.7821, Val Loss: 17.0984
2024-12-27 17:17:10,658 - INFO - Epoch 5/25, Train Loss: 1.3705, Val Loss: 16.5437
2024-12-27 17:17:11,924 - INFO - Epoch 6/25, Train Loss: 1.0802, Val Loss: 16.7555
2024-12-27 17:17:13,082 - INFO - Epoch 7/25, Train Loss: 0.9986, Val Loss: 16.8039
2024-12-27 17:17:13,083 - INFO - Early stopping triggered at epoch 7
2024-12-27 17:17:13,083 - INFO - Training completed in 8.36s
2024-12-27 17:17:13,083 - INFO - Final memory usage: CPU 2542.4 MB, GPU 48.4 MB
2024-12-27 17:17:13,084 - INFO - Model training completed in 8.36s
2024-12-27 17:17:13,121 - INFO - Prediction completed in 0.04s
2024-12-27 17:17:13,136 - INFO - Poison rate 0.1 completed in 18.32s
2024-12-27 17:17:13,136 - INFO - 
Processing poison rate: 0.2
2024-12-27 17:17:13,227 - INFO - Total number of labels flipped: 3951
2024-12-27 17:17:13,227 - INFO - Label flipping completed in 0.09s
2024-12-27 17:17:13,227 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:17:13,228 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:17:15,163 - INFO - Feature scaling completed in 1.94s
2024-12-27 17:17:15,164 - INFO - Starting feature selection (k=50)
2024-12-27 17:17:15,215 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 17:17:15,215 - INFO - Starting anomaly detection
2024-12-27 17:17:22,984 - INFO - Anomaly detection completed in 7.77s
2024-12-27 17:17:22,985 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:17:22,985 - INFO - Total fit_transform time: 9.76s
2024-12-27 17:17:22,986 - INFO - Training set processing completed in 9.76s
2024-12-27 17:17:22,987 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 17:17:22,988 - INFO - Memory usage at start_fit: CPU 2446.0 MB, GPU 48.1 MB
2024-12-27 17:17:22,988 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:17:22,989 - INFO - Number of unique classes: 43
2024-12-27 17:17:23,369 - INFO - Fitted scaler and transformed data
2024-12-27 17:17:23,370 - INFO - Scaling time: 0.38s
2024-12-27 17:17:24,582 - INFO - Epoch 1/25, Train Loss: 34.6614, Val Loss: 38.0875
2024-12-27 17:17:25,828 - INFO - Epoch 2/25, Train Loss: 11.5009, Val Loss: 34.1655
2024-12-27 17:17:27,110 - INFO - Epoch 3/25, Train Loss: 6.5373, Val Loss: 33.4954
2024-12-27 17:17:28,230 - INFO - Epoch 4/25, Train Loss: 4.7878, Val Loss: 33.8400
2024-12-27 17:17:29,465 - INFO - Epoch 5/25, Train Loss: 3.8548, Val Loss: 33.1786
2024-12-27 17:17:30,599 - INFO - Epoch 6/25, Train Loss: 3.1014, Val Loss: 33.5415
2024-12-27 17:17:31,704 - INFO - Epoch 7/25, Train Loss: 2.8067, Val Loss: 35.4250
2024-12-27 17:17:31,704 - INFO - Early stopping triggered at epoch 7
2024-12-27 17:17:31,704 - INFO - Training completed in 8.72s
2024-12-27 17:17:31,705 - INFO - Final memory usage: CPU 2543.5 MB, GPU 48.4 MB
2024-12-27 17:17:31,705 - INFO - Model training completed in 8.72s
2024-12-27 17:17:31,737 - INFO - Prediction completed in 0.03s
2024-12-27 17:17:31,748 - INFO - Poison rate 0.2 completed in 18.61s
2024-12-27 17:17:31,750 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 17:17:31,750 - INFO - Total evaluation time: 161.73s
2024-12-27 17:17:31,756 - INFO - 
Progress: 3.1% - Evaluating GTSRB with LogisticRegression (standard mode, iteration 1/1)
2024-12-27 17:17:31,813 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 17:17:31,943 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 17:17:32,024 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 17:17:32,024 - INFO - Dataset type: image
2024-12-27 17:17:32,024 - INFO - Sample size: 39209
2024-12-27 17:17:32,024 - INFO - Using device: cuda
2024-12-27 17:17:32,024 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 17:17:32,026 - INFO - Loading datasets...
2024-12-27 17:17:49,286 - INFO - Dataset loading completed in 17.26s
2024-12-27 17:17:49,287 - INFO - Extracting validation features...
2024-12-27 17:17:49,287 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:32,  4.21it/s]Extracting features:   2%|▏         | 3/139 [00:00<00:13,  9.92it/s]Extracting features:   4%|▎         | 5/139 [00:00<00:11, 11.54it/s]Extracting features:   6%|▋         | 9/139 [00:00<00:06, 19.23it/s]Extracting features:  11%|█         | 15/139 [00:00<00:04, 29.77it/s]Extracting features:  14%|█▎        | 19/139 [00:00<00:03, 32.53it/s]Extracting features:  17%|█▋        | 24/139 [00:00<00:03, 35.40it/s]Extracting features:  22%|██▏       | 30/139 [00:01<00:02, 41.33it/s]Extracting features:  26%|██▌       | 36/139 [00:01<00:02, 45.40it/s]Extracting features:  29%|██▉       | 41/139 [00:01<00:02, 44.38it/s]Extracting features:  34%|███▍      | 47/139 [00:01<00:01, 47.41it/s]Extracting features:  38%|███▊      | 53/139 [00:01<00:01, 50.81it/s]Extracting features:  42%|████▏     | 59/139 [00:01<00:01, 45.09it/s]Extracting features:  46%|████▌     | 64/139 [00:01<00:01, 42.09it/s]Extracting features:  51%|█████     | 71/139 [00:01<00:01, 47.35it/s]Extracting features:  55%|█████▌    | 77/139 [00:02<00:01, 48.76it/s]Extracting features:  59%|█████▉    | 82/139 [00:02<00:01, 45.94it/s]Extracting features:  63%|██████▎   | 87/139 [00:02<00:01, 44.75it/s]Extracting features:  68%|██████▊   | 94/139 [00:02<00:00, 48.51it/s]Extracting features:  72%|███████▏  | 100/139 [00:02<00:00, 48.37it/s]Extracting features:  76%|███████▌  | 105/139 [00:02<00:00, 48.01it/s]Extracting features:  80%|███████▉  | 111/139 [00:02<00:00, 48.15it/s]Extracting features:  85%|████████▍ | 118/139 [00:02<00:00, 53.61it/s]Extracting features:  89%|████████▉ | 124/139 [00:03<00:00, 48.29it/s]Extracting features:  93%|█████████▎| 129/139 [00:03<00:00, 43.04it/s]Extracting features:  96%|█████████▋| 134/139 [00:03<00:00, 42.85it/s]Extracting features: 100%|██████████| 139/139 [00:03<00:00, 35.32it/s]Extracting features: 100%|██████████| 139/139 [00:03<00:00, 39.52it/s]
2024-12-27 17:17:52,816 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 17:17:52,816 - INFO - Validation feature extraction completed in 3.53s
2024-12-27 17:17:52,816 - INFO - Extracting training features...
2024-12-27 17:17:52,817 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<02:06,  4.88it/s]Extracting features:   1%|          | 6/618 [00:00<00:28, 21.22it/s]Extracting features:   2%|▏         | 11/618 [00:00<00:21, 28.84it/s]Extracting features:   2%|▏         | 15/618 [00:00<00:19, 30.55it/s]Extracting features:   3%|▎         | 19/618 [00:00<00:18, 31.62it/s]Extracting features:   4%|▍         | 24/618 [00:00<00:16, 36.23it/s]Extracting features:   5%|▍         | 28/618 [00:00<00:16, 36.11it/s]Extracting features:   5%|▌         | 32/618 [00:01<00:15, 36.65it/s]Extracting features:   6%|▌         | 37/618 [00:01<00:15, 38.72it/s]Extracting features:   7%|▋         | 43/618 [00:01<00:13, 42.61it/s]Extracting features:   8%|▊         | 50/618 [00:01<00:11, 47.86it/s]Extracting features:   9%|▉         | 56/618 [00:01<00:11, 48.88it/s]Extracting features:  10%|█         | 62/618 [00:01<00:11, 50.32it/s]Extracting features:  11%|█         | 69/618 [00:01<00:09, 55.26it/s]Extracting features:  12%|█▏        | 75/618 [00:01<00:11, 46.57it/s]Extracting features:  13%|█▎        | 80/618 [00:02<00:12, 42.32it/s]Extracting features:  14%|█▍        | 85/618 [00:02<00:13, 40.25it/s]Extracting features:  15%|█▍        | 90/618 [00:02<00:13, 39.71it/s]Extracting features:  15%|█▌        | 95/618 [00:02<00:13, 39.28it/s]Extracting features:  17%|█▋        | 102/618 [00:02<00:11, 45.18it/s]Extracting features:  17%|█▋        | 108/618 [00:02<00:10, 48.88it/s]Extracting features:  18%|█▊        | 114/618 [00:02<00:09, 50.57it/s]Extracting features:  20%|█▉        | 121/618 [00:02<00:09, 55.10it/s]Extracting features:  21%|██        | 127/618 [00:02<00:08, 56.32it/s]Extracting features:  22%|██▏       | 133/618 [00:03<00:08, 56.84it/s]Extracting features:  22%|██▏       | 139/618 [00:03<00:08, 54.61it/s]Extracting features:  23%|██▎       | 145/618 [00:03<00:08, 55.74it/s]Extracting features:  24%|██▍       | 151/618 [00:03<00:08, 56.31it/s]Extracting features:  25%|██▌       | 157/618 [00:03<00:08, 56.53it/s]Extracting features:  27%|██▋       | 164/618 [00:03<00:07, 58.90it/s]Extracting features:  28%|██▊       | 170/618 [00:03<00:07, 58.71it/s]Extracting features:  29%|██▊       | 177/618 [00:03<00:07, 58.81it/s]Extracting features:  30%|██▉       | 183/618 [00:03<00:07, 58.89it/s]Extracting features:  31%|███       | 190/618 [00:04<00:07, 58.94it/s]Extracting features:  32%|███▏      | 197/618 [00:04<00:06, 60.23it/s]Extracting features:  33%|███▎      | 204/618 [00:04<00:07, 53.07it/s]Extracting features:  34%|███▍      | 210/618 [00:04<00:07, 52.15it/s]Extracting features:  35%|███▍      | 216/618 [00:04<00:07, 52.44it/s]Extracting features:  36%|███▌      | 222/618 [00:04<00:07, 52.93it/s]Extracting features:  37%|███▋      | 229/618 [00:04<00:07, 54.07it/s]Extracting features:  38%|███▊      | 235/618 [00:04<00:07, 47.92it/s]Extracting features:  39%|███▉      | 240/618 [00:05<00:08, 46.76it/s]Extracting features:  40%|███▉      | 246/618 [00:05<00:07, 50.05it/s]Extracting features:  41%|████      | 253/618 [00:05<00:07, 51.90it/s]Extracting features:  42%|████▏     | 259/618 [00:05<00:07, 50.27it/s]Extracting features:  43%|████▎     | 265/618 [00:05<00:08, 43.37it/s]Extracting features:  44%|████▍     | 271/618 [00:05<00:07, 46.56it/s]Extracting features:  45%|████▍     | 277/618 [00:05<00:06, 49.21it/s]Extracting features:  46%|████▌     | 283/618 [00:05<00:06, 49.09it/s]Extracting features:  47%|████▋     | 289/618 [00:06<00:06, 51.45it/s]Extracting features:  48%|████▊     | 296/618 [00:06<00:05, 54.32it/s]Extracting features:  49%|████▉     | 302/618 [00:06<00:05, 54.35it/s]Extracting features:  50%|████▉     | 308/618 [00:06<00:07, 40.81it/s]Extracting features:  51%|█████     | 313/618 [00:06<00:07, 41.87it/s]Extracting features:  51%|█████▏    | 318/618 [00:06<00:07, 39.64it/s]Extracting features:  52%|█████▏    | 323/618 [00:06<00:07, 40.12it/s]Extracting features:  53%|█████▎    | 330/618 [00:06<00:06, 46.25it/s]Extracting features:  54%|█████▍    | 335/618 [00:07<00:06, 46.49it/s]Extracting features:  55%|█████▌    | 341/618 [00:07<00:05, 49.34it/s]Extracting features:  56%|█████▌    | 347/618 [00:07<00:06, 41.92it/s]Extracting features:  57%|█████▋    | 352/618 [00:07<00:07, 37.69it/s]Extracting features:  58%|█████▊    | 357/618 [00:07<00:07, 36.11it/s]Extracting features:  59%|█████▊    | 362/618 [00:07<00:06, 38.86it/s]Extracting features:  59%|█████▉    | 367/618 [00:07<00:06, 40.47it/s]Extracting features:  60%|██████    | 372/618 [00:08<00:06, 39.86it/s]Extracting features:  61%|██████▏   | 379/618 [00:08<00:05, 45.27it/s]Extracting features:  62%|██████▏   | 385/618 [00:08<00:04, 48.99it/s]Extracting features:  63%|██████▎   | 391/618 [00:08<00:04, 49.37it/s]Extracting features:  64%|██████▍   | 397/618 [00:08<00:04, 47.43it/s]Extracting features:  65%|██████▌   | 402/618 [00:08<00:04, 47.50it/s]Extracting features:  66%|██████▌   | 409/618 [00:08<00:03, 52.41it/s]Extracting features:  67%|██████▋   | 415/618 [00:08<00:03, 53.98it/s]Extracting features:  68%|██████▊   | 421/618 [00:09<00:04, 46.79it/s]Extracting features:  69%|██████▉   | 427/618 [00:09<00:03, 50.04it/s]Extracting features:  70%|███████   | 434/618 [00:09<00:03, 54.08it/s]Extracting features:  71%|███████   | 440/618 [00:09<00:03, 54.34it/s]Extracting features:  72%|███████▏  | 446/618 [00:09<00:03, 54.45it/s]Extracting features:  73%|███████▎  | 452/618 [00:09<00:03, 51.11it/s]Extracting features:  74%|███████▍  | 458/618 [00:09<00:03, 52.31it/s]Extracting features:  75%|███████▌  | 464/618 [00:09<00:03, 49.95it/s]Extracting features:  76%|███████▌  | 470/618 [00:09<00:02, 51.05it/s]Extracting features:  77%|███████▋  | 476/618 [00:10<00:02, 53.23it/s]Extracting features:  78%|███████▊  | 482/618 [00:10<00:02, 50.85it/s]Extracting features:  79%|███████▉  | 488/618 [00:10<00:02, 50.70it/s]Extracting features:  80%|███████▉  | 494/618 [00:10<00:02, 47.82it/s]Extracting features:  81%|████████  | 500/618 [00:10<00:02, 48.30it/s]Extracting features:  82%|████████▏ | 505/618 [00:10<00:02, 46.78it/s]Extracting features:  83%|████████▎ | 510/618 [00:10<00:02, 44.08it/s]Extracting features:  84%|████████▎ | 517/618 [00:10<00:02, 50.15it/s]Extracting features:  85%|████████▍ | 524/618 [00:11<00:01, 53.24it/s]Extracting features:  86%|████████▌ | 530/618 [00:11<00:01, 52.68it/s]Extracting features:  87%|████████▋ | 536/618 [00:11<00:01, 54.49it/s]Extracting features:  88%|████████▊ | 542/618 [00:11<00:01, 53.65it/s]Extracting features:  89%|████████▊ | 548/618 [00:11<00:01, 55.37it/s]Extracting features:  90%|████████▉ | 555/618 [00:11<00:01, 57.61it/s]Extracting features:  91%|█████████ | 562/618 [00:11<00:00, 59.88it/s]Extracting features:  92%|█████████▏| 570/618 [00:11<00:00, 64.12it/s]Extracting features:  93%|█████████▎| 577/618 [00:11<00:00, 63.48it/s]Extracting features:  94%|█████████▍| 584/618 [00:12<00:00, 59.69it/s]Extracting features:  96%|█████████▌| 591/618 [00:12<00:00, 57.76it/s]Extracting features:  97%|█████████▋| 597/618 [00:12<00:00, 58.29it/s]Extracting features:  98%|█████████▊| 603/618 [00:12<00:00, 57.59it/s]Extracting features:  99%|█████████▊| 609/618 [00:12<00:00, 52.08it/s]Extracting features: 100%|█████████▉| 615/618 [00:12<00:00, 52.65it/s]Extracting features: 100%|██████████| 618/618 [00:12<00:00, 48.57it/s]
2024-12-27 17:18:05,567 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 17:18:05,567 - INFO - Training feature extraction completed in 12.75s
2024-12-27 17:18:05,567 - INFO - Creating model for classifier: LogisticRegression
2024-12-27 17:18:05,567 - INFO - Using device: cuda
2024-12-27 17:18:05,567 - INFO - 
Processing poison rate: 0.0
2024-12-27 17:18:05,568 - INFO - Training set processing completed in 0.00s
2024-12-27 17:18:05,568 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 17:18:05,569 - INFO - Memory usage at start_fit: CPU 2536.6 MB, GPU 47.3 MB
2024-12-27 17:18:05,570 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:18:05,575 - INFO - Number of unique classes: 43
2024-12-27 17:18:05,932 - INFO - Fitted scaler and transformed data
2024-12-27 17:18:05,933 - INFO - Scaling time: 0.35s
2024-12-27 17:18:06,721 - INFO - Epoch 1/200, Train Loss: 1.4565, Val Loss: 0.9969
2024-12-27 17:18:07,516 - INFO - Epoch 2/200, Train Loss: 0.6127, Val Loss: 0.8552
2024-12-27 17:18:08,003 - INFO - Epoch 3/200, Train Loss: 0.4182, Val Loss: 0.9490
2024-12-27 17:18:08,451 - INFO - Epoch 4/200, Train Loss: 0.3389, Val Loss: 0.9011
2024-12-27 17:18:08,451 - INFO - Early stopping triggered at epoch 4
2024-12-27 17:18:08,451 - INFO - Training completed in 2.88s
2024-12-27 17:18:08,452 - INFO - Final memory usage: CPU 2638.4 MB, GPU 48.4 MB
2024-12-27 17:18:08,453 - INFO - Model training completed in 2.89s
2024-12-27 17:18:08,504 - INFO - Prediction completed in 0.05s
2024-12-27 17:18:08,519 - INFO - Poison rate 0.0 completed in 2.95s
2024-12-27 17:18:08,519 - INFO - 
Processing poison rate: 0.01
2024-12-27 17:18:08,530 - INFO - Total number of labels flipped: 197
2024-12-27 17:18:08,531 - INFO - Label flipping completed in 0.01s
2024-12-27 17:18:08,531 - INFO - Training set processing completed in 0.00s
2024-12-27 17:18:08,531 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 17:18:08,532 - INFO - Memory usage at start_fit: CPU 2542.0 MB, GPU 48.1 MB
2024-12-27 17:18:08,532 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:18:08,533 - INFO - Number of unique classes: 43
2024-12-27 17:18:08,903 - INFO - Fitted scaler and transformed data
2024-12-27 17:18:08,904 - INFO - Scaling time: 0.37s
2024-12-27 17:18:09,493 - INFO - Epoch 1/200, Train Loss: 1.6193, Val Loss: 1.2005
2024-12-27 17:18:09,984 - INFO - Epoch 2/200, Train Loss: 0.7633, Val Loss: 1.1047
2024-12-27 17:18:10,484 - INFO - Epoch 3/200, Train Loss: 0.5302, Val Loss: 1.1871
2024-12-27 17:18:11,314 - INFO - Epoch 4/200, Train Loss: 0.4255, Val Loss: 1.2163
2024-12-27 17:18:11,314 - INFO - Early stopping triggered at epoch 4
2024-12-27 17:18:11,314 - INFO - Training completed in 2.78s
2024-12-27 17:18:11,315 - INFO - Final memory usage: CPU 2638.4 MB, GPU 48.4 MB
2024-12-27 17:18:11,316 - INFO - Model training completed in 2.78s
2024-12-27 17:18:11,347 - INFO - Prediction completed in 0.03s
2024-12-27 17:18:11,377 - INFO - Poison rate 0.01 completed in 2.86s
2024-12-27 17:18:11,377 - INFO - 
Processing poison rate: 0.03
2024-12-27 17:18:11,393 - INFO - Total number of labels flipped: 592
2024-12-27 17:18:11,394 - INFO - Label flipping completed in 0.02s
2024-12-27 17:18:11,394 - INFO - Training set processing completed in 0.00s
2024-12-27 17:18:11,394 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 17:18:11,395 - INFO - Memory usage at start_fit: CPU 2542.0 MB, GPU 48.1 MB
2024-12-27 17:18:11,395 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:18:11,396 - INFO - Number of unique classes: 43
2024-12-27 17:18:11,760 - INFO - Fitted scaler and transformed data
2024-12-27 17:18:11,761 - INFO - Scaling time: 0.36s
2024-12-27 17:18:12,619 - INFO - Epoch 1/200, Train Loss: 1.8780, Val Loss: 1.4914
2024-12-27 17:18:13,483 - INFO - Epoch 2/200, Train Loss: 0.9976, Val Loss: 1.5797
2024-12-27 17:18:14,275 - INFO - Epoch 3/200, Train Loss: 0.7968, Val Loss: 1.5558
2024-12-27 17:18:14,275 - INFO - Early stopping triggered at epoch 3
2024-12-27 17:18:14,275 - INFO - Training completed in 2.88s
2024-12-27 17:18:14,275 - INFO - Final memory usage: CPU 2638.5 MB, GPU 48.4 MB
2024-12-27 17:18:14,276 - INFO - Model training completed in 2.88s
2024-12-27 17:18:14,317 - INFO - Prediction completed in 0.04s
2024-12-27 17:18:14,328 - INFO - Poison rate 0.03 completed in 2.95s
2024-12-27 17:18:14,328 - INFO - 
Processing poison rate: 0.05
2024-12-27 17:18:14,346 - INFO - Total number of labels flipped: 987
2024-12-27 17:18:14,346 - INFO - Label flipping completed in 0.02s
2024-12-27 17:18:14,347 - INFO - Training set processing completed in 0.00s
2024-12-27 17:18:14,347 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 17:18:14,347 - INFO - Memory usage at start_fit: CPU 2542.0 MB, GPU 48.1 MB
2024-12-27 17:18:14,348 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:18:14,348 - INFO - Number of unique classes: 43
2024-12-27 17:18:14,714 - INFO - Fitted scaler and transformed data
2024-12-27 17:18:14,715 - INFO - Scaling time: 0.36s
2024-12-27 17:18:15,417 - INFO - Epoch 1/200, Train Loss: 2.0933, Val Loss: 1.8474
2024-12-27 17:18:15,984 - INFO - Epoch 2/200, Train Loss: 1.2254, Val Loss: 1.8330
2024-12-27 17:18:16,543 - INFO - Epoch 3/200, Train Loss: 0.9842, Val Loss: 1.8732
2024-12-27 17:18:17,075 - INFO - Epoch 4/200, Train Loss: 0.8360, Val Loss: 2.0746
2024-12-27 17:18:17,075 - INFO - Early stopping triggered at epoch 4
2024-12-27 17:18:17,075 - INFO - Training completed in 2.73s
2024-12-27 17:18:17,075 - INFO - Final memory usage: CPU 2638.5 MB, GPU 48.4 MB
2024-12-27 17:18:17,076 - INFO - Model training completed in 2.73s
2024-12-27 17:18:17,122 - INFO - Prediction completed in 0.05s
2024-12-27 17:18:17,133 - INFO - Poison rate 0.05 completed in 2.80s
2024-12-27 17:18:17,133 - INFO - 
Processing poison rate: 0.07
2024-12-27 17:18:17,158 - INFO - Total number of labels flipped: 1382
2024-12-27 17:18:17,158 - INFO - Label flipping completed in 0.03s
2024-12-27 17:18:17,158 - INFO - Training set processing completed in 0.00s
2024-12-27 17:18:17,159 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 17:18:17,160 - INFO - Memory usage at start_fit: CPU 2542.1 MB, GPU 48.1 MB
2024-12-27 17:18:17,160 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:18:17,162 - INFO - Number of unique classes: 43
2024-12-27 17:18:17,508 - INFO - Fitted scaler and transformed data
2024-12-27 17:18:17,508 - INFO - Scaling time: 0.34s
2024-12-27 17:18:18,018 - INFO - Epoch 1/200, Train Loss: 2.2913, Val Loss: 2.0170
2024-12-27 17:18:18,585 - INFO - Epoch 2/200, Train Loss: 1.4301, Val Loss: 2.0437
2024-12-27 17:18:19,155 - INFO - Epoch 3/200, Train Loss: 1.1585, Val Loss: 2.1067
2024-12-27 17:18:19,155 - INFO - Early stopping triggered at epoch 3
2024-12-27 17:18:19,155 - INFO - Training completed in 2.00s
2024-12-27 17:18:19,155 - INFO - Final memory usage: CPU 2638.5 MB, GPU 48.4 MB
2024-12-27 17:18:19,156 - INFO - Model training completed in 2.00s
2024-12-27 17:18:19,187 - INFO - Prediction completed in 0.03s
2024-12-27 17:18:19,199 - INFO - Poison rate 0.07 completed in 2.07s
2024-12-27 17:18:19,199 - INFO - 
Processing poison rate: 0.1
2024-12-27 17:18:19,243 - INFO - Total number of labels flipped: 1975
2024-12-27 17:18:19,244 - INFO - Label flipping completed in 0.04s
2024-12-27 17:18:19,244 - INFO - Training set processing completed in 0.00s
2024-12-27 17:18:19,244 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 17:18:19,246 - INFO - Memory usage at start_fit: CPU 2542.1 MB, GPU 48.1 MB
2024-12-27 17:18:19,246 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:18:19,248 - INFO - Number of unique classes: 43
2024-12-27 17:18:19,605 - INFO - Fitted scaler and transformed data
2024-12-27 17:18:19,605 - INFO - Scaling time: 0.36s
2024-12-27 17:18:20,131 - INFO - Epoch 1/200, Train Loss: 2.5030, Val Loss: 2.4029
2024-12-27 17:18:20,645 - INFO - Epoch 2/200, Train Loss: 1.6185, Val Loss: 2.5186
2024-12-27 17:18:21,245 - INFO - Epoch 3/200, Train Loss: 1.3786, Val Loss: 2.8129
2024-12-27 17:18:21,246 - INFO - Early stopping triggered at epoch 3
2024-12-27 17:18:21,246 - INFO - Training completed in 2.00s
2024-12-27 17:18:21,247 - INFO - Final memory usage: CPU 2638.9 MB, GPU 48.4 MB
2024-12-27 17:18:21,249 - INFO - Model training completed in 2.00s
2024-12-27 17:18:21,284 - INFO - Prediction completed in 0.04s
2024-12-27 17:18:21,295 - INFO - Poison rate 0.1 completed in 2.10s
2024-12-27 17:18:21,296 - INFO - 
Processing poison rate: 0.2
2024-12-27 17:18:21,364 - INFO - Total number of labels flipped: 3951
2024-12-27 17:18:21,364 - INFO - Label flipping completed in 0.07s
2024-12-27 17:18:21,364 - INFO - Training set processing completed in 0.00s
2024-12-27 17:18:21,364 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 17:18:21,365 - INFO - Memory usage at start_fit: CPU 2542.5 MB, GPU 48.1 MB
2024-12-27 17:18:21,365 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:18:21,366 - INFO - Number of unique classes: 43
2024-12-27 17:18:21,721 - INFO - Fitted scaler and transformed data
2024-12-27 17:18:21,721 - INFO - Scaling time: 0.35s
2024-12-27 17:18:22,223 - INFO - Epoch 1/200, Train Loss: 3.3031, Val Loss: 3.1262
2024-12-27 17:18:22,750 - INFO - Epoch 2/200, Train Loss: 2.4444, Val Loss: 3.2406
2024-12-27 17:18:23,300 - INFO - Epoch 3/200, Train Loss: 2.2008, Val Loss: 3.5937
2024-12-27 17:18:23,300 - INFO - Early stopping triggered at epoch 3
2024-12-27 17:18:23,300 - INFO - Training completed in 1.93s
2024-12-27 17:18:23,300 - INFO - Final memory usage: CPU 2640.4 MB, GPU 48.4 MB
2024-12-27 17:18:23,301 - INFO - Model training completed in 1.94s
2024-12-27 17:18:23,352 - INFO - Prediction completed in 0.05s
2024-12-27 17:18:23,369 - INFO - Poison rate 0.2 completed in 2.07s
2024-12-27 17:18:23,370 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 17:18:23,371 - INFO - Total evaluation time: 51.34s
2024-12-27 17:18:23,377 - INFO - 
Progress: 4.2% - Evaluating GTSRB with LogisticRegression (dynadetect mode, iteration 1/1)
2024-12-27 17:18:23,440 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 17:18:23,556 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 17:18:23,656 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 17:18:23,657 - INFO - Dataset type: image
2024-12-27 17:18:23,657 - INFO - Sample size: 39209
2024-12-27 17:18:23,657 - INFO - Using device: cuda
2024-12-27 17:18:23,657 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 17:18:23,658 - INFO - Loading datasets...
2024-12-27 17:18:41,290 - INFO - Dataset loading completed in 17.63s
2024-12-27 17:18:41,290 - INFO - Extracting validation features...
2024-12-27 17:18:41,291 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:27,  4.93it/s]Extracting features:   2%|▏         | 3/139 [00:00<00:13, 10.16it/s]Extracting features:   4%|▎         | 5/139 [00:00<00:11, 11.76it/s]Extracting features:   7%|▋         | 10/139 [00:00<00:05, 22.46it/s]Extracting features:  12%|█▏        | 16/139 [00:00<00:03, 33.12it/s]Extracting features:  16%|█▌        | 22/139 [00:00<00:02, 40.11it/s]Extracting features:  21%|██        | 29/139 [00:00<00:02, 46.65it/s]Extracting features:  24%|██▍       | 34/139 [00:01<00:02, 47.39it/s]Extracting features:  29%|██▉       | 40/139 [00:01<00:01, 51.00it/s]Extracting features:  33%|███▎      | 46/139 [00:01<00:01, 52.42it/s]Extracting features:  37%|███▋      | 52/139 [00:01<00:01, 48.83it/s]Extracting features:  42%|████▏     | 58/139 [00:01<00:01, 47.11it/s]Extracting features:  46%|████▌     | 64/139 [00:01<00:01, 50.10it/s]Extracting features:  51%|█████     | 71/139 [00:01<00:01, 52.42it/s]Extracting features:  55%|█████▌    | 77/139 [00:01<00:01, 49.01it/s]Extracting features:  60%|█████▉    | 83/139 [00:01<00:01, 49.53it/s]Extracting features:  64%|██████▍   | 89/139 [00:02<00:00, 50.36it/s]Extracting features:  68%|██████▊   | 95/139 [00:02<00:00, 47.06it/s]Extracting features:  72%|███████▏  | 100/139 [00:02<00:00, 46.79it/s]Extracting features:  76%|███████▋  | 106/139 [00:02<00:00, 48.86it/s]Extracting features:  81%|████████  | 112/139 [00:02<00:00, 51.27it/s]Extracting features:  86%|████████▌ | 119/139 [00:02<00:00, 53.73it/s]Extracting features:  90%|████████▉ | 125/139 [00:02<00:00, 53.59it/s]Extracting features:  94%|█████████▍| 131/139 [00:02<00:00, 52.71it/s]Extracting features:  99%|█████████▊| 137/139 [00:03<00:00, 47.18it/s]Extracting features: 100%|██████████| 139/139 [00:03<00:00, 43.72it/s]
2024-12-27 17:18:44,483 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 17:18:44,483 - INFO - Validation feature extraction completed in 3.19s
2024-12-27 17:18:44,484 - INFO - Extracting training features...
2024-12-27 17:18:44,484 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<01:52,  5.46it/s]Extracting features:   1%|          | 6/618 [00:00<00:25, 24.30it/s]Extracting features:   2%|▏         | 11/618 [00:00<00:18, 32.42it/s]Extracting features:   3%|▎         | 16/618 [00:00<00:15, 37.95it/s]Extracting features:   4%|▎         | 22/618 [00:00<00:14, 41.47it/s]Extracting features:   4%|▍         | 27/618 [00:00<00:13, 43.97it/s]Extracting features:   5%|▌         | 32/618 [00:00<00:13, 45.06it/s]Extracting features:   6%|▌         | 38/618 [00:00<00:12, 45.51it/s]Extracting features:   7%|▋         | 44/618 [00:01<00:11, 49.36it/s]Extracting features:   8%|▊         | 50/618 [00:01<00:11, 48.45it/s]Extracting features:   9%|▉         | 57/618 [00:01<00:10, 52.41it/s]Extracting features:  10%|█         | 63/618 [00:01<00:11, 48.46it/s]Extracting features:  11%|█         | 68/618 [00:01<00:12, 45.34it/s]Extracting features:  12%|█▏        | 73/618 [00:01<00:12, 45.06it/s]Extracting features:  13%|█▎        | 78/618 [00:01<00:12, 42.37it/s]Extracting features:  14%|█▎        | 84/618 [00:01<00:11, 45.53it/s]Extracting features:  14%|█▍        | 89/618 [00:02<00:11, 45.53it/s]Extracting features:  15%|█▌        | 94/618 [00:02<00:11, 44.68it/s]Extracting features:  16%|█▌        | 99/618 [00:02<00:11, 43.75it/s]Extracting features:  17%|█▋        | 104/618 [00:02<00:11, 43.71it/s]Extracting features:  18%|█▊        | 109/618 [00:02<00:12, 41.90it/s]Extracting features:  19%|█▊        | 115/618 [00:02<00:11, 43.27it/s]Extracting features:  19%|█▉        | 120/618 [00:02<00:12, 41.35it/s]Extracting features:  20%|██        | 125/618 [00:02<00:12, 39.93it/s]Extracting features:  21%|██        | 130/618 [00:03<00:11, 42.16it/s]Extracting features:  22%|██▏       | 135/618 [00:03<00:11, 41.27it/s]Extracting features:  23%|██▎       | 140/618 [00:03<00:11, 40.87it/s]Extracting features:  24%|██▍       | 147/618 [00:03<00:09, 47.40it/s]Extracting features:  25%|██▍       | 152/618 [00:03<00:10, 45.61it/s]Extracting features:  25%|██▌       | 157/618 [00:03<00:10, 43.31it/s]Extracting features:  26%|██▌       | 162/618 [00:03<00:10, 43.40it/s]Extracting features:  27%|██▋       | 167/618 [00:03<00:10, 45.01it/s]Extracting features:  28%|██▊       | 172/618 [00:03<00:09, 45.47it/s]Extracting features:  29%|██▊       | 177/618 [00:04<00:10, 43.23it/s]Extracting features:  29%|██▉       | 182/618 [00:04<00:11, 39.20it/s]Extracting features:  30%|███       | 187/618 [00:04<00:11, 37.87it/s]Extracting features:  31%|███       | 191/618 [00:04<00:11, 37.13it/s]Extracting features:  32%|███▏      | 195/618 [00:04<00:11, 37.02it/s]Extracting features:  33%|███▎      | 201/618 [00:04<00:10, 40.71it/s]Extracting features:  33%|███▎      | 207/618 [00:04<00:09, 44.10it/s]Extracting features:  34%|███▍      | 212/618 [00:05<00:09, 41.34it/s]Extracting features:  35%|███▌      | 217/618 [00:05<00:10, 39.26it/s]Extracting features:  36%|███▌      | 222/618 [00:05<00:09, 41.37it/s]Extracting features:  37%|███▋      | 227/618 [00:05<00:09, 41.56it/s]Extracting features:  38%|███▊      | 232/618 [00:05<00:09, 42.15it/s]Extracting features:  38%|███▊      | 237/618 [00:05<00:08, 42.51it/s]Extracting features:  39%|███▉      | 242/618 [00:05<00:08, 44.28it/s]Extracting features:  40%|███▉      | 247/618 [00:05<00:08, 42.56it/s]Extracting features:  41%|████      | 252/618 [00:05<00:08, 42.36it/s]Extracting features:  42%|████▏     | 257/618 [00:06<00:08, 42.05it/s]Extracting features:  42%|████▏     | 262/618 [00:06<00:08, 40.62it/s]Extracting features:  43%|████▎     | 267/618 [00:06<00:08, 41.11it/s]Extracting features:  44%|████▍     | 272/618 [00:06<00:08, 39.50it/s]Extracting features:  45%|████▍     | 276/618 [00:06<00:08, 38.56it/s]Extracting features:  45%|████▌     | 281/618 [00:06<00:08, 40.28it/s]Extracting features:  46%|████▋     | 286/618 [00:06<00:08, 40.04it/s]Extracting features:  47%|████▋     | 291/618 [00:06<00:07, 42.64it/s]Extracting features:  48%|████▊     | 298/618 [00:07<00:06, 46.92it/s]Extracting features:  49%|████▉     | 303/618 [00:07<00:07, 44.85it/s]Extracting features:  50%|████▉     | 308/618 [00:07<00:07, 40.38it/s]Extracting features:  51%|█████     | 313/618 [00:07<00:08, 38.09it/s]Extracting features:  52%|█████▏    | 319/618 [00:07<00:06, 42.96it/s]Extracting features:  52%|█████▏    | 324/618 [00:07<00:07, 41.78it/s]Extracting features:  53%|█████▎    | 329/618 [00:07<00:07, 39.22it/s]Extracting features:  54%|█████▍    | 334/618 [00:07<00:07, 37.72it/s]Extracting features:  55%|█████▍    | 339/618 [00:08<00:07, 38.67it/s]Extracting features:  56%|█████▌    | 344/618 [00:08<00:06, 39.77it/s]Extracting features:  56%|█████▋    | 349/618 [00:08<00:07, 36.04it/s]Extracting features:  57%|█████▋    | 354/618 [00:08<00:06, 39.10it/s]Extracting features:  58%|█████▊    | 359/618 [00:08<00:06, 41.24it/s]Extracting features:  59%|█████▉    | 364/618 [00:08<00:05, 42.51it/s]Extracting features:  60%|█████▉    | 369/618 [00:08<00:06, 40.53it/s]Extracting features:  61%|██████    | 374/618 [00:08<00:06, 40.43it/s]Extracting features:  61%|██████▏   | 379/618 [00:09<00:06, 38.20it/s]Extracting features:  62%|██████▏   | 383/618 [00:09<00:06, 38.35it/s]Extracting features:  63%|██████▎   | 387/618 [00:09<00:06, 37.29it/s]Extracting features:  63%|██████▎   | 391/618 [00:09<00:06, 37.66it/s]Extracting features:  64%|██████▍   | 395/618 [00:09<00:06, 37.12it/s]Extracting features:  65%|██████▍   | 399/618 [00:09<00:05, 36.55it/s]Extracting features:  65%|██████▌   | 404/618 [00:09<00:05, 36.22it/s]Extracting features:  66%|██████▌   | 409/618 [00:09<00:05, 39.16it/s]Extracting features:  67%|██████▋   | 415/618 [00:10<00:04, 42.13it/s]Extracting features:  68%|██████▊   | 420/618 [00:10<00:04, 39.69it/s]Extracting features:  69%|██████▉   | 425/618 [00:10<00:05, 37.87it/s]Extracting features:  70%|██████▉   | 430/618 [00:10<00:04, 39.27it/s]Extracting features:  70%|███████   | 435/618 [00:10<00:04, 38.90it/s]Extracting features:  71%|███████   | 439/618 [00:10<00:04, 38.58it/s]Extracting features:  72%|███████▏  | 444/618 [00:10<00:04, 40.82it/s]Extracting features:  73%|███████▎  | 449/618 [00:10<00:04, 37.21it/s]Extracting features:  73%|███████▎  | 453/618 [00:11<00:04, 36.30it/s]Extracting features:  74%|███████▍  | 457/618 [00:11<00:04, 35.10it/s]Extracting features:  75%|███████▍  | 461/618 [00:11<00:04, 36.34it/s]Extracting features:  75%|███████▌  | 465/618 [00:11<00:04, 34.63it/s]Extracting features:  76%|███████▌  | 470/618 [00:11<00:03, 37.18it/s]Extracting features:  77%|███████▋  | 475/618 [00:11<00:03, 39.49it/s]Extracting features:  78%|███████▊  | 481/618 [00:11<00:03, 42.95it/s]Extracting features:  79%|███████▊  | 486/618 [00:11<00:03, 43.69it/s]Extracting features:  79%|███████▉  | 491/618 [00:12<00:03, 41.12it/s]Extracting features:  80%|████████  | 496/618 [00:12<00:02, 41.77it/s]Extracting features:  81%|████████  | 501/618 [00:12<00:02, 40.91it/s]Extracting features:  82%|████████▏ | 506/618 [00:12<00:02, 39.77it/s]Extracting features:  83%|████████▎ | 511/618 [00:12<00:02, 39.02it/s]Extracting features:  83%|████████▎ | 516/618 [00:12<00:02, 39.03it/s]Extracting features:  84%|████████▍ | 520/618 [00:12<00:02, 37.14it/s]Extracting features:  85%|████████▍ | 525/618 [00:12<00:02, 38.61it/s]Extracting features:  86%|████████▌ | 529/618 [00:13<00:02, 37.97it/s]Extracting features:  86%|████████▌ | 533/618 [00:13<00:02, 36.44it/s]Extracting features:  87%|████████▋ | 538/618 [00:13<00:02, 37.55it/s]Extracting features:  88%|████████▊ | 542/618 [00:13<00:02, 35.75it/s]Extracting features:  88%|████████▊ | 546/618 [00:13<00:02, 35.16it/s]Extracting features:  89%|████████▉ | 550/618 [00:13<00:01, 35.93it/s]Extracting features:  90%|████████▉ | 554/618 [00:13<00:01, 34.61it/s]Extracting features:  90%|█████████ | 558/618 [00:13<00:01, 33.64it/s]Extracting features:  91%|█████████ | 562/618 [00:13<00:01, 34.43it/s]Extracting features:  92%|█████████▏| 566/618 [00:14<00:01, 34.91it/s]Extracting features:  92%|█████████▏| 571/618 [00:14<00:01, 37.96it/s]Extracting features:  93%|█████████▎| 577/618 [00:14<00:00, 42.07it/s]Extracting features:  94%|█████████▍| 582/618 [00:14<00:00, 42.22it/s]Extracting features:  95%|█████████▍| 587/618 [00:14<00:00, 38.61it/s]Extracting features:  96%|█████████▌| 591/618 [00:14<00:00, 38.08it/s]Extracting features:  96%|█████████▋| 595/618 [00:14<00:00, 37.24it/s]Extracting features:  97%|█████████▋| 600/618 [00:14<00:00, 38.48it/s]Extracting features:  98%|█████████▊| 605/618 [00:15<00:00, 40.29it/s]Extracting features:  99%|█████████▊| 610/618 [00:15<00:00, 38.83it/s]Extracting features: 100%|█████████▉| 616/618 [00:15<00:00, 43.86it/s]Extracting features: 100%|██████████| 618/618 [00:15<00:00, 40.08it/s]
2024-12-27 17:18:59,938 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 17:18:59,938 - INFO - Training feature extraction completed in 15.45s
2024-12-27 17:18:59,938 - INFO - Creating model for classifier: LogisticRegression
2024-12-27 17:18:59,939 - INFO - Using device: cuda
2024-12-27 17:18:59,939 - INFO - 
Processing poison rate: 0.0
2024-12-27 17:18:59,939 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:18:59,939 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:19:01,775 - INFO - Feature scaling completed in 1.84s
2024-12-27 17:19:01,775 - INFO - Starting feature selection (k=50)
2024-12-27 17:19:01,803 - INFO - Feature selection completed in 0.03s. Output shape: (19755, 50)
2024-12-27 17:19:01,803 - INFO - Starting anomaly detection
2024-12-27 17:19:09,738 - INFO - Anomaly detection completed in 7.94s
2024-12-27 17:19:09,738 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:19:09,739 - INFO - Total fit_transform time: 9.80s
2024-12-27 17:19:09,739 - INFO - Training set processing completed in 9.80s
2024-12-27 17:19:09,739 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 17:19:09,740 - INFO - Memory usage at start_fit: CPU 2603.1 MB, GPU 47.3 MB
2024-12-27 17:19:09,741 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:19:09,743 - INFO - Number of unique classes: 43
2024-12-27 17:19:10,092 - INFO - Fitted scaler and transformed data
2024-12-27 17:19:10,093 - INFO - Scaling time: 0.35s
2024-12-27 17:19:10,934 - INFO - Epoch 1/200, Train Loss: 1.4685, Val Loss: 0.9964
2024-12-27 17:19:11,836 - INFO - Epoch 2/200, Train Loss: 0.6178, Val Loss: 0.8865
2024-12-27 17:19:12,634 - INFO - Epoch 3/200, Train Loss: 0.4365, Val Loss: 0.9184
2024-12-27 17:19:13,465 - INFO - Epoch 4/200, Train Loss: 0.3565, Val Loss: 0.8186
2024-12-27 17:19:14,341 - INFO - Epoch 5/200, Train Loss: 0.2952, Val Loss: 0.8477
2024-12-27 17:19:15,053 - INFO - Epoch 6/200, Train Loss: 0.2529, Val Loss: 0.8983
2024-12-27 17:19:15,054 - INFO - Early stopping triggered at epoch 6
2024-12-27 17:19:15,054 - INFO - Training completed in 5.31s
2024-12-27 17:19:15,055 - INFO - Final memory usage: CPU 2727.7 MB, GPU 48.4 MB
2024-12-27 17:19:15,056 - INFO - Model training completed in 5.32s
2024-12-27 17:19:15,095 - INFO - Prediction completed in 0.04s
2024-12-27 17:19:15,106 - INFO - Poison rate 0.0 completed in 15.17s
2024-12-27 17:19:15,106 - INFO - 
Processing poison rate: 0.01
2024-12-27 17:19:15,112 - INFO - Total number of labels flipped: 197
2024-12-27 17:19:15,112 - INFO - Label flipping completed in 0.01s
2024-12-27 17:19:15,112 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:19:15,112 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:19:17,070 - INFO - Feature scaling completed in 1.96s
2024-12-27 17:19:17,070 - INFO - Starting feature selection (k=50)
2024-12-27 17:19:17,121 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 17:19:17,121 - INFO - Starting anomaly detection
2024-12-27 17:19:24,593 - INFO - Anomaly detection completed in 7.47s
2024-12-27 17:19:24,594 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:19:24,594 - INFO - Total fit_transform time: 9.48s
2024-12-27 17:19:24,594 - INFO - Training set processing completed in 9.48s
2024-12-27 17:19:24,594 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 17:19:24,595 - INFO - Memory usage at start_fit: CPU 2631.3 MB, GPU 48.1 MB
2024-12-27 17:19:24,595 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:19:24,596 - INFO - Number of unique classes: 43
2024-12-27 17:19:24,924 - INFO - Fitted scaler and transformed data
2024-12-27 17:19:24,925 - INFO - Scaling time: 0.33s
2024-12-27 17:19:25,705 - INFO - Epoch 1/200, Train Loss: 1.5924, Val Loss: 1.2630
2024-12-27 17:19:26,574 - INFO - Epoch 2/200, Train Loss: 0.7595, Val Loss: 1.2254
2024-12-27 17:19:27,398 - INFO - Epoch 3/200, Train Loss: 0.5590, Val Loss: 1.1398
2024-12-27 17:19:28,251 - INFO - Epoch 4/200, Train Loss: 0.4583, Val Loss: 1.2274
2024-12-27 17:19:29,116 - INFO - Epoch 5/200, Train Loss: 0.4040, Val Loss: 1.2690
2024-12-27 17:19:29,117 - INFO - Early stopping triggered at epoch 5
2024-12-27 17:19:29,117 - INFO - Training completed in 4.52s
2024-12-27 17:19:29,117 - INFO - Final memory usage: CPU 2727.7 MB, GPU 48.4 MB
2024-12-27 17:19:29,118 - INFO - Model training completed in 4.52s
2024-12-27 17:19:29,148 - INFO - Prediction completed in 0.03s
2024-12-27 17:19:29,160 - INFO - Poison rate 0.01 completed in 14.05s
2024-12-27 17:19:29,160 - INFO - 
Processing poison rate: 0.03
2024-12-27 17:19:29,172 - INFO - Total number of labels flipped: 592
2024-12-27 17:19:29,172 - INFO - Label flipping completed in 0.01s
2024-12-27 17:19:29,173 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:19:29,173 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:19:30,934 - INFO - Feature scaling completed in 1.76s
2024-12-27 17:19:30,934 - INFO - Starting feature selection (k=50)
2024-12-27 17:19:30,985 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 17:19:30,985 - INFO - Starting anomaly detection
2024-12-27 17:19:37,684 - INFO - Anomaly detection completed in 6.70s
2024-12-27 17:19:37,684 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:19:37,684 - INFO - Total fit_transform time: 8.51s
2024-12-27 17:19:37,685 - INFO - Training set processing completed in 8.51s
2024-12-27 17:19:37,685 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 17:19:37,686 - INFO - Memory usage at start_fit: CPU 2631.3 MB, GPU 48.1 MB
2024-12-27 17:19:37,686 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:19:37,688 - INFO - Number of unique classes: 43
2024-12-27 17:19:38,047 - INFO - Fitted scaler and transformed data
2024-12-27 17:19:38,048 - INFO - Scaling time: 0.36s
2024-12-27 17:19:38,915 - INFO - Epoch 1/200, Train Loss: 1.9058, Val Loss: 1.3996
2024-12-27 17:19:39,804 - INFO - Epoch 2/200, Train Loss: 1.0110, Val Loss: 1.3919
2024-12-27 17:19:40,597 - INFO - Epoch 3/200, Train Loss: 0.7892, Val Loss: 1.3926
2024-12-27 17:19:40,597 - INFO - Early stopping triggered at epoch 3
2024-12-27 17:19:40,597 - INFO - Training completed in 2.91s
2024-12-27 17:19:40,597 - INFO - Final memory usage: CPU 2727.7 MB, GPU 48.4 MB
2024-12-27 17:19:40,598 - INFO - Model training completed in 2.91s
2024-12-27 17:19:40,628 - INFO - Prediction completed in 0.03s
2024-12-27 17:19:40,639 - INFO - Poison rate 0.03 completed in 11.48s
2024-12-27 17:19:40,640 - INFO - 
Processing poison rate: 0.05
2024-12-27 17:19:40,658 - INFO - Total number of labels flipped: 987
2024-12-27 17:19:40,658 - INFO - Label flipping completed in 0.02s
2024-12-27 17:19:40,658 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:19:40,658 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:19:42,645 - INFO - Feature scaling completed in 1.99s
2024-12-27 17:19:42,645 - INFO - Starting feature selection (k=50)
2024-12-27 17:19:42,696 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 17:19:42,696 - INFO - Starting anomaly detection
2024-12-27 17:19:50,284 - INFO - Anomaly detection completed in 7.59s
2024-12-27 17:19:50,285 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:19:50,285 - INFO - Total fit_transform time: 9.63s
2024-12-27 17:19:50,285 - INFO - Training set processing completed in 9.63s
2024-12-27 17:19:50,285 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 17:19:50,287 - INFO - Memory usage at start_fit: CPU 2631.3 MB, GPU 48.1 MB
2024-12-27 17:19:50,287 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:19:50,289 - INFO - Number of unique classes: 43
2024-12-27 17:19:50,624 - INFO - Fitted scaler and transformed data
2024-12-27 17:19:50,625 - INFO - Scaling time: 0.33s
2024-12-27 17:19:51,226 - INFO - Epoch 1/200, Train Loss: 2.0988, Val Loss: 1.8565
2024-12-27 17:19:51,878 - INFO - Epoch 2/200, Train Loss: 1.2430, Val Loss: 1.8154
2024-12-27 17:19:52,624 - INFO - Epoch 3/200, Train Loss: 0.9956, Val Loss: 1.8537
2024-12-27 17:19:53,444 - INFO - Epoch 4/200, Train Loss: 0.8712, Val Loss: 2.0213
2024-12-27 17:19:53,444 - INFO - Early stopping triggered at epoch 4
2024-12-27 17:19:53,444 - INFO - Training completed in 3.16s
2024-12-27 17:19:53,444 - INFO - Final memory usage: CPU 2727.7 MB, GPU 48.4 MB
2024-12-27 17:19:53,445 - INFO - Model training completed in 3.16s
2024-12-27 17:19:53,475 - INFO - Prediction completed in 0.03s
2024-12-27 17:19:53,494 - INFO - Poison rate 0.05 completed in 12.85s
2024-12-27 17:19:53,494 - INFO - 
Processing poison rate: 0.07
2024-12-27 17:19:53,534 - INFO - Total number of labels flipped: 1382
2024-12-27 17:19:53,534 - INFO - Label flipping completed in 0.04s
2024-12-27 17:19:53,535 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:19:53,535 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:19:55,509 - INFO - Feature scaling completed in 1.97s
2024-12-27 17:19:55,509 - INFO - Starting feature selection (k=50)
2024-12-27 17:19:55,559 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 17:19:55,560 - INFO - Starting anomaly detection
2024-12-27 17:20:01,372 - INFO - Anomaly detection completed in 5.81s
2024-12-27 17:20:01,372 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:20:01,372 - INFO - Total fit_transform time: 7.84s
2024-12-27 17:20:01,373 - INFO - Training set processing completed in 7.84s
2024-12-27 17:20:01,373 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 17:20:01,374 - INFO - Memory usage at start_fit: CPU 2631.3 MB, GPU 48.1 MB
2024-12-27 17:20:01,374 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:20:01,374 - INFO - Number of unique classes: 43
2024-12-27 17:20:01,726 - INFO - Fitted scaler and transformed data
2024-12-27 17:20:01,726 - INFO - Scaling time: 0.35s
2024-12-27 17:20:02,542 - INFO - Epoch 1/200, Train Loss: 2.3011, Val Loss: 1.9626
2024-12-27 17:20:03,386 - INFO - Epoch 2/200, Train Loss: 1.4216, Val Loss: 2.1747
2024-12-27 17:20:04,219 - INFO - Epoch 3/200, Train Loss: 1.1718, Val Loss: 2.1855
2024-12-27 17:20:04,220 - INFO - Early stopping triggered at epoch 3
2024-12-27 17:20:04,220 - INFO - Training completed in 2.85s
2024-12-27 17:20:04,221 - INFO - Final memory usage: CPU 2727.7 MB, GPU 48.4 MB
2024-12-27 17:20:04,222 - INFO - Model training completed in 2.85s
2024-12-27 17:20:04,261 - INFO - Prediction completed in 0.04s
2024-12-27 17:20:04,283 - INFO - Poison rate 0.07 completed in 10.79s
2024-12-27 17:20:04,283 - INFO - 
Processing poison rate: 0.1
2024-12-27 17:20:04,321 - INFO - Total number of labels flipped: 1975
2024-12-27 17:20:04,322 - INFO - Label flipping completed in 0.04s
2024-12-27 17:20:04,322 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:20:04,322 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:20:06,236 - INFO - Feature scaling completed in 1.91s
2024-12-27 17:20:06,236 - INFO - Starting feature selection (k=50)
2024-12-27 17:20:06,286 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 17:20:06,286 - INFO - Starting anomaly detection
2024-12-27 17:20:13,709 - INFO - Anomaly detection completed in 7.42s
2024-12-27 17:20:13,710 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:20:13,710 - INFO - Total fit_transform time: 9.39s
2024-12-27 17:20:13,710 - INFO - Training set processing completed in 9.39s
2024-12-27 17:20:13,710 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 17:20:13,711 - INFO - Memory usage at start_fit: CPU 2631.3 MB, GPU 48.1 MB
2024-12-27 17:20:13,711 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:20:13,712 - INFO - Number of unique classes: 43
2024-12-27 17:20:14,044 - INFO - Fitted scaler and transformed data
2024-12-27 17:20:14,045 - INFO - Scaling time: 0.33s
2024-12-27 17:20:14,856 - INFO - Epoch 1/200, Train Loss: 2.6258, Val Loss: 2.1785
2024-12-27 17:20:15,577 - INFO - Epoch 2/200, Train Loss: 1.7025, Val Loss: 2.3918
2024-12-27 17:20:16,227 - INFO - Epoch 3/200, Train Loss: 1.4381, Val Loss: 2.3970
2024-12-27 17:20:16,227 - INFO - Early stopping triggered at epoch 3
2024-12-27 17:20:16,227 - INFO - Training completed in 2.52s
2024-12-27 17:20:16,228 - INFO - Final memory usage: CPU 2728.0 MB, GPU 48.4 MB
2024-12-27 17:20:16,229 - INFO - Model training completed in 2.52s
2024-12-27 17:20:16,258 - INFO - Prediction completed in 0.03s
2024-12-27 17:20:16,284 - INFO - Poison rate 0.1 completed in 12.00s
2024-12-27 17:20:16,285 - INFO - 
Processing poison rate: 0.2
2024-12-27 17:20:16,367 - INFO - Total number of labels flipped: 3951
2024-12-27 17:20:16,367 - INFO - Label flipping completed in 0.08s
2024-12-27 17:20:16,368 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:20:16,368 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:20:18,253 - INFO - Feature scaling completed in 1.88s
2024-12-27 17:20:18,253 - INFO - Starting feature selection (k=50)
2024-12-27 17:20:18,304 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 17:20:18,304 - INFO - Starting anomaly detection
2024-12-27 17:20:26,833 - INFO - Anomaly detection completed in 8.53s
2024-12-27 17:20:26,833 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:20:26,833 - INFO - Total fit_transform time: 10.47s
2024-12-27 17:20:26,834 - INFO - Training set processing completed in 10.47s
2024-12-27 17:20:26,834 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 17:20:26,835 - INFO - Memory usage at start_fit: CPU 2631.5 MB, GPU 48.1 MB
2024-12-27 17:20:26,835 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:20:26,837 - INFO - Number of unique classes: 43
2024-12-27 17:20:27,189 - INFO - Fitted scaler and transformed data
2024-12-27 17:20:27,189 - INFO - Scaling time: 0.35s
2024-12-27 17:20:28,020 - INFO - Epoch 1/200, Train Loss: 3.3208, Val Loss: 3.2184
2024-12-27 17:20:28,772 - INFO - Epoch 2/200, Train Loss: 2.3804, Val Loss: 3.3881
2024-12-27 17:20:29,654 - INFO - Epoch 3/200, Train Loss: 2.1095, Val Loss: 3.5932
2024-12-27 17:20:29,655 - INFO - Early stopping triggered at epoch 3
2024-12-27 17:20:29,655 - INFO - Training completed in 2.82s
2024-12-27 17:20:29,656 - INFO - Final memory usage: CPU 2728.0 MB, GPU 48.4 MB
2024-12-27 17:20:29,658 - INFO - Model training completed in 2.82s
2024-12-27 17:20:29,695 - INFO - Prediction completed in 0.04s
2024-12-27 17:20:29,717 - INFO - Poison rate 0.2 completed in 13.43s
2024-12-27 17:20:29,721 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 17:20:29,721 - INFO - Total evaluation time: 126.06s
2024-12-27 17:20:29,732 - INFO - 
Progress: 5.2% - Evaluating GTSRB with RandomForest (standard mode, iteration 1/1)
2024-12-27 17:20:29,790 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 17:20:29,928 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 17:20:30,016 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 17:20:30,017 - INFO - Dataset type: image
2024-12-27 17:20:30,017 - INFO - Sample size: 39209
2024-12-27 17:20:30,017 - INFO - Using device: cuda
2024-12-27 17:20:30,017 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 17:20:30,018 - INFO - Loading datasets...
2024-12-27 17:20:47,693 - INFO - Dataset loading completed in 17.67s
2024-12-27 17:20:47,694 - INFO - Extracting validation features...
2024-12-27 17:20:47,694 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:30,  4.47it/s]Extracting features:   2%|▏         | 3/139 [00:00<00:15,  8.70it/s]Extracting features:   6%|▋         | 9/139 [00:00<00:05, 23.36it/s]Extracting features:  11%|█         | 15/139 [00:00<00:03, 33.18it/s]Extracting features:  16%|█▌        | 22/139 [00:00<00:02, 41.68it/s]Extracting features:  20%|██        | 28/139 [00:00<00:02, 45.62it/s]Extracting features:  25%|██▌       | 35/139 [00:00<00:02, 50.71it/s]Extracting features:  29%|██▉       | 41/139 [00:01<00:01, 49.00it/s]Extracting features:  35%|███▍      | 48/139 [00:01<00:01, 52.44it/s]Extracting features:  39%|███▉      | 54/139 [00:01<00:01, 53.30it/s]Extracting features:  43%|████▎     | 60/139 [00:01<00:01, 52.11it/s]Extracting features:  48%|████▊     | 67/139 [00:01<00:01, 55.60it/s]Extracting features:  53%|█████▎    | 73/139 [00:01<00:01, 55.18it/s]Extracting features:  57%|█████▋    | 79/139 [00:01<00:01, 55.79it/s]Extracting features:  61%|██████    | 85/139 [00:01<00:01, 48.53it/s]Extracting features:  65%|██████▌   | 91/139 [00:02<00:00, 49.85it/s]Extracting features:  70%|██████▉   | 97/139 [00:02<00:00, 50.22it/s]Extracting features:  74%|███████▍  | 103/139 [00:02<00:00, 51.63it/s]Extracting features:  78%|███████▊  | 109/139 [00:02<00:00, 48.12it/s]Extracting features:  83%|████████▎ | 115/139 [00:02<00:00, 49.51it/s]Extracting features:  87%|████████▋ | 121/139 [00:02<00:00, 51.17it/s]Extracting features:  91%|█████████▏| 127/139 [00:02<00:00, 53.20it/s]Extracting features:  96%|█████████▌| 133/139 [00:02<00:00, 53.33it/s]Extracting features: 100%|██████████| 139/139 [00:02<00:00, 47.05it/s]
2024-12-27 17:20:50,661 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 17:20:50,661 - INFO - Validation feature extraction completed in 2.97s
2024-12-27 17:20:50,661 - INFO - Extracting training features...
2024-12-27 17:20:50,662 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<02:06,  4.86it/s]Extracting features:   1%|          | 7/618 [00:00<00:22, 27.29it/s]Extracting features:   2%|▏         | 13/618 [00:00<00:15, 39.15it/s]Extracting features:   3%|▎         | 20/618 [00:00<00:12, 48.13it/s]Extracting features:   4%|▍         | 27/618 [00:00<00:10, 53.85it/s]Extracting features:   5%|▌         | 33/618 [00:00<00:12, 48.42it/s]Extracting features:   6%|▋         | 39/618 [00:00<00:12, 44.80it/s]Extracting features:   7%|▋         | 44/618 [00:01<00:13, 41.22it/s]Extracting features:   8%|▊         | 49/618 [00:01<00:13, 42.54it/s]Extracting features:   9%|▊         | 54/618 [00:01<00:14, 39.13it/s]Extracting features:  10%|▉         | 60/618 [00:01<00:13, 42.15it/s]Extracting features:  11%|█         | 65/618 [00:01<00:13, 42.03it/s]Extracting features:  11%|█▏        | 70/618 [00:01<00:12, 42.18it/s]Extracting features:  12%|█▏        | 75/618 [00:01<00:13, 40.00it/s]Extracting features:  13%|█▎        | 80/618 [00:01<00:13, 40.48it/s]Extracting features:  14%|█▍        | 85/618 [00:02<00:12, 42.66it/s]Extracting features:  15%|█▍        | 90/618 [00:02<00:12, 43.41it/s]Extracting features:  15%|█▌        | 95/618 [00:02<00:12, 40.52it/s]Extracting features:  16%|█▌        | 100/618 [00:02<00:12, 40.74it/s]Extracting features:  17%|█▋        | 105/618 [00:02<00:13, 38.88it/s]Extracting features:  18%|█▊        | 110/618 [00:02<00:12, 39.60it/s]Extracting features:  19%|█▊        | 115/618 [00:02<00:13, 36.82it/s]Extracting features:  19%|█▉        | 119/618 [00:02<00:14, 34.45it/s]Extracting features:  20%|██        | 124/618 [00:03<00:13, 37.48it/s]Extracting features:  21%|██        | 130/618 [00:03<00:11, 42.42it/s]Extracting features:  22%|██▏       | 137/618 [00:03<00:10, 47.39it/s]Extracting features:  23%|██▎       | 144/618 [00:03<00:09, 52.51it/s]Extracting features:  24%|██▍       | 150/618 [00:03<00:09, 49.54it/s]Extracting features:  25%|██▌       | 156/618 [00:03<00:09, 49.76it/s]Extracting features:  26%|██▌       | 162/618 [00:03<00:10, 44.95it/s]Extracting features:  27%|██▋       | 168/618 [00:03<00:09, 48.19it/s]Extracting features:  28%|██▊       | 175/618 [00:04<00:08, 52.01it/s]Extracting features:  29%|██▉       | 181/618 [00:04<00:08, 52.09it/s]Extracting features:  30%|███       | 187/618 [00:04<00:08, 49.72it/s]Extracting features:  31%|███       | 193/618 [00:04<00:08, 49.85it/s]Extracting features:  32%|███▏      | 200/618 [00:04<00:07, 54.18it/s]Extracting features:  33%|███▎      | 207/618 [00:04<00:07, 58.19it/s]Extracting features:  34%|███▍      | 213/618 [00:04<00:06, 58.11it/s]Extracting features:  36%|███▌      | 220/618 [00:04<00:06, 58.98it/s]Extracting features:  37%|███▋      | 226/618 [00:04<00:06, 58.85it/s]Extracting features:  38%|███▊      | 233/618 [00:05<00:06, 61.77it/s]Extracting features:  39%|███▉      | 240/618 [00:05<00:05, 63.13it/s]Extracting features:  40%|███▉      | 247/618 [00:05<00:06, 61.61it/s]Extracting features:  41%|████      | 254/618 [00:05<00:06, 56.27it/s]Extracting features:  42%|████▏     | 260/618 [00:05<00:06, 56.70it/s]Extracting features:  43%|████▎     | 267/618 [00:05<00:05, 58.93it/s]Extracting features:  44%|████▍     | 274/618 [00:05<00:05, 60.24it/s]Extracting features:  45%|████▌     | 281/618 [00:05<00:05, 61.65it/s]Extracting features:  47%|████▋     | 288/618 [00:05<00:05, 60.58it/s]Extracting features:  48%|████▊     | 295/618 [00:06<00:05, 62.42it/s]Extracting features:  49%|████▉     | 302/618 [00:06<00:04, 63.84it/s]Extracting features:  50%|█████     | 309/618 [00:06<00:05, 61.41it/s]Extracting features:  51%|█████▏    | 317/618 [00:06<00:04, 64.05it/s]Extracting features:  52%|█████▏    | 324/618 [00:06<00:04, 60.31it/s]Extracting features:  54%|█████▎    | 331/618 [00:06<00:04, 58.24it/s]Extracting features:  55%|█████▍    | 337/618 [00:06<00:04, 56.31it/s]Extracting features:  56%|█████▌    | 343/618 [00:06<00:04, 55.84it/s]Extracting features:  56%|█████▋    | 349/618 [00:07<00:05, 50.89it/s]Extracting features:  57%|█████▋    | 355/618 [00:07<00:05, 49.25it/s]Extracting features:  58%|█████▊    | 360/618 [00:07<00:05, 45.44it/s]Extracting features:  59%|█████▉    | 366/618 [00:07<00:05, 48.81it/s]Extracting features:  60%|██████    | 372/618 [00:07<00:04, 50.80it/s]Extracting features:  61%|██████    | 378/618 [00:07<00:04, 53.20it/s]Extracting features:  62%|██████▏   | 384/618 [00:07<00:04, 54.87it/s]Extracting features:  63%|██████▎   | 390/618 [00:07<00:04, 55.15it/s]Extracting features:  64%|██████▍   | 397/618 [00:07<00:03, 59.28it/s]Extracting features:  65%|██████▌   | 403/618 [00:08<00:03, 58.70it/s]Extracting features:  66%|██████▌   | 409/618 [00:08<00:03, 57.36it/s]Extracting features:  67%|██████▋   | 416/618 [00:08<00:03, 57.92it/s]Extracting features:  68%|██████▊   | 422/618 [00:08<00:03, 58.09it/s]Extracting features:  69%|██████▉   | 429/618 [00:08<00:03, 59.88it/s]Extracting features:  70%|███████   | 435/618 [00:08<00:03, 55.79it/s]Extracting features:  71%|███████▏  | 441/618 [00:08<00:03, 56.05it/s]Extracting features:  72%|███████▏  | 447/618 [00:08<00:03, 51.05it/s]Extracting features:  73%|███████▎  | 453/618 [00:08<00:03, 52.08it/s]Extracting features:  74%|███████▍  | 459/618 [00:09<00:02, 53.17it/s]Extracting features:  75%|███████▌  | 465/618 [00:09<00:02, 52.37it/s]Extracting features:  76%|███████▌  | 471/618 [00:09<00:02, 52.58it/s]Extracting features:  77%|███████▋  | 477/618 [00:09<00:02, 54.43it/s]Extracting features:  78%|███████▊  | 484/618 [00:09<00:02, 58.41it/s]Extracting features:  79%|███████▉  | 490/618 [00:09<00:02, 57.28it/s]Extracting features:  80%|████████  | 496/618 [00:09<00:02, 50.66it/s]Extracting features:  81%|████████  | 502/618 [00:09<00:02, 52.05it/s]Extracting features:  82%|████████▏ | 508/618 [00:10<00:02, 53.43it/s]Extracting features:  83%|████████▎ | 516/618 [00:10<00:01, 58.41it/s]Extracting features:  85%|████████▍ | 523/618 [00:10<00:01, 61.23it/s]Extracting features:  86%|████████▌ | 530/618 [00:10<00:01, 58.13it/s]Extracting features:  87%|████████▋ | 536/618 [00:10<00:01, 58.01it/s]Extracting features:  88%|████████▊ | 543/618 [00:10<00:01, 58.31it/s]Extracting features:  89%|████████▉ | 551/618 [00:10<00:01, 61.95it/s]Extracting features:  90%|█████████ | 558/618 [00:10<00:00, 62.01it/s]Extracting features:  91%|█████████▏| 565/618 [00:10<00:00, 61.28it/s]Extracting features:  93%|█████████▎| 572/618 [00:11<00:00, 60.04it/s]Extracting features:  94%|█████████▎| 579/618 [00:11<00:00, 57.99it/s]Extracting features:  95%|█████████▍| 585/618 [00:11<00:00, 57.10it/s]Extracting features:  96%|█████████▌| 591/618 [00:11<00:00, 54.20it/s]Extracting features:  97%|█████████▋| 597/618 [00:11<00:00, 53.81it/s]Extracting features:  98%|█████████▊| 603/618 [00:11<00:00, 53.47it/s]Extracting features:  99%|█████████▊| 610/618 [00:11<00:00, 55.86it/s]Extracting features: 100%|██████████| 618/618 [00:11<00:00, 55.12it/s]Extracting features: 100%|██████████| 618/618 [00:11<00:00, 51.70it/s]
2024-12-27 17:21:02,652 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 17:21:02,653 - INFO - Training feature extraction completed in 11.99s
2024-12-27 17:21:02,653 - INFO - Creating model for classifier: RandomForest
2024-12-27 17:21:02,653 - INFO - Using device: cuda
2024-12-27 17:21:02,653 - INFO - 
Processing poison rate: 0.0
2024-12-27 17:21:02,653 - INFO - Training set processing completed in 0.00s
2024-12-27 17:21:02,653 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 17:21:02,654 - INFO - Memory usage at start_fit: CPU 2632.4 MB, GPU 47.3 MB
2024-12-27 17:21:02,655 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:21:02,944 - INFO - Fitted scaler and transformed data
2024-12-27 17:21:02,944 - INFO - Scaling time: 0.29s
2024-12-27 17:21:02,964 - INFO - Number of unique classes: 43
2024-12-27 17:21:15,449 - INFO - Epoch 1/15, Train Loss: 3.7579, Val Loss: 3.7541
2024-12-27 17:21:29,689 - INFO - Epoch 2/15, Train Loss: 3.7481, Val Loss: 3.7449
2024-12-27 17:21:42,057 - INFO - Epoch 3/15, Train Loss: 3.7364, Val Loss: 3.7343
2024-12-27 17:21:54,671 - INFO - Epoch 4/15, Train Loss: 3.7232, Val Loss: 3.7231
2024-12-27 17:22:07,459 - INFO - Epoch 5/15, Train Loss: 3.7094, Val Loss: 3.7125
2024-12-27 17:22:22,569 - INFO - Epoch 6/15, Train Loss: 3.6967, Val Loss: 3.7033
2024-12-27 17:22:35,055 - INFO - Epoch 7/15, Train Loss: 3.6858, Val Loss: 3.6959
2024-12-27 17:22:48,290 - INFO - Epoch 8/15, Train Loss: 3.6766, Val Loss: 3.6900
2024-12-27 17:23:00,807 - INFO - Epoch 9/15, Train Loss: 3.6694, Val Loss: 3.6854
2024-12-27 17:23:12,907 - INFO - Epoch 10/15, Train Loss: 3.6636, Val Loss: 3.6818
2024-12-27 17:23:25,345 - INFO - Epoch 11/15, Train Loss: 3.6588, Val Loss: 3.6789
2024-12-27 17:23:25,345 - INFO - Early stopping triggered at epoch 11
2024-12-27 17:23:25,345 - INFO - Training completed in 142.69s
2024-12-27 17:23:25,346 - INFO - Final memory usage: CPU 2639.4 MB, GPU 155.0 MB
2024-12-27 17:23:25,346 - INFO - Model training completed in 142.69s
2024-12-27 17:23:25,552 - INFO - Prediction completed in 0.21s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 17:23:25,565 - INFO - Poison rate 0.0 completed in 142.91s
2024-12-27 17:23:25,565 - INFO - 
Processing poison rate: 0.01
2024-12-27 17:23:25,570 - INFO - Total number of labels flipped: 197
2024-12-27 17:23:25,570 - INFO - Label flipping completed in 0.01s
2024-12-27 17:23:25,570 - INFO - Training set processing completed in 0.00s
2024-12-27 17:23:25,570 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 17:23:25,571 - INFO - Memory usage at start_fit: CPU 2660.9 MB, GPU 55.8 MB
2024-12-27 17:23:25,572 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:23:25,876 - INFO - Fitted scaler and transformed data
2024-12-27 17:23:25,876 - INFO - Scaling time: 0.30s
2024-12-27 17:23:25,911 - INFO - Number of unique classes: 43
2024-12-27 17:23:38,985 - INFO - Epoch 1/15, Train Loss: 3.7580, Val Loss: 3.7543
2024-12-27 17:23:52,210 - INFO - Epoch 2/15, Train Loss: 3.7484, Val Loss: 3.7454
2024-12-27 17:24:05,777 - INFO - Epoch 3/15, Train Loss: 3.7370, Val Loss: 3.7350
2024-12-27 17:24:19,345 - INFO - Epoch 4/15, Train Loss: 3.7240, Val Loss: 3.7238
2024-12-27 17:24:30,528 - INFO - Epoch 5/15, Train Loss: 3.7103, Val Loss: 3.7129
2024-12-27 17:24:45,012 - INFO - Epoch 6/15, Train Loss: 3.6975, Val Loss: 3.7035
2024-12-27 17:24:58,451 - INFO - Epoch 7/15, Train Loss: 3.6866, Val Loss: 3.6958
2024-12-27 17:25:10,532 - INFO - Epoch 8/15, Train Loss: 3.6777, Val Loss: 3.6898
2024-12-27 17:25:21,395 - INFO - Epoch 9/15, Train Loss: 3.6705, Val Loss: 3.6851
2024-12-27 17:25:33,064 - INFO - Epoch 10/15, Train Loss: 3.6645, Val Loss: 3.6814
2024-12-27 17:25:44,134 - INFO - Epoch 11/15, Train Loss: 3.6599, Val Loss: 3.6784
2024-12-27 17:25:44,135 - INFO - Early stopping triggered at epoch 11
2024-12-27 17:25:44,135 - INFO - Training completed in 138.56s
2024-12-27 17:25:44,135 - INFO - Final memory usage: CPU 2663.4 MB, GPU 155.0 MB
2024-12-27 17:25:44,135 - INFO - Model training completed in 138.57s
2024-12-27 17:25:44,317 - INFO - Prediction completed in 0.18s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 17:25:44,330 - INFO - Poison rate 0.01 completed in 138.77s
2024-12-27 17:25:44,331 - INFO - 
Processing poison rate: 0.03
2024-12-27 17:25:44,352 - INFO - Total number of labels flipped: 592
2024-12-27 17:25:44,352 - INFO - Label flipping completed in 0.02s
2024-12-27 17:25:44,352 - INFO - Training set processing completed in 0.00s
2024-12-27 17:25:44,352 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 17:25:44,353 - INFO - Memory usage at start_fit: CPU 2663.4 MB, GPU 55.8 MB
2024-12-27 17:25:44,353 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:25:44,629 - INFO - Fitted scaler and transformed data
2024-12-27 17:25:44,629 - INFO - Scaling time: 0.28s
2024-12-27 17:25:44,667 - INFO - Number of unique classes: 43
2024-12-27 17:25:56,209 - INFO - Epoch 1/15, Train Loss: 3.7581, Val Loss: 3.7544
2024-12-27 17:26:08,746 - INFO - Epoch 2/15, Train Loss: 3.7488, Val Loss: 3.7456
2024-12-27 17:26:19,833 - INFO - Epoch 3/15, Train Loss: 3.7377, Val Loss: 3.7353
2024-12-27 17:26:32,356 - INFO - Epoch 4/15, Train Loss: 3.7251, Val Loss: 3.7241
2024-12-27 17:26:44,232 - INFO - Epoch 5/15, Train Loss: 3.7119, Val Loss: 3.7133
2024-12-27 17:26:56,898 - INFO - Epoch 6/15, Train Loss: 3.6995, Val Loss: 3.7039
2024-12-27 17:27:07,962 - INFO - Epoch 7/15, Train Loss: 3.6889, Val Loss: 3.6962
2024-12-27 17:27:20,814 - INFO - Epoch 8/15, Train Loss: 3.6799, Val Loss: 3.6901
2024-12-27 17:27:33,238 - INFO - Epoch 9/15, Train Loss: 3.6727, Val Loss: 3.6852
2024-12-27 17:27:44,396 - INFO - Epoch 10/15, Train Loss: 3.6670, Val Loss: 3.6813
2024-12-27 17:27:56,266 - INFO - Epoch 11/15, Train Loss: 3.6622, Val Loss: 3.6782
2024-12-27 17:27:56,266 - INFO - Early stopping triggered at epoch 11
2024-12-27 17:27:56,266 - INFO - Training completed in 131.91s
2024-12-27 17:27:56,267 - INFO - Final memory usage: CPU 2663.4 MB, GPU 155.0 MB
2024-12-27 17:27:56,267 - INFO - Model training completed in 131.91s
2024-12-27 17:27:56,419 - INFO - Prediction completed in 0.15s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 17:27:56,431 - INFO - Poison rate 0.03 completed in 132.10s
2024-12-27 17:27:56,431 - INFO - 
Processing poison rate: 0.05
2024-12-27 17:27:56,451 - INFO - Total number of labels flipped: 987
2024-12-27 17:27:56,451 - INFO - Label flipping completed in 0.02s
2024-12-27 17:27:56,451 - INFO - Training set processing completed in 0.00s
2024-12-27 17:27:56,451 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 17:27:56,452 - INFO - Memory usage at start_fit: CPU 2663.4 MB, GPU 55.8 MB
2024-12-27 17:27:56,453 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:27:56,709 - INFO - Fitted scaler and transformed data
2024-12-27 17:27:56,709 - INFO - Scaling time: 0.26s
2024-12-27 17:27:56,744 - INFO - Number of unique classes: 43
2024-12-27 17:28:09,484 - INFO - Epoch 1/15, Train Loss: 3.7583, Val Loss: 3.7551
2024-12-27 17:28:21,804 - INFO - Epoch 2/15, Train Loss: 3.7496, Val Loss: 3.7473
2024-12-27 17:28:34,479 - INFO - Epoch 3/15, Train Loss: 3.7394, Val Loss: 3.7381
2024-12-27 17:28:46,539 - INFO - Epoch 4/15, Train Loss: 3.7275, Val Loss: 3.7282
2024-12-27 17:28:58,503 - INFO - Epoch 5/15, Train Loss: 3.7149, Val Loss: 3.7183
2024-12-27 17:29:10,403 - INFO - Epoch 6/15, Train Loss: 3.7029, Val Loss: 3.7096
2024-12-27 17:29:22,039 - INFO - Epoch 7/15, Train Loss: 3.6925, Val Loss: 3.7025
2024-12-27 17:29:34,130 - INFO - Epoch 8/15, Train Loss: 3.6837, Val Loss: 3.6969
2024-12-27 17:29:47,931 - INFO - Epoch 9/15, Train Loss: 3.6767, Val Loss: 3.6924
2024-12-27 17:30:00,694 - INFO - Epoch 10/15, Train Loss: 3.6709, Val Loss: 3.6889
2024-12-27 17:30:13,623 - INFO - Epoch 11/15, Train Loss: 3.6661, Val Loss: 3.6860
2024-12-27 17:30:13,623 - INFO - Early stopping triggered at epoch 11
2024-12-27 17:30:13,623 - INFO - Training completed in 137.17s
2024-12-27 17:30:13,623 - INFO - Final memory usage: CPU 2663.4 MB, GPU 155.0 MB
2024-12-27 17:30:13,624 - INFO - Model training completed in 137.17s
2024-12-27 17:30:13,848 - INFO - Prediction completed in 0.22s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 17:30:13,864 - INFO - Poison rate 0.05 completed in 137.43s
2024-12-27 17:30:13,864 - INFO - 
Processing poison rate: 0.07
2024-12-27 17:30:13,889 - INFO - Total number of labels flipped: 1382
2024-12-27 17:30:13,890 - INFO - Label flipping completed in 0.03s
2024-12-27 17:30:13,890 - INFO - Training set processing completed in 0.00s
2024-12-27 17:30:13,890 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 17:30:13,891 - INFO - Memory usage at start_fit: CPU 2663.4 MB, GPU 55.8 MB
2024-12-27 17:30:13,892 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:30:14,155 - INFO - Fitted scaler and transformed data
2024-12-27 17:30:14,155 - INFO - Scaling time: 0.26s
2024-12-27 17:30:14,191 - INFO - Number of unique classes: 43
2024-12-27 17:30:26,770 - INFO - Epoch 1/15, Train Loss: 3.7584, Val Loss: 3.7551
2024-12-27 17:30:39,975 - INFO - Epoch 2/15, Train Loss: 3.7499, Val Loss: 3.7473
2024-12-27 17:30:53,406 - INFO - Epoch 3/15, Train Loss: 3.7398, Val Loss: 3.7380
2024-12-27 17:31:05,340 - INFO - Epoch 4/15, Train Loss: 3.7281, Val Loss: 3.7276
2024-12-27 17:31:17,934 - INFO - Epoch 5/15, Train Loss: 3.7156, Val Loss: 3.7173
2024-12-27 17:31:31,667 - INFO - Epoch 6/15, Train Loss: 3.7037, Val Loss: 3.7083
2024-12-27 17:31:44,339 - INFO - Epoch 7/15, Train Loss: 3.6933, Val Loss: 3.7009
2024-12-27 17:31:55,977 - INFO - Epoch 8/15, Train Loss: 3.6845, Val Loss: 3.6949
2024-12-27 17:32:10,030 - INFO - Epoch 9/15, Train Loss: 3.6774, Val Loss: 3.6901
2024-12-27 17:32:23,656 - INFO - Epoch 10/15, Train Loss: 3.6717, Val Loss: 3.6863
2024-12-27 17:32:37,867 - INFO - Epoch 11/15, Train Loss: 3.6669, Val Loss: 3.6833
2024-12-27 17:32:37,867 - INFO - Early stopping triggered at epoch 11
2024-12-27 17:32:37,867 - INFO - Training completed in 143.98s
2024-12-27 17:32:37,867 - INFO - Final memory usage: CPU 2663.4 MB, GPU 155.0 MB
2024-12-27 17:32:37,868 - INFO - Model training completed in 143.98s
2024-12-27 17:32:38,067 - INFO - Prediction completed in 0.20s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 17:32:38,080 - INFO - Poison rate 0.07 completed in 144.22s
2024-12-27 17:32:38,080 - INFO - 
Processing poison rate: 0.1
2024-12-27 17:32:38,115 - INFO - Total number of labels flipped: 1975
2024-12-27 17:32:38,116 - INFO - Label flipping completed in 0.04s
2024-12-27 17:32:38,116 - INFO - Training set processing completed in 0.00s
2024-12-27 17:32:38,116 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 17:32:38,117 - INFO - Memory usage at start_fit: CPU 2663.4 MB, GPU 55.8 MB
2024-12-27 17:32:38,117 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:32:38,387 - INFO - Fitted scaler and transformed data
2024-12-27 17:32:38,387 - INFO - Scaling time: 0.27s
2024-12-27 17:32:38,422 - INFO - Number of unique classes: 43
2024-12-27 17:32:51,925 - INFO - Epoch 1/15, Train Loss: 3.7585, Val Loss: 3.7555
2024-12-27 17:33:05,993 - INFO - Epoch 2/15, Train Loss: 3.7503, Val Loss: 3.7482
2024-12-27 17:33:20,394 - INFO - Epoch 3/15, Train Loss: 3.7405, Val Loss: 3.7398
2024-12-27 17:33:34,120 - INFO - Epoch 4/15, Train Loss: 3.7291, Val Loss: 3.7307
2024-12-27 17:33:47,643 - INFO - Epoch 5/15, Train Loss: 3.7171, Val Loss: 3.7219
2024-12-27 17:34:02,442 - INFO - Epoch 6/15, Train Loss: 3.7056, Val Loss: 3.7142
2024-12-27 17:34:16,810 - INFO - Epoch 7/15, Train Loss: 3.6957, Val Loss: 3.7078
2024-12-27 17:34:31,038 - INFO - Epoch 8/15, Train Loss: 3.6873, Val Loss: 3.7027
2024-12-27 17:34:45,351 - INFO - Epoch 9/15, Train Loss: 3.6803, Val Loss: 3.6985
2024-12-27 17:34:45,351 - INFO - Early stopping triggered at epoch 9
2024-12-27 17:34:45,351 - INFO - Training completed in 127.23s
2024-12-27 17:34:45,352 - INFO - Final memory usage: CPU 2663.4 MB, GPU 155.0 MB
2024-12-27 17:34:45,352 - INFO - Model training completed in 127.24s
2024-12-27 17:34:45,496 - INFO - Prediction completed in 0.14s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 17:34:45,509 - INFO - Poison rate 0.1 completed in 127.43s
2024-12-27 17:34:45,509 - INFO - 
Processing poison rate: 0.2
2024-12-27 17:34:45,580 - INFO - Total number of labels flipped: 3951
2024-12-27 17:34:45,580 - INFO - Label flipping completed in 0.07s
2024-12-27 17:34:45,581 - INFO - Training set processing completed in 0.00s
2024-12-27 17:34:45,581 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 17:34:45,581 - INFO - Memory usage at start_fit: CPU 2663.4 MB, GPU 55.8 MB
2024-12-27 17:34:45,582 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:34:45,850 - INFO - Fitted scaler and transformed data
2024-12-27 17:34:45,850 - INFO - Scaling time: 0.27s
2024-12-27 17:34:45,886 - INFO - Number of unique classes: 43
2024-12-27 17:34:58,826 - INFO - Epoch 1/15, Train Loss: 3.7591, Val Loss: 3.7569
2024-12-27 17:35:12,423 - INFO - Epoch 2/15, Train Loss: 3.7524, Val Loss: 3.7514
2024-12-27 17:35:26,291 - INFO - Epoch 3/15, Train Loss: 3.7446, Val Loss: 3.7449
2024-12-27 17:35:40,865 - INFO - Epoch 4/15, Train Loss: 3.7354, Val Loss: 3.7374
2024-12-27 17:35:53,341 - INFO - Epoch 5/15, Train Loss: 3.7254, Val Loss: 3.7296
2024-12-27 17:36:07,002 - INFO - Epoch 6/15, Train Loss: 3.7154, Val Loss: 3.7223
2024-12-27 17:36:20,206 - INFO - Epoch 7/15, Train Loss: 3.7062, Val Loss: 3.7160
2024-12-27 17:36:33,080 - INFO - Epoch 8/15, Train Loss: 3.6984, Val Loss: 3.7109
2024-12-27 17:36:46,466 - INFO - Epoch 9/15, Train Loss: 3.6917, Val Loss: 3.7067
2024-12-27 17:36:46,467 - INFO - Early stopping triggered at epoch 9
2024-12-27 17:36:46,467 - INFO - Training completed in 120.89s
2024-12-27 17:36:46,467 - INFO - Final memory usage: CPU 2663.4 MB, GPU 155.0 MB
2024-12-27 17:36:46,467 - INFO - Model training completed in 120.89s
2024-12-27 17:36:46,634 - INFO - Prediction completed in 0.17s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 17:36:46,647 - INFO - Poison rate 0.2 completed in 121.14s
2024-12-27 17:36:46,648 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 17:36:46,648 - INFO - Total evaluation time: 976.63s
2024-12-27 17:36:46,654 - INFO - 
Progress: 6.2% - Evaluating GTSRB with RandomForest (dynadetect mode, iteration 1/1)
2024-12-27 17:36:46,720 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 17:36:47,056 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 17:36:47,147 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 17:36:47,147 - INFO - Dataset type: image
2024-12-27 17:36:47,147 - INFO - Sample size: 39209
2024-12-27 17:36:47,148 - INFO - Using device: cuda
2024-12-27 17:36:47,148 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 17:36:47,152 - INFO - Loading datasets...
2024-12-27 17:37:05,357 - INFO - Dataset loading completed in 18.20s
2024-12-27 17:37:05,357 - INFO - Extracting validation features...
2024-12-27 17:37:05,358 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:28,  4.77it/s]Extracting features:   2%|▏         | 3/139 [00:00<00:14,  9.40it/s]Extracting features:   4%|▍         | 6/139 [00:00<00:08, 15.37it/s]Extracting features:   9%|▊         | 12/139 [00:00<00:04, 28.71it/s]Extracting features:  12%|█▏        | 17/139 [00:00<00:03, 34.40it/s]Extracting features:  17%|█▋        | 23/139 [00:00<00:02, 39.99it/s]Extracting features:  20%|██        | 28/139 [00:00<00:02, 40.35it/s]Extracting features:  24%|██▎       | 33/139 [00:01<00:02, 42.48it/s]Extracting features:  28%|██▊       | 39/139 [00:01<00:02, 46.73it/s]Extracting features:  33%|███▎      | 46/139 [00:01<00:01, 50.76it/s]Extracting features:  38%|███▊      | 53/139 [00:01<00:01, 52.89it/s]Extracting features:  43%|████▎     | 60/139 [00:01<00:01, 56.10it/s]Extracting features:  48%|████▊     | 67/139 [00:01<00:01, 57.49it/s]Extracting features:  53%|█████▎    | 73/139 [00:01<00:01, 51.30it/s]Extracting features:  57%|█████▋    | 79/139 [00:01<00:01, 45.35it/s]Extracting features:  60%|██████    | 84/139 [00:02<00:01, 43.87it/s]Extracting features:  64%|██████▍   | 89/139 [00:02<00:01, 44.51it/s]Extracting features:  68%|██████▊   | 94/139 [00:02<00:01, 44.39it/s]Extracting features:  71%|███████   | 99/139 [00:02<00:00, 45.51it/s]Extracting features:  75%|███████▍  | 104/139 [00:02<00:00, 45.75it/s]Extracting features:  80%|███████▉  | 111/139 [00:02<00:00, 51.45it/s]Extracting features:  84%|████████▍ | 117/139 [00:02<00:00, 52.00it/s]Extracting features:  88%|████████▊ | 123/139 [00:02<00:00, 44.58it/s]Extracting features:  92%|█████████▏| 128/139 [00:02<00:00, 44.49it/s]Extracting features:  96%|█████████▌| 133/139 [00:03<00:00, 44.81it/s]Extracting features: 100%|██████████| 139/139 [00:03<00:00, 42.88it/s]
2024-12-27 17:37:08,609 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 17:37:08,609 - INFO - Validation feature extraction completed in 3.25s
2024-12-27 17:37:08,610 - INFO - Extracting training features...
2024-12-27 17:37:08,610 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<02:06,  4.86it/s]Extracting features:   1%|▏         | 8/618 [00:00<00:20, 29.86it/s]Extracting features:   2%|▏         | 13/618 [00:00<00:17, 34.03it/s]Extracting features:   3%|▎         | 19/618 [00:00<00:14, 40.32it/s]Extracting features:   4%|▍         | 24/618 [00:00<00:13, 42.88it/s]Extracting features:   5%|▍         | 30/618 [00:00<00:12, 47.69it/s]Extracting features:   6%|▌         | 36/618 [00:00<00:11, 49.23it/s]Extracting features:   7%|▋         | 43/618 [00:00<00:10, 54.44it/s]Extracting features:   8%|▊         | 51/618 [00:01<00:09, 60.65it/s]Extracting features:   9%|▉         | 58/618 [00:01<00:09, 62.02it/s]Extracting features:  11%|█         | 65/618 [00:01<00:08, 63.54it/s]Extracting features:  12%|█▏        | 72/618 [00:01<00:08, 62.05it/s]Extracting features:  13%|█▎        | 80/618 [00:01<00:08, 64.70it/s]Extracting features:  14%|█▍        | 88/618 [00:01<00:07, 67.31it/s]Extracting features:  15%|█▌        | 95/618 [00:01<00:07, 66.72it/s]Extracting features:  17%|█▋        | 103/618 [00:01<00:07, 67.83it/s]Extracting features:  18%|█▊        | 110/618 [00:01<00:07, 66.78it/s]Extracting features:  19%|█▉        | 117/618 [00:02<00:08, 60.88it/s]Extracting features:  20%|██        | 124/618 [00:02<00:08, 60.00it/s]Extracting features:  21%|██        | 131/618 [00:02<00:08, 59.38it/s]Extracting features:  22%|██▏       | 137/618 [00:02<00:08, 59.03it/s]Extracting features:  23%|██▎       | 144/618 [00:02<00:08, 58.31it/s]Extracting features:  24%|██▍       | 150/618 [00:02<00:07, 58.73it/s]Extracting features:  25%|██▌       | 157/618 [00:02<00:07, 61.51it/s]Extracting features:  27%|██▋       | 164/618 [00:02<00:07, 58.12it/s]Extracting features:  28%|██▊       | 170/618 [00:03<00:07, 58.10it/s]Extracting features:  29%|██▊       | 177/618 [00:03<00:07, 58.71it/s]Extracting features:  30%|██▉       | 184/618 [00:03<00:07, 59.76it/s]Extracting features:  31%|███       | 190/618 [00:03<00:07, 59.73it/s]Extracting features:  32%|███▏      | 198/618 [00:03<00:06, 64.03it/s]Extracting features:  33%|███▎      | 205/618 [00:03<00:06, 63.35it/s]Extracting features:  34%|███▍      | 212/618 [00:03<00:06, 62.34it/s]Extracting features:  35%|███▌      | 219/618 [00:03<00:06, 62.66it/s]Extracting features:  37%|███▋      | 226/618 [00:03<00:06, 63.86it/s]Extracting features:  38%|███▊      | 233/618 [00:04<00:06, 62.39it/s]Extracting features:  39%|███▉      | 240/618 [00:04<00:05, 63.27it/s]Extracting features:  40%|████      | 248/618 [00:04<00:05, 62.68it/s]Extracting features:  41%|████▏     | 255/618 [00:04<00:05, 60.57it/s]Extracting features:  42%|████▏     | 262/618 [00:04<00:05, 59.58it/s]Extracting features:  43%|████▎     | 268/618 [00:04<00:06, 57.44it/s]Extracting features:  44%|████▍     | 274/618 [00:04<00:06, 51.79it/s]Extracting features:  45%|████▌     | 280/618 [00:04<00:07, 47.36it/s]Extracting features:  46%|████▌     | 285/618 [00:05<00:07, 46.22it/s]Extracting features:  47%|████▋     | 290/618 [00:05<00:07, 46.72it/s]Extracting features:  48%|████▊     | 296/618 [00:05<00:06, 47.63it/s]Extracting features:  49%|████▊     | 301/618 [00:05<00:06, 46.80it/s]Extracting features:  50%|████▉     | 307/618 [00:05<00:06, 47.28it/s]Extracting features:  50%|█████     | 312/618 [00:05<00:07, 43.35it/s]Extracting features:  51%|█████▏    | 317/618 [00:05<00:07, 41.21it/s]Extracting features:  52%|█████▏    | 323/618 [00:05<00:06, 45.63it/s]Extracting features:  53%|█████▎    | 328/618 [00:06<00:06, 41.91it/s]Extracting features:  54%|█████▍    | 333/618 [00:06<00:07, 39.00it/s]Extracting features:  55%|█████▍    | 338/618 [00:06<00:07, 39.88it/s]Extracting features:  56%|█████▌    | 343/618 [00:06<00:07, 36.62it/s]Extracting features:  56%|█████▌    | 347/618 [00:06<00:08, 31.99it/s]Extracting features:  57%|█████▋    | 351/618 [00:06<00:08, 31.76it/s]Extracting features:  57%|█████▋    | 355/618 [00:06<00:07, 32.91it/s]Extracting features:  58%|█████▊    | 360/618 [00:06<00:07, 35.92it/s]Extracting features:  59%|█████▉    | 364/618 [00:07<00:07, 34.38it/s]Extracting features:  60%|█████▉    | 369/618 [00:07<00:06, 37.87it/s]Extracting features:  60%|██████    | 373/618 [00:07<00:06, 38.05it/s]Extracting features:  61%|██████    | 377/618 [00:07<00:06, 36.52it/s]Extracting features:  62%|██████▏   | 381/618 [00:07<00:06, 37.01it/s]Extracting features:  62%|██████▏   | 386/618 [00:07<00:05, 39.06it/s]Extracting features:  63%|██████▎   | 390/618 [00:07<00:06, 37.32it/s]Extracting features:  64%|██████▍   | 394/618 [00:07<00:06, 37.26it/s]Extracting features:  65%|██████▍   | 399/618 [00:08<00:05, 37.90it/s]Extracting features:  65%|██████▌   | 403/618 [00:08<00:05, 36.09it/s]Extracting features:  66%|██████▌   | 408/618 [00:08<00:05, 37.69it/s]Extracting features:  67%|██████▋   | 413/618 [00:08<00:05, 38.37it/s]Extracting features:  67%|██████▋   | 417/618 [00:08<00:05, 37.22it/s]Extracting features:  68%|██████▊   | 421/618 [00:08<00:05, 37.94it/s]Extracting features:  69%|██████▉   | 426/618 [00:08<00:04, 39.89it/s]Extracting features:  70%|██████▉   | 431/618 [00:08<00:04, 40.46it/s]Extracting features:  71%|███████   | 436/618 [00:08<00:04, 41.01it/s]Extracting features:  71%|███████▏  | 441/618 [00:09<00:04, 40.14it/s]Extracting features:  72%|███████▏  | 446/618 [00:09<00:04, 40.87it/s]Extracting features:  73%|███████▎  | 452/618 [00:09<00:03, 43.43it/s]Extracting features:  74%|███████▍  | 457/618 [00:09<00:03, 40.60it/s]Extracting features:  75%|███████▍  | 462/618 [00:09<00:03, 41.55it/s]Extracting features:  76%|███████▌  | 467/618 [00:09<00:03, 39.70it/s]Extracting features:  76%|███████▋  | 472/618 [00:09<00:03, 38.28it/s]Extracting features:  77%|███████▋  | 477/618 [00:09<00:03, 40.64it/s]Extracting features:  78%|███████▊  | 482/618 [00:10<00:03, 42.95it/s]Extracting features:  79%|███████▉  | 487/618 [00:10<00:03, 43.42it/s]Extracting features:  80%|███████▉  | 492/618 [00:10<00:03, 38.75it/s]Extracting features:  80%|████████  | 497/618 [00:10<00:03, 38.56it/s]Extracting features:  81%|████████  | 501/618 [00:10<00:03, 37.92it/s]Extracting features:  82%|████████▏ | 506/618 [00:10<00:02, 40.88it/s]Extracting features:  83%|████████▎ | 511/618 [00:10<00:02, 41.78it/s]Extracting features:  83%|████████▎ | 516/618 [00:10<00:02, 41.87it/s]Extracting features:  84%|████████▍ | 521/618 [00:11<00:02, 41.19it/s]Extracting features:  85%|████████▌ | 526/618 [00:11<00:02, 41.49it/s]Extracting features:  86%|████████▌ | 531/618 [00:11<00:02, 40.95it/s]Extracting features:  87%|████████▋ | 536/618 [00:11<00:02, 40.61it/s]Extracting features:  88%|████████▊ | 541/618 [00:11<00:01, 42.53it/s]Extracting features:  88%|████████▊ | 546/618 [00:11<00:01, 41.13it/s]Extracting features:  89%|████████▉ | 551/618 [00:11<00:01, 40.19it/s]Extracting features:  90%|████████▉ | 556/618 [00:11<00:01, 40.56it/s]Extracting features:  91%|█████████ | 561/618 [00:12<00:01, 41.71it/s]Extracting features:  92%|█████████▏| 567/618 [00:12<00:01, 44.83it/s]Extracting features:  93%|█████████▎| 572/618 [00:12<00:01, 42.95it/s]Extracting features:  94%|█████████▎| 578/618 [00:12<00:00, 46.68it/s]Extracting features:  94%|█████████▍| 583/618 [00:12<00:00, 46.82it/s]Extracting features:  95%|█████████▌| 588/618 [00:12<00:00, 44.69it/s]Extracting features:  96%|█████████▌| 593/618 [00:12<00:00, 44.84it/s]Extracting features:  97%|█████████▋| 598/618 [00:12<00:00, 45.91it/s]Extracting features:  98%|█████████▊| 603/618 [00:12<00:00, 43.19it/s]Extracting features:  98%|█████████▊| 608/618 [00:13<00:00, 43.77it/s]Extracting features:  99%|█████████▉| 613/618 [00:13<00:00, 42.88it/s]Extracting features: 100%|██████████| 618/618 [00:13<00:00, 44.58it/s]Extracting features: 100%|██████████| 618/618 [00:13<00:00, 46.39it/s]
2024-12-27 17:37:21,966 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 17:37:21,967 - INFO - Training feature extraction completed in 13.36s
2024-12-27 17:37:21,967 - INFO - Creating model for classifier: RandomForest
2024-12-27 17:37:21,967 - INFO - Using device: cuda
2024-12-27 17:37:21,967 - INFO - 
Processing poison rate: 0.0
2024-12-27 17:37:21,967 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:37:21,967 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:37:23,744 - INFO - Feature scaling completed in 1.78s
2024-12-27 17:37:23,744 - INFO - Starting feature selection (k=50)
2024-12-27 17:37:23,763 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 17:37:23,763 - INFO - Starting anomaly detection
2024-12-27 17:37:30,678 - INFO - Anomaly detection completed in 6.91s
2024-12-27 17:37:30,678 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:37:30,678 - INFO - Total fit_transform time: 8.71s
2024-12-27 17:37:30,678 - INFO - Training set processing completed in 8.71s
2024-12-27 17:37:30,679 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 17:37:30,680 - INFO - Memory usage at start_fit: CPU 2735.0 MB, GPU 47.3 MB
2024-12-27 17:37:30,681 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:37:30,988 - INFO - Fitted scaler and transformed data
2024-12-27 17:37:30,988 - INFO - Scaling time: 0.31s
2024-12-27 17:37:31,008 - INFO - Number of unique classes: 43
2024-12-27 17:37:44,386 - INFO - Epoch 1/15, Train Loss: 3.5694, Val Loss: 3.7541
2024-12-27 17:37:57,264 - INFO - Epoch 2/15, Train Loss: 3.5602, Val Loss: 3.7449
2024-12-27 17:38:09,693 - INFO - Epoch 3/15, Train Loss: 3.5492, Val Loss: 3.7342
2024-12-27 17:38:22,996 - INFO - Epoch 4/15, Train Loss: 3.5367, Val Loss: 3.7227
2024-12-27 17:38:35,851 - INFO - Epoch 5/15, Train Loss: 3.5237, Val Loss: 3.7116
2024-12-27 17:38:48,781 - INFO - Epoch 6/15, Train Loss: 3.5115, Val Loss: 3.7021
2024-12-27 17:39:01,890 - INFO - Epoch 7/15, Train Loss: 3.5011, Val Loss: 3.6943
2024-12-27 17:39:14,610 - INFO - Epoch 8/15, Train Loss: 3.4924, Val Loss: 3.6882
2024-12-27 17:39:27,142 - INFO - Epoch 9/15, Train Loss: 3.4856, Val Loss: 3.6834
2024-12-27 17:39:39,501 - INFO - Epoch 10/15, Train Loss: 3.4799, Val Loss: 3.6795
2024-12-27 17:39:51,322 - INFO - Epoch 11/15, Train Loss: 3.4756, Val Loss: 3.6765
2024-12-27 17:39:51,323 - INFO - Early stopping triggered at epoch 11
2024-12-27 17:39:51,323 - INFO - Training completed in 140.64s
2024-12-27 17:39:51,323 - INFO - Final memory usage: CPU 2759.3 MB, GPU 155.0 MB
2024-12-27 17:39:51,323 - INFO - Model training completed in 140.64s
2024-12-27 17:39:51,482 - INFO - Prediction completed in 0.16s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 17:39:51,495 - INFO - Poison rate 0.0 completed in 149.53s
2024-12-27 17:39:51,495 - INFO - 
Processing poison rate: 0.01
2024-12-27 17:39:51,500 - INFO - Total number of labels flipped: 197
2024-12-27 17:39:51,501 - INFO - Label flipping completed in 0.01s
2024-12-27 17:39:51,501 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:39:51,501 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:39:53,342 - INFO - Feature scaling completed in 1.84s
2024-12-27 17:39:53,342 - INFO - Starting feature selection (k=50)
2024-12-27 17:39:53,393 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 17:39:53,393 - INFO - Starting anomaly detection
2024-12-27 17:40:01,421 - INFO - Anomaly detection completed in 8.03s
2024-12-27 17:40:01,421 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:40:01,421 - INFO - Total fit_transform time: 9.92s
2024-12-27 17:40:01,421 - INFO - Training set processing completed in 9.92s
2024-12-27 17:40:01,421 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 17:40:01,422 - INFO - Memory usage at start_fit: CPU 2759.3 MB, GPU 55.8 MB
2024-12-27 17:40:01,422 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:40:01,666 - INFO - Fitted scaler and transformed data
2024-12-27 17:40:01,667 - INFO - Scaling time: 0.24s
2024-12-27 17:40:01,686 - INFO - Number of unique classes: 43
2024-12-27 17:40:14,654 - INFO - Epoch 1/15, Train Loss: 3.5720, Val Loss: 3.7543
2024-12-27 17:40:28,270 - INFO - Epoch 2/15, Train Loss: 3.5631, Val Loss: 3.7454
2024-12-27 17:40:40,862 - INFO - Epoch 3/15, Train Loss: 3.5523, Val Loss: 3.7350
2024-12-27 17:40:54,372 - INFO - Epoch 4/15, Train Loss: 3.5400, Val Loss: 3.7236
2024-12-27 17:41:07,710 - INFO - Epoch 5/15, Train Loss: 3.5271, Val Loss: 3.7126
2024-12-27 17:41:20,357 - INFO - Epoch 6/15, Train Loss: 3.5149, Val Loss: 3.7031
2024-12-27 17:41:33,774 - INFO - Epoch 7/15, Train Loss: 3.5044, Val Loss: 3.6953
2024-12-27 17:41:47,426 - INFO - Epoch 8/15, Train Loss: 3.4958, Val Loss: 3.6892
2024-12-27 17:42:02,786 - INFO - Epoch 9/15, Train Loss: 3.4888, Val Loss: 3.6843
2024-12-27 17:42:18,164 - INFO - Epoch 10/15, Train Loss: 3.4832, Val Loss: 3.6804
2024-12-27 17:42:32,614 - INFO - Epoch 11/15, Train Loss: 3.4788, Val Loss: 3.6774
2024-12-27 17:42:32,614 - INFO - Early stopping triggered at epoch 11
2024-12-27 17:42:32,614 - INFO - Training completed in 151.19s
2024-12-27 17:42:32,615 - INFO - Final memory usage: CPU 2759.3 MB, GPU 155.0 MB
2024-12-27 17:42:32,615 - INFO - Model training completed in 151.19s
2024-12-27 17:42:32,887 - INFO - Prediction completed in 0.27s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 17:42:32,899 - INFO - Poison rate 0.01 completed in 161.40s
2024-12-27 17:42:32,900 - INFO - 
Processing poison rate: 0.03
2024-12-27 17:42:32,912 - INFO - Total number of labels flipped: 592
2024-12-27 17:42:32,912 - INFO - Label flipping completed in 0.01s
2024-12-27 17:42:32,912 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:42:32,912 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:42:34,780 - INFO - Feature scaling completed in 1.87s
2024-12-27 17:42:34,781 - INFO - Starting feature selection (k=50)
2024-12-27 17:42:34,831 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 17:42:34,831 - INFO - Starting anomaly detection
2024-12-27 17:42:40,824 - INFO - Anomaly detection completed in 5.99s
2024-12-27 17:42:40,824 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:42:40,824 - INFO - Total fit_transform time: 7.91s
2024-12-27 17:42:40,824 - INFO - Training set processing completed in 7.91s
2024-12-27 17:42:40,825 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 17:42:40,826 - INFO - Memory usage at start_fit: CPU 2759.3 MB, GPU 55.8 MB
2024-12-27 17:42:40,826 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:42:41,096 - INFO - Fitted scaler and transformed data
2024-12-27 17:42:41,097 - INFO - Scaling time: 0.27s
2024-12-27 17:42:41,117 - INFO - Number of unique classes: 43
2024-12-27 17:42:54,687 - INFO - Epoch 1/15, Train Loss: 3.5716, Val Loss: 3.7547
2024-12-27 17:43:07,977 - INFO - Epoch 2/15, Train Loss: 3.5629, Val Loss: 3.7463
2024-12-27 17:43:20,922 - INFO - Epoch 3/15, Train Loss: 3.5524, Val Loss: 3.7364
2024-12-27 17:43:33,780 - INFO - Epoch 4/15, Train Loss: 3.5405, Val Loss: 3.7257
2024-12-27 17:43:46,818 - INFO - Epoch 5/15, Train Loss: 3.5282, Val Loss: 3.7155
2024-12-27 17:43:59,240 - INFO - Epoch 6/15, Train Loss: 3.5166, Val Loss: 3.7065
2024-12-27 17:44:11,978 - INFO - Epoch 7/15, Train Loss: 3.5067, Val Loss: 3.6990
2024-12-27 17:44:24,662 - INFO - Epoch 8/15, Train Loss: 3.4984, Val Loss: 3.6930
2024-12-27 17:44:37,497 - INFO - Epoch 9/15, Train Loss: 3.4918, Val Loss: 3.6883
2024-12-27 17:44:49,965 - INFO - Epoch 10/15, Train Loss: 3.4862, Val Loss: 3.6844
2024-12-27 17:45:02,217 - INFO - Epoch 11/15, Train Loss: 3.4817, Val Loss: 3.6814
2024-12-27 17:45:02,217 - INFO - Early stopping triggered at epoch 11
2024-12-27 17:45:02,217 - INFO - Training completed in 141.39s
2024-12-27 17:45:02,218 - INFO - Final memory usage: CPU 2759.4 MB, GPU 155.0 MB
2024-12-27 17:45:02,218 - INFO - Model training completed in 141.39s
2024-12-27 17:45:02,353 - INFO - Prediction completed in 0.13s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 17:45:02,366 - INFO - Poison rate 0.03 completed in 149.47s
2024-12-27 17:45:02,366 - INFO - 
Processing poison rate: 0.05
2024-12-27 17:45:02,385 - INFO - Total number of labels flipped: 987
2024-12-27 17:45:02,385 - INFO - Label flipping completed in 0.02s
2024-12-27 17:45:02,385 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:45:02,385 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:45:04,266 - INFO - Feature scaling completed in 1.88s
2024-12-27 17:45:04,267 - INFO - Starting feature selection (k=50)
2024-12-27 17:45:04,317 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 17:45:04,317 - INFO - Starting anomaly detection
2024-12-27 17:45:11,622 - INFO - Anomaly detection completed in 7.30s
2024-12-27 17:45:11,622 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:45:11,622 - INFO - Total fit_transform time: 9.24s
2024-12-27 17:45:11,622 - INFO - Training set processing completed in 9.24s
2024-12-27 17:45:11,623 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 17:45:11,624 - INFO - Memory usage at start_fit: CPU 2759.4 MB, GPU 55.8 MB
2024-12-27 17:45:11,624 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:45:11,897 - INFO - Fitted scaler and transformed data
2024-12-27 17:45:11,897 - INFO - Scaling time: 0.27s
2024-12-27 17:45:11,918 - INFO - Number of unique classes: 43
2024-12-27 17:45:24,697 - INFO - Epoch 1/15, Train Loss: 3.5718, Val Loss: 3.7549
2024-12-27 17:45:37,888 - INFO - Epoch 2/15, Train Loss: 3.5634, Val Loss: 3.7469
2024-12-27 17:45:51,347 - INFO - Epoch 3/15, Train Loss: 3.5535, Val Loss: 3.7376
2024-12-27 17:46:05,622 - INFO - Epoch 4/15, Train Loss: 3.5422, Val Loss: 3.7274
2024-12-27 17:46:17,686 - INFO - Epoch 5/15, Train Loss: 3.5302, Val Loss: 3.7175
2024-12-27 17:46:30,646 - INFO - Epoch 6/15, Train Loss: 3.5186, Val Loss: 3.7087
2024-12-27 17:46:43,325 - INFO - Epoch 7/15, Train Loss: 3.5087, Val Loss: 3.7014
2024-12-27 17:46:56,190 - INFO - Epoch 8/15, Train Loss: 3.5004, Val Loss: 3.6956
2024-12-27 17:47:07,841 - INFO - Epoch 9/15, Train Loss: 3.4934, Val Loss: 3.6911
2024-12-27 17:47:20,504 - INFO - Epoch 10/15, Train Loss: 3.4880, Val Loss: 3.6873
2024-12-27 17:47:20,504 - INFO - Early stopping triggered at epoch 10
2024-12-27 17:47:20,504 - INFO - Training completed in 128.88s
2024-12-27 17:47:20,505 - INFO - Final memory usage: CPU 2759.4 MB, GPU 155.0 MB
2024-12-27 17:47:20,505 - INFO - Model training completed in 128.88s
2024-12-27 17:47:20,728 - INFO - Prediction completed in 0.22s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 17:47:20,740 - INFO - Poison rate 0.05 completed in 138.37s
2024-12-27 17:47:20,740 - INFO - 
Processing poison rate: 0.07
2024-12-27 17:47:20,767 - INFO - Total number of labels flipped: 1382
2024-12-27 17:47:20,767 - INFO - Label flipping completed in 0.03s
2024-12-27 17:47:20,768 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:47:20,768 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:47:22,546 - INFO - Feature scaling completed in 1.78s
2024-12-27 17:47:22,546 - INFO - Starting feature selection (k=50)
2024-12-27 17:47:22,597 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 17:47:22,597 - INFO - Starting anomaly detection
2024-12-27 17:47:30,609 - INFO - Anomaly detection completed in 8.01s
2024-12-27 17:47:30,609 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:47:30,609 - INFO - Total fit_transform time: 9.84s
2024-12-27 17:47:30,610 - INFO - Training set processing completed in 9.84s
2024-12-27 17:47:30,610 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 17:47:30,611 - INFO - Memory usage at start_fit: CPU 2759.4 MB, GPU 55.8 MB
2024-12-27 17:47:30,611 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:47:30,875 - INFO - Fitted scaler and transformed data
2024-12-27 17:47:30,875 - INFO - Scaling time: 0.26s
2024-12-27 17:47:30,896 - INFO - Number of unique classes: 43
2024-12-27 17:47:44,467 - INFO - Epoch 1/15, Train Loss: 3.5684, Val Loss: 3.7552
2024-12-27 17:47:56,372 - INFO - Epoch 2/15, Train Loss: 3.5603, Val Loss: 3.7475
2024-12-27 17:48:09,736 - INFO - Epoch 3/15, Train Loss: 3.5506, Val Loss: 3.7383
2024-12-27 17:48:21,360 - INFO - Epoch 4/15, Train Loss: 3.5395, Val Loss: 3.7281
2024-12-27 17:48:32,817 - INFO - Epoch 5/15, Train Loss: 3.5275, Val Loss: 3.7179
2024-12-27 17:48:45,644 - INFO - Epoch 6/15, Train Loss: 3.5160, Val Loss: 3.7089
2024-12-27 17:48:57,035 - INFO - Epoch 7/15, Train Loss: 3.5061, Val Loss: 3.7016
2024-12-27 17:49:10,793 - INFO - Epoch 8/15, Train Loss: 3.4978, Val Loss: 3.6956
2024-12-27 17:49:22,834 - INFO - Epoch 9/15, Train Loss: 3.4910, Val Loss: 3.6910
2024-12-27 17:49:39,945 - INFO - Epoch 10/15, Train Loss: 3.4857, Val Loss: 3.6872
2024-12-27 17:49:54,248 - INFO - Epoch 11/15, Train Loss: 3.4811, Val Loss: 3.6842
2024-12-27 17:49:54,248 - INFO - Early stopping triggered at epoch 11
2024-12-27 17:49:54,248 - INFO - Training completed in 143.64s
2024-12-27 17:49:54,249 - INFO - Final memory usage: CPU 2759.4 MB, GPU 155.0 MB
2024-12-27 17:49:54,249 - INFO - Model training completed in 143.64s
2024-12-27 17:49:54,419 - INFO - Prediction completed in 0.17s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 17:49:54,431 - INFO - Poison rate 0.07 completed in 153.69s
2024-12-27 17:49:54,432 - INFO - 
Processing poison rate: 0.1
2024-12-27 17:49:54,467 - INFO - Total number of labels flipped: 1975
2024-12-27 17:49:54,467 - INFO - Label flipping completed in 0.04s
2024-12-27 17:49:54,467 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:49:54,468 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:49:56,262 - INFO - Feature scaling completed in 1.79s
2024-12-27 17:49:56,262 - INFO - Starting feature selection (k=50)
2024-12-27 17:49:56,312 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 17:49:56,313 - INFO - Starting anomaly detection
2024-12-27 17:50:04,281 - INFO - Anomaly detection completed in 7.97s
2024-12-27 17:50:04,281 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:50:04,281 - INFO - Total fit_transform time: 9.81s
2024-12-27 17:50:04,282 - INFO - Training set processing completed in 9.81s
2024-12-27 17:50:04,282 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 17:50:04,283 - INFO - Memory usage at start_fit: CPU 2759.4 MB, GPU 55.8 MB
2024-12-27 17:50:04,283 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:50:04,535 - INFO - Fitted scaler and transformed data
2024-12-27 17:50:04,536 - INFO - Scaling time: 0.25s
2024-12-27 17:50:04,566 - INFO - Number of unique classes: 43
2024-12-27 17:50:16,810 - INFO - Epoch 1/15, Train Loss: 3.5715, Val Loss: 3.7555
2024-12-27 17:50:27,681 - INFO - Epoch 2/15, Train Loss: 3.5638, Val Loss: 3.7482
2024-12-27 17:50:40,984 - INFO - Epoch 3/15, Train Loss: 3.5546, Val Loss: 3.7396
2024-12-27 17:50:53,515 - INFO - Epoch 4/15, Train Loss: 3.5440, Val Loss: 3.7300
2024-12-27 17:51:05,446 - INFO - Epoch 5/15, Train Loss: 3.5326, Val Loss: 3.7204
2024-12-27 17:51:17,653 - INFO - Epoch 6/15, Train Loss: 3.5216, Val Loss: 3.7119
2024-12-27 17:51:28,973 - INFO - Epoch 7/15, Train Loss: 3.5119, Val Loss: 3.7047
2024-12-27 17:51:41,314 - INFO - Epoch 8/15, Train Loss: 3.5037, Val Loss: 3.6990
2024-12-27 17:51:54,087 - INFO - Epoch 9/15, Train Loss: 3.4970, Val Loss: 3.6943
2024-12-27 17:52:06,578 - INFO - Epoch 10/15, Train Loss: 3.4917, Val Loss: 3.6906
2024-12-27 17:52:19,950 - INFO - Epoch 11/15, Train Loss: 3.4872, Val Loss: 3.6876
2024-12-27 17:52:19,951 - INFO - Early stopping triggered at epoch 11
2024-12-27 17:52:19,951 - INFO - Training completed in 135.67s
2024-12-27 17:52:19,951 - INFO - Final memory usage: CPU 2759.4 MB, GPU 155.0 MB
2024-12-27 17:52:19,952 - INFO - Model training completed in 135.67s
2024-12-27 17:52:20,130 - INFO - Prediction completed in 0.18s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 17:52:20,141 - INFO - Poison rate 0.1 completed in 145.71s
2024-12-27 17:52:20,141 - INFO - 
Processing poison rate: 0.2
2024-12-27 17:52:20,214 - INFO - Total number of labels flipped: 3951
2024-12-27 17:52:20,214 - INFO - Label flipping completed in 0.07s
2024-12-27 17:52:20,215 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:52:20,215 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:52:22,042 - INFO - Feature scaling completed in 1.83s
2024-12-27 17:52:22,043 - INFO - Starting feature selection (k=50)
2024-12-27 17:52:22,093 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 17:52:22,093 - INFO - Starting anomaly detection
2024-12-27 17:52:30,203 - INFO - Anomaly detection completed in 8.11s
2024-12-27 17:52:30,204 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:52:30,204 - INFO - Total fit_transform time: 9.99s
2024-12-27 17:52:30,204 - INFO - Training set processing completed in 9.99s
2024-12-27 17:52:30,204 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 17:52:30,206 - INFO - Memory usage at start_fit: CPU 2759.4 MB, GPU 55.8 MB
2024-12-27 17:52:30,206 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:52:30,456 - INFO - Fitted scaler and transformed data
2024-12-27 17:52:30,456 - INFO - Scaling time: 0.25s
2024-12-27 17:52:30,476 - INFO - Number of unique classes: 43
2024-12-27 17:52:43,802 - INFO - Epoch 1/15, Train Loss: 3.5690, Val Loss: 3.7567
2024-12-27 17:52:55,789 - INFO - Epoch 2/15, Train Loss: 3.5628, Val Loss: 3.7511
2024-12-27 17:53:08,034 - INFO - Epoch 3/15, Train Loss: 3.5556, Val Loss: 3.7443
2024-12-27 17:53:19,408 - INFO - Epoch 4/15, Train Loss: 3.5471, Val Loss: 3.7365
2024-12-27 17:53:31,317 - INFO - Epoch 5/15, Train Loss: 3.5377, Val Loss: 3.7284
2024-12-27 17:53:43,308 - INFO - Epoch 6/15, Train Loss: 3.5285, Val Loss: 3.7209
2024-12-27 17:53:55,943 - INFO - Epoch 7/15, Train Loss: 3.5199, Val Loss: 3.7144
2024-12-27 17:54:09,394 - INFO - Epoch 8/15, Train Loss: 3.5126, Val Loss: 3.7091
2024-12-27 17:54:22,267 - INFO - Epoch 9/15, Train Loss: 3.5063, Val Loss: 3.7047
2024-12-27 17:54:22,268 - INFO - Early stopping triggered at epoch 9
2024-12-27 17:54:22,268 - INFO - Training completed in 112.06s
2024-12-27 17:54:22,268 - INFO - Final memory usage: CPU 2759.4 MB, GPU 155.0 MB
2024-12-27 17:54:22,268 - INFO - Model training completed in 112.06s
2024-12-27 17:54:22,405 - INFO - Prediction completed in 0.14s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 17:54:22,418 - INFO - Poison rate 0.2 completed in 122.28s
2024-12-27 17:54:22,419 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 17:54:22,419 - INFO - Total evaluation time: 1055.27s
2024-12-27 17:54:22,425 - INFO - 
Progress: 7.3% - Evaluating GTSRB with KNeighbors (standard mode, iteration 1/1)
2024-12-27 17:54:22,481 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 17:54:22,654 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 17:54:22,750 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 17:54:22,750 - INFO - Dataset type: image
2024-12-27 17:54:22,750 - INFO - Sample size: 39209
2024-12-27 17:54:22,750 - INFO - Using device: cuda
2024-12-27 17:54:22,750 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 17:54:22,752 - INFO - Loading datasets...
2024-12-27 17:54:40,128 - INFO - Dataset loading completed in 17.38s
2024-12-27 17:54:40,129 - INFO - Extracting validation features...
2024-12-27 17:54:40,129 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:32,  4.25it/s]Extracting features:   2%|▏         | 3/139 [00:00<00:16,  8.02it/s]Extracting features:   4%|▎         | 5/139 [00:00<00:11, 11.24it/s]Extracting features:   7%|▋         | 10/139 [00:00<00:05, 21.87it/s]Extracting features:  11%|█         | 15/139 [00:00<00:04, 28.94it/s]Extracting features:  14%|█▎        | 19/139 [00:00<00:03, 31.46it/s]Extracting features:  17%|█▋        | 24/139 [00:00<00:03, 35.44it/s]Extracting features:  22%|██▏       | 30/139 [00:01<00:02, 40.63it/s]Extracting features:  26%|██▌       | 36/139 [00:01<00:02, 42.50it/s]Extracting features:  30%|███       | 42/139 [00:01<00:02, 46.40it/s]Extracting features:  35%|███▍      | 48/139 [00:01<00:01, 48.89it/s]Extracting features:  40%|███▉      | 55/139 [00:01<00:01, 52.68it/s]Extracting features:  45%|████▍     | 62/139 [00:01<00:01, 55.41it/s]Extracting features:  50%|████▉     | 69/139 [00:01<00:01, 57.84it/s]Extracting features:  55%|█████▍    | 76/139 [00:01<00:01, 59.05it/s]Extracting features:  59%|█████▉    | 82/139 [00:01<00:01, 55.53it/s]Extracting features:  63%|██████▎   | 88/139 [00:02<00:01, 48.54it/s]Extracting features:  68%|██████▊   | 94/139 [00:02<00:00, 49.81it/s]Extracting features:  72%|███████▏  | 100/139 [00:02<00:00, 49.92it/s]Extracting features:  77%|███████▋  | 107/139 [00:02<00:00, 52.69it/s]Extracting features:  82%|████████▏ | 114/139 [00:02<00:00, 56.55it/s]Extracting features:  87%|████████▋ | 121/139 [00:02<00:00, 57.78it/s]Extracting features:  91%|█████████▏| 127/139 [00:02<00:00, 57.97it/s]Extracting features:  96%|█████████▌| 133/139 [00:02<00:00, 57.81it/s]Extracting features: 100%|██████████| 139/139 [00:03<00:00, 47.98it/s]Extracting features: 100%|██████████| 139/139 [00:03<00:00, 43.83it/s]
2024-12-27 17:54:43,312 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 17:54:43,312 - INFO - Validation feature extraction completed in 3.18s
2024-12-27 17:54:43,312 - INFO - Extracting training features...
2024-12-27 17:54:43,312 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<02:21,  4.36it/s]Extracting features:   1%|          | 6/618 [00:00<00:28, 21.38it/s]Extracting features:   2%|▏         | 12/618 [00:00<00:18, 33.65it/s]Extracting features:   3%|▎         | 17/618 [00:00<00:15, 38.33it/s]Extracting features:   4%|▎         | 22/618 [00:00<00:15, 37.97it/s]Extracting features:   4%|▍         | 27/618 [00:00<00:14, 41.33it/s]Extracting features:   5%|▌         | 32/618 [00:00<00:14, 39.12it/s]Extracting features:   6%|▌         | 38/618 [00:01<00:13, 42.02it/s]Extracting features:   7%|▋         | 43/618 [00:01<00:13, 42.45it/s]Extracting features:   8%|▊         | 49/618 [00:01<00:12, 44.86it/s]Extracting features:   9%|▊         | 54/618 [00:01<00:13, 41.18it/s]Extracting features:  10%|▉         | 59/618 [00:01<00:12, 43.36it/s]Extracting features:  10%|█         | 64/618 [00:01<00:12, 43.39it/s]Extracting features:  11%|█         | 69/618 [00:01<00:12, 43.95it/s]Extracting features:  12%|█▏        | 75/618 [00:01<00:11, 46.83it/s]Extracting features:  13%|█▎        | 81/618 [00:01<00:10, 49.66it/s]Extracting features:  14%|█▍        | 87/618 [00:02<00:10, 51.64it/s]Extracting features:  15%|█▌        | 93/618 [00:02<00:10, 50.06it/s]Extracting features:  16%|█▌        | 99/618 [00:02<00:10, 51.20it/s]Extracting features:  17%|█▋        | 105/618 [00:02<00:09, 53.48it/s]Extracting features:  18%|█▊        | 112/618 [00:02<00:09, 56.13it/s]Extracting features:  19%|█▉        | 119/618 [00:02<00:08, 58.31it/s]Extracting features:  20%|██        | 125/618 [00:02<00:08, 56.71it/s]Extracting features:  21%|██        | 131/618 [00:02<00:08, 57.37it/s]Extracting features:  22%|██▏       | 137/618 [00:02<00:08, 56.79it/s]Extracting features:  23%|██▎       | 143/618 [00:03<00:08, 53.22it/s]Extracting features:  24%|██▍       | 149/618 [00:03<00:09, 51.40it/s]Extracting features:  25%|██▌       | 156/618 [00:03<00:08, 55.32it/s]Extracting features:  26%|██▌       | 162/618 [00:03<00:08, 54.70it/s]Extracting features:  27%|██▋       | 168/618 [00:03<00:08, 51.90it/s]Extracting features:  28%|██▊       | 174/618 [00:03<00:08, 53.20it/s]Extracting features:  29%|██▉       | 180/618 [00:03<00:08, 52.59it/s]Extracting features:  30%|███       | 186/618 [00:03<00:08, 53.24it/s]Extracting features:  31%|███       | 192/618 [00:04<00:08, 52.57it/s]Extracting features:  32%|███▏      | 199/618 [00:04<00:07, 55.52it/s]Extracting features:  33%|███▎      | 205/618 [00:04<00:07, 56.43it/s]Extracting features:  34%|███▍      | 212/618 [00:04<00:06, 58.64it/s]Extracting features:  35%|███▌      | 218/618 [00:04<00:07, 52.43it/s]Extracting features:  36%|███▌      | 224/618 [00:04<00:07, 52.90it/s]Extracting features:  37%|███▋      | 230/618 [00:04<00:07, 53.02it/s]Extracting features:  38%|███▊      | 236/618 [00:04<00:07, 48.95it/s]Extracting features:  39%|███▉      | 242/618 [00:04<00:07, 51.10it/s]Extracting features:  40%|████      | 248/618 [00:05<00:07, 52.09it/s]Extracting features:  41%|████      | 254/618 [00:05<00:06, 53.09it/s]Extracting features:  42%|████▏     | 260/618 [00:05<00:06, 51.79it/s]Extracting features:  43%|████▎     | 266/618 [00:05<00:06, 52.20it/s]Extracting features:  44%|████▍     | 272/618 [00:05<00:06, 52.13it/s]Extracting features:  45%|████▍     | 278/618 [00:05<00:06, 50.32it/s]Extracting features:  46%|████▌     | 284/618 [00:05<00:06, 50.66it/s]Extracting features:  47%|████▋     | 291/618 [00:05<00:06, 53.73it/s]Extracting features:  48%|████▊     | 297/618 [00:06<00:06, 51.85it/s]Extracting features:  49%|████▉     | 303/618 [00:06<00:06, 47.97it/s]Extracting features:  50%|█████     | 309/618 [00:06<00:06, 50.01it/s]Extracting features:  51%|█████     | 316/618 [00:06<00:05, 53.79it/s]Extracting features:  52%|█████▏    | 322/618 [00:06<00:05, 51.33it/s]Extracting features:  53%|█████▎    | 328/618 [00:06<00:05, 52.72it/s]Extracting features:  54%|█████▍    | 334/618 [00:06<00:05, 54.52it/s]Extracting features:  55%|█████▌    | 340/618 [00:06<00:05, 51.71it/s]Extracting features:  56%|█████▌    | 346/618 [00:07<00:05, 47.26it/s]Extracting features:  57%|█████▋    | 351/618 [00:07<00:05, 44.51it/s]Extracting features:  58%|█████▊    | 356/618 [00:07<00:06, 42.78it/s]Extracting features:  59%|█████▊    | 362/618 [00:07<00:05, 44.74it/s]Extracting features:  59%|█████▉    | 367/618 [00:07<00:05, 44.02it/s]Extracting features:  60%|██████    | 372/618 [00:07<00:06, 39.82it/s]Extracting features:  61%|██████    | 378/618 [00:07<00:05, 42.90it/s]Extracting features:  62%|██████▏   | 383/618 [00:07<00:05, 44.09it/s]Extracting features:  63%|██████▎   | 389/618 [00:07<00:04, 46.83it/s]Extracting features:  64%|██████▍   | 396/618 [00:08<00:04, 52.21it/s]Extracting features:  65%|██████▌   | 402/618 [00:08<00:04, 52.80it/s]Extracting features:  66%|██████▌   | 408/618 [00:08<00:03, 52.94it/s]Extracting features:  67%|██████▋   | 414/618 [00:08<00:03, 53.35it/s]Extracting features:  68%|██████▊   | 420/618 [00:08<00:03, 51.41it/s]Extracting features:  69%|██████▉   | 426/618 [00:08<00:03, 48.76it/s]Extracting features:  70%|███████   | 433/618 [00:08<00:03, 52.79it/s]Extracting features:  71%|███████   | 439/618 [00:08<00:03, 48.96it/s]Extracting features:  72%|███████▏  | 445/618 [00:09<00:03, 49.04it/s]Extracting features:  73%|███████▎  | 450/618 [00:09<00:03, 47.48it/s]Extracting features:  74%|███████▍  | 456/618 [00:09<00:03, 50.43it/s]Extracting features:  75%|███████▍  | 462/618 [00:09<00:03, 45.23it/s]Extracting features:  76%|███████▌  | 467/618 [00:09<00:03, 44.25it/s]Extracting features:  77%|███████▋  | 473/618 [00:09<00:03, 45.40it/s]Extracting features:  77%|███████▋  | 478/618 [00:09<00:03, 41.92it/s]Extracting features:  78%|███████▊  | 484/618 [00:09<00:02, 45.10it/s]Extracting features:  79%|███████▉  | 489/618 [00:10<00:02, 45.53it/s]Extracting features:  80%|████████  | 495/618 [00:10<00:02, 48.49it/s]Extracting features:  81%|████████  | 501/618 [00:10<00:02, 49.05it/s]Extracting features:  82%|████████▏ | 507/618 [00:10<00:02, 50.75it/s]Extracting features:  83%|████████▎ | 513/618 [00:10<00:02, 47.57it/s]Extracting features:  84%|████████▍ | 519/618 [00:10<00:02, 49.25it/s]Extracting features:  85%|████████▍ | 525/618 [00:10<00:01, 51.75it/s]Extracting features:  86%|████████▌ | 532/618 [00:10<00:01, 56.57it/s]Extracting features:  87%|████████▋ | 538/618 [00:10<00:01, 54.00it/s]Extracting features:  88%|████████▊ | 544/618 [00:11<00:01, 51.92it/s]Extracting features:  89%|████████▉ | 550/618 [00:11<00:01, 53.87it/s]Extracting features:  90%|████████▉ | 556/618 [00:11<00:01, 53.85it/s]Extracting features:  91%|█████████ | 562/618 [00:11<00:01, 54.18it/s]Extracting features:  92%|█████████▏| 568/618 [00:11<00:00, 51.49it/s]Extracting features:  93%|█████████▎| 574/618 [00:11<00:00, 46.02it/s]Extracting features:  94%|█████████▍| 581/618 [00:11<00:00, 51.20it/s]Extracting features:  95%|█████████▍| 587/618 [00:11<00:00, 53.14it/s]Extracting features:  96%|█████████▌| 593/618 [00:12<00:00, 52.35it/s]Extracting features:  97%|█████████▋| 599/618 [00:12<00:00, 52.99it/s]Extracting features:  98%|█████████▊| 606/618 [00:12<00:00, 55.77it/s]Extracting features:  99%|█████████▉| 612/618 [00:12<00:00, 51.24it/s]Extracting features: 100%|██████████| 618/618 [00:12<00:00, 52.18it/s]Extracting features: 100%|██████████| 618/618 [00:12<00:00, 49.09it/s]
2024-12-27 17:54:55,936 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 17:54:55,936 - INFO - Training feature extraction completed in 12.62s
2024-12-27 17:54:55,936 - INFO - Creating model for classifier: KNeighbors
2024-12-27 17:54:55,936 - INFO - Using device: cuda
2024-12-27 17:54:55,936 - INFO - 
Processing poison rate: 0.0
2024-12-27 17:54:55,936 - INFO - Training set processing completed in 0.00s
2024-12-27 17:54:55,936 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 17:54:55,938 - INFO - Memory usage at start_fit: CPU 2756.1 MB, GPU 47.3 MB
2024-12-27 17:54:55,939 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:54:56,232 - INFO - Fitted scaler and transformed data
2024-12-27 17:54:56,232 - INFO - Scaling time: 0.29s
2024-12-27 17:54:56,258 - INFO - Training completed in 0.32s
2024-12-27 17:54:56,259 - INFO - Final memory usage: CPU 2876.6 MB, GPU 143.9 MB
2024-12-27 17:54:56,260 - INFO - Model training completed in 0.32s
2024-12-27 17:54:56,375 - INFO - Prediction completed in 0.11s
2024-12-27 17:54:56,387 - INFO - Poison rate 0.0 completed in 0.45s
2024-12-27 17:54:56,387 - INFO - 
Processing poison rate: 0.01
2024-12-27 17:54:56,392 - INFO - Total number of labels flipped: 197
2024-12-27 17:54:56,393 - INFO - Label flipping completed in 0.01s
2024-12-27 17:54:56,393 - INFO - Training set processing completed in 0.00s
2024-12-27 17:54:56,393 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 17:54:56,394 - INFO - Memory usage at start_fit: CPU 2780.2 MB, GPU 143.9 MB
2024-12-27 17:54:56,394 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:54:56,677 - INFO - Fitted scaler and transformed data
2024-12-27 17:54:56,678 - INFO - Scaling time: 0.28s
2024-12-27 17:54:56,698 - INFO - Training completed in 0.30s
2024-12-27 17:54:56,699 - INFO - Final memory usage: CPU 2876.6 MB, GPU 143.9 MB
2024-12-27 17:54:56,699 - INFO - Model training completed in 0.31s
2024-12-27 17:54:56,815 - INFO - Prediction completed in 0.11s
2024-12-27 17:54:56,828 - INFO - Poison rate 0.01 completed in 0.44s
2024-12-27 17:54:56,829 - INFO - 
Processing poison rate: 0.03
2024-12-27 17:54:56,846 - INFO - Total number of labels flipped: 592
2024-12-27 17:54:56,847 - INFO - Label flipping completed in 0.02s
2024-12-27 17:54:56,847 - INFO - Training set processing completed in 0.00s
2024-12-27 17:54:56,847 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 17:54:56,848 - INFO - Memory usage at start_fit: CPU 2780.2 MB, GPU 143.9 MB
2024-12-27 17:54:56,848 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:54:57,116 - INFO - Fitted scaler and transformed data
2024-12-27 17:54:57,116 - INFO - Scaling time: 0.27s
2024-12-27 17:54:57,131 - INFO - Training completed in 0.28s
2024-12-27 17:54:57,132 - INFO - Final memory usage: CPU 2876.6 MB, GPU 143.9 MB
2024-12-27 17:54:57,132 - INFO - Model training completed in 0.29s
2024-12-27 17:54:57,211 - INFO - Prediction completed in 0.08s
2024-12-27 17:54:57,221 - INFO - Poison rate 0.03 completed in 0.39s
2024-12-27 17:54:57,221 - INFO - 
Processing poison rate: 0.05
2024-12-27 17:54:57,240 - INFO - Total number of labels flipped: 987
2024-12-27 17:54:57,240 - INFO - Label flipping completed in 0.02s
2024-12-27 17:54:57,240 - INFO - Training set processing completed in 0.00s
2024-12-27 17:54:57,240 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 17:54:57,242 - INFO - Memory usage at start_fit: CPU 2780.2 MB, GPU 143.9 MB
2024-12-27 17:54:57,242 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:54:57,516 - INFO - Fitted scaler and transformed data
2024-12-27 17:54:57,516 - INFO - Scaling time: 0.27s
2024-12-27 17:54:57,531 - INFO - Training completed in 0.29s
2024-12-27 17:54:57,532 - INFO - Final memory usage: CPU 2876.6 MB, GPU 143.9 MB
2024-12-27 17:54:57,533 - INFO - Model training completed in 0.29s
2024-12-27 17:54:57,619 - INFO - Prediction completed in 0.09s
2024-12-27 17:54:57,630 - INFO - Poison rate 0.05 completed in 0.41s
2024-12-27 17:54:57,630 - INFO - 
Processing poison rate: 0.07
2024-12-27 17:54:57,656 - INFO - Total number of labels flipped: 1382
2024-12-27 17:54:57,656 - INFO - Label flipping completed in 0.03s
2024-12-27 17:54:57,656 - INFO - Training set processing completed in 0.00s
2024-12-27 17:54:57,656 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 17:54:57,657 - INFO - Memory usage at start_fit: CPU 2780.2 MB, GPU 143.9 MB
2024-12-27 17:54:57,657 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:54:57,916 - INFO - Fitted scaler and transformed data
2024-12-27 17:54:57,916 - INFO - Scaling time: 0.26s
2024-12-27 17:54:57,932 - INFO - Training completed in 0.28s
2024-12-27 17:54:57,932 - INFO - Final memory usage: CPU 2876.6 MB, GPU 143.9 MB
2024-12-27 17:54:57,933 - INFO - Model training completed in 0.28s
2024-12-27 17:54:58,022 - INFO - Prediction completed in 0.09s
2024-12-27 17:54:58,034 - INFO - Poison rate 0.07 completed in 0.40s
2024-12-27 17:54:58,034 - INFO - 
Processing poison rate: 0.1
2024-12-27 17:54:58,070 - INFO - Total number of labels flipped: 1975
2024-12-27 17:54:58,070 - INFO - Label flipping completed in 0.04s
2024-12-27 17:54:58,070 - INFO - Training set processing completed in 0.00s
2024-12-27 17:54:58,070 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 17:54:58,071 - INFO - Memory usage at start_fit: CPU 2780.2 MB, GPU 143.9 MB
2024-12-27 17:54:58,071 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:54:58,337 - INFO - Fitted scaler and transformed data
2024-12-27 17:54:58,338 - INFO - Scaling time: 0.27s
2024-12-27 17:54:58,353 - INFO - Training completed in 0.28s
2024-12-27 17:54:58,353 - INFO - Final memory usage: CPU 2876.6 MB, GPU 143.9 MB
2024-12-27 17:54:58,354 - INFO - Model training completed in 0.28s
2024-12-27 17:54:58,429 - INFO - Prediction completed in 0.08s
2024-12-27 17:54:58,441 - INFO - Poison rate 0.1 completed in 0.41s
2024-12-27 17:54:58,441 - INFO - 
Processing poison rate: 0.2
2024-12-27 17:54:58,506 - INFO - Total number of labels flipped: 3951
2024-12-27 17:54:58,506 - INFO - Label flipping completed in 0.07s
2024-12-27 17:54:58,507 - INFO - Training set processing completed in 0.00s
2024-12-27 17:54:58,507 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 17:54:58,507 - INFO - Memory usage at start_fit: CPU 2780.2 MB, GPU 143.9 MB
2024-12-27 17:54:58,508 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:54:58,757 - INFO - Fitted scaler and transformed data
2024-12-27 17:54:58,757 - INFO - Scaling time: 0.25s
2024-12-27 17:54:58,772 - INFO - Training completed in 0.27s
2024-12-27 17:54:58,773 - INFO - Final memory usage: CPU 2876.6 MB, GPU 143.9 MB
2024-12-27 17:54:58,773 - INFO - Model training completed in 0.27s
2024-12-27 17:54:58,902 - INFO - Prediction completed in 0.13s
2024-12-27 17:54:58,918 - INFO - Poison rate 0.2 completed in 0.48s
2024-12-27 17:54:58,919 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 17:54:58,919 - INFO - Total evaluation time: 36.17s
2024-12-27 17:54:58,926 - INFO - 
Progress: 8.3% - Evaluating GTSRB with KNeighbors (dynadetect mode, iteration 1/1)
2024-12-27 17:54:58,984 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 17:54:59,056 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 17:54:59,140 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 17:54:59,141 - INFO - Dataset type: image
2024-12-27 17:54:59,141 - INFO - Sample size: 39209
2024-12-27 17:54:59,141 - INFO - Using device: cuda
2024-12-27 17:54:59,141 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 17:54:59,143 - INFO - Loading datasets...
2024-12-27 17:55:16,874 - INFO - Dataset loading completed in 17.73s
2024-12-27 17:55:16,875 - INFO - Extracting validation features...
2024-12-27 17:55:16,875 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:35,  3.94it/s]Extracting features:   1%|▏         | 2/139 [00:00<00:22,  6.03it/s]Extracting features:   4%|▎         | 5/139 [00:00<00:11, 11.40it/s]Extracting features:   6%|▋         | 9/139 [00:00<00:07, 17.78it/s]Extracting features:  11%|█         | 15/139 [00:00<00:04, 29.08it/s]Extracting features:  16%|█▌        | 22/139 [00:00<00:02, 39.10it/s]Extracting features:  21%|██        | 29/139 [00:00<00:02, 45.66it/s]Extracting features:  26%|██▌       | 36/139 [00:01<00:02, 50.74it/s]Extracting features:  30%|███       | 42/139 [00:01<00:01, 52.69it/s]Extracting features:  35%|███▌      | 49/139 [00:01<00:01, 56.98it/s]Extracting features:  40%|███▉      | 55/139 [00:01<00:01, 57.74it/s]Extracting features:  44%|████▍     | 61/139 [00:01<00:01, 57.37it/s]Extracting features:  48%|████▊     | 67/139 [00:01<00:01, 57.65it/s]Extracting features:  53%|█████▎    | 73/139 [00:01<00:01, 58.09it/s]Extracting features:  57%|█████▋    | 79/139 [00:01<00:01, 58.10it/s]Extracting features:  62%|██████▏   | 86/139 [00:01<00:00, 57.70it/s]Extracting features:  66%|██████▌   | 92/139 [00:02<00:00, 57.21it/s]Extracting features:  71%|███████   | 98/139 [00:02<00:00, 56.85it/s]Extracting features:  75%|███████▍  | 104/139 [00:02<00:00, 57.11it/s]Extracting features:  79%|███████▉  | 110/139 [00:02<00:00, 55.10it/s]Extracting features:  84%|████████▍ | 117/139 [00:02<00:00, 57.74it/s]Extracting features:  89%|████████▉ | 124/139 [00:02<00:00, 59.90it/s]Extracting features:  94%|█████████▍| 131/139 [00:02<00:00, 58.98it/s]Extracting features:  99%|█████████▊| 137/139 [00:02<00:00, 55.60it/s]Extracting features: 100%|██████████| 139/139 [00:03<00:00, 45.92it/s]
2024-12-27 17:55:19,912 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 17:55:19,913 - INFO - Validation feature extraction completed in 3.04s
2024-12-27 17:55:19,913 - INFO - Extracting training features...
2024-12-27 17:55:19,913 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<02:07,  4.85it/s]Extracting features:   1%|          | 5/618 [00:00<00:32, 19.08it/s]Extracting features:   2%|▏         | 11/618 [00:00<00:17, 34.00it/s]Extracting features:   3%|▎         | 18/618 [00:00<00:13, 43.81it/s]Extracting features:   4%|▍         | 24/618 [00:00<00:12, 47.93it/s]Extracting features:   5%|▍         | 30/618 [00:00<00:11, 49.74it/s]Extracting features:   6%|▌         | 37/618 [00:00<00:10, 53.88it/s]Extracting features:   7%|▋         | 43/618 [00:00<00:10, 54.03it/s]Extracting features:   8%|▊         | 49/618 [00:01<00:10, 54.25it/s]Extracting features:   9%|▉         | 56/618 [00:01<00:09, 56.30it/s]Extracting features:  10%|█         | 63/618 [00:01<00:09, 57.92it/s]Extracting features:  11%|█         | 69/618 [00:01<00:09, 56.39it/s]Extracting features:  12%|█▏        | 75/618 [00:01<00:09, 55.58it/s]Extracting features:  13%|█▎        | 81/618 [00:01<00:10, 49.77it/s]Extracting features:  14%|█▍        | 87/618 [00:01<00:11, 44.84it/s]Extracting features:  15%|█▍        | 92/618 [00:01<00:12, 42.80it/s]Extracting features:  16%|█▌        | 98/618 [00:02<00:11, 46.88it/s]Extracting features:  17%|█▋        | 105/618 [00:02<00:09, 51.55it/s]Extracting features:  18%|█▊        | 111/618 [00:02<00:10, 49.92it/s]Extracting features:  19%|█▉        | 118/618 [00:02<00:09, 53.25it/s]Extracting features:  20%|██        | 124/618 [00:02<00:10, 47.66it/s]Extracting features:  21%|██        | 129/618 [00:02<00:10, 47.87it/s]Extracting features:  22%|██▏       | 135/618 [00:02<00:09, 49.98it/s]Extracting features:  23%|██▎       | 141/618 [00:02<00:09, 50.91it/s]Extracting features:  24%|██▍       | 148/618 [00:03<00:08, 53.42it/s]Extracting features:  25%|██▌       | 155/618 [00:03<00:08, 55.39it/s]Extracting features:  26%|██▌       | 161/618 [00:03<00:08, 56.25it/s]Extracting features:  27%|██▋       | 167/618 [00:03<00:08, 54.61it/s]Extracting features:  28%|██▊       | 173/618 [00:03<00:09, 49.01it/s]Extracting features:  29%|██▉       | 179/618 [00:03<00:09, 48.43it/s]Extracting features:  30%|██▉       | 185/618 [00:03<00:08, 51.14it/s]Extracting features:  31%|███       | 192/618 [00:03<00:07, 55.09it/s]Extracting features:  32%|███▏      | 199/618 [00:03<00:07, 56.27it/s]Extracting features:  33%|███▎      | 205/618 [00:04<00:07, 57.07it/s]Extracting features:  34%|███▍      | 211/618 [00:04<00:08, 46.60it/s]Extracting features:  35%|███▍      | 216/618 [00:04<00:09, 42.76it/s]Extracting features:  36%|███▌      | 221/618 [00:04<00:08, 44.40it/s]Extracting features:  37%|███▋      | 228/618 [00:04<00:07, 49.38it/s]Extracting features:  38%|███▊      | 234/618 [00:04<00:07, 50.75it/s]Extracting features:  39%|███▉      | 240/618 [00:04<00:07, 50.41it/s]Extracting features:  40%|███▉      | 246/618 [00:04<00:07, 50.71it/s]Extracting features:  41%|████      | 252/618 [00:05<00:07, 50.45it/s]Extracting features:  42%|████▏     | 258/618 [00:05<00:07, 48.64it/s]Extracting features:  43%|████▎     | 263/618 [00:05<00:07, 48.15it/s]Extracting features:  43%|████▎     | 268/618 [00:05<00:07, 46.16it/s]Extracting features:  44%|████▍     | 275/618 [00:05<00:06, 50.85it/s]Extracting features:  45%|████▌     | 281/618 [00:05<00:06, 52.77it/s]Extracting features:  46%|████▋     | 287/618 [00:05<00:06, 51.86it/s]Extracting features:  47%|████▋     | 293/618 [00:05<00:06, 52.70it/s]Extracting features:  48%|████▊     | 299/618 [00:06<00:06, 53.15it/s]Extracting features:  49%|████▉     | 305/618 [00:06<00:06, 50.22it/s]Extracting features:  50%|█████     | 311/618 [00:06<00:06, 46.49it/s]Extracting features:  51%|█████     | 316/618 [00:06<00:06, 44.36it/s]Extracting features:  52%|█████▏    | 321/618 [00:06<00:07, 40.49it/s]Extracting features:  53%|█████▎    | 327/618 [00:06<00:06, 44.66it/s]Extracting features:  54%|█████▍    | 334/618 [00:06<00:05, 49.73it/s]Extracting features:  55%|█████▌    | 340/618 [00:06<00:05, 51.59it/s]Extracting features:  56%|█████▌    | 346/618 [00:07<00:05, 47.35it/s]Extracting features:  57%|█████▋    | 351/618 [00:07<00:05, 46.14it/s]Extracting features:  58%|█████▊    | 357/618 [00:07<00:05, 47.96it/s]Extracting features:  59%|█████▉    | 364/618 [00:07<00:04, 51.24it/s]Extracting features:  60%|█████▉    | 370/618 [00:07<00:05, 46.88it/s]Extracting features:  61%|██████    | 377/618 [00:07<00:04, 49.29it/s]Extracting features:  62%|██████▏   | 384/618 [00:07<00:04, 53.56it/s]Extracting features:  63%|██████▎   | 390/618 [00:07<00:04, 55.16it/s]Extracting features:  64%|██████▍   | 397/618 [00:07<00:03, 56.95it/s]Extracting features:  65%|██████▌   | 403/618 [00:08<00:04, 53.10it/s]Extracting features:  66%|██████▌   | 409/618 [00:08<00:04, 51.51it/s]Extracting features:  67%|██████▋   | 415/618 [00:08<00:03, 52.85it/s]Extracting features:  68%|██████▊   | 422/618 [00:08<00:03, 55.78it/s]Extracting features:  69%|██████▉   | 428/618 [00:08<00:03, 56.31it/s]Extracting features:  70%|███████   | 435/618 [00:08<00:03, 59.07it/s]Extracting features:  72%|███████▏  | 442/618 [00:08<00:02, 60.53it/s]Extracting features:  73%|███████▎  | 449/618 [00:08<00:02, 59.03it/s]Extracting features:  74%|███████▎  | 455/618 [00:09<00:02, 58.15it/s]Extracting features:  75%|███████▍  | 461/618 [00:09<00:02, 57.73it/s]Extracting features:  76%|███████▌  | 467/618 [00:09<00:02, 55.65it/s]Extracting features:  77%|███████▋  | 473/618 [00:09<00:02, 54.23it/s]Extracting features:  78%|███████▊  | 480/618 [00:09<00:02, 55.21it/s]Extracting features:  79%|███████▉  | 487/618 [00:09<00:02, 55.85it/s]Extracting features:  80%|███████▉  | 493/618 [00:09<00:02, 53.17it/s]Extracting features:  81%|████████  | 500/618 [00:09<00:02, 56.27it/s]Extracting features:  82%|████████▏ | 506/618 [00:09<00:01, 57.02it/s]Extracting features:  83%|████████▎ | 513/618 [00:10<00:01, 55.88it/s]Extracting features:  84%|████████▍ | 519/618 [00:10<00:01, 56.81it/s]Extracting features:  85%|████████▍ | 525/618 [00:10<00:01, 56.03it/s]Extracting features:  86%|████████▌ | 531/618 [00:10<00:01, 55.57it/s]Extracting features:  87%|████████▋ | 537/618 [00:10<00:01, 54.47it/s]Extracting features:  88%|████████▊ | 543/618 [00:10<00:01, 49.82it/s]Extracting features:  89%|████████▉ | 549/618 [00:10<00:01, 48.15it/s]Extracting features:  90%|████████▉ | 554/618 [00:10<00:01, 45.60it/s]Extracting features:  91%|█████████ | 560/618 [00:11<00:01, 48.91it/s]Extracting features:  92%|█████████▏| 567/618 [00:11<00:00, 53.69it/s]Extracting features:  93%|█████████▎| 573/618 [00:11<00:00, 54.85it/s]Extracting features:  94%|█████████▎| 579/618 [00:11<00:00, 51.91it/s]Extracting features:  95%|█████████▍| 585/618 [00:11<00:00, 50.03it/s]Extracting features:  96%|█████████▌| 591/618 [00:11<00:00, 49.86it/s]Extracting features:  97%|█████████▋| 597/618 [00:11<00:00, 48.64it/s]Extracting features:  97%|█████████▋| 602/618 [00:11<00:00, 48.20it/s]Extracting features:  98%|█████████▊| 607/618 [00:12<00:00, 43.32it/s]Extracting features:  99%|█████████▉| 613/618 [00:12<00:00, 46.97it/s]Extracting features: 100%|██████████| 618/618 [00:12<00:00, 46.90it/s]Extracting features: 100%|██████████| 618/618 [00:12<00:00, 50.37it/s]
2024-12-27 17:55:32,218 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 17:55:32,218 - INFO - Training feature extraction completed in 12.31s
2024-12-27 17:55:32,219 - INFO - Creating model for classifier: KNeighbors
2024-12-27 17:55:32,219 - INFO - Using device: cuda
2024-12-27 17:55:32,219 - INFO - 
Processing poison rate: 0.0
2024-12-27 17:55:32,219 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:55:32,219 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:55:34,059 - INFO - Feature scaling completed in 1.84s
2024-12-27 17:55:34,059 - INFO - Starting feature selection (k=50)
2024-12-27 17:55:34,076 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 17:55:34,077 - INFO - Starting anomaly detection
2024-12-27 17:55:42,194 - INFO - Anomaly detection completed in 8.12s
2024-12-27 17:55:42,194 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:55:42,194 - INFO - Total fit_transform time: 9.98s
2024-12-27 17:55:42,195 - INFO - Training set processing completed in 9.98s
2024-12-27 17:55:42,195 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 17:55:42,196 - INFO - Memory usage at start_fit: CPU 2784.5 MB, GPU 47.3 MB
2024-12-27 17:55:42,196 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:55:42,478 - INFO - Fitted scaler and transformed data
2024-12-27 17:55:42,479 - INFO - Scaling time: 0.28s
2024-12-27 17:55:42,498 - INFO - Training completed in 0.30s
2024-12-27 17:55:42,499 - INFO - Final memory usage: CPU 2887.1 MB, GPU 143.9 MB
2024-12-27 17:55:42,499 - INFO - Model training completed in 0.30s
2024-12-27 17:55:42,889 - INFO - Prediction completed in 0.39s
2024-12-27 17:55:42,900 - INFO - Poison rate 0.0 completed in 10.68s
2024-12-27 17:55:42,901 - INFO - 
Processing poison rate: 0.01
2024-12-27 17:55:42,906 - INFO - Total number of labels flipped: 197
2024-12-27 17:55:42,906 - INFO - Label flipping completed in 0.01s
2024-12-27 17:55:42,906 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:55:42,906 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:55:44,782 - INFO - Feature scaling completed in 1.88s
2024-12-27 17:55:44,783 - INFO - Starting feature selection (k=50)
2024-12-27 17:55:44,799 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 17:55:44,800 - INFO - Starting anomaly detection
2024-12-27 17:55:52,831 - INFO - Anomaly detection completed in 8.03s
2024-12-27 17:55:52,831 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:55:52,831 - INFO - Total fit_transform time: 9.93s
2024-12-27 17:55:52,832 - INFO - Training set processing completed in 9.93s
2024-12-27 17:55:52,832 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 17:55:52,833 - INFO - Memory usage at start_fit: CPU 2790.6 MB, GPU 143.9 MB
2024-12-27 17:55:52,833 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:55:53,132 - INFO - Fitted scaler and transformed data
2024-12-27 17:55:53,132 - INFO - Scaling time: 0.30s
2024-12-27 17:55:53,152 - INFO - Training completed in 0.32s
2024-12-27 17:55:53,152 - INFO - Final memory usage: CPU 2887.1 MB, GPU 143.9 MB
2024-12-27 17:55:53,153 - INFO - Model training completed in 0.32s
2024-12-27 17:55:53,459 - INFO - Prediction completed in 0.31s
2024-12-27 17:55:53,471 - INFO - Poison rate 0.01 completed in 10.57s
2024-12-27 17:55:53,471 - INFO - 
Processing poison rate: 0.03
2024-12-27 17:55:53,483 - INFO - Total number of labels flipped: 592
2024-12-27 17:55:53,483 - INFO - Label flipping completed in 0.01s
2024-12-27 17:55:53,483 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:55:53,483 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:55:55,393 - INFO - Feature scaling completed in 1.91s
2024-12-27 17:55:55,393 - INFO - Starting feature selection (k=50)
2024-12-27 17:55:55,410 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 17:55:55,410 - INFO - Starting anomaly detection
2024-12-27 17:56:02,621 - INFO - Anomaly detection completed in 7.21s
2024-12-27 17:56:02,621 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:56:02,621 - INFO - Total fit_transform time: 9.14s
2024-12-27 17:56:02,621 - INFO - Training set processing completed in 9.14s
2024-12-27 17:56:02,622 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 17:56:02,622 - INFO - Memory usage at start_fit: CPU 2790.6 MB, GPU 143.9 MB
2024-12-27 17:56:02,623 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:56:02,889 - INFO - Fitted scaler and transformed data
2024-12-27 17:56:02,890 - INFO - Scaling time: 0.27s
2024-12-27 17:56:02,911 - INFO - Training completed in 0.29s
2024-12-27 17:56:02,911 - INFO - Final memory usage: CPU 2887.1 MB, GPU 143.9 MB
2024-12-27 17:56:02,912 - INFO - Model training completed in 0.29s
2024-12-27 17:56:03,252 - INFO - Prediction completed in 0.34s
2024-12-27 17:56:03,263 - INFO - Poison rate 0.03 completed in 9.79s
2024-12-27 17:56:03,263 - INFO - 
Processing poison rate: 0.05
2024-12-27 17:56:03,282 - INFO - Total number of labels flipped: 987
2024-12-27 17:56:03,282 - INFO - Label flipping completed in 0.02s
2024-12-27 17:56:03,282 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:56:03,282 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:56:04,995 - INFO - Feature scaling completed in 1.71s
2024-12-27 17:56:04,995 - INFO - Starting feature selection (k=50)
2024-12-27 17:56:05,013 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 17:56:05,014 - INFO - Starting anomaly detection
2024-12-27 17:56:11,190 - INFO - Anomaly detection completed in 6.18s
2024-12-27 17:56:11,191 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:56:11,191 - INFO - Total fit_transform time: 7.91s
2024-12-27 17:56:11,191 - INFO - Training set processing completed in 7.91s
2024-12-27 17:56:11,191 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 17:56:11,193 - INFO - Memory usage at start_fit: CPU 2790.6 MB, GPU 143.9 MB
2024-12-27 17:56:11,193 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:56:11,458 - INFO - Fitted scaler and transformed data
2024-12-27 17:56:11,459 - INFO - Scaling time: 0.27s
2024-12-27 17:56:11,477 - INFO - Training completed in 0.29s
2024-12-27 17:56:11,478 - INFO - Final memory usage: CPU 2887.1 MB, GPU 143.9 MB
2024-12-27 17:56:11,479 - INFO - Model training completed in 0.29s
2024-12-27 17:56:11,662 - INFO - Prediction completed in 0.18s
2024-12-27 17:56:11,672 - INFO - Poison rate 0.05 completed in 8.41s
2024-12-27 17:56:11,673 - INFO - 
Processing poison rate: 0.07
2024-12-27 17:56:11,698 - INFO - Total number of labels flipped: 1382
2024-12-27 17:56:11,698 - INFO - Label flipping completed in 0.03s
2024-12-27 17:56:11,698 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:56:11,699 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:56:13,535 - INFO - Feature scaling completed in 1.84s
2024-12-27 17:56:13,535 - INFO - Starting feature selection (k=50)
2024-12-27 17:56:13,552 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 17:56:13,552 - INFO - Starting anomaly detection
2024-12-27 17:56:19,359 - INFO - Anomaly detection completed in 5.81s
2024-12-27 17:56:19,359 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:56:19,359 - INFO - Total fit_transform time: 7.66s
2024-12-27 17:56:19,360 - INFO - Training set processing completed in 7.66s
2024-12-27 17:56:19,360 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 17:56:19,361 - INFO - Memory usage at start_fit: CPU 2790.6 MB, GPU 143.9 MB
2024-12-27 17:56:19,362 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:56:19,636 - INFO - Fitted scaler and transformed data
2024-12-27 17:56:19,636 - INFO - Scaling time: 0.27s
2024-12-27 17:56:19,655 - INFO - Training completed in 0.29s
2024-12-27 17:56:19,655 - INFO - Final memory usage: CPU 2887.1 MB, GPU 143.9 MB
2024-12-27 17:56:19,656 - INFO - Model training completed in 0.30s
2024-12-27 17:56:20,042 - INFO - Prediction completed in 0.39s
2024-12-27 17:56:20,053 - INFO - Poison rate 0.07 completed in 8.38s
2024-12-27 17:56:20,053 - INFO - 
Processing poison rate: 0.1
2024-12-27 17:56:20,088 - INFO - Total number of labels flipped: 1975
2024-12-27 17:56:20,089 - INFO - Label flipping completed in 0.04s
2024-12-27 17:56:20,089 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:56:20,089 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:56:22,067 - INFO - Feature scaling completed in 1.98s
2024-12-27 17:56:22,068 - INFO - Starting feature selection (k=50)
2024-12-27 17:56:22,085 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 17:56:22,085 - INFO - Starting anomaly detection
2024-12-27 17:56:29,844 - INFO - Anomaly detection completed in 7.76s
2024-12-27 17:56:29,845 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:56:29,845 - INFO - Total fit_transform time: 9.76s
2024-12-27 17:56:29,845 - INFO - Training set processing completed in 9.76s
2024-12-27 17:56:29,845 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 17:56:29,846 - INFO - Memory usage at start_fit: CPU 2790.6 MB, GPU 143.9 MB
2024-12-27 17:56:29,847 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:56:30,113 - INFO - Fitted scaler and transformed data
2024-12-27 17:56:30,113 - INFO - Scaling time: 0.27s
2024-12-27 17:56:30,133 - INFO - Training completed in 0.29s
2024-12-27 17:56:30,133 - INFO - Final memory usage: CPU 2887.1 MB, GPU 143.9 MB
2024-12-27 17:56:30,134 - INFO - Model training completed in 0.29s
2024-12-27 17:56:30,456 - INFO - Prediction completed in 0.32s
2024-12-27 17:56:30,471 - INFO - Poison rate 0.1 completed in 10.42s
2024-12-27 17:56:30,472 - INFO - 
Processing poison rate: 0.2
2024-12-27 17:56:30,543 - INFO - Total number of labels flipped: 3951
2024-12-27 17:56:30,543 - INFO - Label flipping completed in 0.07s
2024-12-27 17:56:30,543 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:56:30,543 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:56:32,466 - INFO - Feature scaling completed in 1.92s
2024-12-27 17:56:32,466 - INFO - Starting feature selection (k=50)
2024-12-27 17:56:32,489 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 17:56:32,489 - INFO - Starting anomaly detection
2024-12-27 17:56:40,706 - INFO - Anomaly detection completed in 8.22s
2024-12-27 17:56:40,706 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:56:40,706 - INFO - Total fit_transform time: 10.16s
2024-12-27 17:56:40,707 - INFO - Training set processing completed in 10.16s
2024-12-27 17:56:40,707 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 17:56:40,708 - INFO - Memory usage at start_fit: CPU 2790.6 MB, GPU 143.9 MB
2024-12-27 17:56:40,708 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:56:40,971 - INFO - Fitted scaler and transformed data
2024-12-27 17:56:40,971 - INFO - Scaling time: 0.26s
2024-12-27 17:56:40,995 - INFO - Training completed in 0.29s
2024-12-27 17:56:40,998 - INFO - Final memory usage: CPU 2887.1 MB, GPU 143.9 MB
2024-12-27 17:56:40,999 - INFO - Model training completed in 0.29s
2024-12-27 17:56:41,286 - INFO - Prediction completed in 0.29s
2024-12-27 17:56:41,298 - INFO - Poison rate 0.2 completed in 10.83s
2024-12-27 17:56:41,299 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 17:56:41,299 - INFO - Total evaluation time: 102.16s
2024-12-27 17:56:41,305 - INFO - Completed evaluation for GTSRB
2024-12-27 17:56:41,306 - INFO - 
Processing dataset: GTSRB
2024-12-27 17:56:41,364 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 17:56:41,484 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 17:56:41,556 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 17:56:41,556 - INFO - Dataset type: image
2024-12-27 17:56:41,556 - INFO - Sample size: 39209
2024-12-27 17:56:41,556 - INFO - Using device: cuda
2024-12-27 17:56:41,557 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 17:56:41,559 - INFO - 
Progress: 9.4% - Evaluating GTSRB with SVM (standard mode, iteration 1/1)
2024-12-27 17:56:41,616 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 17:56:41,691 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 17:56:41,775 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 17:56:41,776 - INFO - Dataset type: image
2024-12-27 17:56:41,776 - INFO - Sample size: 39209
2024-12-27 17:56:41,776 - INFO - Using device: cuda
2024-12-27 17:56:41,776 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 17:56:41,778 - INFO - Loading datasets...
2024-12-27 17:56:59,409 - INFO - Dataset loading completed in 17.63s
2024-12-27 17:56:59,409 - INFO - Extracting validation features...
2024-12-27 17:56:59,410 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:32,  4.31it/s]Extracting features:   2%|▏         | 3/139 [00:00<00:15,  9.04it/s]Extracting features:   5%|▌         | 7/139 [00:00<00:07, 17.99it/s]Extracting features:   9%|▊         | 12/139 [00:00<00:04, 27.63it/s]Extracting features:  14%|█▎        | 19/139 [00:00<00:03, 38.41it/s]Extracting features:  18%|█▊        | 25/139 [00:00<00:02, 43.36it/s]Extracting features:  22%|██▏       | 31/139 [00:00<00:02, 48.09it/s]Extracting features:  27%|██▋       | 37/139 [00:01<00:02, 49.89it/s]Extracting features:  31%|███       | 43/139 [00:01<00:01, 50.21it/s]Extracting features:  35%|███▌      | 49/139 [00:01<00:01, 50.99it/s]Extracting features:  40%|███▉      | 55/139 [00:01<00:01, 49.53it/s]Extracting features:  44%|████▍     | 61/139 [00:01<00:01, 48.54it/s]Extracting features:  48%|████▊     | 67/139 [00:01<00:01, 49.54it/s]Extracting features:  53%|█████▎    | 73/139 [00:01<00:01, 49.98it/s]Extracting features:  57%|█████▋    | 79/139 [00:01<00:01, 51.69it/s]Extracting features:  61%|██████    | 85/139 [00:02<00:01, 47.12it/s]Extracting features:  65%|██████▌   | 91/139 [00:02<00:00, 48.45it/s]Extracting features:  70%|██████▉   | 97/139 [00:02<00:00, 48.08it/s]Extracting features:  73%|███████▎  | 102/139 [00:02<00:00, 47.75it/s]Extracting features:  78%|███████▊  | 108/139 [00:02<00:00, 50.24it/s]Extracting features:  82%|████████▏ | 114/139 [00:02<00:00, 51.74it/s]Extracting features:  86%|████████▋ | 120/139 [00:02<00:00, 51.75it/s]Extracting features:  91%|█████████ | 126/139 [00:02<00:00, 52.80it/s]Extracting features:  95%|█████████▍| 132/139 [00:02<00:00, 54.15it/s]Extracting features:  99%|█████████▉| 138/139 [00:03<00:00, 48.01it/s]Extracting features: 100%|██████████| 139/139 [00:03<00:00, 44.06it/s]
2024-12-27 17:57:02,574 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 17:57:02,574 - INFO - Validation feature extraction completed in 3.16s
2024-12-27 17:57:02,574 - INFO - Extracting training features...
2024-12-27 17:57:02,574 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<02:02,  5.05it/s]Extracting features:   1%|          | 7/618 [00:00<00:22, 27.45it/s]Extracting features:   2%|▏         | 11/618 [00:00<00:19, 31.23it/s]Extracting features:   3%|▎         | 16/618 [00:00<00:16, 36.86it/s]Extracting features:   3%|▎         | 21/618 [00:00<00:14, 40.18it/s]Extracting features:   4%|▍         | 27/618 [00:00<00:13, 44.45it/s]Extracting features:   5%|▌         | 33/618 [00:00<00:12, 48.51it/s]Extracting features:   6%|▋         | 40/618 [00:00<00:10, 53.60it/s]Extracting features:   7%|▋         | 46/618 [00:01<00:10, 54.71it/s]Extracting features:   8%|▊         | 52/618 [00:01<00:10, 55.98it/s]Extracting features:  10%|▉         | 59/618 [00:01<00:09, 58.55it/s]Extracting features:  11%|█         | 66/618 [00:01<00:09, 59.23it/s]Extracting features:  12%|█▏        | 72/618 [00:01<00:10, 54.51it/s]Extracting features:  13%|█▎        | 78/618 [00:01<00:10, 52.94it/s]Extracting features:  14%|█▎        | 84/618 [00:01<00:10, 53.27it/s]Extracting features:  15%|█▍        | 91/618 [00:01<00:09, 56.62it/s]Extracting features:  16%|█▌        | 98/618 [00:01<00:08, 58.18it/s]Extracting features:  17%|█▋        | 104/618 [00:02<00:08, 57.35it/s]Extracting features:  18%|█▊        | 110/618 [00:02<00:09, 53.55it/s]Extracting features:  19%|█▉        | 116/618 [00:02<00:09, 54.70it/s]Extracting features:  20%|█▉        | 122/618 [00:02<00:09, 52.36it/s]Extracting features:  21%|██        | 128/618 [00:02<00:09, 50.40it/s]Extracting features:  22%|██▏       | 134/618 [00:02<00:09, 52.58it/s]Extracting features:  23%|██▎       | 140/618 [00:02<00:09, 52.00it/s]Extracting features:  24%|██▎       | 146/618 [00:02<00:08, 54.01it/s]Extracting features:  25%|██▍       | 154/618 [00:02<00:07, 59.54it/s]Extracting features:  26%|██▌       | 161/618 [00:03<00:07, 61.13it/s]Extracting features:  27%|██▋       | 168/618 [00:03<00:07, 61.15it/s]Extracting features:  28%|██▊       | 175/618 [00:03<00:07, 60.18it/s]Extracting features:  29%|██▉       | 182/618 [00:03<00:07, 59.21it/s]Extracting features:  31%|███       | 189/618 [00:03<00:07, 59.02it/s]Extracting features:  32%|███▏      | 196/618 [00:03<00:06, 61.04it/s]Extracting features:  33%|███▎      | 203/618 [00:03<00:07, 58.87it/s]Extracting features:  34%|███▍      | 209/618 [00:03<00:06, 58.87it/s]Extracting features:  35%|███▍      | 215/618 [00:04<00:07, 55.97it/s]Extracting features:  36%|███▌      | 223/618 [00:04<00:06, 60.01it/s]Extracting features:  37%|███▋      | 230/618 [00:04<00:06, 59.57it/s]Extracting features:  38%|███▊      | 236/618 [00:04<00:06, 58.68it/s]Extracting features:  39%|███▉      | 242/618 [00:04<00:06, 58.19it/s]Extracting features:  40%|████      | 248/618 [00:04<00:06, 56.31it/s]Extracting features:  41%|████      | 254/618 [00:04<00:06, 55.93it/s]Extracting features:  42%|████▏     | 260/618 [00:04<00:07, 48.44it/s]Extracting features:  43%|████▎     | 266/618 [00:04<00:06, 50.54it/s]Extracting features:  44%|████▍     | 272/618 [00:05<00:06, 52.20it/s]Extracting features:  45%|████▍     | 278/618 [00:05<00:06, 52.08it/s]Extracting features:  46%|████▌     | 284/618 [00:05<00:06, 48.45it/s]Extracting features:  47%|████▋     | 289/618 [00:05<00:06, 47.08it/s]Extracting features:  48%|████▊     | 295/618 [00:05<00:06, 50.07it/s]Extracting features:  49%|████▊     | 301/618 [00:05<00:06, 51.36it/s]Extracting features:  50%|████▉     | 307/618 [00:05<00:06, 48.59it/s]Extracting features:  50%|█████     | 312/618 [00:05<00:07, 43.70it/s]Extracting features:  51%|█████▏    | 317/618 [00:06<00:06, 44.98it/s]Extracting features:  52%|█████▏    | 323/618 [00:06<00:06, 48.70it/s]Extracting features:  53%|█████▎    | 329/618 [00:06<00:05, 48.94it/s]Extracting features:  54%|█████▍    | 334/618 [00:06<00:05, 49.00it/s]Extracting features:  55%|█████▍    | 339/618 [00:06<00:06, 45.83it/s]Extracting features:  56%|█████▌    | 344/618 [00:06<00:05, 46.15it/s]Extracting features:  56%|█████▋    | 349/618 [00:06<00:06, 42.29it/s]Extracting features:  57%|█████▋    | 354/618 [00:06<00:06, 38.86it/s]Extracting features:  58%|█████▊    | 360/618 [00:07<00:05, 43.72it/s]Extracting features:  59%|█████▉    | 365/618 [00:07<00:06, 39.77it/s]Extracting features:  60%|█████▉    | 370/618 [00:07<00:05, 41.79it/s]Extracting features:  61%|██████    | 375/618 [00:07<00:05, 41.65it/s]Extracting features:  62%|██████▏   | 381/618 [00:07<00:05, 45.45it/s]Extracting features:  63%|██████▎   | 387/618 [00:07<00:04, 48.57it/s]Extracting features:  64%|██████▎   | 393/618 [00:07<00:04, 49.52it/s]Extracting features:  65%|██████▍   | 399/618 [00:07<00:04, 47.35it/s]Extracting features:  66%|██████▌   | 405/618 [00:07<00:04, 49.72it/s]Extracting features:  67%|██████▋   | 411/618 [00:08<00:03, 52.22it/s]Extracting features:  68%|██████▊   | 418/618 [00:08<00:03, 53.56it/s]Extracting features:  69%|██████▊   | 424/618 [00:08<00:03, 51.48it/s]Extracting features:  70%|██████▉   | 430/618 [00:08<00:03, 52.41it/s]Extracting features:  71%|███████   | 436/618 [00:08<00:03, 52.24it/s]Extracting features:  72%|███████▏  | 442/618 [00:08<00:03, 53.62it/s]Extracting features:  72%|███████▏  | 448/618 [00:08<00:03, 50.78it/s]Extracting features:  73%|███████▎  | 454/618 [00:08<00:03, 52.26it/s]Extracting features:  74%|███████▍  | 460/618 [00:09<00:03, 46.63it/s]Extracting features:  75%|███████▌  | 465/618 [00:09<00:03, 41.87it/s]Extracting features:  76%|███████▌  | 470/618 [00:09<00:03, 41.26it/s]Extracting features:  77%|███████▋  | 475/618 [00:09<00:03, 41.88it/s]Extracting features:  78%|███████▊  | 481/618 [00:09<00:03, 45.18it/s]Extracting features:  79%|███████▊  | 486/618 [00:09<00:02, 46.26it/s]Extracting features:  79%|███████▉  | 491/618 [00:09<00:02, 44.00it/s]Extracting features:  80%|████████  | 496/618 [00:09<00:02, 41.69it/s]Extracting features:  81%|████████  | 501/618 [00:10<00:02, 40.85it/s]Extracting features:  82%|████████▏ | 507/618 [00:10<00:02, 42.19it/s]Extracting features:  83%|████████▎ | 512/618 [00:10<00:02, 40.92it/s]Extracting features:  84%|████████▎ | 517/618 [00:10<00:02, 41.98it/s]Extracting features:  84%|████████▍ | 522/618 [00:10<00:02, 40.59it/s]Extracting features:  85%|████████▌ | 527/618 [00:10<00:02, 41.21it/s]Extracting features:  86%|████████▌ | 533/618 [00:10<00:01, 43.90it/s]Extracting features:  87%|████████▋ | 539/618 [00:10<00:01, 46.92it/s]Extracting features:  88%|████████▊ | 546/618 [00:11<00:01, 51.40it/s]Extracting features:  89%|████████▉ | 553/618 [00:11<00:01, 54.40it/s]Extracting features:  90%|█████████ | 559/618 [00:11<00:01, 54.87it/s]Extracting features:  91%|█████████▏| 565/618 [00:11<00:00, 54.60it/s]Extracting features:  92%|█████████▏| 571/618 [00:11<00:00, 48.93it/s]Extracting features:  93%|█████████▎| 577/618 [00:11<00:00, 51.04it/s]Extracting features:  94%|█████████▍| 584/618 [00:11<00:00, 55.07it/s]Extracting features:  95%|█████████▌| 590/618 [00:11<00:00, 46.86it/s]Extracting features:  96%|█████████▋| 595/618 [00:12<00:00, 46.37it/s]Extracting features:  97%|█████████▋| 600/618 [00:12<00:00, 44.46it/s]Extracting features:  98%|█████████▊| 605/618 [00:12<00:00, 41.51it/s]Extracting features:  99%|█████████▉| 611/618 [00:12<00:00, 44.25it/s]Extracting features: 100%|█████████▉| 616/618 [00:12<00:00, 44.06it/s]Extracting features: 100%|██████████| 618/618 [00:12<00:00, 48.74it/s]
2024-12-27 17:57:15,286 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 17:57:15,286 - INFO - Training feature extraction completed in 12.71s
2024-12-27 17:57:15,286 - INFO - Creating model for classifier: SVM
2024-12-27 17:57:15,287 - INFO - Using device: cuda
2024-12-27 17:57:15,287 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-27 17:57:15,287 - INFO - 
Processing poison rate: 0.0
2024-12-27 17:57:15,287 - INFO - Training set processing completed in 0.00s
2024-12-27 17:57:15,287 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 17:57:15,289 - INFO - Memory usage at start_fit: CPU 2791.2 MB, GPU 47.3 MB
2024-12-27 17:57:15,289 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:57:15,293 - INFO - Number of unique classes: 43
2024-12-27 17:57:15,712 - INFO - Fitted scaler and transformed data
2024-12-27 17:57:15,713 - INFO - Scaling time: 0.42s
2024-12-27 17:57:16,807 - INFO - Epoch 1/25, Train Loss: 5.3564, Val Loss: 2.1200
2024-12-27 17:57:17,820 - INFO - Epoch 2/25, Train Loss: 0.9795, Val Loss: 1.5683
2024-12-27 17:57:18,875 - INFO - Epoch 3/25, Train Loss: 0.5836, Val Loss: 1.3682
2024-12-27 17:57:19,904 - INFO - Epoch 4/25, Train Loss: 0.4444, Val Loss: 1.1627
2024-12-27 17:57:21,012 - INFO - Epoch 5/25, Train Loss: 0.3753, Val Loss: 1.1338
2024-12-27 17:57:22,161 - INFO - Epoch 6/25, Train Loss: 0.3371, Val Loss: 1.1990
2024-12-27 17:57:23,340 - INFO - Epoch 7/25, Train Loss: 0.3031, Val Loss: 1.3172
2024-12-27 17:57:23,341 - INFO - Early stopping triggered at epoch 7
2024-12-27 17:57:23,341 - INFO - Training completed in 8.05s
2024-12-27 17:57:23,341 - INFO - Final memory usage: CPU 2895.9 MB, GPU 48.4 MB
2024-12-27 17:57:23,342 - INFO - Model training completed in 8.05s
2024-12-27 17:57:23,373 - INFO - Prediction completed in 0.03s
2024-12-27 17:57:23,384 - INFO - Poison rate 0.0 completed in 8.10s
2024-12-27 17:57:23,385 - INFO - 
Processing poison rate: 0.01
2024-12-27 17:57:23,387 - INFO - Total number of labels flipped: 196
2024-12-27 17:57:23,387 - INFO - Label flipping completed in 0.00s
2024-12-27 17:57:23,388 - INFO - Training set processing completed in 0.00s
2024-12-27 17:57:23,388 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 17:57:23,388 - INFO - Memory usage at start_fit: CPU 2799.4 MB, GPU 48.1 MB
2024-12-27 17:57:23,388 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:57:23,390 - INFO - Number of unique classes: 43
2024-12-27 17:57:23,724 - INFO - Fitted scaler and transformed data
2024-12-27 17:57:23,724 - INFO - Scaling time: 0.33s
2024-12-27 17:57:24,845 - INFO - Epoch 1/25, Train Loss: 6.7338, Val Loss: 4.2887
2024-12-27 17:57:25,981 - INFO - Epoch 2/25, Train Loss: 1.4503, Val Loss: 3.0586
2024-12-27 17:57:27,058 - INFO - Epoch 3/25, Train Loss: 0.8570, Val Loss: 2.7767
2024-12-27 17:57:28,167 - INFO - Epoch 4/25, Train Loss: 0.6433, Val Loss: 2.7536
2024-12-27 17:57:29,376 - INFO - Epoch 5/25, Train Loss: 0.5163, Val Loss: 2.6089
2024-12-27 17:57:30,576 - INFO - Epoch 6/25, Train Loss: 0.4709, Val Loss: 2.5634
2024-12-27 17:57:31,908 - INFO - Epoch 7/25, Train Loss: 0.4284, Val Loss: 2.7416
2024-12-27 17:57:33,297 - INFO - Epoch 8/25, Train Loss: 0.3984, Val Loss: 2.7977
2024-12-27 17:57:33,298 - INFO - Early stopping triggered at epoch 8
2024-12-27 17:57:33,298 - INFO - Training completed in 9.91s
2024-12-27 17:57:33,299 - INFO - Final memory usage: CPU 2900.9 MB, GPU 48.4 MB
2024-12-27 17:57:33,301 - INFO - Model training completed in 9.91s
2024-12-27 17:57:33,332 - INFO - Prediction completed in 0.03s
2024-12-27 17:57:33,343 - INFO - Poison rate 0.01 completed in 9.96s
2024-12-27 17:57:33,344 - INFO - 
Processing poison rate: 0.03
2024-12-27 17:57:33,346 - INFO - Total number of labels flipped: 587
2024-12-27 17:57:33,346 - INFO - Label flipping completed in 0.00s
2024-12-27 17:57:33,346 - INFO - Training set processing completed in 0.00s
2024-12-27 17:57:33,346 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 17:57:33,347 - INFO - Memory usage at start_fit: CPU 2804.4 MB, GPU 48.1 MB
2024-12-27 17:57:33,347 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:57:33,348 - INFO - Number of unique classes: 43
2024-12-27 17:57:33,685 - INFO - Fitted scaler and transformed data
2024-12-27 17:57:33,685 - INFO - Scaling time: 0.33s
2024-12-27 17:57:34,935 - INFO - Epoch 1/25, Train Loss: 9.1572, Val Loss: 4.8515
2024-12-27 17:57:36,205 - INFO - Epoch 2/25, Train Loss: 2.4713, Val Loss: 4.0128
2024-12-27 17:57:37,472 - INFO - Epoch 3/25, Train Loss: 1.4875, Val Loss: 3.9387
2024-12-27 17:57:38,613 - INFO - Epoch 4/25, Train Loss: 1.0985, Val Loss: 3.8978
2024-12-27 17:57:39,807 - INFO - Epoch 5/25, Train Loss: 0.9350, Val Loss: 4.3549
2024-12-27 17:57:40,983 - INFO - Epoch 6/25, Train Loss: 0.7447, Val Loss: 3.8837
2024-12-27 17:57:42,087 - INFO - Epoch 7/25, Train Loss: 0.6971, Val Loss: 4.3207
2024-12-27 17:57:43,202 - INFO - Epoch 8/25, Train Loss: 0.7063, Val Loss: 4.4088
2024-12-27 17:57:43,202 - INFO - Early stopping triggered at epoch 8
2024-12-27 17:57:43,202 - INFO - Training completed in 9.86s
2024-12-27 17:57:43,202 - INFO - Final memory usage: CPU 2900.9 MB, GPU 48.4 MB
2024-12-27 17:57:43,203 - INFO - Model training completed in 9.86s
2024-12-27 17:57:43,231 - INFO - Prediction completed in 0.03s
2024-12-27 17:57:43,242 - INFO - Poison rate 0.03 completed in 9.90s
2024-12-27 17:57:43,242 - INFO - 
Processing poison rate: 0.05
2024-12-27 17:57:43,244 - INFO - Total number of labels flipped: 978
2024-12-27 17:57:43,244 - INFO - Label flipping completed in 0.00s
2024-12-27 17:57:43,244 - INFO - Training set processing completed in 0.00s
2024-12-27 17:57:43,244 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 17:57:43,245 - INFO - Memory usage at start_fit: CPU 2804.4 MB, GPU 48.1 MB
2024-12-27 17:57:43,245 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:57:43,246 - INFO - Number of unique classes: 43
2024-12-27 17:57:43,594 - INFO - Fitted scaler and transformed data
2024-12-27 17:57:43,595 - INFO - Scaling time: 0.35s
2024-12-27 17:57:44,751 - INFO - Epoch 1/25, Train Loss: 10.8575, Val Loss: 6.1552
2024-12-27 17:57:46,001 - INFO - Epoch 2/25, Train Loss: 3.5289, Val Loss: 5.0164
2024-12-27 17:57:47,157 - INFO - Epoch 3/25, Train Loss: 1.8563, Val Loss: 4.0597
2024-12-27 17:57:48,433 - INFO - Epoch 4/25, Train Loss: 1.4509, Val Loss: 3.9632
2024-12-27 17:57:49,758 - INFO - Epoch 5/25, Train Loss: 1.1419, Val Loss: 4.3040
2024-12-27 17:57:51,203 - INFO - Epoch 6/25, Train Loss: 1.0711, Val Loss: 3.6145
2024-12-27 17:57:52,647 - INFO - Epoch 7/25, Train Loss: 0.9517, Val Loss: 3.9996
2024-12-27 17:57:54,053 - INFO - Epoch 8/25, Train Loss: 0.8438, Val Loss: 3.9637
2024-12-27 17:57:54,054 - INFO - Early stopping triggered at epoch 8
2024-12-27 17:57:54,054 - INFO - Training completed in 10.81s
2024-12-27 17:57:54,054 - INFO - Final memory usage: CPU 2901.0 MB, GPU 48.4 MB
2024-12-27 17:57:54,055 - INFO - Model training completed in 10.81s
2024-12-27 17:57:54,089 - INFO - Prediction completed in 0.03s
2024-12-27 17:57:54,103 - INFO - Poison rate 0.05 completed in 10.86s
2024-12-27 17:57:54,104 - INFO - 
Processing poison rate: 0.07
2024-12-27 17:57:54,107 - INFO - Total number of labels flipped: 1377
2024-12-27 17:57:54,107 - INFO - Label flipping completed in 0.00s
2024-12-27 17:57:54,107 - INFO - Training set processing completed in 0.00s
2024-12-27 17:57:54,107 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 17:57:54,108 - INFO - Memory usage at start_fit: CPU 2804.5 MB, GPU 48.1 MB
2024-12-27 17:57:54,109 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:57:54,110 - INFO - Number of unique classes: 43
2024-12-27 17:57:54,547 - INFO - Fitted scaler and transformed data
2024-12-27 17:57:54,547 - INFO - Scaling time: 0.44s
2024-12-27 17:57:55,911 - INFO - Epoch 1/25, Train Loss: 12.8609, Val Loss: 7.7997
2024-12-27 17:57:57,235 - INFO - Epoch 2/25, Train Loss: 3.9116, Val Loss: 5.6546
2024-12-27 17:57:58,477 - INFO - Epoch 3/25, Train Loss: 2.2866, Val Loss: 5.4302
2024-12-27 17:57:59,704 - INFO - Epoch 4/25, Train Loss: 1.6399, Val Loss: 4.8352
2024-12-27 17:58:00,905 - INFO - Epoch 5/25, Train Loss: 1.2693, Val Loss: 4.1770
2024-12-27 17:58:02,072 - INFO - Epoch 6/25, Train Loss: 1.1597, Val Loss: 4.4390
2024-12-27 17:58:03,208 - INFO - Epoch 7/25, Train Loss: 1.0571, Val Loss: 4.2523
2024-12-27 17:58:03,208 - INFO - Early stopping triggered at epoch 7
2024-12-27 17:58:03,208 - INFO - Training completed in 9.10s
2024-12-27 17:58:03,209 - INFO - Final memory usage: CPU 2901.0 MB, GPU 48.4 MB
2024-12-27 17:58:03,209 - INFO - Model training completed in 9.10s
2024-12-27 17:58:03,243 - INFO - Prediction completed in 0.03s
2024-12-27 17:58:03,255 - INFO - Poison rate 0.07 completed in 9.15s
2024-12-27 17:58:03,255 - INFO - 
Processing poison rate: 0.1
2024-12-27 17:58:03,257 - INFO - Total number of labels flipped: 1954
2024-12-27 17:58:03,258 - INFO - Label flipping completed in 0.00s
2024-12-27 17:58:03,258 - INFO - Training set processing completed in 0.00s
2024-12-27 17:58:03,258 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 17:58:03,259 - INFO - Memory usage at start_fit: CPU 2804.6 MB, GPU 48.1 MB
2024-12-27 17:58:03,259 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:58:03,259 - INFO - Number of unique classes: 43
2024-12-27 17:58:03,625 - INFO - Fitted scaler and transformed data
2024-12-27 17:58:03,625 - INFO - Scaling time: 0.36s
2024-12-27 17:58:04,820 - INFO - Epoch 1/25, Train Loss: 14.6907, Val Loss: 8.5809
2024-12-27 17:58:06,092 - INFO - Epoch 2/25, Train Loss: 4.7138, Val Loss: 6.6591
2024-12-27 17:58:07,445 - INFO - Epoch 3/25, Train Loss: 2.8087, Val Loss: 5.0706
2024-12-27 17:58:08,781 - INFO - Epoch 4/25, Train Loss: 1.8469, Val Loss: 4.3374
2024-12-27 17:58:10,086 - INFO - Epoch 5/25, Train Loss: 1.5884, Val Loss: 4.4087
2024-12-27 17:58:11,303 - INFO - Epoch 6/25, Train Loss: 1.4002, Val Loss: 4.1467
2024-12-27 17:58:12,530 - INFO - Epoch 7/25, Train Loss: 1.2386, Val Loss: 3.8957
2024-12-27 17:58:13,845 - INFO - Epoch 8/25, Train Loss: 1.1756, Val Loss: 4.5090
2024-12-27 17:58:15,199 - INFO - Epoch 9/25, Train Loss: 1.1819, Val Loss: 4.1785
2024-12-27 17:58:15,199 - INFO - Early stopping triggered at epoch 9
2024-12-27 17:58:15,199 - INFO - Training completed in 11.94s
2024-12-27 17:58:15,199 - INFO - Final memory usage: CPU 2902.5 MB, GPU 48.4 MB
2024-12-27 17:58:15,200 - INFO - Model training completed in 11.94s
2024-12-27 17:58:15,233 - INFO - Prediction completed in 0.03s
2024-12-27 17:58:15,243 - INFO - Poison rate 0.1 completed in 11.99s
2024-12-27 17:58:15,243 - INFO - 
Processing poison rate: 0.2
2024-12-27 17:58:15,247 - INFO - Total number of labels flipped: 3929
2024-12-27 17:58:15,247 - INFO - Label flipping completed in 0.00s
2024-12-27 17:58:15,247 - INFO - Training set processing completed in 0.00s
2024-12-27 17:58:15,247 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 17:58:15,248 - INFO - Memory usage at start_fit: CPU 2806.1 MB, GPU 48.1 MB
2024-12-27 17:58:15,248 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:58:15,249 - INFO - Number of unique classes: 43
2024-12-27 17:58:15,596 - INFO - Fitted scaler and transformed data
2024-12-27 17:58:15,597 - INFO - Scaling time: 0.35s
2024-12-27 17:58:16,954 - INFO - Epoch 1/25, Train Loss: 19.3788, Val Loss: 12.1442
2024-12-27 17:58:18,212 - INFO - Epoch 2/25, Train Loss: 6.3100, Val Loss: 7.4619
2024-12-27 17:58:19,390 - INFO - Epoch 3/25, Train Loss: 3.3851, Val Loss: 5.5858
2024-12-27 17:58:20,602 - INFO - Epoch 4/25, Train Loss: 2.4956, Val Loss: 4.8945
2024-12-27 17:58:21,971 - INFO - Epoch 5/25, Train Loss: 2.0924, Val Loss: 4.8291
2024-12-27 17:58:23,132 - INFO - Epoch 6/25, Train Loss: 1.9488, Val Loss: 4.8312
2024-12-27 17:58:24,356 - INFO - Epoch 7/25, Train Loss: 1.6953, Val Loss: 4.4246
2024-12-27 17:58:25,519 - INFO - Epoch 8/25, Train Loss: 1.5708, Val Loss: 4.6418
2024-12-27 17:58:26,633 - INFO - Epoch 9/25, Train Loss: 1.4844, Val Loss: 4.5916
2024-12-27 17:58:26,634 - INFO - Early stopping triggered at epoch 9
2024-12-27 17:58:26,634 - INFO - Training completed in 11.39s
2024-12-27 17:58:26,634 - INFO - Final memory usage: CPU 2904.8 MB, GPU 48.4 MB
2024-12-27 17:58:26,635 - INFO - Model training completed in 11.39s
2024-12-27 17:58:26,662 - INFO - Prediction completed in 0.03s
2024-12-27 17:58:26,674 - INFO - Poison rate 0.2 completed in 11.43s
2024-12-27 17:58:26,676 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 17:58:26,676 - INFO - Total evaluation time: 104.90s
2024-12-27 17:58:26,685 - INFO - 
Progress: 10.4% - Evaluating GTSRB with SVM (dynadetect mode, iteration 1/1)
2024-12-27 17:58:26,749 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 17:58:27,125 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 17:58:27,193 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 17:58:27,193 - INFO - Dataset type: image
2024-12-27 17:58:27,193 - INFO - Sample size: 39209
2024-12-27 17:58:27,193 - INFO - Using device: cuda
2024-12-27 17:58:27,193 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 17:58:27,196 - INFO - Loading datasets...
2024-12-27 17:58:44,399 - INFO - Dataset loading completed in 17.20s
2024-12-27 17:58:44,399 - INFO - Extracting validation features...
2024-12-27 17:58:44,399 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:28,  4.78it/s]Extracting features:   3%|▎         | 4/139 [00:00<00:10, 12.60it/s]Extracting features:   7%|▋         | 10/139 [00:00<00:04, 26.74it/s]Extracting features:  12%|█▏        | 17/139 [00:00<00:03, 37.54it/s]Extracting features:  16%|█▌        | 22/139 [00:00<00:02, 40.89it/s]Extracting features:  19%|█▉        | 27/139 [00:00<00:02, 42.88it/s]Extracting features:  24%|██▍       | 34/139 [00:00<00:02, 48.82it/s]Extracting features:  29%|██▉       | 40/139 [00:01<00:01, 49.59it/s]Extracting features:  33%|███▎      | 46/139 [00:01<00:01, 49.90it/s]Extracting features:  37%|███▋      | 52/139 [00:01<00:01, 46.76it/s]Extracting features:  41%|████      | 57/139 [00:01<00:01, 46.32it/s]Extracting features:  45%|████▌     | 63/139 [00:01<00:01, 48.71it/s]Extracting features:  49%|████▉     | 68/139 [00:01<00:01, 47.41it/s]Extracting features:  53%|█████▎    | 74/139 [00:01<00:01, 50.34it/s]Extracting features:  58%|█████▊    | 80/139 [00:01<00:01, 49.32it/s]Extracting features:  62%|██████▏   | 86/139 [00:01<00:01, 52.08it/s]Extracting features:  67%|██████▋   | 93/139 [00:02<00:00, 54.72it/s]Extracting features:  71%|███████   | 99/139 [00:02<00:00, 55.92it/s]Extracting features:  76%|███████▌  | 105/139 [00:02<00:00, 55.92it/s]Extracting features:  80%|███████▉  | 111/139 [00:02<00:00, 53.94it/s]Extracting features:  84%|████████▍ | 117/139 [00:02<00:00, 51.90it/s]Extracting features:  88%|████████▊ | 123/139 [00:02<00:00, 51.53it/s]Extracting features:  93%|█████████▎| 129/139 [00:02<00:00, 52.23it/s]Extracting features:  97%|█████████▋| 135/139 [00:02<00:00, 50.84it/s]Extracting features: 100%|██████████| 139/139 [00:03<00:00, 46.10it/s]
2024-12-27 17:58:47,427 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 17:58:47,427 - INFO - Validation feature extraction completed in 3.03s
2024-12-27 17:58:47,427 - INFO - Extracting training features...
2024-12-27 17:58:47,427 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<02:13,  4.63it/s]Extracting features:   1%|          | 7/618 [00:00<00:25, 24.32it/s]Extracting features:   2%|▏         | 12/618 [00:00<00:19, 31.17it/s]Extracting features:   3%|▎         | 17/618 [00:00<00:17, 34.42it/s]Extracting features:   4%|▎         | 22/618 [00:00<00:15, 38.29it/s]Extracting features:   4%|▍         | 27/618 [00:00<00:15, 36.97it/s]Extracting features:   5%|▌         | 32/618 [00:00<00:15, 38.84it/s]Extracting features:   6%|▌         | 37/618 [00:01<00:15, 38.13it/s]Extracting features:   7%|▋         | 42/618 [00:01<00:14, 40.87it/s]Extracting features:   8%|▊         | 47/618 [00:01<00:14, 40.04it/s]Extracting features:   8%|▊         | 52/618 [00:01<00:15, 37.52it/s]Extracting features:   9%|▉         | 57/618 [00:01<00:14, 38.74it/s]Extracting features:  10%|█         | 62/618 [00:01<00:13, 39.81it/s]Extracting features:  11%|█         | 67/618 [00:01<00:13, 41.96it/s]Extracting features:  12%|█▏        | 72/618 [00:01<00:12, 43.86it/s]Extracting features:  12%|█▏        | 77/618 [00:02<00:11, 45.46it/s]Extracting features:  13%|█▎        | 83/618 [00:02<00:11, 48.10it/s]Extracting features:  14%|█▍        | 89/618 [00:02<00:10, 49.70it/s]Extracting features:  15%|█▌        | 95/618 [00:02<00:10, 51.07it/s]Extracting features:  16%|█▋        | 101/618 [00:02<00:09, 51.88it/s]Extracting features:  17%|█▋        | 108/618 [00:02<00:09, 56.25it/s]Extracting features:  19%|█▊        | 115/618 [00:02<00:08, 59.55it/s]Extracting features:  20%|█▉        | 121/618 [00:02<00:08, 58.92it/s]Extracting features:  21%|██        | 127/618 [00:02<00:08, 59.19it/s]Extracting features:  22%|██▏       | 134/618 [00:02<00:08, 59.79it/s]Extracting features:  23%|██▎       | 140/618 [00:03<00:08, 55.33it/s]Extracting features:  24%|██▎       | 146/618 [00:03<00:09, 48.02it/s]Extracting features:  25%|██▍       | 152/618 [00:03<00:10, 44.50it/s]Extracting features:  25%|██▌       | 157/618 [00:03<00:11, 41.05it/s]Extracting features:  26%|██▌       | 162/618 [00:03<00:11, 38.53it/s]Extracting features:  27%|██▋       | 166/618 [00:03<00:12, 36.40it/s]Extracting features:  28%|██▊       | 170/618 [00:04<00:13, 34.46it/s]Extracting features:  28%|██▊       | 174/618 [00:04<00:13, 33.68it/s]Extracting features:  29%|██▉       | 178/618 [00:04<00:13, 32.89it/s]Extracting features:  29%|██▉       | 182/618 [00:04<00:12, 34.09it/s]Extracting features:  30%|███       | 186/618 [00:04<00:12, 33.97it/s]Extracting features:  31%|███       | 191/618 [00:04<00:11, 37.92it/s]Extracting features:  32%|███▏      | 195/618 [00:04<00:11, 37.23it/s]Extracting features:  32%|███▏      | 200/618 [00:04<00:10, 39.16it/s]Extracting features:  33%|███▎      | 204/618 [00:04<00:10, 38.28it/s]Extracting features:  34%|███▎      | 208/618 [00:05<00:11, 36.39it/s]Extracting features:  34%|███▍      | 213/618 [00:05<00:10, 38.35it/s]Extracting features:  35%|███▌      | 218/618 [00:05<00:10, 38.57it/s]Extracting features:  36%|███▌      | 222/618 [00:05<00:10, 37.15it/s]Extracting features:  37%|███▋      | 227/618 [00:05<00:10, 39.02it/s]Extracting features:  37%|███▋      | 231/618 [00:05<00:09, 38.80it/s]Extracting features:  38%|███▊      | 235/618 [00:05<00:09, 38.70it/s]Extracting features:  39%|███▊      | 239/618 [00:05<00:10, 36.96it/s]Extracting features:  39%|███▉      | 243/618 [00:05<00:10, 35.18it/s]Extracting features:  40%|███▉      | 247/618 [00:06<00:10, 34.25it/s]Extracting features:  41%|████      | 251/618 [00:06<00:10, 35.20it/s]Extracting features:  41%|████▏     | 255/618 [00:06<00:10, 34.99it/s]Extracting features:  42%|████▏     | 259/618 [00:06<00:10, 35.12it/s]Extracting features:  43%|████▎     | 263/618 [00:06<00:10, 34.30it/s]Extracting features:  43%|████▎     | 268/618 [00:06<00:09, 36.29it/s]Extracting features:  44%|████▍     | 272/618 [00:06<00:09, 35.66it/s]Extracting features:  45%|████▍     | 276/618 [00:06<00:09, 34.73it/s]Extracting features:  45%|████▌     | 280/618 [00:07<00:09, 33.88it/s]Extracting features:  46%|████▌     | 284/618 [00:07<00:09, 33.69it/s]Extracting features:  47%|████▋     | 288/618 [00:07<00:09, 33.64it/s]Extracting features:  47%|████▋     | 292/618 [00:07<00:09, 33.14it/s]Extracting features:  48%|████▊     | 296/618 [00:07<00:09, 32.96it/s]Extracting features:  49%|████▊     | 300/618 [00:07<00:09, 32.81it/s]Extracting features:  49%|████▉     | 304/618 [00:07<00:09, 34.36it/s]Extracting features:  50%|████▉     | 308/618 [00:07<00:09, 33.35it/s]Extracting features:  50%|█████     | 312/618 [00:08<00:09, 32.08it/s]Extracting features:  51%|█████     | 316/618 [00:08<00:10, 29.20it/s]Extracting features:  52%|█████▏    | 320/618 [00:08<00:09, 30.47it/s]Extracting features:  52%|█████▏    | 324/618 [00:08<00:08, 32.78it/s]Extracting features:  53%|█████▎    | 328/618 [00:08<00:08, 34.47it/s]Extracting features:  54%|█████▎    | 332/618 [00:08<00:08, 34.98it/s]Extracting features:  54%|█████▍    | 336/618 [00:08<00:08, 34.50it/s]Extracting features:  55%|█████▌    | 340/618 [00:08<00:08, 33.39it/s]Extracting features:  56%|█████▌    | 344/618 [00:08<00:08, 34.10it/s]Extracting features:  56%|█████▋    | 348/618 [00:09<00:07, 35.48it/s]Extracting features:  57%|█████▋    | 352/618 [00:09<00:08, 32.98it/s]Extracting features:  58%|█████▊    | 356/618 [00:09<00:07, 32.89it/s]Extracting features:  58%|█████▊    | 360/618 [00:09<00:07, 32.81it/s]Extracting features:  59%|█████▉    | 364/618 [00:09<00:07, 32.47it/s]Extracting features:  60%|█████▉    | 368/618 [00:09<00:07, 33.36it/s]Extracting features:  60%|██████    | 372/618 [00:09<00:07, 34.45it/s]Extracting features:  61%|██████    | 376/618 [00:09<00:06, 35.66it/s]Extracting features:  62%|██████▏   | 381/618 [00:10<00:06, 36.83it/s]Extracting features:  62%|██████▏   | 385/618 [00:10<00:06, 36.71it/s]Extracting features:  63%|██████▎   | 389/618 [00:10<00:06, 36.75it/s]Extracting features:  64%|██████▎   | 393/618 [00:10<00:06, 35.85it/s]Extracting features:  64%|██████▍   | 397/618 [00:10<00:06, 35.80it/s]Extracting features:  65%|██████▌   | 402/618 [00:10<00:05, 37.56it/s]Extracting features:  66%|██████▌   | 407/618 [00:10<00:05, 38.34it/s]Extracting features:  67%|██████▋   | 413/618 [00:10<00:04, 42.16it/s]Extracting features:  68%|██████▊   | 418/618 [00:11<00:05, 39.23it/s]Extracting features:  68%|██████▊   | 422/618 [00:11<00:05, 38.27it/s]Extracting features:  69%|██████▉   | 426/618 [00:11<00:05, 37.95it/s]Extracting features:  70%|██████▉   | 431/618 [00:11<00:04, 39.35it/s]Extracting features:  70%|███████   | 435/618 [00:11<00:04, 37.67it/s]Extracting features:  71%|███████   | 439/618 [00:11<00:05, 35.23it/s]Extracting features:  72%|███████▏  | 443/618 [00:11<00:04, 36.46it/s]Extracting features:  72%|███████▏  | 447/618 [00:11<00:04, 36.11it/s]Extracting features:  73%|███████▎  | 451/618 [00:11<00:04, 36.22it/s]Extracting features:  74%|███████▎  | 455/618 [00:12<00:04, 34.92it/s]Extracting features:  74%|███████▍  | 459/618 [00:12<00:04, 35.44it/s]Extracting features:  75%|███████▍  | 463/618 [00:12<00:04, 34.35it/s]Extracting features:  76%|███████▌  | 467/618 [00:12<00:04, 34.76it/s]Extracting features:  76%|███████▌  | 471/618 [00:12<00:04, 35.31it/s]Extracting features:  77%|███████▋  | 475/618 [00:12<00:03, 35.99it/s]Extracting features:  78%|███████▊  | 480/618 [00:12<00:03, 36.51it/s]Extracting features:  78%|███████▊  | 484/618 [00:12<00:03, 37.41it/s]Extracting features:  79%|███████▉  | 488/618 [00:12<00:03, 38.00it/s]Extracting features:  80%|███████▉  | 492/618 [00:13<00:03, 36.65it/s]Extracting features:  80%|████████  | 496/618 [00:13<00:03, 36.22it/s]Extracting features:  81%|████████  | 501/618 [00:13<00:03, 38.72it/s]Extracting features:  82%|████████▏ | 506/618 [00:13<00:02, 40.03it/s]Extracting features:  83%|████████▎ | 512/618 [00:13<00:02, 44.88it/s]Extracting features:  84%|████████▍ | 518/618 [00:13<00:02, 45.39it/s]Extracting features:  85%|████████▍ | 523/618 [00:13<00:02, 43.58it/s]Extracting features:  85%|████████▌ | 528/618 [00:13<00:02, 39.97it/s]Extracting features:  86%|████████▌ | 533/618 [00:14<00:02, 37.08it/s]Extracting features:  87%|████████▋ | 538/618 [00:14<00:02, 37.35it/s]Extracting features:  88%|████████▊ | 543/618 [00:14<00:01, 38.10it/s]Extracting features:  89%|████████▊ | 547/618 [00:14<00:01, 37.67it/s]Extracting features:  89%|████████▉ | 551/618 [00:14<00:01, 37.75it/s]Extracting features:  90%|████████▉ | 555/618 [00:14<00:01, 38.28it/s]Extracting features:  91%|█████████ | 560/618 [00:14<00:01, 40.16it/s]Extracting features:  91%|█████████▏| 565/618 [00:14<00:01, 40.35it/s]Extracting features:  92%|█████████▏| 570/618 [00:15<00:01, 38.92it/s]Extracting features:  93%|█████████▎| 574/618 [00:15<00:01, 38.06it/s]Extracting features:  94%|█████████▎| 579/618 [00:15<00:01, 36.33it/s]Extracting features:  94%|█████████▍| 583/618 [00:15<00:00, 36.89it/s]Extracting features:  95%|█████████▌| 588/618 [00:15<00:00, 37.91it/s]Extracting features:  96%|█████████▌| 592/618 [00:15<00:00, 36.87it/s]Extracting features:  97%|█████████▋| 597/618 [00:15<00:00, 38.42it/s]Extracting features:  97%|█████████▋| 601/618 [00:15<00:00, 37.35it/s]Extracting features:  98%|█████████▊| 605/618 [00:15<00:00, 36.62it/s]Extracting features:  99%|█████████▊| 609/618 [00:16<00:00, 37.09it/s]Extracting features:  99%|█████████▉| 614/618 [00:16<00:00, 39.26it/s]Extracting features: 100%|██████████| 618/618 [00:16<00:00, 34.81it/s]Extracting features: 100%|██████████| 618/618 [00:16<00:00, 37.67it/s]
2024-12-27 17:59:03,867 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 17:59:03,868 - INFO - Training feature extraction completed in 16.44s
2024-12-27 17:59:03,868 - INFO - Creating model for classifier: SVM
2024-12-27 17:59:03,868 - INFO - Using device: cuda
2024-12-27 17:59:03,868 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-27 17:59:03,868 - INFO - 
Processing poison rate: 0.0
2024-12-27 17:59:03,869 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:59:03,869 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:59:05,791 - INFO - Feature scaling completed in 1.92s
2024-12-27 17:59:05,791 - INFO - Starting feature selection (k=50)
2024-12-27 17:59:05,817 - INFO - Feature selection completed in 0.03s. Output shape: (19755, 50)
2024-12-27 17:59:05,817 - INFO - Starting anomaly detection
2024-12-27 17:59:13,426 - INFO - Anomaly detection completed in 7.61s
2024-12-27 17:59:13,426 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:59:13,426 - INFO - Total fit_transform time: 9.56s
2024-12-27 17:59:13,426 - INFO - Training set processing completed in 9.56s
2024-12-27 17:59:13,427 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 17:59:13,428 - INFO - Memory usage at start_fit: CPU 2811.1 MB, GPU 47.3 MB
2024-12-27 17:59:13,429 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:59:13,433 - INFO - Number of unique classes: 43
2024-12-27 17:59:13,784 - INFO - Fitted scaler and transformed data
2024-12-27 17:59:13,784 - INFO - Scaling time: 0.35s
2024-12-27 17:59:15,024 - INFO - Epoch 1/25, Train Loss: 5.0302, Val Loss: 2.2992
2024-12-27 17:59:16,256 - INFO - Epoch 2/25, Train Loss: 0.8941, Val Loss: 1.6067
2024-12-27 17:59:17,510 - INFO - Epoch 3/25, Train Loss: 0.5687, Val Loss: 1.5108
2024-12-27 17:59:18,708 - INFO - Epoch 4/25, Train Loss: 0.4301, Val Loss: 1.4809
2024-12-27 17:59:19,949 - INFO - Epoch 5/25, Train Loss: 0.4001, Val Loss: 1.4389
2024-12-27 17:59:21,156 - INFO - Epoch 6/25, Train Loss: 0.3452, Val Loss: 1.5612
2024-12-27 17:59:22,343 - INFO - Epoch 7/25, Train Loss: 0.3006, Val Loss: 1.4023
2024-12-27 17:59:23,511 - INFO - Epoch 8/25, Train Loss: 0.2654, Val Loss: 1.4390
2024-12-27 17:59:24,677 - INFO - Epoch 9/25, Train Loss: 0.3034, Val Loss: 1.6436
2024-12-27 17:59:24,677 - INFO - Early stopping triggered at epoch 9
2024-12-27 17:59:24,678 - INFO - Training completed in 11.25s
2024-12-27 17:59:24,678 - INFO - Final memory usage: CPU 2921.4 MB, GPU 48.4 MB
2024-12-27 17:59:24,679 - INFO - Model training completed in 11.25s
2024-12-27 17:59:24,710 - INFO - Prediction completed in 0.03s
2024-12-27 17:59:24,722 - INFO - Poison rate 0.0 completed in 20.85s
2024-12-27 17:59:24,722 - INFO - 
Processing poison rate: 0.01
2024-12-27 17:59:24,724 - INFO - Total number of labels flipped: 195
2024-12-27 17:59:24,724 - INFO - Label flipping completed in 0.00s
2024-12-27 17:59:24,724 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:59:24,724 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:59:26,663 - INFO - Feature scaling completed in 1.94s
2024-12-27 17:59:26,663 - INFO - Starting feature selection (k=50)
2024-12-27 17:59:26,714 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 17:59:26,714 - INFO - Starting anomaly detection
2024-12-27 17:59:34,829 - INFO - Anomaly detection completed in 8.11s
2024-12-27 17:59:34,829 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:59:34,829 - INFO - Total fit_transform time: 10.11s
2024-12-27 17:59:34,830 - INFO - Training set processing completed in 10.11s
2024-12-27 17:59:34,830 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 17:59:34,831 - INFO - Memory usage at start_fit: CPU 2831.7 MB, GPU 48.1 MB
2024-12-27 17:59:34,832 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:59:34,836 - INFO - Number of unique classes: 43
2024-12-27 17:59:35,162 - INFO - Fitted scaler and transformed data
2024-12-27 17:59:35,162 - INFO - Scaling time: 0.32s
2024-12-27 17:59:36,210 - INFO - Epoch 1/25, Train Loss: 6.4262, Val Loss: 3.5840
2024-12-27 17:59:37,297 - INFO - Epoch 2/25, Train Loss: 1.3598, Val Loss: 3.0134
2024-12-27 17:59:38,390 - INFO - Epoch 3/25, Train Loss: 0.7498, Val Loss: 2.7987
2024-12-27 17:59:39,522 - INFO - Epoch 4/25, Train Loss: 0.6115, Val Loss: 2.6483
2024-12-27 17:59:40,557 - INFO - Epoch 5/25, Train Loss: 0.4877, Val Loss: 2.6297
2024-12-27 17:59:41,670 - INFO - Epoch 6/25, Train Loss: 0.4605, Val Loss: 2.9619
2024-12-27 17:59:42,736 - INFO - Epoch 7/25, Train Loss: 0.4172, Val Loss: 2.7999
2024-12-27 17:59:42,737 - INFO - Early stopping triggered at epoch 7
2024-12-27 17:59:42,737 - INFO - Training completed in 7.91s
2024-12-27 17:59:42,737 - INFO - Final memory usage: CPU 2934.0 MB, GPU 48.4 MB
2024-12-27 17:59:42,738 - INFO - Model training completed in 7.91s
2024-12-27 17:59:42,769 - INFO - Prediction completed in 0.03s
2024-12-27 17:59:42,780 - INFO - Poison rate 0.01 completed in 18.06s
2024-12-27 17:59:42,780 - INFO - 
Processing poison rate: 0.03
2024-12-27 17:59:42,782 - INFO - Total number of labels flipped: 589
2024-12-27 17:59:42,782 - INFO - Label flipping completed in 0.00s
2024-12-27 17:59:42,782 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 17:59:42,782 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 17:59:44,563 - INFO - Feature scaling completed in 1.78s
2024-12-27 17:59:44,563 - INFO - Starting feature selection (k=50)
2024-12-27 17:59:44,614 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 17:59:44,614 - INFO - Starting anomaly detection
2024-12-27 17:59:52,496 - INFO - Anomaly detection completed in 7.88s
2024-12-27 17:59:52,496 - INFO - Found 1976 outliers (10.0%)
2024-12-27 17:59:52,496 - INFO - Total fit_transform time: 9.71s
2024-12-27 17:59:52,496 - INFO - Training set processing completed in 9.71s
2024-12-27 17:59:52,497 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 17:59:52,498 - INFO - Memory usage at start_fit: CPU 2837.6 MB, GPU 48.1 MB
2024-12-27 17:59:52,498 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 17:59:52,499 - INFO - Number of unique classes: 43
2024-12-27 17:59:52,856 - INFO - Fitted scaler and transformed data
2024-12-27 17:59:52,856 - INFO - Scaling time: 0.36s
2024-12-27 17:59:53,987 - INFO - Epoch 1/25, Train Loss: 8.8225, Val Loss: 6.5180
2024-12-27 17:59:55,102 - INFO - Epoch 2/25, Train Loss: 2.3843, Val Loss: 4.3684
2024-12-27 17:59:56,149 - INFO - Epoch 3/25, Train Loss: 1.3101, Val Loss: 3.9578
2024-12-27 17:59:57,207 - INFO - Epoch 4/25, Train Loss: 0.9609, Val Loss: 3.6958
2024-12-27 17:59:58,396 - INFO - Epoch 5/25, Train Loss: 0.8248, Val Loss: 3.6450
2024-12-27 17:59:59,684 - INFO - Epoch 6/25, Train Loss: 0.7223, Val Loss: 3.8711
2024-12-27 18:00:01,015 - INFO - Epoch 7/25, Train Loss: 0.7090, Val Loss: 3.7684
2024-12-27 18:00:01,015 - INFO - Early stopping triggered at epoch 7
2024-12-27 18:00:01,015 - INFO - Training completed in 8.52s
2024-12-27 18:00:01,015 - INFO - Final memory usage: CPU 2935.5 MB, GPU 48.4 MB
2024-12-27 18:00:01,016 - INFO - Model training completed in 8.52s
2024-12-27 18:00:01,048 - INFO - Prediction completed in 0.03s
2024-12-27 18:00:01,068 - INFO - Poison rate 0.03 completed in 18.29s
2024-12-27 18:00:01,069 - INFO - 
Processing poison rate: 0.05
2024-12-27 18:00:01,074 - INFO - Total number of labels flipped: 979
2024-12-27 18:00:01,074 - INFO - Label flipping completed in 0.01s
2024-12-27 18:00:01,074 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:00:01,074 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:00:02,955 - INFO - Feature scaling completed in 1.88s
2024-12-27 18:00:02,955 - INFO - Starting feature selection (k=50)
2024-12-27 18:00:03,006 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 18:00:03,006 - INFO - Starting anomaly detection
2024-12-27 18:00:10,583 - INFO - Anomaly detection completed in 7.58s
2024-12-27 18:00:10,583 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:00:10,583 - INFO - Total fit_transform time: 9.51s
2024-12-27 18:00:10,584 - INFO - Training set processing completed in 9.51s
2024-12-27 18:00:10,584 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 18:00:10,584 - INFO - Memory usage at start_fit: CPU 2842.5 MB, GPU 48.1 MB
2024-12-27 18:00:10,585 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:00:10,586 - INFO - Number of unique classes: 43
2024-12-27 18:00:10,943 - INFO - Fitted scaler and transformed data
2024-12-27 18:00:10,943 - INFO - Scaling time: 0.36s
2024-12-27 18:00:12,145 - INFO - Epoch 1/25, Train Loss: 10.4135, Val Loss: 5.6528
2024-12-27 18:00:13,332 - INFO - Epoch 2/25, Train Loss: 3.2517, Val Loss: 4.7653
2024-12-27 18:00:14,418 - INFO - Epoch 3/25, Train Loss: 1.8466, Val Loss: 3.9870
2024-12-27 18:00:15,728 - INFO - Epoch 4/25, Train Loss: 1.3498, Val Loss: 4.1289
2024-12-27 18:00:16,915 - INFO - Epoch 5/25, Train Loss: 1.0139, Val Loss: 3.2619
2024-12-27 18:00:18,120 - INFO - Epoch 6/25, Train Loss: 0.9819, Val Loss: 3.8101
2024-12-27 18:00:19,278 - INFO - Epoch 7/25, Train Loss: 0.8859, Val Loss: 3.5675
2024-12-27 18:00:19,278 - INFO - Early stopping triggered at epoch 7
2024-12-27 18:00:19,278 - INFO - Training completed in 8.69s
2024-12-27 18:00:19,278 - INFO - Final memory usage: CPU 2941.1 MB, GPU 48.4 MB
2024-12-27 18:00:19,279 - INFO - Model training completed in 8.70s
2024-12-27 18:00:19,310 - INFO - Prediction completed in 0.03s
2024-12-27 18:00:19,321 - INFO - Poison rate 0.05 completed in 18.25s
2024-12-27 18:00:19,322 - INFO - 
Processing poison rate: 0.07
2024-12-27 18:00:19,324 - INFO - Total number of labels flipped: 1375
2024-12-27 18:00:19,324 - INFO - Label flipping completed in 0.00s
2024-12-27 18:00:19,324 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:00:19,324 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:00:21,151 - INFO - Feature scaling completed in 1.83s
2024-12-27 18:00:21,152 - INFO - Starting feature selection (k=50)
2024-12-27 18:00:21,202 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 18:00:21,203 - INFO - Starting anomaly detection
2024-12-27 18:00:28,720 - INFO - Anomaly detection completed in 7.52s
2024-12-27 18:00:28,720 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:00:28,720 - INFO - Total fit_transform time: 9.40s
2024-12-27 18:00:28,720 - INFO - Training set processing completed in 9.40s
2024-12-27 18:00:28,720 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 18:00:28,721 - INFO - Memory usage at start_fit: CPU 2847.8 MB, GPU 48.1 MB
2024-12-27 18:00:28,721 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:00:28,722 - INFO - Number of unique classes: 43
2024-12-27 18:00:29,090 - INFO - Fitted scaler and transformed data
2024-12-27 18:00:29,091 - INFO - Scaling time: 0.37s
2024-12-27 18:00:30,078 - INFO - Epoch 1/25, Train Loss: 11.8011, Val Loss: 6.5397
2024-12-27 18:00:31,118 - INFO - Epoch 2/25, Train Loss: 3.9097, Val Loss: 5.5389
2024-12-27 18:00:32,161 - INFO - Epoch 3/25, Train Loss: 2.0612, Val Loss: 4.7166
2024-12-27 18:00:33,191 - INFO - Epoch 4/25, Train Loss: 1.5264, Val Loss: 4.2564
2024-12-27 18:00:34,213 - INFO - Epoch 5/25, Train Loss: 1.2081, Val Loss: 4.6070
2024-12-27 18:00:35,236 - INFO - Epoch 6/25, Train Loss: 1.1631, Val Loss: 4.4579
2024-12-27 18:00:35,236 - INFO - Early stopping triggered at epoch 6
2024-12-27 18:00:35,237 - INFO - Training completed in 6.52s
2024-12-27 18:00:35,237 - INFO - Final memory usage: CPU 2944.8 MB, GPU 48.4 MB
2024-12-27 18:00:35,237 - INFO - Model training completed in 6.52s
2024-12-27 18:00:35,267 - INFO - Prediction completed in 0.03s
2024-12-27 18:00:35,279 - INFO - Poison rate 0.07 completed in 15.96s
2024-12-27 18:00:35,279 - INFO - 
Processing poison rate: 0.1
2024-12-27 18:00:35,282 - INFO - Total number of labels flipped: 1962
2024-12-27 18:00:35,282 - INFO - Label flipping completed in 0.00s
2024-12-27 18:00:35,282 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:00:35,282 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:00:37,091 - INFO - Feature scaling completed in 1.81s
2024-12-27 18:00:37,092 - INFO - Starting feature selection (k=50)
2024-12-27 18:00:37,142 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 18:00:37,142 - INFO - Starting anomaly detection
2024-12-27 18:00:45,173 - INFO - Anomaly detection completed in 8.03s
2024-12-27 18:00:45,173 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:00:45,173 - INFO - Total fit_transform time: 9.89s
2024-12-27 18:00:45,173 - INFO - Training set processing completed in 9.89s
2024-12-27 18:00:45,174 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 18:00:45,174 - INFO - Memory usage at start_fit: CPU 2848.7 MB, GPU 48.1 MB
2024-12-27 18:00:45,175 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:00:45,176 - INFO - Number of unique classes: 43
2024-12-27 18:00:45,510 - INFO - Fitted scaler and transformed data
2024-12-27 18:00:45,511 - INFO - Scaling time: 0.33s
2024-12-27 18:00:46,671 - INFO - Epoch 1/25, Train Loss: 13.6687, Val Loss: 9.1472
2024-12-27 18:00:47,705 - INFO - Epoch 2/25, Train Loss: 4.4132, Val Loss: 4.9228
2024-12-27 18:00:48,747 - INFO - Epoch 3/25, Train Loss: 2.4668, Val Loss: 4.2846
2024-12-27 18:00:49,763 - INFO - Epoch 4/25, Train Loss: 1.7249, Val Loss: 4.3664
2024-12-27 18:00:50,808 - INFO - Epoch 5/25, Train Loss: 1.5907, Val Loss: 4.0461
2024-12-27 18:00:51,824 - INFO - Epoch 6/25, Train Loss: 1.3654, Val Loss: 3.9900
2024-12-27 18:00:52,927 - INFO - Epoch 7/25, Train Loss: 1.2563, Val Loss: 4.1329
2024-12-27 18:00:54,180 - INFO - Epoch 8/25, Train Loss: 1.0772, Val Loss: 3.8634
2024-12-27 18:00:55,392 - INFO - Epoch 9/25, Train Loss: 1.1018, Val Loss: 4.1581
2024-12-27 18:00:56,518 - INFO - Epoch 10/25, Train Loss: 1.0759, Val Loss: 4.5586
2024-12-27 18:00:56,518 - INFO - Early stopping triggered at epoch 10
2024-12-27 18:00:56,518 - INFO - Training completed in 11.34s
2024-12-27 18:00:56,519 - INFO - Final memory usage: CPU 2946.8 MB, GPU 48.4 MB
2024-12-27 18:00:56,519 - INFO - Model training completed in 11.35s
2024-12-27 18:00:56,550 - INFO - Prediction completed in 0.03s
2024-12-27 18:00:56,561 - INFO - Poison rate 0.1 completed in 21.28s
2024-12-27 18:00:56,562 - INFO - 
Processing poison rate: 0.2
2024-12-27 18:00:56,565 - INFO - Total number of labels flipped: 3931
2024-12-27 18:00:56,565 - INFO - Label flipping completed in 0.00s
2024-12-27 18:00:56,565 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:00:56,565 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:00:58,377 - INFO - Feature scaling completed in 1.81s
2024-12-27 18:00:58,377 - INFO - Starting feature selection (k=50)
2024-12-27 18:00:58,428 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 18:00:58,428 - INFO - Starting anomaly detection
2024-12-27 18:01:06,627 - INFO - Anomaly detection completed in 8.20s
2024-12-27 18:01:06,627 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:01:06,628 - INFO - Total fit_transform time: 10.06s
2024-12-27 18:01:06,628 - INFO - Training set processing completed in 10.06s
2024-12-27 18:01:06,628 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 18:01:06,629 - INFO - Memory usage at start_fit: CPU 2853.3 MB, GPU 48.1 MB
2024-12-27 18:01:06,629 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:01:06,630 - INFO - Number of unique classes: 43
2024-12-27 18:01:06,992 - INFO - Fitted scaler and transformed data
2024-12-27 18:01:06,992 - INFO - Scaling time: 0.36s
2024-12-27 18:01:08,143 - INFO - Epoch 1/25, Train Loss: 19.0016, Val Loss: 11.7724
2024-12-27 18:01:09,361 - INFO - Epoch 2/25, Train Loss: 5.9740, Val Loss: 6.5914
2024-12-27 18:01:10,642 - INFO - Epoch 3/25, Train Loss: 3.1082, Val Loss: 5.2953
2024-12-27 18:01:11,962 - INFO - Epoch 4/25, Train Loss: 2.4643, Val Loss: 4.8512
2024-12-27 18:01:13,288 - INFO - Epoch 5/25, Train Loss: 2.1047, Val Loss: 4.4750
2024-12-27 18:01:14,607 - INFO - Epoch 6/25, Train Loss: 1.8313, Val Loss: 4.1760
2024-12-27 18:01:15,915 - INFO - Epoch 7/25, Train Loss: 1.6484, Val Loss: 4.3958
2024-12-27 18:01:17,248 - INFO - Epoch 8/25, Train Loss: 1.5327, Val Loss: 4.3875
2024-12-27 18:01:17,249 - INFO - Early stopping triggered at epoch 8
2024-12-27 18:01:17,249 - INFO - Training completed in 10.62s
2024-12-27 18:01:17,249 - INFO - Final memory usage: CPU 2950.4 MB, GPU 48.4 MB
2024-12-27 18:01:17,250 - INFO - Model training completed in 10.62s
2024-12-27 18:01:17,298 - INFO - Prediction completed in 0.05s
2024-12-27 18:01:17,310 - INFO - Poison rate 0.2 completed in 20.75s
2024-12-27 18:01:17,311 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 18:01:17,311 - INFO - Total evaluation time: 170.12s
2024-12-27 18:01:17,318 - INFO - 
Progress: 11.5% - Evaluating GTSRB with LogisticRegression (standard mode, iteration 1/1)
2024-12-27 18:01:17,377 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 18:01:17,448 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 18:01:17,534 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 18:01:17,534 - INFO - Dataset type: image
2024-12-27 18:01:17,534 - INFO - Sample size: 39209
2024-12-27 18:01:17,534 - INFO - Using device: cuda
2024-12-27 18:01:17,534 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 18:01:17,537 - INFO - Loading datasets...
2024-12-27 18:01:34,854 - INFO - Dataset loading completed in 17.32s
2024-12-27 18:01:34,854 - INFO - Extracting validation features...
2024-12-27 18:01:34,854 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:34,  3.98it/s]Extracting features:   2%|▏         | 3/139 [00:00<00:15,  9.02it/s]Extracting features:   4%|▍         | 6/139 [00:00<00:08, 15.47it/s]Extracting features:   7%|▋         | 10/139 [00:00<00:05, 21.54it/s]Extracting features:  10%|█         | 14/139 [00:00<00:04, 25.84it/s]Extracting features:  14%|█▎        | 19/139 [00:00<00:03, 30.35it/s]Extracting features:  18%|█▊        | 25/139 [00:00<00:03, 35.19it/s]Extracting features:  22%|██▏       | 30/139 [00:01<00:02, 36.99it/s]Extracting features:  24%|██▍       | 34/139 [00:01<00:02, 37.60it/s]Extracting features:  27%|██▋       | 38/139 [00:01<00:02, 36.39it/s]Extracting features:  30%|███       | 42/139 [00:01<00:02, 36.37it/s]Extracting features:  33%|███▎      | 46/139 [00:01<00:02, 35.00it/s]Extracting features:  36%|███▌      | 50/139 [00:01<00:02, 35.42it/s]Extracting features:  39%|███▉      | 54/139 [00:01<00:02, 35.66it/s]Extracting features:  42%|████▏     | 58/139 [00:01<00:02, 34.35it/s]Extracting features:  45%|████▍     | 62/139 [00:02<00:02, 33.03it/s]Extracting features:  47%|████▋     | 66/139 [00:02<00:02, 32.13it/s]Extracting features:  50%|█████     | 70/139 [00:02<00:02, 28.70it/s]Extracting features:  53%|█████▎    | 74/139 [00:02<00:02, 29.18it/s]Extracting features:  56%|█████▌    | 78/139 [00:02<00:01, 31.15it/s]Extracting features:  59%|█████▉    | 82/139 [00:02<00:01, 33.17it/s]Extracting features:  62%|██████▏   | 86/139 [00:02<00:01, 32.98it/s]Extracting features:  65%|██████▍   | 90/139 [00:02<00:01, 32.17it/s]Extracting features:  68%|██████▊   | 94/139 [00:03<00:01, 32.57it/s]Extracting features:  71%|███████   | 98/139 [00:03<00:01, 30.91it/s]Extracting features:  74%|███████▍  | 103/139 [00:03<00:01, 34.10it/s]Extracting features:  77%|███████▋  | 107/139 [00:03<00:00, 34.46it/s]Extracting features:  80%|███████▉  | 111/139 [00:03<00:00, 33.42it/s]Extracting features:  83%|████████▎ | 115/139 [00:03<00:00, 34.15it/s]Extracting features:  86%|████████▌ | 119/139 [00:03<00:00, 34.33it/s]Extracting features:  88%|████████▊ | 123/139 [00:03<00:00, 33.53it/s]Extracting features:  92%|█████████▏| 128/139 [00:04<00:00, 36.01it/s]Extracting features:  95%|█████████▍| 132/139 [00:04<00:00, 36.37it/s]Extracting features: 100%|██████████| 139/139 [00:04<00:00, 40.84it/s]Extracting features: 100%|██████████| 139/139 [00:04<00:00, 32.00it/s]
2024-12-27 18:01:39,208 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 18:01:39,208 - INFO - Validation feature extraction completed in 4.35s
2024-12-27 18:01:39,208 - INFO - Extracting training features...
2024-12-27 18:01:39,208 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<02:15,  4.55it/s]Extracting features:   1%|          | 5/618 [00:00<00:34, 17.70it/s]Extracting features:   1%|▏         | 9/618 [00:00<00:26, 23.09it/s]Extracting features:   2%|▏         | 13/618 [00:00<00:23, 26.19it/s]Extracting features:   3%|▎         | 17/618 [00:00<00:20, 29.98it/s]Extracting features:   3%|▎         | 21/618 [00:00<00:18, 32.00it/s]Extracting features:   4%|▍         | 25/618 [00:00<00:18, 32.14it/s]Extracting features:   5%|▍         | 29/618 [00:01<00:18, 31.85it/s]Extracting features:   5%|▌         | 33/618 [00:01<00:17, 33.40it/s]Extracting features:   6%|▌         | 37/618 [00:01<00:17, 33.32it/s]Extracting features:   7%|▋         | 41/618 [00:01<00:17, 32.74it/s]Extracting features:   7%|▋         | 45/618 [00:01<00:17, 33.25it/s]Extracting features:   8%|▊         | 51/618 [00:01<00:14, 39.46it/s]Extracting features:   9%|▉         | 57/618 [00:01<00:12, 43.61it/s]Extracting features:  10%|█         | 63/618 [00:01<00:11, 46.83it/s]Extracting features:  11%|█▏        | 70/618 [00:01<00:10, 52.12it/s]Extracting features:  12%|█▏        | 77/618 [00:02<00:09, 55.31it/s]Extracting features:  13%|█▎        | 83/618 [00:02<00:09, 53.84it/s]Extracting features:  14%|█▍        | 89/618 [00:02<00:09, 53.69it/s]Extracting features:  16%|█▌        | 96/618 [00:02<00:09, 55.34it/s]Extracting features:  17%|█▋        | 102/618 [00:02<00:09, 56.52it/s]Extracting features:  17%|█▋        | 108/618 [00:02<00:10, 50.49it/s]Extracting features:  18%|█▊        | 114/618 [00:02<00:10, 50.22it/s]Extracting features:  20%|█▉        | 121/618 [00:02<00:09, 54.81it/s]Extracting features:  21%|██        | 128/618 [00:03<00:08, 57.35it/s]Extracting features:  22%|██▏       | 135/618 [00:03<00:08, 59.90it/s]Extracting features:  23%|██▎       | 142/618 [00:03<00:08, 59.49it/s]Extracting features:  24%|██▍       | 149/618 [00:03<00:07, 59.03it/s]Extracting features:  25%|██▌       | 156/618 [00:03<00:07, 60.34it/s]Extracting features:  26%|██▋       | 163/618 [00:03<00:07, 59.81it/s]Extracting features:  28%|██▊       | 170/618 [00:03<00:07, 57.67it/s]Extracting features:  28%|██▊       | 176/618 [00:03<00:07, 56.63it/s]Extracting features:  29%|██▉       | 182/618 [00:03<00:07, 54.99it/s]Extracting features:  30%|███       | 188/618 [00:04<00:07, 55.07it/s]Extracting features:  31%|███▏      | 194/618 [00:04<00:08, 51.49it/s]Extracting features:  32%|███▏      | 200/618 [00:04<00:08, 47.10it/s]Extracting features:  33%|███▎      | 206/618 [00:04<00:08, 48.78it/s]Extracting features:  34%|███▍      | 213/618 [00:04<00:07, 52.30it/s]Extracting features:  35%|███▌      | 219/618 [00:04<00:07, 52.32it/s]Extracting features:  36%|███▋      | 225/618 [00:04<00:07, 50.59it/s]Extracting features:  37%|███▋      | 231/618 [00:04<00:07, 50.44it/s]Extracting features:  38%|███▊      | 237/618 [00:05<00:07, 49.27it/s]Extracting features:  39%|███▉      | 242/618 [00:05<00:08, 46.53it/s]Extracting features:  40%|████      | 248/618 [00:05<00:07, 48.69it/s]Extracting features:  41%|████      | 254/618 [00:05<00:07, 50.94it/s]Extracting features:  42%|████▏     | 260/618 [00:05<00:06, 52.64it/s]Extracting features:  43%|████▎     | 266/618 [00:05<00:06, 54.66it/s]Extracting features:  44%|████▍     | 272/618 [00:05<00:06, 54.32it/s]Extracting features:  45%|████▍     | 278/618 [00:05<00:06, 52.55it/s]Extracting features:  46%|████▌     | 284/618 [00:05<00:06, 53.16it/s]Extracting features:  47%|████▋     | 290/618 [00:06<00:06, 50.17it/s]Extracting features:  48%|████▊     | 296/618 [00:06<00:07, 45.41it/s]Extracting features:  49%|████▉     | 303/618 [00:06<00:06, 50.91it/s]Extracting features:  50%|█████     | 309/618 [00:06<00:05, 51.69it/s]Extracting features:  51%|█████     | 315/618 [00:06<00:06, 49.59it/s]Extracting features:  52%|█████▏    | 321/618 [00:06<00:05, 51.25it/s]Extracting features:  53%|█████▎    | 327/618 [00:06<00:05, 53.43it/s]Extracting features:  54%|█████▍    | 334/618 [00:06<00:05, 54.29it/s]Extracting features:  55%|█████▌    | 340/618 [00:07<00:05, 53.58it/s]Extracting features:  56%|█████▌    | 346/618 [00:07<00:05, 52.96it/s]Extracting features:  57%|█████▋    | 352/618 [00:07<00:04, 54.64it/s]Extracting features:  58%|█████▊    | 359/618 [00:07<00:04, 56.63it/s]Extracting features:  59%|█████▉    | 366/618 [00:07<00:04, 57.98it/s]Extracting features:  60%|██████    | 372/618 [00:07<00:04, 54.04it/s]Extracting features:  61%|██████    | 378/618 [00:07<00:04, 54.54it/s]Extracting features:  62%|██████▏   | 384/618 [00:07<00:04, 54.57it/s]Extracting features:  63%|██████▎   | 390/618 [00:07<00:04, 53.34it/s]Extracting features:  64%|██████▍   | 396/618 [00:08<00:04, 50.18it/s]Extracting features:  65%|██████▌   | 402/618 [00:08<00:04, 50.78it/s]Extracting features:  66%|██████▌   | 409/618 [00:08<00:03, 53.53it/s]Extracting features:  67%|██████▋   | 415/618 [00:08<00:03, 54.67it/s]Extracting features:  68%|██████▊   | 422/618 [00:08<00:03, 57.93it/s]Extracting features:  69%|██████▉   | 429/618 [00:08<00:03, 59.14it/s]Extracting features:  71%|███████   | 436/618 [00:08<00:02, 61.57it/s]Extracting features:  72%|███████▏  | 443/618 [00:08<00:03, 57.71it/s]Extracting features:  73%|███████▎  | 449/618 [00:09<00:03, 55.67it/s]Extracting features:  74%|███████▍  | 456/618 [00:09<00:02, 58.63it/s]Extracting features:  75%|███████▍  | 462/618 [00:09<00:02, 57.60it/s]Extracting features:  76%|███████▌  | 469/618 [00:09<00:02, 59.64it/s]Extracting features:  77%|███████▋  | 475/618 [00:09<00:02, 59.11it/s]Extracting features:  78%|███████▊  | 481/618 [00:09<00:02, 54.43it/s]Extracting features:  79%|███████▉  | 487/618 [00:09<00:02, 54.65it/s]Extracting features:  80%|███████▉  | 494/618 [00:09<00:02, 57.05it/s]Extracting features:  81%|████████  | 500/618 [00:09<00:02, 57.29it/s]Extracting features:  82%|████████▏ | 507/618 [00:10<00:01, 57.59it/s]Extracting features:  83%|████████▎ | 513/618 [00:10<00:01, 57.61it/s]Extracting features:  84%|████████▍ | 520/618 [00:10<00:01, 59.94it/s]Extracting features:  85%|████████▌ | 527/618 [00:10<00:01, 57.28it/s]Extracting features:  86%|████████▌ | 533/618 [00:10<00:01, 53.93it/s]Extracting features:  87%|████████▋ | 540/618 [00:10<00:01, 56.50it/s]Extracting features:  89%|████████▊ | 547/618 [00:10<00:01, 57.94it/s]Extracting features:  89%|████████▉ | 553/618 [00:10<00:01, 58.44it/s]Extracting features:  90%|█████████ | 559/618 [00:10<00:01, 55.14it/s]Extracting features:  91%|█████████▏| 565/618 [00:11<00:00, 54.92it/s]Extracting features:  92%|█████████▏| 571/618 [00:11<00:00, 54.65it/s]Extracting features:  94%|█████████▎| 578/618 [00:11<00:00, 57.07it/s]Extracting features:  95%|█████████▍| 585/618 [00:11<00:00, 58.42it/s]Extracting features:  96%|█████████▌| 592/618 [00:11<00:00, 60.35it/s]Extracting features:  97%|█████████▋| 599/618 [00:11<00:00, 60.04it/s]Extracting features:  98%|█████████▊| 606/618 [00:11<00:00, 52.14it/s]Extracting features:  99%|█████████▉| 612/618 [00:11<00:00, 53.02it/s]Extracting features: 100%|██████████| 618/618 [00:12<00:00, 51.36it/s]
2024-12-27 18:01:51,276 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 18:01:51,276 - INFO - Training feature extraction completed in 12.07s
2024-12-27 18:01:51,276 - INFO - Creating model for classifier: LogisticRegression
2024-12-27 18:01:51,276 - INFO - Using device: cuda
2024-12-27 18:01:51,277 - INFO - 
Processing poison rate: 0.0
2024-12-27 18:01:51,277 - INFO - Training set processing completed in 0.00s
2024-12-27 18:01:51,277 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:01:51,278 - INFO - Memory usage at start_fit: CPU 2852.3 MB, GPU 47.3 MB
2024-12-27 18:01:51,279 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:01:51,284 - INFO - Number of unique classes: 43
2024-12-27 18:01:51,643 - INFO - Fitted scaler and transformed data
2024-12-27 18:01:51,643 - INFO - Scaling time: 0.36s
2024-12-27 18:01:52,126 - INFO - Epoch 1/200, Train Loss: 1.4510, Val Loss: 1.0046
2024-12-27 18:01:52,627 - INFO - Epoch 2/200, Train Loss: 0.6296, Val Loss: 0.8342
2024-12-27 18:01:53,239 - INFO - Epoch 3/200, Train Loss: 0.4258, Val Loss: 0.8492
2024-12-27 18:01:54,048 - INFO - Epoch 4/200, Train Loss: 0.3470, Val Loss: 0.7893
2024-12-27 18:01:54,889 - INFO - Epoch 5/200, Train Loss: 0.3114, Val Loss: 0.7967
2024-12-27 18:01:55,731 - INFO - Epoch 6/200, Train Loss: 0.2863, Val Loss: 0.8592
2024-12-27 18:01:55,731 - INFO - Early stopping triggered at epoch 6
2024-12-27 18:01:55,731 - INFO - Training completed in 4.45s
2024-12-27 18:01:55,732 - INFO - Final memory usage: CPU 2964.1 MB, GPU 48.4 MB
2024-12-27 18:01:55,733 - INFO - Model training completed in 4.46s
2024-12-27 18:01:55,761 - INFO - Prediction completed in 0.03s
2024-12-27 18:01:55,773 - INFO - Poison rate 0.0 completed in 4.50s
2024-12-27 18:01:55,773 - INFO - 
Processing poison rate: 0.01
2024-12-27 18:01:55,775 - INFO - Total number of labels flipped: 196
2024-12-27 18:01:55,775 - INFO - Label flipping completed in 0.00s
2024-12-27 18:01:55,776 - INFO - Training set processing completed in 0.00s
2024-12-27 18:01:55,776 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:01:55,776 - INFO - Memory usage at start_fit: CPU 2867.7 MB, GPU 48.1 MB
2024-12-27 18:01:55,777 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:01:55,778 - INFO - Number of unique classes: 43
2024-12-27 18:01:56,111 - INFO - Fitted scaler and transformed data
2024-12-27 18:01:56,112 - INFO - Scaling time: 0.33s
2024-12-27 18:01:56,800 - INFO - Epoch 1/200, Train Loss: 1.5888, Val Loss: 1.2333
2024-12-27 18:01:57,377 - INFO - Epoch 2/200, Train Loss: 0.7526, Val Loss: 1.0475
2024-12-27 18:01:58,101 - INFO - Epoch 3/200, Train Loss: 0.5554, Val Loss: 1.0238
2024-12-27 18:01:58,968 - INFO - Epoch 4/200, Train Loss: 0.4735, Val Loss: 1.1073
2024-12-27 18:01:59,776 - INFO - Epoch 5/200, Train Loss: 0.4167, Val Loss: 1.0929
2024-12-27 18:01:59,776 - INFO - Early stopping triggered at epoch 5
2024-12-27 18:01:59,776 - INFO - Training completed in 4.00s
2024-12-27 18:01:59,776 - INFO - Final memory usage: CPU 2965.9 MB, GPU 48.4 MB
2024-12-27 18:01:59,777 - INFO - Model training completed in 4.00s
2024-12-27 18:01:59,808 - INFO - Prediction completed in 0.03s
2024-12-27 18:01:59,819 - INFO - Poison rate 0.01 completed in 4.05s
2024-12-27 18:01:59,819 - INFO - 
Processing poison rate: 0.03
2024-12-27 18:01:59,821 - INFO - Total number of labels flipped: 591
2024-12-27 18:01:59,821 - INFO - Label flipping completed in 0.00s
2024-12-27 18:01:59,821 - INFO - Training set processing completed in 0.00s
2024-12-27 18:01:59,821 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:01:59,822 - INFO - Memory usage at start_fit: CPU 2869.4 MB, GPU 48.1 MB
2024-12-27 18:01:59,822 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:01:59,823 - INFO - Number of unique classes: 43
2024-12-27 18:02:00,192 - INFO - Fitted scaler and transformed data
2024-12-27 18:02:00,193 - INFO - Scaling time: 0.37s
2024-12-27 18:02:01,043 - INFO - Epoch 1/200, Train Loss: 1.7963, Val Loss: 1.5583
2024-12-27 18:02:01,910 - INFO - Epoch 2/200, Train Loss: 0.9576, Val Loss: 1.4639
2024-12-27 18:02:02,757 - INFO - Epoch 3/200, Train Loss: 0.7442, Val Loss: 1.3970
2024-12-27 18:02:03,617 - INFO - Epoch 4/200, Train Loss: 0.6452, Val Loss: 1.3451
2024-12-27 18:02:04,477 - INFO - Epoch 5/200, Train Loss: 0.5600, Val Loss: 1.5382
2024-12-27 18:02:05,339 - INFO - Epoch 6/200, Train Loss: 0.5435, Val Loss: 1.5952
2024-12-27 18:02:05,339 - INFO - Early stopping triggered at epoch 6
2024-12-27 18:02:05,339 - INFO - Training completed in 5.52s
2024-12-27 18:02:05,339 - INFO - Final memory usage: CPU 2965.9 MB, GPU 48.4 MB
2024-12-27 18:02:05,340 - INFO - Model training completed in 5.52s
2024-12-27 18:02:05,369 - INFO - Prediction completed in 0.03s
2024-12-27 18:02:05,381 - INFO - Poison rate 0.03 completed in 5.56s
2024-12-27 18:02:05,381 - INFO - 
Processing poison rate: 0.05
2024-12-27 18:02:05,384 - INFO - Total number of labels flipped: 985
2024-12-27 18:02:05,384 - INFO - Label flipping completed in 0.00s
2024-12-27 18:02:05,384 - INFO - Training set processing completed in 0.00s
2024-12-27 18:02:05,384 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:02:05,385 - INFO - Memory usage at start_fit: CPU 2869.4 MB, GPU 48.1 MB
2024-12-27 18:02:05,385 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:02:05,386 - INFO - Number of unique classes: 43
2024-12-27 18:02:05,750 - INFO - Fitted scaler and transformed data
2024-12-27 18:02:05,750 - INFO - Scaling time: 0.36s
2024-12-27 18:02:06,603 - INFO - Epoch 1/200, Train Loss: 1.9921, Val Loss: 1.7138
2024-12-27 18:02:07,486 - INFO - Epoch 2/200, Train Loss: 1.1030, Val Loss: 1.5898
2024-12-27 18:02:08,084 - INFO - Epoch 3/200, Train Loss: 0.8999, Val Loss: 1.6293
2024-12-27 18:02:08,631 - INFO - Epoch 4/200, Train Loss: 0.7912, Val Loss: 1.5353
2024-12-27 18:02:09,210 - INFO - Epoch 5/200, Train Loss: 0.7037, Val Loss: 1.7455
2024-12-27 18:02:09,759 - INFO - Epoch 6/200, Train Loss: 0.6381, Val Loss: 1.6573
2024-12-27 18:02:09,760 - INFO - Early stopping triggered at epoch 6
2024-12-27 18:02:09,760 - INFO - Training completed in 4.38s
2024-12-27 18:02:09,760 - INFO - Final memory usage: CPU 2967.2 MB, GPU 48.4 MB
2024-12-27 18:02:09,762 - INFO - Model training completed in 4.38s
2024-12-27 18:02:09,810 - INFO - Prediction completed in 0.05s
2024-12-27 18:02:09,822 - INFO - Poison rate 0.05 completed in 4.44s
2024-12-27 18:02:09,822 - INFO - 
Processing poison rate: 0.07
2024-12-27 18:02:09,824 - INFO - Total number of labels flipped: 1374
2024-12-27 18:02:09,825 - INFO - Label flipping completed in 0.00s
2024-12-27 18:02:09,825 - INFO - Training set processing completed in 0.00s
2024-12-27 18:02:09,825 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:02:09,826 - INFO - Memory usage at start_fit: CPU 2870.8 MB, GPU 48.1 MB
2024-12-27 18:02:09,826 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:02:09,828 - INFO - Number of unique classes: 43
2024-12-27 18:02:10,203 - INFO - Fitted scaler and transformed data
2024-12-27 18:02:10,203 - INFO - Scaling time: 0.37s
2024-12-27 18:02:10,756 - INFO - Epoch 1/200, Train Loss: 2.1261, Val Loss: 1.7959
2024-12-27 18:02:11,301 - INFO - Epoch 2/200, Train Loss: 1.2683, Val Loss: 1.6470
2024-12-27 18:02:12,052 - INFO - Epoch 3/200, Train Loss: 1.0480, Val Loss: 1.7688
2024-12-27 18:02:12,755 - INFO - Epoch 4/200, Train Loss: 0.9147, Val Loss: 1.7244
2024-12-27 18:02:12,755 - INFO - Early stopping triggered at epoch 4
2024-12-27 18:02:12,755 - INFO - Training completed in 2.93s
2024-12-27 18:02:12,755 - INFO - Final memory usage: CPU 2968.5 MB, GPU 48.4 MB
2024-12-27 18:02:12,756 - INFO - Model training completed in 2.93s
2024-12-27 18:02:12,785 - INFO - Prediction completed in 0.03s
2024-12-27 18:02:12,798 - INFO - Poison rate 0.07 completed in 2.98s
2024-12-27 18:02:12,798 - INFO - 
Processing poison rate: 0.1
2024-12-27 18:02:12,800 - INFO - Total number of labels flipped: 1955
2024-12-27 18:02:12,801 - INFO - Label flipping completed in 0.00s
2024-12-27 18:02:12,801 - INFO - Training set processing completed in 0.00s
2024-12-27 18:02:12,801 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:02:12,802 - INFO - Memory usage at start_fit: CPU 2872.0 MB, GPU 48.1 MB
2024-12-27 18:02:12,802 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:02:12,803 - INFO - Number of unique classes: 43
2024-12-27 18:02:13,135 - INFO - Fitted scaler and transformed data
2024-12-27 18:02:13,136 - INFO - Scaling time: 0.33s
2024-12-27 18:02:13,695 - INFO - Epoch 1/200, Train Loss: 2.4072, Val Loss: 1.9534
2024-12-27 18:02:14,244 - INFO - Epoch 2/200, Train Loss: 1.4805, Val Loss: 1.9892
2024-12-27 18:02:14,858 - INFO - Epoch 3/200, Train Loss: 1.2714, Val Loss: 1.9959
2024-12-27 18:02:14,858 - INFO - Early stopping triggered at epoch 3
2024-12-27 18:02:14,858 - INFO - Training completed in 2.06s
2024-12-27 18:02:14,859 - INFO - Final memory usage: CPU 2970.0 MB, GPU 48.4 MB
2024-12-27 18:02:14,860 - INFO - Model training completed in 2.06s
2024-12-27 18:02:14,889 - INFO - Prediction completed in 0.03s
2024-12-27 18:02:14,901 - INFO - Poison rate 0.1 completed in 2.10s
2024-12-27 18:02:14,901 - INFO - 
Processing poison rate: 0.2
2024-12-27 18:02:14,909 - INFO - Total number of labels flipped: 3923
2024-12-27 18:02:14,909 - INFO - Label flipping completed in 0.01s
2024-12-27 18:02:14,910 - INFO - Training set processing completed in 0.00s
2024-12-27 18:02:14,910 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:02:14,911 - INFO - Memory usage at start_fit: CPU 2873.6 MB, GPU 48.1 MB
2024-12-27 18:02:14,912 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:02:14,913 - INFO - Number of unique classes: 43
2024-12-27 18:02:15,247 - INFO - Fitted scaler and transformed data
2024-12-27 18:02:15,248 - INFO - Scaling time: 0.33s
2024-12-27 18:02:15,812 - INFO - Epoch 1/200, Train Loss: 2.9339, Val Loss: 2.7180
2024-12-27 18:02:16,399 - INFO - Epoch 2/200, Train Loss: 1.9271, Val Loss: 2.5038
2024-12-27 18:02:16,973 - INFO - Epoch 3/200, Train Loss: 1.6080, Val Loss: 2.4054
2024-12-27 18:02:17,620 - INFO - Epoch 4/200, Train Loss: 1.3460, Val Loss: 2.2323
2024-12-27 18:02:18,297 - INFO - Epoch 5/200, Train Loss: 1.2294, Val Loss: 2.4170
2024-12-27 18:02:19,060 - INFO - Epoch 6/200, Train Loss: 1.1537, Val Loss: 2.3186
2024-12-27 18:02:19,060 - INFO - Early stopping triggered at epoch 6
2024-12-27 18:02:19,060 - INFO - Training completed in 4.15s
2024-12-27 18:02:19,060 - INFO - Final memory usage: CPU 2971.2 MB, GPU 48.4 MB
2024-12-27 18:02:19,061 - INFO - Model training completed in 4.15s
2024-12-27 18:02:19,090 - INFO - Prediction completed in 0.03s
2024-12-27 18:02:19,106 - INFO - Poison rate 0.2 completed in 4.21s
2024-12-27 18:02:19,108 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 18:02:19,108 - INFO - Total evaluation time: 61.57s
2024-12-27 18:02:19,114 - INFO - 
Progress: 12.5% - Evaluating GTSRB with LogisticRegression (dynadetect mode, iteration 1/1)
2024-12-27 18:02:19,174 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 18:02:19,252 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 18:02:19,335 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 18:02:19,335 - INFO - Dataset type: image
2024-12-27 18:02:19,335 - INFO - Sample size: 39209
2024-12-27 18:02:19,335 - INFO - Using device: cuda
2024-12-27 18:02:19,335 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 18:02:19,337 - INFO - Loading datasets...
2024-12-27 18:02:37,214 - INFO - Dataset loading completed in 17.88s
2024-12-27 18:02:37,214 - INFO - Extracting validation features...
2024-12-27 18:02:37,214 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:29,  4.74it/s]Extracting features:   3%|▎         | 4/139 [00:00<00:12, 11.18it/s]Extracting features:   5%|▌         | 7/139 [00:00<00:08, 15.67it/s]Extracting features:   8%|▊         | 11/139 [00:00<00:05, 21.60it/s]Extracting features:  12%|█▏        | 16/139 [00:00<00:04, 27.70it/s]Extracting features:  14%|█▍        | 20/139 [00:00<00:03, 30.68it/s]Extracting features:  17%|█▋        | 24/139 [00:00<00:03, 32.22it/s]Extracting features:  20%|██        | 28/139 [00:01<00:03, 33.60it/s]Extracting features:  23%|██▎       | 32/139 [00:01<00:03, 35.00it/s]Extracting features:  26%|██▌       | 36/139 [00:01<00:02, 36.12it/s]Extracting features:  29%|██▉       | 40/139 [00:01<00:02, 35.40it/s]Extracting features:  32%|███▏      | 44/139 [00:01<00:02, 35.60it/s]Extracting features:  35%|███▍      | 48/139 [00:01<00:02, 35.81it/s]Extracting features:  37%|███▋      | 52/139 [00:01<00:02, 36.42it/s]Extracting features:  40%|████      | 56/139 [00:01<00:02, 34.08it/s]Extracting features:  43%|████▎     | 60/139 [00:01<00:02, 35.47it/s]Extracting features:  47%|████▋     | 65/139 [00:02<00:01, 38.99it/s]Extracting features:  50%|█████     | 70/139 [00:02<00:01, 40.13it/s]Extracting features:  55%|█████▍    | 76/139 [00:02<00:01, 44.50it/s]Extracting features:  58%|█████▊    | 81/139 [00:02<00:01, 43.72it/s]Extracting features:  63%|██████▎   | 87/139 [00:02<00:01, 46.94it/s]Extracting features:  68%|██████▊   | 94/139 [00:02<00:00, 51.07it/s]Extracting features:  72%|███████▏  | 100/139 [00:02<00:00, 53.03it/s]Extracting features:  76%|███████▋  | 106/139 [00:02<00:00, 52.35it/s]Extracting features:  81%|████████  | 112/139 [00:03<00:00, 45.35it/s]Extracting features:  84%|████████▍ | 117/139 [00:03<00:00, 43.46it/s]Extracting features:  88%|████████▊ | 122/139 [00:03<00:00, 43.50it/s]Extracting features:  91%|█████████▏| 127/139 [00:03<00:00, 40.96it/s]Extracting features:  95%|█████████▍| 132/139 [00:03<00:00, 40.15it/s]Extracting features:  99%|█████████▊| 137/139 [00:03<00:00, 41.49it/s]Extracting features: 100%|██████████| 139/139 [00:03<00:00, 36.94it/s]
2024-12-27 18:02:40,990 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 18:02:40,990 - INFO - Validation feature extraction completed in 3.78s
2024-12-27 18:02:40,990 - INFO - Extracting training features...
2024-12-27 18:02:40,990 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<02:03,  5.01it/s]Extracting features:   1%|          | 7/618 [00:00<00:22, 27.71it/s]Extracting features:   2%|▏         | 11/618 [00:00<00:19, 31.33it/s]Extracting features:   2%|▏         | 15/618 [00:00<00:18, 32.58it/s]Extracting features:   3%|▎         | 19/618 [00:00<00:17, 33.34it/s]Extracting features:   4%|▎         | 23/618 [00:00<00:17, 34.06it/s]Extracting features:   4%|▍         | 27/618 [00:00<00:16, 35.21it/s]Extracting features:   5%|▌         | 31/618 [00:00<00:16, 34.55it/s]Extracting features:   6%|▌         | 35/618 [00:01<00:16, 35.63it/s]Extracting features:   6%|▋         | 39/618 [00:01<00:16, 36.14it/s]Extracting features:   7%|▋         | 44/618 [00:01<00:15, 37.52it/s]Extracting features:   8%|▊         | 48/618 [00:01<00:15, 36.74it/s]Extracting features:   8%|▊         | 52/618 [00:01<00:15, 37.59it/s]Extracting features:   9%|▉         | 56/618 [00:01<00:15, 36.38it/s]Extracting features:  10%|▉         | 60/618 [00:01<00:15, 36.89it/s]Extracting features:  10%|█         | 64/618 [00:01<00:15, 36.38it/s]Extracting features:  11%|█         | 69/618 [00:01<00:14, 37.40it/s]Extracting features:  12%|█▏        | 74/618 [00:02<00:14, 37.91it/s]Extracting features:  13%|█▎        | 79/618 [00:02<00:13, 38.63it/s]Extracting features:  13%|█▎        | 83/618 [00:02<00:14, 38.06it/s]Extracting features:  14%|█▍        | 87/618 [00:02<00:14, 37.06it/s]Extracting features:  15%|█▍        | 92/618 [00:02<00:13, 37.95it/s]Extracting features:  16%|█▌        | 97/618 [00:02<00:13, 39.59it/s]Extracting features:  16%|█▋        | 101/618 [00:02<00:13, 37.42it/s]Extracting features:  17%|█▋        | 106/618 [00:02<00:13, 37.91it/s]Extracting features:  18%|█▊        | 110/618 [00:03<00:13, 36.89it/s]Extracting features:  18%|█▊        | 114/618 [00:03<00:13, 36.34it/s]Extracting features:  19%|█▉        | 118/618 [00:03<00:13, 37.27it/s]Extracting features:  20%|█▉        | 122/618 [00:03<00:13, 35.44it/s]Extracting features:  20%|██        | 126/618 [00:03<00:14, 34.95it/s]Extracting features:  21%|██        | 130/618 [00:03<00:13, 35.71it/s]Extracting features:  22%|██▏       | 134/618 [00:03<00:13, 34.94it/s]Extracting features:  22%|██▏       | 138/618 [00:03<00:13, 34.70it/s]Extracting features:  23%|██▎       | 143/618 [00:03<00:12, 37.92it/s]Extracting features:  24%|██▍       | 147/618 [00:04<00:12, 38.40it/s]Extracting features:  24%|██▍       | 151/618 [00:04<00:12, 37.20it/s]Extracting features:  25%|██▌       | 155/618 [00:04<00:13, 35.46it/s]Extracting features:  26%|██▌       | 160/618 [00:04<00:12, 36.88it/s]Extracting features:  27%|██▋       | 164/618 [00:04<00:12, 36.82it/s]Extracting features:  27%|██▋       | 168/618 [00:04<00:12, 36.53it/s]Extracting features:  28%|██▊       | 172/618 [00:04<00:12, 36.96it/s]Extracting features:  28%|██▊       | 176/618 [00:04<00:11, 36.86it/s]Extracting features:  29%|██▉       | 180/618 [00:04<00:11, 37.16it/s]Extracting features:  30%|██▉       | 184/618 [00:05<00:11, 36.35it/s]Extracting features:  30%|███       | 188/618 [00:05<00:11, 36.93it/s]Extracting features:  31%|███       | 193/618 [00:05<00:11, 38.39it/s]Extracting features:  32%|███▏      | 198/618 [00:05<00:10, 41.23it/s]Extracting features:  33%|███▎      | 203/618 [00:05<00:10, 40.15it/s]Extracting features:  34%|███▎      | 208/618 [00:05<00:10, 40.88it/s]Extracting features:  34%|███▍      | 213/618 [00:05<00:10, 39.69it/s]Extracting features:  35%|███▌      | 217/618 [00:05<00:10, 38.78it/s]Extracting features:  36%|███▌      | 221/618 [00:06<00:10, 38.36it/s]Extracting features:  37%|███▋      | 226/618 [00:06<00:10, 38.86it/s]Extracting features:  37%|███▋      | 230/618 [00:06<00:10, 37.49it/s]Extracting features:  38%|███▊      | 234/618 [00:06<00:10, 37.79it/s]Extracting features:  39%|███▊      | 238/618 [00:06<00:09, 38.02it/s]Extracting features:  39%|███▉      | 242/618 [00:06<00:10, 36.89it/s]Extracting features:  40%|███▉      | 246/618 [00:06<00:10, 36.26it/s]Extracting features:  41%|████      | 251/618 [00:06<00:09, 39.23it/s]Extracting features:  41%|████▏     | 255/618 [00:07<00:11, 31.57it/s]Extracting features:  42%|████▏     | 259/618 [00:07<00:11, 30.35it/s]Extracting features:  43%|████▎     | 264/618 [00:07<00:10, 33.68it/s]Extracting features:  43%|████▎     | 268/618 [00:07<00:10, 34.25it/s]Extracting features:  44%|████▍     | 272/618 [00:07<00:09, 34.73it/s]Extracting features:  45%|████▍     | 276/618 [00:07<00:09, 36.08it/s]Extracting features:  45%|████▌     | 281/618 [00:07<00:08, 38.90it/s]Extracting features:  46%|████▌     | 285/618 [00:07<00:08, 37.74it/s]Extracting features:  47%|████▋     | 290/618 [00:07<00:08, 38.26it/s]Extracting features:  48%|████▊     | 294/618 [00:08<00:08, 37.45it/s]Extracting features:  48%|████▊     | 298/618 [00:08<00:08, 37.28it/s]Extracting features:  49%|████▉     | 303/618 [00:08<00:08, 38.91it/s]Extracting features:  50%|████▉     | 307/618 [00:08<00:07, 39.16it/s]Extracting features:  50%|█████     | 311/618 [00:08<00:08, 37.62it/s]Extracting features:  51%|█████     | 315/618 [00:08<00:08, 35.30it/s]Extracting features:  52%|█████▏    | 319/618 [00:08<00:08, 35.70it/s]Extracting features:  52%|█████▏    | 324/618 [00:08<00:07, 37.55it/s]Extracting features:  53%|█████▎    | 328/618 [00:08<00:07, 37.75it/s]Extracting features:  54%|█████▎    | 332/618 [00:09<00:07, 38.32it/s]Extracting features:  54%|█████▍    | 336/618 [00:09<00:07, 36.63it/s]Extracting features:  55%|█████▌    | 340/618 [00:09<00:07, 35.48it/s]Extracting features:  56%|█████▌    | 344/618 [00:09<00:07, 34.98it/s]Extracting features:  56%|█████▋    | 348/618 [00:09<00:07, 36.06it/s]Extracting features:  57%|█████▋    | 353/618 [00:09<00:06, 38.99it/s]Extracting features:  58%|█████▊    | 357/618 [00:09<00:06, 38.09it/s]Extracting features:  58%|█████▊    | 361/618 [00:09<00:06, 36.87it/s]Extracting features:  59%|█████▉    | 365/618 [00:09<00:07, 36.13it/s]Extracting features:  60%|█████▉    | 369/618 [00:10<00:06, 36.77it/s]Extracting features:  60%|██████    | 373/618 [00:10<00:06, 36.16it/s]Extracting features:  61%|██████    | 378/618 [00:10<00:06, 39.47it/s]Extracting features:  62%|██████▏   | 382/618 [00:10<00:06, 39.29it/s]Extracting features:  62%|██████▏   | 386/618 [00:10<00:06, 37.96it/s]Extracting features:  63%|██████▎   | 390/618 [00:10<00:06, 36.51it/s]Extracting features:  64%|██████▍   | 394/618 [00:10<00:06, 37.17it/s]Extracting features:  64%|██████▍   | 398/618 [00:10<00:05, 37.67it/s]Extracting features:  65%|██████▌   | 402/618 [00:10<00:06, 35.14it/s]Extracting features:  66%|██████▌   | 407/618 [00:11<00:05, 36.49it/s]Extracting features:  67%|██████▋   | 411/618 [00:11<00:05, 34.96it/s]Extracting features:  67%|██████▋   | 415/618 [00:11<00:05, 34.82it/s]Extracting features:  68%|██████▊   | 419/618 [00:11<00:05, 34.19it/s]Extracting features:  69%|██████▊   | 424/618 [00:11<00:05, 36.23it/s]Extracting features:  69%|██████▉   | 428/618 [00:11<00:05, 37.14it/s]Extracting features:  70%|██████▉   | 432/618 [00:11<00:04, 37.31it/s]Extracting features:  71%|███████   | 437/618 [00:11<00:04, 39.38it/s]Extracting features:  72%|███████▏  | 442/618 [00:12<00:04, 41.66it/s]Extracting features:  72%|███████▏  | 447/618 [00:12<00:04, 41.78it/s]Extracting features:  73%|███████▎  | 452/618 [00:12<00:04, 40.73it/s]Extracting features:  74%|███████▍  | 457/618 [00:12<00:03, 40.37it/s]Extracting features:  75%|███████▍  | 462/618 [00:12<00:04, 37.24it/s]Extracting features:  75%|███████▌  | 466/618 [00:12<00:04, 36.81it/s]Extracting features:  76%|███████▌  | 470/618 [00:12<00:03, 37.26it/s]Extracting features:  77%|███████▋  | 474/618 [00:12<00:03, 36.69it/s]Extracting features:  78%|███████▊  | 479/618 [00:13<00:03, 38.93it/s]Extracting features:  78%|███████▊  | 483/618 [00:13<00:03, 38.20it/s]Extracting features:  79%|███████▉  | 487/618 [00:13<00:03, 38.24it/s]Extracting features:  79%|███████▉  | 491/618 [00:13<00:03, 36.79it/s]Extracting features:  80%|████████  | 496/618 [00:13<00:03, 38.87it/s]Extracting features:  81%|████████  | 501/618 [00:13<00:02, 41.50it/s]Extracting features:  82%|████████▏ | 506/618 [00:13<00:02, 40.62it/s]Extracting features:  83%|████████▎ | 511/618 [00:13<00:02, 39.68it/s]Extracting features:  83%|████████▎ | 515/618 [00:13<00:02, 38.64it/s]Extracting features:  84%|████████▍ | 519/618 [00:14<00:02, 36.98it/s]Extracting features:  85%|████████▍ | 523/618 [00:14<00:02, 37.60it/s]Extracting features:  85%|████████▌ | 527/618 [00:14<00:02, 37.80it/s]Extracting features:  86%|████████▌ | 532/618 [00:14<00:02, 39.07it/s]Extracting features:  87%|████████▋ | 537/618 [00:14<00:02, 39.83it/s]Extracting features:  88%|████████▊ | 541/618 [00:14<00:01, 38.67it/s]Extracting features:  88%|████████▊ | 546/618 [00:14<00:01, 39.67it/s]Extracting features:  89%|████████▉ | 550/618 [00:14<00:01, 39.15it/s]Extracting features:  90%|████████▉ | 555/618 [00:14<00:01, 39.78it/s]Extracting features:  90%|█████████ | 559/618 [00:15<00:01, 37.68it/s]Extracting features:  91%|█████████ | 563/618 [00:15<00:01, 36.68it/s]Extracting features:  92%|█████████▏| 567/618 [00:15<00:01, 36.81it/s]Extracting features:  93%|█████████▎| 572/618 [00:15<00:01, 38.19it/s]Extracting features:  93%|█████████▎| 576/618 [00:15<00:01, 38.66it/s]Extracting features:  94%|█████████▍| 581/618 [00:15<00:00, 41.10it/s]Extracting features:  95%|█████████▍| 586/618 [00:15<00:00, 42.55it/s]Extracting features:  96%|█████████▌| 591/618 [00:15<00:00, 40.38it/s]Extracting features:  96%|█████████▋| 596/618 [00:16<00:00, 39.67it/s]Extracting features:  97%|█████████▋| 601/618 [00:16<00:00, 39.57it/s]Extracting features:  98%|█████████▊| 605/618 [00:16<00:00, 38.77it/s]Extracting features:  99%|█████████▊| 609/618 [00:16<00:00, 38.77it/s]Extracting features:  99%|█████████▉| 614/618 [00:16<00:00, 40.76it/s]Extracting features: 100%|██████████| 618/618 [00:16<00:00, 37.15it/s]
2024-12-27 18:02:57,663 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 18:02:57,663 - INFO - Training feature extraction completed in 16.67s
2024-12-27 18:02:57,663 - INFO - Creating model for classifier: LogisticRegression
2024-12-27 18:02:57,664 - INFO - Using device: cuda
2024-12-27 18:02:57,664 - INFO - 
Processing poison rate: 0.0
2024-12-27 18:02:57,664 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:02:57,664 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:02:59,554 - INFO - Feature scaling completed in 1.89s
2024-12-27 18:02:59,554 - INFO - Starting feature selection (k=50)
2024-12-27 18:02:59,581 - INFO - Feature selection completed in 0.03s. Output shape: (19755, 50)
2024-12-27 18:02:59,581 - INFO - Starting anomaly detection
2024-12-27 18:03:07,492 - INFO - Anomaly detection completed in 7.91s
2024-12-27 18:03:07,493 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:03:07,493 - INFO - Total fit_transform time: 9.83s
2024-12-27 18:03:07,494 - INFO - Training set processing completed in 9.83s
2024-12-27 18:03:07,495 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:03:07,496 - INFO - Memory usage at start_fit: CPU 2871.9 MB, GPU 47.3 MB
2024-12-27 18:03:07,497 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:03:07,501 - INFO - Number of unique classes: 43
2024-12-27 18:03:07,861 - INFO - Fitted scaler and transformed data
2024-12-27 18:03:07,861 - INFO - Scaling time: 0.36s
2024-12-27 18:03:08,499 - INFO - Epoch 1/200, Train Loss: 1.4290, Val Loss: 1.1273
2024-12-27 18:03:09,134 - INFO - Epoch 2/200, Train Loss: 0.6191, Val Loss: 0.9567
2024-12-27 18:03:09,734 - INFO - Epoch 3/200, Train Loss: 0.4499, Val Loss: 1.0063
2024-12-27 18:03:10,499 - INFO - Epoch 4/200, Train Loss: 0.3455, Val Loss: 1.0410
2024-12-27 18:03:10,500 - INFO - Early stopping triggered at epoch 4
2024-12-27 18:03:10,500 - INFO - Training completed in 3.00s
2024-12-27 18:03:10,500 - INFO - Final memory usage: CPU 2976.9 MB, GPU 48.4 MB
2024-12-27 18:03:10,501 - INFO - Model training completed in 3.01s
2024-12-27 18:03:10,545 - INFO - Prediction completed in 0.04s
2024-12-27 18:03:10,559 - INFO - Poison rate 0.0 completed in 12.90s
2024-12-27 18:03:10,559 - INFO - 
Processing poison rate: 0.01
2024-12-27 18:03:10,561 - INFO - Total number of labels flipped: 195
2024-12-27 18:03:10,561 - INFO - Label flipping completed in 0.00s
2024-12-27 18:03:10,562 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:03:10,562 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:03:12,449 - INFO - Feature scaling completed in 1.89s
2024-12-27 18:03:12,450 - INFO - Starting feature selection (k=50)
2024-12-27 18:03:12,502 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 18:03:12,502 - INFO - Starting anomaly detection
2024-12-27 18:03:20,535 - INFO - Anomaly detection completed in 8.03s
2024-12-27 18:03:20,536 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:03:20,536 - INFO - Total fit_transform time: 9.97s
2024-12-27 18:03:20,537 - INFO - Training set processing completed in 9.98s
2024-12-27 18:03:20,537 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:03:20,538 - INFO - Memory usage at start_fit: CPU 2882.0 MB, GPU 48.1 MB
2024-12-27 18:03:20,538 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:03:20,540 - INFO - Number of unique classes: 43
2024-12-27 18:03:20,898 - INFO - Fitted scaler and transformed data
2024-12-27 18:03:20,899 - INFO - Scaling time: 0.36s
2024-12-27 18:03:21,742 - INFO - Epoch 1/200, Train Loss: 1.5920, Val Loss: 1.2461
2024-12-27 18:03:22,598 - INFO - Epoch 2/200, Train Loss: 0.7410, Val Loss: 1.0724
2024-12-27 18:03:23,394 - INFO - Epoch 3/200, Train Loss: 0.5661, Val Loss: 1.0536
2024-12-27 18:03:24,217 - INFO - Epoch 4/200, Train Loss: 0.4890, Val Loss: 1.1322
2024-12-27 18:03:25,064 - INFO - Epoch 5/200, Train Loss: 0.4307, Val Loss: 1.1078
2024-12-27 18:03:25,065 - INFO - Early stopping triggered at epoch 5
2024-12-27 18:03:25,065 - INFO - Training completed in 4.53s
2024-12-27 18:03:25,066 - INFO - Final memory usage: CPU 2979.6 MB, GPU 48.4 MB
2024-12-27 18:03:25,067 - INFO - Model training completed in 4.53s
2024-12-27 18:03:25,104 - INFO - Prediction completed in 0.04s
2024-12-27 18:03:25,115 - INFO - Poison rate 0.01 completed in 14.56s
2024-12-27 18:03:25,115 - INFO - 
Processing poison rate: 0.03
2024-12-27 18:03:25,117 - INFO - Total number of labels flipped: 589
2024-12-27 18:03:25,117 - INFO - Label flipping completed in 0.00s
2024-12-27 18:03:25,118 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:03:25,118 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:03:26,987 - INFO - Feature scaling completed in 1.87s
2024-12-27 18:03:26,987 - INFO - Starting feature selection (k=50)
2024-12-27 18:03:27,037 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 18:03:27,038 - INFO - Starting anomaly detection
2024-12-27 18:03:35,473 - INFO - Anomaly detection completed in 8.44s
2024-12-27 18:03:35,474 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:03:35,474 - INFO - Total fit_transform time: 10.36s
2024-12-27 18:03:35,474 - INFO - Training set processing completed in 10.36s
2024-12-27 18:03:35,475 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:03:35,475 - INFO - Memory usage at start_fit: CPU 2884.2 MB, GPU 48.1 MB
2024-12-27 18:03:35,476 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:03:35,477 - INFO - Number of unique classes: 43
2024-12-27 18:03:35,814 - INFO - Fitted scaler and transformed data
2024-12-27 18:03:35,815 - INFO - Scaling time: 0.34s
2024-12-27 18:03:36,505 - INFO - Epoch 1/200, Train Loss: 1.8331, Val Loss: 1.4093
2024-12-27 18:03:37,300 - INFO - Epoch 2/200, Train Loss: 0.9827, Val Loss: 1.3189
2024-12-27 18:03:38,193 - INFO - Epoch 3/200, Train Loss: 0.7984, Val Loss: 1.3494
2024-12-27 18:03:39,042 - INFO - Epoch 4/200, Train Loss: 0.6422, Val Loss: 1.4809
2024-12-27 18:03:39,042 - INFO - Early stopping triggered at epoch 4
2024-12-27 18:03:39,043 - INFO - Training completed in 3.57s
2024-12-27 18:03:39,043 - INFO - Final memory usage: CPU 2981.5 MB, GPU 48.4 MB
2024-12-27 18:03:39,044 - INFO - Model training completed in 3.57s
2024-12-27 18:03:39,077 - INFO - Prediction completed in 0.03s
2024-12-27 18:03:39,089 - INFO - Poison rate 0.03 completed in 13.97s
2024-12-27 18:03:39,089 - INFO - 
Processing poison rate: 0.05
2024-12-27 18:03:39,091 - INFO - Total number of labels flipped: 987
2024-12-27 18:03:39,091 - INFO - Label flipping completed in 0.00s
2024-12-27 18:03:39,091 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:03:39,091 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:03:41,075 - INFO - Feature scaling completed in 1.98s
2024-12-27 18:03:41,075 - INFO - Starting feature selection (k=50)
2024-12-27 18:03:41,129 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 18:03:41,130 - INFO - Starting anomaly detection
2024-12-27 18:03:49,118 - INFO - Anomaly detection completed in 7.99s
2024-12-27 18:03:49,119 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:03:49,119 - INFO - Total fit_transform time: 10.03s
2024-12-27 18:03:49,119 - INFO - Training set processing completed in 10.03s
2024-12-27 18:03:49,119 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:03:49,121 - INFO - Memory usage at start_fit: CPU 2885.7 MB, GPU 48.1 MB
2024-12-27 18:03:49,121 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:03:49,124 - INFO - Number of unique classes: 43
2024-12-27 18:03:49,487 - INFO - Fitted scaler and transformed data
2024-12-27 18:03:49,487 - INFO - Scaling time: 0.36s
2024-12-27 18:03:50,211 - INFO - Epoch 1/200, Train Loss: 2.0225, Val Loss: 1.5024
2024-12-27 18:03:51,050 - INFO - Epoch 2/200, Train Loss: 1.1553, Val Loss: 1.4475
2024-12-27 18:03:51,667 - INFO - Epoch 3/200, Train Loss: 0.9147, Val Loss: 1.5070
2024-12-27 18:03:52,175 - INFO - Epoch 4/200, Train Loss: 0.8304, Val Loss: 1.5385
2024-12-27 18:03:52,175 - INFO - Early stopping triggered at epoch 4
2024-12-27 18:03:52,175 - INFO - Training completed in 3.06s
2024-12-27 18:03:52,176 - INFO - Final memory usage: CPU 2982.2 MB, GPU 48.4 MB
2024-12-27 18:03:52,176 - INFO - Model training completed in 3.06s
2024-12-27 18:03:52,219 - INFO - Prediction completed in 0.04s
2024-12-27 18:03:52,231 - INFO - Poison rate 0.05 completed in 13.14s
2024-12-27 18:03:52,231 - INFO - 
Processing poison rate: 0.07
2024-12-27 18:03:52,233 - INFO - Total number of labels flipped: 1374
2024-12-27 18:03:52,233 - INFO - Label flipping completed in 0.00s
2024-12-27 18:03:52,233 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:03:52,233 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:03:54,058 - INFO - Feature scaling completed in 1.82s
2024-12-27 18:03:54,058 - INFO - Starting feature selection (k=50)
2024-12-27 18:03:54,109 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 18:03:54,109 - INFO - Starting anomaly detection
2024-12-27 18:04:01,771 - INFO - Anomaly detection completed in 7.66s
2024-12-27 18:04:01,772 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:04:01,772 - INFO - Total fit_transform time: 9.54s
2024-12-27 18:04:01,773 - INFO - Training set processing completed in 9.54s
2024-12-27 18:04:01,773 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:04:01,774 - INFO - Memory usage at start_fit: CPU 2886.3 MB, GPU 48.1 MB
2024-12-27 18:04:01,774 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:04:01,775 - INFO - Number of unique classes: 43
2024-12-27 18:04:02,151 - INFO - Fitted scaler and transformed data
2024-12-27 18:04:02,151 - INFO - Scaling time: 0.38s
2024-12-27 18:04:02,675 - INFO - Epoch 1/200, Train Loss: 2.1757, Val Loss: 1.8037
2024-12-27 18:04:03,159 - INFO - Epoch 2/200, Train Loss: 1.3014, Val Loss: 1.6964
2024-12-27 18:04:03,666 - INFO - Epoch 3/200, Train Loss: 1.0799, Val Loss: 1.7159
2024-12-27 18:04:04,173 - INFO - Epoch 4/200, Train Loss: 0.9383, Val Loss: 1.8188
2024-12-27 18:04:04,173 - INFO - Early stopping triggered at epoch 4
2024-12-27 18:04:04,173 - INFO - Training completed in 2.40s
2024-12-27 18:04:04,174 - INFO - Final memory usage: CPU 2984.6 MB, GPU 48.4 MB
2024-12-27 18:04:04,175 - INFO - Model training completed in 2.40s
2024-12-27 18:04:04,206 - INFO - Prediction completed in 0.03s
2024-12-27 18:04:04,222 - INFO - Poison rate 0.07 completed in 11.99s
2024-12-27 18:04:04,223 - INFO - 
Processing poison rate: 0.1
2024-12-27 18:04:04,225 - INFO - Total number of labels flipped: 1962
2024-12-27 18:04:04,225 - INFO - Label flipping completed in 0.00s
2024-12-27 18:04:04,225 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:04:04,225 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:04:06,265 - INFO - Feature scaling completed in 2.04s
2024-12-27 18:04:06,266 - INFO - Starting feature selection (k=50)
2024-12-27 18:04:06,317 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 18:04:06,317 - INFO - Starting anomaly detection
2024-12-27 18:04:14,378 - INFO - Anomaly detection completed in 8.06s
2024-12-27 18:04:14,378 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:04:14,379 - INFO - Total fit_transform time: 10.15s
2024-12-27 18:04:14,380 - INFO - Training set processing completed in 10.15s
2024-12-27 18:04:14,380 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:04:14,382 - INFO - Memory usage at start_fit: CPU 2889.7 MB, GPU 48.1 MB
2024-12-27 18:04:14,382 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:04:14,385 - INFO - Number of unique classes: 43
2024-12-27 18:04:14,733 - INFO - Fitted scaler and transformed data
2024-12-27 18:04:14,733 - INFO - Scaling time: 0.35s
2024-12-27 18:04:15,211 - INFO - Epoch 1/200, Train Loss: 2.3811, Val Loss: 2.0398
2024-12-27 18:04:15,744 - INFO - Epoch 2/200, Train Loss: 1.4847, Val Loss: 2.0634
2024-12-27 18:04:16,267 - INFO - Epoch 3/200, Train Loss: 1.2354, Val Loss: 2.0328
2024-12-27 18:04:16,267 - INFO - Early stopping triggered at epoch 3
2024-12-27 18:04:16,268 - INFO - Training completed in 1.89s
2024-12-27 18:04:16,268 - INFO - Final memory usage: CPU 2986.2 MB, GPU 48.4 MB
2024-12-27 18:04:16,269 - INFO - Model training completed in 1.89s
2024-12-27 18:04:16,301 - INFO - Prediction completed in 0.03s
2024-12-27 18:04:16,312 - INFO - Poison rate 0.1 completed in 12.09s
2024-12-27 18:04:16,312 - INFO - 
Processing poison rate: 0.2
2024-12-27 18:04:16,315 - INFO - Total number of labels flipped: 3925
2024-12-27 18:04:16,316 - INFO - Label flipping completed in 0.00s
2024-12-27 18:04:16,316 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:04:16,316 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:04:18,223 - INFO - Feature scaling completed in 1.91s
2024-12-27 18:04:18,223 - INFO - Starting feature selection (k=50)
2024-12-27 18:04:18,275 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 18:04:18,276 - INFO - Starting anomaly detection
2024-12-27 18:04:26,187 - INFO - Anomaly detection completed in 7.91s
2024-12-27 18:04:26,187 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:04:26,187 - INFO - Total fit_transform time: 9.87s
2024-12-27 18:04:26,188 - INFO - Training set processing completed in 9.87s
2024-12-27 18:04:26,189 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:04:26,189 - INFO - Memory usage at start_fit: CPU 2889.7 MB, GPU 48.1 MB
2024-12-27 18:04:26,190 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:04:26,191 - INFO - Number of unique classes: 43
2024-12-27 18:04:26,557 - INFO - Fitted scaler and transformed data
2024-12-27 18:04:26,557 - INFO - Scaling time: 0.36s
2024-12-27 18:04:27,019 - INFO - Epoch 1/200, Train Loss: 2.9480, Val Loss: 2.5890
2024-12-27 18:04:27,533 - INFO - Epoch 2/200, Train Loss: 1.9552, Val Loss: 2.5063
2024-12-27 18:04:28,048 - INFO - Epoch 3/200, Train Loss: 1.6182, Val Loss: 2.3339
2024-12-27 18:04:28,613 - INFO - Epoch 4/200, Train Loss: 1.3799, Val Loss: 2.3630
2024-12-27 18:04:29,150 - INFO - Epoch 5/200, Train Loss: 1.2681, Val Loss: 2.4191
2024-12-27 18:04:29,151 - INFO - Early stopping triggered at epoch 5
2024-12-27 18:04:29,151 - INFO - Training completed in 2.96s
2024-12-27 18:04:29,151 - INFO - Final memory usage: CPU 2986.4 MB, GPU 48.4 MB
2024-12-27 18:04:29,152 - INFO - Model training completed in 2.96s
2024-12-27 18:04:29,183 - INFO - Prediction completed in 0.03s
2024-12-27 18:04:29,194 - INFO - Poison rate 0.2 completed in 12.88s
2024-12-27 18:04:29,196 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 18:04:29,196 - INFO - Total evaluation time: 129.86s
2024-12-27 18:04:29,202 - INFO - 
Progress: 13.5% - Evaluating GTSRB with RandomForest (standard mode, iteration 1/1)
2024-12-27 18:04:29,260 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 18:04:29,334 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 18:04:29,406 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 18:04:29,407 - INFO - Dataset type: image
2024-12-27 18:04:29,407 - INFO - Sample size: 39209
2024-12-27 18:04:29,407 - INFO - Using device: cuda
2024-12-27 18:04:29,407 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 18:04:29,409 - INFO - Loading datasets...
2024-12-27 18:04:46,776 - INFO - Dataset loading completed in 17.37s
2024-12-27 18:04:46,776 - INFO - Extracting validation features...
2024-12-27 18:04:46,776 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:30,  4.56it/s]Extracting features:   2%|▏         | 3/139 [00:00<00:15,  8.73it/s]Extracting features:   4%|▎         | 5/139 [00:00<00:10, 12.25it/s]Extracting features:   7%|▋         | 10/139 [00:00<00:05, 22.16it/s]Extracting features:  11%|█         | 15/139 [00:00<00:04, 28.98it/s]Extracting features:  14%|█▍        | 20/139 [00:00<00:03, 34.14it/s]Extracting features:  17%|█▋        | 24/139 [00:00<00:03, 34.28it/s]Extracting features:  20%|██        | 28/139 [00:01<00:03, 34.78it/s]Extracting features:  23%|██▎       | 32/139 [00:01<00:03, 34.75it/s]Extracting features:  26%|██▌       | 36/139 [00:01<00:02, 35.97it/s]Extracting features:  29%|██▉       | 40/139 [00:01<00:02, 35.76it/s]Extracting features:  32%|███▏      | 44/139 [00:01<00:02, 36.28it/s]Extracting features:  35%|███▍      | 48/139 [00:01<00:02, 36.33it/s]Extracting features:  37%|███▋      | 52/139 [00:01<00:02, 37.02it/s]Extracting features:  40%|████      | 56/139 [00:01<00:02, 37.30it/s]Extracting features:  43%|████▎     | 60/139 [00:01<00:02, 37.86it/s]Extracting features:  46%|████▌     | 64/139 [00:02<00:01, 38.39it/s]Extracting features:  50%|████▉     | 69/139 [00:02<00:01, 40.27it/s]Extracting features:  53%|█████▎    | 74/139 [00:02<00:01, 41.95it/s]Extracting features:  57%|█████▋    | 79/139 [00:02<00:01, 40.61it/s]Extracting features:  60%|██████    | 84/139 [00:02<00:01, 41.84it/s]Extracting features:  65%|██████▍   | 90/139 [00:02<00:01, 44.35it/s]Extracting features:  68%|██████▊   | 95/139 [00:02<00:01, 42.18it/s]Extracting features:  72%|███████▏  | 100/139 [00:02<00:00, 40.65it/s]Extracting features:  76%|███████▌  | 105/139 [00:02<00:00, 40.05it/s]Extracting features:  79%|███████▉  | 110/139 [00:03<00:00, 38.29it/s]Extracting features:  82%|████████▏ | 114/139 [00:03<00:00, 36.44it/s]Extracting features:  86%|████████▌ | 119/139 [00:03<00:00, 37.84it/s]Extracting features:  88%|████████▊ | 123/139 [00:03<00:00, 35.37it/s]Extracting features:  91%|█████████▏| 127/139 [00:03<00:00, 35.42it/s]Extracting features:  94%|█████████▍| 131/139 [00:03<00:00, 34.26it/s]Extracting features:  97%|█████████▋| 135/139 [00:03<00:00, 34.20it/s]Extracting features: 100%|██████████| 139/139 [00:04<00:00, 34.66it/s]
2024-12-27 18:04:50,796 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 18:04:50,796 - INFO - Validation feature extraction completed in 4.02s
2024-12-27 18:04:50,796 - INFO - Extracting training features...
2024-12-27 18:04:50,796 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<02:10,  4.72it/s]Extracting features:   1%|          | 7/618 [00:00<00:23, 26.13it/s]Extracting features:   2%|▏         | 14/618 [00:00<00:15, 38.93it/s]Extracting features:   3%|▎         | 21/618 [00:00<00:13, 44.80it/s]Extracting features:   5%|▍         | 28/618 [00:00<00:11, 49.65it/s]Extracting features:   6%|▌         | 34/618 [00:00<00:13, 43.00it/s]Extracting features:   7%|▋         | 41/618 [00:00<00:11, 48.89it/s]Extracting features:   8%|▊         | 47/618 [00:01<00:11, 50.79it/s]Extracting features:   9%|▊         | 53/618 [00:01<00:10, 51.89it/s]Extracting features:  10%|▉         | 59/618 [00:01<00:10, 53.60it/s]Extracting features:  11%|█         | 66/618 [00:01<00:09, 55.99it/s]Extracting features:  12%|█▏        | 72/618 [00:01<00:10, 52.62it/s]Extracting features:  13%|█▎        | 78/618 [00:01<00:10, 52.30it/s]Extracting features:  14%|█▍        | 85/618 [00:01<00:09, 55.38it/s]Extracting features:  15%|█▍        | 91/618 [00:01<00:09, 55.52it/s]Extracting features:  16%|█▌        | 97/618 [00:01<00:09, 54.29it/s]Extracting features:  17%|█▋        | 104/618 [00:02<00:09, 55.56it/s]Extracting features:  18%|█▊        | 110/618 [00:02<00:09, 54.61it/s]Extracting features:  19%|█▉        | 116/618 [00:02<00:09, 55.23it/s]Extracting features:  20%|█▉        | 122/618 [00:02<00:09, 53.79it/s]Extracting features:  21%|██        | 128/618 [00:02<00:09, 53.47it/s]Extracting features:  22%|██▏       | 134/618 [00:02<00:09, 49.81it/s]Extracting features:  23%|██▎       | 140/618 [00:02<00:09, 48.26it/s]Extracting features:  24%|██▎       | 146/618 [00:02<00:09, 50.00it/s]Extracting features:  25%|██▍       | 152/618 [00:03<00:08, 52.34it/s]Extracting features:  26%|██▌       | 158/618 [00:03<00:08, 53.94it/s]Extracting features:  27%|██▋       | 164/618 [00:03<00:08, 52.06it/s]Extracting features:  28%|██▊       | 171/618 [00:03<00:08, 55.54it/s]Extracting features:  29%|██▉       | 178/618 [00:03<00:07, 56.37it/s]Extracting features:  30%|██▉       | 184/618 [00:03<00:08, 53.80it/s]Extracting features:  31%|███       | 190/618 [00:03<00:08, 52.50it/s]Extracting features:  32%|███▏      | 196/618 [00:03<00:08, 52.02it/s]Extracting features:  33%|███▎      | 203/618 [00:03<00:07, 55.59it/s]Extracting features:  34%|███▍      | 209/618 [00:04<00:07, 56.14it/s]Extracting features:  35%|███▍      | 215/618 [00:04<00:07, 57.14it/s]Extracting features:  36%|███▌      | 222/618 [00:04<00:06, 59.49it/s]Extracting features:  37%|███▋      | 228/618 [00:04<00:07, 55.61it/s]Extracting features:  38%|███▊      | 235/618 [00:04<00:06, 59.31it/s]Extracting features:  39%|███▉      | 242/618 [00:04<00:06, 61.82it/s]Extracting features:  40%|████      | 249/618 [00:04<00:06, 58.68it/s]Extracting features:  41%|████▏     | 255/618 [00:04<00:06, 59.01it/s]Extracting features:  42%|████▏     | 261/618 [00:04<00:06, 58.11it/s]Extracting features:  43%|████▎     | 267/618 [00:05<00:06, 58.17it/s]Extracting features:  44%|████▍     | 274/618 [00:05<00:05, 60.11it/s]Extracting features:  45%|████▌     | 281/618 [00:05<00:05, 62.27it/s]Extracting features:  47%|████▋     | 288/618 [00:05<00:05, 63.43it/s]Extracting features:  48%|████▊     | 295/618 [00:05<00:05, 63.62it/s]Extracting features:  49%|████▉     | 302/618 [00:05<00:05, 61.63it/s]Extracting features:  50%|█████     | 309/618 [00:05<00:04, 63.60it/s]Extracting features:  51%|█████     | 316/618 [00:05<00:04, 63.11it/s]Extracting features:  52%|█████▏    | 323/618 [00:05<00:05, 57.10it/s]Extracting features:  53%|█████▎    | 329/618 [00:06<00:05, 56.75it/s]Extracting features:  54%|█████▍    | 335/618 [00:06<00:04, 57.35it/s]Extracting features:  55%|█████▌    | 341/618 [00:06<00:04, 57.09it/s]Extracting features:  56%|█████▌    | 347/618 [00:06<00:04, 55.18it/s]Extracting features:  57%|█████▋    | 353/618 [00:06<00:04, 54.34it/s]Extracting features:  58%|█████▊    | 359/618 [00:06<00:04, 54.18it/s]Extracting features:  59%|█████▉    | 365/618 [00:06<00:04, 52.84it/s]Extracting features:  60%|██████    | 371/618 [00:06<00:04, 54.31it/s]Extracting features:  61%|██████    | 377/618 [00:06<00:04, 53.43it/s]Extracting features:  62%|██████▏   | 383/618 [00:07<00:04, 53.60it/s]Extracting features:  63%|██████▎   | 390/618 [00:07<00:04, 56.57it/s]Extracting features:  64%|██████▍   | 397/618 [00:07<00:03, 59.57it/s]Extracting features:  65%|██████▌   | 403/618 [00:07<00:03, 57.78it/s]Extracting features:  66%|██████▋   | 410/618 [00:07<00:03, 56.85it/s]Extracting features:  67%|██████▋   | 416/618 [00:07<00:03, 57.14it/s]Extracting features:  68%|██████▊   | 423/618 [00:07<00:03, 58.88it/s]Extracting features:  70%|██████▉   | 431/618 [00:07<00:03, 62.08it/s]Extracting features:  71%|███████   | 438/618 [00:07<00:02, 62.66it/s]Extracting features:  72%|███████▏  | 445/618 [00:08<00:02, 62.17it/s]Extracting features:  73%|███████▎  | 452/618 [00:08<00:02, 60.38it/s]Extracting features:  74%|███████▍  | 459/618 [00:08<00:02, 58.59it/s]Extracting features:  75%|███████▌  | 465/618 [00:08<00:02, 56.63it/s]Extracting features:  76%|███████▌  | 471/618 [00:08<00:02, 53.25it/s]Extracting features:  77%|███████▋  | 477/618 [00:08<00:02, 53.09it/s]Extracting features:  78%|███████▊  | 484/618 [00:08<00:02, 55.49it/s]Extracting features:  79%|███████▉  | 490/618 [00:08<00:02, 52.62it/s]Extracting features:  80%|████████  | 497/618 [00:09<00:02, 53.83it/s]Extracting features:  81%|████████▏ | 503/618 [00:09<00:02, 54.00it/s]Extracting features:  83%|████████▎ | 510/618 [00:09<00:01, 58.07it/s]Extracting features:  83%|████████▎ | 516/618 [00:09<00:01, 58.21it/s]Extracting features:  84%|████████▍ | 522/618 [00:09<00:01, 58.43it/s]Extracting features:  86%|████████▌ | 529/618 [00:09<00:01, 59.97it/s]Extracting features:  87%|████████▋ | 536/618 [00:09<00:01, 56.71it/s]Extracting features:  88%|████████▊ | 543/618 [00:09<00:01, 59.41it/s]Extracting features:  89%|████████▉ | 550/618 [00:10<00:01, 52.43it/s]Extracting features:  90%|████████▉ | 556/618 [00:10<00:01, 52.54it/s]Extracting features:  91%|█████████ | 562/618 [00:10<00:01, 53.86it/s]Extracting features:  92%|█████████▏| 569/618 [00:10<00:00, 55.50it/s]Extracting features:  93%|█████████▎| 576/618 [00:10<00:00, 58.90it/s]Extracting features:  94%|█████████▍| 582/618 [00:10<00:00, 58.17it/s]Extracting features:  95%|█████████▌| 588/618 [00:10<00:00, 53.55it/s]Extracting features:  96%|█████████▌| 594/618 [00:10<00:00, 51.78it/s]Extracting features:  97%|█████████▋| 601/618 [00:10<00:00, 54.64it/s]Extracting features:  98%|█████████▊| 607/618 [00:11<00:00, 55.57it/s]Extracting features:  99%|█████████▉| 613/618 [00:11<00:00, 55.25it/s]Extracting features: 100%|██████████| 618/618 [00:11<00:00, 54.44it/s]
2024-12-27 18:05:02,182 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 18:05:02,183 - INFO - Training feature extraction completed in 11.39s
2024-12-27 18:05:02,183 - INFO - Creating model for classifier: RandomForest
2024-12-27 18:05:02,183 - INFO - Using device: cuda
2024-12-27 18:05:02,183 - INFO - 
Processing poison rate: 0.0
2024-12-27 18:05:02,183 - INFO - Training set processing completed in 0.00s
2024-12-27 18:05:02,183 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 18:05:02,185 - INFO - Memory usage at start_fit: CPU 2887.1 MB, GPU 47.3 MB
2024-12-27 18:05:02,185 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:05:02,469 - INFO - Fitted scaler and transformed data
2024-12-27 18:05:02,470 - INFO - Scaling time: 0.28s
2024-12-27 18:05:02,492 - INFO - Number of unique classes: 43
2024-12-27 18:05:16,728 - INFO - Epoch 1/15, Train Loss: 3.7579, Val Loss: 3.7542
2024-12-27 18:05:29,772 - INFO - Epoch 2/15, Train Loss: 3.7483, Val Loss: 3.7451
2024-12-27 18:05:43,595 - INFO - Epoch 3/15, Train Loss: 3.7366, Val Loss: 3.7345
2024-12-27 18:05:55,613 - INFO - Epoch 4/15, Train Loss: 3.7232, Val Loss: 3.7228
2024-12-27 18:06:08,191 - INFO - Epoch 5/15, Train Loss: 3.7092, Val Loss: 3.7115
2024-12-27 18:06:20,614 - INFO - Epoch 6/15, Train Loss: 3.6962, Val Loss: 3.7017
2024-12-27 18:06:32,811 - INFO - Epoch 7/15, Train Loss: 3.6850, Val Loss: 3.6938
2024-12-27 18:06:44,148 - INFO - Epoch 8/15, Train Loss: 3.6759, Val Loss: 3.6875
2024-12-27 18:06:54,183 - INFO - Epoch 9/15, Train Loss: 3.6688, Val Loss: 3.6826
2024-12-27 18:07:06,400 - INFO - Epoch 10/15, Train Loss: 3.6630, Val Loss: 3.6788
2024-12-27 18:07:20,212 - INFO - Epoch 11/15, Train Loss: 3.6582, Val Loss: 3.6757
2024-12-27 18:07:20,212 - INFO - Early stopping triggered at epoch 11
2024-12-27 18:07:20,212 - INFO - Training completed in 138.03s
2024-12-27 18:07:20,212 - INFO - Final memory usage: CPU 2897.5 MB, GPU 155.0 MB
2024-12-27 18:07:20,213 - INFO - Model training completed in 138.03s
2024-12-27 18:07:20,352 - INFO - Prediction completed in 0.14s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:07:20,364 - INFO - Poison rate 0.0 completed in 138.18s
2024-12-27 18:07:20,365 - INFO - 
Processing poison rate: 0.01
2024-12-27 18:07:20,366 - INFO - Total number of labels flipped: 195
2024-12-27 18:07:20,367 - INFO - Label flipping completed in 0.00s
2024-12-27 18:07:20,367 - INFO - Training set processing completed in 0.00s
2024-12-27 18:07:20,367 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 18:07:20,368 - INFO - Memory usage at start_fit: CPU 2897.5 MB, GPU 55.8 MB
2024-12-27 18:07:20,368 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:07:20,647 - INFO - Fitted scaler and transformed data
2024-12-27 18:07:20,647 - INFO - Scaling time: 0.28s
2024-12-27 18:07:20,682 - INFO - Number of unique classes: 43
2024-12-27 18:07:33,475 - INFO - Epoch 1/15, Train Loss: 3.7580, Val Loss: 3.7542
2024-12-27 18:07:45,782 - INFO - Epoch 2/15, Train Loss: 3.7486, Val Loss: 3.7451
2024-12-27 18:07:56,888 - INFO - Epoch 3/15, Train Loss: 3.7373, Val Loss: 3.7343
2024-12-27 18:08:08,431 - INFO - Epoch 4/15, Train Loss: 3.7243, Val Loss: 3.7224
2024-12-27 18:08:21,775 - INFO - Epoch 5/15, Train Loss: 3.7107, Val Loss: 3.7109
2024-12-27 18:08:33,177 - INFO - Epoch 6/15, Train Loss: 3.6980, Val Loss: 3.7010
2024-12-27 18:08:46,459 - INFO - Epoch 7/15, Train Loss: 3.6871, Val Loss: 3.6929
2024-12-27 18:08:59,649 - INFO - Epoch 8/15, Train Loss: 3.6782, Val Loss: 3.6865
2024-12-27 18:09:10,891 - INFO - Epoch 9/15, Train Loss: 3.6710, Val Loss: 3.6814
2024-12-27 18:09:23,435 - INFO - Epoch 10/15, Train Loss: 3.6651, Val Loss: 3.6774
2024-12-27 18:09:35,743 - INFO - Epoch 11/15, Train Loss: 3.6605, Val Loss: 3.6742
2024-12-27 18:09:35,744 - INFO - Early stopping triggered at epoch 11
2024-12-27 18:09:35,744 - INFO - Training completed in 135.38s
2024-12-27 18:09:35,744 - INFO - Final memory usage: CPU 2903.3 MB, GPU 155.0 MB
2024-12-27 18:09:35,745 - INFO - Model training completed in 135.38s
2024-12-27 18:09:35,873 - INFO - Prediction completed in 0.13s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:09:35,885 - INFO - Poison rate 0.01 completed in 135.52s
2024-12-27 18:09:35,885 - INFO - 
Processing poison rate: 0.03
2024-12-27 18:09:35,887 - INFO - Total number of labels flipped: 590
2024-12-27 18:09:35,888 - INFO - Label flipping completed in 0.00s
2024-12-27 18:09:35,888 - INFO - Training set processing completed in 0.00s
2024-12-27 18:09:35,888 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 18:09:35,889 - INFO - Memory usage at start_fit: CPU 2903.3 MB, GPU 55.8 MB
2024-12-27 18:09:35,889 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:09:36,154 - INFO - Fitted scaler and transformed data
2024-12-27 18:09:36,154 - INFO - Scaling time: 0.27s
2024-12-27 18:09:36,190 - INFO - Number of unique classes: 43
2024-12-27 18:09:48,474 - INFO - Epoch 1/15, Train Loss: 3.7581, Val Loss: 3.7544
2024-12-27 18:10:01,235 - INFO - Epoch 2/15, Train Loss: 3.7487, Val Loss: 3.7455
2024-12-27 18:10:12,332 - INFO - Epoch 3/15, Train Loss: 3.7375, Val Loss: 3.7349
2024-12-27 18:10:26,413 - INFO - Epoch 4/15, Train Loss: 3.7245, Val Loss: 3.7233
2024-12-27 18:10:36,528 - INFO - Epoch 5/15, Train Loss: 3.7108, Val Loss: 3.7118
2024-12-27 18:10:49,594 - INFO - Epoch 6/15, Train Loss: 3.6981, Val Loss: 3.7018
2024-12-27 18:11:00,684 - INFO - Epoch 7/15, Train Loss: 3.6871, Val Loss: 3.6935
2024-12-27 18:11:13,424 - INFO - Epoch 8/15, Train Loss: 3.6782, Val Loss: 3.6870
2024-12-27 18:11:26,335 - INFO - Epoch 9/15, Train Loss: 3.6711, Val Loss: 3.6818
2024-12-27 18:11:41,217 - INFO - Epoch 10/15, Train Loss: 3.6652, Val Loss: 3.6778
2024-12-27 18:11:41,217 - INFO - Early stopping triggered at epoch 10
2024-12-27 18:11:41,217 - INFO - Training completed in 125.33s
2024-12-27 18:11:41,217 - INFO - Final memory usage: CPU 2905.9 MB, GPU 155.0 MB
2024-12-27 18:11:41,218 - INFO - Model training completed in 125.33s
2024-12-27 18:11:41,350 - INFO - Prediction completed in 0.13s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:11:41,362 - INFO - Poison rate 0.03 completed in 125.48s
2024-12-27 18:11:41,363 - INFO - 
Processing poison rate: 0.05
2024-12-27 18:11:41,365 - INFO - Total number of labels flipped: 983
2024-12-27 18:11:41,365 - INFO - Label flipping completed in 0.00s
2024-12-27 18:11:41,365 - INFO - Training set processing completed in 0.00s
2024-12-27 18:11:41,365 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 18:11:41,366 - INFO - Memory usage at start_fit: CPU 2905.9 MB, GPU 55.8 MB
2024-12-27 18:11:41,366 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:11:41,657 - INFO - Fitted scaler and transformed data
2024-12-27 18:11:41,658 - INFO - Scaling time: 0.29s
2024-12-27 18:11:41,693 - INFO - Number of unique classes: 43
2024-12-27 18:11:54,024 - INFO - Epoch 1/15, Train Loss: 3.7581, Val Loss: 3.7545
2024-12-27 18:12:05,354 - INFO - Epoch 2/15, Train Loss: 3.7489, Val Loss: 3.7461
2024-12-27 18:12:16,299 - INFO - Epoch 3/15, Train Loss: 3.7381, Val Loss: 3.7364
2024-12-27 18:12:27,366 - INFO - Epoch 4/15, Train Loss: 3.7257, Val Loss: 3.7258
2024-12-27 18:12:38,243 - INFO - Epoch 5/15, Train Loss: 3.7127, Val Loss: 3.7154
2024-12-27 18:12:50,648 - INFO - Epoch 6/15, Train Loss: 3.7004, Val Loss: 3.7063
2024-12-27 18:13:04,736 - INFO - Epoch 7/15, Train Loss: 3.6898, Val Loss: 3.6989
2024-12-27 18:13:17,886 - INFO - Epoch 8/15, Train Loss: 3.6810, Val Loss: 3.6930
2024-12-27 18:13:31,610 - INFO - Epoch 9/15, Train Loss: 3.6741, Val Loss: 3.6884
2024-12-27 18:13:44,829 - INFO - Epoch 10/15, Train Loss: 3.6684, Val Loss: 3.6848
2024-12-27 18:13:58,984 - INFO - Epoch 11/15, Train Loss: 3.6636, Val Loss: 3.6819
2024-12-27 18:13:58,984 - INFO - Early stopping triggered at epoch 11
2024-12-27 18:13:58,984 - INFO - Training completed in 137.62s
2024-12-27 18:13:58,984 - INFO - Final memory usage: CPU 2907.2 MB, GPU 155.0 MB
2024-12-27 18:13:58,985 - INFO - Model training completed in 137.62s
2024-12-27 18:13:59,160 - INFO - Prediction completed in 0.17s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:13:59,172 - INFO - Poison rate 0.05 completed in 137.81s
2024-12-27 18:13:59,172 - INFO - 
Processing poison rate: 0.07
2024-12-27 18:13:59,175 - INFO - Total number of labels flipped: 1374
2024-12-27 18:13:59,175 - INFO - Label flipping completed in 0.00s
2024-12-27 18:13:59,175 - INFO - Training set processing completed in 0.00s
2024-12-27 18:13:59,175 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 18:13:59,176 - INFO - Memory usage at start_fit: CPU 2907.2 MB, GPU 55.8 MB
2024-12-27 18:13:59,176 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:13:59,438 - INFO - Fitted scaler and transformed data
2024-12-27 18:13:59,438 - INFO - Scaling time: 0.26s
2024-12-27 18:13:59,474 - INFO - Number of unique classes: 43
2024-12-27 18:14:12,140 - INFO - Epoch 1/15, Train Loss: 3.7580, Val Loss: 3.7544
2024-12-27 18:14:25,670 - INFO - Epoch 2/15, Train Loss: 3.7488, Val Loss: 3.7460
2024-12-27 18:14:38,009 - INFO - Epoch 3/15, Train Loss: 3.7381, Val Loss: 3.7364
2024-12-27 18:14:50,641 - INFO - Epoch 4/15, Train Loss: 3.7261, Val Loss: 3.7262
2024-12-27 18:15:02,558 - INFO - Epoch 5/15, Train Loss: 3.7137, Val Loss: 3.7163
2024-12-27 18:15:16,576 - INFO - Epoch 6/15, Train Loss: 3.7021, Val Loss: 3.7076
2024-12-27 18:15:29,069 - INFO - Epoch 7/15, Train Loss: 3.6918, Val Loss: 3.7005
2024-12-27 18:15:43,231 - INFO - Epoch 8/15, Train Loss: 3.6834, Val Loss: 3.6947
2024-12-27 18:15:55,291 - INFO - Epoch 9/15, Train Loss: 3.6764, Val Loss: 3.6902
2024-12-27 18:16:08,219 - INFO - Epoch 10/15, Train Loss: 3.6708, Val Loss: 3.6866
2024-12-27 18:16:08,219 - INFO - Early stopping triggered at epoch 10
2024-12-27 18:16:08,220 - INFO - Training completed in 129.04s
2024-12-27 18:16:08,220 - INFO - Final memory usage: CPU 2916.9 MB, GPU 155.0 MB
2024-12-27 18:16:08,220 - INFO - Model training completed in 129.05s
2024-12-27 18:16:08,378 - INFO - Prediction completed in 0.16s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:16:08,391 - INFO - Poison rate 0.07 completed in 129.22s
2024-12-27 18:16:08,391 - INFO - 
Processing poison rate: 0.1
2024-12-27 18:16:08,393 - INFO - Total number of labels flipped: 1963
2024-12-27 18:16:08,394 - INFO - Label flipping completed in 0.00s
2024-12-27 18:16:08,394 - INFO - Training set processing completed in 0.00s
2024-12-27 18:16:08,394 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 18:16:08,395 - INFO - Memory usage at start_fit: CPU 2916.9 MB, GPU 55.8 MB
2024-12-27 18:16:08,395 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:16:08,676 - INFO - Fitted scaler and transformed data
2024-12-27 18:16:08,677 - INFO - Scaling time: 0.28s
2024-12-27 18:16:08,712 - INFO - Number of unique classes: 43
2024-12-27 18:16:21,815 - INFO - Epoch 1/15, Train Loss: 3.7579, Val Loss: 3.7538
2024-12-27 18:16:36,210 - INFO - Epoch 2/15, Train Loss: 3.7483, Val Loss: 3.7444
2024-12-27 18:16:49,005 - INFO - Epoch 3/15, Train Loss: 3.7369, Val Loss: 3.7338
2024-12-27 18:17:03,904 - INFO - Epoch 4/15, Train Loss: 3.7243, Val Loss: 3.7227
2024-12-27 18:17:16,667 - INFO - Epoch 5/15, Train Loss: 3.7115, Val Loss: 3.7123
2024-12-27 18:17:29,989 - INFO - Epoch 6/15, Train Loss: 3.6996, Val Loss: 3.7034
2024-12-27 18:17:42,713 - INFO - Epoch 7/15, Train Loss: 3.6893, Val Loss: 3.6960
2024-12-27 18:17:58,139 - INFO - Epoch 8/15, Train Loss: 3.6807, Val Loss: 3.6902
2024-12-27 18:18:12,553 - INFO - Epoch 9/15, Train Loss: 3.6738, Val Loss: 3.6856
2024-12-27 18:18:26,678 - INFO - Epoch 10/15, Train Loss: 3.6681, Val Loss: 3.6820
2024-12-27 18:18:38,314 - INFO - Epoch 11/15, Train Loss: 3.6635, Val Loss: 3.6791
2024-12-27 18:18:38,314 - INFO - Early stopping triggered at epoch 11
2024-12-27 18:18:38,314 - INFO - Training completed in 149.92s
2024-12-27 18:18:38,314 - INFO - Final memory usage: CPU 2923.3 MB, GPU 155.0 MB
2024-12-27 18:18:38,315 - INFO - Model training completed in 149.92s
2024-12-27 18:18:38,466 - INFO - Prediction completed in 0.15s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:18:38,480 - INFO - Poison rate 0.1 completed in 150.09s
2024-12-27 18:18:38,480 - INFO - 
Processing poison rate: 0.2
2024-12-27 18:18:38,483 - INFO - Total number of labels flipped: 3924
2024-12-27 18:18:38,483 - INFO - Label flipping completed in 0.00s
2024-12-27 18:18:38,483 - INFO - Training set processing completed in 0.00s
2024-12-27 18:18:38,483 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 18:18:38,484 - INFO - Memory usage at start_fit: CPU 2923.3 MB, GPU 55.8 MB
2024-12-27 18:18:38,484 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:18:38,744 - INFO - Fitted scaler and transformed data
2024-12-27 18:18:38,744 - INFO - Scaling time: 0.26s
2024-12-27 18:18:38,780 - INFO - Number of unique classes: 43
2024-12-27 18:18:52,865 - INFO - Epoch 1/15, Train Loss: 3.7573, Val Loss: 3.7524
2024-12-27 18:19:05,945 - INFO - Epoch 2/15, Train Loss: 3.7449, Val Loss: 3.7387
2024-12-27 18:19:18,362 - INFO - Epoch 3/15, Train Loss: 3.7259, Val Loss: 3.7169
2024-12-27 18:19:30,187 - INFO - Epoch 4/15, Train Loss: 3.6988, Val Loss: 3.6898
2024-12-27 18:19:42,598 - INFO - Epoch 5/15, Train Loss: 3.6716, Val Loss: 3.6676
2024-12-27 18:19:54,858 - INFO - Epoch 6/15, Train Loss: 3.6506, Val Loss: 3.6518
2024-12-27 18:20:09,102 - INFO - Epoch 7/15, Train Loss: 3.6354, Val Loss: 3.6410
2024-12-27 18:20:20,900 - INFO - Epoch 8/15, Train Loss: 3.6242, Val Loss: 3.6333
2024-12-27 18:20:32,317 - INFO - Epoch 9/15, Train Loss: 3.6165, Val Loss: 3.6277
2024-12-27 18:20:43,663 - INFO - Epoch 10/15, Train Loss: 3.6104, Val Loss: 3.6235
2024-12-27 18:20:56,117 - INFO - Epoch 11/15, Train Loss: 3.6061, Val Loss: 3.6204
2024-12-27 18:20:56,117 - INFO - Early stopping triggered at epoch 11
2024-12-27 18:20:56,117 - INFO - Training completed in 137.63s
2024-12-27 18:20:56,118 - INFO - Final memory usage: CPU 2924.8 MB, GPU 155.0 MB
2024-12-27 18:20:56,118 - INFO - Model training completed in 137.63s
2024-12-27 18:20:56,247 - INFO - Prediction completed in 0.13s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:20:56,257 - INFO - Poison rate 0.2 completed in 137.78s
2024-12-27 18:20:56,258 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 18:20:56,258 - INFO - Total evaluation time: 986.85s
2024-12-27 18:20:56,262 - INFO - 
Progress: 14.6% - Evaluating GTSRB with RandomForest (dynadetect mode, iteration 1/1)
2024-12-27 18:20:56,320 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 18:20:56,527 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 18:20:56,637 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 18:20:56,638 - INFO - Dataset type: image
2024-12-27 18:20:56,638 - INFO - Sample size: 39209
2024-12-27 18:20:56,638 - INFO - Using device: cuda
2024-12-27 18:20:56,638 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 18:20:56,640 - INFO - Loading datasets...
2024-12-27 18:21:13,814 - INFO - Dataset loading completed in 17.17s
2024-12-27 18:21:13,814 - INFO - Extracting validation features...
2024-12-27 18:21:13,814 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:28,  4.77it/s]Extracting features:   2%|▏         | 3/139 [00:00<00:14,  9.71it/s]Extracting features:   4%|▎         | 5/139 [00:00<00:10, 12.70it/s]Extracting features:   6%|▌         | 8/139 [00:00<00:07, 18.17it/s]Extracting features:   9%|▉         | 13/139 [00:00<00:04, 27.62it/s]Extracting features:  13%|█▎        | 18/139 [00:00<00:03, 34.22it/s]Extracting features:  17%|█▋        | 23/139 [00:00<00:03, 37.66it/s]Extracting features:  20%|██        | 28/139 [00:00<00:02, 40.43it/s]Extracting features:  24%|██▎       | 33/139 [00:01<00:02, 39.40it/s]Extracting features:  27%|██▋       | 38/139 [00:01<00:02, 36.62it/s]Extracting features:  30%|███       | 42/139 [00:01<00:02, 37.35it/s]Extracting features:  33%|███▎      | 46/139 [00:01<00:02, 37.97it/s]Extracting features:  37%|███▋      | 52/139 [00:01<00:02, 41.75it/s]Extracting features:  42%|████▏     | 58/139 [00:01<00:01, 46.33it/s]Extracting features:  45%|████▌     | 63/139 [00:01<00:01, 44.13it/s]Extracting features:  49%|████▉     | 68/139 [00:01<00:01, 45.21it/s]Extracting features:  53%|█████▎    | 73/139 [00:02<00:01, 43.40it/s]Extracting features:  56%|█████▌    | 78/139 [00:02<00:01, 38.04it/s]Extracting features:  59%|█████▉    | 82/139 [00:02<00:01, 37.40it/s]Extracting features:  63%|██████▎   | 87/139 [00:02<00:01, 39.20it/s]Extracting features:  66%|██████▌   | 92/139 [00:02<00:01, 39.12it/s]Extracting features:  69%|██████▉   | 96/139 [00:02<00:01, 37.79it/s]Extracting features:  72%|███████▏  | 100/139 [00:02<00:01, 38.07it/s]Extracting features:  75%|███████▍  | 104/139 [00:02<00:00, 36.09it/s]Extracting features:  78%|███████▊  | 108/139 [00:03<00:00, 36.53it/s]Extracting features:  82%|████████▏ | 114/139 [00:03<00:00, 40.80it/s]Extracting features:  86%|████████▌ | 119/139 [00:03<00:00, 42.92it/s]Extracting features:  91%|█████████ | 126/139 [00:03<00:00, 49.29it/s]Extracting features:  95%|█████████▍| 132/139 [00:03<00:00, 49.75it/s]Extracting features:  99%|█████████▊| 137/139 [00:03<00:00, 48.55it/s]Extracting features: 100%|██████████| 139/139 [00:03<00:00, 37.53it/s]
2024-12-27 18:21:17,525 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 18:21:17,525 - INFO - Validation feature extraction completed in 3.71s
2024-12-27 18:21:17,526 - INFO - Extracting training features...
2024-12-27 18:21:17,526 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<02:03,  4.99it/s]Extracting features:   1%|          | 6/618 [00:00<00:28, 21.33it/s]Extracting features:   2%|▏         | 10/618 [00:00<00:21, 27.81it/s]Extracting features:   2%|▏         | 14/618 [00:00<00:21, 28.50it/s]Extracting features:   3%|▎         | 18/618 [00:00<00:19, 30.34it/s]Extracting features:   4%|▎         | 22/618 [00:00<00:18, 33.10it/s]Extracting features:   4%|▍         | 26/618 [00:00<00:18, 32.21it/s]Extracting features:   5%|▌         | 31/618 [00:01<00:17, 34.45it/s]Extracting features:   6%|▌         | 35/618 [00:01<00:17, 34.07it/s]Extracting features:   6%|▋         | 39/618 [00:01<00:16, 35.33it/s]Extracting features:   7%|▋         | 43/618 [00:01<00:16, 34.84it/s]Extracting features:   8%|▊         | 47/618 [00:01<00:16, 35.04it/s]Extracting features:   8%|▊         | 51/618 [00:01<00:16, 35.04it/s]Extracting features:   9%|▉         | 55/618 [00:01<00:15, 35.54it/s]Extracting features:  10%|▉         | 59/618 [00:01<00:16, 33.85it/s]Extracting features:  10%|█         | 63/618 [00:01<00:16, 33.58it/s]Extracting features:  11%|█         | 67/618 [00:02<00:16, 33.42it/s]Extracting features:  12%|█▏        | 73/618 [00:02<00:14, 36.36it/s]Extracting features:  12%|█▏        | 77/618 [00:02<00:14, 37.01it/s]Extracting features:  13%|█▎        | 81/618 [00:02<00:14, 36.14it/s]Extracting features:  14%|█▍        | 85/618 [00:02<00:15, 34.15it/s]Extracting features:  14%|█▍        | 89/618 [00:02<00:15, 34.70it/s]Extracting features:  15%|█▌        | 94/618 [00:02<00:14, 37.24it/s]Extracting features:  16%|█▌        | 99/618 [00:02<00:12, 40.09it/s]Extracting features:  17%|█▋        | 104/618 [00:03<00:12, 40.39it/s]Extracting features:  18%|█▊        | 109/618 [00:03<00:12, 39.21it/s]Extracting features:  18%|█▊        | 113/618 [00:03<00:13, 38.50it/s]Extracting features:  19%|█▉        | 118/618 [00:03<00:12, 38.91it/s]Extracting features:  20%|█▉        | 122/618 [00:03<00:12, 38.23it/s]Extracting features:  21%|██        | 127/618 [00:03<00:12, 40.10it/s]Extracting features:  21%|██▏       | 132/618 [00:03<00:12, 38.04it/s]Extracting features:  22%|██▏       | 136/618 [00:03<00:12, 37.24it/s]Extracting features:  23%|██▎       | 140/618 [00:03<00:12, 37.87it/s]Extracting features:  23%|██▎       | 145/618 [00:04<00:11, 40.43it/s]Extracting features:  24%|██▍       | 150/618 [00:04<00:11, 41.60it/s]Extracting features:  25%|██▌       | 155/618 [00:04<00:10, 43.82it/s]Extracting features:  26%|██▌       | 160/618 [00:04<00:10, 44.54it/s]Extracting features:  27%|██▋       | 165/618 [00:04<00:10, 42.33it/s]Extracting features:  28%|██▊       | 170/618 [00:04<00:10, 41.03it/s]Extracting features:  28%|██▊       | 175/618 [00:04<00:10, 42.30it/s]Extracting features:  29%|██▉       | 180/618 [00:04<00:10, 43.42it/s]Extracting features:  30%|██▉       | 185/618 [00:05<00:09, 45.04it/s]Extracting features:  31%|███       | 191/618 [00:05<00:08, 48.27it/s]Extracting features:  32%|███▏      | 196/618 [00:05<00:09, 44.36it/s]Extracting features:  33%|███▎      | 201/618 [00:05<00:09, 42.57it/s]Extracting features:  33%|███▎      | 206/618 [00:05<00:10, 40.81it/s]Extracting features:  34%|███▍      | 211/618 [00:05<00:10, 40.58it/s]Extracting features:  35%|███▌      | 218/618 [00:05<00:08, 46.73it/s]Extracting features:  36%|███▌      | 224/618 [00:05<00:08, 47.71it/s]Extracting features:  37%|███▋      | 229/618 [00:06<00:08, 44.07it/s]Extracting features:  38%|███▊      | 234/618 [00:06<00:09, 41.76it/s]Extracting features:  39%|███▊      | 239/618 [00:06<00:10, 37.01it/s]Extracting features:  39%|███▉      | 243/618 [00:06<00:10, 37.02it/s]Extracting features:  40%|███▉      | 247/618 [00:06<00:09, 37.32it/s]Extracting features:  41%|████      | 251/618 [00:06<00:09, 36.90it/s]Extracting features:  41%|████▏     | 255/618 [00:06<00:09, 36.48it/s]Extracting features:  42%|████▏     | 259/618 [00:06<00:09, 35.99it/s]Extracting features:  43%|████▎     | 263/618 [00:06<00:09, 36.14it/s]Extracting features:  43%|████▎     | 268/618 [00:07<00:09, 37.16it/s]Extracting features:  44%|████▍     | 273/618 [00:07<00:08, 39.13it/s]Extracting features:  45%|████▍     | 278/618 [00:07<00:08, 39.72it/s]Extracting features:  46%|████▌     | 282/618 [00:07<00:08, 37.82it/s]Extracting features:  46%|████▋     | 286/618 [00:07<00:09, 36.54it/s]Extracting features:  47%|████▋     | 290/618 [00:07<00:09, 35.92it/s]Extracting features:  48%|████▊     | 296/618 [00:07<00:08, 39.53it/s]Extracting features:  49%|████▊     | 301/618 [00:07<00:07, 39.90it/s]Extracting features:  49%|████▉     | 305/618 [00:08<00:07, 39.85it/s]Extracting features:  50%|█████     | 310/618 [00:08<00:07, 39.72it/s]Extracting features:  51%|█████     | 314/618 [00:08<00:07, 39.13it/s]Extracting features:  52%|█████▏    | 319/618 [00:08<00:07, 39.14it/s]Extracting features:  52%|█████▏    | 324/618 [00:08<00:07, 41.90it/s]Extracting features:  53%|█████▎    | 329/618 [00:08<00:07, 40.88it/s]Extracting features:  54%|█████▍    | 334/618 [00:08<00:07, 39.24it/s]Extracting features:  55%|█████▍    | 338/618 [00:08<00:07, 36.47it/s]Extracting features:  55%|█████▌    | 342/618 [00:09<00:07, 36.28it/s]Extracting features:  56%|█████▌    | 346/618 [00:09<00:08, 33.99it/s]Extracting features:  57%|█████▋    | 350/618 [00:09<00:08, 30.42it/s]Extracting features:  57%|█████▋    | 354/618 [00:09<00:08, 32.66it/s]Extracting features:  58%|█████▊    | 359/618 [00:09<00:07, 35.23it/s]Extracting features:  59%|█████▊    | 363/618 [00:09<00:07, 34.57it/s]Extracting features:  60%|█████▉    | 368/618 [00:09<00:07, 35.38it/s]Extracting features:  60%|██████    | 372/618 [00:09<00:07, 34.21it/s]Extracting features:  61%|██████    | 376/618 [00:10<00:06, 34.93it/s]Extracting features:  61%|██████▏   | 380/618 [00:10<00:06, 35.76it/s]Extracting features:  62%|██████▏   | 384/618 [00:10<00:06, 35.96it/s]Extracting features:  63%|██████▎   | 388/618 [00:10<00:06, 35.10it/s]Extracting features:  63%|██████▎   | 392/618 [00:10<00:06, 34.67it/s]Extracting features:  64%|██████▍   | 397/618 [00:10<00:05, 37.14it/s]Extracting features:  65%|██████▌   | 402/618 [00:10<00:05, 38.81it/s]Extracting features:  66%|██████▌   | 406/618 [00:10<00:05, 37.51it/s]Extracting features:  67%|██████▋   | 411/618 [00:10<00:05, 40.45it/s]Extracting features:  67%|██████▋   | 416/618 [00:11<00:04, 41.34it/s]Extracting features:  68%|██████▊   | 421/618 [00:11<00:04, 40.32it/s]Extracting features:  69%|██████▉   | 427/618 [00:11<00:04, 42.75it/s]Extracting features:  70%|██████▉   | 432/618 [00:11<00:04, 40.64it/s]Extracting features:  71%|███████   | 437/618 [00:11<00:04, 40.79it/s]Extracting features:  72%|███████▏  | 442/618 [00:11<00:04, 39.63it/s]Extracting features:  72%|███████▏  | 446/618 [00:11<00:04, 37.84it/s]Extracting features:  73%|███████▎  | 450/618 [00:11<00:04, 38.27it/s]Extracting features:  73%|███████▎  | 454/618 [00:12<00:04, 37.74it/s]Extracting features:  74%|███████▍  | 459/618 [00:12<00:04, 38.95it/s]Extracting features:  75%|███████▌  | 464/618 [00:12<00:03, 40.64it/s]Extracting features:  76%|███████▌  | 469/618 [00:12<00:03, 39.81it/s]Extracting features:  77%|███████▋  | 473/618 [00:12<00:03, 39.19it/s]Extracting features:  78%|███████▊  | 479/618 [00:12<00:03, 41.29it/s]Extracting features:  78%|███████▊  | 484/618 [00:12<00:03, 40.31it/s]Extracting features:  79%|███████▉  | 489/618 [00:12<00:03, 39.24it/s]Extracting features:  80%|███████▉  | 494/618 [00:13<00:03, 39.65it/s]Extracting features:  81%|████████  | 499/618 [00:13<00:02, 39.98it/s]Extracting features:  82%|████████▏ | 504/618 [00:13<00:02, 40.19it/s]Extracting features:  82%|████████▏ | 509/618 [00:13<00:02, 38.59it/s]Extracting features:  83%|████████▎ | 513/618 [00:13<00:02, 38.52it/s]Extracting features:  84%|████████▍ | 518/618 [00:13<00:02, 41.50it/s]Extracting features:  85%|████████▍ | 523/618 [00:13<00:02, 40.00it/s]Extracting features:  85%|████████▌ | 528/618 [00:13<00:02, 40.17it/s]Extracting features:  86%|████████▌ | 533/618 [00:14<00:02, 39.04it/s]Extracting features:  87%|████████▋ | 537/618 [00:14<00:02, 38.49it/s]Extracting features:  88%|████████▊ | 542/618 [00:14<00:01, 41.34it/s]Extracting features:  89%|████████▊ | 547/618 [00:14<00:01, 41.11it/s]Extracting features:  89%|████████▉ | 552/618 [00:14<00:01, 39.21it/s]Extracting features:  90%|████████▉ | 556/618 [00:14<00:01, 38.97it/s]Extracting features:  91%|█████████ | 561/618 [00:14<00:01, 39.73it/s]Extracting features:  91%|█████████▏| 565/618 [00:14<00:01, 38.76it/s]Extracting features:  92%|█████████▏| 569/618 [00:14<00:01, 37.81it/s]Extracting features:  93%|█████████▎| 573/618 [00:15<00:01, 35.63it/s]Extracting features:  93%|█████████▎| 577/618 [00:15<00:01, 35.89it/s]Extracting features:  94%|█████████▍| 581/618 [00:15<00:01, 34.28it/s]Extracting features:  95%|█████████▍| 585/618 [00:15<00:00, 34.40it/s]Extracting features:  95%|█████████▌| 589/618 [00:15<00:00, 35.21it/s]Extracting features:  96%|█████████▌| 593/618 [00:15<00:00, 33.74it/s]Extracting features:  97%|█████████▋| 597/618 [00:15<00:00, 34.89it/s]Extracting features:  97%|█████████▋| 602/618 [00:15<00:00, 37.00it/s]Extracting features:  98%|█████████▊| 606/618 [00:15<00:00, 37.32it/s]Extracting features:  99%|█████████▊| 610/618 [00:16<00:00, 37.74it/s]Extracting features: 100%|██████████| 618/618 [00:16<00:00, 43.57it/s]Extracting features: 100%|██████████| 618/618 [00:16<00:00, 37.91it/s]
2024-12-27 18:21:33,870 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 18:21:33,871 - INFO - Training feature extraction completed in 16.34s
2024-12-27 18:21:33,871 - INFO - Creating model for classifier: RandomForest
2024-12-27 18:21:33,871 - INFO - Using device: cuda
2024-12-27 18:21:33,871 - INFO - 
Processing poison rate: 0.0
2024-12-27 18:21:33,871 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:21:33,871 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:21:35,707 - INFO - Feature scaling completed in 1.84s
2024-12-27 18:21:35,707 - INFO - Starting feature selection (k=50)
2024-12-27 18:21:35,737 - INFO - Feature selection completed in 0.03s. Output shape: (19755, 50)
2024-12-27 18:21:35,737 - INFO - Starting anomaly detection
2024-12-27 18:21:43,825 - INFO - Anomaly detection completed in 8.09s
2024-12-27 18:21:43,825 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:21:43,825 - INFO - Total fit_transform time: 9.95s
2024-12-27 18:21:43,825 - INFO - Training set processing completed in 9.95s
2024-12-27 18:21:43,826 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 18:21:43,826 - INFO - Memory usage at start_fit: CPU 2919.0 MB, GPU 47.3 MB
2024-12-27 18:21:43,827 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:21:44,079 - INFO - Fitted scaler and transformed data
2024-12-27 18:21:44,079 - INFO - Scaling time: 0.25s
2024-12-27 18:21:44,099 - INFO - Number of unique classes: 43
2024-12-27 18:22:00,812 - INFO - Epoch 1/15, Train Loss: 3.5717, Val Loss: 3.7539
2024-12-27 18:22:15,246 - INFO - Epoch 2/15, Train Loss: 3.5622, Val Loss: 3.7443
2024-12-27 18:22:31,959 - INFO - Epoch 3/15, Train Loss: 3.5509, Val Loss: 3.7330
2024-12-27 18:22:46,241 - INFO - Epoch 4/15, Train Loss: 3.5381, Val Loss: 3.7211
2024-12-27 18:23:01,320 - INFO - Epoch 5/15, Train Loss: 3.5250, Val Loss: 3.7097
2024-12-27 18:23:15,421 - INFO - Epoch 6/15, Train Loss: 3.5129, Val Loss: 3.6998
2024-12-27 18:23:29,222 - INFO - Epoch 7/15, Train Loss: 3.5026, Val Loss: 3.6917
2024-12-27 18:23:42,767 - INFO - Epoch 8/15, Train Loss: 3.4940, Val Loss: 3.6852
2024-12-27 18:23:56,514 - INFO - Epoch 9/15, Train Loss: 3.4871, Val Loss: 3.6802
2024-12-27 18:24:10,692 - INFO - Epoch 10/15, Train Loss: 3.4816, Val Loss: 3.6762
2024-12-27 18:24:25,774 - INFO - Epoch 11/15, Train Loss: 3.4771, Val Loss: 3.6729
2024-12-27 18:24:25,775 - INFO - Early stopping triggered at epoch 11
2024-12-27 18:24:25,775 - INFO - Training completed in 161.95s
2024-12-27 18:24:25,775 - INFO - Final memory usage: CPU 2925.5 MB, GPU 155.0 MB
2024-12-27 18:24:25,775 - INFO - Model training completed in 161.95s
2024-12-27 18:24:25,975 - INFO - Prediction completed in 0.20s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:24:25,988 - INFO - Poison rate 0.0 completed in 172.12s
2024-12-27 18:24:25,988 - INFO - 
Processing poison rate: 0.01
2024-12-27 18:24:25,990 - INFO - Total number of labels flipped: 196
2024-12-27 18:24:25,990 - INFO - Label flipping completed in 0.00s
2024-12-27 18:24:25,990 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:24:25,990 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:24:27,925 - INFO - Feature scaling completed in 1.94s
2024-12-27 18:24:27,926 - INFO - Starting feature selection (k=50)
2024-12-27 18:24:27,976 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 18:24:27,976 - INFO - Starting anomaly detection
2024-12-27 18:24:36,221 - INFO - Anomaly detection completed in 8.24s
2024-12-27 18:24:36,221 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:24:36,221 - INFO - Total fit_transform time: 10.23s
2024-12-27 18:24:36,221 - INFO - Training set processing completed in 10.23s
2024-12-27 18:24:36,222 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 18:24:36,223 - INFO - Memory usage at start_fit: CPU 2925.5 MB, GPU 55.8 MB
2024-12-27 18:24:36,223 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:24:36,481 - INFO - Fitted scaler and transformed data
2024-12-27 18:24:36,482 - INFO - Scaling time: 0.26s
2024-12-27 18:24:36,502 - INFO - Number of unique classes: 43
2024-12-27 18:24:50,993 - INFO - Epoch 1/15, Train Loss: 3.5706, Val Loss: 3.7540
2024-12-27 18:25:03,476 - INFO - Epoch 2/15, Train Loss: 3.5615, Val Loss: 3.7445
2024-12-27 18:25:14,810 - INFO - Epoch 3/15, Train Loss: 3.5504, Val Loss: 3.7334
2024-12-27 18:25:28,509 - INFO - Epoch 4/15, Train Loss: 3.5377, Val Loss: 3.7215
2024-12-27 18:25:41,737 - INFO - Epoch 5/15, Train Loss: 3.5244, Val Loss: 3.7101
2024-12-27 18:25:54,936 - INFO - Epoch 6/15, Train Loss: 3.5121, Val Loss: 3.7003
2024-12-27 18:26:08,037 - INFO - Epoch 7/15, Train Loss: 3.5014, Val Loss: 3.6925
2024-12-27 18:26:21,206 - INFO - Epoch 8/15, Train Loss: 3.4929, Val Loss: 3.6863
2024-12-27 18:26:32,710 - INFO - Epoch 9/15, Train Loss: 3.4859, Val Loss: 3.6815
2024-12-27 18:26:46,598 - INFO - Epoch 10/15, Train Loss: 3.4802, Val Loss: 3.6777
2024-12-27 18:27:00,800 - INFO - Epoch 11/15, Train Loss: 3.4758, Val Loss: 3.6746
2024-12-27 18:27:00,800 - INFO - Early stopping triggered at epoch 11
2024-12-27 18:27:00,800 - INFO - Training completed in 144.58s
2024-12-27 18:27:00,801 - INFO - Final memory usage: CPU 2925.5 MB, GPU 155.0 MB
2024-12-27 18:27:00,801 - INFO - Model training completed in 144.58s
2024-12-27 18:27:01,063 - INFO - Prediction completed in 0.26s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:27:01,075 - INFO - Poison rate 0.01 completed in 155.09s
2024-12-27 18:27:01,075 - INFO - 
Processing poison rate: 0.03
2024-12-27 18:27:01,078 - INFO - Total number of labels flipped: 589
2024-12-27 18:27:01,078 - INFO - Label flipping completed in 0.00s
2024-12-27 18:27:01,078 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:27:01,078 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:27:03,006 - INFO - Feature scaling completed in 1.93s
2024-12-27 18:27:03,006 - INFO - Starting feature selection (k=50)
2024-12-27 18:27:03,056 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 18:27:03,057 - INFO - Starting anomaly detection
2024-12-27 18:27:09,596 - INFO - Anomaly detection completed in 6.54s
2024-12-27 18:27:09,597 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:27:09,597 - INFO - Total fit_transform time: 8.52s
2024-12-27 18:27:09,597 - INFO - Training set processing completed in 8.52s
2024-12-27 18:27:09,597 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 18:27:09,598 - INFO - Memory usage at start_fit: CPU 2925.5 MB, GPU 55.8 MB
2024-12-27 18:27:09,599 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:27:09,899 - INFO - Fitted scaler and transformed data
2024-12-27 18:27:09,900 - INFO - Scaling time: 0.30s
2024-12-27 18:27:09,920 - INFO - Number of unique classes: 43
2024-12-27 18:27:23,284 - INFO - Epoch 1/15, Train Loss: 3.5744, Val Loss: 3.7545
2024-12-27 18:27:38,519 - INFO - Epoch 2/15, Train Loss: 3.5655, Val Loss: 3.7460
2024-12-27 18:27:51,307 - INFO - Epoch 3/15, Train Loss: 3.5548, Val Loss: 3.7360
2024-12-27 18:28:02,813 - INFO - Epoch 4/15, Train Loss: 3.5427, Val Loss: 3.7253
2024-12-27 18:28:15,064 - INFO - Epoch 5/15, Train Loss: 3.5299, Val Loss: 3.7146
2024-12-27 18:28:28,544 - INFO - Epoch 6/15, Train Loss: 3.5178, Val Loss: 3.7053
2024-12-27 18:28:41,829 - INFO - Epoch 7/15, Train Loss: 3.5075, Val Loss: 3.6977
2024-12-27 18:28:54,603 - INFO - Epoch 8/15, Train Loss: 3.4990, Val Loss: 3.6917
2024-12-27 18:29:06,360 - INFO - Epoch 9/15, Train Loss: 3.4920, Val Loss: 3.6869
2024-12-27 18:29:21,349 - INFO - Epoch 10/15, Train Loss: 3.4866, Val Loss: 3.6832
2024-12-27 18:29:33,730 - INFO - Epoch 11/15, Train Loss: 3.4822, Val Loss: 3.6802
2024-12-27 18:29:33,730 - INFO - Early stopping triggered at epoch 11
2024-12-27 18:29:33,730 - INFO - Training completed in 144.13s
2024-12-27 18:29:33,731 - INFO - Final memory usage: CPU 2925.6 MB, GPU 155.0 MB
2024-12-27 18:29:33,731 - INFO - Model training completed in 144.13s
2024-12-27 18:29:33,991 - INFO - Prediction completed in 0.26s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:29:34,003 - INFO - Poison rate 0.03 completed in 152.93s
2024-12-27 18:29:34,004 - INFO - 
Processing poison rate: 0.05
2024-12-27 18:29:34,006 - INFO - Total number of labels flipped: 983
2024-12-27 18:29:34,006 - INFO - Label flipping completed in 0.00s
2024-12-27 18:29:34,006 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:29:34,006 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:29:35,965 - INFO - Feature scaling completed in 1.96s
2024-12-27 18:29:35,965 - INFO - Starting feature selection (k=50)
2024-12-27 18:29:36,016 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 18:29:36,016 - INFO - Starting anomaly detection
2024-12-27 18:29:42,895 - INFO - Anomaly detection completed in 6.88s
2024-12-27 18:29:42,895 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:29:42,896 - INFO - Total fit_transform time: 8.89s
2024-12-27 18:29:42,896 - INFO - Training set processing completed in 8.89s
2024-12-27 18:29:42,896 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 18:29:42,897 - INFO - Memory usage at start_fit: CPU 2925.6 MB, GPU 55.8 MB
2024-12-27 18:29:42,897 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:29:43,176 - INFO - Fitted scaler and transformed data
2024-12-27 18:29:43,176 - INFO - Scaling time: 0.28s
2024-12-27 18:29:43,196 - INFO - Number of unique classes: 43
2024-12-27 18:29:54,406 - INFO - Epoch 1/15, Train Loss: 3.5689, Val Loss: 3.7544
2024-12-27 18:30:08,125 - INFO - Epoch 2/15, Train Loss: 3.5602, Val Loss: 3.7458
2024-12-27 18:30:21,202 - INFO - Epoch 3/15, Train Loss: 3.5499, Val Loss: 3.7359
2024-12-27 18:30:34,993 - INFO - Epoch 4/15, Train Loss: 3.5382, Val Loss: 3.7252
2024-12-27 18:30:49,037 - INFO - Epoch 5/15, Train Loss: 3.5259, Val Loss: 3.7149
2024-12-27 18:31:01,712 - INFO - Epoch 6/15, Train Loss: 3.5144, Val Loss: 3.7058
2024-12-27 18:31:14,433 - INFO - Epoch 7/15, Train Loss: 3.5042, Val Loss: 3.6984
2024-12-27 18:31:28,013 - INFO - Epoch 8/15, Train Loss: 3.4959, Val Loss: 3.6925
2024-12-27 18:31:42,629 - INFO - Epoch 9/15, Train Loss: 3.4891, Val Loss: 3.6879
2024-12-27 18:31:57,144 - INFO - Epoch 10/15, Train Loss: 3.4838, Val Loss: 3.6842
2024-12-27 18:32:10,571 - INFO - Epoch 11/15, Train Loss: 3.4794, Val Loss: 3.6813
2024-12-27 18:32:10,572 - INFO - Early stopping triggered at epoch 11
2024-12-27 18:32:10,572 - INFO - Training completed in 147.68s
2024-12-27 18:32:10,572 - INFO - Final memory usage: CPU 2925.6 MB, GPU 155.0 MB
2024-12-27 18:32:10,572 - INFO - Model training completed in 147.68s
2024-12-27 18:32:10,762 - INFO - Prediction completed in 0.19s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:32:10,775 - INFO - Poison rate 0.05 completed in 156.77s
2024-12-27 18:32:10,775 - INFO - 
Processing poison rate: 0.07
2024-12-27 18:32:10,777 - INFO - Total number of labels flipped: 1371
2024-12-27 18:32:10,777 - INFO - Label flipping completed in 0.00s
2024-12-27 18:32:10,777 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:32:10,778 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:32:12,640 - INFO - Feature scaling completed in 1.86s
2024-12-27 18:32:12,640 - INFO - Starting feature selection (k=50)
2024-12-27 18:32:12,694 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 18:32:12,694 - INFO - Starting anomaly detection
2024-12-27 18:32:20,831 - INFO - Anomaly detection completed in 8.14s
2024-12-27 18:32:20,832 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:32:20,832 - INFO - Total fit_transform time: 10.05s
2024-12-27 18:32:20,832 - INFO - Training set processing completed in 10.05s
2024-12-27 18:32:20,832 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 18:32:20,833 - INFO - Memory usage at start_fit: CPU 2925.6 MB, GPU 55.8 MB
2024-12-27 18:32:20,834 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:32:21,080 - INFO - Fitted scaler and transformed data
2024-12-27 18:32:21,080 - INFO - Scaling time: 0.25s
2024-12-27 18:32:21,100 - INFO - Number of unique classes: 43
2024-12-27 18:32:34,952 - INFO - Epoch 1/15, Train Loss: 3.5693, Val Loss: 3.7541
2024-12-27 18:32:47,665 - INFO - Epoch 2/15, Train Loss: 3.5604, Val Loss: 3.7453
2024-12-27 18:33:01,463 - INFO - Epoch 3/15, Train Loss: 3.5501, Val Loss: 3.7355
2024-12-27 18:33:13,601 - INFO - Epoch 4/15, Train Loss: 3.5388, Val Loss: 3.7253
2024-12-27 18:33:26,272 - INFO - Epoch 5/15, Train Loss: 3.5272, Val Loss: 3.7154
2024-12-27 18:33:38,804 - INFO - Epoch 6/15, Train Loss: 3.5161, Val Loss: 3.7068
2024-12-27 18:33:52,216 - INFO - Epoch 7/15, Train Loss: 3.5064, Val Loss: 3.6998
2024-12-27 18:34:03,920 - INFO - Epoch 8/15, Train Loss: 3.4986, Val Loss: 3.6942
2024-12-27 18:34:17,062 - INFO - Epoch 9/15, Train Loss: 3.4920, Val Loss: 3.6897
2024-12-27 18:34:29,932 - INFO - Epoch 10/15, Train Loss: 3.4866, Val Loss: 3.6862
2024-12-27 18:34:29,932 - INFO - Early stopping triggered at epoch 10
2024-12-27 18:34:29,933 - INFO - Training completed in 129.10s
2024-12-27 18:34:29,933 - INFO - Final memory usage: CPU 2925.6 MB, GPU 155.0 MB
2024-12-27 18:34:29,933 - INFO - Model training completed in 129.10s
2024-12-27 18:34:30,134 - INFO - Prediction completed in 0.20s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:34:30,147 - INFO - Poison rate 0.07 completed in 139.37s
2024-12-27 18:34:30,147 - INFO - 
Processing poison rate: 0.1
2024-12-27 18:34:30,150 - INFO - Total number of labels flipped: 1962
2024-12-27 18:34:30,150 - INFO - Label flipping completed in 0.00s
2024-12-27 18:34:30,150 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:34:30,150 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:34:32,066 - INFO - Feature scaling completed in 1.92s
2024-12-27 18:34:32,066 - INFO - Starting feature selection (k=50)
2024-12-27 18:34:32,116 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 18:34:32,117 - INFO - Starting anomaly detection
2024-12-27 18:34:39,545 - INFO - Anomaly detection completed in 7.43s
2024-12-27 18:34:39,545 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:34:39,545 - INFO - Total fit_transform time: 9.40s
2024-12-27 18:34:39,546 - INFO - Training set processing completed in 9.40s
2024-12-27 18:34:39,546 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 18:34:39,547 - INFO - Memory usage at start_fit: CPU 2925.6 MB, GPU 55.8 MB
2024-12-27 18:34:39,547 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:34:39,802 - INFO - Fitted scaler and transformed data
2024-12-27 18:34:39,802 - INFO - Scaling time: 0.26s
2024-12-27 18:34:39,827 - INFO - Number of unique classes: 43
2024-12-27 18:34:53,696 - INFO - Epoch 1/15, Train Loss: 3.5690, Val Loss: 3.7540
2024-12-27 18:35:07,424 - INFO - Epoch 2/15, Train Loss: 3.5599, Val Loss: 3.7449
2024-12-27 18:35:19,714 - INFO - Epoch 3/15, Train Loss: 3.5492, Val Loss: 3.7346
2024-12-27 18:35:36,258 - INFO - Epoch 4/15, Train Loss: 3.5373, Val Loss: 3.7238
2024-12-27 18:35:51,201 - INFO - Epoch 5/15, Train Loss: 3.5253, Val Loss: 3.7137
2024-12-27 18:36:05,215 - INFO - Epoch 6/15, Train Loss: 3.5141, Val Loss: 3.7049
2024-12-27 18:36:17,128 - INFO - Epoch 7/15, Train Loss: 3.5045, Val Loss: 3.6978
2024-12-27 18:36:29,126 - INFO - Epoch 8/15, Train Loss: 3.4963, Val Loss: 3.6922
2024-12-27 18:36:41,538 - INFO - Epoch 9/15, Train Loss: 3.4897, Val Loss: 3.6877
2024-12-27 18:36:53,495 - INFO - Epoch 10/15, Train Loss: 3.4843, Val Loss: 3.6841
2024-12-27 18:37:04,754 - INFO - Epoch 11/15, Train Loss: 3.4800, Val Loss: 3.6812
2024-12-27 18:37:04,754 - INFO - Early stopping triggered at epoch 11
2024-12-27 18:37:04,754 - INFO - Training completed in 145.21s
2024-12-27 18:37:04,754 - INFO - Final memory usage: CPU 2925.6 MB, GPU 155.0 MB
2024-12-27 18:37:04,755 - INFO - Model training completed in 145.21s
2024-12-27 18:37:04,935 - INFO - Prediction completed in 0.18s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:37:04,949 - INFO - Poison rate 0.1 completed in 154.80s
2024-12-27 18:37:04,949 - INFO - 
Processing poison rate: 0.2
2024-12-27 18:37:04,952 - INFO - Total number of labels flipped: 3918
2024-12-27 18:37:04,953 - INFO - Label flipping completed in 0.00s
2024-12-27 18:37:04,953 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:37:04,953 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:37:06,766 - INFO - Feature scaling completed in 1.81s
2024-12-27 18:37:06,766 - INFO - Starting feature selection (k=50)
2024-12-27 18:37:06,819 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 18:37:06,820 - INFO - Starting anomaly detection
2024-12-27 18:37:12,279 - INFO - Anomaly detection completed in 5.46s
2024-12-27 18:37:12,280 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:37:12,280 - INFO - Total fit_transform time: 7.33s
2024-12-27 18:37:12,281 - INFO - Training set processing completed in 7.33s
2024-12-27 18:37:12,283 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 18:37:12,285 - INFO - Memory usage at start_fit: CPU 2925.6 MB, GPU 55.8 MB
2024-12-27 18:37:12,285 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:37:12,566 - INFO - Fitted scaler and transformed data
2024-12-27 18:37:12,566 - INFO - Scaling time: 0.28s
2024-12-27 18:37:12,586 - INFO - Number of unique classes: 43
2024-12-27 18:37:25,131 - INFO - Epoch 1/15, Train Loss: 3.5676, Val Loss: 3.7527
2024-12-27 18:37:38,518 - INFO - Epoch 2/15, Train Loss: 3.5559, Val Loss: 3.7396
2024-12-27 18:37:50,801 - INFO - Epoch 3/15, Train Loss: 3.5381, Val Loss: 3.7189
2024-12-27 18:38:02,975 - INFO - Epoch 4/15, Train Loss: 3.5130, Val Loss: 3.6926
2024-12-27 18:38:14,367 - INFO - Epoch 5/15, Train Loss: 3.4867, Val Loss: 3.6705
2024-12-27 18:38:25,560 - INFO - Epoch 6/15, Train Loss: 3.4667, Val Loss: 3.6546
2024-12-27 18:38:37,911 - INFO - Epoch 7/15, Train Loss: 3.4519, Val Loss: 3.6434
2024-12-27 18:38:49,560 - INFO - Epoch 8/15, Train Loss: 3.4416, Val Loss: 3.6354
2024-12-27 18:39:01,354 - INFO - Epoch 9/15, Train Loss: 3.4339, Val Loss: 3.6296
2024-12-27 18:39:14,598 - INFO - Epoch 10/15, Train Loss: 3.4281, Val Loss: 3.6253
2024-12-27 18:39:25,433 - INFO - Epoch 11/15, Train Loss: 3.4238, Val Loss: 3.6220
2024-12-27 18:39:25,433 - INFO - Early stopping triggered at epoch 11
2024-12-27 18:39:25,433 - INFO - Training completed in 133.15s
2024-12-27 18:39:25,433 - INFO - Final memory usage: CPU 2925.6 MB, GPU 155.0 MB
2024-12-27 18:39:25,434 - INFO - Model training completed in 133.15s
2024-12-27 18:39:25,598 - INFO - Prediction completed in 0.16s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:39:25,608 - INFO - Poison rate 0.2 completed in 140.66s
2024-12-27 18:39:25,609 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 18:39:25,609 - INFO - Total evaluation time: 1108.97s
2024-12-27 18:39:25,621 - INFO - 
Progress: 15.6% - Evaluating GTSRB with KNeighbors (standard mode, iteration 1/1)
2024-12-27 18:39:25,697 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 18:39:25,885 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 18:39:26,011 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 18:39:26,011 - INFO - Dataset type: image
2024-12-27 18:39:26,011 - INFO - Sample size: 39209
2024-12-27 18:39:26,011 - INFO - Using device: cuda
2024-12-27 18:39:26,011 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 18:39:26,016 - INFO - Loading datasets...
2024-12-27 18:39:43,640 - INFO - Dataset loading completed in 17.62s
2024-12-27 18:39:43,641 - INFO - Extracting validation features...
2024-12-27 18:39:43,641 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:28,  4.91it/s]Extracting features:   2%|▏         | 3/139 [00:00<00:13, 10.26it/s]Extracting features:   5%|▌         | 7/139 [00:00<00:06, 19.97it/s]Extracting features:   9%|▊         | 12/139 [00:00<00:04, 29.08it/s]Extracting features:  12%|█▏        | 16/139 [00:00<00:03, 32.35it/s]Extracting features:  14%|█▍        | 20/139 [00:00<00:03, 32.55it/s]Extracting features:  17%|█▋        | 24/139 [00:00<00:03, 33.31it/s]Extracting features:  20%|██        | 28/139 [00:00<00:03, 33.94it/s]Extracting features:  24%|██▎       | 33/139 [00:01<00:02, 38.10it/s]Extracting features:  27%|██▋       | 38/139 [00:01<00:02, 40.22it/s]Extracting features:  31%|███       | 43/139 [00:01<00:02, 42.36it/s]Extracting features:  35%|███▍      | 48/139 [00:01<00:02, 40.35it/s]Extracting features:  39%|███▉      | 54/139 [00:01<00:01, 43.99it/s]Extracting features:  42%|████▏     | 59/139 [00:01<00:01, 45.45it/s]Extracting features:  46%|████▌     | 64/139 [00:01<00:01, 41.92it/s]Extracting features:  50%|████▉     | 69/139 [00:01<00:01, 39.97it/s]Extracting features:  53%|█████▎    | 74/139 [00:02<00:01, 41.80it/s]Extracting features:  57%|█████▋    | 79/139 [00:02<00:01, 38.89it/s]Extracting features:  60%|██████    | 84/139 [00:02<00:01, 41.13it/s]Extracting features:  65%|██████▍   | 90/139 [00:02<00:01, 44.03it/s]Extracting features:  68%|██████▊   | 95/139 [00:02<00:01, 43.09it/s]Extracting features:  72%|███████▏  | 100/139 [00:02<00:00, 41.68it/s]Extracting features:  76%|███████▌  | 105/139 [00:02<00:00, 41.99it/s]Extracting features:  79%|███████▉  | 110/139 [00:02<00:00, 39.31it/s]Extracting features:  83%|████████▎ | 115/139 [00:03<00:00, 41.08it/s]Extracting features:  87%|████████▋ | 121/139 [00:03<00:00, 43.89it/s]Extracting features:  91%|█████████ | 126/139 [00:03<00:00, 44.35it/s]Extracting features:  94%|█████████▍| 131/139 [00:03<00:00, 42.26it/s]Extracting features:  98%|█████████▊| 136/139 [00:03<00:00, 42.27it/s]Extracting features: 100%|██████████| 139/139 [00:03<00:00, 37.52it/s]
2024-12-27 18:39:47,355 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 18:39:47,355 - INFO - Validation feature extraction completed in 3.71s
2024-12-27 18:39:47,355 - INFO - Extracting training features...
2024-12-27 18:39:47,355 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<01:57,  5.26it/s]Extracting features:   1%|          | 7/618 [00:00<00:21, 28.29it/s]Extracting features:   2%|▏         | 11/618 [00:00<00:20, 29.82it/s]Extracting features:   3%|▎         | 16/618 [00:00<00:17, 33.82it/s]Extracting features:   3%|▎         | 20/618 [00:00<00:17, 33.73it/s]Extracting features:   4%|▍         | 24/618 [00:00<00:17, 34.69it/s]Extracting features:   5%|▍         | 28/618 [00:00<00:17, 34.26it/s]Extracting features:   5%|▌         | 32/618 [00:01<00:16, 34.58it/s]Extracting features:   6%|▌         | 37/618 [00:01<00:15, 38.20it/s]Extracting features:   7%|▋         | 41/618 [00:01<00:15, 37.51it/s]Extracting features:   7%|▋         | 46/618 [00:01<00:14, 39.17it/s]Extracting features:   8%|▊         | 51/618 [00:01<00:13, 41.65it/s]Extracting features:   9%|▉         | 56/618 [00:01<00:13, 42.18it/s]Extracting features:  10%|▉         | 61/618 [00:01<00:13, 42.71it/s]Extracting features:  11%|█         | 66/618 [00:01<00:13, 40.92it/s]Extracting features:  11%|█▏        | 71/618 [00:01<00:13, 40.05it/s]Extracting features:  12%|█▏        | 76/618 [00:02<00:12, 41.99it/s]Extracting features:  13%|█▎        | 81/618 [00:02<00:12, 42.67it/s]Extracting features:  14%|█▍        | 86/618 [00:02<00:11, 44.36it/s]Extracting features:  15%|█▍        | 92/618 [00:02<00:10, 47.89it/s]Extracting features:  16%|█▌        | 97/618 [00:02<00:10, 47.60it/s]Extracting features:  17%|█▋        | 102/618 [00:02<00:11, 45.56it/s]Extracting features:  17%|█▋        | 107/618 [00:02<00:11, 45.57it/s]Extracting features:  18%|█▊        | 112/618 [00:02<00:11, 42.20it/s]Extracting features:  19%|█▉        | 117/618 [00:02<00:12, 40.12it/s]Extracting features:  20%|█▉        | 122/618 [00:03<00:12, 40.02it/s]Extracting features:  21%|██        | 127/618 [00:03<00:12, 38.32it/s]Extracting features:  21%|██        | 131/618 [00:03<00:13, 36.43it/s]Extracting features:  22%|██▏       | 135/618 [00:03<00:13, 35.23it/s]Extracting features:  22%|██▏       | 139/618 [00:03<00:13, 36.39it/s]Extracting features:  23%|██▎       | 143/618 [00:03<00:13, 36.18it/s]Extracting features:  24%|██▍       | 147/618 [00:03<00:13, 34.50it/s]Extracting features:  24%|██▍       | 151/618 [00:03<00:13, 34.23it/s]Extracting features:  25%|██▌       | 155/618 [00:04<00:13, 35.56it/s]Extracting features:  26%|██▌       | 159/618 [00:04<00:12, 36.12it/s]Extracting features:  26%|██▋       | 163/618 [00:04<00:12, 37.03it/s]Extracting features:  27%|██▋       | 167/618 [00:04<00:12, 37.00it/s]Extracting features:  28%|██▊       | 171/618 [00:04<00:12, 36.81it/s]Extracting features:  28%|██▊       | 175/618 [00:04<00:12, 35.08it/s]Extracting features:  29%|██▉       | 179/618 [00:04<00:12, 34.97it/s]Extracting features:  30%|██▉       | 183/618 [00:04<00:12, 33.66it/s]Extracting features:  30%|███       | 187/618 [00:04<00:13, 32.91it/s]Extracting features:  31%|███       | 192/618 [00:05<00:11, 36.70it/s]Extracting features:  32%|███▏      | 196/618 [00:05<00:11, 35.32it/s]Extracting features:  32%|███▏      | 200/618 [00:05<00:12, 34.35it/s]Extracting features:  33%|███▎      | 204/618 [00:05<00:11, 34.92it/s]Extracting features:  34%|███▍      | 210/618 [00:05<00:10, 38.84it/s]Extracting features:  35%|███▍      | 215/618 [00:05<00:09, 41.54it/s]Extracting features:  36%|███▌      | 221/618 [00:05<00:08, 46.34it/s]Extracting features:  37%|███▋      | 226/618 [00:05<00:08, 46.23it/s]Extracting features:  37%|███▋      | 231/618 [00:05<00:08, 47.17it/s]Extracting features:  38%|███▊      | 237/618 [00:06<00:08, 46.12it/s]Extracting features:  39%|███▉      | 242/618 [00:06<00:08, 43.36it/s]Extracting features:  40%|████      | 248/618 [00:06<00:07, 47.57it/s]Extracting features:  41%|████      | 254/618 [00:06<00:07, 48.28it/s]Extracting features:  42%|████▏     | 259/618 [00:06<00:07, 47.87it/s]Extracting features:  43%|████▎     | 266/618 [00:06<00:06, 51.44it/s]Extracting features:  44%|████▍     | 272/618 [00:06<00:07, 48.92it/s]Extracting features:  45%|████▍     | 278/618 [00:06<00:06, 49.91it/s]Extracting features:  46%|████▌     | 284/618 [00:07<00:06, 51.27it/s]Extracting features:  47%|████▋     | 290/618 [00:07<00:06, 52.21it/s]Extracting features:  48%|████▊     | 296/618 [00:07<00:05, 53.82it/s]Extracting features:  49%|████▉     | 302/618 [00:07<00:06, 49.96it/s]Extracting features:  50%|████▉     | 308/618 [00:07<00:06, 50.44it/s]Extracting features:  51%|█████     | 314/618 [00:07<00:05, 51.70it/s]Extracting features:  52%|█████▏    | 320/618 [00:07<00:05, 49.97it/s]Extracting features:  53%|█████▎    | 326/618 [00:07<00:05, 49.18it/s]Extracting features:  54%|█████▎    | 331/618 [00:08<00:06, 46.91it/s]Extracting features:  54%|█████▍    | 336/618 [00:08<00:05, 47.59it/s]Extracting features:  55%|█████▌    | 342/618 [00:08<00:05, 50.01it/s]Extracting features:  56%|█████▋    | 348/618 [00:08<00:06, 43.30it/s]Extracting features:  57%|█████▋    | 353/618 [00:08<00:05, 44.28it/s]Extracting features:  58%|█████▊    | 359/618 [00:08<00:05, 47.37it/s]Extracting features:  59%|█████▉    | 365/618 [00:08<00:05, 49.84it/s]Extracting features:  60%|██████    | 371/618 [00:08<00:04, 50.08it/s]Extracting features:  61%|██████    | 377/618 [00:08<00:04, 48.74it/s]Extracting features:  62%|██████▏   | 382/618 [00:09<00:04, 48.06it/s]Extracting features:  63%|██████▎   | 389/618 [00:09<00:04, 50.89it/s]Extracting features:  64%|██████▍   | 395/618 [00:09<00:04, 49.05it/s]Extracting features:  65%|██████▍   | 401/618 [00:09<00:04, 50.47it/s]Extracting features:  66%|██████▌   | 407/618 [00:09<00:04, 48.27it/s]Extracting features:  67%|██████▋   | 412/618 [00:09<00:04, 46.92it/s]Extracting features:  68%|██████▊   | 418/618 [00:09<00:04, 49.39it/s]Extracting features:  68%|██████▊   | 423/618 [00:09<00:04, 48.14it/s]Extracting features:  69%|██████▉   | 428/618 [00:10<00:04, 44.85it/s]Extracting features:  70%|███████   | 433/618 [00:10<00:04, 45.02it/s]Extracting features:  71%|███████   | 439/618 [00:10<00:03, 47.78it/s]Extracting features:  72%|███████▏  | 445/618 [00:10<00:03, 49.40it/s]Extracting features:  73%|███████▎  | 451/618 [00:10<00:03, 50.88it/s]Extracting features:  74%|███████▍  | 458/618 [00:10<00:02, 54.90it/s]Extracting features:  75%|███████▌  | 464/618 [00:10<00:02, 55.97it/s]Extracting features:  76%|███████▌  | 470/618 [00:10<00:02, 52.19it/s]Extracting features:  77%|███████▋  | 476/618 [00:10<00:02, 48.60it/s]Extracting features:  78%|███████▊  | 481/618 [00:11<00:02, 47.82it/s]Extracting features:  79%|███████▉  | 487/618 [00:11<00:02, 49.42it/s]Extracting features:  80%|███████▉  | 493/618 [00:11<00:02, 51.70it/s]Extracting features:  81%|████████  | 499/618 [00:11<00:02, 51.93it/s]Extracting features:  82%|████████▏ | 505/618 [00:11<00:02, 50.68it/s]Extracting features:  83%|████████▎ | 511/618 [00:11<00:02, 50.68it/s]Extracting features:  84%|████████▍ | 518/618 [00:11<00:01, 53.12it/s]Extracting features:  85%|████████▍ | 524/618 [00:11<00:01, 50.56it/s]Extracting features:  86%|████████▌ | 530/618 [00:12<00:01, 48.03it/s]Extracting features:  87%|████████▋ | 535/618 [00:12<00:01, 48.03it/s]Extracting features:  87%|████████▋ | 540/618 [00:12<00:01, 47.81it/s]Extracting features:  88%|████████▊ | 545/618 [00:12<00:01, 46.03it/s]Extracting features:  89%|████████▉ | 552/618 [00:12<00:01, 51.17it/s]Extracting features:  90%|█████████ | 558/618 [00:12<00:01, 49.64it/s]Extracting features:  91%|█████████▏| 564/618 [00:12<00:01, 48.71it/s]Extracting features:  92%|█████████▏| 570/618 [00:12<00:00, 49.98it/s]Extracting features:  93%|█████████▎| 576/618 [00:12<00:00, 50.79it/s]Extracting features:  94%|█████████▍| 582/618 [00:13<00:00, 47.38it/s]Extracting features:  95%|█████████▌| 588/618 [00:13<00:00, 48.87it/s]Extracting features:  96%|█████████▌| 593/618 [00:13<00:00, 48.52it/s]Extracting features:  97%|█████████▋| 599/618 [00:13<00:00, 51.00it/s]Extracting features:  98%|█████████▊| 605/618 [00:13<00:00, 50.38it/s]Extracting features:  99%|█████████▉| 611/618 [00:13<00:00, 51.56it/s]Extracting features: 100%|██████████| 618/618 [00:13<00:00, 51.47it/s]Extracting features: 100%|██████████| 618/618 [00:13<00:00, 44.51it/s]
2024-12-27 18:40:01,274 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 18:40:01,274 - INFO - Training feature extraction completed in 13.92s
2024-12-27 18:40:01,274 - INFO - Creating model for classifier: KNeighbors
2024-12-27 18:40:01,274 - INFO - Using device: cuda
2024-12-27 18:40:01,275 - INFO - 
Processing poison rate: 0.0
2024-12-27 18:40:01,275 - INFO - Training set processing completed in 0.00s
2024-12-27 18:40:01,275 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 18:40:01,276 - INFO - Memory usage at start_fit: CPU 2925.8 MB, GPU 47.3 MB
2024-12-27 18:40:01,277 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:40:01,546 - INFO - Fitted scaler and transformed data
2024-12-27 18:40:01,546 - INFO - Scaling time: 0.27s
2024-12-27 18:40:01,562 - INFO - Training completed in 0.29s
2024-12-27 18:40:01,563 - INFO - Final memory usage: CPU 3030.1 MB, GPU 143.9 MB
2024-12-27 18:40:01,563 - INFO - Model training completed in 0.29s
2024-12-27 18:40:01,697 - INFO - Prediction completed in 0.13s
2024-12-27 18:40:01,709 - INFO - Poison rate 0.0 completed in 0.43s
2024-12-27 18:40:01,709 - INFO - 
Processing poison rate: 0.01
2024-12-27 18:40:01,711 - INFO - Total number of labels flipped: 197
2024-12-27 18:40:01,711 - INFO - Label flipping completed in 0.00s
2024-12-27 18:40:01,711 - INFO - Training set processing completed in 0.00s
2024-12-27 18:40:01,711 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 18:40:01,712 - INFO - Memory usage at start_fit: CPU 2933.7 MB, GPU 143.9 MB
2024-12-27 18:40:01,713 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:40:01,994 - INFO - Fitted scaler and transformed data
2024-12-27 18:40:01,994 - INFO - Scaling time: 0.28s
2024-12-27 18:40:02,010 - INFO - Training completed in 0.30s
2024-12-27 18:40:02,010 - INFO - Final memory usage: CPU 3030.1 MB, GPU 143.9 MB
2024-12-27 18:40:02,011 - INFO - Model training completed in 0.30s
2024-12-27 18:40:02,130 - INFO - Prediction completed in 0.12s
2024-12-27 18:40:02,140 - INFO - Poison rate 0.01 completed in 0.43s
2024-12-27 18:40:02,141 - INFO - 
Processing poison rate: 0.03
2024-12-27 18:40:02,143 - INFO - Total number of labels flipped: 588
2024-12-27 18:40:02,143 - INFO - Label flipping completed in 0.00s
2024-12-27 18:40:02,143 - INFO - Training set processing completed in 0.00s
2024-12-27 18:40:02,143 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 18:40:02,144 - INFO - Memory usage at start_fit: CPU 2933.7 MB, GPU 143.9 MB
2024-12-27 18:40:02,144 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:40:02,421 - INFO - Fitted scaler and transformed data
2024-12-27 18:40:02,421 - INFO - Scaling time: 0.28s
2024-12-27 18:40:02,441 - INFO - Training completed in 0.30s
2024-12-27 18:40:02,444 - INFO - Final memory usage: CPU 3030.1 MB, GPU 143.9 MB
2024-12-27 18:40:02,445 - INFO - Model training completed in 0.30s
2024-12-27 18:40:02,559 - INFO - Prediction completed in 0.11s
2024-12-27 18:40:02,570 - INFO - Poison rate 0.03 completed in 0.43s
2024-12-27 18:40:02,570 - INFO - 
Processing poison rate: 0.05
2024-12-27 18:40:02,572 - INFO - Total number of labels flipped: 985
2024-12-27 18:40:02,572 - INFO - Label flipping completed in 0.00s
2024-12-27 18:40:02,572 - INFO - Training set processing completed in 0.00s
2024-12-27 18:40:02,572 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 18:40:02,573 - INFO - Memory usage at start_fit: CPU 2933.7 MB, GPU 143.9 MB
2024-12-27 18:40:02,573 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:40:02,839 - INFO - Fitted scaler and transformed data
2024-12-27 18:40:02,839 - INFO - Scaling time: 0.27s
2024-12-27 18:40:02,854 - INFO - Training completed in 0.28s
2024-12-27 18:40:02,855 - INFO - Final memory usage: CPU 3030.1 MB, GPU 143.9 MB
2024-12-27 18:40:02,855 - INFO - Model training completed in 0.28s
2024-12-27 18:40:02,968 - INFO - Prediction completed in 0.11s
2024-12-27 18:40:02,980 - INFO - Poison rate 0.05 completed in 0.41s
2024-12-27 18:40:02,980 - INFO - 
Processing poison rate: 0.07
2024-12-27 18:40:02,982 - INFO - Total number of labels flipped: 1376
2024-12-27 18:40:02,983 - INFO - Label flipping completed in 0.00s
2024-12-27 18:40:02,983 - INFO - Training set processing completed in 0.00s
2024-12-27 18:40:02,983 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 18:40:02,984 - INFO - Memory usage at start_fit: CPU 2933.7 MB, GPU 143.9 MB
2024-12-27 18:40:02,984 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:40:03,228 - INFO - Fitted scaler and transformed data
2024-12-27 18:40:03,228 - INFO - Scaling time: 0.24s
2024-12-27 18:40:03,249 - INFO - Training completed in 0.27s
2024-12-27 18:40:03,251 - INFO - Final memory usage: CPU 3030.1 MB, GPU 143.9 MB
2024-12-27 18:40:03,253 - INFO - Model training completed in 0.27s
2024-12-27 18:40:03,370 - INFO - Prediction completed in 0.12s
2024-12-27 18:40:03,381 - INFO - Poison rate 0.07 completed in 0.40s
2024-12-27 18:40:03,381 - INFO - 
Processing poison rate: 0.1
2024-12-27 18:40:03,383 - INFO - Total number of labels flipped: 1968
2024-12-27 18:40:03,383 - INFO - Label flipping completed in 0.00s
2024-12-27 18:40:03,384 - INFO - Training set processing completed in 0.00s
2024-12-27 18:40:03,384 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 18:40:03,384 - INFO - Memory usage at start_fit: CPU 2933.7 MB, GPU 143.9 MB
2024-12-27 18:40:03,385 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:40:03,629 - INFO - Fitted scaler and transformed data
2024-12-27 18:40:03,629 - INFO - Scaling time: 0.24s
2024-12-27 18:40:03,644 - INFO - Training completed in 0.26s
2024-12-27 18:40:03,645 - INFO - Final memory usage: CPU 3030.1 MB, GPU 143.9 MB
2024-12-27 18:40:03,645 - INFO - Model training completed in 0.26s
2024-12-27 18:40:03,765 - INFO - Prediction completed in 0.12s
2024-12-27 18:40:03,776 - INFO - Poison rate 0.1 completed in 0.40s
2024-12-27 18:40:03,777 - INFO - 
Processing poison rate: 0.2
2024-12-27 18:40:03,780 - INFO - Total number of labels flipped: 3930
2024-12-27 18:40:03,780 - INFO - Label flipping completed in 0.00s
2024-12-27 18:40:03,780 - INFO - Training set processing completed in 0.00s
2024-12-27 18:40:03,780 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 18:40:03,781 - INFO - Memory usage at start_fit: CPU 2933.7 MB, GPU 143.9 MB
2024-12-27 18:40:03,781 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:40:04,015 - INFO - Fitted scaler and transformed data
2024-12-27 18:40:04,016 - INFO - Scaling time: 0.23s
2024-12-27 18:40:04,031 - INFO - Training completed in 0.25s
2024-12-27 18:40:04,032 - INFO - Final memory usage: CPU 3030.1 MB, GPU 143.9 MB
2024-12-27 18:40:04,032 - INFO - Model training completed in 0.25s
2024-12-27 18:40:04,148 - INFO - Prediction completed in 0.12s
2024-12-27 18:40:04,165 - INFO - Poison rate 0.2 completed in 0.39s
2024-12-27 18:40:04,169 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 18:40:04,169 - INFO - Total evaluation time: 38.15s
2024-12-27 18:40:04,177 - INFO - 
Progress: 16.7% - Evaluating GTSRB with KNeighbors (dynadetect mode, iteration 1/1)
2024-12-27 18:40:04,236 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 18:40:04,309 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 18:40:04,383 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 18:40:04,384 - INFO - Dataset type: image
2024-12-27 18:40:04,384 - INFO - Sample size: 39209
2024-12-27 18:40:04,384 - INFO - Using device: cuda
2024-12-27 18:40:04,384 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 18:40:04,386 - INFO - Loading datasets...
2024-12-27 18:40:22,673 - INFO - Dataset loading completed in 18.29s
2024-12-27 18:40:22,673 - INFO - Extracting validation features...
2024-12-27 18:40:22,674 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:29,  4.67it/s]Extracting features:   2%|▏         | 3/139 [00:00<00:14,  9.21it/s]Extracting features:   4%|▎         | 5/139 [00:00<00:10, 12.71it/s]Extracting features:   6%|▌         | 8/139 [00:00<00:07, 17.40it/s]Extracting features:  10%|█         | 14/139 [00:00<00:04, 28.93it/s]Extracting features:  14%|█▍        | 20/139 [00:00<00:03, 37.04it/s]Extracting features:  19%|█▉        | 27/139 [00:00<00:02, 44.86it/s]Extracting features:  24%|██▍       | 34/139 [00:01<00:02, 50.38it/s]Extracting features:  29%|██▉       | 40/139 [00:01<00:01, 52.76it/s]Extracting features:  33%|███▎      | 46/139 [00:01<00:01, 54.48it/s]Extracting features:  37%|███▋      | 52/139 [00:01<00:01, 47.68it/s]Extracting features:  42%|████▏     | 58/139 [00:01<00:01, 49.12it/s]Extracting features:  46%|████▌     | 64/139 [00:01<00:01, 50.64it/s]Extracting features:  50%|█████     | 70/139 [00:01<00:01, 48.96it/s]Extracting features:  54%|█████▍    | 75/139 [00:01<00:01, 44.86it/s]Extracting features:  58%|█████▊    | 80/139 [00:02<00:01, 42.11it/s]Extracting features:  63%|██████▎   | 87/139 [00:02<00:01, 48.30it/s]Extracting features:  68%|██████▊   | 94/139 [00:02<00:00, 51.36it/s]Extracting features:  72%|███████▏  | 100/139 [00:02<00:00, 47.24it/s]Extracting features:  76%|███████▋  | 106/139 [00:02<00:00, 49.41it/s]Extracting features:  81%|████████  | 112/139 [00:02<00:00, 49.34it/s]Extracting features:  85%|████████▍ | 118/139 [00:02<00:00, 46.36it/s]Extracting features:  88%|████████▊ | 123/139 [00:02<00:00, 44.46it/s]Extracting features:  92%|█████████▏| 128/139 [00:03<00:00, 44.97it/s]Extracting features:  97%|█████████▋| 135/139 [00:03<00:00, 50.98it/s]Extracting features: 100%|██████████| 139/139 [00:03<00:00, 42.97it/s]
2024-12-27 18:40:25,920 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 18:40:25,920 - INFO - Validation feature extraction completed in 3.25s
2024-12-27 18:40:25,920 - INFO - Extracting training features...
2024-12-27 18:40:25,920 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<02:14,  4.60it/s]Extracting features:   1%|▏         | 8/618 [00:00<00:21, 28.48it/s]Extracting features:   2%|▏         | 14/618 [00:00<00:15, 38.05it/s]Extracting features:   3%|▎         | 21/618 [00:00<00:12, 46.47it/s]Extracting features:   5%|▍         | 28/618 [00:00<00:11, 51.53it/s]Extracting features:   6%|▌         | 35/618 [00:00<00:10, 56.05it/s]Extracting features:   7%|▋         | 41/618 [00:00<00:10, 55.91it/s]Extracting features:   8%|▊         | 48/618 [00:00<00:09, 58.19it/s]Extracting features:   9%|▊         | 54/618 [00:01<00:09, 57.69it/s]Extracting features:  10%|▉         | 60/618 [00:01<00:09, 57.53it/s]Extracting features:  11%|█         | 66/618 [00:01<00:09, 55.87it/s]Extracting features:  12%|█▏        | 72/618 [00:01<00:10, 52.12it/s]Extracting features:  13%|█▎        | 79/618 [00:01<00:09, 56.10it/s]Extracting features:  14%|█▍        | 86/618 [00:01<00:09, 57.04it/s]Extracting features:  15%|█▍        | 92/618 [00:01<00:09, 57.08it/s]Extracting features:  16%|█▌        | 98/618 [00:01<00:09, 54.48it/s]Extracting features:  17%|█▋        | 104/618 [00:02<00:09, 54.84it/s]Extracting features:  18%|█▊        | 110/618 [00:02<00:09, 54.91it/s]Extracting features:  19%|█▉        | 116/618 [00:02<00:09, 54.15it/s]Extracting features:  20%|█▉        | 122/618 [00:02<00:09, 53.83it/s]Extracting features:  21%|██        | 129/618 [00:02<00:08, 56.36it/s]Extracting features:  22%|██▏       | 136/618 [00:02<00:08, 58.63it/s]Extracting features:  23%|██▎       | 143/618 [00:02<00:07, 60.23it/s]Extracting features:  24%|██▍       | 150/618 [00:02<00:08, 58.43it/s]Extracting features:  25%|██▌       | 156/618 [00:02<00:08, 56.57it/s]Extracting features:  26%|██▋       | 163/618 [00:03<00:07, 59.21it/s]Extracting features:  27%|██▋       | 169/618 [00:03<00:07, 59.31it/s]Extracting features:  28%|██▊       | 176/618 [00:03<00:07, 58.85it/s]Extracting features:  29%|██▉       | 182/618 [00:03<00:08, 52.78it/s]Extracting features:  30%|███       | 188/618 [00:03<00:08, 51.32it/s]Extracting features:  31%|███▏      | 194/618 [00:03<00:08, 52.46it/s]Extracting features:  33%|███▎      | 201/618 [00:03<00:07, 56.52it/s]Extracting features:  34%|███▎      | 208/618 [00:03<00:07, 58.31it/s]Extracting features:  35%|███▍      | 215/618 [00:03<00:06, 61.24it/s]Extracting features:  36%|███▌      | 222/618 [00:04<00:06, 61.31it/s]Extracting features:  37%|███▋      | 229/618 [00:04<00:06, 62.58it/s]Extracting features:  38%|███▊      | 236/618 [00:04<00:06, 61.10it/s]Extracting features:  39%|███▉      | 243/618 [00:04<00:06, 58.22it/s]Extracting features:  40%|████      | 250/618 [00:04<00:06, 60.67it/s]Extracting features:  42%|████▏     | 257/618 [00:04<00:06, 56.01it/s]Extracting features:  43%|████▎     | 263/618 [00:04<00:06, 53.57it/s]Extracting features:  44%|████▎     | 270/618 [00:04<00:06, 56.24it/s]Extracting features:  45%|████▍     | 277/618 [00:05<00:05, 58.01it/s]Extracting features:  46%|████▌     | 283/618 [00:05<00:05, 57.35it/s]Extracting features:  47%|████▋     | 290/618 [00:05<00:05, 59.09it/s]Extracting features:  48%|████▊     | 296/618 [00:05<00:05, 56.85it/s]Extracting features:  49%|████▉     | 302/618 [00:05<00:05, 57.68it/s]Extracting features:  50%|████▉     | 308/618 [00:05<00:05, 53.46it/s]Extracting features:  51%|█████     | 314/618 [00:05<00:05, 54.81it/s]Extracting features:  52%|█████▏    | 320/618 [00:05<00:05, 54.19it/s]Extracting features:  53%|█████▎    | 327/618 [00:05<00:05, 56.43it/s]Extracting features:  54%|█████▍    | 333/618 [00:06<00:05, 54.59it/s]Extracting features:  55%|█████▌    | 340/618 [00:06<00:05, 55.39it/s]Extracting features:  56%|█████▌    | 346/618 [00:06<00:05, 53.10it/s]Extracting features:  57%|█████▋    | 352/618 [00:06<00:05, 52.32it/s]Extracting features:  58%|█████▊    | 358/618 [00:06<00:04, 54.03it/s]Extracting features:  59%|█████▉    | 364/618 [00:06<00:04, 52.82it/s]Extracting features:  60%|█████▉    | 370/618 [00:06<00:04, 53.82it/s]Extracting features:  61%|██████    | 377/618 [00:06<00:04, 57.92it/s]Extracting features:  62%|██████▏   | 383/618 [00:06<00:04, 56.28it/s]Extracting features:  63%|██████▎   | 389/618 [00:07<00:04, 55.41it/s]Extracting features:  64%|██████▍   | 395/618 [00:07<00:04, 53.93it/s]Extracting features:  65%|██████▍   | 401/618 [00:07<00:04, 52.64it/s]Extracting features:  66%|██████▌   | 407/618 [00:07<00:03, 53.69it/s]Extracting features:  67%|██████▋   | 413/618 [00:07<00:03, 51.46it/s]Extracting features:  68%|██████▊   | 419/618 [00:07<00:04, 46.69it/s]Extracting features:  69%|██████▊   | 424/618 [00:07<00:04, 43.23it/s]Extracting features:  69%|██████▉   | 429/618 [00:07<00:04, 44.43it/s]Extracting features:  70%|███████   | 434/618 [00:08<00:04, 42.34it/s]Extracting features:  71%|███████   | 439/618 [00:08<00:04, 43.65it/s]Extracting features:  72%|███████▏  | 444/618 [00:08<00:04, 43.41it/s]Extracting features:  73%|███████▎  | 449/618 [00:08<00:03, 42.85it/s]Extracting features:  73%|███████▎  | 454/618 [00:08<00:04, 39.28it/s]Extracting features:  74%|███████▍  | 459/618 [00:08<00:04, 39.23it/s]Extracting features:  75%|███████▌  | 465/618 [00:08<00:03, 42.48it/s]Extracting features:  76%|███████▋  | 472/618 [00:08<00:02, 48.83it/s]Extracting features:  77%|███████▋  | 478/618 [00:09<00:02, 49.48it/s]Extracting features:  78%|███████▊  | 484/618 [00:09<00:02, 51.83it/s]Extracting features:  79%|███████▉  | 490/618 [00:09<00:02, 54.05it/s]Extracting features:  80%|████████  | 496/618 [00:09<00:02, 50.88it/s]Extracting features:  82%|████████▏ | 504/618 [00:09<00:02, 56.21it/s]Extracting features:  83%|████████▎ | 510/618 [00:09<00:02, 52.39it/s]Extracting features:  83%|████████▎ | 516/618 [00:09<00:01, 54.09it/s]Extracting features:  84%|████████▍ | 522/618 [00:09<00:01, 55.23it/s]Extracting features:  85%|████████▌ | 528/618 [00:09<00:01, 55.93it/s]Extracting features:  86%|████████▋ | 534/618 [00:10<00:01, 48.84it/s]Extracting features:  87%|████████▋ | 540/618 [00:10<00:01, 45.70it/s]Extracting features:  88%|████████▊ | 545/618 [00:10<00:01, 46.23it/s]Extracting features:  89%|████████▉ | 550/618 [00:10<00:01, 41.28it/s]Extracting features:  90%|████████▉ | 555/618 [00:10<00:01, 41.04it/s]Extracting features:  91%|█████████ | 560/618 [00:10<00:01, 41.90it/s]Extracting features:  92%|█████████▏| 566/618 [00:10<00:01, 43.79it/s]Extracting features:  92%|█████████▏| 571/618 [00:10<00:01, 42.67it/s]Extracting features:  93%|█████████▎| 576/618 [00:11<00:01, 40.22it/s]Extracting features:  94%|█████████▍| 581/618 [00:11<00:00, 40.39it/s]Extracting features:  95%|█████████▍| 586/618 [00:11<00:00, 38.65it/s]Extracting features:  95%|█████████▌| 590/618 [00:11<00:00, 38.81it/s]Extracting features:  96%|█████████▌| 594/618 [00:11<00:00, 38.75it/s]Extracting features:  97%|█████████▋| 598/618 [00:11<00:00, 38.65it/s]Extracting features:  97%|█████████▋| 602/618 [00:11<00:00, 37.40it/s]Extracting features:  98%|█████████▊| 606/618 [00:11<00:00, 37.18it/s]Extracting features:  99%|█████████▉| 611/618 [00:12<00:00, 39.78it/s]Extracting features: 100%|██████████| 618/618 [00:12<00:00, 45.91it/s]Extracting features: 100%|██████████| 618/618 [00:12<00:00, 50.59it/s]
2024-12-27 18:40:38,173 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 18:40:38,174 - INFO - Training feature extraction completed in 12.25s
2024-12-27 18:40:38,174 - INFO - Creating model for classifier: KNeighbors
2024-12-27 18:40:38,174 - INFO - Using device: cuda
2024-12-27 18:40:38,174 - INFO - 
Processing poison rate: 0.0
2024-12-27 18:40:38,174 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:40:38,174 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:40:39,992 - INFO - Feature scaling completed in 1.82s
2024-12-27 18:40:39,992 - INFO - Starting feature selection (k=50)
2024-12-27 18:40:40,011 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 18:40:40,012 - INFO - Starting anomaly detection
2024-12-27 18:40:45,600 - INFO - Anomaly detection completed in 5.59s
2024-12-27 18:40:45,601 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:40:45,601 - INFO - Total fit_transform time: 7.43s
2024-12-27 18:40:45,601 - INFO - Training set processing completed in 7.43s
2024-12-27 18:40:45,601 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 18:40:45,603 - INFO - Memory usage at start_fit: CPU 2930.7 MB, GPU 47.3 MB
2024-12-27 18:40:45,603 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:40:45,863 - INFO - Fitted scaler and transformed data
2024-12-27 18:40:45,863 - INFO - Scaling time: 0.26s
2024-12-27 18:40:45,882 - INFO - Training completed in 0.28s
2024-12-27 18:40:45,883 - INFO - Final memory usage: CPU 3034.5 MB, GPU 143.9 MB
2024-12-27 18:40:45,883 - INFO - Model training completed in 0.28s
2024-12-27 18:40:46,198 - INFO - Prediction completed in 0.31s
2024-12-27 18:40:46,209 - INFO - Poison rate 0.0 completed in 8.04s
2024-12-27 18:40:46,210 - INFO - 
Processing poison rate: 0.01
2024-12-27 18:40:46,211 - INFO - Total number of labels flipped: 193
2024-12-27 18:40:46,212 - INFO - Label flipping completed in 0.00s
2024-12-27 18:40:46,212 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:40:46,212 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:40:48,101 - INFO - Feature scaling completed in 1.89s
2024-12-27 18:40:48,101 - INFO - Starting feature selection (k=50)
2024-12-27 18:40:48,118 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 18:40:48,119 - INFO - Starting anomaly detection
2024-12-27 18:40:55,263 - INFO - Anomaly detection completed in 7.14s
2024-12-27 18:40:55,263 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:40:55,264 - INFO - Total fit_transform time: 9.05s
2024-12-27 18:40:55,264 - INFO - Training set processing completed in 9.05s
2024-12-27 18:40:55,264 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 18:40:55,265 - INFO - Memory usage at start_fit: CPU 2938.1 MB, GPU 143.9 MB
2024-12-27 18:40:55,266 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:40:55,537 - INFO - Fitted scaler and transformed data
2024-12-27 18:40:55,537 - INFO - Scaling time: 0.27s
2024-12-27 18:40:55,557 - INFO - Training completed in 0.29s
2024-12-27 18:40:55,558 - INFO - Final memory usage: CPU 3034.5 MB, GPU 143.9 MB
2024-12-27 18:40:55,558 - INFO - Model training completed in 0.29s
2024-12-27 18:40:55,803 - INFO - Prediction completed in 0.24s
2024-12-27 18:40:55,814 - INFO - Poison rate 0.01 completed in 9.60s
2024-12-27 18:40:55,814 - INFO - 
Processing poison rate: 0.03
2024-12-27 18:40:55,816 - INFO - Total number of labels flipped: 587
2024-12-27 18:40:55,816 - INFO - Label flipping completed in 0.00s
2024-12-27 18:40:55,817 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:40:55,817 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:40:57,667 - INFO - Feature scaling completed in 1.85s
2024-12-27 18:40:57,667 - INFO - Starting feature selection (k=50)
2024-12-27 18:40:57,685 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 18:40:57,686 - INFO - Starting anomaly detection
2024-12-27 18:41:02,915 - INFO - Anomaly detection completed in 5.23s
2024-12-27 18:41:02,915 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:41:02,916 - INFO - Total fit_transform time: 7.10s
2024-12-27 18:41:02,916 - INFO - Training set processing completed in 7.10s
2024-12-27 18:41:02,916 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 18:41:02,917 - INFO - Memory usage at start_fit: CPU 2938.1 MB, GPU 143.9 MB
2024-12-27 18:41:02,918 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:41:03,173 - INFO - Fitted scaler and transformed data
2024-12-27 18:41:03,173 - INFO - Scaling time: 0.25s
2024-12-27 18:41:03,193 - INFO - Training completed in 0.28s
2024-12-27 18:41:03,194 - INFO - Final memory usage: CPU 3034.5 MB, GPU 143.9 MB
2024-12-27 18:41:03,194 - INFO - Model training completed in 0.28s
2024-12-27 18:41:03,416 - INFO - Prediction completed in 0.22s
2024-12-27 18:41:03,429 - INFO - Poison rate 0.03 completed in 7.62s
2024-12-27 18:41:03,429 - INFO - 
Processing poison rate: 0.05
2024-12-27 18:41:03,432 - INFO - Total number of labels flipped: 980
2024-12-27 18:41:03,432 - INFO - Label flipping completed in 0.00s
2024-12-27 18:41:03,432 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:41:03,432 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:41:05,386 - INFO - Feature scaling completed in 1.95s
2024-12-27 18:41:05,387 - INFO - Starting feature selection (k=50)
2024-12-27 18:41:05,404 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 18:41:05,405 - INFO - Starting anomaly detection
2024-12-27 18:41:12,965 - INFO - Anomaly detection completed in 7.56s
2024-12-27 18:41:12,965 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:41:12,966 - INFO - Total fit_transform time: 9.53s
2024-12-27 18:41:12,967 - INFO - Training set processing completed in 9.53s
2024-12-27 18:41:12,967 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 18:41:12,968 - INFO - Memory usage at start_fit: CPU 2938.1 MB, GPU 143.9 MB
2024-12-27 18:41:12,969 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:41:13,278 - INFO - Fitted scaler and transformed data
2024-12-27 18:41:13,278 - INFO - Scaling time: 0.31s
2024-12-27 18:41:13,297 - INFO - Training completed in 0.33s
2024-12-27 18:41:13,298 - INFO - Final memory usage: CPU 3034.5 MB, GPU 143.9 MB
2024-12-27 18:41:13,298 - INFO - Model training completed in 0.33s
2024-12-27 18:41:13,600 - INFO - Prediction completed in 0.30s
2024-12-27 18:41:13,616 - INFO - Poison rate 0.05 completed in 10.19s
2024-12-27 18:41:13,616 - INFO - 
Processing poison rate: 0.07
2024-12-27 18:41:13,618 - INFO - Total number of labels flipped: 1379
2024-12-27 18:41:13,618 - INFO - Label flipping completed in 0.00s
2024-12-27 18:41:13,618 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:41:13,618 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:41:15,419 - INFO - Feature scaling completed in 1.80s
2024-12-27 18:41:15,419 - INFO - Starting feature selection (k=50)
2024-12-27 18:41:15,436 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 18:41:15,436 - INFO - Starting anomaly detection
2024-12-27 18:41:23,145 - INFO - Anomaly detection completed in 7.71s
2024-12-27 18:41:23,145 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:41:23,145 - INFO - Total fit_transform time: 9.53s
2024-12-27 18:41:23,146 - INFO - Training set processing completed in 9.53s
2024-12-27 18:41:23,146 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 18:41:23,147 - INFO - Memory usage at start_fit: CPU 2938.1 MB, GPU 143.9 MB
2024-12-27 18:41:23,147 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:41:23,418 - INFO - Fitted scaler and transformed data
2024-12-27 18:41:23,418 - INFO - Scaling time: 0.27s
2024-12-27 18:41:23,438 - INFO - Training completed in 0.29s
2024-12-27 18:41:23,439 - INFO - Final memory usage: CPU 3034.5 MB, GPU 143.9 MB
2024-12-27 18:41:23,439 - INFO - Model training completed in 0.29s
2024-12-27 18:41:23,784 - INFO - Prediction completed in 0.34s
2024-12-27 18:41:23,795 - INFO - Poison rate 0.07 completed in 10.18s
2024-12-27 18:41:23,796 - INFO - 
Processing poison rate: 0.1
2024-12-27 18:41:23,798 - INFO - Total number of labels flipped: 1965
2024-12-27 18:41:23,799 - INFO - Label flipping completed in 0.00s
2024-12-27 18:41:23,799 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:41:23,799 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:41:25,670 - INFO - Feature scaling completed in 1.87s
2024-12-27 18:41:25,670 - INFO - Starting feature selection (k=50)
2024-12-27 18:41:25,687 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 18:41:25,688 - INFO - Starting anomaly detection
2024-12-27 18:41:31,684 - INFO - Anomaly detection completed in 6.00s
2024-12-27 18:41:31,684 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:41:31,684 - INFO - Total fit_transform time: 7.89s
2024-12-27 18:41:31,685 - INFO - Training set processing completed in 7.89s
2024-12-27 18:41:31,685 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 18:41:31,687 - INFO - Memory usage at start_fit: CPU 2938.1 MB, GPU 143.9 MB
2024-12-27 18:41:31,687 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:41:31,949 - INFO - Fitted scaler and transformed data
2024-12-27 18:41:31,949 - INFO - Scaling time: 0.26s
2024-12-27 18:41:31,968 - INFO - Training completed in 0.28s
2024-12-27 18:41:31,968 - INFO - Final memory usage: CPU 3034.5 MB, GPU 143.9 MB
2024-12-27 18:41:31,969 - INFO - Model training completed in 0.28s
2024-12-27 18:41:32,377 - INFO - Prediction completed in 0.41s
2024-12-27 18:41:32,389 - INFO - Poison rate 0.1 completed in 8.59s
2024-12-27 18:41:32,389 - INFO - 
Processing poison rate: 0.2
2024-12-27 18:41:32,392 - INFO - Total number of labels flipped: 3926
2024-12-27 18:41:32,393 - INFO - Label flipping completed in 0.00s
2024-12-27 18:41:32,393 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:41:32,393 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:41:34,338 - INFO - Feature scaling completed in 1.95s
2024-12-27 18:41:34,339 - INFO - Starting feature selection (k=50)
2024-12-27 18:41:34,355 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 18:41:34,356 - INFO - Starting anomaly detection
2024-12-27 18:41:42,068 - INFO - Anomaly detection completed in 7.71s
2024-12-27 18:41:42,068 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:41:42,069 - INFO - Total fit_transform time: 9.68s
2024-12-27 18:41:42,069 - INFO - Training set processing completed in 9.68s
2024-12-27 18:41:42,069 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 18:41:42,070 - INFO - Memory usage at start_fit: CPU 2938.1 MB, GPU 143.9 MB
2024-12-27 18:41:42,070 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:41:42,364 - INFO - Fitted scaler and transformed data
2024-12-27 18:41:42,364 - INFO - Scaling time: 0.29s
2024-12-27 18:41:42,383 - INFO - Training completed in 0.31s
2024-12-27 18:41:42,383 - INFO - Final memory usage: CPU 3034.5 MB, GPU 143.9 MB
2024-12-27 18:41:42,384 - INFO - Model training completed in 0.31s
2024-12-27 18:41:42,778 - INFO - Prediction completed in 0.39s
2024-12-27 18:41:42,792 - INFO - Poison rate 0.2 completed in 10.40s
2024-12-27 18:41:42,795 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 18:41:42,795 - INFO - Total evaluation time: 98.41s
2024-12-27 18:41:42,801 - INFO - Completed evaluation for GTSRB
2024-12-27 18:41:42,802 - INFO - 
Processing dataset: GTSRB
2024-12-27 18:41:42,893 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 18:41:42,967 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 18:41:43,039 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 18:41:43,039 - INFO - Dataset type: image
2024-12-27 18:41:43,039 - INFO - Sample size: 39209
2024-12-27 18:41:43,039 - INFO - Using device: cuda
2024-12-27 18:41:43,039 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 18:41:43,044 - INFO - 
Progress: 17.7% - Evaluating GTSRB with SVM (standard mode, iteration 1/1)
2024-12-27 18:41:43,104 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 18:41:43,177 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 18:41:43,255 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 18:41:43,255 - INFO - Dataset type: image
2024-12-27 18:41:43,255 - INFO - Sample size: 39209
2024-12-27 18:41:43,255 - INFO - Using device: cuda
2024-12-27 18:41:43,255 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 18:41:43,258 - INFO - Loading datasets...
2024-12-27 18:42:00,780 - INFO - Dataset loading completed in 17.52s
2024-12-27 18:42:00,780 - INFO - Extracting validation features...
2024-12-27 18:42:00,780 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:34,  4.02it/s]Extracting features:   2%|▏         | 3/139 [00:00<00:15,  8.76it/s]Extracting features:   4%|▎         | 5/139 [00:00<00:13, 10.13it/s]Extracting features:   8%|▊         | 11/139 [00:00<00:05, 23.15it/s]Extracting features:  13%|█▎        | 18/139 [00:00<00:03, 34.89it/s]Extracting features:  17%|█▋        | 24/139 [00:00<00:02, 40.31it/s]Extracting features:  21%|██        | 29/139 [00:01<00:02, 38.92it/s]Extracting features:  26%|██▌       | 36/139 [00:01<00:02, 44.48it/s]Extracting features:  29%|██▉       | 41/139 [00:01<00:02, 44.62it/s]Extracting features:  34%|███▍      | 47/139 [00:01<00:01, 48.47it/s]Extracting features:  38%|███▊      | 53/139 [00:01<00:01, 51.19it/s]Extracting features:  42%|████▏     | 59/139 [00:01<00:01, 52.00it/s]Extracting features:  47%|████▋     | 65/139 [00:01<00:01, 52.79it/s]Extracting features:  51%|█████     | 71/139 [00:01<00:01, 53.96it/s]Extracting features:  55%|█████▌    | 77/139 [00:01<00:01, 52.90it/s]Extracting features:  60%|█████▉    | 83/139 [00:02<00:01, 54.02it/s]Extracting features:  65%|██████▍   | 90/139 [00:02<00:00, 56.02it/s]Extracting features:  69%|██████▉   | 96/139 [00:02<00:00, 57.09it/s]Extracting features:  73%|███████▎  | 102/139 [00:02<00:00, 52.05it/s]Extracting features:  78%|███████▊  | 108/139 [00:02<00:00, 52.04it/s]Extracting features:  82%|████████▏ | 114/139 [00:02<00:00, 53.38it/s]Extracting features:  86%|████████▋ | 120/139 [00:02<00:00, 51.56it/s]Extracting features:  91%|█████████ | 126/139 [00:02<00:00, 47.65it/s]Extracting features:  96%|█████████▌| 133/139 [00:02<00:00, 52.03it/s]Extracting features: 100%|██████████| 139/139 [00:03<00:00, 51.26it/s]Extracting features: 100%|██████████| 139/139 [00:03<00:00, 44.02it/s]
2024-12-27 18:42:03,951 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 18:42:03,951 - INFO - Validation feature extraction completed in 3.17s
2024-12-27 18:42:03,951 - INFO - Extracting training features...
2024-12-27 18:42:03,951 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<01:54,  5.39it/s]Extracting features:   1%|▏         | 8/618 [00:00<00:19, 30.84it/s]Extracting features:   2%|▏         | 14/618 [00:00<00:14, 40.56it/s]Extracting features:   3%|▎         | 20/618 [00:00<00:12, 47.11it/s]Extracting features:   4%|▍         | 27/618 [00:00<00:11, 53.37it/s]Extracting features:   5%|▌         | 33/618 [00:00<00:10, 54.37it/s]Extracting features:   6%|▋         | 39/618 [00:00<00:10, 55.71it/s]Extracting features:   7%|▋         | 45/618 [00:00<00:10, 54.16it/s]Extracting features:   8%|▊         | 51/618 [00:01<00:10, 53.75it/s]Extracting features:   9%|▉         | 57/618 [00:01<00:10, 52.01it/s]Extracting features:  10%|█         | 63/618 [00:01<00:10, 52.26it/s]Extracting features:  11%|█▏        | 70/618 [00:01<00:09, 55.16it/s]Extracting features:  12%|█▏        | 76/618 [00:01<00:09, 55.16it/s]Extracting features:  13%|█▎        | 83/618 [00:01<00:09, 59.03it/s]Extracting features:  15%|█▍        | 90/618 [00:01<00:08, 60.01it/s]Extracting features:  16%|█▌        | 97/618 [00:01<00:08, 60.67it/s]Extracting features:  17%|█▋        | 104/618 [00:01<00:08, 62.28it/s]Extracting features:  18%|█▊        | 111/618 [00:02<00:07, 63.67it/s]Extracting features:  19%|█▉        | 118/618 [00:02<00:07, 65.05it/s]Extracting features:  20%|██        | 126/618 [00:02<00:07, 66.81it/s]Extracting features:  22%|██▏       | 133/618 [00:02<00:07, 67.71it/s]Extracting features:  23%|██▎       | 140/618 [00:02<00:07, 60.28it/s]Extracting features:  24%|██▍       | 147/618 [00:02<00:08, 57.62it/s]Extracting features:  25%|██▍       | 154/618 [00:02<00:07, 59.88it/s]Extracting features:  26%|██▌       | 161/618 [00:02<00:07, 61.10it/s]Extracting features:  27%|██▋       | 168/618 [00:02<00:07, 61.00it/s]Extracting features:  28%|██▊       | 175/618 [00:03<00:07, 62.83it/s]Extracting features:  29%|██▉       | 182/618 [00:03<00:06, 62.67it/s]Extracting features:  31%|███       | 189/618 [00:03<00:06, 64.43it/s]Extracting features:  32%|███▏      | 196/618 [00:03<00:06, 64.49it/s]Extracting features:  33%|███▎      | 203/618 [00:03<00:06, 63.01it/s]Extracting features:  34%|███▍      | 210/618 [00:03<00:06, 58.57it/s]Extracting features:  35%|███▌      | 217/618 [00:03<00:06, 60.06it/s]Extracting features:  36%|███▌      | 224/618 [00:03<00:06, 57.49it/s]Extracting features:  37%|███▋      | 230/618 [00:04<00:06, 56.19it/s]Extracting features:  38%|███▊      | 236/618 [00:04<00:06, 56.33it/s]Extracting features:  39%|███▉      | 243/618 [00:04<00:06, 57.24it/s]Extracting features:  40%|████      | 250/618 [00:04<00:06, 58.52it/s]Extracting features:  41%|████▏     | 256/618 [00:04<00:06, 57.05it/s]Extracting features:  43%|████▎     | 263/618 [00:04<00:06, 58.61it/s]Extracting features:  44%|████▎     | 269/618 [00:04<00:05, 58.93it/s]Extracting features:  44%|████▍     | 275/618 [00:04<00:05, 59.10it/s]Extracting features:  46%|████▌     | 282/618 [00:04<00:05, 60.40it/s]Extracting features:  47%|████▋     | 289/618 [00:05<00:05, 61.55it/s]Extracting features:  48%|████▊     | 296/618 [00:05<00:05, 59.63it/s]Extracting features:  49%|████▉     | 302/618 [00:05<00:05, 55.42it/s]Extracting features:  50%|████▉     | 308/618 [00:05<00:05, 56.19it/s]Extracting features:  51%|█████     | 314/618 [00:05<00:05, 56.46it/s]Extracting features:  52%|█████▏    | 320/618 [00:05<00:05, 50.56it/s]Extracting features:  53%|█████▎    | 326/618 [00:05<00:05, 49.13it/s]Extracting features:  54%|█████▎    | 332/618 [00:05<00:05, 50.92it/s]Extracting features:  55%|█████▍    | 339/618 [00:05<00:05, 55.27it/s]Extracting features:  56%|█████▌    | 346/618 [00:06<00:04, 57.71it/s]Extracting features:  57%|█████▋    | 353/618 [00:06<00:04, 55.11it/s]Extracting features:  58%|█████▊    | 359/618 [00:06<00:04, 56.03it/s]Extracting features:  59%|█████▉    | 365/618 [00:06<00:04, 55.20it/s]Extracting features:  60%|██████    | 371/618 [00:06<00:04, 54.05it/s]Extracting features:  61%|██████    | 377/618 [00:06<00:04, 53.65it/s]Extracting features:  62%|██████▏   | 384/618 [00:06<00:04, 56.19it/s]Extracting features:  63%|██████▎   | 391/618 [00:06<00:03, 59.47it/s]Extracting features:  64%|██████▍   | 398/618 [00:06<00:03, 61.52it/s]Extracting features:  66%|██████▌   | 405/618 [00:07<00:03, 60.02it/s]Extracting features:  67%|██████▋   | 412/618 [00:07<00:03, 62.71it/s]Extracting features:  68%|██████▊   | 419/618 [00:07<00:03, 57.51it/s]Extracting features:  69%|██████▉   | 425/618 [00:07<00:03, 53.58it/s]Extracting features:  70%|██████▉   | 431/618 [00:07<00:03, 51.37it/s]Extracting features:  71%|███████   | 437/618 [00:07<00:03, 53.19it/s]Extracting features:  72%|███████▏  | 443/618 [00:07<00:03, 48.65it/s]Extracting features:  72%|███████▏  | 448/618 [00:07<00:03, 47.14it/s]Extracting features:  73%|███████▎  | 453/618 [00:08<00:03, 46.48it/s]Extracting features:  74%|███████▍  | 458/618 [00:08<00:03, 45.63it/s]Extracting features:  75%|███████▌  | 464/618 [00:08<00:03, 49.02it/s]Extracting features:  76%|███████▌  | 471/618 [00:08<00:02, 53.07it/s]Extracting features:  77%|███████▋  | 477/618 [00:08<00:02, 54.00it/s]Extracting features:  78%|███████▊  | 484/618 [00:08<00:02, 55.55it/s]Extracting features:  79%|███████▉  | 491/618 [00:08<00:02, 58.40it/s]Extracting features:  81%|████████  | 498/618 [00:08<00:02, 58.16it/s]Extracting features:  82%|████████▏ | 504/618 [00:08<00:02, 56.81it/s]Extracting features:  83%|████████▎ | 510/618 [00:09<00:01, 54.31it/s]Extracting features:  84%|████████▎ | 517/618 [00:09<00:01, 56.71it/s]Extracting features:  85%|████████▍ | 523/618 [00:09<00:01, 56.75it/s]Extracting features:  86%|████████▌ | 530/618 [00:09<00:01, 57.76it/s]Extracting features:  87%|████████▋ | 537/618 [00:09<00:01, 59.44it/s]Extracting features:  88%|████████▊ | 543/618 [00:09<00:01, 59.58it/s]Extracting features:  89%|████████▉ | 549/618 [00:09<00:01, 51.38it/s]Extracting features:  90%|████████▉ | 555/618 [00:09<00:01, 50.40it/s]Extracting features:  91%|█████████ | 561/618 [00:10<00:01, 51.27it/s]Extracting features:  92%|█████████▏| 567/618 [00:10<00:00, 53.26it/s]Extracting features:  93%|█████████▎| 574/618 [00:10<00:00, 55.37it/s]Extracting features:  94%|█████████▍| 580/618 [00:10<00:00, 54.46it/s]Extracting features:  95%|█████████▍| 586/618 [00:10<00:00, 55.22it/s]Extracting features:  96%|█████████▌| 593/618 [00:10<00:00, 56.28it/s]Extracting features:  97%|█████████▋| 600/618 [00:10<00:00, 57.77it/s]Extracting features:  98%|█████████▊| 606/618 [00:10<00:00, 56.98it/s]Extracting features:  99%|█████████▉| 612/618 [00:10<00:00, 52.09it/s]Extracting features: 100%|██████████| 618/618 [00:11<00:00, 55.60it/s]
2024-12-27 18:42:15,102 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 18:42:15,102 - INFO - Training feature extraction completed in 11.15s
2024-12-27 18:42:15,102 - INFO - Creating model for classifier: SVM
2024-12-27 18:42:15,102 - INFO - Using device: cuda
2024-12-27 18:42:15,102 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-27 18:42:15,103 - INFO - 
Processing poison rate: 0.0
2024-12-27 18:42:15,103 - INFO - Training set processing completed in 0.00s
2024-12-27 18:42:15,103 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 18:42:15,103 - INFO - Memory usage at start_fit: CPU 2935.3 MB, GPU 47.3 MB
2024-12-27 18:42:15,104 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:42:15,105 - INFO - Number of unique classes: 43
2024-12-27 18:42:15,446 - INFO - Fitted scaler and transformed data
2024-12-27 18:42:15,447 - INFO - Scaling time: 0.34s
2024-12-27 18:42:16,505 - INFO - Epoch 1/25, Train Loss: 5.2672, Val Loss: 2.1315
2024-12-27 18:42:17,647 - INFO - Epoch 2/25, Train Loss: 0.9574, Val Loss: 1.3428
2024-12-27 18:42:18,821 - INFO - Epoch 3/25, Train Loss: 0.5908, Val Loss: 1.1893
2024-12-27 18:42:20,076 - INFO - Epoch 4/25, Train Loss: 0.4624, Val Loss: 1.5389
2024-12-27 18:42:21,372 - INFO - Epoch 5/25, Train Loss: 0.4063, Val Loss: 1.3632
2024-12-27 18:42:21,372 - INFO - Early stopping triggered at epoch 5
2024-12-27 18:42:21,372 - INFO - Training completed in 6.27s
2024-12-27 18:42:21,372 - INFO - Final memory usage: CPU 3044.3 MB, GPU 48.4 MB
2024-12-27 18:42:21,373 - INFO - Model training completed in 6.27s
2024-12-27 18:42:21,404 - INFO - Prediction completed in 0.03s
2024-12-27 18:42:21,416 - INFO - Poison rate 0.0 completed in 6.31s
2024-12-27 18:42:21,416 - INFO - 
Processing poison rate: 0.01
2024-12-27 18:42:21,418 - INFO - Label flipping details:
2024-12-27 18:42:21,418 - INFO - - Source class: 1
2024-12-27 18:42:21,418 - INFO - - Target class: 0
2024-12-27 18:42:21,418 - INFO - - Available samples in source class: 913
2024-12-27 18:42:21,418 - INFO - - Requested samples to poison: 197
2024-12-27 18:42:21,418 - INFO - - Actual samples to flip: 197
2024-12-27 18:42:21,418 - INFO - - Samples remaining in source class: 716
2024-12-27 18:42:21,418 - INFO - Successfully flipped 197 labels from class 1 to 0
2024-12-27 18:42:21,418 - INFO - Total number of labels flipped: 197
2024-12-27 18:42:21,418 - INFO - Label flipping completed in 0.00s
2024-12-27 18:42:21,419 - INFO - Training set processing completed in 0.00s
2024-12-27 18:42:21,419 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 18:42:21,420 - INFO - Memory usage at start_fit: CPU 2947.8 MB, GPU 48.1 MB
2024-12-27 18:42:21,420 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:42:21,421 - INFO - Number of unique classes: 43
2024-12-27 18:42:21,762 - INFO - Fitted scaler and transformed data
2024-12-27 18:42:21,762 - INFO - Scaling time: 0.34s
2024-12-27 18:42:23,037 - INFO - Epoch 1/25, Train Loss: 5.6535, Val Loss: 2.3825
2024-12-27 18:42:24,361 - INFO - Epoch 2/25, Train Loss: 1.0979, Val Loss: 1.5422
2024-12-27 18:42:25,662 - INFO - Epoch 3/25, Train Loss: 0.6805, Val Loss: 1.4941
2024-12-27 18:42:26,861 - INFO - Epoch 4/25, Train Loss: 0.5395, Val Loss: 1.3506
2024-12-27 18:42:28,085 - INFO - Epoch 5/25, Train Loss: 0.4432, Val Loss: 1.2398
2024-12-27 18:42:29,322 - INFO - Epoch 6/25, Train Loss: 0.4142, Val Loss: 1.3610
2024-12-27 18:42:30,663 - INFO - Epoch 7/25, Train Loss: 0.3872, Val Loss: 1.3463
2024-12-27 18:42:30,663 - INFO - Early stopping triggered at epoch 7
2024-12-27 18:42:30,663 - INFO - Training completed in 9.24s
2024-12-27 18:42:30,663 - INFO - Final memory usage: CPU 3044.3 MB, GPU 48.4 MB
2024-12-27 18:42:30,664 - INFO - Model training completed in 9.25s
2024-12-27 18:42:30,693 - INFO - Prediction completed in 0.03s
2024-12-27 18:42:30,711 - INFO - Poison rate 0.01 completed in 9.29s
2024-12-27 18:42:30,712 - INFO - 
Processing poison rate: 0.03
2024-12-27 18:42:30,716 - INFO - Label flipping details:
2024-12-27 18:42:30,716 - INFO - - Source class: 1
2024-12-27 18:42:30,716 - INFO - - Target class: 0
2024-12-27 18:42:30,716 - INFO - - Available samples in source class: 913
2024-12-27 18:42:30,717 - INFO - - Requested samples to poison: 592
2024-12-27 18:42:30,717 - INFO - - Actual samples to flip: 592
2024-12-27 18:42:30,717 - INFO - - Samples remaining in source class: 321
2024-12-27 18:42:30,717 - INFO - Successfully flipped 592 labels from class 1 to 0
2024-12-27 18:42:30,718 - INFO - Total number of labels flipped: 592
2024-12-27 18:42:30,718 - INFO - Label flipping completed in 0.01s
2024-12-27 18:42:30,718 - INFO - Training set processing completed in 0.00s
2024-12-27 18:42:30,719 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 18:42:30,720 - INFO - Memory usage at start_fit: CPU 2947.8 MB, GPU 48.1 MB
2024-12-27 18:42:30,720 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:42:30,723 - INFO - Number of unique classes: 43
2024-12-27 18:42:31,087 - INFO - Fitted scaler and transformed data
2024-12-27 18:42:31,088 - INFO - Scaling time: 0.36s
2024-12-27 18:42:32,424 - INFO - Epoch 1/25, Train Loss: 5.6717, Val Loss: 2.3313
2024-12-27 18:42:33,719 - INFO - Epoch 2/25, Train Loss: 1.1280, Val Loss: 1.6416
2024-12-27 18:42:35,000 - INFO - Epoch 3/25, Train Loss: 0.6643, Val Loss: 1.4789
2024-12-27 18:42:36,255 - INFO - Epoch 4/25, Train Loss: 0.5484, Val Loss: 1.4692
2024-12-27 18:42:37,548 - INFO - Epoch 5/25, Train Loss: 0.4648, Val Loss: 1.4665
2024-12-27 18:42:38,732 - INFO - Epoch 6/25, Train Loss: 0.3978, Val Loss: 1.5296
2024-12-27 18:42:40,098 - INFO - Epoch 7/25, Train Loss: 0.4109, Val Loss: 1.5194
2024-12-27 18:42:40,098 - INFO - Early stopping triggered at epoch 7
2024-12-27 18:42:40,098 - INFO - Training completed in 9.38s
2024-12-27 18:42:40,098 - INFO - Final memory usage: CPU 3044.3 MB, GPU 48.4 MB
2024-12-27 18:42:40,099 - INFO - Model training completed in 9.38s
2024-12-27 18:42:40,129 - INFO - Prediction completed in 0.03s
2024-12-27 18:42:40,140 - INFO - Poison rate 0.03 completed in 9.43s
2024-12-27 18:42:40,140 - INFO - 
Processing poison rate: 0.05
2024-12-27 18:42:40,142 - INFO - Label flipping details:
2024-12-27 18:42:40,142 - INFO - - Source class: 1
2024-12-27 18:42:40,142 - INFO - - Target class: 0
2024-12-27 18:42:40,142 - INFO - - Available samples in source class: 913
2024-12-27 18:42:40,142 - INFO - - Requested samples to poison: 987
2024-12-27 18:42:40,142 - INFO - - Actual samples to flip: 912
2024-12-27 18:42:40,142 - INFO - - Samples remaining in source class: 1
2024-12-27 18:42:40,142 - INFO - Successfully flipped 912 labels from class 1 to 0
2024-12-27 18:42:40,142 - INFO - Total number of labels flipped: 912
2024-12-27 18:42:40,142 - INFO - Label flipping completed in 0.00s
2024-12-27 18:42:40,142 - INFO - Training set processing completed in 0.00s
2024-12-27 18:42:40,142 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 18:42:40,143 - INFO - Memory usage at start_fit: CPU 2947.8 MB, GPU 48.1 MB
2024-12-27 18:42:40,143 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:42:40,145 - INFO - Number of unique classes: 43
2024-12-27 18:42:40,524 - INFO - Fitted scaler and transformed data
2024-12-27 18:42:40,524 - INFO - Scaling time: 0.38s
2024-12-27 18:42:41,883 - INFO - Epoch 1/25, Train Loss: 5.2297, Val Loss: 2.1946
2024-12-27 18:42:43,159 - INFO - Epoch 2/25, Train Loss: 0.9549, Val Loss: 1.5040
2024-12-27 18:42:44,499 - INFO - Epoch 3/25, Train Loss: 0.6269, Val Loss: 1.3425
2024-12-27 18:42:45,823 - INFO - Epoch 4/25, Train Loss: 0.4667, Val Loss: 1.4097
2024-12-27 18:42:47,212 - INFO - Epoch 5/25, Train Loss: 0.3993, Val Loss: 1.3408
2024-12-27 18:42:47,212 - INFO - Early stopping triggered at epoch 5
2024-12-27 18:42:47,212 - INFO - Training completed in 7.07s
2024-12-27 18:42:47,213 - INFO - Final memory usage: CPU 3044.3 MB, GPU 48.4 MB
2024-12-27 18:42:47,213 - INFO - Model training completed in 7.07s
2024-12-27 18:42:47,244 - INFO - Prediction completed in 0.03s
2024-12-27 18:42:47,255 - INFO - Poison rate 0.05 completed in 7.11s
2024-12-27 18:42:47,255 - INFO - 
Processing poison rate: 0.07
2024-12-27 18:42:47,256 - INFO - Label flipping details:
2024-12-27 18:42:47,257 - INFO - - Source class: 1
2024-12-27 18:42:47,257 - INFO - - Target class: 0
2024-12-27 18:42:47,257 - INFO - - Available samples in source class: 913
2024-12-27 18:42:47,257 - INFO - - Requested samples to poison: 1382
2024-12-27 18:42:47,257 - INFO - - Actual samples to flip: 912
2024-12-27 18:42:47,257 - INFO - - Samples remaining in source class: 1
2024-12-27 18:42:47,257 - INFO - Successfully flipped 912 labels from class 1 to 0
2024-12-27 18:42:47,257 - INFO - Total number of labels flipped: 912
2024-12-27 18:42:47,257 - INFO - Label flipping completed in 0.00s
2024-12-27 18:42:47,257 - INFO - Training set processing completed in 0.00s
2024-12-27 18:42:47,257 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 18:42:47,258 - INFO - Memory usage at start_fit: CPU 2947.8 MB, GPU 48.1 MB
2024-12-27 18:42:47,259 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:42:47,262 - INFO - Number of unique classes: 43
2024-12-27 18:42:47,612 - INFO - Fitted scaler and transformed data
2024-12-27 18:42:47,612 - INFO - Scaling time: 0.35s
2024-12-27 18:42:48,963 - INFO - Epoch 1/25, Train Loss: 5.1937, Val Loss: 2.0204
2024-12-27 18:42:50,328 - INFO - Epoch 2/25, Train Loss: 1.0029, Val Loss: 1.4099
2024-12-27 18:42:51,715 - INFO - Epoch 3/25, Train Loss: 0.6026, Val Loss: 1.3005
2024-12-27 18:42:53,017 - INFO - Epoch 4/25, Train Loss: 0.4686, Val Loss: 1.3125
2024-12-27 18:42:54,303 - INFO - Epoch 5/25, Train Loss: 0.3937, Val Loss: 1.2555
2024-12-27 18:42:55,513 - INFO - Epoch 6/25, Train Loss: 0.3431, Val Loss: 1.4475
2024-12-27 18:42:56,840 - INFO - Epoch 7/25, Train Loss: 0.3324, Val Loss: 1.3606
2024-12-27 18:42:56,840 - INFO - Early stopping triggered at epoch 7
2024-12-27 18:42:56,841 - INFO - Training completed in 9.58s
2024-12-27 18:42:56,841 - INFO - Final memory usage: CPU 3046.3 MB, GPU 48.4 MB
2024-12-27 18:42:56,842 - INFO - Model training completed in 9.58s
2024-12-27 18:42:56,871 - INFO - Prediction completed in 0.03s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:42:56,882 - INFO - Poison rate 0.07 completed in 9.63s
2024-12-27 18:42:56,882 - INFO - 
Processing poison rate: 0.1
2024-12-27 18:42:56,884 - INFO - Label flipping details:
2024-12-27 18:42:56,884 - INFO - - Source class: 1
2024-12-27 18:42:56,884 - INFO - - Target class: 0
2024-12-27 18:42:56,884 - INFO - - Available samples in source class: 913
2024-12-27 18:42:56,884 - INFO - - Requested samples to poison: 1975
2024-12-27 18:42:56,884 - INFO - - Actual samples to flip: 912
2024-12-27 18:42:56,884 - INFO - - Samples remaining in source class: 1
2024-12-27 18:42:56,884 - INFO - Successfully flipped 912 labels from class 1 to 0
2024-12-27 18:42:56,884 - INFO - Total number of labels flipped: 912
2024-12-27 18:42:56,884 - INFO - Label flipping completed in 0.00s
2024-12-27 18:42:56,885 - INFO - Training set processing completed in 0.00s
2024-12-27 18:42:56,885 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 18:42:56,886 - INFO - Memory usage at start_fit: CPU 2949.8 MB, GPU 48.1 MB
2024-12-27 18:42:56,886 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:42:56,887 - INFO - Number of unique classes: 43
2024-12-27 18:42:57,232 - INFO - Fitted scaler and transformed data
2024-12-27 18:42:57,233 - INFO - Scaling time: 0.34s
2024-12-27 18:42:58,538 - INFO - Epoch 1/25, Train Loss: 5.1264, Val Loss: 2.2468
2024-12-27 18:42:59,859 - INFO - Epoch 2/25, Train Loss: 1.0104, Val Loss: 1.4936
2024-12-27 18:43:01,049 - INFO - Epoch 3/25, Train Loss: 0.5743, Val Loss: 1.2548
2024-12-27 18:43:02,167 - INFO - Epoch 4/25, Train Loss: 0.4762, Val Loss: 1.2162
2024-12-27 18:43:03,402 - INFO - Epoch 5/25, Train Loss: 0.3882, Val Loss: 1.1553
2024-12-27 18:43:04,549 - INFO - Epoch 6/25, Train Loss: 0.3728, Val Loss: 1.3230
2024-12-27 18:43:05,696 - INFO - Epoch 7/25, Train Loss: 0.3558, Val Loss: 1.3363
2024-12-27 18:43:05,696 - INFO - Early stopping triggered at epoch 7
2024-12-27 18:43:05,696 - INFO - Training completed in 8.81s
2024-12-27 18:43:05,696 - INFO - Final memory usage: CPU 3048.4 MB, GPU 48.4 MB
2024-12-27 18:43:05,697 - INFO - Model training completed in 8.81s
2024-12-27 18:43:05,726 - INFO - Prediction completed in 0.03s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:43:05,738 - INFO - Poison rate 0.1 completed in 8.86s
2024-12-27 18:43:05,738 - INFO - 
Processing poison rate: 0.2
2024-12-27 18:43:05,739 - INFO - Label flipping details:
2024-12-27 18:43:05,739 - INFO - - Source class: 1
2024-12-27 18:43:05,740 - INFO - - Target class: 0
2024-12-27 18:43:05,740 - INFO - - Available samples in source class: 913
2024-12-27 18:43:05,740 - INFO - - Requested samples to poison: 3951
2024-12-27 18:43:05,740 - INFO - - Actual samples to flip: 912
2024-12-27 18:43:05,740 - INFO - - Samples remaining in source class: 1
2024-12-27 18:43:05,740 - INFO - Successfully flipped 912 labels from class 1 to 0
2024-12-27 18:43:05,740 - INFO - Total number of labels flipped: 912
2024-12-27 18:43:05,740 - INFO - Label flipping completed in 0.00s
2024-12-27 18:43:05,740 - INFO - Training set processing completed in 0.00s
2024-12-27 18:43:05,740 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 18:43:05,741 - INFO - Memory usage at start_fit: CPU 2951.9 MB, GPU 48.1 MB
2024-12-27 18:43:05,741 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:43:05,742 - INFO - Number of unique classes: 43
2024-12-27 18:43:06,070 - INFO - Fitted scaler and transformed data
2024-12-27 18:43:06,071 - INFO - Scaling time: 0.33s
2024-12-27 18:43:07,258 - INFO - Epoch 1/25, Train Loss: 5.1428, Val Loss: 1.9455
2024-12-27 18:43:08,429 - INFO - Epoch 2/25, Train Loss: 0.9399, Val Loss: 1.5694
2024-12-27 18:43:09,619 - INFO - Epoch 3/25, Train Loss: 0.5822, Val Loss: 1.3111
2024-12-27 18:43:10,785 - INFO - Epoch 4/25, Train Loss: 0.4777, Val Loss: 1.2885
2024-12-27 18:43:11,934 - INFO - Epoch 5/25, Train Loss: 0.4090, Val Loss: 1.3406
2024-12-27 18:43:13,083 - INFO - Epoch 6/25, Train Loss: 0.3481, Val Loss: 1.3058
2024-12-27 18:43:13,083 - INFO - Early stopping triggered at epoch 6
2024-12-27 18:43:13,083 - INFO - Training completed in 7.34s
2024-12-27 18:43:13,084 - INFO - Final memory usage: CPU 3051.6 MB, GPU 48.4 MB
2024-12-27 18:43:13,084 - INFO - Model training completed in 7.34s
2024-12-27 18:43:13,114 - INFO - Prediction completed in 0.03s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:43:13,125 - INFO - Poison rate 0.2 completed in 7.39s
2024-12-27 18:43:13,126 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 18:43:13,126 - INFO - Total evaluation time: 89.87s
2024-12-27 18:43:13,133 - INFO - 
Progress: 18.8% - Evaluating GTSRB with SVM (dynadetect mode, iteration 1/1)
2024-12-27 18:43:13,206 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 18:43:13,279 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 18:43:13,364 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 18:43:13,365 - INFO - Dataset type: image
2024-12-27 18:43:13,365 - INFO - Sample size: 39209
2024-12-27 18:43:13,365 - INFO - Using device: cuda
2024-12-27 18:43:13,365 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 18:43:13,367 - INFO - Loading datasets...
2024-12-27 18:43:30,636 - INFO - Dataset loading completed in 17.27s
2024-12-27 18:43:30,636 - INFO - Extracting validation features...
2024-12-27 18:43:30,636 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:31,  4.36it/s]Extracting features:   3%|▎         | 4/139 [00:00<00:12, 11.13it/s]Extracting features:   6%|▌         | 8/139 [00:00<00:06, 18.84it/s]Extracting features:  10%|█         | 14/139 [00:00<00:04, 30.20it/s]Extracting features:  15%|█▌        | 21/139 [00:00<00:02, 39.48it/s]Extracting features:  20%|██        | 28/139 [00:00<00:02, 46.61it/s]Extracting features:  25%|██▌       | 35/139 [00:00<00:02, 51.26it/s]Extracting features:  29%|██▉       | 41/139 [00:01<00:01, 51.88it/s]Extracting features:  34%|███▍      | 47/139 [00:01<00:01, 53.67it/s]Extracting features:  38%|███▊      | 53/139 [00:01<00:01, 54.51it/s]Extracting features:  43%|████▎     | 60/139 [00:01<00:01, 57.28it/s]Extracting features:  48%|████▊     | 67/139 [00:01<00:01, 57.24it/s]Extracting features:  53%|█████▎    | 74/139 [00:01<00:01, 58.60it/s]Extracting features:  58%|█████▊    | 81/139 [00:01<00:00, 60.53it/s]Extracting features:  63%|██████▎   | 88/139 [00:01<00:00, 62.56it/s]Extracting features:  68%|██████▊   | 95/139 [00:01<00:00, 62.25it/s]Extracting features:  73%|███████▎  | 102/139 [00:02<00:00, 60.57it/s]Extracting features:  78%|███████▊  | 109/139 [00:02<00:00, 59.40it/s]Extracting features:  83%|████████▎ | 115/139 [00:02<00:00, 57.19it/s]Extracting features:  88%|████████▊ | 122/139 [00:02<00:00, 60.10it/s]Extracting features:  93%|█████████▎| 129/139 [00:02<00:00, 61.39it/s]Extracting features:  99%|█████████▊| 137/139 [00:02<00:00, 66.19it/s]Extracting features: 100%|██████████| 139/139 [00:02<00:00, 51.10it/s]
2024-12-27 18:43:33,368 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 18:43:33,368 - INFO - Validation feature extraction completed in 2.73s
2024-12-27 18:43:33,368 - INFO - Extracting training features...
2024-12-27 18:43:33,368 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<02:02,  5.04it/s]Extracting features:   1%|▏         | 8/618 [00:00<00:19, 31.25it/s]Extracting features:   2%|▏         | 13/618 [00:00<00:16, 37.64it/s]Extracting features:   3%|▎         | 19/618 [00:00<00:14, 40.40it/s]Extracting features:   4%|▍         | 25/618 [00:00<00:13, 45.26it/s]Extracting features:   5%|▍         | 30/618 [00:00<00:12, 46.49it/s]Extracting features:   6%|▌         | 37/618 [00:00<00:11, 51.32it/s]Extracting features:   7%|▋         | 43/618 [00:00<00:11, 50.69it/s]Extracting features:   8%|▊         | 49/618 [00:01<00:11, 49.98it/s]Extracting features:   9%|▉         | 55/618 [00:01<00:11, 49.79it/s]Extracting features:  10%|▉         | 61/618 [00:01<00:10, 51.13it/s]Extracting features:  11%|█         | 67/618 [00:01<00:10, 52.61it/s]Extracting features:  12%|█▏        | 74/618 [00:01<00:09, 55.65it/s]Extracting features:  13%|█▎        | 80/618 [00:01<00:09, 55.59it/s]Extracting features:  14%|█▍        | 86/618 [00:01<00:09, 56.48it/s]Extracting features:  15%|█▍        | 92/618 [00:01<00:09, 56.51it/s]Extracting features:  16%|█▌        | 98/618 [00:02<00:09, 52.89it/s]Extracting features:  17%|█▋        | 104/618 [00:02<00:10, 47.98it/s]Extracting features:  18%|█▊        | 110/618 [00:02<00:10, 49.02it/s]Extracting features:  19%|█▊        | 115/618 [00:02<00:10, 47.45it/s]Extracting features:  19%|█▉        | 120/618 [00:02<00:11, 44.69it/s]Extracting features:  20%|██        | 126/618 [00:02<00:10, 47.10it/s]Extracting features:  22%|██▏       | 134/618 [00:02<00:09, 52.59it/s]Extracting features:  23%|██▎       | 141/618 [00:02<00:08, 55.45it/s]Extracting features:  24%|██▍       | 147/618 [00:02<00:08, 56.21it/s]Extracting features:  25%|██▍       | 153/618 [00:03<00:08, 55.93it/s]Extracting features:  26%|██▌       | 161/618 [00:03<00:07, 60.66it/s]Extracting features:  27%|██▋       | 169/618 [00:03<00:07, 62.90it/s]Extracting features:  28%|██▊       | 176/618 [00:03<00:07, 60.67it/s]Extracting features:  30%|██▉       | 183/618 [00:03<00:07, 59.80it/s]Extracting features:  31%|███       | 189/618 [00:03<00:08, 53.53it/s]Extracting features:  32%|███▏      | 196/618 [00:03<00:07, 55.85it/s]Extracting features:  33%|███▎      | 203/618 [00:03<00:07, 57.73it/s]Extracting features:  34%|███▍      | 209/618 [00:04<00:07, 52.00it/s]Extracting features:  35%|███▍      | 216/618 [00:04<00:07, 55.12it/s]Extracting features:  36%|███▌      | 223/618 [00:04<00:06, 57.99it/s]Extracting features:  37%|███▋      | 230/618 [00:04<00:06, 60.70it/s]Extracting features:  38%|███▊      | 237/618 [00:04<00:06, 60.34it/s]Extracting features:  39%|███▉      | 244/618 [00:04<00:06, 58.74it/s]Extracting features:  41%|████      | 252/618 [00:04<00:05, 62.48it/s]Extracting features:  42%|████▏     | 259/618 [00:04<00:06, 59.41it/s]Extracting features:  43%|████▎     | 266/618 [00:04<00:05, 60.07it/s]Extracting features:  44%|████▍     | 273/618 [00:05<00:06, 54.80it/s]Extracting features:  45%|████▌     | 280/618 [00:05<00:05, 57.02it/s]Extracting features:  46%|████▋     | 286/618 [00:05<00:05, 57.27it/s]Extracting features:  47%|████▋     | 292/618 [00:05<00:05, 57.61it/s]Extracting features:  48%|████▊     | 298/618 [00:05<00:05, 58.20it/s]Extracting features:  49%|████▉     | 304/618 [00:05<00:05, 58.46it/s]Extracting features:  50%|█████     | 311/618 [00:05<00:05, 60.07it/s]Extracting features:  51%|█████▏    | 318/618 [00:05<00:04, 60.28it/s]Extracting features:  53%|█████▎    | 325/618 [00:06<00:04, 60.83it/s]Extracting features:  54%|█████▎    | 332/618 [00:06<00:04, 61.10it/s]Extracting features:  55%|█████▍    | 339/618 [00:06<00:04, 59.03it/s]Extracting features:  56%|█████▌    | 346/618 [00:06<00:04, 57.67it/s]Extracting features:  57%|█████▋    | 352/618 [00:06<00:04, 55.53it/s]Extracting features:  58%|█████▊    | 358/618 [00:06<00:04, 52.15it/s]Extracting features:  59%|█████▉    | 364/618 [00:06<00:04, 54.08it/s]Extracting features:  60%|█████▉    | 370/618 [00:06<00:04, 55.53it/s]Extracting features:  61%|██████    | 376/618 [00:06<00:04, 56.15it/s]Extracting features:  62%|██████▏   | 382/618 [00:07<00:04, 56.53it/s]Extracting features:  63%|██████▎   | 389/618 [00:07<00:03, 58.20it/s]Extracting features:  64%|██████▍   | 397/618 [00:07<00:03, 60.55it/s]Extracting features:  65%|██████▌   | 404/618 [00:07<00:03, 62.50it/s]Extracting features:  67%|██████▋   | 411/618 [00:07<00:03, 61.67it/s]Extracting features:  68%|██████▊   | 418/618 [00:07<00:03, 60.34it/s]Extracting features:  69%|██████▉   | 425/618 [00:07<00:03, 59.87it/s]Extracting features:  70%|██████▉   | 432/618 [00:07<00:03, 61.16it/s]Extracting features:  71%|███████   | 440/618 [00:07<00:02, 63.87it/s]Extracting features:  72%|███████▏  | 447/618 [00:08<00:02, 59.48it/s]Extracting features:  73%|███████▎  | 454/618 [00:08<00:02, 61.52it/s]Extracting features:  75%|███████▍  | 461/618 [00:08<00:02, 57.77it/s]Extracting features:  76%|███████▌  | 467/618 [00:08<00:02, 57.25it/s]Extracting features:  77%|███████▋  | 474/618 [00:08<00:02, 59.20it/s]Extracting features:  78%|███████▊  | 480/618 [00:08<00:02, 57.03it/s]Extracting features:  79%|███████▉  | 487/618 [00:08<00:02, 59.10it/s]Extracting features:  80%|███████▉  | 493/618 [00:08<00:02, 57.49it/s]Extracting features:  81%|████████  | 500/618 [00:08<00:01, 59.28it/s]Extracting features:  82%|████████▏ | 506/618 [00:09<00:01, 58.69it/s]Extracting features:  83%|████████▎ | 513/618 [00:09<00:01, 60.40it/s]Extracting features:  84%|████████▍ | 520/618 [00:09<00:01, 58.17it/s]Extracting features:  85%|████████▌ | 527/618 [00:09<00:01, 60.61it/s]Extracting features:  86%|████████▋ | 534/618 [00:09<00:01, 60.46it/s]Extracting features:  88%|████████▊ | 541/618 [00:09<00:01, 60.52it/s]Extracting features:  89%|████████▊ | 548/618 [00:09<00:01, 61.12it/s]Extracting features:  90%|████████▉ | 555/618 [00:09<00:01, 61.43it/s]Extracting features:  91%|█████████ | 562/618 [00:10<00:00, 58.66it/s]Extracting features:  92%|█████████▏| 568/618 [00:10<00:00, 55.47it/s]Extracting features:  93%|█████████▎| 575/618 [00:10<00:00, 57.74it/s]Extracting features:  94%|█████████▍| 582/618 [00:10<00:00, 59.03it/s]Extracting features:  95%|█████████▌| 588/618 [00:10<00:00, 55.78it/s]Extracting features:  96%|█████████▋| 595/618 [00:10<00:00, 57.59it/s]Extracting features:  97%|█████████▋| 601/618 [00:10<00:00, 56.99it/s]Extracting features:  99%|█████████▊| 609/618 [00:10<00:00, 61.42it/s]Extracting features: 100%|█████████▉| 616/618 [00:11<00:00, 54.28it/s]Extracting features: 100%|██████████| 618/618 [00:11<00:00, 55.45it/s]
2024-12-27 18:43:44,547 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 18:43:44,548 - INFO - Training feature extraction completed in 11.18s
2024-12-27 18:43:44,548 - INFO - Creating model for classifier: SVM
2024-12-27 18:43:44,548 - INFO - Using device: cuda
2024-12-27 18:43:44,548 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-27 18:43:44,548 - INFO - 
Processing poison rate: 0.0
2024-12-27 18:43:44,548 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:43:44,548 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:43:46,325 - INFO - Feature scaling completed in 1.78s
2024-12-27 18:43:46,325 - INFO - Starting feature selection (k=50)
2024-12-27 18:43:46,343 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 18:43:46,343 - INFO - Starting anomaly detection
2024-12-27 18:43:53,164 - INFO - Anomaly detection completed in 6.82s
2024-12-27 18:43:53,164 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:43:53,164 - INFO - Total fit_transform time: 8.62s
2024-12-27 18:43:53,165 - INFO - Training set processing completed in 8.62s
2024-12-27 18:43:53,165 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 18:43:53,167 - INFO - Memory usage at start_fit: CPU 2947.9 MB, GPU 47.3 MB
2024-12-27 18:43:53,167 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:43:53,172 - INFO - Number of unique classes: 43
2024-12-27 18:43:53,516 - INFO - Fitted scaler and transformed data
2024-12-27 18:43:53,516 - INFO - Scaling time: 0.34s
2024-12-27 18:43:54,680 - INFO - Epoch 1/25, Train Loss: 5.2323, Val Loss: 2.1342
2024-12-27 18:43:55,760 - INFO - Epoch 2/25, Train Loss: 0.9346, Val Loss: 1.6738
2024-12-27 18:43:56,911 - INFO - Epoch 3/25, Train Loss: 0.5788, Val Loss: 1.3556
2024-12-27 18:43:58,211 - INFO - Epoch 4/25, Train Loss: 0.4498, Val Loss: 1.3681
2024-12-27 18:43:59,521 - INFO - Epoch 5/25, Train Loss: 0.3628, Val Loss: 1.4127
2024-12-27 18:43:59,522 - INFO - Early stopping triggered at epoch 5
2024-12-27 18:43:59,522 - INFO - Training completed in 6.36s
2024-12-27 18:43:59,522 - INFO - Final memory usage: CPU 3048.9 MB, GPU 48.4 MB
2024-12-27 18:43:59,523 - INFO - Model training completed in 6.36s
2024-12-27 18:43:59,554 - INFO - Prediction completed in 0.03s
2024-12-27 18:43:59,566 - INFO - Poison rate 0.0 completed in 15.02s
2024-12-27 18:43:59,566 - INFO - 
Processing poison rate: 0.01
2024-12-27 18:43:59,567 - INFO - Label flipping details:
2024-12-27 18:43:59,567 - INFO - - Source class: 1
2024-12-27 18:43:59,567 - INFO - - Target class: 0
2024-12-27 18:43:59,567 - INFO - - Available samples in source class: 918
2024-12-27 18:43:59,567 - INFO - - Requested samples to poison: 197
2024-12-27 18:43:59,568 - INFO - - Actual samples to flip: 197
2024-12-27 18:43:59,568 - INFO - - Samples remaining in source class: 721
2024-12-27 18:43:59,568 - INFO - Successfully flipped 197 labels from class 1 to 0
2024-12-27 18:43:59,568 - INFO - Total number of labels flipped: 197
2024-12-27 18:43:59,568 - INFO - Label flipping completed in 0.00s
2024-12-27 18:43:59,568 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:43:59,568 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:44:01,465 - INFO - Feature scaling completed in 1.90s
2024-12-27 18:44:01,465 - INFO - Starting feature selection (k=50)
2024-12-27 18:44:01,516 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 18:44:01,516 - INFO - Starting anomaly detection
2024-12-27 18:44:08,193 - INFO - Anomaly detection completed in 6.68s
2024-12-27 18:44:08,193 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:44:08,193 - INFO - Total fit_transform time: 8.63s
2024-12-27 18:44:08,194 - INFO - Training set processing completed in 8.63s
2024-12-27 18:44:08,194 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 18:44:08,195 - INFO - Memory usage at start_fit: CPU 2952.5 MB, GPU 48.1 MB
2024-12-27 18:44:08,195 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:44:08,200 - INFO - Number of unique classes: 43
2024-12-27 18:44:08,570 - INFO - Fitted scaler and transformed data
2024-12-27 18:44:08,570 - INFO - Scaling time: 0.37s
2024-12-27 18:44:09,643 - INFO - Epoch 1/25, Train Loss: 5.3652, Val Loss: 1.9195
2024-12-27 18:44:10,926 - INFO - Epoch 2/25, Train Loss: 1.0191, Val Loss: 1.3776
2024-12-27 18:44:12,072 - INFO - Epoch 3/25, Train Loss: 0.6605, Val Loss: 1.3182
2024-12-27 18:44:13,289 - INFO - Epoch 4/25, Train Loss: 0.5183, Val Loss: 1.2852
2024-12-27 18:44:14,677 - INFO - Epoch 5/25, Train Loss: 0.4269, Val Loss: 1.2317
2024-12-27 18:44:15,885 - INFO - Epoch 6/25, Train Loss: 0.4213, Val Loss: 1.1194
2024-12-27 18:44:17,114 - INFO - Epoch 7/25, Train Loss: 0.3439, Val Loss: 1.2539
2024-12-27 18:44:18,433 - INFO - Epoch 8/25, Train Loss: 0.3538, Val Loss: 1.3096
2024-12-27 18:44:18,433 - INFO - Early stopping triggered at epoch 8
2024-12-27 18:44:18,433 - INFO - Training completed in 10.24s
2024-12-27 18:44:18,434 - INFO - Final memory usage: CPU 3050.2 MB, GPU 48.4 MB
2024-12-27 18:44:18,434 - INFO - Model training completed in 10.24s
2024-12-27 18:44:18,465 - INFO - Prediction completed in 0.03s
2024-12-27 18:44:18,476 - INFO - Poison rate 0.01 completed in 18.91s
2024-12-27 18:44:18,477 - INFO - 
Processing poison rate: 0.03
2024-12-27 18:44:18,478 - INFO - Label flipping details:
2024-12-27 18:44:18,478 - INFO - - Source class: 1
2024-12-27 18:44:18,478 - INFO - - Target class: 0
2024-12-27 18:44:18,478 - INFO - - Available samples in source class: 918
2024-12-27 18:44:18,478 - INFO - - Requested samples to poison: 592
2024-12-27 18:44:18,478 - INFO - - Actual samples to flip: 592
2024-12-27 18:44:18,478 - INFO - - Samples remaining in source class: 326
2024-12-27 18:44:18,478 - INFO - Successfully flipped 592 labels from class 1 to 0
2024-12-27 18:44:18,478 - INFO - Total number of labels flipped: 592
2024-12-27 18:44:18,479 - INFO - Label flipping completed in 0.00s
2024-12-27 18:44:18,479 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:44:18,479 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:44:20,549 - INFO - Feature scaling completed in 2.07s
2024-12-27 18:44:20,549 - INFO - Starting feature selection (k=50)
2024-12-27 18:44:20,600 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 18:44:20,600 - INFO - Starting anomaly detection
2024-12-27 18:44:27,610 - INFO - Anomaly detection completed in 7.01s
2024-12-27 18:44:27,611 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:44:27,611 - INFO - Total fit_transform time: 9.13s
2024-12-27 18:44:27,612 - INFO - Training set processing completed in 9.13s
2024-12-27 18:44:27,613 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 18:44:27,614 - INFO - Memory usage at start_fit: CPU 2953.8 MB, GPU 48.1 MB
2024-12-27 18:44:27,615 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:44:27,619 - INFO - Number of unique classes: 43
2024-12-27 18:44:27,966 - INFO - Fitted scaler and transformed data
2024-12-27 18:44:27,967 - INFO - Scaling time: 0.34s
2024-12-27 18:44:29,191 - INFO - Epoch 1/25, Train Loss: 5.3270, Val Loss: 2.4124
2024-12-27 18:44:30,478 - INFO - Epoch 2/25, Train Loss: 1.0915, Val Loss: 1.5592
2024-12-27 18:44:31,779 - INFO - Epoch 3/25, Train Loss: 0.6777, Val Loss: 1.4342
2024-12-27 18:44:33,095 - INFO - Epoch 4/25, Train Loss: 0.5175, Val Loss: 1.4456
2024-12-27 18:44:34,422 - INFO - Epoch 5/25, Train Loss: 0.4030, Val Loss: 1.4319
2024-12-27 18:44:34,423 - INFO - Early stopping triggered at epoch 5
2024-12-27 18:44:34,423 - INFO - Training completed in 6.81s
2024-12-27 18:44:34,423 - INFO - Final memory usage: CPU 3051.5 MB, GPU 48.4 MB
2024-12-27 18:44:34,424 - INFO - Model training completed in 6.81s
2024-12-27 18:44:34,455 - INFO - Prediction completed in 0.03s
2024-12-27 18:44:34,472 - INFO - Poison rate 0.03 completed in 16.00s
2024-12-27 18:44:34,473 - INFO - 
Processing poison rate: 0.05
2024-12-27 18:44:34,477 - INFO - Label flipping details:
2024-12-27 18:44:34,477 - INFO - - Source class: 1
2024-12-27 18:44:34,477 - INFO - - Target class: 0
2024-12-27 18:44:34,478 - INFO - - Available samples in source class: 918
2024-12-27 18:44:34,478 - INFO - - Requested samples to poison: 987
2024-12-27 18:44:34,478 - INFO - - Actual samples to flip: 917
2024-12-27 18:44:34,478 - INFO - - Samples remaining in source class: 1
2024-12-27 18:44:34,479 - INFO - Successfully flipped 917 labels from class 1 to 0
2024-12-27 18:44:34,480 - INFO - Total number of labels flipped: 917
2024-12-27 18:44:34,480 - INFO - Label flipping completed in 0.01s
2024-12-27 18:44:34,480 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:44:34,481 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:44:36,546 - INFO - Feature scaling completed in 2.06s
2024-12-27 18:44:36,546 - INFO - Starting feature selection (k=50)
2024-12-27 18:44:36,598 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 18:44:36,599 - INFO - Starting anomaly detection
2024-12-27 18:44:43,487 - INFO - Anomaly detection completed in 6.89s
2024-12-27 18:44:43,487 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:44:43,488 - INFO - Total fit_transform time: 9.01s
2024-12-27 18:44:43,488 - INFO - Training set processing completed in 9.01s
2024-12-27 18:44:43,488 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 18:44:43,489 - INFO - Memory usage at start_fit: CPU 2955.0 MB, GPU 48.1 MB
2024-12-27 18:44:43,489 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:44:43,492 - INFO - Number of unique classes: 43
2024-12-27 18:44:43,837 - INFO - Fitted scaler and transformed data
2024-12-27 18:44:43,837 - INFO - Scaling time: 0.34s
2024-12-27 18:44:44,884 - INFO - Epoch 1/25, Train Loss: 4.9096, Val Loss: 2.1116
2024-12-27 18:44:46,103 - INFO - Epoch 2/25, Train Loss: 0.9841, Val Loss: 1.3749
2024-12-27 18:44:47,369 - INFO - Epoch 3/25, Train Loss: 0.5974, Val Loss: 1.2172
2024-12-27 18:44:48,551 - INFO - Epoch 4/25, Train Loss: 0.4533, Val Loss: 1.3211
2024-12-27 18:44:49,646 - INFO - Epoch 5/25, Train Loss: 0.4035, Val Loss: 1.3160
2024-12-27 18:44:49,647 - INFO - Early stopping triggered at epoch 5
2024-12-27 18:44:49,647 - INFO - Training completed in 6.16s
2024-12-27 18:44:49,647 - INFO - Final memory usage: CPU 3053.5 MB, GPU 48.4 MB
2024-12-27 18:44:49,648 - INFO - Model training completed in 6.16s
2024-12-27 18:44:49,678 - INFO - Prediction completed in 0.03s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:44:49,689 - INFO - Poison rate 0.05 completed in 15.22s
2024-12-27 18:44:49,690 - INFO - 
Processing poison rate: 0.07
2024-12-27 18:44:49,691 - INFO - Label flipping details:
2024-12-27 18:44:49,691 - INFO - - Source class: 1
2024-12-27 18:44:49,691 - INFO - - Target class: 0
2024-12-27 18:44:49,691 - INFO - - Available samples in source class: 918
2024-12-27 18:44:49,691 - INFO - - Requested samples to poison: 1382
2024-12-27 18:44:49,691 - INFO - - Actual samples to flip: 917
2024-12-27 18:44:49,691 - INFO - - Samples remaining in source class: 1
2024-12-27 18:44:49,691 - INFO - Successfully flipped 917 labels from class 1 to 0
2024-12-27 18:44:49,692 - INFO - Total number of labels flipped: 917
2024-12-27 18:44:49,692 - INFO - Label flipping completed in 0.00s
2024-12-27 18:44:49,692 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:44:49,692 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:44:51,481 - INFO - Feature scaling completed in 1.79s
2024-12-27 18:44:51,482 - INFO - Starting feature selection (k=50)
2024-12-27 18:44:51,532 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 18:44:51,532 - INFO - Starting anomaly detection
2024-12-27 18:44:59,908 - INFO - Anomaly detection completed in 8.38s
2024-12-27 18:44:59,908 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:44:59,908 - INFO - Total fit_transform time: 10.22s
2024-12-27 18:44:59,908 - INFO - Training set processing completed in 10.22s
2024-12-27 18:44:59,909 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 18:44:59,909 - INFO - Memory usage at start_fit: CPU 2957.0 MB, GPU 48.1 MB
2024-12-27 18:44:59,910 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:44:59,911 - INFO - Number of unique classes: 43
2024-12-27 18:45:00,277 - INFO - Fitted scaler and transformed data
2024-12-27 18:45:00,278 - INFO - Scaling time: 0.37s
2024-12-27 18:45:01,400 - INFO - Epoch 1/25, Train Loss: 4.9828, Val Loss: 2.0031
2024-12-27 18:45:02,649 - INFO - Epoch 2/25, Train Loss: 0.9437, Val Loss: 1.4555
2024-12-27 18:45:03,946 - INFO - Epoch 3/25, Train Loss: 0.5528, Val Loss: 1.2073
2024-12-27 18:45:05,312 - INFO - Epoch 4/25, Train Loss: 0.4215, Val Loss: 1.3707
2024-12-27 18:45:06,641 - INFO - Epoch 5/25, Train Loss: 0.3840, Val Loss: 1.2404
2024-12-27 18:45:06,641 - INFO - Early stopping triggered at epoch 5
2024-12-27 18:45:06,641 - INFO - Training completed in 6.73s
2024-12-27 18:45:06,642 - INFO - Final memory usage: CPU 3053.5 MB, GPU 48.4 MB
2024-12-27 18:45:06,642 - INFO - Model training completed in 6.73s
2024-12-27 18:45:06,672 - INFO - Prediction completed in 0.03s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:45:06,690 - INFO - Poison rate 0.07 completed in 17.00s
2024-12-27 18:45:06,690 - INFO - 
Processing poison rate: 0.1
2024-12-27 18:45:06,694 - INFO - Label flipping details:
2024-12-27 18:45:06,694 - INFO - - Source class: 1
2024-12-27 18:45:06,695 - INFO - - Target class: 0
2024-12-27 18:45:06,695 - INFO - - Available samples in source class: 918
2024-12-27 18:45:06,695 - INFO - - Requested samples to poison: 1975
2024-12-27 18:45:06,696 - INFO - - Actual samples to flip: 917
2024-12-27 18:45:06,696 - INFO - - Samples remaining in source class: 1
2024-12-27 18:45:06,696 - INFO - Successfully flipped 917 labels from class 1 to 0
2024-12-27 18:45:06,697 - INFO - Total number of labels flipped: 917
2024-12-27 18:45:06,697 - INFO - Label flipping completed in 0.01s
2024-12-27 18:45:06,698 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:45:06,698 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:45:08,617 - INFO - Feature scaling completed in 1.92s
2024-12-27 18:45:08,617 - INFO - Starting feature selection (k=50)
2024-12-27 18:45:08,667 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 18:45:08,668 - INFO - Starting anomaly detection
2024-12-27 18:45:15,795 - INFO - Anomaly detection completed in 7.13s
2024-12-27 18:45:15,795 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:45:15,795 - INFO - Total fit_transform time: 9.10s
2024-12-27 18:45:15,796 - INFO - Training set processing completed in 9.10s
2024-12-27 18:45:15,796 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 18:45:15,797 - INFO - Memory usage at start_fit: CPU 2957.0 MB, GPU 48.1 MB
2024-12-27 18:45:15,798 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:45:15,803 - INFO - Number of unique classes: 43
2024-12-27 18:45:16,132 - INFO - Fitted scaler and transformed data
2024-12-27 18:45:16,133 - INFO - Scaling time: 0.33s
2024-12-27 18:45:17,243 - INFO - Epoch 1/25, Train Loss: 5.1047, Val Loss: 2.0604
2024-12-27 18:45:18,288 - INFO - Epoch 2/25, Train Loss: 0.9626, Val Loss: 1.5579
2024-12-27 18:45:19,397 - INFO - Epoch 3/25, Train Loss: 0.5417, Val Loss: 1.3883
2024-12-27 18:45:20,526 - INFO - Epoch 4/25, Train Loss: 0.4605, Val Loss: 1.3546
2024-12-27 18:45:21,675 - INFO - Epoch 5/25, Train Loss: 0.4227, Val Loss: 1.3778
2024-12-27 18:45:22,797 - INFO - Epoch 6/25, Train Loss: 0.3729, Val Loss: 1.2877
2024-12-27 18:45:23,944 - INFO - Epoch 7/25, Train Loss: 0.3512, Val Loss: 1.5301
2024-12-27 18:45:25,172 - INFO - Epoch 8/25, Train Loss: 0.2881, Val Loss: 1.3791
2024-12-27 18:45:25,172 - INFO - Early stopping triggered at epoch 8
2024-12-27 18:45:25,172 - INFO - Training completed in 9.38s
2024-12-27 18:45:25,173 - INFO - Final memory usage: CPU 3053.5 MB, GPU 48.4 MB
2024-12-27 18:45:25,173 - INFO - Model training completed in 9.38s
2024-12-27 18:45:25,204 - INFO - Prediction completed in 0.03s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:45:25,215 - INFO - Poison rate 0.1 completed in 18.52s
2024-12-27 18:45:25,215 - INFO - 
Processing poison rate: 0.2
2024-12-27 18:45:25,217 - INFO - Label flipping details:
2024-12-27 18:45:25,217 - INFO - - Source class: 1
2024-12-27 18:45:25,217 - INFO - - Target class: 0
2024-12-27 18:45:25,217 - INFO - - Available samples in source class: 918
2024-12-27 18:45:25,217 - INFO - - Requested samples to poison: 3951
2024-12-27 18:45:25,217 - INFO - - Actual samples to flip: 917
2024-12-27 18:45:25,217 - INFO - - Samples remaining in source class: 1
2024-12-27 18:45:25,217 - INFO - Successfully flipped 917 labels from class 1 to 0
2024-12-27 18:45:25,217 - INFO - Total number of labels flipped: 917
2024-12-27 18:45:25,217 - INFO - Label flipping completed in 0.00s
2024-12-27 18:45:25,217 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:45:25,217 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:45:27,037 - INFO - Feature scaling completed in 1.82s
2024-12-27 18:45:27,037 - INFO - Starting feature selection (k=50)
2024-12-27 18:45:27,092 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 18:45:27,092 - INFO - Starting anomaly detection
2024-12-27 18:45:33,695 - INFO - Anomaly detection completed in 6.60s
2024-12-27 18:45:33,695 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:45:33,695 - INFO - Total fit_transform time: 8.48s
2024-12-27 18:45:33,696 - INFO - Training set processing completed in 8.48s
2024-12-27 18:45:33,696 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 18:45:33,697 - INFO - Memory usage at start_fit: CPU 2957.0 MB, GPU 48.1 MB
2024-12-27 18:45:33,697 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:45:33,702 - INFO - Number of unique classes: 43
2024-12-27 18:45:34,026 - INFO - Fitted scaler and transformed data
2024-12-27 18:45:34,026 - INFO - Scaling time: 0.32s
2024-12-27 18:45:35,139 - INFO - Epoch 1/25, Train Loss: 4.9192, Val Loss: 2.1179
2024-12-27 18:45:36,131 - INFO - Epoch 2/25, Train Loss: 0.9444, Val Loss: 1.6965
2024-12-27 18:45:37,196 - INFO - Epoch 3/25, Train Loss: 0.5878, Val Loss: 1.4681
2024-12-27 18:45:38,234 - INFO - Epoch 4/25, Train Loss: 0.4596, Val Loss: 1.4439
2024-12-27 18:45:39,255 - INFO - Epoch 5/25, Train Loss: 0.3892, Val Loss: 1.5430
2024-12-27 18:45:40,259 - INFO - Epoch 6/25, Train Loss: 0.3632, Val Loss: 1.5854
2024-12-27 18:45:40,260 - INFO - Early stopping triggered at epoch 6
2024-12-27 18:45:40,260 - INFO - Training completed in 6.56s
2024-12-27 18:45:40,260 - INFO - Final memory usage: CPU 3055.2 MB, GPU 48.4 MB
2024-12-27 18:45:40,261 - INFO - Model training completed in 6.56s
2024-12-27 18:45:40,290 - INFO - Prediction completed in 0.03s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:45:40,302 - INFO - Poison rate 0.2 completed in 15.09s
2024-12-27 18:45:40,303 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 18:45:40,303 - INFO - Total evaluation time: 146.94s
2024-12-27 18:45:40,309 - INFO - 
Progress: 19.8% - Evaluating GTSRB with LogisticRegression (standard mode, iteration 1/1)
2024-12-27 18:45:40,368 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 18:45:40,445 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 18:45:40,548 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 18:45:40,549 - INFO - Dataset type: image
2024-12-27 18:45:40,549 - INFO - Sample size: 39209
2024-12-27 18:45:40,549 - INFO - Using device: cuda
2024-12-27 18:45:40,549 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 18:45:40,554 - INFO - Loading datasets...
2024-12-27 18:45:57,676 - INFO - Dataset loading completed in 17.12s
2024-12-27 18:45:57,677 - INFO - Extracting validation features...
2024-12-27 18:45:57,677 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:31,  4.40it/s]Extracting features:   2%|▏         | 3/139 [00:00<00:15,  8.77it/s]Extracting features:   6%|▌         | 8/139 [00:00<00:06, 21.58it/s]Extracting features:  10%|█         | 14/139 [00:00<00:03, 32.48it/s]Extracting features:  14%|█▍        | 20/139 [00:00<00:03, 39.20it/s]Extracting features:  19%|█▊        | 26/139 [00:00<00:02, 45.27it/s]Extracting features:  22%|██▏       | 31/139 [00:00<00:02, 44.33it/s]Extracting features:  27%|██▋       | 37/139 [00:01<00:02, 46.42it/s]Extracting features:  31%|███       | 43/139 [00:01<00:01, 49.31it/s]Extracting features:  35%|███▌      | 49/139 [00:01<00:01, 51.91it/s]Extracting features:  40%|████      | 56/139 [00:01<00:01, 55.72it/s]Extracting features:  45%|████▌     | 63/139 [00:01<00:01, 58.72it/s]Extracting features:  50%|████▉     | 69/139 [00:01<00:01, 56.91it/s]Extracting features:  54%|█████▍    | 75/139 [00:01<00:01, 56.38it/s]Extracting features:  58%|█████▊    | 81/139 [00:01<00:01, 45.29it/s]Extracting features:  62%|██████▏   | 86/139 [00:01<00:01, 44.43it/s]Extracting features:  66%|██████▌   | 92/139 [00:02<00:00, 47.44it/s]Extracting features:  71%|███████   | 99/139 [00:02<00:00, 51.87it/s]Extracting features:  76%|███████▌  | 105/139 [00:02<00:00, 49.01it/s]Extracting features:  80%|███████▉  | 111/139 [00:02<00:00, 49.89it/s]Extracting features:  84%|████████▍ | 117/139 [00:02<00:00, 51.68it/s]Extracting features:  88%|████████▊ | 123/139 [00:02<00:00, 53.54it/s]Extracting features:  93%|█████████▎| 129/139 [00:02<00:00, 50.41it/s]Extracting features:  97%|█████████▋| 135/139 [00:02<00:00, 52.53it/s]Extracting features: 100%|██████████| 139/139 [00:03<00:00, 45.40it/s]
2024-12-27 18:46:00,751 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 18:46:00,751 - INFO - Validation feature extraction completed in 3.07s
2024-12-27 18:46:00,751 - INFO - Extracting training features...
2024-12-27 18:46:00,752 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<02:22,  4.32it/s]Extracting features:   1%|          | 6/618 [00:00<00:29, 20.90it/s]Extracting features:   2%|▏         | 12/618 [00:00<00:18, 32.17it/s]Extracting features:   3%|▎         | 17/618 [00:00<00:16, 36.49it/s]Extracting features:   4%|▎         | 22/618 [00:00<00:17, 34.98it/s]Extracting features:   4%|▍         | 27/618 [00:00<00:15, 37.84it/s]Extracting features:   5%|▌         | 33/618 [00:00<00:14, 40.38it/s]Extracting features:   6%|▌         | 38/618 [00:01<00:15, 38.63it/s]Extracting features:   7%|▋         | 43/618 [00:01<00:14, 40.88it/s]Extracting features:   8%|▊         | 49/618 [00:01<00:12, 44.34it/s]Extracting features:   9%|▉         | 55/618 [00:01<00:12, 46.67it/s]Extracting features:  10%|▉         | 61/618 [00:01<00:11, 48.82it/s]Extracting features:  11%|█         | 66/618 [00:01<00:11, 47.71it/s]Extracting features:  12%|█▏        | 72/618 [00:01<00:11, 49.59it/s]Extracting features:  13%|█▎        | 78/618 [00:01<00:10, 51.58it/s]Extracting features:  14%|█▎        | 84/618 [00:01<00:10, 52.66it/s]Extracting features:  15%|█▍        | 90/618 [00:02<00:10, 51.91it/s]Extracting features:  16%|█▌        | 96/618 [00:02<00:09, 52.49it/s]Extracting features:  17%|█▋        | 102/618 [00:02<00:09, 54.05it/s]Extracting features:  17%|█▋        | 108/618 [00:02<00:09, 55.31it/s]Extracting features:  18%|█▊        | 114/618 [00:02<00:09, 53.99it/s]Extracting features:  19%|█▉        | 120/618 [00:02<00:09, 54.88it/s]Extracting features:  20%|██        | 126/618 [00:02<00:08, 56.16it/s]Extracting features:  21%|██▏       | 132/618 [00:02<00:08, 56.78it/s]Extracting features:  22%|██▏       | 138/618 [00:03<00:09, 50.39it/s]Extracting features:  23%|██▎       | 144/618 [00:03<00:09, 50.52it/s]Extracting features:  24%|██▍       | 150/618 [00:03<00:08, 52.39it/s]Extracting features:  25%|██▌       | 156/618 [00:03<00:08, 53.12it/s]Extracting features:  26%|██▋       | 163/618 [00:03<00:08, 54.79it/s]Extracting features:  27%|██▋       | 169/618 [00:03<00:08, 55.09it/s]Extracting features:  28%|██▊       | 175/618 [00:03<00:08, 51.49it/s]Extracting features:  29%|██▉       | 181/618 [00:03<00:08, 51.71it/s]Extracting features:  30%|███       | 188/618 [00:03<00:07, 54.71it/s]Extracting features:  31%|███▏      | 194/618 [00:04<00:07, 55.63it/s]Extracting features:  33%|███▎      | 201/618 [00:04<00:07, 58.35it/s]Extracting features:  34%|███▎      | 208/618 [00:04<00:06, 59.13it/s]Extracting features:  35%|███▍      | 214/618 [00:04<00:06, 58.96it/s]Extracting features:  36%|███▌      | 221/618 [00:04<00:06, 61.11it/s]Extracting features:  37%|███▋      | 228/618 [00:04<00:06, 58.19it/s]Extracting features:  38%|███▊      | 234/618 [00:04<00:06, 57.73it/s]Extracting features:  39%|███▉      | 241/618 [00:04<00:06, 59.27it/s]Extracting features:  40%|███▉      | 247/618 [00:04<00:06, 59.13it/s]Extracting features:  41%|████      | 253/618 [00:05<00:06, 59.20it/s]Extracting features:  42%|████▏     | 259/618 [00:05<00:06, 58.61it/s]Extracting features:  43%|████▎     | 265/618 [00:05<00:05, 58.83it/s]Extracting features:  44%|████▍     | 271/618 [00:05<00:06, 54.75it/s]Extracting features:  45%|████▍     | 277/618 [00:05<00:06, 54.42it/s]Extracting features:  46%|████▌     | 284/618 [00:05<00:05, 56.03it/s]Extracting features:  47%|████▋     | 291/618 [00:05<00:05, 56.92it/s]Extracting features:  48%|████▊     | 298/618 [00:05<00:05, 57.47it/s]Extracting features:  49%|████▉     | 304/618 [00:05<00:06, 51.72it/s]Extracting features:  50%|█████     | 310/618 [00:06<00:05, 51.36it/s]Extracting features:  51%|█████     | 316/618 [00:06<00:05, 50.65it/s]Extracting features:  52%|█████▏    | 323/618 [00:06<00:05, 54.02it/s]Extracting features:  53%|█████▎    | 330/618 [00:06<00:05, 57.19it/s]Extracting features:  55%|█████▍    | 337/618 [00:06<00:04, 58.21it/s]Extracting features:  56%|█████▌    | 344/618 [00:06<00:04, 57.05it/s]Extracting features:  57%|█████▋    | 350/618 [00:06<00:05, 49.69it/s]Extracting features:  58%|█████▊    | 356/618 [00:06<00:05, 48.18it/s]Extracting features:  58%|█████▊    | 361/618 [00:07<00:05, 44.56it/s]Extracting features:  59%|█████▉    | 366/618 [00:07<00:05, 42.90it/s]Extracting features:  60%|██████    | 371/618 [00:07<00:05, 42.18it/s]Extracting features:  61%|██████    | 378/618 [00:07<00:05, 47.44it/s]Extracting features:  62%|██████▏   | 384/618 [00:07<00:04, 49.37it/s]Extracting features:  63%|██████▎   | 390/618 [00:07<00:04, 51.40it/s]Extracting features:  64%|██████▍   | 397/618 [00:07<00:03, 56.22it/s]Extracting features:  65%|██████▌   | 403/618 [00:07<00:03, 56.68it/s]Extracting features:  66%|██████▌   | 409/618 [00:07<00:03, 55.86it/s]Extracting features:  67%|██████▋   | 415/618 [00:08<00:03, 56.74it/s]Extracting features:  68%|██████▊   | 421/618 [00:08<00:03, 55.79it/s]Extracting features:  69%|██████▉   | 427/618 [00:08<00:03, 55.86it/s]Extracting features:  70%|███████   | 433/618 [00:08<00:03, 55.10it/s]Extracting features:  71%|███████   | 440/618 [00:08<00:03, 55.39it/s]Extracting features:  72%|███████▏  | 446/618 [00:08<00:03, 53.81it/s]Extracting features:  73%|███████▎  | 452/618 [00:08<00:03, 53.96it/s]Extracting features:  74%|███████▍  | 458/618 [00:08<00:02, 54.54it/s]Extracting features:  75%|███████▌  | 464/618 [00:09<00:02, 52.51it/s]Extracting features:  76%|███████▌  | 470/618 [00:09<00:02, 53.78it/s]Extracting features:  77%|███████▋  | 476/618 [00:09<00:02, 53.64it/s]Extracting features:  78%|███████▊  | 483/618 [00:09<00:02, 54.41it/s]Extracting features:  79%|███████▉  | 489/618 [00:09<00:02, 52.92it/s]Extracting features:  80%|████████  | 495/618 [00:09<00:02, 54.64it/s]Extracting features:  81%|████████  | 501/618 [00:09<00:02, 52.02it/s]Extracting features:  82%|████████▏ | 507/618 [00:09<00:02, 53.53it/s]Extracting features:  83%|████████▎ | 513/618 [00:09<00:02, 51.48it/s]Extracting features:  84%|████████▍ | 519/618 [00:10<00:01, 52.89it/s]Extracting features:  85%|████████▍ | 525/618 [00:10<00:01, 52.10it/s]Extracting features:  86%|████████▌ | 531/618 [00:10<00:01, 50.14it/s]Extracting features:  87%|████████▋ | 537/618 [00:10<00:01, 50.71it/s]Extracting features:  88%|████████▊ | 543/618 [00:10<00:01, 51.14it/s]Extracting features:  89%|████████▉ | 549/618 [00:10<00:01, 51.10it/s]Extracting features:  90%|████████▉ | 555/618 [00:10<00:01, 49.59it/s]Extracting features:  91%|█████████ | 561/618 [00:10<00:01, 51.70it/s]Extracting features:  92%|█████████▏| 567/618 [00:11<00:00, 51.16it/s]Extracting features:  93%|█████████▎| 573/618 [00:11<00:00, 50.08it/s]Extracting features:  94%|█████████▎| 579/618 [00:11<00:00, 49.53it/s]Extracting features:  95%|█████████▍| 585/618 [00:11<00:00, 52.09it/s]Extracting features:  96%|█████████▌| 591/618 [00:11<00:00, 54.08it/s]Extracting features:  97%|█████████▋| 598/618 [00:11<00:00, 57.03it/s]Extracting features:  98%|█████████▊| 604/618 [00:11<00:00, 57.66it/s]Extracting features:  99%|█████████▉| 611/618 [00:11<00:00, 59.99it/s]Extracting features: 100%|██████████| 618/618 [00:11<00:00, 57.09it/s]Extracting features: 100%|██████████| 618/618 [00:11<00:00, 51.59it/s]
2024-12-27 18:46:12,765 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 18:46:12,766 - INFO - Training feature extraction completed in 12.01s
2024-12-27 18:46:12,766 - INFO - Creating model for classifier: LogisticRegression
2024-12-27 18:46:12,766 - INFO - Using device: cuda
2024-12-27 18:46:12,766 - INFO - 
Processing poison rate: 0.0
2024-12-27 18:46:12,766 - INFO - Training set processing completed in 0.00s
2024-12-27 18:46:12,766 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:46:12,768 - INFO - Memory usage at start_fit: CPU 2952.8 MB, GPU 47.3 MB
2024-12-27 18:46:12,768 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:46:12,774 - INFO - Number of unique classes: 43
2024-12-27 18:46:13,140 - INFO - Fitted scaler and transformed data
2024-12-27 18:46:13,140 - INFO - Scaling time: 0.36s
2024-12-27 18:46:13,665 - INFO - Epoch 1/200, Train Loss: 1.4615, Val Loss: 0.9748
2024-12-27 18:46:14,107 - INFO - Epoch 2/200, Train Loss: 0.5980, Val Loss: 0.8163
2024-12-27 18:46:14,596 - INFO - Epoch 3/200, Train Loss: 0.4523, Val Loss: 0.7848
2024-12-27 18:46:15,080 - INFO - Epoch 4/200, Train Loss: 0.3580, Val Loss: 0.8276
2024-12-27 18:46:15,543 - INFO - Epoch 5/200, Train Loss: 0.3178, Val Loss: 0.7946
2024-12-27 18:46:15,543 - INFO - Early stopping triggered at epoch 5
2024-12-27 18:46:15,543 - INFO - Training completed in 2.78s
2024-12-27 18:46:15,544 - INFO - Final memory usage: CPU 3057.2 MB, GPU 48.4 MB
2024-12-27 18:46:15,545 - INFO - Model training completed in 2.78s
2024-12-27 18:46:15,574 - INFO - Prediction completed in 0.03s
2024-12-27 18:46:15,585 - INFO - Poison rate 0.0 completed in 2.82s
2024-12-27 18:46:15,586 - INFO - 
Processing poison rate: 0.01
2024-12-27 18:46:15,587 - INFO - Label flipping details:
2024-12-27 18:46:15,587 - INFO - - Source class: 1
2024-12-27 18:46:15,587 - INFO - - Target class: 0
2024-12-27 18:46:15,587 - INFO - - Available samples in source class: 916
2024-12-27 18:46:15,587 - INFO - - Requested samples to poison: 197
2024-12-27 18:46:15,587 - INFO - - Actual samples to flip: 197
2024-12-27 18:46:15,587 - INFO - - Samples remaining in source class: 719
2024-12-27 18:46:15,587 - INFO - Successfully flipped 197 labels from class 1 to 0
2024-12-27 18:46:15,588 - INFO - Total number of labels flipped: 197
2024-12-27 18:46:15,588 - INFO - Label flipping completed in 0.00s
2024-12-27 18:46:15,588 - INFO - Training set processing completed in 0.00s
2024-12-27 18:46:15,588 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:46:15,589 - INFO - Memory usage at start_fit: CPU 2960.7 MB, GPU 48.1 MB
2024-12-27 18:46:15,589 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:46:15,591 - INFO - Number of unique classes: 43
2024-12-27 18:46:15,953 - INFO - Fitted scaler and transformed data
2024-12-27 18:46:15,953 - INFO - Scaling time: 0.36s
2024-12-27 18:46:16,456 - INFO - Epoch 1/200, Train Loss: 1.4918, Val Loss: 1.2749
2024-12-27 18:46:16,961 - INFO - Epoch 2/200, Train Loss: 0.6595, Val Loss: 1.0576
2024-12-27 18:46:17,487 - INFO - Epoch 3/200, Train Loss: 0.5036, Val Loss: 1.0483
2024-12-27 18:46:18,130 - INFO - Epoch 4/200, Train Loss: 0.3864, Val Loss: 0.9488
2024-12-27 18:46:18,689 - INFO - Epoch 5/200, Train Loss: 0.3470, Val Loss: 1.1015
2024-12-27 18:46:19,256 - INFO - Epoch 6/200, Train Loss: 0.3287, Val Loss: 1.0362
2024-12-27 18:46:19,257 - INFO - Early stopping triggered at epoch 6
2024-12-27 18:46:19,257 - INFO - Training completed in 3.67s
2024-12-27 18:46:19,257 - INFO - Final memory usage: CPU 3057.2 MB, GPU 48.4 MB
2024-12-27 18:46:19,258 - INFO - Model training completed in 3.67s
2024-12-27 18:46:19,288 - INFO - Prediction completed in 0.03s
2024-12-27 18:46:19,299 - INFO - Poison rate 0.01 completed in 3.71s
2024-12-27 18:46:19,299 - INFO - 
Processing poison rate: 0.03
2024-12-27 18:46:19,300 - INFO - Label flipping details:
2024-12-27 18:46:19,300 - INFO - - Source class: 1
2024-12-27 18:46:19,300 - INFO - - Target class: 0
2024-12-27 18:46:19,300 - INFO - - Available samples in source class: 916
2024-12-27 18:46:19,300 - INFO - - Requested samples to poison: 592
2024-12-27 18:46:19,300 - INFO - - Actual samples to flip: 592
2024-12-27 18:46:19,301 - INFO - - Samples remaining in source class: 324
2024-12-27 18:46:19,301 - INFO - Successfully flipped 592 labels from class 1 to 0
2024-12-27 18:46:19,301 - INFO - Total number of labels flipped: 592
2024-12-27 18:46:19,301 - INFO - Label flipping completed in 0.00s
2024-12-27 18:46:19,301 - INFO - Training set processing completed in 0.00s
2024-12-27 18:46:19,301 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:46:19,302 - INFO - Memory usage at start_fit: CPU 2960.7 MB, GPU 48.1 MB
2024-12-27 18:46:19,302 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:46:19,304 - INFO - Number of unique classes: 43
2024-12-27 18:46:19,642 - INFO - Fitted scaler and transformed data
2024-12-27 18:46:19,643 - INFO - Scaling time: 0.34s
2024-12-27 18:46:20,414 - INFO - Epoch 1/200, Train Loss: 1.5409, Val Loss: 1.0238
2024-12-27 18:46:21,217 - INFO - Epoch 2/200, Train Loss: 0.6768, Val Loss: 0.9694
2024-12-27 18:46:22,055 - INFO - Epoch 3/200, Train Loss: 0.5052, Val Loss: 0.9623
2024-12-27 18:46:22,912 - INFO - Epoch 4/200, Train Loss: 0.4339, Val Loss: 0.9059
2024-12-27 18:46:23,578 - INFO - Epoch 5/200, Train Loss: 0.3502, Val Loss: 0.9617
2024-12-27 18:46:24,206 - INFO - Epoch 6/200, Train Loss: 0.3133, Val Loss: 0.9220
2024-12-27 18:46:24,206 - INFO - Early stopping triggered at epoch 6
2024-12-27 18:46:24,206 - INFO - Training completed in 4.90s
2024-12-27 18:46:24,207 - INFO - Final memory usage: CPU 3057.2 MB, GPU 48.4 MB
2024-12-27 18:46:24,208 - INFO - Model training completed in 4.91s
2024-12-27 18:46:24,241 - INFO - Prediction completed in 0.03s
2024-12-27 18:46:24,267 - INFO - Poison rate 0.03 completed in 4.97s
2024-12-27 18:46:24,267 - INFO - 
Processing poison rate: 0.05
2024-12-27 18:46:24,269 - INFO - Label flipping details:
2024-12-27 18:46:24,269 - INFO - - Source class: 1
2024-12-27 18:46:24,269 - INFO - - Target class: 0
2024-12-27 18:46:24,270 - INFO - - Available samples in source class: 916
2024-12-27 18:46:24,270 - INFO - - Requested samples to poison: 987
2024-12-27 18:46:24,270 - INFO - - Actual samples to flip: 915
2024-12-27 18:46:24,270 - INFO - - Samples remaining in source class: 1
2024-12-27 18:46:24,270 - INFO - Successfully flipped 915 labels from class 1 to 0
2024-12-27 18:46:24,270 - INFO - Total number of labels flipped: 915
2024-12-27 18:46:24,270 - INFO - Label flipping completed in 0.00s
2024-12-27 18:46:24,271 - INFO - Training set processing completed in 0.00s
2024-12-27 18:46:24,271 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:46:24,272 - INFO - Memory usage at start_fit: CPU 2960.7 MB, GPU 48.1 MB
2024-12-27 18:46:24,272 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:46:24,274 - INFO - Number of unique classes: 43
2024-12-27 18:46:24,618 - INFO - Fitted scaler and transformed data
2024-12-27 18:46:24,618 - INFO - Scaling time: 0.34s
2024-12-27 18:46:25,363 - INFO - Epoch 1/200, Train Loss: 1.4646, Val Loss: 1.0485
2024-12-27 18:46:26,179 - INFO - Epoch 2/200, Train Loss: 0.6357, Val Loss: 0.9543
2024-12-27 18:46:26,854 - INFO - Epoch 3/200, Train Loss: 0.4350, Val Loss: 0.9023
2024-12-27 18:46:27,391 - INFO - Epoch 4/200, Train Loss: 0.3619, Val Loss: 0.9483
2024-12-27 18:46:27,963 - INFO - Epoch 5/200, Train Loss: 0.3298, Val Loss: 0.8940
2024-12-27 18:46:27,963 - INFO - Early stopping triggered at epoch 5
2024-12-27 18:46:27,963 - INFO - Training completed in 3.69s
2024-12-27 18:46:27,964 - INFO - Final memory usage: CPU 3060.0 MB, GPU 48.4 MB
2024-12-27 18:46:27,965 - INFO - Model training completed in 3.69s
2024-12-27 18:46:28,010 - INFO - Prediction completed in 0.05s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:46:28,022 - INFO - Poison rate 0.05 completed in 3.75s
2024-12-27 18:46:28,022 - INFO - 
Processing poison rate: 0.07
2024-12-27 18:46:28,023 - INFO - Label flipping details:
2024-12-27 18:46:28,023 - INFO - - Source class: 1
2024-12-27 18:46:28,023 - INFO - - Target class: 0
2024-12-27 18:46:28,023 - INFO - - Available samples in source class: 916
2024-12-27 18:46:28,023 - INFO - - Requested samples to poison: 1382
2024-12-27 18:46:28,023 - INFO - - Actual samples to flip: 915
2024-12-27 18:46:28,023 - INFO - - Samples remaining in source class: 1
2024-12-27 18:46:28,023 - INFO - Successfully flipped 915 labels from class 1 to 0
2024-12-27 18:46:28,024 - INFO - Total number of labels flipped: 915
2024-12-27 18:46:28,024 - INFO - Label flipping completed in 0.00s
2024-12-27 18:46:28,024 - INFO - Training set processing completed in 0.00s
2024-12-27 18:46:28,024 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:46:28,025 - INFO - Memory usage at start_fit: CPU 2963.5 MB, GPU 48.1 MB
2024-12-27 18:46:28,025 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:46:28,030 - INFO - Number of unique classes: 43
2024-12-27 18:46:28,397 - INFO - Fitted scaler and transformed data
2024-12-27 18:46:28,397 - INFO - Scaling time: 0.36s
2024-12-27 18:46:28,948 - INFO - Epoch 1/200, Train Loss: 1.4548, Val Loss: 0.9992
2024-12-27 18:46:29,516 - INFO - Epoch 2/200, Train Loss: 0.5779, Val Loss: 0.9326
2024-12-27 18:46:30,079 - INFO - Epoch 3/200, Train Loss: 0.4508, Val Loss: 0.8691
2024-12-27 18:46:30,845 - INFO - Epoch 4/200, Train Loss: 0.3676, Val Loss: 0.9415
2024-12-27 18:46:31,707 - INFO - Epoch 5/200, Train Loss: 0.3149, Val Loss: 0.9681
2024-12-27 18:46:31,708 - INFO - Early stopping triggered at epoch 5
2024-12-27 18:46:31,708 - INFO - Training completed in 3.68s
2024-12-27 18:46:31,708 - INFO - Final memory usage: CPU 3060.0 MB, GPU 48.4 MB
2024-12-27 18:46:31,709 - INFO - Model training completed in 3.68s
2024-12-27 18:46:31,738 - INFO - Prediction completed in 0.03s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:46:31,750 - INFO - Poison rate 0.07 completed in 3.73s
2024-12-27 18:46:31,750 - INFO - 
Processing poison rate: 0.1
2024-12-27 18:46:31,752 - INFO - Label flipping details:
2024-12-27 18:46:31,752 - INFO - - Source class: 1
2024-12-27 18:46:31,753 - INFO - - Target class: 0
2024-12-27 18:46:31,753 - INFO - - Available samples in source class: 916
2024-12-27 18:46:31,753 - INFO - - Requested samples to poison: 1975
2024-12-27 18:46:31,754 - INFO - - Actual samples to flip: 915
2024-12-27 18:46:31,754 - INFO - - Samples remaining in source class: 1
2024-12-27 18:46:31,754 - INFO - Successfully flipped 915 labels from class 1 to 0
2024-12-27 18:46:31,755 - INFO - Total number of labels flipped: 915
2024-12-27 18:46:31,755 - INFO - Label flipping completed in 0.01s
2024-12-27 18:46:31,756 - INFO - Training set processing completed in 0.00s
2024-12-27 18:46:31,756 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:46:31,757 - INFO - Memory usage at start_fit: CPU 2963.5 MB, GPU 48.1 MB
2024-12-27 18:46:31,757 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:46:31,759 - INFO - Number of unique classes: 43
2024-12-27 18:46:32,118 - INFO - Fitted scaler and transformed data
2024-12-27 18:46:32,118 - INFO - Scaling time: 0.36s
2024-12-27 18:46:33,006 - INFO - Epoch 1/200, Train Loss: 1.4372, Val Loss: 1.0717
2024-12-27 18:46:33,880 - INFO - Epoch 2/200, Train Loss: 0.6032, Val Loss: 0.8431
2024-12-27 18:46:34,763 - INFO - Epoch 3/200, Train Loss: 0.4347, Val Loss: 0.9063
2024-12-27 18:46:35,631 - INFO - Epoch 4/200, Train Loss: 0.3740, Val Loss: 0.8343
2024-12-27 18:46:35,632 - INFO - Early stopping triggered at epoch 4
2024-12-27 18:46:35,632 - INFO - Training completed in 3.87s
2024-12-27 18:46:35,632 - INFO - Final memory usage: CPU 3060.0 MB, GPU 48.4 MB
2024-12-27 18:46:35,633 - INFO - Model training completed in 3.88s
2024-12-27 18:46:35,665 - INFO - Prediction completed in 0.03s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:46:35,677 - INFO - Poison rate 0.1 completed in 3.93s
2024-12-27 18:46:35,677 - INFO - 
Processing poison rate: 0.2
2024-12-27 18:46:35,679 - INFO - Label flipping details:
2024-12-27 18:46:35,679 - INFO - - Source class: 1
2024-12-27 18:46:35,679 - INFO - - Target class: 0
2024-12-27 18:46:35,679 - INFO - - Available samples in source class: 916
2024-12-27 18:46:35,679 - INFO - - Requested samples to poison: 3951
2024-12-27 18:46:35,679 - INFO - - Actual samples to flip: 915
2024-12-27 18:46:35,679 - INFO - - Samples remaining in source class: 1
2024-12-27 18:46:35,679 - INFO - Successfully flipped 915 labels from class 1 to 0
2024-12-27 18:46:35,679 - INFO - Total number of labels flipped: 915
2024-12-27 18:46:35,679 - INFO - Label flipping completed in 0.00s
2024-12-27 18:46:35,679 - INFO - Training set processing completed in 0.00s
2024-12-27 18:46:35,680 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:46:35,680 - INFO - Memory usage at start_fit: CPU 2963.5 MB, GPU 48.1 MB
2024-12-27 18:46:35,681 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:46:35,682 - INFO - Number of unique classes: 43
2024-12-27 18:46:36,015 - INFO - Fitted scaler and transformed data
2024-12-27 18:46:36,015 - INFO - Scaling time: 0.33s
2024-12-27 18:46:36,902 - INFO - Epoch 1/200, Train Loss: 1.4336, Val Loss: 0.9729
2024-12-27 18:46:37,753 - INFO - Epoch 2/200, Train Loss: 0.5924, Val Loss: 0.8931
2024-12-27 18:46:38,618 - INFO - Epoch 3/200, Train Loss: 0.4571, Val Loss: 0.8569
2024-12-27 18:46:39,482 - INFO - Epoch 4/200, Train Loss: 0.3544, Val Loss: 0.8204
2024-12-27 18:46:40,357 - INFO - Epoch 5/200, Train Loss: 0.3078, Val Loss: 0.9833
2024-12-27 18:46:41,217 - INFO - Epoch 6/200, Train Loss: 0.3042, Val Loss: 0.8566
2024-12-27 18:46:41,217 - INFO - Early stopping triggered at epoch 6
2024-12-27 18:46:41,217 - INFO - Training completed in 5.54s
2024-12-27 18:46:41,217 - INFO - Final memory usage: CPU 3063.1 MB, GPU 48.4 MB
2024-12-27 18:46:41,218 - INFO - Model training completed in 5.54s
2024-12-27 18:46:41,249 - INFO - Prediction completed in 0.03s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:46:41,261 - INFO - Poison rate 0.2 completed in 5.58s
2024-12-27 18:46:41,262 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 18:46:41,263 - INFO - Total evaluation time: 60.71s
2024-12-27 18:46:41,269 - INFO - 
Progress: 20.8% - Evaluating GTSRB with LogisticRegression (dynadetect mode, iteration 1/1)
2024-12-27 18:46:41,328 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 18:46:41,409 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 18:46:41,492 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 18:46:41,493 - INFO - Dataset type: image
2024-12-27 18:46:41,493 - INFO - Sample size: 39209
2024-12-27 18:46:41,493 - INFO - Using device: cuda
2024-12-27 18:46:41,493 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 18:46:41,495 - INFO - Loading datasets...
2024-12-27 18:46:58,448 - INFO - Dataset loading completed in 16.95s
2024-12-27 18:46:58,448 - INFO - Extracting validation features...
2024-12-27 18:46:58,448 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:29,  4.62it/s]Extracting features:   1%|▏         | 2/139 [00:00<00:20,  6.67it/s]Extracting features:   4%|▎         | 5/139 [00:00<00:08, 14.93it/s]Extracting features:   6%|▋         | 9/139 [00:00<00:05, 23.21it/s]Extracting features:  10%|█         | 14/139 [00:00<00:04, 30.29it/s]Extracting features:  14%|█▎        | 19/139 [00:00<00:03, 34.27it/s]Extracting features:  17%|█▋        | 23/139 [00:00<00:03, 35.74it/s]Extracting features:  19%|█▉        | 27/139 [00:00<00:03, 35.26it/s]Extracting features:  24%|██▎       | 33/139 [00:01<00:02, 39.29it/s]Extracting features:  27%|██▋       | 37/139 [00:01<00:02, 37.55it/s]Extracting features:  29%|██▉       | 41/139 [00:01<00:02, 37.95it/s]Extracting features:  32%|███▏      | 45/139 [00:01<00:02, 35.95it/s]Extracting features:  36%|███▌      | 50/139 [00:01<00:02, 36.25it/s]Extracting features:  39%|███▉      | 54/139 [00:01<00:02, 36.21it/s]Extracting features:  43%|████▎     | 60/139 [00:01<00:01, 40.44it/s]Extracting features:  48%|████▊     | 67/139 [00:01<00:01, 46.74it/s]Extracting features:  53%|█████▎    | 73/139 [00:02<00:01, 47.56it/s]Extracting features:  56%|█████▌    | 78/139 [00:02<00:01, 45.99it/s]Extracting features:  60%|█████▉    | 83/139 [00:02<00:01, 42.70it/s]Extracting features:  63%|██████▎   | 88/139 [00:02<00:01, 41.21it/s]Extracting features:  67%|██████▋   | 93/139 [00:02<00:01, 42.48it/s]Extracting features:  71%|███████   | 98/139 [00:02<00:01, 39.75it/s]Extracting features:  74%|███████▍  | 103/139 [00:02<00:00, 40.35it/s]Extracting features:  78%|███████▊  | 108/139 [00:02<00:00, 42.40it/s]Extracting features:  81%|████████▏ | 113/139 [00:03<00:00, 41.16it/s]Extracting features:  85%|████████▍ | 118/139 [00:03<00:00, 42.58it/s]Extracting features:  89%|████████▉ | 124/139 [00:03<00:00, 47.15it/s]Extracting features:  93%|█████████▎| 129/139 [00:03<00:00, 47.17it/s]Extracting features:  98%|█████████▊| 136/139 [00:03<00:00, 53.30it/s]Extracting features: 100%|██████████| 139/139 [00:03<00:00, 38.99it/s]
2024-12-27 18:47:02,020 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 18:47:02,021 - INFO - Validation feature extraction completed in 3.57s
2024-12-27 18:47:02,021 - INFO - Extracting training features...
2024-12-27 18:47:02,021 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<01:55,  5.33it/s]Extracting features:   1%|          | 7/618 [00:00<00:21, 28.76it/s]Extracting features:   2%|▏         | 12/618 [00:00<00:16, 35.74it/s]Extracting features:   3%|▎         | 17/618 [00:00<00:15, 38.52it/s]Extracting features:   4%|▎         | 22/618 [00:00<00:14, 41.00it/s]Extracting features:   5%|▍         | 28/618 [00:00<00:12, 46.35it/s]Extracting features:   6%|▌         | 34/618 [00:00<00:11, 49.15it/s]Extracting features:   6%|▋         | 40/618 [00:00<00:11, 50.43it/s]Extracting features:   8%|▊         | 47/618 [00:01<00:10, 54.68it/s]Extracting features:   9%|▊         | 53/618 [00:01<00:10, 53.59it/s]Extracting features:  10%|▉         | 59/618 [00:01<00:11, 50.11it/s]Extracting features:  11%|█         | 65/618 [00:01<00:10, 52.47it/s]Extracting features:  12%|█▏        | 72/618 [00:01<00:09, 55.47it/s]Extracting features:  13%|█▎        | 79/618 [00:01<00:09, 58.37it/s]Extracting features:  14%|█▍        | 85/618 [00:01<00:09, 57.93it/s]Extracting features:  15%|█▍        | 92/618 [00:01<00:08, 60.18it/s]Extracting features:  16%|█▌        | 100/618 [00:01<00:08, 62.89it/s]Extracting features:  17%|█▋        | 107/618 [00:02<00:08, 58.28it/s]Extracting features:  18%|█▊        | 113/618 [00:02<00:08, 58.69it/s]Extracting features:  19%|█▉        | 120/618 [00:02<00:08, 60.37it/s]Extracting features:  21%|██        | 127/618 [00:02<00:08, 58.42it/s]Extracting features:  22%|██▏       | 133/618 [00:02<00:08, 56.80it/s]Extracting features:  23%|██▎       | 140/618 [00:02<00:07, 60.25it/s]Extracting features:  24%|██▍       | 147/618 [00:02<00:08, 58.86it/s]Extracting features:  25%|██▍       | 153/618 [00:02<00:08, 57.24it/s]Extracting features:  26%|██▌       | 159/618 [00:03<00:08, 54.48it/s]Extracting features:  27%|██▋       | 165/618 [00:03<00:08, 53.41it/s]Extracting features:  28%|██▊       | 172/618 [00:03<00:07, 57.75it/s]Extracting features:  29%|██▉       | 179/618 [00:03<00:07, 60.63it/s]Extracting features:  30%|███       | 186/618 [00:03<00:07, 56.07it/s]Extracting features:  31%|███       | 192/618 [00:03<00:07, 56.29it/s]Extracting features:  32%|███▏      | 199/618 [00:03<00:07, 57.16it/s]Extracting features:  33%|███▎      | 205/618 [00:03<00:07, 56.57it/s]Extracting features:  34%|███▍      | 212/618 [00:03<00:06, 58.46it/s]Extracting features:  35%|███▌      | 219/618 [00:04<00:06, 59.34it/s]Extracting features:  37%|███▋      | 226/618 [00:04<00:06, 60.54it/s]Extracting features:  38%|███▊      | 233/618 [00:04<00:07, 52.21it/s]Extracting features:  39%|███▉      | 240/618 [00:04<00:06, 54.69it/s]Extracting features:  40%|███▉      | 247/618 [00:04<00:06, 56.35it/s]Extracting features:  41%|████      | 254/618 [00:04<00:06, 57.93it/s]Extracting features:  42%|████▏     | 261/618 [00:04<00:06, 58.78it/s]Extracting features:  43%|████▎     | 267/618 [00:04<00:06, 58.21it/s]Extracting features:  44%|████▍     | 274/618 [00:05<00:05, 58.69it/s]Extracting features:  45%|████▌     | 280/618 [00:05<00:06, 51.04it/s]Extracting features:  46%|████▋     | 286/618 [00:05<00:06, 50.72it/s]Extracting features:  47%|████▋     | 292/618 [00:05<00:06, 51.48it/s]Extracting features:  48%|████▊     | 298/618 [00:05<00:06, 52.30it/s]Extracting features:  49%|████▉     | 304/618 [00:05<00:05, 52.66it/s]Extracting features:  50%|█████     | 310/618 [00:05<00:05, 53.87it/s]Extracting features:  51%|█████▏    | 317/618 [00:05<00:05, 56.81it/s]Extracting features:  52%|█████▏    | 323/618 [00:05<00:05, 55.19it/s]Extracting features:  53%|█████▎    | 330/618 [00:06<00:04, 57.92it/s]Extracting features:  54%|█████▍    | 336/618 [00:06<00:04, 57.53it/s]Extracting features:  55%|█████▌    | 342/618 [00:06<00:04, 57.96it/s]Extracting features:  56%|█████▋    | 348/618 [00:06<00:06, 43.71it/s]Extracting features:  57%|█████▋    | 353/618 [00:06<00:06, 41.69it/s]Extracting features:  58%|█████▊    | 359/618 [00:06<00:05, 45.16it/s]Extracting features:  59%|█████▉    | 365/618 [00:06<00:05, 48.78it/s]Extracting features:  60%|██████    | 371/618 [00:06<00:04, 49.46it/s]Extracting features:  61%|██████    | 377/618 [00:07<00:05, 48.00it/s]Extracting features:  62%|██████▏   | 383/618 [00:07<00:04, 49.38it/s]Extracting features:  63%|██████▎   | 389/618 [00:07<00:04, 50.96it/s]Extracting features:  64%|██████▍   | 395/618 [00:07<00:04, 52.73it/s]Extracting features:  65%|██████▍   | 401/618 [00:07<00:04, 54.00it/s]Extracting features:  66%|██████▌   | 407/618 [00:07<00:04, 46.13it/s]Extracting features:  67%|██████▋   | 413/618 [00:07<00:04, 47.15it/s]Extracting features:  68%|██████▊   | 418/618 [00:07<00:04, 44.46it/s]Extracting features:  69%|██████▊   | 424/618 [00:08<00:04, 47.66it/s]Extracting features:  69%|██████▉   | 429/618 [00:08<00:04, 46.11it/s]Extracting features:  70%|███████   | 434/618 [00:08<00:04, 44.16it/s]Extracting features:  71%|███████   | 440/618 [00:08<00:03, 45.69it/s]Extracting features:  72%|███████▏  | 446/618 [00:08<00:03, 49.39it/s]Extracting features:  73%|███████▎  | 452/618 [00:08<00:03, 46.60it/s]Extracting features:  74%|███████▍  | 457/618 [00:08<00:03, 44.16it/s]Extracting features:  75%|███████▍  | 463/618 [00:08<00:03, 46.15it/s]Extracting features:  76%|███████▌  | 469/618 [00:09<00:03, 48.65it/s]Extracting features:  77%|███████▋  | 475/618 [00:09<00:02, 50.03it/s]Extracting features:  78%|███████▊  | 482/618 [00:09<00:02, 52.82it/s]Extracting features:  79%|███████▉  | 488/618 [00:09<00:02, 53.31it/s]Extracting features:  80%|███████▉  | 494/618 [00:09<00:02, 54.02it/s]Extracting features:  81%|████████  | 500/618 [00:09<00:02, 54.28it/s]Extracting features:  82%|████████▏ | 506/618 [00:09<00:02, 54.63it/s]Extracting features:  83%|████████▎ | 513/618 [00:09<00:01, 56.37it/s]Extracting features:  84%|████████▍ | 519/618 [00:09<00:01, 57.31it/s]Extracting features:  85%|████████▍ | 525/618 [00:09<00:01, 57.64it/s]Extracting features:  86%|████████▌ | 531/618 [00:10<00:01, 55.27it/s]Extracting features:  87%|████████▋ | 537/618 [00:10<00:01, 53.79it/s]Extracting features:  88%|████████▊ | 544/618 [00:10<00:01, 57.14it/s]Extracting features:  89%|████████▉ | 551/618 [00:10<00:01, 59.75it/s]Extracting features:  90%|█████████ | 558/618 [00:10<00:01, 58.98it/s]Extracting features:  91%|█████████▏| 564/618 [00:10<00:00, 58.14it/s]Extracting features:  92%|█████████▏| 570/618 [00:10<00:00, 57.89it/s]Extracting features:  93%|█████████▎| 576/618 [00:10<00:00, 51.17it/s]Extracting features:  94%|█████████▍| 582/618 [00:11<00:00, 50.95it/s]Extracting features:  95%|█████████▌| 588/618 [00:11<00:00, 47.41it/s]Extracting features:  96%|█████████▌| 593/618 [00:11<00:00, 46.57it/s]Extracting features:  97%|█████████▋| 599/618 [00:11<00:00, 49.34it/s]Extracting features:  98%|█████████▊| 605/618 [00:11<00:00, 49.61it/s]Extracting features:  99%|█████████▉| 611/618 [00:11<00:00, 48.71it/s]Extracting features: 100%|█████████▉| 616/618 [00:11<00:00, 47.53it/s]Extracting features: 100%|██████████| 618/618 [00:11<00:00, 51.86it/s]
2024-12-27 18:47:13,974 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 18:47:13,974 - INFO - Training feature extraction completed in 11.95s
2024-12-27 18:47:13,974 - INFO - Creating model for classifier: LogisticRegression
2024-12-27 18:47:13,974 - INFO - Using device: cuda
2024-12-27 18:47:13,975 - INFO - 
Processing poison rate: 0.0
2024-12-27 18:47:13,975 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:47:13,975 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:47:15,916 - INFO - Feature scaling completed in 1.94s
2024-12-27 18:47:15,916 - INFO - Starting feature selection (k=50)
2024-12-27 18:47:15,940 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 18:47:15,940 - INFO - Starting anomaly detection
2024-12-27 18:47:23,831 - INFO - Anomaly detection completed in 7.89s
2024-12-27 18:47:23,831 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:47:23,831 - INFO - Total fit_transform time: 9.86s
2024-12-27 18:47:23,832 - INFO - Training set processing completed in 9.86s
2024-12-27 18:47:23,832 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:47:23,833 - INFO - Memory usage at start_fit: CPU 2961.1 MB, GPU 47.3 MB
2024-12-27 18:47:23,834 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:47:23,837 - INFO - Number of unique classes: 43
2024-12-27 18:47:24,224 - INFO - Fitted scaler and transformed data
2024-12-27 18:47:24,224 - INFO - Scaling time: 0.38s
2024-12-27 18:47:24,726 - INFO - Epoch 1/200, Train Loss: 1.4429, Val Loss: 1.0516
2024-12-27 18:47:25,227 - INFO - Epoch 2/200, Train Loss: 0.6027, Val Loss: 0.8975
2024-12-27 18:47:25,708 - INFO - Epoch 3/200, Train Loss: 0.4230, Val Loss: 0.9409
2024-12-27 18:47:26,277 - INFO - Epoch 4/200, Train Loss: 0.3700, Val Loss: 0.9486
2024-12-27 18:47:26,277 - INFO - Early stopping triggered at epoch 4
2024-12-27 18:47:26,277 - INFO - Training completed in 2.44s
2024-12-27 18:47:26,277 - INFO - Final memory usage: CPU 3063.7 MB, GPU 48.4 MB
2024-12-27 18:47:26,278 - INFO - Model training completed in 2.45s
2024-12-27 18:47:26,308 - INFO - Prediction completed in 0.03s
2024-12-27 18:47:26,319 - INFO - Poison rate 0.0 completed in 12.34s
2024-12-27 18:47:26,319 - INFO - 
Processing poison rate: 0.01
2024-12-27 18:47:26,321 - INFO - Label flipping details:
2024-12-27 18:47:26,321 - INFO - - Source class: 1
2024-12-27 18:47:26,321 - INFO - - Target class: 0
2024-12-27 18:47:26,321 - INFO - - Available samples in source class: 919
2024-12-27 18:47:26,321 - INFO - - Requested samples to poison: 197
2024-12-27 18:47:26,321 - INFO - - Actual samples to flip: 197
2024-12-27 18:47:26,321 - INFO - - Samples remaining in source class: 722
2024-12-27 18:47:26,321 - INFO - Successfully flipped 197 labels from class 1 to 0
2024-12-27 18:47:26,321 - INFO - Total number of labels flipped: 197
2024-12-27 18:47:26,321 - INFO - Label flipping completed in 0.00s
2024-12-27 18:47:26,321 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:47:26,322 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:47:28,239 - INFO - Feature scaling completed in 1.92s
2024-12-27 18:47:28,239 - INFO - Starting feature selection (k=50)
2024-12-27 18:47:28,290 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 18:47:28,290 - INFO - Starting anomaly detection
2024-12-27 18:47:36,255 - INFO - Anomaly detection completed in 7.96s
2024-12-27 18:47:36,255 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:47:36,255 - INFO - Total fit_transform time: 9.93s
2024-12-27 18:47:36,256 - INFO - Training set processing completed in 9.93s
2024-12-27 18:47:36,256 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:47:36,257 - INFO - Memory usage at start_fit: CPU 2967.2 MB, GPU 48.1 MB
2024-12-27 18:47:36,257 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:47:36,258 - INFO - Number of unique classes: 43
2024-12-27 18:47:36,609 - INFO - Fitted scaler and transformed data
2024-12-27 18:47:36,609 - INFO - Scaling time: 0.35s
2024-12-27 18:47:37,167 - INFO - Epoch 1/200, Train Loss: 1.4866, Val Loss: 0.9263
2024-12-27 18:47:37,697 - INFO - Epoch 2/200, Train Loss: 0.6594, Val Loss: 0.9541
2024-12-27 18:47:38,201 - INFO - Epoch 3/200, Train Loss: 0.4880, Val Loss: 0.9429
2024-12-27 18:47:38,201 - INFO - Early stopping triggered at epoch 3
2024-12-27 18:47:38,202 - INFO - Training completed in 1.95s
2024-12-27 18:47:38,203 - INFO - Final memory usage: CPU 3063.7 MB, GPU 48.4 MB
2024-12-27 18:47:38,204 - INFO - Model training completed in 1.95s
2024-12-27 18:47:38,256 - INFO - Prediction completed in 0.05s
2024-12-27 18:47:38,267 - INFO - Poison rate 0.01 completed in 11.95s
2024-12-27 18:47:38,267 - INFO - 
Processing poison rate: 0.03
2024-12-27 18:47:38,269 - INFO - Label flipping details:
2024-12-27 18:47:38,269 - INFO - - Source class: 1
2024-12-27 18:47:38,269 - INFO - - Target class: 0
2024-12-27 18:47:38,269 - INFO - - Available samples in source class: 919
2024-12-27 18:47:38,269 - INFO - - Requested samples to poison: 592
2024-12-27 18:47:38,269 - INFO - - Actual samples to flip: 592
2024-12-27 18:47:38,269 - INFO - - Samples remaining in source class: 327
2024-12-27 18:47:38,269 - INFO - Successfully flipped 592 labels from class 1 to 0
2024-12-27 18:47:38,269 - INFO - Total number of labels flipped: 592
2024-12-27 18:47:38,269 - INFO - Label flipping completed in 0.00s
2024-12-27 18:47:38,269 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:47:38,270 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:47:40,295 - INFO - Feature scaling completed in 2.03s
2024-12-27 18:47:40,295 - INFO - Starting feature selection (k=50)
2024-12-27 18:47:40,345 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 18:47:40,345 - INFO - Starting anomaly detection
2024-12-27 18:47:48,553 - INFO - Anomaly detection completed in 8.21s
2024-12-27 18:47:48,553 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:47:48,553 - INFO - Total fit_transform time: 10.28s
2024-12-27 18:47:48,554 - INFO - Training set processing completed in 10.28s
2024-12-27 18:47:48,554 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:47:48,555 - INFO - Memory usage at start_fit: CPU 2967.2 MB, GPU 48.1 MB
2024-12-27 18:47:48,556 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:47:48,559 - INFO - Number of unique classes: 43
2024-12-27 18:47:48,927 - INFO - Fitted scaler and transformed data
2024-12-27 18:47:48,927 - INFO - Scaling time: 0.37s
2024-12-27 18:47:49,431 - INFO - Epoch 1/200, Train Loss: 1.5257, Val Loss: 1.0871
2024-12-27 18:47:50,059 - INFO - Epoch 2/200, Train Loss: 0.7104, Val Loss: 0.9844
2024-12-27 18:47:50,582 - INFO - Epoch 3/200, Train Loss: 0.5105, Val Loss: 0.9440
2024-12-27 18:47:51,160 - INFO - Epoch 4/200, Train Loss: 0.4120, Val Loss: 0.9372
2024-12-27 18:47:51,790 - INFO - Epoch 5/200, Train Loss: 0.3578, Val Loss: 0.8793
2024-12-27 18:47:52,345 - INFO - Epoch 6/200, Train Loss: 0.3322, Val Loss: 0.9570
2024-12-27 18:47:52,910 - INFO - Epoch 7/200, Train Loss: 0.3219, Val Loss: 1.1508
2024-12-27 18:47:52,910 - INFO - Early stopping triggered at epoch 7
2024-12-27 18:47:52,911 - INFO - Training completed in 4.36s
2024-12-27 18:47:52,911 - INFO - Final memory usage: CPU 3065.5 MB, GPU 48.4 MB
2024-12-27 18:47:52,912 - INFO - Model training completed in 4.36s
2024-12-27 18:47:52,942 - INFO - Prediction completed in 0.03s
2024-12-27 18:47:52,953 - INFO - Poison rate 0.03 completed in 14.69s
2024-12-27 18:47:52,953 - INFO - 
Processing poison rate: 0.05
2024-12-27 18:47:52,954 - INFO - Label flipping details:
2024-12-27 18:47:52,955 - INFO - - Source class: 1
2024-12-27 18:47:52,955 - INFO - - Target class: 0
2024-12-27 18:47:52,955 - INFO - - Available samples in source class: 919
2024-12-27 18:47:52,955 - INFO - - Requested samples to poison: 987
2024-12-27 18:47:52,955 - INFO - - Actual samples to flip: 918
2024-12-27 18:47:52,955 - INFO - - Samples remaining in source class: 1
2024-12-27 18:47:52,955 - INFO - Successfully flipped 918 labels from class 1 to 0
2024-12-27 18:47:52,955 - INFO - Total number of labels flipped: 918
2024-12-27 18:47:52,955 - INFO - Label flipping completed in 0.00s
2024-12-27 18:47:52,955 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:47:52,955 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:47:54,878 - INFO - Feature scaling completed in 1.92s
2024-12-27 18:47:54,878 - INFO - Starting feature selection (k=50)
2024-12-27 18:47:54,935 - INFO - Feature selection completed in 0.06s. Output shape: (19755, 50)
2024-12-27 18:47:54,935 - INFO - Starting anomaly detection
2024-12-27 18:48:02,900 - INFO - Anomaly detection completed in 7.96s
2024-12-27 18:48:02,900 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:48:02,900 - INFO - Total fit_transform time: 9.94s
2024-12-27 18:48:02,901 - INFO - Training set processing completed in 9.95s
2024-12-27 18:48:02,901 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:48:02,901 - INFO - Memory usage at start_fit: CPU 2969.0 MB, GPU 48.1 MB
2024-12-27 18:48:02,902 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:48:02,903 - INFO - Number of unique classes: 43
2024-12-27 18:48:03,238 - INFO - Fitted scaler and transformed data
2024-12-27 18:48:03,239 - INFO - Scaling time: 0.33s
2024-12-27 18:48:03,739 - INFO - Epoch 1/200, Train Loss: 1.4430, Val Loss: 1.0333
2024-12-27 18:48:04,252 - INFO - Epoch 2/200, Train Loss: 0.6134, Val Loss: 0.9392
2024-12-27 18:48:04,785 - INFO - Epoch 3/200, Train Loss: 0.4522, Val Loss: 0.8641
2024-12-27 18:48:05,382 - INFO - Epoch 4/200, Train Loss: 0.3671, Val Loss: 0.8618
2024-12-27 18:48:05,981 - INFO - Epoch 5/200, Train Loss: 0.3122, Val Loss: 0.9002
2024-12-27 18:48:05,981 - INFO - Early stopping triggered at epoch 5
2024-12-27 18:48:05,981 - INFO - Training completed in 3.08s
2024-12-27 18:48:05,981 - INFO - Final memory usage: CPU 3066.8 MB, GPU 48.4 MB
2024-12-27 18:48:05,982 - INFO - Model training completed in 3.08s
2024-12-27 18:48:06,012 - INFO - Prediction completed in 0.03s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:48:06,023 - INFO - Poison rate 0.05 completed in 13.07s
2024-12-27 18:48:06,023 - INFO - 
Processing poison rate: 0.07
2024-12-27 18:48:06,025 - INFO - Label flipping details:
2024-12-27 18:48:06,025 - INFO - - Source class: 1
2024-12-27 18:48:06,025 - INFO - - Target class: 0
2024-12-27 18:48:06,025 - INFO - - Available samples in source class: 919
2024-12-27 18:48:06,025 - INFO - - Requested samples to poison: 1382
2024-12-27 18:48:06,025 - INFO - - Actual samples to flip: 918
2024-12-27 18:48:06,025 - INFO - - Samples remaining in source class: 1
2024-12-27 18:48:06,025 - INFO - Successfully flipped 918 labels from class 1 to 0
2024-12-27 18:48:06,025 - INFO - Total number of labels flipped: 918
2024-12-27 18:48:06,025 - INFO - Label flipping completed in 0.00s
2024-12-27 18:48:06,026 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:48:06,026 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:48:07,899 - INFO - Feature scaling completed in 1.87s
2024-12-27 18:48:07,899 - INFO - Starting feature selection (k=50)
2024-12-27 18:48:07,949 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 18:48:07,950 - INFO - Starting anomaly detection
2024-12-27 18:48:15,168 - INFO - Anomaly detection completed in 7.22s
2024-12-27 18:48:15,168 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:48:15,168 - INFO - Total fit_transform time: 9.14s
2024-12-27 18:48:15,169 - INFO - Training set processing completed in 9.14s
2024-12-27 18:48:15,169 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:48:15,170 - INFO - Memory usage at start_fit: CPU 2970.3 MB, GPU 48.1 MB
2024-12-27 18:48:15,170 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:48:15,174 - INFO - Number of unique classes: 43
2024-12-27 18:48:15,510 - INFO - Fitted scaler and transformed data
2024-12-27 18:48:15,510 - INFO - Scaling time: 0.33s
2024-12-27 18:48:16,014 - INFO - Epoch 1/200, Train Loss: 1.4439, Val Loss: 1.0117
2024-12-27 18:48:16,496 - INFO - Epoch 2/200, Train Loss: 0.6062, Val Loss: 0.9720
2024-12-27 18:48:16,952 - INFO - Epoch 3/200, Train Loss: 0.4643, Val Loss: 0.8822
2024-12-27 18:48:17,534 - INFO - Epoch 4/200, Train Loss: 0.3766, Val Loss: 0.8650
2024-12-27 18:48:18,021 - INFO - Epoch 5/200, Train Loss: 0.3064, Val Loss: 0.8485
2024-12-27 18:48:18,536 - INFO - Epoch 6/200, Train Loss: 0.3130, Val Loss: 0.9951
2024-12-27 18:48:19,060 - INFO - Epoch 7/200, Train Loss: 0.2788, Val Loss: 1.0218
2024-12-27 18:48:19,060 - INFO - Early stopping triggered at epoch 7
2024-12-27 18:48:19,061 - INFO - Training completed in 3.89s
2024-12-27 18:48:19,061 - INFO - Final memory usage: CPU 3066.8 MB, GPU 48.4 MB
2024-12-27 18:48:19,062 - INFO - Model training completed in 3.89s
2024-12-27 18:48:19,111 - INFO - Prediction completed in 0.05s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:48:19,122 - INFO - Poison rate 0.07 completed in 13.10s
2024-12-27 18:48:19,122 - INFO - 
Processing poison rate: 0.1
2024-12-27 18:48:19,124 - INFO - Label flipping details:
2024-12-27 18:48:19,124 - INFO - - Source class: 1
2024-12-27 18:48:19,124 - INFO - - Target class: 0
2024-12-27 18:48:19,124 - INFO - - Available samples in source class: 919
2024-12-27 18:48:19,124 - INFO - - Requested samples to poison: 1975
2024-12-27 18:48:19,124 - INFO - - Actual samples to flip: 918
2024-12-27 18:48:19,124 - INFO - - Samples remaining in source class: 1
2024-12-27 18:48:19,124 - INFO - Successfully flipped 918 labels from class 1 to 0
2024-12-27 18:48:19,124 - INFO - Total number of labels flipped: 918
2024-12-27 18:48:19,124 - INFO - Label flipping completed in 0.00s
2024-12-27 18:48:19,125 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:48:19,125 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:48:21,027 - INFO - Feature scaling completed in 1.90s
2024-12-27 18:48:21,027 - INFO - Starting feature selection (k=50)
2024-12-27 18:48:21,078 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 18:48:21,079 - INFO - Starting anomaly detection
2024-12-27 18:48:27,042 - INFO - Anomaly detection completed in 5.96s
2024-12-27 18:48:27,043 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:48:27,043 - INFO - Total fit_transform time: 7.92s
2024-12-27 18:48:27,043 - INFO - Training set processing completed in 7.92s
2024-12-27 18:48:27,043 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:48:27,044 - INFO - Memory usage at start_fit: CPU 2970.3 MB, GPU 48.1 MB
2024-12-27 18:48:27,045 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:48:27,048 - INFO - Number of unique classes: 43
2024-12-27 18:48:27,402 - INFO - Fitted scaler and transformed data
2024-12-27 18:48:27,402 - INFO - Scaling time: 0.35s
2024-12-27 18:48:27,876 - INFO - Epoch 1/200, Train Loss: 1.4273, Val Loss: 1.1005
2024-12-27 18:48:28,357 - INFO - Epoch 2/200, Train Loss: 0.6187, Val Loss: 0.9628
2024-12-27 18:48:28,850 - INFO - Epoch 3/200, Train Loss: 0.4356, Val Loss: 0.8894
2024-12-27 18:48:29,325 - INFO - Epoch 4/200, Train Loss: 0.3640, Val Loss: 0.9629
2024-12-27 18:48:29,817 - INFO - Epoch 5/200, Train Loss: 0.3081, Val Loss: 0.9196
2024-12-27 18:48:29,817 - INFO - Early stopping triggered at epoch 5
2024-12-27 18:48:29,817 - INFO - Training completed in 2.77s
2024-12-27 18:48:29,818 - INFO - Final memory usage: CPU 3068.4 MB, GPU 48.4 MB
2024-12-27 18:48:29,818 - INFO - Model training completed in 2.78s
2024-12-27 18:48:29,848 - INFO - Prediction completed in 0.03s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:48:29,859 - INFO - Poison rate 0.1 completed in 10.74s
2024-12-27 18:48:29,860 - INFO - 
Processing poison rate: 0.2
2024-12-27 18:48:29,861 - INFO - Label flipping details:
2024-12-27 18:48:29,861 - INFO - - Source class: 1
2024-12-27 18:48:29,861 - INFO - - Target class: 0
2024-12-27 18:48:29,861 - INFO - - Available samples in source class: 919
2024-12-27 18:48:29,861 - INFO - - Requested samples to poison: 3951
2024-12-27 18:48:29,861 - INFO - - Actual samples to flip: 918
2024-12-27 18:48:29,861 - INFO - - Samples remaining in source class: 1
2024-12-27 18:48:29,861 - INFO - Successfully flipped 918 labels from class 1 to 0
2024-12-27 18:48:29,861 - INFO - Total number of labels flipped: 918
2024-12-27 18:48:29,861 - INFO - Label flipping completed in 0.00s
2024-12-27 18:48:29,862 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 18:48:29,862 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 18:48:31,702 - INFO - Feature scaling completed in 1.84s
2024-12-27 18:48:31,703 - INFO - Starting feature selection (k=50)
2024-12-27 18:48:31,753 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 18:48:31,753 - INFO - Starting anomaly detection
2024-12-27 18:48:39,889 - INFO - Anomaly detection completed in 8.14s
2024-12-27 18:48:39,889 - INFO - Found 1976 outliers (10.0%)
2024-12-27 18:48:39,889 - INFO - Total fit_transform time: 10.03s
2024-12-27 18:48:39,889 - INFO - Training set processing completed in 10.03s
2024-12-27 18:48:39,890 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 18:48:39,891 - INFO - Memory usage at start_fit: CPU 2971.9 MB, GPU 48.1 MB
2024-12-27 18:48:39,891 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:48:39,894 - INFO - Number of unique classes: 43
2024-12-27 18:48:40,248 - INFO - Fitted scaler and transformed data
2024-12-27 18:48:40,249 - INFO - Scaling time: 0.35s
2024-12-27 18:48:40,719 - INFO - Epoch 1/200, Train Loss: 1.4149, Val Loss: 0.9743
2024-12-27 18:48:41,223 - INFO - Epoch 2/200, Train Loss: 0.6113, Val Loss: 0.9236
2024-12-27 18:48:41,746 - INFO - Epoch 3/200, Train Loss: 0.4553, Val Loss: 0.8040
2024-12-27 18:48:42,285 - INFO - Epoch 4/200, Train Loss: 0.3566, Val Loss: 0.7994
2024-12-27 18:48:42,797 - INFO - Epoch 5/200, Train Loss: 0.3083, Val Loss: 0.7847
2024-12-27 18:48:43,315 - INFO - Epoch 6/200, Train Loss: 0.2826, Val Loss: 0.8137
2024-12-27 18:48:43,880 - INFO - Epoch 7/200, Train Loss: 0.2561, Val Loss: 0.8493
2024-12-27 18:48:43,880 - INFO - Early stopping triggered at epoch 7
2024-12-27 18:48:43,880 - INFO - Training completed in 3.99s
2024-12-27 18:48:43,881 - INFO - Final memory usage: CPU 3069.4 MB, GPU 48.4 MB
2024-12-27 18:48:43,882 - INFO - Model training completed in 3.99s
2024-12-27 18:48:43,912 - INFO - Prediction completed in 0.03s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:48:43,923 - INFO - Poison rate 0.2 completed in 14.06s
2024-12-27 18:48:43,925 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 18:48:43,925 - INFO - Total evaluation time: 122.43s
2024-12-27 18:48:43,931 - INFO - 
Progress: 21.9% - Evaluating GTSRB with RandomForest (standard mode, iteration 1/1)
2024-12-27 18:48:43,991 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 18:48:44,063 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 18:48:44,171 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 18:48:44,171 - INFO - Dataset type: image
2024-12-27 18:48:44,171 - INFO - Sample size: 39209
2024-12-27 18:48:44,171 - INFO - Using device: cuda
2024-12-27 18:48:44,171 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 18:48:44,174 - INFO - Loading datasets...
2024-12-27 18:49:02,298 - INFO - Dataset loading completed in 18.12s
2024-12-27 18:49:02,298 - INFO - Extracting validation features...
2024-12-27 18:49:02,298 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:34,  3.96it/s]Extracting features:   1%|▏         | 2/139 [00:00<00:22,  6.04it/s]Extracting features:   4%|▎         | 5/139 [00:00<00:09, 14.04it/s]Extracting features:   7%|▋         | 10/139 [00:00<00:05, 23.91it/s]Extracting features:  12%|█▏        | 17/139 [00:00<00:03, 35.87it/s]Extracting features:  17%|█▋        | 23/139 [00:00<00:02, 40.73it/s]Extracting features:  22%|██▏       | 30/139 [00:00<00:02, 48.36it/s]Extracting features:  26%|██▌       | 36/139 [00:01<00:02, 50.49it/s]Extracting features:  30%|███       | 42/139 [00:01<00:01, 52.31it/s]Extracting features:  35%|███▌      | 49/139 [00:01<00:01, 56.99it/s]Extracting features:  40%|███▉      | 55/139 [00:01<00:01, 57.80it/s]Extracting features:  44%|████▍     | 61/139 [00:01<00:01, 58.11it/s]Extracting features:  49%|████▉     | 68/139 [00:01<00:01, 58.76it/s]Extracting features:  54%|█████▍    | 75/139 [00:01<00:01, 60.29it/s]Extracting features:  59%|█████▉    | 82/139 [00:01<00:01, 56.27it/s]Extracting features:  64%|██████▍   | 89/139 [00:01<00:00, 58.16it/s]Extracting features:  68%|██████▊   | 95/139 [00:02<00:00, 58.38it/s]Extracting features:  73%|███████▎  | 102/139 [00:02<00:00, 58.04it/s]Extracting features:  78%|███████▊  | 109/139 [00:02<00:00, 59.72it/s]Extracting features:  83%|████████▎ | 116/139 [00:02<00:00, 55.82it/s]Extracting features:  88%|████████▊ | 123/139 [00:02<00:00, 57.91it/s]Extracting features:  94%|█████████▎| 130/139 [00:02<00:00, 59.90it/s]Extracting features:  99%|█████████▉| 138/139 [00:02<00:00, 64.17it/s]Extracting features: 100%|██████████| 139/139 [00:02<00:00, 48.66it/s]
2024-12-27 18:49:05,164 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 18:49:05,164 - INFO - Validation feature extraction completed in 2.87s
2024-12-27 18:49:05,164 - INFO - Extracting training features...
2024-12-27 18:49:05,164 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<02:10,  4.75it/s]Extracting features:   1%|          | 6/618 [00:00<00:28, 21.28it/s]Extracting features:   2%|▏         | 12/618 [00:00<00:17, 33.78it/s]Extracting features:   3%|▎         | 17/618 [00:00<00:15, 37.97it/s]Extracting features:   4%|▍         | 24/618 [00:00<00:12, 46.44it/s]Extracting features:   5%|▌         | 31/618 [00:00<00:11, 52.02it/s]Extracting features:   6%|▌         | 38/618 [00:00<00:10, 55.19it/s]Extracting features:   7%|▋         | 44/618 [00:00<00:10, 54.11it/s]Extracting features:   8%|▊         | 51/618 [00:01<00:10, 56.36it/s]Extracting features:   9%|▉         | 58/618 [00:01<00:09, 58.79it/s]Extracting features:  10%|█         | 64/618 [00:01<00:10, 53.99it/s]Extracting features:  11%|█▏        | 71/618 [00:01<00:09, 56.43it/s]Extracting features:  13%|█▎        | 78/618 [00:01<00:09, 57.60it/s]Extracting features:  14%|█▎        | 84/618 [00:01<00:09, 58.10it/s]Extracting features:  15%|█▍        | 91/618 [00:01<00:08, 59.23it/s]Extracting features:  16%|█▌        | 97/618 [00:01<00:08, 58.64it/s]Extracting features:  17%|█▋        | 104/618 [00:02<00:08, 60.11it/s]Extracting features:  18%|█▊        | 111/618 [00:02<00:08, 60.21it/s]Extracting features:  19%|█▉        | 118/618 [00:02<00:08, 58.59it/s]Extracting features:  20%|██        | 124/618 [00:02<00:08, 55.75it/s]Extracting features:  21%|██        | 131/618 [00:02<00:08, 57.39it/s]Extracting features:  22%|██▏       | 137/618 [00:02<00:08, 57.68it/s]Extracting features:  23%|██▎       | 144/618 [00:02<00:07, 59.75it/s]Extracting features:  24%|██▍       | 150/618 [00:02<00:07, 58.78it/s]Extracting features:  25%|██▌       | 156/618 [00:02<00:08, 57.26it/s]Extracting features:  26%|██▋       | 163/618 [00:03<00:07, 60.26it/s]Extracting features:  28%|██▊       | 170/618 [00:03<00:07, 56.54it/s]Extracting features:  28%|██▊       | 176/618 [00:03<00:07, 56.65it/s]Extracting features:  29%|██▉       | 182/618 [00:03<00:07, 57.23it/s]Extracting features:  30%|███       | 188/618 [00:03<00:07, 56.05it/s]Extracting features:  31%|███▏      | 194/618 [00:03<00:08, 52.91it/s]Extracting features:  33%|███▎      | 201/618 [00:03<00:07, 55.44it/s]Extracting features:  34%|███▎      | 208/618 [00:03<00:07, 57.59it/s]Extracting features:  35%|███▍      | 214/618 [00:03<00:07, 57.02it/s]Extracting features:  36%|███▌      | 221/618 [00:04<00:06, 58.14it/s]Extracting features:  37%|███▋      | 227/618 [00:04<00:06, 58.62it/s]Extracting features:  38%|███▊      | 234/618 [00:04<00:06, 59.51it/s]Extracting features:  39%|███▉      | 240/618 [00:04<00:06, 59.31it/s]Extracting features:  40%|███▉      | 246/618 [00:04<00:06, 58.98it/s]Extracting features:  41%|████      | 253/618 [00:04<00:06, 59.51it/s]Extracting features:  42%|████▏     | 259/618 [00:04<00:06, 55.80it/s]Extracting features:  43%|████▎     | 265/618 [00:04<00:06, 55.26it/s]Extracting features:  44%|████▍     | 271/618 [00:04<00:06, 54.85it/s]Extracting features:  45%|████▍     | 277/618 [00:05<00:06, 55.16it/s]Extracting features:  46%|████▌     | 283/618 [00:05<00:06, 51.96it/s]Extracting features:  47%|████▋     | 289/618 [00:05<00:06, 51.39it/s]Extracting features:  48%|████▊     | 295/618 [00:05<00:06, 53.09it/s]Extracting features:  49%|████▊     | 301/618 [00:05<00:05, 53.33it/s]Extracting features:  50%|████▉     | 307/618 [00:05<00:06, 51.10it/s]Extracting features:  51%|█████     | 313/618 [00:05<00:06, 49.53it/s]Extracting features:  51%|█████▏    | 318/618 [00:05<00:06, 48.00it/s]Extracting features:  52%|█████▏    | 324/618 [00:05<00:05, 49.89it/s]Extracting features:  53%|█████▎    | 330/618 [00:06<00:05, 49.03it/s]Extracting features:  54%|█████▍    | 335/618 [00:06<00:06, 46.87it/s]Extracting features:  55%|█████▌    | 341/618 [00:06<00:05, 48.07it/s]Extracting features:  56%|█████▌    | 346/618 [00:06<00:06, 42.48it/s]Extracting features:  57%|█████▋    | 351/618 [00:06<00:07, 37.43it/s]Extracting features:  57%|█████▋    | 355/618 [00:06<00:08, 31.60it/s]Extracting features:  58%|█████▊    | 361/618 [00:06<00:06, 37.20it/s]Extracting features:  59%|█████▉    | 367/618 [00:07<00:05, 41.89it/s]Extracting features:  60%|██████    | 373/618 [00:07<00:05, 45.52it/s]Extracting features:  61%|██████▏   | 379/618 [00:07<00:05, 47.67it/s]Extracting features:  62%|██████▏   | 385/618 [00:07<00:04, 50.08it/s]Extracting features:  63%|██████▎   | 391/618 [00:07<00:04, 50.75it/s]Extracting features:  64%|██████▍   | 397/618 [00:07<00:04, 51.49it/s]Extracting features:  65%|██████▌   | 403/618 [00:07<00:04, 51.35it/s]Extracting features:  66%|██████▌   | 409/618 [00:07<00:03, 53.14it/s]Extracting features:  67%|██████▋   | 415/618 [00:07<00:03, 54.55it/s]Extracting features:  68%|██████▊   | 421/618 [00:08<00:03, 54.21it/s]Extracting features:  69%|██████▉   | 428/618 [00:08<00:03, 56.54it/s]Extracting features:  70%|███████   | 434/618 [00:08<00:03, 55.98it/s]Extracting features:  71%|███████   | 440/618 [00:08<00:03, 54.57it/s]Extracting features:  72%|███████▏  | 447/618 [00:08<00:03, 55.32it/s]Extracting features:  73%|███████▎  | 454/618 [00:08<00:02, 57.18it/s]Extracting features:  74%|███████▍  | 460/618 [00:08<00:02, 54.73it/s]Extracting features:  75%|███████▌  | 466/618 [00:08<00:02, 52.81it/s]Extracting features:  76%|███████▋  | 472/618 [00:09<00:02, 51.18it/s]Extracting features:  77%|███████▋  | 478/618 [00:09<00:02, 52.80it/s]Extracting features:  78%|███████▊  | 484/618 [00:09<00:02, 46.47it/s]Extracting features:  79%|███████▉  | 489/618 [00:09<00:03, 41.45it/s]Extracting features:  80%|████████  | 495/618 [00:09<00:02, 44.84it/s]Extracting features:  81%|████████  | 501/618 [00:09<00:02, 47.61it/s]Extracting features:  82%|████████▏ | 507/618 [00:09<00:02, 49.21it/s]Extracting features:  83%|████████▎ | 513/618 [00:09<00:02, 44.21it/s]Extracting features:  84%|████████▍ | 518/618 [00:10<00:02, 38.87it/s]Extracting features:  85%|████████▍ | 523/618 [00:10<00:02, 38.29it/s]Extracting features:  85%|████████▌ | 528/618 [00:10<00:02, 40.84it/s]Extracting features:  86%|████████▋ | 534/618 [00:10<00:01, 44.66it/s]Extracting features:  87%|████████▋ | 539/618 [00:10<00:01, 45.54it/s]Extracting features:  88%|████████▊ | 545/618 [00:10<00:01, 47.49it/s]Extracting features:  89%|████████▉ | 552/618 [00:10<00:01, 52.57it/s]Extracting features:  90%|█████████ | 558/618 [00:10<00:01, 52.73it/s]Extracting features:  91%|█████████▏| 564/618 [00:11<00:01, 53.26it/s]Extracting features:  92%|█████████▏| 570/618 [00:11<00:00, 52.18it/s]Extracting features:  93%|█████████▎| 576/618 [00:11<00:00, 49.20it/s]Extracting features:  94%|█████████▍| 582/618 [00:11<00:00, 50.58it/s]Extracting features:  95%|█████████▌| 588/618 [00:11<00:00, 51.89it/s]Extracting features:  96%|█████████▌| 594/618 [00:11<00:00, 50.86it/s]Extracting features:  97%|█████████▋| 600/618 [00:11<00:00, 52.92it/s]Extracting features:  98%|█████████▊| 606/618 [00:11<00:00, 54.47it/s]Extracting features:  99%|█████████▉| 612/618 [00:11<00:00, 50.60it/s]Extracting features: 100%|██████████| 618/618 [00:12<00:00, 49.74it/s]Extracting features: 100%|██████████| 618/618 [00:12<00:00, 50.83it/s]
2024-12-27 18:49:17,360 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 18:49:17,361 - INFO - Training feature extraction completed in 12.20s
2024-12-27 18:49:17,361 - INFO - Creating model for classifier: RandomForest
2024-12-27 18:49:17,361 - INFO - Using device: cuda
2024-12-27 18:49:17,361 - INFO - 
Processing poison rate: 0.0
2024-12-27 18:49:17,362 - INFO - Training set processing completed in 0.00s
2024-12-27 18:49:17,362 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 18:49:17,363 - INFO - Memory usage at start_fit: CPU 2965.7 MB, GPU 47.3 MB
2024-12-27 18:49:17,363 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:49:17,630 - INFO - Fitted scaler and transformed data
2024-12-27 18:49:17,630 - INFO - Scaling time: 0.27s
2024-12-27 18:49:17,647 - INFO - Number of unique classes: 43
2024-12-27 18:49:31,794 - INFO - Epoch 1/15, Train Loss: 3.7580, Val Loss: 3.7543
2024-12-27 18:49:44,656 - INFO - Epoch 2/15, Train Loss: 3.7483, Val Loss: 3.7452
2024-12-27 18:49:56,446 - INFO - Epoch 3/15, Train Loss: 3.7367, Val Loss: 3.7346
2024-12-27 18:50:11,802 - INFO - Epoch 4/15, Train Loss: 3.7235, Val Loss: 3.7231
2024-12-27 18:50:24,190 - INFO - Epoch 5/15, Train Loss: 3.7098, Val Loss: 3.7120
2024-12-27 18:50:35,398 - INFO - Epoch 6/15, Train Loss: 3.6970, Val Loss: 3.7025
2024-12-27 18:50:47,935 - INFO - Epoch 7/15, Train Loss: 3.6860, Val Loss: 3.6948
2024-12-27 18:51:01,415 - INFO - Epoch 8/15, Train Loss: 3.6768, Val Loss: 3.6887
2024-12-27 18:51:13,832 - INFO - Epoch 9/15, Train Loss: 3.6695, Val Loss: 3.6838
2024-12-27 18:51:28,274 - INFO - Epoch 10/15, Train Loss: 3.6635, Val Loss: 3.6800
2024-12-27 18:51:42,087 - INFO - Epoch 11/15, Train Loss: 3.6588, Val Loss: 3.6770
2024-12-27 18:51:42,087 - INFO - Early stopping triggered at epoch 11
2024-12-27 18:51:42,087 - INFO - Training completed in 144.72s
2024-12-27 18:51:42,088 - INFO - Final memory usage: CPU 2972.7 MB, GPU 155.0 MB
2024-12-27 18:51:42,088 - INFO - Model training completed in 144.73s
2024-12-27 18:51:42,323 - INFO - Prediction completed in 0.23s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:51:42,338 - INFO - Poison rate 0.0 completed in 144.98s
2024-12-27 18:51:42,339 - INFO - 
Processing poison rate: 0.01
2024-12-27 18:51:42,340 - INFO - Label flipping details:
2024-12-27 18:51:42,340 - INFO - - Source class: 1
2024-12-27 18:51:42,340 - INFO - - Target class: 0
2024-12-27 18:51:42,340 - INFO - - Available samples in source class: 916
2024-12-27 18:51:42,340 - INFO - - Requested samples to poison: 197
2024-12-27 18:51:42,340 - INFO - - Actual samples to flip: 197
2024-12-27 18:51:42,340 - INFO - - Samples remaining in source class: 719
2024-12-27 18:51:42,340 - INFO - Successfully flipped 197 labels from class 1 to 0
2024-12-27 18:51:42,341 - INFO - Total number of labels flipped: 197
2024-12-27 18:51:42,341 - INFO - Label flipping completed in 0.00s
2024-12-27 18:51:42,341 - INFO - Training set processing completed in 0.00s
2024-12-27 18:51:42,341 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 18:51:42,342 - INFO - Memory usage at start_fit: CPU 2972.7 MB, GPU 55.8 MB
2024-12-27 18:51:42,342 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:51:42,623 - INFO - Fitted scaler and transformed data
2024-12-27 18:51:42,624 - INFO - Scaling time: 0.28s
2024-12-27 18:51:42,659 - INFO - Number of unique classes: 43
2024-12-27 18:51:57,414 - INFO - Epoch 1/15, Train Loss: 3.7580, Val Loss: 3.7544
2024-12-27 18:52:10,306 - INFO - Epoch 2/15, Train Loss: 3.7486, Val Loss: 3.7456
2024-12-27 18:52:24,554 - INFO - Epoch 3/15, Train Loss: 3.7372, Val Loss: 3.7355
2024-12-27 18:52:37,856 - INFO - Epoch 4/15, Train Loss: 3.7244, Val Loss: 3.7246
2024-12-27 18:52:50,242 - INFO - Epoch 5/15, Train Loss: 3.7109, Val Loss: 3.7140
2024-12-27 18:53:02,342 - INFO - Epoch 6/15, Train Loss: 3.6984, Val Loss: 3.7048
2024-12-27 18:53:15,303 - INFO - Epoch 7/15, Train Loss: 3.6874, Val Loss: 3.6973
2024-12-27 18:53:28,518 - INFO - Epoch 8/15, Train Loss: 3.6787, Val Loss: 3.6914
2024-12-27 18:53:42,224 - INFO - Epoch 9/15, Train Loss: 3.6715, Val Loss: 3.6868
2024-12-27 18:53:55,675 - INFO - Epoch 10/15, Train Loss: 3.6657, Val Loss: 3.6831
2024-12-27 18:54:10,202 - INFO - Epoch 11/15, Train Loss: 3.6610, Val Loss: 3.6802
2024-12-27 18:54:10,202 - INFO - Early stopping triggered at epoch 11
2024-12-27 18:54:10,202 - INFO - Training completed in 147.86s
2024-12-27 18:54:10,203 - INFO - Final memory usage: CPU 2972.7 MB, GPU 155.0 MB
2024-12-27 18:54:10,204 - INFO - Model training completed in 147.86s
2024-12-27 18:54:10,434 - INFO - Prediction completed in 0.23s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:54:10,446 - INFO - Poison rate 0.01 completed in 148.11s
2024-12-27 18:54:10,446 - INFO - 
Processing poison rate: 0.03
2024-12-27 18:54:10,448 - INFO - Label flipping details:
2024-12-27 18:54:10,448 - INFO - - Source class: 1
2024-12-27 18:54:10,448 - INFO - - Target class: 0
2024-12-27 18:54:10,448 - INFO - - Available samples in source class: 916
2024-12-27 18:54:10,448 - INFO - - Requested samples to poison: 592
2024-12-27 18:54:10,448 - INFO - - Actual samples to flip: 592
2024-12-27 18:54:10,448 - INFO - - Samples remaining in source class: 324
2024-12-27 18:54:10,448 - INFO - Successfully flipped 592 labels from class 1 to 0
2024-12-27 18:54:10,448 - INFO - Total number of labels flipped: 592
2024-12-27 18:54:10,449 - INFO - Label flipping completed in 0.00s
2024-12-27 18:54:10,449 - INFO - Training set processing completed in 0.00s
2024-12-27 18:54:10,449 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 18:54:10,450 - INFO - Memory usage at start_fit: CPU 2972.7 MB, GPU 55.8 MB
2024-12-27 18:54:10,450 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:54:10,726 - INFO - Fitted scaler and transformed data
2024-12-27 18:54:10,726 - INFO - Scaling time: 0.28s
2024-12-27 18:54:10,761 - INFO - Number of unique classes: 43
2024-12-27 18:54:24,580 - INFO - Epoch 1/15, Train Loss: 3.7580, Val Loss: 3.7542
2024-12-27 18:54:39,734 - INFO - Epoch 2/15, Train Loss: 3.7485, Val Loss: 3.7450
2024-12-27 18:54:56,589 - INFO - Epoch 3/15, Train Loss: 3.7370, Val Loss: 3.7342
2024-12-27 18:55:10,708 - INFO - Epoch 4/15, Train Loss: 3.7239, Val Loss: 3.7226
2024-12-27 18:55:23,937 - INFO - Epoch 5/15, Train Loss: 3.7102, Val Loss: 3.7113
2024-12-27 18:55:38,772 - INFO - Epoch 6/15, Train Loss: 3.6976, Val Loss: 3.7015
2024-12-27 18:55:52,666 - INFO - Epoch 7/15, Train Loss: 3.6867, Val Loss: 3.6936
2024-12-27 18:56:05,764 - INFO - Epoch 8/15, Train Loss: 3.6777, Val Loss: 3.6873
2024-12-27 18:56:19,212 - INFO - Epoch 9/15, Train Loss: 3.6705, Val Loss: 3.6822
2024-12-27 18:56:32,963 - INFO - Epoch 10/15, Train Loss: 3.6645, Val Loss: 3.6783
2024-12-27 18:56:46,588 - INFO - Epoch 11/15, Train Loss: 3.6598, Val Loss: 3.6751
2024-12-27 18:56:46,588 - INFO - Early stopping triggered at epoch 11
2024-12-27 18:56:46,588 - INFO - Training completed in 156.14s
2024-12-27 18:56:46,588 - INFO - Final memory usage: CPU 2972.7 MB, GPU 155.0 MB
2024-12-27 18:56:46,589 - INFO - Model training completed in 156.14s
2024-12-27 18:56:46,788 - INFO - Prediction completed in 0.20s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:56:46,801 - INFO - Poison rate 0.03 completed in 156.35s
2024-12-27 18:56:46,802 - INFO - 
Processing poison rate: 0.05
2024-12-27 18:56:46,803 - INFO - Label flipping details:
2024-12-27 18:56:46,803 - INFO - - Source class: 1
2024-12-27 18:56:46,803 - INFO - - Target class: 0
2024-12-27 18:56:46,803 - INFO - - Available samples in source class: 916
2024-12-27 18:56:46,803 - INFO - - Requested samples to poison: 987
2024-12-27 18:56:46,803 - INFO - - Actual samples to flip: 915
2024-12-27 18:56:46,803 - INFO - - Samples remaining in source class: 1
2024-12-27 18:56:46,804 - INFO - Successfully flipped 915 labels from class 1 to 0
2024-12-27 18:56:46,804 - INFO - Total number of labels flipped: 915
2024-12-27 18:56:46,804 - INFO - Label flipping completed in 0.00s
2024-12-27 18:56:46,804 - INFO - Training set processing completed in 0.00s
2024-12-27 18:56:46,804 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 18:56:46,805 - INFO - Memory usage at start_fit: CPU 2972.7 MB, GPU 55.8 MB
2024-12-27 18:56:46,805 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:56:47,075 - INFO - Fitted scaler and transformed data
2024-12-27 18:56:47,075 - INFO - Scaling time: 0.27s
2024-12-27 18:56:47,110 - INFO - Number of unique classes: 43
2024-12-27 18:57:01,257 - INFO - Epoch 1/15, Train Loss: 3.7579, Val Loss: 3.7539
2024-12-27 18:57:14,262 - INFO - Epoch 2/15, Train Loss: 3.7481, Val Loss: 3.7445
2024-12-27 18:57:28,370 - INFO - Epoch 3/15, Train Loss: 3.7363, Val Loss: 3.7335
2024-12-27 18:57:40,390 - INFO - Epoch 4/15, Train Loss: 3.7230, Val Loss: 3.7218
2024-12-27 18:57:55,238 - INFO - Epoch 5/15, Train Loss: 3.7091, Val Loss: 3.7105
2024-12-27 18:58:07,342 - INFO - Epoch 6/15, Train Loss: 3.6962, Val Loss: 3.7008
2024-12-27 18:58:18,560 - INFO - Epoch 7/15, Train Loss: 3.6851, Val Loss: 3.6929
2024-12-27 18:58:30,346 - INFO - Epoch 8/15, Train Loss: 3.6760, Val Loss: 3.6867
2024-12-27 18:58:43,737 - INFO - Epoch 9/15, Train Loss: 3.6685, Val Loss: 3.6818
2024-12-27 18:58:56,159 - INFO - Epoch 10/15, Train Loss: 3.6626, Val Loss: 3.6780
2024-12-27 18:59:09,463 - INFO - Epoch 11/15, Train Loss: 3.6578, Val Loss: 3.6749
2024-12-27 18:59:09,464 - INFO - Early stopping triggered at epoch 11
2024-12-27 18:59:09,464 - INFO - Training completed in 142.66s
2024-12-27 18:59:09,464 - INFO - Final memory usage: CPU 2972.7 MB, GPU 155.0 MB
2024-12-27 18:59:09,464 - INFO - Model training completed in 142.66s
2024-12-27 18:59:09,599 - INFO - Prediction completed in 0.13s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 18:59:09,615 - INFO - Poison rate 0.05 completed in 142.81s
2024-12-27 18:59:09,615 - INFO - 
Processing poison rate: 0.07
2024-12-27 18:59:09,618 - INFO - Label flipping details:
2024-12-27 18:59:09,618 - INFO - - Source class: 1
2024-12-27 18:59:09,618 - INFO - - Target class: 0
2024-12-27 18:59:09,618 - INFO - - Available samples in source class: 916
2024-12-27 18:59:09,618 - INFO - - Requested samples to poison: 1382
2024-12-27 18:59:09,619 - INFO - - Actual samples to flip: 915
2024-12-27 18:59:09,619 - INFO - - Samples remaining in source class: 1
2024-12-27 18:59:09,619 - INFO - Successfully flipped 915 labels from class 1 to 0
2024-12-27 18:59:09,619 - INFO - Total number of labels flipped: 915
2024-12-27 18:59:09,619 - INFO - Label flipping completed in 0.00s
2024-12-27 18:59:09,619 - INFO - Training set processing completed in 0.00s
2024-12-27 18:59:09,620 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 18:59:09,620 - INFO - Memory usage at start_fit: CPU 2972.7 MB, GPU 55.8 MB
2024-12-27 18:59:09,621 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 18:59:09,883 - INFO - Fitted scaler and transformed data
2024-12-27 18:59:09,884 - INFO - Scaling time: 0.26s
2024-12-27 18:59:09,921 - INFO - Number of unique classes: 43
2024-12-27 18:59:22,310 - INFO - Epoch 1/15, Train Loss: 3.7578, Val Loss: 3.7537
2024-12-27 18:59:34,397 - INFO - Epoch 2/15, Train Loss: 3.7479, Val Loss: 3.7439
2024-12-27 18:59:46,539 - INFO - Epoch 3/15, Train Loss: 3.7360, Val Loss: 3.7327
2024-12-27 18:59:58,984 - INFO - Epoch 4/15, Train Loss: 3.7225, Val Loss: 3.7208
2024-12-27 19:00:11,039 - INFO - Epoch 5/15, Train Loss: 3.7087, Val Loss: 3.7094
2024-12-27 19:00:23,469 - INFO - Epoch 6/15, Train Loss: 3.6959, Val Loss: 3.6998
2024-12-27 19:00:35,193 - INFO - Epoch 7/15, Train Loss: 3.6849, Val Loss: 3.6920
2024-12-27 19:00:46,676 - INFO - Epoch 8/15, Train Loss: 3.6759, Val Loss: 3.6857
2024-12-27 19:00:58,779 - INFO - Epoch 9/15, Train Loss: 3.6687, Val Loss: 3.6808
2024-12-27 19:01:09,675 - INFO - Epoch 10/15, Train Loss: 3.6628, Val Loss: 3.6769
2024-12-27 19:01:22,395 - INFO - Epoch 11/15, Train Loss: 3.6581, Val Loss: 3.6738
2024-12-27 19:01:22,396 - INFO - Early stopping triggered at epoch 11
2024-12-27 19:01:22,396 - INFO - Training completed in 132.78s
2024-12-27 19:01:22,396 - INFO - Final memory usage: CPU 2972.7 MB, GPU 155.0 MB
2024-12-27 19:01:22,397 - INFO - Model training completed in 132.78s
2024-12-27 19:01:22,534 - INFO - Prediction completed in 0.14s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:01:22,547 - INFO - Poison rate 0.07 completed in 132.93s
2024-12-27 19:01:22,547 - INFO - 
Processing poison rate: 0.1
2024-12-27 19:01:22,548 - INFO - Label flipping details:
2024-12-27 19:01:22,548 - INFO - - Source class: 1
2024-12-27 19:01:22,548 - INFO - - Target class: 0
2024-12-27 19:01:22,548 - INFO - - Available samples in source class: 916
2024-12-27 19:01:22,548 - INFO - - Requested samples to poison: 1975
2024-12-27 19:01:22,548 - INFO - - Actual samples to flip: 915
2024-12-27 19:01:22,549 - INFO - - Samples remaining in source class: 1
2024-12-27 19:01:22,549 - INFO - Successfully flipped 915 labels from class 1 to 0
2024-12-27 19:01:22,549 - INFO - Total number of labels flipped: 915
2024-12-27 19:01:22,549 - INFO - Label flipping completed in 0.00s
2024-12-27 19:01:22,549 - INFO - Training set processing completed in 0.00s
2024-12-27 19:01:22,549 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 19:01:22,550 - INFO - Memory usage at start_fit: CPU 2972.7 MB, GPU 55.8 MB
2024-12-27 19:01:22,550 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:01:22,834 - INFO - Fitted scaler and transformed data
2024-12-27 19:01:22,835 - INFO - Scaling time: 0.28s
2024-12-27 19:01:22,870 - INFO - Number of unique classes: 43
2024-12-27 19:01:34,777 - INFO - Epoch 1/15, Train Loss: 3.7578, Val Loss: 3.7540
2024-12-27 19:01:48,015 - INFO - Epoch 2/15, Train Loss: 3.7479, Val Loss: 3.7445
2024-12-27 19:02:00,676 - INFO - Epoch 3/15, Train Loss: 3.7359, Val Loss: 3.7334
2024-12-27 19:02:14,273 - INFO - Epoch 4/15, Train Loss: 3.7224, Val Loss: 3.7212
2024-12-27 19:02:27,097 - INFO - Epoch 5/15, Train Loss: 3.7084, Val Loss: 3.7096
2024-12-27 19:02:40,877 - INFO - Epoch 6/15, Train Loss: 3.6953, Val Loss: 3.6994
2024-12-27 19:02:55,234 - INFO - Epoch 7/15, Train Loss: 3.6842, Val Loss: 3.6911
2024-12-27 19:03:08,942 - INFO - Epoch 8/15, Train Loss: 3.6752, Val Loss: 3.6845
2024-12-27 19:03:21,433 - INFO - Epoch 9/15, Train Loss: 3.6678, Val Loss: 3.6793
2024-12-27 19:03:36,179 - INFO - Epoch 10/15, Train Loss: 3.6619, Val Loss: 3.6752
2024-12-27 19:03:36,179 - INFO - Early stopping triggered at epoch 10
2024-12-27 19:03:36,179 - INFO - Training completed in 133.63s
2024-12-27 19:03:36,179 - INFO - Final memory usage: CPU 2972.7 MB, GPU 155.0 MB
2024-12-27 19:03:36,180 - INFO - Model training completed in 133.63s
2024-12-27 19:03:36,367 - INFO - Prediction completed in 0.19s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:03:36,380 - INFO - Poison rate 0.1 completed in 133.83s
2024-12-27 19:03:36,380 - INFO - 
Processing poison rate: 0.2
2024-12-27 19:03:36,381 - INFO - Label flipping details:
2024-12-27 19:03:36,381 - INFO - - Source class: 1
2024-12-27 19:03:36,381 - INFO - - Target class: 0
2024-12-27 19:03:36,382 - INFO - - Available samples in source class: 916
2024-12-27 19:03:36,382 - INFO - - Requested samples to poison: 3951
2024-12-27 19:03:36,382 - INFO - - Actual samples to flip: 915
2024-12-27 19:03:36,382 - INFO - - Samples remaining in source class: 1
2024-12-27 19:03:36,382 - INFO - Successfully flipped 915 labels from class 1 to 0
2024-12-27 19:03:36,382 - INFO - Total number of labels flipped: 915
2024-12-27 19:03:36,382 - INFO - Label flipping completed in 0.00s
2024-12-27 19:03:36,382 - INFO - Training set processing completed in 0.00s
2024-12-27 19:03:36,382 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 19:03:36,383 - INFO - Memory usage at start_fit: CPU 2972.7 MB, GPU 55.8 MB
2024-12-27 19:03:36,383 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:03:36,658 - INFO - Fitted scaler and transformed data
2024-12-27 19:03:36,659 - INFO - Scaling time: 0.28s
2024-12-27 19:03:36,697 - INFO - Number of unique classes: 43
2024-12-27 19:03:51,789 - INFO - Epoch 1/15, Train Loss: 3.7578, Val Loss: 3.7539
2024-12-27 19:04:04,202 - INFO - Epoch 2/15, Train Loss: 3.7477, Val Loss: 3.7445
2024-12-27 19:04:16,608 - INFO - Epoch 3/15, Train Loss: 3.7356, Val Loss: 3.7336
2024-12-27 19:04:30,414 - INFO - Epoch 4/15, Train Loss: 3.7219, Val Loss: 3.7218
2024-12-27 19:04:43,673 - INFO - Epoch 5/15, Train Loss: 3.7077, Val Loss: 3.7107
2024-12-27 19:04:56,328 - INFO - Epoch 6/15, Train Loss: 3.6946, Val Loss: 3.7012
2024-12-27 19:05:08,262 - INFO - Epoch 7/15, Train Loss: 3.6835, Val Loss: 3.6935
2024-12-27 19:05:21,320 - INFO - Epoch 8/15, Train Loss: 3.6745, Val Loss: 3.6874
2024-12-27 19:05:36,124 - INFO - Epoch 9/15, Train Loss: 3.6672, Val Loss: 3.6826
2024-12-27 19:05:51,751 - INFO - Epoch 10/15, Train Loss: 3.6611, Val Loss: 3.6788
2024-12-27 19:06:06,632 - INFO - Epoch 11/15, Train Loss: 3.6565, Val Loss: 3.6758
2024-12-27 19:06:06,632 - INFO - Early stopping triggered at epoch 11
2024-12-27 19:06:06,632 - INFO - Training completed in 150.25s
2024-12-27 19:06:06,633 - INFO - Final memory usage: CPU 2972.7 MB, GPU 155.0 MB
2024-12-27 19:06:06,633 - INFO - Model training completed in 150.25s
2024-12-27 19:06:06,821 - INFO - Prediction completed in 0.19s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:06:06,834 - INFO - Poison rate 0.2 completed in 150.45s
2024-12-27 19:06:06,835 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 19:06:06,836 - INFO - Total evaluation time: 1042.66s
2024-12-27 19:06:06,843 - INFO - 
Progress: 22.9% - Evaluating GTSRB with RandomForest (dynadetect mode, iteration 1/1)
2024-12-27 19:06:06,941 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 19:06:07,128 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 19:06:07,251 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 19:06:07,251 - INFO - Dataset type: image
2024-12-27 19:06:07,251 - INFO - Sample size: 39209
2024-12-27 19:06:07,251 - INFO - Using device: cuda
2024-12-27 19:06:07,251 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 19:06:07,255 - INFO - Loading datasets...
2024-12-27 19:06:24,961 - INFO - Dataset loading completed in 17.71s
2024-12-27 19:06:24,961 - INFO - Extracting validation features...
2024-12-27 19:06:24,961 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:27,  4.97it/s]Extracting features:   3%|▎         | 4/139 [00:00<00:11, 12.20it/s]Extracting features:   4%|▍         | 6/139 [00:00<00:10, 12.86it/s]Extracting features:   7%|▋         | 10/139 [00:00<00:06, 19.64it/s]Extracting features:  11%|█         | 15/139 [00:00<00:04, 27.09it/s]Extracting features:  14%|█▍        | 20/139 [00:00<00:03, 32.35it/s]Extracting features:  19%|█▊        | 26/139 [00:00<00:02, 38.92it/s]Extracting features:  23%|██▎       | 32/139 [00:01<00:02, 43.47it/s]Extracting features:  27%|██▋       | 37/139 [00:01<00:02, 41.36it/s]Extracting features:  30%|███       | 42/139 [00:01<00:02, 37.46it/s]Extracting features:  33%|███▎      | 46/139 [00:01<00:02, 37.05it/s]Extracting features:  36%|███▌      | 50/139 [00:01<00:02, 37.69it/s]Extracting features:  39%|███▉      | 54/139 [00:01<00:02, 37.75it/s]Extracting features:  42%|████▏     | 58/139 [00:01<00:02, 37.13it/s]Extracting features:  45%|████▍     | 62/139 [00:01<00:02, 35.80it/s]Extracting features:  47%|████▋     | 66/139 [00:02<00:02, 34.86it/s]Extracting features:  50%|█████     | 70/139 [00:02<00:02, 34.47it/s]Extracting features:  54%|█████▍    | 75/139 [00:02<00:01, 38.20it/s]Extracting features:  57%|█████▋    | 79/139 [00:02<00:01, 37.67it/s]Extracting features:  60%|█████▉    | 83/139 [00:02<00:01, 37.61it/s]Extracting features:  63%|██████▎   | 87/139 [00:02<00:01, 37.29it/s]Extracting features:  66%|██████▌   | 92/139 [00:02<00:01, 39.47it/s]Extracting features:  69%|██████▉   | 96/139 [00:02<00:01, 37.05it/s]Extracting features:  72%|███████▏  | 100/139 [00:02<00:01, 37.53it/s]Extracting features:  75%|███████▍  | 104/139 [00:03<00:00, 35.89it/s]Extracting features:  78%|███████▊  | 108/139 [00:03<00:00, 35.08it/s]Extracting features:  81%|████████  | 112/139 [00:03<00:00, 35.20it/s]Extracting features:  83%|████████▎ | 116/139 [00:03<00:00, 35.45it/s]Extracting features:  87%|████████▋ | 121/139 [00:03<00:00, 38.12it/s]Extracting features:  90%|████████▉ | 125/139 [00:03<00:00, 38.43it/s]Extracting features:  93%|█████████▎| 129/139 [00:03<00:00, 37.47it/s]Extracting features:  96%|█████████▋| 134/139 [00:03<00:00, 38.43it/s]Extracting features: 100%|██████████| 139/139 [00:03<00:00, 37.84it/s]Extracting features: 100%|██████████| 139/139 [00:04<00:00, 34.30it/s]
2024-12-27 19:06:29,021 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 19:06:29,021 - INFO - Validation feature extraction completed in 4.06s
2024-12-27 19:06:29,021 - INFO - Extracting training features...
2024-12-27 19:06:29,021 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<01:54,  5.38it/s]Extracting features:   1%|▏         | 8/618 [00:00<00:18, 32.22it/s]Extracting features:   2%|▏         | 14/618 [00:00<00:14, 42.46it/s]Extracting features:   3%|▎         | 20/618 [00:00<00:12, 47.66it/s]Extracting features:   4%|▍         | 27/618 [00:00<00:11, 52.56it/s]Extracting features:   6%|▌         | 34/618 [00:00<00:10, 56.54it/s]Extracting features:   7%|▋         | 41/618 [00:00<00:09, 59.85it/s]Extracting features:   8%|▊         | 48/618 [00:00<00:09, 58.52it/s]Extracting features:   9%|▊         | 54/618 [00:01<00:09, 58.57it/s]Extracting features:  10%|▉         | 60/618 [00:01<00:09, 58.09it/s]Extracting features:  11%|█         | 66/618 [00:01<00:09, 58.09it/s]Extracting features:  12%|█▏        | 73/618 [00:01<00:09, 60.11it/s]Extracting features:  13%|█▎        | 80/618 [00:01<00:09, 58.04it/s]Extracting features:  14%|█▍        | 87/618 [00:01<00:08, 59.26it/s]Extracting features:  15%|█▌        | 93/618 [00:01<00:09, 56.85it/s]Extracting features:  16%|█▌        | 100/618 [00:01<00:08, 58.14it/s]Extracting features:  17%|█▋        | 107/618 [00:01<00:08, 60.39it/s]Extracting features:  18%|█▊        | 114/618 [00:02<00:08, 60.87it/s]Extracting features:  20%|█▉        | 121/618 [00:02<00:08, 56.78it/s]Extracting features:  21%|██        | 128/618 [00:02<00:08, 58.54it/s]Extracting features:  22%|██▏       | 134/618 [00:02<00:08, 58.93it/s]Extracting features:  23%|██▎       | 140/618 [00:02<00:08, 59.19it/s]Extracting features:  24%|██▎       | 146/618 [00:02<00:08, 56.53it/s]Extracting features:  25%|██▍       | 152/618 [00:02<00:08, 56.68it/s]Extracting features:  26%|██▌       | 158/618 [00:02<00:08, 55.82it/s]Extracting features:  27%|██▋       | 164/618 [00:02<00:08, 56.16it/s]Extracting features:  28%|██▊       | 171/618 [00:03<00:07, 59.29it/s]Extracting features:  29%|██▉       | 179/618 [00:03<00:06, 63.23it/s]Extracting features:  30%|███       | 186/618 [00:03<00:06, 62.13it/s]Extracting features:  31%|███       | 193/618 [00:03<00:07, 59.67it/s]Extracting features:  32%|███▏      | 200/618 [00:03<00:06, 60.48it/s]Extracting features:  33%|███▎      | 207/618 [00:03<00:06, 59.96it/s]Extracting features:  35%|███▍      | 214/618 [00:03<00:06, 60.23it/s]Extracting features:  36%|███▌      | 221/618 [00:03<00:06, 62.68it/s]Extracting features:  37%|███▋      | 228/618 [00:03<00:06, 61.18it/s]Extracting features:  38%|███▊      | 235/618 [00:04<00:06, 56.41it/s]Extracting features:  39%|███▉      | 241/618 [00:04<00:06, 55.96it/s]Extracting features:  40%|███▉      | 247/618 [00:04<00:06, 56.35it/s]Extracting features:  41%|████      | 254/618 [00:04<00:06, 58.84it/s]Extracting features:  42%|████▏     | 260/618 [00:04<00:06, 57.25it/s]Extracting features:  43%|████▎     | 267/618 [00:04<00:05, 58.71it/s]Extracting features:  44%|████▍     | 273/618 [00:04<00:05, 57.71it/s]Extracting features:  45%|████▌     | 279/618 [00:04<00:06, 50.46it/s]Extracting features:  46%|████▌     | 285/618 [00:05<00:06, 50.45it/s]Extracting features:  47%|████▋     | 291/618 [00:05<00:07, 45.46it/s]Extracting features:  48%|████▊     | 296/618 [00:05<00:07, 44.97it/s]Extracting features:  49%|████▊     | 301/618 [00:05<00:07, 41.95it/s]Extracting features:  50%|████▉     | 306/618 [00:05<00:08, 38.93it/s]Extracting features:  50%|█████     | 310/618 [00:05<00:08, 36.98it/s]Extracting features:  51%|█████     | 315/618 [00:05<00:07, 38.24it/s]Extracting features:  52%|█████▏    | 320/618 [00:06<00:07, 37.97it/s]Extracting features:  52%|█████▏    | 324/618 [00:06<00:07, 37.31it/s]Extracting features:  53%|█████▎    | 328/618 [00:06<00:07, 37.46it/s]Extracting features:  54%|█████▍    | 334/618 [00:06<00:06, 41.91it/s]Extracting features:  55%|█████▍    | 339/618 [00:06<00:06, 43.99it/s]Extracting features:  56%|█████▌    | 344/618 [00:06<00:06, 41.91it/s]Extracting features:  56%|█████▋    | 349/618 [00:06<00:06, 40.52it/s]Extracting features:  57%|█████▋    | 354/618 [00:06<00:06, 38.47it/s]Extracting features:  58%|█████▊    | 358/618 [00:06<00:07, 36.28it/s]Extracting features:  59%|█████▊    | 363/618 [00:07<00:06, 39.44it/s]Extracting features:  60%|█████▉    | 368/618 [00:07<00:06, 39.71it/s]Extracting features:  60%|██████    | 373/618 [00:07<00:06, 37.51it/s]Extracting features:  61%|██████    | 377/618 [00:07<00:06, 36.44it/s]Extracting features:  62%|██████▏   | 381/618 [00:07<00:06, 37.10it/s]Extracting features:  62%|██████▏   | 385/618 [00:07<00:06, 36.46it/s]Extracting features:  63%|██████▎   | 390/618 [00:07<00:05, 38.36it/s]Extracting features:  64%|██████▍   | 394/618 [00:07<00:06, 36.54it/s]Extracting features:  64%|██████▍   | 398/618 [00:08<00:06, 35.10it/s]Extracting features:  65%|██████▌   | 402/618 [00:08<00:05, 36.27it/s]Extracting features:  66%|██████▌   | 406/618 [00:08<00:05, 36.43it/s]Extracting features:  67%|██████▋   | 411/618 [00:08<00:05, 38.33it/s]Extracting features:  67%|██████▋   | 415/618 [00:08<00:05, 36.31it/s]Extracting features:  68%|██████▊   | 419/618 [00:08<00:05, 35.17it/s]Extracting features:  68%|██████▊   | 423/618 [00:08<00:05, 35.48it/s]Extracting features:  69%|██████▉   | 427/618 [00:08<00:05, 36.19it/s]Extracting features:  70%|██████▉   | 432/618 [00:08<00:04, 39.27it/s]Extracting features:  71%|███████   | 437/618 [00:09<00:04, 39.90it/s]Extracting features:  72%|███████▏  | 442/618 [00:09<00:04, 37.31it/s]Extracting features:  72%|███████▏  | 447/618 [00:09<00:04, 39.29it/s]Extracting features:  73%|███████▎  | 452/618 [00:09<00:04, 40.61it/s]Extracting features:  74%|███████▍  | 457/618 [00:09<00:04, 39.47it/s]Extracting features:  75%|███████▍  | 461/618 [00:09<00:04, 37.75it/s]Extracting features:  75%|███████▌  | 466/618 [00:09<00:03, 39.51it/s]Extracting features:  76%|███████▋  | 472/618 [00:09<00:03, 43.58it/s]Extracting features:  77%|███████▋  | 477/618 [00:10<00:03, 43.54it/s]Extracting features:  78%|███████▊  | 482/618 [00:10<00:03, 41.35it/s]Extracting features:  79%|███████▉  | 487/618 [00:10<00:03, 41.92it/s]Extracting features:  80%|███████▉  | 492/618 [00:10<00:02, 42.08it/s]Extracting features:  80%|████████  | 497/618 [00:10<00:03, 39.42it/s]Extracting features:  81%|████████  | 502/618 [00:10<00:02, 41.20it/s]Extracting features:  82%|████████▏ | 507/618 [00:10<00:02, 41.54it/s]Extracting features:  83%|████████▎ | 512/618 [00:10<00:02, 39.26it/s]Extracting features:  83%|████████▎ | 516/618 [00:11<00:02, 38.64it/s]Extracting features:  84%|████████▍ | 520/618 [00:11<00:02, 38.39it/s]Extracting features:  85%|████████▍ | 524/618 [00:11<00:02, 37.63it/s]Extracting features:  85%|████████▌ | 528/618 [00:11<00:02, 36.12it/s]Extracting features:  86%|████████▌ | 532/618 [00:11<00:02, 35.86it/s]Extracting features:  87%|████████▋ | 536/618 [00:11<00:02, 35.12it/s]Extracting features:  87%|████████▋ | 540/618 [00:11<00:02, 34.69it/s]Extracting features:  88%|████████▊ | 544/618 [00:11<00:02, 35.25it/s]Extracting features:  89%|████████▉ | 549/618 [00:11<00:01, 36.87it/s]Extracting features:  89%|████████▉ | 553/618 [00:12<00:01, 37.44it/s]Extracting features:  90%|█████████ | 557/618 [00:12<00:01, 36.72it/s]Extracting features:  91%|█████████ | 561/618 [00:12<00:01, 35.64it/s]Extracting features:  91%|█████████▏| 565/618 [00:12<00:01, 36.78it/s]Extracting features:  92%|█████████▏| 570/618 [00:12<00:01, 37.78it/s]Extracting features:  93%|█████████▎| 574/618 [00:12<00:01, 36.77it/s]Extracting features:  94%|█████████▎| 578/618 [00:12<00:01, 36.45it/s]Extracting features:  94%|█████████▍| 582/618 [00:12<00:00, 36.61it/s]Extracting features:  95%|█████████▍| 586/618 [00:12<00:00, 37.36it/s]Extracting features:  95%|█████████▌| 590/618 [00:13<00:00, 36.74it/s]Extracting features:  96%|█████████▌| 594/618 [00:13<00:00, 36.70it/s]Extracting features:  97%|█████████▋| 598/618 [00:13<00:00, 35.87it/s]Extracting features:  97%|█████████▋| 602/618 [00:13<00:00, 35.91it/s]Extracting features:  98%|█████████▊| 607/618 [00:13<00:00, 37.32it/s]Extracting features:  99%|█████████▉| 612/618 [00:13<00:00, 38.55it/s]Extracting features: 100%|██████████| 618/618 [00:13<00:00, 40.30it/s]Extracting features: 100%|██████████| 618/618 [00:13<00:00, 44.56it/s]
2024-12-27 19:06:42,925 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 19:06:42,925 - INFO - Training feature extraction completed in 13.90s
2024-12-27 19:06:42,925 - INFO - Creating model for classifier: RandomForest
2024-12-27 19:06:42,926 - INFO - Using device: cuda
2024-12-27 19:06:42,926 - INFO - 
Processing poison rate: 0.0
2024-12-27 19:06:42,926 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:06:42,926 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:06:44,855 - INFO - Feature scaling completed in 1.93s
2024-12-27 19:06:44,855 - INFO - Starting feature selection (k=50)
2024-12-27 19:06:44,882 - INFO - Feature selection completed in 0.03s. Output shape: (19755, 50)
2024-12-27 19:06:44,882 - INFO - Starting anomaly detection
2024-12-27 19:06:52,665 - INFO - Anomaly detection completed in 7.78s
2024-12-27 19:06:52,665 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:06:52,665 - INFO - Total fit_transform time: 9.74s
2024-12-27 19:06:52,666 - INFO - Training set processing completed in 9.74s
2024-12-27 19:06:52,666 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 19:06:52,667 - INFO - Memory usage at start_fit: CPU 2974.1 MB, GPU 47.3 MB
2024-12-27 19:06:52,667 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:06:52,921 - INFO - Fitted scaler and transformed data
2024-12-27 19:06:52,921 - INFO - Scaling time: 0.25s
2024-12-27 19:06:52,941 - INFO - Number of unique classes: 43
2024-12-27 19:07:04,823 - INFO - Epoch 1/15, Train Loss: 3.5686, Val Loss: 3.7541
2024-12-27 19:07:16,316 - INFO - Epoch 2/15, Train Loss: 3.5594, Val Loss: 3.7449
2024-12-27 19:07:27,804 - INFO - Epoch 3/15, Train Loss: 3.5484, Val Loss: 3.7343
2024-12-27 19:07:39,214 - INFO - Epoch 4/15, Train Loss: 3.5359, Val Loss: 3.7231
2024-12-27 19:07:51,339 - INFO - Epoch 5/15, Train Loss: 3.5228, Val Loss: 3.7123
2024-12-27 19:08:02,340 - INFO - Epoch 6/15, Train Loss: 3.5108, Val Loss: 3.7030
2024-12-27 19:08:14,604 - INFO - Epoch 7/15, Train Loss: 3.5002, Val Loss: 3.6955
2024-12-27 19:08:26,858 - INFO - Epoch 8/15, Train Loss: 3.4916, Val Loss: 3.6896
2024-12-27 19:08:38,479 - INFO - Epoch 9/15, Train Loss: 3.4846, Val Loss: 3.6848
2024-12-27 19:08:50,560 - INFO - Epoch 10/15, Train Loss: 3.4791, Val Loss: 3.6811
2024-12-27 19:09:02,782 - INFO - Epoch 11/15, Train Loss: 3.4746, Val Loss: 3.6781
2024-12-27 19:09:02,782 - INFO - Early stopping triggered at epoch 11
2024-12-27 19:09:02,782 - INFO - Training completed in 130.12s
2024-12-27 19:09:02,783 - INFO - Final memory usage: CPU 2982.4 MB, GPU 155.0 MB
2024-12-27 19:09:02,783 - INFO - Model training completed in 130.12s
2024-12-27 19:09:02,957 - INFO - Prediction completed in 0.17s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:09:02,976 - INFO - Poison rate 0.0 completed in 140.05s
2024-12-27 19:09:02,976 - INFO - 
Processing poison rate: 0.01
2024-12-27 19:09:02,977 - INFO - Label flipping details:
2024-12-27 19:09:02,977 - INFO - - Source class: 1
2024-12-27 19:09:02,977 - INFO - - Target class: 0
2024-12-27 19:09:02,978 - INFO - - Available samples in source class: 916
2024-12-27 19:09:02,978 - INFO - - Requested samples to poison: 197
2024-12-27 19:09:02,978 - INFO - - Actual samples to flip: 197
2024-12-27 19:09:02,978 - INFO - - Samples remaining in source class: 719
2024-12-27 19:09:02,978 - INFO - Successfully flipped 197 labels from class 1 to 0
2024-12-27 19:09:02,978 - INFO - Total number of labels flipped: 197
2024-12-27 19:09:02,978 - INFO - Label flipping completed in 0.00s
2024-12-27 19:09:02,978 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:09:02,978 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:09:04,836 - INFO - Feature scaling completed in 1.86s
2024-12-27 19:09:04,836 - INFO - Starting feature selection (k=50)
2024-12-27 19:09:04,886 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 19:09:04,887 - INFO - Starting anomaly detection
2024-12-27 19:09:11,802 - INFO - Anomaly detection completed in 6.92s
2024-12-27 19:09:11,803 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:09:11,803 - INFO - Total fit_transform time: 8.82s
2024-12-27 19:09:11,803 - INFO - Training set processing completed in 8.83s
2024-12-27 19:09:11,803 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 19:09:11,805 - INFO - Memory usage at start_fit: CPU 2982.4 MB, GPU 55.8 MB
2024-12-27 19:09:11,805 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:09:12,091 - INFO - Fitted scaler and transformed data
2024-12-27 19:09:12,091 - INFO - Scaling time: 0.29s
2024-12-27 19:09:12,111 - INFO - Number of unique classes: 43
2024-12-27 19:09:23,806 - INFO - Epoch 1/15, Train Loss: 3.5710, Val Loss: 3.7544
2024-12-27 19:09:35,533 - INFO - Epoch 2/15, Train Loss: 3.5619, Val Loss: 3.7456
2024-12-27 19:09:47,924 - INFO - Epoch 3/15, Train Loss: 3.5511, Val Loss: 3.7354
2024-12-27 19:09:59,054 - INFO - Epoch 4/15, Train Loss: 3.5387, Val Loss: 3.7246
2024-12-27 19:10:10,188 - INFO - Epoch 5/15, Train Loss: 3.5258, Val Loss: 3.7144
2024-12-27 19:10:20,918 - INFO - Epoch 6/15, Train Loss: 3.5138, Val Loss: 3.7056
2024-12-27 19:10:31,612 - INFO - Epoch 7/15, Train Loss: 3.5035, Val Loss: 3.6983
2024-12-27 19:10:42,590 - INFO - Epoch 8/15, Train Loss: 3.4948, Val Loss: 3.6927
2024-12-27 19:10:53,838 - INFO - Epoch 9/15, Train Loss: 3.4879, Val Loss: 3.6882
2024-12-27 19:11:06,119 - INFO - Epoch 10/15, Train Loss: 3.4825, Val Loss: 3.6847
2024-12-27 19:11:18,713 - INFO - Epoch 11/15, Train Loss: 3.4780, Val Loss: 3.6819
2024-12-27 19:11:18,713 - INFO - Early stopping triggered at epoch 11
2024-12-27 19:11:18,713 - INFO - Training completed in 126.91s
2024-12-27 19:11:18,713 - INFO - Final memory usage: CPU 2982.4 MB, GPU 155.0 MB
2024-12-27 19:11:18,714 - INFO - Model training completed in 126.91s
2024-12-27 19:11:18,877 - INFO - Prediction completed in 0.16s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:11:18,890 - INFO - Poison rate 0.01 completed in 135.91s
2024-12-27 19:11:18,890 - INFO - 
Processing poison rate: 0.03
2024-12-27 19:11:18,891 - INFO - Label flipping details:
2024-12-27 19:11:18,892 - INFO - - Source class: 1
2024-12-27 19:11:18,892 - INFO - - Target class: 0
2024-12-27 19:11:18,892 - INFO - - Available samples in source class: 916
2024-12-27 19:11:18,892 - INFO - - Requested samples to poison: 592
2024-12-27 19:11:18,892 - INFO - - Actual samples to flip: 592
2024-12-27 19:11:18,892 - INFO - - Samples remaining in source class: 324
2024-12-27 19:11:18,892 - INFO - Successfully flipped 592 labels from class 1 to 0
2024-12-27 19:11:18,892 - INFO - Total number of labels flipped: 592
2024-12-27 19:11:18,892 - INFO - Label flipping completed in 0.00s
2024-12-27 19:11:18,892 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:11:18,892 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:11:20,730 - INFO - Feature scaling completed in 1.84s
2024-12-27 19:11:20,730 - INFO - Starting feature selection (k=50)
2024-12-27 19:11:20,781 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 19:11:20,781 - INFO - Starting anomaly detection
2024-12-27 19:11:27,219 - INFO - Anomaly detection completed in 6.44s
2024-12-27 19:11:27,220 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:11:27,220 - INFO - Total fit_transform time: 8.33s
2024-12-27 19:11:27,221 - INFO - Training set processing completed in 8.33s
2024-12-27 19:11:27,222 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 19:11:27,223 - INFO - Memory usage at start_fit: CPU 2982.4 MB, GPU 55.8 MB
2024-12-27 19:11:27,223 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:11:27,511 - INFO - Fitted scaler and transformed data
2024-12-27 19:11:27,511 - INFO - Scaling time: 0.29s
2024-12-27 19:11:27,531 - INFO - Number of unique classes: 43
2024-12-27 19:11:38,410 - INFO - Epoch 1/15, Train Loss: 3.5701, Val Loss: 3.7543
2024-12-27 19:11:49,967 - INFO - Epoch 2/15, Train Loss: 3.5611, Val Loss: 3.7453
2024-12-27 19:12:00,858 - INFO - Epoch 3/15, Train Loss: 3.5502, Val Loss: 3.7346
2024-12-27 19:12:13,248 - INFO - Epoch 4/15, Train Loss: 3.5378, Val Loss: 3.7229
2024-12-27 19:12:25,125 - INFO - Epoch 5/15, Train Loss: 3.5247, Val Loss: 3.7116
2024-12-27 19:12:36,006 - INFO - Epoch 6/15, Train Loss: 3.5126, Val Loss: 3.7019
2024-12-27 19:12:46,760 - INFO - Epoch 7/15, Train Loss: 3.5023, Val Loss: 3.6940
2024-12-27 19:12:57,286 - INFO - Epoch 8/15, Train Loss: 3.4937, Val Loss: 3.6878
2024-12-27 19:13:08,110 - INFO - Epoch 9/15, Train Loss: 3.4869, Val Loss: 3.6829
2024-12-27 19:13:18,769 - INFO - Epoch 10/15, Train Loss: 3.4812, Val Loss: 3.6790
2024-12-27 19:13:29,896 - INFO - Epoch 11/15, Train Loss: 3.4769, Val Loss: 3.6759
2024-12-27 19:13:29,896 - INFO - Early stopping triggered at epoch 11
2024-12-27 19:13:29,896 - INFO - Training completed in 122.67s
2024-12-27 19:13:29,897 - INFO - Final memory usage: CPU 2982.4 MB, GPU 155.0 MB
2024-12-27 19:13:29,897 - INFO - Model training completed in 122.68s
2024-12-27 19:13:30,038 - INFO - Prediction completed in 0.14s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:13:30,050 - INFO - Poison rate 0.03 completed in 131.16s
2024-12-27 19:13:30,050 - INFO - 
Processing poison rate: 0.05
2024-12-27 19:13:30,052 - INFO - Label flipping details:
2024-12-27 19:13:30,052 - INFO - - Source class: 1
2024-12-27 19:13:30,052 - INFO - - Target class: 0
2024-12-27 19:13:30,052 - INFO - - Available samples in source class: 916
2024-12-27 19:13:30,052 - INFO - - Requested samples to poison: 987
2024-12-27 19:13:30,052 - INFO - - Actual samples to flip: 915
2024-12-27 19:13:30,052 - INFO - - Samples remaining in source class: 1
2024-12-27 19:13:30,052 - INFO - Successfully flipped 915 labels from class 1 to 0
2024-12-27 19:13:30,052 - INFO - Total number of labels flipped: 915
2024-12-27 19:13:30,053 - INFO - Label flipping completed in 0.00s
2024-12-27 19:13:30,053 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:13:30,053 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:13:31,812 - INFO - Feature scaling completed in 1.76s
2024-12-27 19:13:31,812 - INFO - Starting feature selection (k=50)
2024-12-27 19:13:31,862 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 19:13:31,863 - INFO - Starting anomaly detection
2024-12-27 19:13:40,000 - INFO - Anomaly detection completed in 8.14s
2024-12-27 19:13:40,001 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:13:40,001 - INFO - Total fit_transform time: 9.95s
2024-12-27 19:13:40,001 - INFO - Training set processing completed in 9.95s
2024-12-27 19:13:40,002 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 19:13:40,003 - INFO - Memory usage at start_fit: CPU 2982.4 MB, GPU 55.8 MB
2024-12-27 19:13:40,003 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:13:40,275 - INFO - Fitted scaler and transformed data
2024-12-27 19:13:40,276 - INFO - Scaling time: 0.27s
2024-12-27 19:13:40,296 - INFO - Number of unique classes: 43
2024-12-27 19:13:51,026 - INFO - Epoch 1/15, Train Loss: 3.5689, Val Loss: 3.7540
2024-12-27 19:14:01,694 - INFO - Epoch 2/15, Train Loss: 3.5595, Val Loss: 3.7446
2024-12-27 19:14:12,748 - INFO - Epoch 3/15, Train Loss: 3.5483, Val Loss: 3.7338
2024-12-27 19:14:24,322 - INFO - Epoch 4/15, Train Loss: 3.5355, Val Loss: 3.7220
2024-12-27 19:14:36,478 - INFO - Epoch 5/15, Train Loss: 3.5220, Val Loss: 3.7108
2024-12-27 19:14:48,139 - INFO - Epoch 6/15, Train Loss: 3.5096, Val Loss: 3.7010
2024-12-27 19:15:00,327 - INFO - Epoch 7/15, Train Loss: 3.4990, Val Loss: 3.6932
2024-12-27 19:15:14,540 - INFO - Epoch 8/15, Train Loss: 3.4901, Val Loss: 3.6870
2024-12-27 19:15:30,484 - INFO - Epoch 9/15, Train Loss: 3.4831, Val Loss: 3.6821
2024-12-27 19:15:43,516 - INFO - Epoch 10/15, Train Loss: 3.4776, Val Loss: 3.6783
2024-12-27 19:15:55,109 - INFO - Epoch 11/15, Train Loss: 3.4731, Val Loss: 3.6753
2024-12-27 19:15:55,109 - INFO - Early stopping triggered at epoch 11
2024-12-27 19:15:55,109 - INFO - Training completed in 135.11s
2024-12-27 19:15:55,109 - INFO - Final memory usage: CPU 2982.4 MB, GPU 155.0 MB
2024-12-27 19:15:55,110 - INFO - Model training completed in 135.11s
2024-12-27 19:15:55,240 - INFO - Prediction completed in 0.13s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:15:55,252 - INFO - Poison rate 0.05 completed in 145.20s
2024-12-27 19:15:55,252 - INFO - 
Processing poison rate: 0.07
2024-12-27 19:15:55,253 - INFO - Label flipping details:
2024-12-27 19:15:55,253 - INFO - - Source class: 1
2024-12-27 19:15:55,253 - INFO - - Target class: 0
2024-12-27 19:15:55,253 - INFO - - Available samples in source class: 916
2024-12-27 19:15:55,253 - INFO - - Requested samples to poison: 1382
2024-12-27 19:15:55,254 - INFO - - Actual samples to flip: 915
2024-12-27 19:15:55,254 - INFO - - Samples remaining in source class: 1
2024-12-27 19:15:55,254 - INFO - Successfully flipped 915 labels from class 1 to 0
2024-12-27 19:15:55,254 - INFO - Total number of labels flipped: 915
2024-12-27 19:15:55,254 - INFO - Label flipping completed in 0.00s
2024-12-27 19:15:55,254 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:15:55,254 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:15:57,134 - INFO - Feature scaling completed in 1.88s
2024-12-27 19:15:57,134 - INFO - Starting feature selection (k=50)
2024-12-27 19:15:57,185 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 19:15:57,185 - INFO - Starting anomaly detection
2024-12-27 19:16:04,378 - INFO - Anomaly detection completed in 7.19s
2024-12-27 19:16:04,378 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:16:04,379 - INFO - Total fit_transform time: 9.12s
2024-12-27 19:16:04,379 - INFO - Training set processing completed in 9.12s
2024-12-27 19:16:04,379 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 19:16:04,381 - INFO - Memory usage at start_fit: CPU 2982.4 MB, GPU 55.8 MB
2024-12-27 19:16:04,381 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:16:04,654 - INFO - Fitted scaler and transformed data
2024-12-27 19:16:04,654 - INFO - Scaling time: 0.27s
2024-12-27 19:16:04,674 - INFO - Number of unique classes: 43
2024-12-27 19:16:16,931 - INFO - Epoch 1/15, Train Loss: 3.5675, Val Loss: 3.7541
2024-12-27 19:16:28,005 - INFO - Epoch 2/15, Train Loss: 3.5582, Val Loss: 3.7449
2024-12-27 19:16:38,966 - INFO - Epoch 3/15, Train Loss: 3.5469, Val Loss: 3.7341
2024-12-27 19:16:49,700 - INFO - Epoch 4/15, Train Loss: 3.5340, Val Loss: 3.7225
2024-12-27 19:17:00,609 - INFO - Epoch 5/15, Train Loss: 3.5205, Val Loss: 3.7113
2024-12-27 19:17:11,829 - INFO - Epoch 6/15, Train Loss: 3.5078, Val Loss: 3.7018
2024-12-27 19:17:22,726 - INFO - Epoch 7/15, Train Loss: 3.4971, Val Loss: 3.6941
2024-12-27 19:17:33,763 - INFO - Epoch 8/15, Train Loss: 3.4884, Val Loss: 3.6881
2024-12-27 19:17:45,428 - INFO - Epoch 9/15, Train Loss: 3.4815, Val Loss: 3.6834
2024-12-27 19:17:57,388 - INFO - Epoch 10/15, Train Loss: 3.4757, Val Loss: 3.6797
2024-12-27 19:18:08,928 - INFO - Epoch 11/15, Train Loss: 3.4713, Val Loss: 3.6767
2024-12-27 19:18:08,928 - INFO - Early stopping triggered at epoch 11
2024-12-27 19:18:08,928 - INFO - Training completed in 124.55s
2024-12-27 19:18:08,928 - INFO - Final memory usage: CPU 2982.4 MB, GPU 155.0 MB
2024-12-27 19:18:08,929 - INFO - Model training completed in 124.55s
2024-12-27 19:18:09,059 - INFO - Prediction completed in 0.13s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:18:09,072 - INFO - Poison rate 0.07 completed in 133.82s
2024-12-27 19:18:09,072 - INFO - 
Processing poison rate: 0.1
2024-12-27 19:18:09,073 - INFO - Label flipping details:
2024-12-27 19:18:09,073 - INFO - - Source class: 1
2024-12-27 19:18:09,073 - INFO - - Target class: 0
2024-12-27 19:18:09,073 - INFO - - Available samples in source class: 916
2024-12-27 19:18:09,073 - INFO - - Requested samples to poison: 1975
2024-12-27 19:18:09,073 - INFO - - Actual samples to flip: 915
2024-12-27 19:18:09,074 - INFO - - Samples remaining in source class: 1
2024-12-27 19:18:09,074 - INFO - Successfully flipped 915 labels from class 1 to 0
2024-12-27 19:18:09,074 - INFO - Total number of labels flipped: 915
2024-12-27 19:18:09,074 - INFO - Label flipping completed in 0.00s
2024-12-27 19:18:09,074 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:18:09,074 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:18:10,866 - INFO - Feature scaling completed in 1.79s
2024-12-27 19:18:10,866 - INFO - Starting feature selection (k=50)
2024-12-27 19:18:10,917 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 19:18:10,917 - INFO - Starting anomaly detection
2024-12-27 19:18:17,724 - INFO - Anomaly detection completed in 6.81s
2024-12-27 19:18:17,724 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:18:17,724 - INFO - Total fit_transform time: 8.65s
2024-12-27 19:18:17,725 - INFO - Training set processing completed in 8.65s
2024-12-27 19:18:17,725 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 19:18:17,727 - INFO - Memory usage at start_fit: CPU 2982.4 MB, GPU 55.8 MB
2024-12-27 19:18:17,727 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:18:18,008 - INFO - Fitted scaler and transformed data
2024-12-27 19:18:18,009 - INFO - Scaling time: 0.28s
2024-12-27 19:18:18,028 - INFO - Number of unique classes: 43
2024-12-27 19:18:30,086 - INFO - Epoch 1/15, Train Loss: 3.5683, Val Loss: 3.7539
2024-12-27 19:18:41,076 - INFO - Epoch 2/15, Train Loss: 3.5588, Val Loss: 3.7443
2024-12-27 19:18:51,804 - INFO - Epoch 3/15, Train Loss: 3.5474, Val Loss: 3.7330
2024-12-27 19:19:02,882 - INFO - Epoch 4/15, Train Loss: 3.5344, Val Loss: 3.7209
2024-12-27 19:19:13,482 - INFO - Epoch 5/15, Train Loss: 3.5208, Val Loss: 3.7093
2024-12-27 19:19:24,840 - INFO - Epoch 6/15, Train Loss: 3.5083, Val Loss: 3.6993
2024-12-27 19:19:36,392 - INFO - Epoch 7/15, Train Loss: 3.4975, Val Loss: 3.6912
2024-12-27 19:19:46,962 - INFO - Epoch 8/15, Train Loss: 3.4886, Val Loss: 3.6847
2024-12-27 19:19:57,997 - INFO - Epoch 9/15, Train Loss: 3.4816, Val Loss: 3.6796
2024-12-27 19:20:09,290 - INFO - Epoch 10/15, Train Loss: 3.4757, Val Loss: 3.6756
2024-12-27 19:20:20,354 - INFO - Epoch 11/15, Train Loss: 3.4712, Val Loss: 3.6724
2024-12-27 19:20:20,355 - INFO - Early stopping triggered at epoch 11
2024-12-27 19:20:20,355 - INFO - Training completed in 122.63s
2024-12-27 19:20:20,355 - INFO - Final memory usage: CPU 2982.4 MB, GPU 155.0 MB
2024-12-27 19:20:20,356 - INFO - Model training completed in 122.63s
2024-12-27 19:20:20,535 - INFO - Prediction completed in 0.18s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:20:20,550 - INFO - Poison rate 0.1 completed in 131.48s
2024-12-27 19:20:20,551 - INFO - 
Processing poison rate: 0.2
2024-12-27 19:20:20,552 - INFO - Label flipping details:
2024-12-27 19:20:20,552 - INFO - - Source class: 1
2024-12-27 19:20:20,552 - INFO - - Target class: 0
2024-12-27 19:20:20,552 - INFO - - Available samples in source class: 916
2024-12-27 19:20:20,552 - INFO - - Requested samples to poison: 3951
2024-12-27 19:20:20,552 - INFO - - Actual samples to flip: 915
2024-12-27 19:20:20,552 - INFO - - Samples remaining in source class: 1
2024-12-27 19:20:20,552 - INFO - Successfully flipped 915 labels from class 1 to 0
2024-12-27 19:20:20,552 - INFO - Total number of labels flipped: 915
2024-12-27 19:20:20,553 - INFO - Label flipping completed in 0.00s
2024-12-27 19:20:20,553 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:20:20,553 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:20:22,376 - INFO - Feature scaling completed in 1.82s
2024-12-27 19:20:22,376 - INFO - Starting feature selection (k=50)
2024-12-27 19:20:22,427 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 19:20:22,428 - INFO - Starting anomaly detection
2024-12-27 19:20:30,100 - INFO - Anomaly detection completed in 7.67s
2024-12-27 19:20:30,100 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:20:30,100 - INFO - Total fit_transform time: 9.55s
2024-12-27 19:20:30,101 - INFO - Training set processing completed in 9.55s
2024-12-27 19:20:30,101 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 19:20:30,102 - INFO - Memory usage at start_fit: CPU 2982.4 MB, GPU 55.8 MB
2024-12-27 19:20:30,102 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:20:30,356 - INFO - Fitted scaler and transformed data
2024-12-27 19:20:30,357 - INFO - Scaling time: 0.25s
2024-12-27 19:20:30,377 - INFO - Number of unique classes: 43
2024-12-27 19:20:42,597 - INFO - Epoch 1/15, Train Loss: 3.5690, Val Loss: 3.7539
2024-12-27 19:20:54,589 - INFO - Epoch 2/15, Train Loss: 3.5595, Val Loss: 3.7444
2024-12-27 19:21:07,556 - INFO - Epoch 3/15, Train Loss: 3.5480, Val Loss: 3.7333
2024-12-27 19:21:19,018 - INFO - Epoch 4/15, Train Loss: 3.5349, Val Loss: 3.7215
2024-12-27 19:21:30,575 - INFO - Epoch 5/15, Train Loss: 3.5212, Val Loss: 3.7102
2024-12-27 19:21:43,163 - INFO - Epoch 6/15, Train Loss: 3.5086, Val Loss: 3.7005
2024-12-27 19:21:55,813 - INFO - Epoch 7/15, Train Loss: 3.4978, Val Loss: 3.6927
2024-12-27 19:22:07,750 - INFO - Epoch 8/15, Train Loss: 3.4890, Val Loss: 3.6865
2024-12-27 19:22:18,295 - INFO - Epoch 9/15, Train Loss: 3.4821, Val Loss: 3.6817
2024-12-27 19:22:29,557 - INFO - Epoch 10/15, Train Loss: 3.4765, Val Loss: 3.6779
2024-12-27 19:22:41,222 - INFO - Epoch 11/15, Train Loss: 3.4719, Val Loss: 3.6748
2024-12-27 19:22:41,223 - INFO - Early stopping triggered at epoch 11
2024-12-27 19:22:41,223 - INFO - Training completed in 131.12s
2024-12-27 19:22:41,223 - INFO - Final memory usage: CPU 2982.4 MB, GPU 155.0 MB
2024-12-27 19:22:41,223 - INFO - Model training completed in 131.12s
2024-12-27 19:22:41,370 - INFO - Prediction completed in 0.15s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:22:41,382 - INFO - Poison rate 0.2 completed in 140.83s
2024-12-27 19:22:41,384 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 19:22:41,384 - INFO - Total evaluation time: 994.13s
2024-12-27 19:22:41,390 - INFO - 
Progress: 24.0% - Evaluating GTSRB with KNeighbors (standard mode, iteration 1/1)
2024-12-27 19:22:41,461 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 19:22:41,634 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 19:22:41,718 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 19:22:41,718 - INFO - Dataset type: image
2024-12-27 19:22:41,718 - INFO - Sample size: 39209
2024-12-27 19:22:41,718 - INFO - Using device: cuda
2024-12-27 19:22:41,718 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 19:22:41,721 - INFO - Loading datasets...
2024-12-27 19:22:59,223 - INFO - Dataset loading completed in 17.50s
2024-12-27 19:22:59,223 - INFO - Extracting validation features...
2024-12-27 19:22:59,223 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:26,  5.12it/s]Extracting features:   3%|▎         | 4/139 [00:00<00:10, 12.77it/s]Extracting features:   6%|▌         | 8/139 [00:00<00:06, 20.08it/s]Extracting features:   9%|▉         | 13/139 [00:00<00:04, 27.77it/s]Extracting features:  13%|█▎        | 18/139 [00:00<00:03, 31.83it/s]Extracting features:  16%|█▌        | 22/139 [00:00<00:03, 31.95it/s]Extracting features:  19%|█▊        | 26/139 [00:00<00:03, 31.74it/s]Extracting features:  22%|██▏       | 30/139 [00:01<00:03, 31.22it/s]Extracting features:  24%|██▍       | 34/139 [00:01<00:03, 31.09it/s]Extracting features:  27%|██▋       | 38/139 [00:01<00:03, 30.94it/s]Extracting features:  30%|███       | 42/139 [00:01<00:02, 32.79it/s]Extracting features:  33%|███▎      | 46/139 [00:01<00:02, 33.20it/s]Extracting features:  36%|███▌      | 50/139 [00:01<00:02, 34.56it/s]Extracting features:  40%|████      | 56/139 [00:01<00:02, 39.57it/s]Extracting features:  44%|████▍     | 61/139 [00:01<00:01, 40.83it/s]Extracting features:  48%|████▊     | 67/139 [00:02<00:01, 46.01it/s]Extracting features:  52%|█████▏    | 72/139 [00:02<00:01, 41.80it/s]Extracting features:  55%|█████▌    | 77/139 [00:02<00:01, 41.86it/s]Extracting features:  60%|██████    | 84/139 [00:02<00:01, 47.63it/s]Extracting features:  65%|██████▌   | 91/139 [00:02<00:00, 53.16it/s]Extracting features:  70%|██████▉   | 97/139 [00:02<00:00, 53.79it/s]Extracting features:  75%|███████▍  | 104/139 [00:02<00:00, 57.22it/s]Extracting features:  79%|███████▉  | 110/139 [00:02<00:00, 55.67it/s]Extracting features:  83%|████████▎ | 116/139 [00:02<00:00, 52.04it/s]Extracting features:  88%|████████▊ | 122/139 [00:03<00:00, 53.57it/s]Extracting features:  93%|█████████▎| 129/139 [00:03<00:00, 55.40it/s]Extracting features:  97%|█████████▋| 135/139 [00:03<00:00, 52.75it/s]Extracting features: 100%|██████████| 139/139 [00:03<00:00, 39.69it/s]
2024-12-27 19:23:02,736 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 19:23:02,736 - INFO - Validation feature extraction completed in 3.51s
2024-12-27 19:23:02,736 - INFO - Extracting training features...
2024-12-27 19:23:02,736 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<02:08,  4.80it/s]Extracting features:   1%|          | 6/618 [00:00<00:27, 22.48it/s]Extracting features:   2%|▏         | 11/618 [00:00<00:18, 32.11it/s]Extracting features:   3%|▎         | 17/618 [00:00<00:14, 40.85it/s]Extracting features:   4%|▎         | 23/618 [00:00<00:12, 46.41it/s]Extracting features:   5%|▍         | 29/618 [00:00<00:12, 47.46it/s]Extracting features:   6%|▌         | 35/618 [00:00<00:12, 47.97it/s]Extracting features:   7%|▋         | 41/618 [00:00<00:11, 50.84it/s]Extracting features:   8%|▊         | 47/618 [00:01<00:11, 51.11it/s]Extracting features:   9%|▊         | 53/618 [00:01<00:11, 50.16it/s]Extracting features:  10%|▉         | 59/618 [00:01<00:10, 51.95it/s]Extracting features:  11%|█         | 65/618 [00:01<00:10, 51.07it/s]Extracting features:  12%|█▏        | 72/618 [00:01<00:10, 53.70it/s]Extracting features:  13%|█▎        | 78/618 [00:01<00:10, 52.89it/s]Extracting features:  14%|█▎        | 84/618 [00:01<00:09, 54.63it/s]Extracting features:  15%|█▍        | 91/618 [00:01<00:09, 57.02it/s]Extracting features:  16%|█▌        | 98/618 [00:02<00:09, 57.26it/s]Extracting features:  17%|█▋        | 104/618 [00:02<00:09, 55.02it/s]Extracting features:  18%|█▊        | 110/618 [00:02<00:09, 52.46it/s]Extracting features:  19%|█▉        | 117/618 [00:02<00:09, 55.05it/s]Extracting features:  20%|█▉        | 123/618 [00:02<00:08, 55.54it/s]Extracting features:  21%|██        | 130/618 [00:02<00:08, 56.33it/s]Extracting features:  22%|██▏       | 136/618 [00:02<00:08, 55.60it/s]Extracting features:  23%|██▎       | 142/618 [00:02<00:08, 56.36it/s]Extracting features:  24%|██▍       | 148/618 [00:02<00:08, 55.09it/s]Extracting features:  25%|██▍       | 154/618 [00:03<00:08, 55.19it/s]Extracting features:  26%|██▌       | 160/618 [00:03<00:08, 55.14it/s]Extracting features:  27%|██▋       | 166/618 [00:03<00:08, 53.84it/s]Extracting features:  28%|██▊       | 172/618 [00:03<00:08, 51.89it/s]Extracting features:  29%|██▉       | 179/618 [00:03<00:07, 56.58it/s]Extracting features:  30%|██▉       | 185/618 [00:03<00:07, 56.26it/s]Extracting features:  31%|███       | 192/618 [00:03<00:07, 58.28it/s]Extracting features:  32%|███▏      | 198/618 [00:03<00:07, 58.09it/s]Extracting features:  33%|███▎      | 204/618 [00:03<00:07, 54.61it/s]Extracting features:  34%|███▍      | 211/618 [00:04<00:07, 57.36it/s]Extracting features:  35%|███▌      | 218/618 [00:04<00:06, 58.28it/s]Extracting features:  36%|███▌      | 224/618 [00:04<00:06, 57.66it/s]Extracting features:  37%|███▋      | 230/618 [00:04<00:06, 56.50it/s]Extracting features:  38%|███▊      | 236/618 [00:04<00:06, 55.93it/s]Extracting features:  39%|███▉      | 242/618 [00:04<00:08, 46.49it/s]Extracting features:  40%|████      | 249/618 [00:04<00:07, 51.17it/s]Extracting features:  41%|████▏     | 255/618 [00:04<00:06, 52.30it/s]Extracting features:  42%|████▏     | 261/618 [00:05<00:06, 52.16it/s]Extracting features:  43%|████▎     | 267/618 [00:05<00:06, 50.83it/s]Extracting features:  44%|████▍     | 273/618 [00:05<00:06, 53.13it/s]Extracting features:  45%|████▌     | 279/618 [00:05<00:06, 53.18it/s]Extracting features:  46%|████▌     | 285/618 [00:05<00:06, 54.70it/s]Extracting features:  47%|████▋     | 291/618 [00:05<00:06, 50.95it/s]Extracting features:  48%|████▊     | 298/618 [00:05<00:05, 55.37it/s]Extracting features:  49%|████▉     | 305/618 [00:05<00:05, 53.73it/s]Extracting features:  50%|█████     | 311/618 [00:05<00:05, 52.15it/s]Extracting features:  51%|█████▏    | 317/618 [00:06<00:05, 51.47it/s]Extracting features:  52%|█████▏    | 323/618 [00:06<00:06, 47.69it/s]Extracting features:  53%|█████▎    | 328/618 [00:06<00:06, 46.77it/s]Extracting features:  54%|█████▍    | 335/618 [00:06<00:05, 50.10it/s]Extracting features:  55%|█████▌    | 341/618 [00:06<00:05, 49.77it/s]Extracting features:  56%|█████▌    | 347/618 [00:06<00:05, 47.41it/s]Extracting features:  57%|█████▋    | 352/618 [00:06<00:05, 47.39it/s]Extracting features:  58%|█████▊    | 357/618 [00:06<00:05, 48.05it/s]Extracting features:  59%|█████▊    | 362/618 [00:07<00:05, 48.37it/s]Extracting features:  59%|█████▉    | 367/618 [00:07<00:05, 44.89it/s]Extracting features:  60%|██████    | 373/618 [00:07<00:05, 47.99it/s]Extracting features:  61%|██████▏   | 379/618 [00:07<00:04, 50.91it/s]Extracting features:  62%|██████▏   | 386/618 [00:07<00:04, 54.61it/s]Extracting features:  64%|██████▎   | 393/618 [00:07<00:03, 56.89it/s]Extracting features:  65%|██████▍   | 399/618 [00:07<00:03, 56.58it/s]Extracting features:  66%|██████▌   | 405/618 [00:07<00:03, 54.76it/s]Extracting features:  67%|██████▋   | 412/618 [00:07<00:03, 58.75it/s]Extracting features:  68%|██████▊   | 418/618 [00:08<00:03, 57.26it/s]Extracting features:  69%|██████▉   | 425/618 [00:08<00:03, 58.78it/s]Extracting features:  70%|██████▉   | 431/618 [00:08<00:03, 57.58it/s]Extracting features:  71%|███████   | 437/618 [00:08<00:03, 52.86it/s]Extracting features:  72%|███████▏  | 443/618 [00:08<00:03, 51.04it/s]Extracting features:  73%|███████▎  | 450/618 [00:08<00:03, 54.65it/s]Extracting features:  74%|███████▍  | 456/618 [00:08<00:03, 50.72it/s]Extracting features:  75%|███████▍  | 462/618 [00:08<00:02, 52.01it/s]Extracting features:  76%|███████▌  | 468/618 [00:08<00:02, 52.55it/s]Extracting features:  77%|███████▋  | 474/618 [00:09<00:02, 53.28it/s]Extracting features:  78%|███████▊  | 480/618 [00:09<00:02, 53.74it/s]Extracting features:  79%|███████▊  | 486/618 [00:09<00:02, 54.13it/s]Extracting features:  80%|███████▉  | 492/618 [00:09<00:02, 51.58it/s]Extracting features:  81%|████████  | 498/618 [00:09<00:02, 51.48it/s]Extracting features:  82%|████████▏ | 504/618 [00:09<00:02, 50.53it/s]Extracting features:  83%|████████▎ | 510/618 [00:09<00:02, 52.85it/s]Extracting features:  84%|████████▎ | 517/618 [00:09<00:01, 56.28it/s]Extracting features:  85%|████████▍ | 524/618 [00:09<00:01, 58.52it/s]Extracting features:  86%|████████▌ | 530/618 [00:10<00:01, 56.32it/s]Extracting features:  87%|████████▋ | 537/618 [00:10<00:01, 58.72it/s]Extracting features:  88%|████████▊ | 544/618 [00:10<00:01, 59.21it/s]Extracting features:  89%|████████▉ | 550/618 [00:10<00:01, 58.48it/s]Extracting features:  90%|████████▉ | 556/618 [00:10<00:01, 58.76it/s]Extracting features:  91%|█████████ | 563/618 [00:10<00:00, 59.72it/s]Extracting features:  92%|█████████▏| 570/618 [00:10<00:00, 60.24it/s]Extracting features:  93%|█████████▎| 577/618 [00:10<00:00, 58.36it/s]Extracting features:  94%|█████████▍| 583/618 [00:11<00:00, 57.51it/s]Extracting features:  95%|█████████▌| 589/618 [00:11<00:00, 57.17it/s]Extracting features:  96%|█████████▋| 595/618 [00:11<00:00, 56.45it/s]Extracting features:  97%|█████████▋| 601/618 [00:11<00:00, 56.45it/s]Extracting features:  98%|█████████▊| 608/618 [00:11<00:00, 57.62it/s]Extracting features:  99%|█████████▉| 614/618 [00:11<00:00, 55.02it/s]Extracting features: 100%|██████████| 618/618 [00:11<00:00, 52.52it/s]
2024-12-27 19:23:14,538 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 19:23:14,538 - INFO - Training feature extraction completed in 11.80s
2024-12-27 19:23:14,538 - INFO - Creating model for classifier: KNeighbors
2024-12-27 19:23:14,539 - INFO - Using device: cuda
2024-12-27 19:23:14,539 - INFO - 
Processing poison rate: 0.0
2024-12-27 19:23:14,539 - INFO - Training set processing completed in 0.00s
2024-12-27 19:23:14,539 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 19:23:14,541 - INFO - Memory usage at start_fit: CPU 2977.7 MB, GPU 47.3 MB
2024-12-27 19:23:14,541 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:23:14,803 - INFO - Fitted scaler and transformed data
2024-12-27 19:23:14,803 - INFO - Scaling time: 0.26s
2024-12-27 19:23:14,818 - INFO - Training completed in 0.28s
2024-12-27 19:23:14,819 - INFO - Final memory usage: CPU 3077.9 MB, GPU 143.9 MB
2024-12-27 19:23:14,819 - INFO - Model training completed in 0.28s
2024-12-27 19:23:14,952 - INFO - Prediction completed in 0.13s
2024-12-27 19:23:14,963 - INFO - Poison rate 0.0 completed in 0.42s
2024-12-27 19:23:14,964 - INFO - 
Processing poison rate: 0.01
2024-12-27 19:23:14,965 - INFO - Label flipping details:
2024-12-27 19:23:14,965 - INFO - - Source class: 1
2024-12-27 19:23:14,965 - INFO - - Target class: 0
2024-12-27 19:23:14,965 - INFO - - Available samples in source class: 918
2024-12-27 19:23:14,965 - INFO - - Requested samples to poison: 197
2024-12-27 19:23:14,965 - INFO - - Actual samples to flip: 197
2024-12-27 19:23:14,965 - INFO - - Samples remaining in source class: 721
2024-12-27 19:23:14,965 - INFO - Successfully flipped 197 labels from class 1 to 0
2024-12-27 19:23:14,965 - INFO - Total number of labels flipped: 197
2024-12-27 19:23:14,966 - INFO - Label flipping completed in 0.00s
2024-12-27 19:23:14,966 - INFO - Training set processing completed in 0.00s
2024-12-27 19:23:14,966 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 19:23:14,967 - INFO - Memory usage at start_fit: CPU 2981.4 MB, GPU 143.9 MB
2024-12-27 19:23:14,967 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:23:15,226 - INFO - Fitted scaler and transformed data
2024-12-27 19:23:15,226 - INFO - Scaling time: 0.26s
2024-12-27 19:23:15,244 - INFO - Training completed in 0.28s
2024-12-27 19:23:15,245 - INFO - Final memory usage: CPU 3077.9 MB, GPU 143.9 MB
2024-12-27 19:23:15,245 - INFO - Model training completed in 0.28s
2024-12-27 19:23:15,367 - INFO - Prediction completed in 0.12s
2024-12-27 19:23:15,378 - INFO - Poison rate 0.01 completed in 0.41s
2024-12-27 19:23:15,378 - INFO - 
Processing poison rate: 0.03
2024-12-27 19:23:15,379 - INFO - Label flipping details:
2024-12-27 19:23:15,380 - INFO - - Source class: 1
2024-12-27 19:23:15,380 - INFO - - Target class: 0
2024-12-27 19:23:15,380 - INFO - - Available samples in source class: 918
2024-12-27 19:23:15,380 - INFO - - Requested samples to poison: 592
2024-12-27 19:23:15,380 - INFO - - Actual samples to flip: 592
2024-12-27 19:23:15,380 - INFO - - Samples remaining in source class: 326
2024-12-27 19:23:15,380 - INFO - Successfully flipped 592 labels from class 1 to 0
2024-12-27 19:23:15,380 - INFO - Total number of labels flipped: 592
2024-12-27 19:23:15,380 - INFO - Label flipping completed in 0.00s
2024-12-27 19:23:15,380 - INFO - Training set processing completed in 0.00s
2024-12-27 19:23:15,380 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 19:23:15,381 - INFO - Memory usage at start_fit: CPU 2981.4 MB, GPU 143.9 MB
2024-12-27 19:23:15,381 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:23:15,638 - INFO - Fitted scaler and transformed data
2024-12-27 19:23:15,639 - INFO - Scaling time: 0.26s
2024-12-27 19:23:15,655 - INFO - Training completed in 0.27s
2024-12-27 19:23:15,655 - INFO - Final memory usage: CPU 3077.9 MB, GPU 143.9 MB
2024-12-27 19:23:15,656 - INFO - Model training completed in 0.28s
2024-12-27 19:23:15,789 - INFO - Prediction completed in 0.13s
2024-12-27 19:23:15,800 - INFO - Poison rate 0.03 completed in 0.42s
2024-12-27 19:23:15,800 - INFO - 
Processing poison rate: 0.05
2024-12-27 19:23:15,802 - INFO - Label flipping details:
2024-12-27 19:23:15,802 - INFO - - Source class: 1
2024-12-27 19:23:15,802 - INFO - - Target class: 0
2024-12-27 19:23:15,802 - INFO - - Available samples in source class: 918
2024-12-27 19:23:15,802 - INFO - - Requested samples to poison: 987
2024-12-27 19:23:15,802 - INFO - - Actual samples to flip: 917
2024-12-27 19:23:15,802 - INFO - - Samples remaining in source class: 1
2024-12-27 19:23:15,802 - INFO - Successfully flipped 917 labels from class 1 to 0
2024-12-27 19:23:15,802 - INFO - Total number of labels flipped: 917
2024-12-27 19:23:15,802 - INFO - Label flipping completed in 0.00s
2024-12-27 19:23:15,802 - INFO - Training set processing completed in 0.00s
2024-12-27 19:23:15,802 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 19:23:15,804 - INFO - Memory usage at start_fit: CPU 2981.4 MB, GPU 143.9 MB
2024-12-27 19:23:15,804 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:23:16,067 - INFO - Fitted scaler and transformed data
2024-12-27 19:23:16,067 - INFO - Scaling time: 0.26s
2024-12-27 19:23:16,084 - INFO - Training completed in 0.28s
2024-12-27 19:23:16,085 - INFO - Final memory usage: CPU 3077.9 MB, GPU 143.9 MB
2024-12-27 19:23:16,085 - INFO - Model training completed in 0.28s
2024-12-27 19:23:16,200 - INFO - Prediction completed in 0.11s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:23:16,214 - INFO - Poison rate 0.05 completed in 0.41s
2024-12-27 19:23:16,214 - INFO - 
Processing poison rate: 0.07
2024-12-27 19:23:16,217 - INFO - Label flipping details:
2024-12-27 19:23:16,217 - INFO - - Source class: 1
2024-12-27 19:23:16,217 - INFO - - Target class: 0
2024-12-27 19:23:16,217 - INFO - - Available samples in source class: 918
2024-12-27 19:23:16,217 - INFO - - Requested samples to poison: 1382
2024-12-27 19:23:16,218 - INFO - - Actual samples to flip: 917
2024-12-27 19:23:16,218 - INFO - - Samples remaining in source class: 1
2024-12-27 19:23:16,218 - INFO - Successfully flipped 917 labels from class 1 to 0
2024-12-27 19:23:16,218 - INFO - Total number of labels flipped: 917
2024-12-27 19:23:16,218 - INFO - Label flipping completed in 0.00s
2024-12-27 19:23:16,219 - INFO - Training set processing completed in 0.00s
2024-12-27 19:23:16,219 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 19:23:16,220 - INFO - Memory usage at start_fit: CPU 2981.4 MB, GPU 143.9 MB
2024-12-27 19:23:16,220 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:23:16,523 - INFO - Fitted scaler and transformed data
2024-12-27 19:23:16,524 - INFO - Scaling time: 0.30s
2024-12-27 19:23:16,540 - INFO - Training completed in 0.32s
2024-12-27 19:23:16,540 - INFO - Final memory usage: CPU 3077.9 MB, GPU 143.9 MB
2024-12-27 19:23:16,541 - INFO - Model training completed in 0.32s
2024-12-27 19:23:16,660 - INFO - Prediction completed in 0.12s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:23:16,671 - INFO - Poison rate 0.07 completed in 0.46s
2024-12-27 19:23:16,671 - INFO - 
Processing poison rate: 0.1
2024-12-27 19:23:16,673 - INFO - Label flipping details:
2024-12-27 19:23:16,673 - INFO - - Source class: 1
2024-12-27 19:23:16,673 - INFO - - Target class: 0
2024-12-27 19:23:16,673 - INFO - - Available samples in source class: 918
2024-12-27 19:23:16,673 - INFO - - Requested samples to poison: 1975
2024-12-27 19:23:16,673 - INFO - - Actual samples to flip: 917
2024-12-27 19:23:16,673 - INFO - - Samples remaining in source class: 1
2024-12-27 19:23:16,673 - INFO - Successfully flipped 917 labels from class 1 to 0
2024-12-27 19:23:16,673 - INFO - Total number of labels flipped: 917
2024-12-27 19:23:16,673 - INFO - Label flipping completed in 0.00s
2024-12-27 19:23:16,673 - INFO - Training set processing completed in 0.00s
2024-12-27 19:23:16,673 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 19:23:16,674 - INFO - Memory usage at start_fit: CPU 2981.4 MB, GPU 143.9 MB
2024-12-27 19:23:16,674 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:23:16,984 - INFO - Fitted scaler and transformed data
2024-12-27 19:23:16,984 - INFO - Scaling time: 0.31s
2024-12-27 19:23:17,002 - INFO - Training completed in 0.33s
2024-12-27 19:23:17,003 - INFO - Final memory usage: CPU 3077.9 MB, GPU 143.9 MB
2024-12-27 19:23:17,003 - INFO - Model training completed in 0.33s
2024-12-27 19:23:17,118 - INFO - Prediction completed in 0.11s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:23:17,129 - INFO - Poison rate 0.1 completed in 0.46s
2024-12-27 19:23:17,129 - INFO - 
Processing poison rate: 0.2
2024-12-27 19:23:17,130 - INFO - Label flipping details:
2024-12-27 19:23:17,130 - INFO - - Source class: 1
2024-12-27 19:23:17,130 - INFO - - Target class: 0
2024-12-27 19:23:17,130 - INFO - - Available samples in source class: 918
2024-12-27 19:23:17,131 - INFO - - Requested samples to poison: 3951
2024-12-27 19:23:17,131 - INFO - - Actual samples to flip: 917
2024-12-27 19:23:17,131 - INFO - - Samples remaining in source class: 1
2024-12-27 19:23:17,131 - INFO - Successfully flipped 917 labels from class 1 to 0
2024-12-27 19:23:17,131 - INFO - Total number of labels flipped: 917
2024-12-27 19:23:17,131 - INFO - Label flipping completed in 0.00s
2024-12-27 19:23:17,131 - INFO - Training set processing completed in 0.00s
2024-12-27 19:23:17,131 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 19:23:17,132 - INFO - Memory usage at start_fit: CPU 2981.4 MB, GPU 143.9 MB
2024-12-27 19:23:17,132 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:23:17,381 - INFO - Fitted scaler and transformed data
2024-12-27 19:23:17,381 - INFO - Scaling time: 0.25s
2024-12-27 19:23:17,396 - INFO - Training completed in 0.26s
2024-12-27 19:23:17,397 - INFO - Final memory usage: CPU 3077.9 MB, GPU 143.9 MB
2024-12-27 19:23:17,397 - INFO - Model training completed in 0.27s
2024-12-27 19:23:17,512 - INFO - Prediction completed in 0.11s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:23:17,522 - INFO - Poison rate 0.2 completed in 0.39s
2024-12-27 19:23:17,524 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 19:23:17,524 - INFO - Total evaluation time: 35.80s
2024-12-27 19:23:17,530 - INFO - 
Progress: 25.0% - Evaluating GTSRB with KNeighbors (dynadetect mode, iteration 1/1)
2024-12-27 19:23:17,620 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 19:23:17,695 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 19:23:17,780 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 19:23:17,780 - INFO - Dataset type: image
2024-12-27 19:23:17,780 - INFO - Sample size: 39209
2024-12-27 19:23:17,780 - INFO - Using device: cuda
2024-12-27 19:23:17,780 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 19:23:17,782 - INFO - Loading datasets...
2024-12-27 19:23:35,398 - INFO - Dataset loading completed in 17.61s
2024-12-27 19:23:35,398 - INFO - Extracting validation features...
2024-12-27 19:23:35,398 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:27,  4.97it/s]Extracting features:   1%|▏         | 2/139 [00:00<00:19,  6.91it/s]Extracting features:   6%|▌         | 8/139 [00:00<00:05, 25.05it/s]Extracting features:  10%|█         | 14/139 [00:00<00:03, 36.29it/s]Extracting features:  14%|█▍        | 20/139 [00:00<00:02, 43.82it/s]Extracting features:  19%|█▊        | 26/139 [00:00<00:02, 45.72it/s]Extracting features:  23%|██▎       | 32/139 [00:00<00:02, 49.45it/s]Extracting features:  28%|██▊       | 39/139 [00:00<00:01, 54.60it/s]Extracting features:  32%|███▏      | 45/139 [00:01<00:01, 53.83it/s]Extracting features:  37%|███▋      | 51/139 [00:01<00:01, 55.25it/s]Extracting features:  41%|████      | 57/139 [00:01<00:01, 55.55it/s]Extracting features:  46%|████▌     | 64/139 [00:01<00:01, 59.14it/s]Extracting features:  50%|█████     | 70/139 [00:01<00:01, 59.38it/s]Extracting features:  55%|█████▍    | 76/139 [00:01<00:01, 58.07it/s]Extracting features:  59%|█████▉    | 82/139 [00:01<00:01, 55.57it/s]Extracting features:  63%|██████▎   | 88/139 [00:01<00:00, 55.96it/s]Extracting features:  68%|██████▊   | 94/139 [00:01<00:00, 55.32it/s]Extracting features:  72%|███████▏  | 100/139 [00:02<00:00, 56.09it/s]Extracting features:  76%|███████▋  | 106/139 [00:02<00:00, 56.12it/s]Extracting features:  81%|████████▏ | 113/139 [00:02<00:00, 58.49it/s]Extracting features:  86%|████████▌ | 119/139 [00:02<00:00, 54.53it/s]Extracting features:  90%|████████▉ | 125/139 [00:02<00:00, 50.26it/s]Extracting features:  95%|█████████▍| 132/139 [00:02<00:00, 53.11it/s]Extracting features:  99%|█████████▉| 138/139 [00:02<00:00, 47.48it/s]Extracting features: 100%|██████████| 139/139 [00:02<00:00, 48.12it/s]
2024-12-27 19:23:38,300 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 19:23:38,301 - INFO - Validation feature extraction completed in 2.90s
2024-12-27 19:23:38,301 - INFO - Extracting training features...
2024-12-27 19:23:38,301 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<02:11,  4.69it/s]Extracting features:   1%|          | 6/618 [00:00<00:28, 21.77it/s]Extracting features:   2%|▏         | 12/618 [00:00<00:17, 34.63it/s]Extracting features:   3%|▎         | 18/618 [00:00<00:14, 40.76it/s]Extracting features:   4%|▍         | 25/618 [00:00<00:12, 47.50it/s]Extracting features:   5%|▌         | 31/618 [00:00<00:12, 48.80it/s]Extracting features:   6%|▌         | 37/618 [00:00<00:11, 51.41it/s]Extracting features:   7%|▋         | 43/618 [00:00<00:10, 52.41it/s]Extracting features:   8%|▊         | 49/618 [00:01<00:10, 53.63it/s]Extracting features:   9%|▉         | 55/618 [00:01<00:10, 55.05it/s]Extracting features:  10%|▉         | 61/618 [00:01<00:10, 54.72it/s]Extracting features:  11%|█         | 67/618 [00:01<00:10, 54.77it/s]Extracting features:  12%|█▏        | 73/618 [00:01<00:09, 56.15it/s]Extracting features:  13%|█▎        | 79/618 [00:01<00:09, 53.95it/s]Extracting features:  14%|█▍        | 86/618 [00:01<00:09, 56.22it/s]Extracting features:  15%|█▌        | 94/618 [00:01<00:08, 59.80it/s]Extracting features:  16%|█▌        | 100/618 [00:01<00:08, 59.25it/s]Extracting features:  17%|█▋        | 107/618 [00:02<00:08, 59.83it/s]Extracting features:  18%|█▊        | 113/618 [00:02<00:08, 59.08it/s]Extracting features:  19%|█▉        | 119/618 [00:02<00:08, 58.52it/s]Extracting features:  20%|██        | 125/618 [00:02<00:08, 56.23it/s]Extracting features:  21%|██        | 131/618 [00:02<00:08, 55.31it/s]Extracting features:  22%|██▏       | 137/618 [00:02<00:08, 54.23it/s]Extracting features:  23%|██▎       | 143/618 [00:02<00:08, 54.05it/s]Extracting features:  24%|██▍       | 149/618 [00:02<00:08, 54.49it/s]Extracting features:  25%|██▌       | 155/618 [00:02<00:08, 55.58it/s]Extracting features:  26%|██▌       | 161/618 [00:03<00:08, 56.43it/s]Extracting features:  27%|██▋       | 167/618 [00:03<00:07, 57.29it/s]Extracting features:  28%|██▊       | 173/618 [00:03<00:07, 57.85it/s]Extracting features:  29%|██▉       | 179/618 [00:03<00:07, 56.81it/s]Extracting features:  30%|██▉       | 185/618 [00:03<00:08, 50.42it/s]Extracting features:  31%|███       | 191/618 [00:03<00:08, 49.55it/s]Extracting features:  32%|███▏      | 197/618 [00:03<00:08, 50.08it/s]Extracting features:  33%|███▎      | 203/618 [00:03<00:08, 51.29it/s]Extracting features:  34%|███▍      | 209/618 [00:03<00:07, 53.24it/s]Extracting features:  35%|███▍      | 216/618 [00:04<00:07, 56.27it/s]Extracting features:  36%|███▌      | 223/618 [00:04<00:06, 58.39it/s]Extracting features:  37%|███▋      | 229/618 [00:04<00:06, 55.90it/s]Extracting features:  38%|███▊      | 236/618 [00:04<00:06, 58.33it/s]Extracting features:  39%|███▉      | 242/618 [00:04<00:06, 55.84it/s]Extracting features:  40%|████      | 248/618 [00:04<00:06, 55.35it/s]Extracting features:  41%|████      | 254/618 [00:04<00:06, 54.70it/s]Extracting features:  42%|████▏     | 260/618 [00:04<00:06, 52.87it/s]Extracting features:  43%|████▎     | 266/618 [00:05<00:07, 49.91it/s]Extracting features:  44%|████▍     | 272/618 [00:05<00:06, 50.69it/s]Extracting features:  45%|████▍     | 278/618 [00:05<00:06, 52.26it/s]Extracting features:  46%|████▌     | 285/618 [00:05<00:06, 54.93it/s]Extracting features:  47%|████▋     | 291/618 [00:05<00:05, 55.86it/s]Extracting features:  48%|████▊     | 297/618 [00:05<00:05, 55.11it/s]Extracting features:  49%|████▉     | 304/618 [00:05<00:05, 55.96it/s]Extracting features:  50%|█████     | 310/618 [00:05<00:05, 53.21it/s]Extracting features:  51%|█████▏    | 317/618 [00:05<00:05, 55.83it/s]Extracting features:  52%|█████▏    | 323/618 [00:06<00:05, 55.37it/s]Extracting features:  53%|█████▎    | 329/618 [00:06<00:05, 53.58it/s]Extracting features:  54%|█████▍    | 335/618 [00:06<00:05, 51.05it/s]Extracting features:  55%|█████▌    | 341/618 [00:06<00:05, 48.37it/s]Extracting features:  56%|█████▌    | 346/618 [00:06<00:06, 44.74it/s]Extracting features:  57%|█████▋    | 351/618 [00:06<00:06, 41.66it/s]Extracting features:  58%|█████▊    | 357/618 [00:06<00:05, 46.01it/s]Extracting features:  59%|█████▊    | 362/618 [00:06<00:05, 43.94it/s]Extracting features:  60%|█████▉    | 368/618 [00:07<00:05, 46.45it/s]Extracting features:  61%|██████    | 374/618 [00:07<00:04, 49.12it/s]Extracting features:  61%|██████▏   | 380/618 [00:07<00:04, 51.24it/s]Extracting features:  62%|██████▏   | 386/618 [00:07<00:04, 51.92it/s]Extracting features:  63%|██████▎   | 392/618 [00:07<00:04, 53.74it/s]Extracting features:  65%|██████▍   | 399/618 [00:07<00:03, 55.92it/s]Extracting features:  66%|██████▌   | 405/618 [00:07<00:03, 56.44it/s]Extracting features:  67%|██████▋   | 411/618 [00:07<00:04, 50.38it/s]Extracting features:  67%|██████▋   | 417/618 [00:07<00:04, 49.75it/s]Extracting features:  69%|██████▊   | 424/618 [00:08<00:03, 53.42it/s]Extracting features:  70%|██████▉   | 430/618 [00:08<00:03, 54.68it/s]Extracting features:  71%|███████   | 437/618 [00:08<00:03, 56.99it/s]Extracting features:  72%|███████▏  | 443/618 [00:08<00:03, 53.31it/s]Extracting features:  73%|███████▎  | 449/618 [00:08<00:03, 45.54it/s]Extracting features:  73%|███████▎  | 454/618 [00:08<00:03, 45.19it/s]Extracting features:  74%|███████▍  | 459/618 [00:08<00:03, 43.52it/s]Extracting features:  75%|███████▌  | 464/618 [00:09<00:03, 40.50it/s]Extracting features:  76%|███████▌  | 469/618 [00:09<00:03, 41.41it/s]Extracting features:  77%|███████▋  | 474/618 [00:09<00:03, 42.99it/s]Extracting features:  78%|███████▊  | 480/618 [00:09<00:02, 47.21it/s]Extracting features:  79%|███████▊  | 486/618 [00:09<00:02, 48.09it/s]Extracting features:  79%|███████▉  | 491/618 [00:09<00:02, 45.03it/s]Extracting features:  80%|████████  | 496/618 [00:09<00:02, 44.54it/s]Extracting features:  81%|████████  | 501/618 [00:09<00:02, 43.27it/s]Extracting features:  82%|████████▏ | 506/618 [00:09<00:02, 39.37it/s]Extracting features:  83%|████████▎ | 511/618 [00:10<00:02, 40.50it/s]Extracting features:  84%|████████▎ | 517/618 [00:10<00:02, 43.68it/s]Extracting features:  84%|████████▍ | 522/618 [00:10<00:02, 43.98it/s]Extracting features:  85%|████████▌ | 527/618 [00:10<00:02, 39.64it/s]Extracting features:  86%|████████▌ | 532/618 [00:10<00:02, 41.47it/s]Extracting features:  87%|████████▋ | 539/618 [00:10<00:01, 46.52it/s]Extracting features:  88%|████████▊ | 545/618 [00:10<00:01, 49.36it/s]Extracting features:  89%|████████▉ | 552/618 [00:10<00:01, 52.11it/s]Extracting features:  90%|█████████ | 558/618 [00:11<00:01, 51.78it/s]Extracting features:  91%|█████████▏| 565/618 [00:11<00:00, 55.47it/s]Extracting features:  92%|█████████▏| 571/618 [00:11<00:00, 56.23it/s]Extracting features:  93%|█████████▎| 577/618 [00:11<00:00, 53.29it/s]Extracting features:  94%|█████████▍| 583/618 [00:11<00:00, 50.64it/s]Extracting features:  96%|█████████▌| 591/618 [00:11<00:00, 55.61it/s]Extracting features:  97%|█████████▋| 597/618 [00:11<00:00, 55.53it/s]Extracting features:  98%|█████████▊| 604/618 [00:11<00:00, 58.22it/s]Extracting features:  99%|█████████▊| 610/618 [00:11<00:00, 53.19it/s]Extracting features: 100%|█████████▉| 616/618 [00:12<00:00, 48.32it/s]Extracting features: 100%|██████████| 618/618 [00:12<00:00, 50.32it/s]
2024-12-27 19:23:50,617 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 19:23:50,618 - INFO - Training feature extraction completed in 12.32s
2024-12-27 19:23:50,618 - INFO - Creating model for classifier: KNeighbors
2024-12-27 19:23:50,618 - INFO - Using device: cuda
2024-12-27 19:23:50,618 - INFO - 
Processing poison rate: 0.0
2024-12-27 19:23:50,618 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:23:50,618 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:23:52,505 - INFO - Feature scaling completed in 1.89s
2024-12-27 19:23:52,506 - INFO - Starting feature selection (k=50)
2024-12-27 19:23:52,523 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 19:23:52,523 - INFO - Starting anomaly detection
2024-12-27 19:24:00,438 - INFO - Anomaly detection completed in 7.91s
2024-12-27 19:24:00,438 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:24:00,438 - INFO - Total fit_transform time: 9.82s
2024-12-27 19:24:00,438 - INFO - Training set processing completed in 9.82s
2024-12-27 19:24:00,439 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 19:24:00,440 - INFO - Memory usage at start_fit: CPU 2981.0 MB, GPU 47.3 MB
2024-12-27 19:24:00,440 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:24:00,693 - INFO - Fitted scaler and transformed data
2024-12-27 19:24:00,694 - INFO - Scaling time: 0.25s
2024-12-27 19:24:00,717 - INFO - Training completed in 0.28s
2024-12-27 19:24:00,718 - INFO - Final memory usage: CPU 3083.7 MB, GPU 143.9 MB
2024-12-27 19:24:00,718 - INFO - Model training completed in 0.28s
2024-12-27 19:24:00,985 - INFO - Prediction completed in 0.27s
2024-12-27 19:24:00,999 - INFO - Poison rate 0.0 completed in 10.38s
2024-12-27 19:24:00,999 - INFO - 
Processing poison rate: 0.01
2024-12-27 19:24:01,001 - INFO - Label flipping details:
2024-12-27 19:24:01,001 - INFO - - Source class: 1
2024-12-27 19:24:01,001 - INFO - - Target class: 0
2024-12-27 19:24:01,001 - INFO - - Available samples in source class: 916
2024-12-27 19:24:01,001 - INFO - - Requested samples to poison: 197
2024-12-27 19:24:01,001 - INFO - - Actual samples to flip: 197
2024-12-27 19:24:01,001 - INFO - - Samples remaining in source class: 719
2024-12-27 19:24:01,001 - INFO - Successfully flipped 197 labels from class 1 to 0
2024-12-27 19:24:01,001 - INFO - Total number of labels flipped: 197
2024-12-27 19:24:01,001 - INFO - Label flipping completed in 0.00s
2024-12-27 19:24:01,001 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:24:01,001 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:24:02,851 - INFO - Feature scaling completed in 1.85s
2024-12-27 19:24:02,851 - INFO - Starting feature selection (k=50)
2024-12-27 19:24:02,876 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 19:24:02,877 - INFO - Starting anomaly detection
2024-12-27 19:24:10,557 - INFO - Anomaly detection completed in 7.68s
2024-12-27 19:24:10,557 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:24:10,558 - INFO - Total fit_transform time: 9.56s
2024-12-27 19:24:10,558 - INFO - Training set processing completed in 9.56s
2024-12-27 19:24:10,559 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 19:24:10,560 - INFO - Memory usage at start_fit: CPU 2987.3 MB, GPU 143.9 MB
2024-12-27 19:24:10,560 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:24:10,839 - INFO - Fitted scaler and transformed data
2024-12-27 19:24:10,840 - INFO - Scaling time: 0.28s
2024-12-27 19:24:10,860 - INFO - Training completed in 0.30s
2024-12-27 19:24:10,861 - INFO - Final memory usage: CPU 3083.7 MB, GPU 143.9 MB
2024-12-27 19:24:10,861 - INFO - Model training completed in 0.30s
2024-12-27 19:24:11,169 - INFO - Prediction completed in 0.31s
2024-12-27 19:24:11,180 - INFO - Poison rate 0.01 completed in 10.18s
2024-12-27 19:24:11,180 - INFO - 
Processing poison rate: 0.03
2024-12-27 19:24:11,181 - INFO - Label flipping details:
2024-12-27 19:24:11,181 - INFO - - Source class: 1
2024-12-27 19:24:11,181 - INFO - - Target class: 0
2024-12-27 19:24:11,181 - INFO - - Available samples in source class: 916
2024-12-27 19:24:11,181 - INFO - - Requested samples to poison: 592
2024-12-27 19:24:11,181 - INFO - - Actual samples to flip: 592
2024-12-27 19:24:11,182 - INFO - - Samples remaining in source class: 324
2024-12-27 19:24:11,182 - INFO - Successfully flipped 592 labels from class 1 to 0
2024-12-27 19:24:11,182 - INFO - Total number of labels flipped: 592
2024-12-27 19:24:11,182 - INFO - Label flipping completed in 0.00s
2024-12-27 19:24:11,182 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:24:11,182 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:24:13,022 - INFO - Feature scaling completed in 1.84s
2024-12-27 19:24:13,022 - INFO - Starting feature selection (k=50)
2024-12-27 19:24:13,042 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 19:24:13,042 - INFO - Starting anomaly detection
2024-12-27 19:24:20,844 - INFO - Anomaly detection completed in 7.80s
2024-12-27 19:24:20,844 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:24:20,845 - INFO - Total fit_transform time: 9.66s
2024-12-27 19:24:20,845 - INFO - Training set processing completed in 9.66s
2024-12-27 19:24:20,846 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 19:24:20,847 - INFO - Memory usage at start_fit: CPU 2987.3 MB, GPU 143.9 MB
2024-12-27 19:24:20,848 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:24:21,128 - INFO - Fitted scaler and transformed data
2024-12-27 19:24:21,128 - INFO - Scaling time: 0.28s
2024-12-27 19:24:21,148 - INFO - Training completed in 0.30s
2024-12-27 19:24:21,149 - INFO - Final memory usage: CPU 3083.7 MB, GPU 143.9 MB
2024-12-27 19:24:21,149 - INFO - Model training completed in 0.30s
2024-12-27 19:24:21,553 - INFO - Prediction completed in 0.40s
2024-12-27 19:24:21,563 - INFO - Poison rate 0.03 completed in 10.38s
2024-12-27 19:24:21,564 - INFO - 
Processing poison rate: 0.05
2024-12-27 19:24:21,565 - INFO - Label flipping details:
2024-12-27 19:24:21,565 - INFO - - Source class: 1
2024-12-27 19:24:21,565 - INFO - - Target class: 0
2024-12-27 19:24:21,565 - INFO - - Available samples in source class: 916
2024-12-27 19:24:21,565 - INFO - - Requested samples to poison: 987
2024-12-27 19:24:21,565 - INFO - - Actual samples to flip: 915
2024-12-27 19:24:21,565 - INFO - - Samples remaining in source class: 1
2024-12-27 19:24:21,565 - INFO - Successfully flipped 915 labels from class 1 to 0
2024-12-27 19:24:21,565 - INFO - Total number of labels flipped: 915
2024-12-27 19:24:21,566 - INFO - Label flipping completed in 0.00s
2024-12-27 19:24:21,566 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:24:21,566 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:24:23,365 - INFO - Feature scaling completed in 1.80s
2024-12-27 19:24:23,366 - INFO - Starting feature selection (k=50)
2024-12-27 19:24:23,387 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 19:24:23,387 - INFO - Starting anomaly detection
2024-12-27 19:24:31,285 - INFO - Anomaly detection completed in 7.90s
2024-12-27 19:24:31,286 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:24:31,286 - INFO - Total fit_transform time: 9.72s
2024-12-27 19:24:31,286 - INFO - Training set processing completed in 9.72s
2024-12-27 19:24:31,286 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 19:24:31,288 - INFO - Memory usage at start_fit: CPU 2987.3 MB, GPU 143.9 MB
2024-12-27 19:24:31,288 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:24:31,562 - INFO - Fitted scaler and transformed data
2024-12-27 19:24:31,562 - INFO - Scaling time: 0.27s
2024-12-27 19:24:31,581 - INFO - Training completed in 0.29s
2024-12-27 19:24:31,582 - INFO - Final memory usage: CPU 3083.7 MB, GPU 143.9 MB
2024-12-27 19:24:31,582 - INFO - Model training completed in 0.30s
2024-12-27 19:24:31,955 - INFO - Prediction completed in 0.37s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:24:31,967 - INFO - Poison rate 0.05 completed in 10.40s
2024-12-27 19:24:31,967 - INFO - 
Processing poison rate: 0.07
2024-12-27 19:24:31,968 - INFO - Label flipping details:
2024-12-27 19:24:31,968 - INFO - - Source class: 1
2024-12-27 19:24:31,968 - INFO - - Target class: 0
2024-12-27 19:24:31,968 - INFO - - Available samples in source class: 916
2024-12-27 19:24:31,968 - INFO - - Requested samples to poison: 1382
2024-12-27 19:24:31,968 - INFO - - Actual samples to flip: 915
2024-12-27 19:24:31,968 - INFO - - Samples remaining in source class: 1
2024-12-27 19:24:31,969 - INFO - Successfully flipped 915 labels from class 1 to 0
2024-12-27 19:24:31,969 - INFO - Total number of labels flipped: 915
2024-12-27 19:24:31,969 - INFO - Label flipping completed in 0.00s
2024-12-27 19:24:31,969 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:24:31,969 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:24:33,826 - INFO - Feature scaling completed in 1.86s
2024-12-27 19:24:33,826 - INFO - Starting feature selection (k=50)
2024-12-27 19:24:33,843 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 19:24:33,843 - INFO - Starting anomaly detection
2024-12-27 19:24:41,476 - INFO - Anomaly detection completed in 7.63s
2024-12-27 19:24:41,476 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:24:41,476 - INFO - Total fit_transform time: 9.51s
2024-12-27 19:24:41,477 - INFO - Training set processing completed in 9.51s
2024-12-27 19:24:41,477 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 19:24:41,478 - INFO - Memory usage at start_fit: CPU 2987.3 MB, GPU 143.9 MB
2024-12-27 19:24:41,478 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:24:41,735 - INFO - Fitted scaler and transformed data
2024-12-27 19:24:41,736 - INFO - Scaling time: 0.26s
2024-12-27 19:24:41,755 - INFO - Training completed in 0.28s
2024-12-27 19:24:41,755 - INFO - Final memory usage: CPU 3083.7 MB, GPU 143.9 MB
2024-12-27 19:24:41,756 - INFO - Model training completed in 0.28s
2024-12-27 19:24:42,156 - INFO - Prediction completed in 0.40s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:24:42,176 - INFO - Poison rate 0.07 completed in 10.21s
2024-12-27 19:24:42,176 - INFO - 
Processing poison rate: 0.1
2024-12-27 19:24:42,178 - INFO - Label flipping details:
2024-12-27 19:24:42,178 - INFO - - Source class: 1
2024-12-27 19:24:42,178 - INFO - - Target class: 0
2024-12-27 19:24:42,178 - INFO - - Available samples in source class: 916
2024-12-27 19:24:42,178 - INFO - - Requested samples to poison: 1975
2024-12-27 19:24:42,178 - INFO - - Actual samples to flip: 915
2024-12-27 19:24:42,179 - INFO - - Samples remaining in source class: 1
2024-12-27 19:24:42,179 - INFO - Successfully flipped 915 labels from class 1 to 0
2024-12-27 19:24:42,179 - INFO - Total number of labels flipped: 915
2024-12-27 19:24:42,179 - INFO - Label flipping completed in 0.00s
2024-12-27 19:24:42,179 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:24:42,179 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:24:44,082 - INFO - Feature scaling completed in 1.90s
2024-12-27 19:24:44,082 - INFO - Starting feature selection (k=50)
2024-12-27 19:24:44,099 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 19:24:44,099 - INFO - Starting anomaly detection
2024-12-27 19:24:51,597 - INFO - Anomaly detection completed in 7.50s
2024-12-27 19:24:51,597 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:24:51,597 - INFO - Total fit_transform time: 9.42s
2024-12-27 19:24:51,598 - INFO - Training set processing completed in 9.42s
2024-12-27 19:24:51,598 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 19:24:51,599 - INFO - Memory usage at start_fit: CPU 2987.3 MB, GPU 143.9 MB
2024-12-27 19:24:51,599 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:24:51,849 - INFO - Fitted scaler and transformed data
2024-12-27 19:24:51,849 - INFO - Scaling time: 0.25s
2024-12-27 19:24:51,870 - INFO - Training completed in 0.27s
2024-12-27 19:24:51,871 - INFO - Final memory usage: CPU 3083.7 MB, GPU 143.9 MB
2024-12-27 19:24:51,872 - INFO - Model training completed in 0.27s
2024-12-27 19:24:52,166 - INFO - Prediction completed in 0.29s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:24:52,177 - INFO - Poison rate 0.1 completed in 10.00s
2024-12-27 19:24:52,177 - INFO - 
Processing poison rate: 0.2
2024-12-27 19:24:52,178 - INFO - Label flipping details:
2024-12-27 19:24:52,178 - INFO - - Source class: 1
2024-12-27 19:24:52,178 - INFO - - Target class: 0
2024-12-27 19:24:52,178 - INFO - - Available samples in source class: 916
2024-12-27 19:24:52,178 - INFO - - Requested samples to poison: 3951
2024-12-27 19:24:52,178 - INFO - - Actual samples to flip: 915
2024-12-27 19:24:52,178 - INFO - - Samples remaining in source class: 1
2024-12-27 19:24:52,178 - INFO - Successfully flipped 915 labels from class 1 to 0
2024-12-27 19:24:52,179 - INFO - Total number of labels flipped: 915
2024-12-27 19:24:52,179 - INFO - Label flipping completed in 0.00s
2024-12-27 19:24:52,179 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:24:52,179 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:24:54,064 - INFO - Feature scaling completed in 1.89s
2024-12-27 19:24:54,064 - INFO - Starting feature selection (k=50)
2024-12-27 19:24:54,081 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 19:24:54,082 - INFO - Starting anomaly detection
2024-12-27 19:25:00,692 - INFO - Anomaly detection completed in 6.61s
2024-12-27 19:25:00,692 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:25:00,693 - INFO - Total fit_transform time: 8.51s
2024-12-27 19:25:00,694 - INFO - Training set processing completed in 8.52s
2024-12-27 19:25:00,694 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 19:25:00,696 - INFO - Memory usage at start_fit: CPU 2987.3 MB, GPU 143.9 MB
2024-12-27 19:25:00,696 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:25:00,973 - INFO - Fitted scaler and transformed data
2024-12-27 19:25:00,973 - INFO - Scaling time: 0.28s
2024-12-27 19:25:00,992 - INFO - Training completed in 0.30s
2024-12-27 19:25:00,992 - INFO - Final memory usage: CPU 3083.7 MB, GPU 143.9 MB
2024-12-27 19:25:00,993 - INFO - Model training completed in 0.30s
2024-12-27 19:25:01,351 - INFO - Prediction completed in 0.36s
2024-12-27 19:25:01,364 - INFO - Poison rate 0.2 completed in 9.19s
2024-12-27 19:25:01,366 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 19:25:01,366 - INFO - Total evaluation time: 103.58s
2024-12-27 19:25:01,372 - INFO - Completed evaluation for GTSRB
2024-12-27 19:25:01,372 - INFO - 
Processing dataset: GTSRB
2024-12-27 19:25:01,442 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 19:25:01,660 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 19:25:01,742 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 19:25:01,742 - INFO - Dataset type: image
2024-12-27 19:25:01,742 - INFO - Sample size: 39209
2024-12-27 19:25:01,742 - INFO - Using device: cuda
2024-12-27 19:25:01,742 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 19:25:01,745 - INFO - 
Progress: 26.0% - Evaluating GTSRB with SVM (standard mode, iteration 1/1)
2024-12-27 19:25:01,804 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 19:25:02,399 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 19:25:02,496 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 19:25:02,496 - INFO - Dataset type: image
2024-12-27 19:25:02,496 - INFO - Sample size: 39209
2024-12-27 19:25:02,496 - INFO - Using device: cuda
2024-12-27 19:25:02,496 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 19:25:02,498 - INFO - Loading datasets...
2024-12-27 19:25:19,865 - INFO - Dataset loading completed in 17.37s
2024-12-27 19:25:19,865 - INFO - Extracting validation features...
2024-12-27 19:25:19,865 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:39,  3.51it/s]Extracting features:   2%|▏         | 3/139 [00:00<00:15,  8.92it/s]Extracting features:   5%|▌         | 7/139 [00:00<00:07, 18.45it/s]Extracting features:   9%|▉         | 13/139 [00:00<00:04, 30.60it/s]Extracting features:  14%|█▎        | 19/139 [00:00<00:03, 39.31it/s]Extracting features:  18%|█▊        | 25/139 [00:00<00:02, 44.83it/s]Extracting features:  22%|██▏       | 31/139 [00:00<00:02, 47.58it/s]Extracting features:  27%|██▋       | 37/139 [00:01<00:02, 48.77it/s]Extracting features:  31%|███       | 43/139 [00:01<00:02, 44.89it/s]Extracting features:  36%|███▌      | 50/139 [00:01<00:01, 49.90it/s]Extracting features:  41%|████      | 57/139 [00:01<00:01, 52.72it/s]Extracting features:  45%|████▌     | 63/139 [00:01<00:01, 53.41it/s]Extracting features:  50%|█████     | 70/139 [00:01<00:01, 56.50it/s]Extracting features:  55%|█████▍    | 76/139 [00:01<00:01, 54.45it/s]Extracting features:  59%|█████▉    | 82/139 [00:01<00:01, 54.44it/s]Extracting features:  63%|██████▎   | 88/139 [00:01<00:00, 54.25it/s]Extracting features:  68%|██████▊   | 94/139 [00:02<00:00, 54.01it/s]Extracting features:  72%|███████▏  | 100/139 [00:02<00:00, 54.22it/s]Extracting features:  76%|███████▋  | 106/139 [00:02<00:00, 51.51it/s]Extracting features:  81%|████████  | 112/139 [00:02<00:00, 53.34it/s]Extracting features:  86%|████████▌ | 119/139 [00:02<00:00, 56.81it/s]Extracting features:  90%|████████▉ | 125/139 [00:02<00:00, 56.72it/s]Extracting features:  94%|█████████▍| 131/139 [00:02<00:00, 56.68it/s]Extracting features:  99%|█████████▉| 138/139 [00:02<00:00, 59.88it/s]Extracting features: 100%|██████████| 139/139 [00:02<00:00, 46.44it/s]
2024-12-27 19:25:22,871 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 19:25:22,871 - INFO - Validation feature extraction completed in 3.01s
2024-12-27 19:25:22,871 - INFO - Extracting training features...
2024-12-27 19:25:22,871 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<02:25,  4.24it/s]Extracting features:   1%|          | 6/618 [00:00<00:30, 20.28it/s]Extracting features:   2%|▏         | 12/618 [00:00<00:19, 30.94it/s]Extracting features:   3%|▎         | 17/618 [00:00<00:16, 35.47it/s]Extracting features:   3%|▎         | 21/618 [00:00<00:16, 36.46it/s]Extracting features:   4%|▍         | 27/618 [00:00<00:14, 40.23it/s]Extracting features:   5%|▌         | 32/618 [00:00<00:14, 41.75it/s]Extracting features:   6%|▌         | 37/618 [00:01<00:14, 40.74it/s]Extracting features:   7%|▋         | 43/618 [00:01<00:12, 45.46it/s]Extracting features:   8%|▊         | 49/618 [00:01<00:12, 47.28it/s]Extracting features:   9%|▉         | 55/618 [00:01<00:11, 50.05it/s]Extracting features:  10%|▉         | 61/618 [00:01<00:10, 50.78it/s]Extracting features:  11%|█         | 67/618 [00:01<00:11, 49.03it/s]Extracting features:  12%|█▏        | 74/618 [00:01<00:10, 52.03it/s]Extracting features:  13%|█▎        | 80/618 [00:01<00:10, 52.29it/s]Extracting features:  14%|█▍        | 86/618 [00:01<00:10, 52.95it/s]Extracting features:  15%|█▍        | 92/618 [00:02<00:09, 54.23it/s]Extracting features:  16%|█▌        | 98/618 [00:02<00:09, 54.97it/s]Extracting features:  17%|█▋        | 104/618 [00:02<00:09, 55.54it/s]Extracting features:  18%|█▊        | 110/618 [00:02<00:09, 54.55it/s]Extracting features:  19%|█▉        | 117/618 [00:02<00:08, 56.84it/s]Extracting features:  20%|█▉        | 123/618 [00:02<00:08, 57.42it/s]Extracting features:  21%|██        | 130/618 [00:02<00:08, 57.59it/s]Extracting features:  22%|██▏       | 136/618 [00:02<00:08, 56.84it/s]Extracting features:  23%|██▎       | 143/618 [00:02<00:08, 58.78it/s]Extracting features:  24%|██▍       | 149/618 [00:03<00:08, 57.22it/s]Extracting features:  25%|██▌       | 155/618 [00:03<00:08, 56.67it/s]Extracting features:  26%|██▌       | 161/618 [00:03<00:08, 53.51it/s]Extracting features:  27%|██▋       | 167/618 [00:03<00:08, 55.24it/s]Extracting features:  28%|██▊       | 173/618 [00:03<00:08, 54.96it/s]Extracting features:  29%|██▉       | 180/618 [00:03<00:07, 56.83it/s]Extracting features:  30%|███       | 186/618 [00:03<00:07, 55.90it/s]Extracting features:  31%|███       | 192/618 [00:03<00:07, 56.25it/s]Extracting features:  32%|███▏      | 199/618 [00:03<00:07, 58.12it/s]Extracting features:  33%|███▎      | 205/618 [00:04<00:07, 57.07it/s]Extracting features:  34%|███▍      | 212/618 [00:04<00:06, 58.68it/s]Extracting features:  35%|███▌      | 218/618 [00:04<00:06, 57.96it/s]Extracting features:  36%|███▌      | 224/618 [00:04<00:06, 56.53it/s]Extracting features:  37%|███▋      | 231/618 [00:04<00:06, 58.56it/s]Extracting features:  38%|███▊      | 237/618 [00:04<00:06, 55.83it/s]Extracting features:  39%|███▉      | 243/618 [00:04<00:06, 56.04it/s]Extracting features:  40%|████      | 250/618 [00:04<00:06, 59.41it/s]Extracting features:  41%|████▏     | 256/618 [00:04<00:06, 58.30it/s]Extracting features:  42%|████▏     | 262/618 [00:05<00:06, 54.68it/s]Extracting features:  43%|████▎     | 268/618 [00:05<00:06, 56.07it/s]Extracting features:  44%|████▍     | 274/618 [00:05<00:06, 55.04it/s]Extracting features:  45%|████▌     | 280/618 [00:05<00:06, 54.03it/s]Extracting features:  46%|████▋     | 286/618 [00:05<00:06, 53.46it/s]Extracting features:  47%|████▋     | 293/618 [00:05<00:05, 55.30it/s]Extracting features:  48%|████▊     | 299/618 [00:05<00:05, 54.78it/s]Extracting features:  50%|████▉     | 306/618 [00:05<00:05, 57.11it/s]Extracting features:  50%|█████     | 312/618 [00:05<00:05, 55.49it/s]Extracting features:  51%|█████▏    | 318/618 [00:06<00:06, 45.07it/s]Extracting features:  52%|█████▏    | 324/618 [00:06<00:06, 47.19it/s]Extracting features:  53%|█████▎    | 330/618 [00:06<00:05, 49.52it/s]Extracting features:  55%|█████▍    | 337/618 [00:06<00:05, 52.35it/s]Extracting features:  56%|█████▌    | 343/618 [00:06<00:05, 51.46it/s]Extracting features:  56%|█████▋    | 349/618 [00:06<00:05, 47.30it/s]Extracting features:  57%|█████▋    | 355/618 [00:06<00:05, 49.60it/s]Extracting features:  58%|█████▊    | 361/618 [00:07<00:05, 49.46it/s]Extracting features:  59%|█████▉    | 367/618 [00:07<00:04, 50.75it/s]Extracting features:  60%|██████    | 373/618 [00:07<00:04, 53.18it/s]Extracting features:  61%|██████▏   | 380/618 [00:07<00:04, 57.47it/s]Extracting features:  62%|██████▏   | 386/618 [00:07<00:04, 56.07it/s]Extracting features:  63%|██████▎   | 392/618 [00:07<00:04, 55.44it/s]Extracting features:  64%|██████▍   | 398/618 [00:07<00:03, 56.47it/s]Extracting features:  65%|██████▌   | 404/618 [00:07<00:04, 49.48it/s]Extracting features:  66%|██████▋   | 410/618 [00:07<00:04, 48.23it/s]Extracting features:  67%|██████▋   | 416/618 [00:08<00:04, 50.20it/s]Extracting features:  68%|██████▊   | 422/618 [00:08<00:03, 52.71it/s]Extracting features:  69%|██████▉   | 428/618 [00:08<00:03, 52.47it/s]Extracting features:  70%|███████   | 434/618 [00:08<00:03, 50.73it/s]Extracting features:  71%|███████   | 440/618 [00:08<00:03, 51.68it/s]Extracting features:  72%|███████▏  | 446/618 [00:08<00:03, 52.34it/s]Extracting features:  73%|███████▎  | 452/618 [00:08<00:03, 52.34it/s]Extracting features:  74%|███████▍  | 458/618 [00:08<00:03, 48.14it/s]Extracting features:  75%|███████▍  | 463/618 [00:08<00:03, 48.45it/s]Extracting features:  76%|███████▌  | 468/618 [00:09<00:03, 47.63it/s]Extracting features:  77%|███████▋  | 474/618 [00:09<00:02, 50.49it/s]Extracting features:  78%|███████▊  | 480/618 [00:09<00:03, 45.12it/s]Extracting features:  78%|███████▊  | 485/618 [00:09<00:02, 44.59it/s]Extracting features:  79%|███████▉  | 491/618 [00:09<00:02, 47.33it/s]Extracting features:  80%|████████  | 497/618 [00:09<00:02, 49.87it/s]Extracting features:  81%|████████▏ | 503/618 [00:09<00:02, 52.19it/s]Extracting features:  82%|████████▏ | 509/618 [00:09<00:02, 46.79it/s]Extracting features:  83%|████████▎ | 515/618 [00:10<00:02, 49.37it/s]Extracting features:  84%|████████▍ | 522/618 [00:10<00:01, 53.32it/s]Extracting features:  85%|████████▌ | 528/618 [00:10<00:01, 51.61it/s]Extracting features:  87%|████████▋ | 535/618 [00:10<00:01, 54.83it/s]Extracting features:  88%|████████▊ | 542/618 [00:10<00:01, 57.07it/s]Extracting features:  89%|████████▊ | 548/618 [00:10<00:01, 55.43it/s]Extracting features:  90%|████████▉ | 554/618 [00:10<00:01, 55.59it/s]Extracting features:  91%|█████████ | 560/618 [00:10<00:01, 55.74it/s]Extracting features:  92%|█████████▏| 566/618 [00:10<00:00, 55.36it/s]Extracting features:  93%|█████████▎| 573/618 [00:11<00:00, 56.60it/s]Extracting features:  94%|█████████▍| 580/618 [00:11<00:00, 57.24it/s]Extracting features:  95%|█████████▍| 586/618 [00:11<00:00, 53.74it/s]Extracting features:  96%|█████████▌| 592/618 [00:11<00:00, 52.44it/s]Extracting features:  97%|█████████▋| 598/618 [00:11<00:00, 47.73it/s]Extracting features:  98%|█████████▊| 604/618 [00:11<00:00, 49.28it/s]Extracting features:  99%|█████████▊| 610/618 [00:11<00:00, 43.66it/s]Extracting features: 100%|█████████▉| 617/618 [00:11<00:00, 48.41it/s]Extracting features: 100%|██████████| 618/618 [00:12<00:00, 51.13it/s]
2024-12-27 19:25:34,994 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 19:25:34,995 - INFO - Training feature extraction completed in 12.12s
2024-12-27 19:25:34,995 - INFO - Creating model for classifier: SVM
2024-12-27 19:25:34,995 - INFO - Using device: cuda
2024-12-27 19:25:34,995 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-27 19:25:34,995 - INFO - 
Processing poison rate: 0.0
2024-12-27 19:25:34,995 - INFO - Training set processing completed in 0.00s
2024-12-27 19:25:34,995 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 19:25:34,996 - INFO - Memory usage at start_fit: CPU 2982.6 MB, GPU 47.3 MB
2024-12-27 19:25:34,996 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:25:34,998 - INFO - Number of unique classes: 43
2024-12-27 19:25:35,340 - INFO - Fitted scaler and transformed data
2024-12-27 19:25:35,341 - INFO - Scaling time: 0.34s
2024-12-27 19:25:36,364 - INFO - Epoch 1/25, Train Loss: 5.2399, Val Loss: 2.1394
2024-12-27 19:25:37,365 - INFO - Epoch 2/25, Train Loss: 0.9714, Val Loss: 1.7309
2024-12-27 19:25:38,417 - INFO - Epoch 3/25, Train Loss: 0.6182, Val Loss: 1.4534
2024-12-27 19:25:39,427 - INFO - Epoch 4/25, Train Loss: 0.4856, Val Loss: 1.4989
2024-12-27 19:25:40,505 - INFO - Epoch 5/25, Train Loss: 0.3874, Val Loss: 1.3684
2024-12-27 19:25:41,636 - INFO - Epoch 6/25, Train Loss: 0.3752, Val Loss: 1.6089
2024-12-27 19:25:42,844 - INFO - Epoch 7/25, Train Loss: 0.3415, Val Loss: 1.5371
2024-12-27 19:25:42,844 - INFO - Early stopping triggered at epoch 7
2024-12-27 19:25:42,844 - INFO - Training completed in 7.85s
2024-12-27 19:25:42,845 - INFO - Final memory usage: CPU 3085.9 MB, GPU 48.4 MB
2024-12-27 19:25:42,845 - INFO - Model training completed in 7.85s
2024-12-27 19:25:42,877 - INFO - Prediction completed in 0.03s
2024-12-27 19:25:42,891 - INFO - Poison rate 0.0 completed in 7.90s
2024-12-27 19:25:42,891 - INFO - 
Processing poison rate: 0.01
2024-12-27 19:25:42,897 - INFO - Total number of labels flipped: 197
2024-12-27 19:25:42,897 - INFO - Label flipping completed in 0.01s
2024-12-27 19:25:42,897 - INFO - Training set processing completed in 0.00s
2024-12-27 19:25:42,897 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 19:25:42,898 - INFO - Memory usage at start_fit: CPU 2989.5 MB, GPU 48.1 MB
2024-12-27 19:25:42,898 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:25:42,898 - INFO - Number of unique classes: 43
2024-12-27 19:25:43,275 - INFO - Fitted scaler and transformed data
2024-12-27 19:25:43,275 - INFO - Scaling time: 0.37s
2024-12-27 19:25:44,510 - INFO - Epoch 1/25, Train Loss: 7.2965, Val Loss: 5.2841
2024-12-27 19:25:45,825 - INFO - Epoch 2/25, Train Loss: 1.3632, Val Loss: 4.4250
2024-12-27 19:25:47,177 - INFO - Epoch 3/25, Train Loss: 0.7556, Val Loss: 4.2364
2024-12-27 19:25:48,477 - INFO - Epoch 4/25, Train Loss: 0.5661, Val Loss: 3.9813
2024-12-27 19:25:49,813 - INFO - Epoch 5/25, Train Loss: 0.4619, Val Loss: 4.3482
2024-12-27 19:25:51,154 - INFO - Epoch 6/25, Train Loss: 0.4267, Val Loss: 4.1449
2024-12-27 19:25:51,154 - INFO - Early stopping triggered at epoch 6
2024-12-27 19:25:51,155 - INFO - Training completed in 8.26s
2024-12-27 19:25:51,155 - INFO - Final memory usage: CPU 3089.1 MB, GPU 48.4 MB
2024-12-27 19:25:51,156 - INFO - Model training completed in 8.26s
2024-12-27 19:25:51,184 - INFO - Prediction completed in 0.03s
2024-12-27 19:25:51,205 - INFO - Poison rate 0.01 completed in 8.31s
2024-12-27 19:25:51,205 - INFO - 
Processing poison rate: 0.03
2024-12-27 19:25:51,218 - INFO - Total number of labels flipped: 592
2024-12-27 19:25:51,218 - INFO - Label flipping completed in 0.01s
2024-12-27 19:25:51,218 - INFO - Training set processing completed in 0.00s
2024-12-27 19:25:51,218 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 19:25:51,219 - INFO - Memory usage at start_fit: CPU 2992.7 MB, GPU 48.1 MB
2024-12-27 19:25:51,219 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:25:51,220 - INFO - Number of unique classes: 43
2024-12-27 19:25:51,559 - INFO - Fitted scaler and transformed data
2024-12-27 19:25:51,559 - INFO - Scaling time: 0.34s
2024-12-27 19:25:52,766 - INFO - Epoch 1/25, Train Loss: 11.0214, Val Loss: 9.5086
2024-12-27 19:25:53,959 - INFO - Epoch 2/25, Train Loss: 2.2269, Val Loss: 7.7347
2024-12-27 19:25:55,159 - INFO - Epoch 3/25, Train Loss: 1.0653, Val Loss: 7.2851
2024-12-27 19:25:56,363 - INFO - Epoch 4/25, Train Loss: 0.7572, Val Loss: 7.4675
2024-12-27 19:25:57,479 - INFO - Epoch 5/25, Train Loss: 0.6287, Val Loss: 7.3915
2024-12-27 19:25:57,479 - INFO - Early stopping triggered at epoch 5
2024-12-27 19:25:57,479 - INFO - Training completed in 6.26s
2024-12-27 19:25:57,480 - INFO - Final memory usage: CPU 3091.4 MB, GPU 48.4 MB
2024-12-27 19:25:57,480 - INFO - Model training completed in 6.26s
2024-12-27 19:25:57,509 - INFO - Prediction completed in 0.03s
2024-12-27 19:25:57,520 - INFO - Poison rate 0.03 completed in 6.31s
2024-12-27 19:25:57,520 - INFO - 
Processing poison rate: 0.05
2024-12-27 19:25:57,538 - INFO - Total number of labels flipped: 987
2024-12-27 19:25:57,539 - INFO - Label flipping completed in 0.02s
2024-12-27 19:25:57,539 - INFO - Training set processing completed in 0.00s
2024-12-27 19:25:57,539 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 19:25:57,540 - INFO - Memory usage at start_fit: CPU 2994.9 MB, GPU 48.1 MB
2024-12-27 19:25:57,540 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:25:57,541 - INFO - Number of unique classes: 43
2024-12-27 19:25:57,881 - INFO - Fitted scaler and transformed data
2024-12-27 19:25:57,882 - INFO - Scaling time: 0.34s
2024-12-27 19:25:59,006 - INFO - Epoch 1/25, Train Loss: 14.8903, Val Loss: 13.7055
2024-12-27 19:26:00,173 - INFO - Epoch 2/25, Train Loss: 3.2789, Val Loss: 11.9753
2024-12-27 19:26:01,580 - INFO - Epoch 3/25, Train Loss: 1.5273, Val Loss: 10.6262
2024-12-27 19:26:02,966 - INFO - Epoch 4/25, Train Loss: 0.9993, Val Loss: 10.3803
2024-12-27 19:26:04,289 - INFO - Epoch 5/25, Train Loss: 0.7871, Val Loss: 10.6049
2024-12-27 19:26:05,567 - INFO - Epoch 6/25, Train Loss: 0.6955, Val Loss: 10.5742
2024-12-27 19:26:05,567 - INFO - Early stopping triggered at epoch 6
2024-12-27 19:26:05,567 - INFO - Training completed in 8.03s
2024-12-27 19:26:05,567 - INFO - Final memory usage: CPU 3096.2 MB, GPU 48.4 MB
2024-12-27 19:26:05,568 - INFO - Model training completed in 8.03s
2024-12-27 19:26:05,598 - INFO - Prediction completed in 0.03s
2024-12-27 19:26:05,609 - INFO - Poison rate 0.05 completed in 8.09s
2024-12-27 19:26:05,609 - INFO - 
Processing poison rate: 0.07
2024-12-27 19:26:05,635 - INFO - Total number of labels flipped: 1382
2024-12-27 19:26:05,635 - INFO - Label flipping completed in 0.03s
2024-12-27 19:26:05,635 - INFO - Training set processing completed in 0.00s
2024-12-27 19:26:05,635 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 19:26:05,636 - INFO - Memory usage at start_fit: CPU 2999.7 MB, GPU 48.1 MB
2024-12-27 19:26:05,636 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:26:05,637 - INFO - Number of unique classes: 43
2024-12-27 19:26:06,017 - INFO - Fitted scaler and transformed data
2024-12-27 19:26:06,017 - INFO - Scaling time: 0.38s
2024-12-27 19:26:07,389 - INFO - Epoch 1/25, Train Loss: 18.1514, Val Loss: 15.1410
2024-12-27 19:26:08,780 - INFO - Epoch 2/25, Train Loss: 4.3161, Val Loss: 12.2968
2024-12-27 19:26:10,130 - INFO - Epoch 3/25, Train Loss: 1.9746, Val Loss: 11.5735
2024-12-27 19:26:11,456 - INFO - Epoch 4/25, Train Loss: 1.3077, Val Loss: 11.2759
2024-12-27 19:26:12,770 - INFO - Epoch 5/25, Train Loss: 1.0199, Val Loss: 11.4002
2024-12-27 19:26:14,144 - INFO - Epoch 6/25, Train Loss: 0.9029, Val Loss: 11.2562
2024-12-27 19:26:15,448 - INFO - Epoch 7/25, Train Loss: 0.8102, Val Loss: 11.3203
2024-12-27 19:26:16,769 - INFO - Epoch 8/25, Train Loss: 0.7998, Val Loss: 11.6352
2024-12-27 19:26:16,769 - INFO - Early stopping triggered at epoch 8
2024-12-27 19:26:16,769 - INFO - Training completed in 11.13s
2024-12-27 19:26:16,769 - INFO - Final memory usage: CPU 3099.6 MB, GPU 48.4 MB
2024-12-27 19:26:16,770 - INFO - Model training completed in 11.13s
2024-12-27 19:26:16,800 - INFO - Prediction completed in 0.03s
2024-12-27 19:26:16,815 - INFO - Poison rate 0.07 completed in 11.21s
2024-12-27 19:26:16,815 - INFO - 
Processing poison rate: 0.1
2024-12-27 19:26:16,850 - INFO - Total number of labels flipped: 1975
2024-12-27 19:26:16,851 - INFO - Label flipping completed in 0.04s
2024-12-27 19:26:16,851 - INFO - Training set processing completed in 0.00s
2024-12-27 19:26:16,851 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 19:26:16,852 - INFO - Memory usage at start_fit: CPU 3003.2 MB, GPU 48.1 MB
2024-12-27 19:26:16,852 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:26:16,853 - INFO - Number of unique classes: 43
2024-12-27 19:26:17,198 - INFO - Fitted scaler and transformed data
2024-12-27 19:26:17,198 - INFO - Scaling time: 0.34s
2024-12-27 19:26:18,373 - INFO - Epoch 1/25, Train Loss: 22.7086, Val Loss: 21.2290
2024-12-27 19:26:19,532 - INFO - Epoch 2/25, Train Loss: 5.8356, Val Loss: 17.8845
2024-12-27 19:26:20,736 - INFO - Epoch 3/25, Train Loss: 2.9158, Val Loss: 15.8101
2024-12-27 19:26:21,893 - INFO - Epoch 4/25, Train Loss: 1.8232, Val Loss: 15.0799
2024-12-27 19:26:23,045 - INFO - Epoch 5/25, Train Loss: 1.4477, Val Loss: 15.7479
2024-12-27 19:26:24,288 - INFO - Epoch 6/25, Train Loss: 1.2857, Val Loss: 15.3829
2024-12-27 19:26:24,288 - INFO - Early stopping triggered at epoch 6
2024-12-27 19:26:24,288 - INFO - Training completed in 7.44s
2024-12-27 19:26:24,288 - INFO - Final memory usage: CPU 3099.6 MB, GPU 48.4 MB
2024-12-27 19:26:24,289 - INFO - Model training completed in 7.44s
2024-12-27 19:26:24,336 - INFO - Prediction completed in 0.05s
2024-12-27 19:26:24,347 - INFO - Poison rate 0.1 completed in 7.53s
2024-12-27 19:26:24,347 - INFO - 
Processing poison rate: 0.2
2024-12-27 19:26:24,416 - INFO - Total number of labels flipped: 3951
2024-12-27 19:26:24,417 - INFO - Label flipping completed in 0.07s
2024-12-27 19:26:24,417 - INFO - Training set processing completed in 0.00s
2024-12-27 19:26:24,417 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 19:26:24,418 - INFO - Memory usage at start_fit: CPU 3003.2 MB, GPU 48.1 MB
2024-12-27 19:26:24,418 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:26:24,419 - INFO - Number of unique classes: 43
2024-12-27 19:26:24,774 - INFO - Fitted scaler and transformed data
2024-12-27 19:26:24,774 - INFO - Scaling time: 0.35s
2024-12-27 19:26:25,921 - INFO - Epoch 1/25, Train Loss: 36.5110, Val Loss: 32.1922
2024-12-27 19:26:27,078 - INFO - Epoch 2/25, Train Loss: 12.3577, Val Loss: 30.1378
2024-12-27 19:26:28,268 - INFO - Epoch 3/25, Train Loss: 7.1831, Val Loss: 28.8674
2024-12-27 19:26:29,454 - INFO - Epoch 4/25, Train Loss: 5.0484, Val Loss: 28.9128
2024-12-27 19:26:30,662 - INFO - Epoch 5/25, Train Loss: 3.9215, Val Loss: 28.4881
2024-12-27 19:26:31,934 - INFO - Epoch 6/25, Train Loss: 3.3910, Val Loss: 29.6179
2024-12-27 19:26:33,341 - INFO - Epoch 7/25, Train Loss: 3.0922, Val Loss: 29.2010
2024-12-27 19:26:33,341 - INFO - Early stopping triggered at epoch 7
2024-12-27 19:26:33,341 - INFO - Training completed in 8.92s
2024-12-27 19:26:33,341 - INFO - Final memory usage: CPU 3099.6 MB, GPU 48.4 MB
2024-12-27 19:26:33,342 - INFO - Model training completed in 8.93s
2024-12-27 19:26:33,371 - INFO - Prediction completed in 0.03s
2024-12-27 19:26:33,382 - INFO - Poison rate 0.2 completed in 9.04s
2024-12-27 19:26:33,384 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 19:26:33,384 - INFO - Total evaluation time: 90.89s
2024-12-27 19:26:33,390 - INFO - 
Progress: 27.1% - Evaluating GTSRB with SVM (dynadetect mode, iteration 1/1)
2024-12-27 19:26:33,449 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 19:26:33,521 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 19:26:33,608 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 19:26:33,608 - INFO - Dataset type: image
2024-12-27 19:26:33,608 - INFO - Sample size: 39209
2024-12-27 19:26:33,608 - INFO - Using device: cuda
2024-12-27 19:26:33,609 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 19:26:33,611 - INFO - Loading datasets...
2024-12-27 19:26:50,634 - INFO - Dataset loading completed in 17.02s
2024-12-27 19:26:50,634 - INFO - Extracting validation features...
2024-12-27 19:26:50,634 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:35,  3.91it/s]Extracting features:   2%|▏         | 3/139 [00:00<00:15,  8.57it/s]Extracting features:   5%|▌         | 7/139 [00:00<00:07, 16.93it/s]Extracting features:  10%|█         | 14/139 [00:00<00:03, 31.28it/s]Extracting features:  15%|█▌        | 21/139 [00:00<00:02, 41.95it/s]Extracting features:  20%|██        | 28/139 [00:00<00:02, 48.66it/s]Extracting features:  25%|██▌       | 35/139 [00:00<00:01, 54.03it/s]Extracting features:  30%|███       | 42/139 [00:01<00:01, 57.56it/s]Extracting features:  35%|███▌      | 49/139 [00:01<00:01, 58.36it/s]Extracting features:  40%|████      | 56/139 [00:01<00:01, 60.79it/s]Extracting features:  45%|████▌     | 63/139 [00:01<00:01, 55.25it/s]Extracting features:  50%|████▉     | 69/139 [00:01<00:01, 54.95it/s]Extracting features:  55%|█████▍    | 76/139 [00:01<00:01, 57.23it/s]Extracting features:  59%|█████▉    | 82/139 [00:01<00:00, 57.73it/s]Extracting features:  63%|██████▎   | 88/139 [00:01<00:00, 56.76it/s]Extracting features:  68%|██████▊   | 95/139 [00:01<00:00, 57.55it/s]Extracting features:  73%|███████▎  | 101/139 [00:02<00:00, 56.98it/s]Extracting features:  77%|███████▋  | 107/139 [00:02<00:00, 57.19it/s]Extracting features:  81%|████████▏ | 113/139 [00:02<00:00, 57.23it/s]Extracting features:  86%|████████▌ | 119/139 [00:02<00:00, 57.37it/s]Extracting features:  90%|████████▉ | 125/139 [00:02<00:00, 55.78it/s]Extracting features:  95%|█████████▍| 132/139 [00:02<00:00, 59.24it/s]Extracting features: 100%|██████████| 139/139 [00:02<00:00, 50.04it/s]
2024-12-27 19:26:53,422 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 19:26:53,423 - INFO - Validation feature extraction completed in 2.79s
2024-12-27 19:26:53,423 - INFO - Extracting training features...
2024-12-27 19:26:53,423 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<02:29,  4.12it/s]Extracting features:   1%|          | 7/618 [00:00<00:25, 23.78it/s]Extracting features:   2%|▏         | 14/618 [00:00<00:15, 38.45it/s]Extracting features:   3%|▎         | 20/618 [00:00<00:13, 45.27it/s]Extracting features:   4%|▍         | 26/618 [00:00<00:12, 48.94it/s]Extracting features:   5%|▌         | 32/618 [00:00<00:11, 52.01it/s]Extracting features:   6%|▌         | 38/618 [00:00<00:11, 49.62it/s]Extracting features:   7%|▋         | 44/618 [00:01<00:11, 51.40it/s]Extracting features:   8%|▊         | 50/618 [00:01<00:10, 53.53it/s]Extracting features:   9%|▉         | 57/618 [00:01<00:10, 54.84it/s]Extracting features:  10%|█         | 64/618 [00:01<00:09, 55.57it/s]Extracting features:  11%|█▏        | 70/618 [00:01<00:09, 55.54it/s]Extracting features:  12%|█▏        | 76/618 [00:01<00:09, 56.31it/s]Extracting features:  13%|█▎        | 82/618 [00:01<00:09, 55.91it/s]Extracting features:  14%|█▍        | 88/618 [00:01<00:09, 55.54it/s]Extracting features:  15%|█▌        | 94/618 [00:01<00:09, 54.58it/s]Extracting features:  16%|█▌        | 100/618 [00:02<00:09, 53.51it/s]Extracting features:  17%|█▋        | 107/618 [00:02<00:09, 54.65it/s]Extracting features:  18%|█▊        | 113/618 [00:02<00:09, 55.15it/s]Extracting features:  19%|█▉        | 119/618 [00:02<00:09, 55.34it/s]Extracting features:  20%|██        | 125/618 [00:02<00:08, 55.35it/s]Extracting features:  21%|██        | 131/618 [00:02<00:09, 52.08it/s]Extracting features:  22%|██▏       | 137/618 [00:02<00:09, 50.09it/s]Extracting features:  23%|██▎       | 143/618 [00:02<00:09, 52.21it/s]Extracting features:  24%|██▍       | 149/618 [00:02<00:08, 53.76it/s]Extracting features:  25%|██▌       | 156/618 [00:03<00:08, 55.04it/s]Extracting features:  26%|██▌       | 162/618 [00:03<00:08, 53.93it/s]Extracting features:  27%|██▋       | 168/618 [00:03<00:08, 53.51it/s]Extracting features:  28%|██▊       | 176/618 [00:03<00:07, 58.40it/s]Extracting features:  29%|██▉       | 182/618 [00:03<00:07, 55.84it/s]Extracting features:  30%|███       | 188/618 [00:03<00:07, 55.04it/s]Extracting features:  31%|███▏      | 194/618 [00:03<00:07, 55.90it/s]Extracting features:  32%|███▏      | 200/618 [00:03<00:07, 56.92it/s]Extracting features:  33%|███▎      | 207/618 [00:03<00:06, 59.35it/s]Extracting features:  35%|███▍      | 214/618 [00:04<00:06, 61.01it/s]Extracting features:  36%|███▌      | 221/618 [00:04<00:07, 56.02it/s]Extracting features:  37%|███▋      | 227/618 [00:04<00:06, 56.16it/s]Extracting features:  38%|███▊      | 233/618 [00:04<00:06, 56.95it/s]Extracting features:  39%|███▊      | 239/618 [00:04<00:06, 55.80it/s]Extracting features:  40%|███▉      | 246/618 [00:04<00:06, 57.54it/s]Extracting features:  41%|████      | 253/618 [00:04<00:06, 58.58it/s]Extracting features:  42%|████▏     | 259/618 [00:04<00:06, 57.77it/s]Extracting features:  43%|████▎     | 265/618 [00:04<00:06, 54.18it/s]Extracting features:  44%|████▍     | 271/618 [00:05<00:07, 49.33it/s]Extracting features:  45%|████▍     | 277/618 [00:05<00:06, 49.79it/s]Extracting features:  46%|████▌     | 283/618 [00:05<00:06, 50.97it/s]Extracting features:  47%|████▋     | 289/618 [00:05<00:06, 51.66it/s]Extracting features:  48%|████▊     | 295/618 [00:05<00:06, 53.71it/s]Extracting features:  49%|████▊     | 301/618 [00:05<00:05, 54.01it/s]Extracting features:  50%|████▉     | 307/618 [00:05<00:06, 49.06it/s]Extracting features:  51%|█████     | 314/618 [00:05<00:05, 51.18it/s]Extracting features:  52%|█████▏    | 320/618 [00:06<00:05, 52.85it/s]Extracting features:  53%|█████▎    | 327/618 [00:06<00:05, 56.96it/s]Extracting features:  54%|█████▍    | 333/618 [00:06<00:05, 56.82it/s]Extracting features:  55%|█████▍    | 339/618 [00:06<00:05, 55.57it/s]Extracting features:  56%|█████▌    | 345/618 [00:06<00:05, 53.04it/s]Extracting features:  57%|█████▋    | 351/618 [00:06<00:05, 48.16it/s]Extracting features:  58%|█████▊    | 357/618 [00:06<00:05, 51.10it/s]Extracting features:  59%|█████▉    | 364/618 [00:06<00:04, 53.40it/s]Extracting features:  60%|██████    | 371/618 [00:06<00:04, 56.29it/s]Extracting features:  61%|██████    | 377/618 [00:07<00:04, 52.98it/s]Extracting features:  62%|██████▏   | 383/618 [00:07<00:04, 51.73it/s]Extracting features:  63%|██████▎   | 389/618 [00:07<00:04, 50.90it/s]Extracting features:  64%|██████▍   | 396/618 [00:07<00:03, 55.74it/s]Extracting features:  65%|██████▌   | 402/618 [00:07<00:03, 55.27it/s]Extracting features:  66%|██████▌   | 408/618 [00:07<00:03, 52.83it/s]Extracting features:  67%|██████▋   | 414/618 [00:07<00:03, 54.73it/s]Extracting features:  68%|██████▊   | 421/618 [00:07<00:03, 56.23it/s]Extracting features:  69%|██████▉   | 428/618 [00:08<00:03, 58.53it/s]Extracting features:  70%|███████   | 434/618 [00:08<00:03, 57.58it/s]Extracting features:  71%|███████   | 440/618 [00:08<00:03, 58.01it/s]Extracting features:  72%|███████▏  | 446/618 [00:08<00:03, 54.45it/s]Extracting features:  73%|███████▎  | 453/618 [00:08<00:02, 56.80it/s]Extracting features:  74%|███████▍  | 459/618 [00:08<00:02, 57.41it/s]Extracting features:  75%|███████▌  | 465/618 [00:08<00:02, 56.19it/s]Extracting features:  76%|███████▌  | 471/618 [00:08<00:02, 53.90it/s]Extracting features:  77%|███████▋  | 478/618 [00:08<00:02, 56.36it/s]Extracting features:  78%|███████▊  | 484/618 [00:09<00:02, 56.26it/s]Extracting features:  79%|███████▉  | 490/618 [00:09<00:02, 52.06it/s]Extracting features:  80%|████████  | 496/618 [00:09<00:02, 41.85it/s]Extracting features:  81%|████████  | 502/618 [00:09<00:02, 44.79it/s]Extracting features:  82%|████████▏ | 508/618 [00:09<00:02, 48.14it/s]Extracting features:  83%|████████▎ | 514/618 [00:09<00:02, 50.32it/s]Extracting features:  84%|████████▍ | 520/618 [00:09<00:01, 51.70it/s]Extracting features:  85%|████████▌ | 527/618 [00:09<00:01, 55.19it/s]Extracting features:  86%|████████▌ | 533/618 [00:10<00:01, 54.64it/s]Extracting features:  87%|████████▋ | 539/618 [00:10<00:01, 55.33it/s]Extracting features:  88%|████████▊ | 545/618 [00:10<00:01, 55.38it/s]Extracting features:  89%|████████▉ | 551/618 [00:10<00:01, 53.90it/s]Extracting features:  90%|█████████ | 557/618 [00:10<00:01, 53.69it/s]Extracting features:  91%|█████████▏| 564/618 [00:10<00:00, 56.67it/s]Extracting features:  92%|█████████▏| 570/618 [00:10<00:00, 56.17it/s]Extracting features:  93%|█████████▎| 576/618 [00:10<00:00, 56.60it/s]Extracting features:  94%|█████████▍| 583/618 [00:10<00:00, 57.01it/s]Extracting features:  95%|█████████▌| 589/618 [00:11<00:00, 56.65it/s]Extracting features:  96%|█████████▋| 595/618 [00:11<00:00, 51.86it/s]Extracting features:  97%|█████████▋| 602/618 [00:11<00:00, 55.15it/s]Extracting features:  99%|█████████▊| 609/618 [00:11<00:00, 57.74it/s]Extracting features: 100%|█████████▉| 615/618 [00:11<00:00, 57.89it/s]Extracting features: 100%|██████████| 618/618 [00:11<00:00, 53.14it/s]
2024-12-27 19:27:05,093 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 19:27:05,093 - INFO - Training feature extraction completed in 11.67s
2024-12-27 19:27:05,093 - INFO - Creating model for classifier: SVM
2024-12-27 19:27:05,093 - INFO - Using device: cuda
2024-12-27 19:27:05,093 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-27 19:27:05,093 - INFO - 
Processing poison rate: 0.0
2024-12-27 19:27:05,094 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:27:05,094 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:27:06,952 - INFO - Feature scaling completed in 1.86s
2024-12-27 19:27:06,952 - INFO - Starting feature selection (k=50)
2024-12-27 19:27:06,969 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 19:27:06,970 - INFO - Starting anomaly detection
2024-12-27 19:27:13,155 - INFO - Anomaly detection completed in 6.18s
2024-12-27 19:27:13,155 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:27:13,155 - INFO - Total fit_transform time: 8.06s
2024-12-27 19:27:13,155 - INFO - Training set processing completed in 8.06s
2024-12-27 19:27:13,155 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 19:27:13,157 - INFO - Memory usage at start_fit: CPU 3000.8 MB, GPU 47.3 MB
2024-12-27 19:27:13,157 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:27:13,160 - INFO - Number of unique classes: 43
2024-12-27 19:27:13,514 - INFO - Fitted scaler and transformed data
2024-12-27 19:27:13,515 - INFO - Scaling time: 0.35s
2024-12-27 19:27:14,646 - INFO - Epoch 1/25, Train Loss: 5.0945, Val Loss: 2.2005
2024-12-27 19:27:15,834 - INFO - Epoch 2/25, Train Loss: 0.9244, Val Loss: 1.5032
2024-12-27 19:27:17,082 - INFO - Epoch 3/25, Train Loss: 0.5118, Val Loss: 1.3216
2024-12-27 19:27:18,292 - INFO - Epoch 4/25, Train Loss: 0.4396, Val Loss: 1.3430
2024-12-27 19:27:19,446 - INFO - Epoch 5/25, Train Loss: 0.3538, Val Loss: 1.2866
2024-12-27 19:27:20,603 - INFO - Epoch 6/25, Train Loss: 0.3174, Val Loss: 1.3014
2024-12-27 19:27:21,801 - INFO - Epoch 7/25, Train Loss: 0.3123, Val Loss: 1.2647
2024-12-27 19:27:22,925 - INFO - Epoch 8/25, Train Loss: 0.2997, Val Loss: 1.4278
2024-12-27 19:27:24,089 - INFO - Epoch 9/25, Train Loss: 0.2884, Val Loss: 1.5030
2024-12-27 19:27:24,089 - INFO - Early stopping triggered at epoch 9
2024-12-27 19:27:24,090 - INFO - Training completed in 10.93s
2024-12-27 19:27:24,090 - INFO - Final memory usage: CPU 3102.7 MB, GPU 48.4 MB
2024-12-27 19:27:24,091 - INFO - Model training completed in 10.94s
2024-12-27 19:27:24,121 - INFO - Prediction completed in 0.03s
2024-12-27 19:27:24,132 - INFO - Poison rate 0.0 completed in 19.04s
2024-12-27 19:27:24,132 - INFO - 
Processing poison rate: 0.01
2024-12-27 19:27:24,137 - INFO - Total number of labels flipped: 197
2024-12-27 19:27:24,138 - INFO - Label flipping completed in 0.01s
2024-12-27 19:27:24,138 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:27:24,138 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:27:26,001 - INFO - Feature scaling completed in 1.86s
2024-12-27 19:27:26,001 - INFO - Starting feature selection (k=50)
2024-12-27 19:27:26,052 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 19:27:26,052 - INFO - Starting anomaly detection
2024-12-27 19:27:34,218 - INFO - Anomaly detection completed in 8.17s
2024-12-27 19:27:34,218 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:27:34,218 - INFO - Total fit_transform time: 10.08s
2024-12-27 19:27:34,218 - INFO - Training set processing completed in 10.08s
2024-12-27 19:27:34,218 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 19:27:34,220 - INFO - Memory usage at start_fit: CPU 3006.2 MB, GPU 48.1 MB
2024-12-27 19:27:34,220 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:27:34,222 - INFO - Number of unique classes: 43
2024-12-27 19:27:34,552 - INFO - Fitted scaler and transformed data
2024-12-27 19:27:34,553 - INFO - Scaling time: 0.33s
2024-12-27 19:27:35,570 - INFO - Epoch 1/25, Train Loss: 7.1018, Val Loss: 3.8436
2024-12-27 19:27:36,594 - INFO - Epoch 2/25, Train Loss: 1.3718, Val Loss: 2.8287
2024-12-27 19:27:37,627 - INFO - Epoch 3/25, Train Loss: 0.6644, Val Loss: 2.7857
2024-12-27 19:27:38,779 - INFO - Epoch 4/25, Train Loss: 0.5098, Val Loss: 2.5009
2024-12-27 19:27:39,854 - INFO - Epoch 5/25, Train Loss: 0.3929, Val Loss: 2.6112
2024-12-27 19:27:40,883 - INFO - Epoch 6/25, Train Loss: 0.3655, Val Loss: 2.6914
2024-12-27 19:27:40,883 - INFO - Early stopping triggered at epoch 6
2024-12-27 19:27:40,884 - INFO - Training completed in 6.66s
2024-12-27 19:27:40,884 - INFO - Final memory usage: CPU 3102.7 MB, GPU 48.4 MB
2024-12-27 19:27:40,885 - INFO - Model training completed in 6.67s
2024-12-27 19:27:40,914 - INFO - Prediction completed in 0.03s
2024-12-27 19:27:40,925 - INFO - Poison rate 0.01 completed in 16.79s
2024-12-27 19:27:40,925 - INFO - 
Processing poison rate: 0.03
2024-12-27 19:27:40,937 - INFO - Total number of labels flipped: 592
2024-12-27 19:27:40,937 - INFO - Label flipping completed in 0.01s
2024-12-27 19:27:40,937 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:27:40,937 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:27:42,779 - INFO - Feature scaling completed in 1.84s
2024-12-27 19:27:42,779 - INFO - Starting feature selection (k=50)
2024-12-27 19:27:42,829 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 19:27:42,830 - INFO - Starting anomaly detection
2024-12-27 19:27:48,714 - INFO - Anomaly detection completed in 5.88s
2024-12-27 19:27:48,714 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:27:48,714 - INFO - Total fit_transform time: 7.78s
2024-12-27 19:27:48,714 - INFO - Training set processing completed in 7.78s
2024-12-27 19:27:48,715 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 19:27:48,715 - INFO - Memory usage at start_fit: CPU 3006.2 MB, GPU 48.1 MB
2024-12-27 19:27:48,716 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:27:48,716 - INFO - Number of unique classes: 43
2024-12-27 19:27:49,051 - INFO - Fitted scaler and transformed data
2024-12-27 19:27:49,052 - INFO - Scaling time: 0.33s
2024-12-27 19:27:50,136 - INFO - Epoch 1/25, Train Loss: 10.7948, Val Loss: 9.3740
2024-12-27 19:27:51,252 - INFO - Epoch 2/25, Train Loss: 2.2099, Val Loss: 6.9583
2024-12-27 19:27:52,445 - INFO - Epoch 3/25, Train Loss: 1.0064, Val Loss: 6.5369
2024-12-27 19:27:53,672 - INFO - Epoch 4/25, Train Loss: 0.6537, Val Loss: 6.6331
2024-12-27 19:27:54,994 - INFO - Epoch 5/25, Train Loss: 0.5263, Val Loss: 6.6539
2024-12-27 19:27:54,995 - INFO - Early stopping triggered at epoch 5
2024-12-27 19:27:54,995 - INFO - Training completed in 6.28s
2024-12-27 19:27:54,995 - INFO - Final memory usage: CPU 3102.7 MB, GPU 48.4 MB
2024-12-27 19:27:54,996 - INFO - Model training completed in 6.28s
2024-12-27 19:27:55,026 - INFO - Prediction completed in 0.03s
2024-12-27 19:27:55,037 - INFO - Poison rate 0.03 completed in 14.11s
2024-12-27 19:27:55,037 - INFO - 
Processing poison rate: 0.05
2024-12-27 19:27:55,057 - INFO - Total number of labels flipped: 987
2024-12-27 19:27:55,058 - INFO - Label flipping completed in 0.02s
2024-12-27 19:27:55,058 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:27:55,058 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:27:56,949 - INFO - Feature scaling completed in 1.89s
2024-12-27 19:27:56,950 - INFO - Starting feature selection (k=50)
2024-12-27 19:27:57,000 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 19:27:57,000 - INFO - Starting anomaly detection
2024-12-27 19:28:04,732 - INFO - Anomaly detection completed in 7.73s
2024-12-27 19:28:04,732 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:28:04,732 - INFO - Total fit_transform time: 9.67s
2024-12-27 19:28:04,733 - INFO - Training set processing completed in 9.68s
2024-12-27 19:28:04,733 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 19:28:04,734 - INFO - Memory usage at start_fit: CPU 3006.2 MB, GPU 48.1 MB
2024-12-27 19:28:04,734 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:28:04,735 - INFO - Number of unique classes: 43
2024-12-27 19:28:05,101 - INFO - Fitted scaler and transformed data
2024-12-27 19:28:05,102 - INFO - Scaling time: 0.37s
2024-12-27 19:28:06,179 - INFO - Epoch 1/25, Train Loss: 13.6225, Val Loss: 13.0209
2024-12-27 19:28:07,318 - INFO - Epoch 2/25, Train Loss: 3.1693, Val Loss: 11.3655
2024-12-27 19:28:08,473 - INFO - Epoch 3/25, Train Loss: 1.4092, Val Loss: 10.4790
2024-12-27 19:28:09,756 - INFO - Epoch 4/25, Train Loss: 0.8961, Val Loss: 10.2383
2024-12-27 19:28:11,075 - INFO - Epoch 5/25, Train Loss: 0.7072, Val Loss: 10.2710
2024-12-27 19:28:12,393 - INFO - Epoch 6/25, Train Loss: 0.6381, Val Loss: 10.1486
2024-12-27 19:28:13,706 - INFO - Epoch 7/25, Train Loss: 0.6061, Val Loss: 10.0205
2024-12-27 19:28:14,969 - INFO - Epoch 8/25, Train Loss: 0.5650, Val Loss: 10.3448
2024-12-27 19:28:16,348 - INFO - Epoch 9/25, Train Loss: 0.5975, Val Loss: 10.0223
2024-12-27 19:28:16,348 - INFO - Early stopping triggered at epoch 9
2024-12-27 19:28:16,348 - INFO - Training completed in 11.61s
2024-12-27 19:28:16,349 - INFO - Final memory usage: CPU 3104.0 MB, GPU 48.4 MB
2024-12-27 19:28:16,349 - INFO - Model training completed in 11.62s
2024-12-27 19:28:16,380 - INFO - Prediction completed in 0.03s
2024-12-27 19:28:16,391 - INFO - Poison rate 0.05 completed in 21.35s
2024-12-27 19:28:16,391 - INFO - 
Processing poison rate: 0.07
2024-12-27 19:28:16,416 - INFO - Total number of labels flipped: 1382
2024-12-27 19:28:16,417 - INFO - Label flipping completed in 0.03s
2024-12-27 19:28:16,417 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:28:16,417 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:28:18,234 - INFO - Feature scaling completed in 1.82s
2024-12-27 19:28:18,234 - INFO - Starting feature selection (k=50)
2024-12-27 19:28:18,285 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 19:28:18,285 - INFO - Starting anomaly detection
2024-12-27 19:28:26,069 - INFO - Anomaly detection completed in 7.78s
2024-12-27 19:28:26,070 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:28:26,070 - INFO - Total fit_transform time: 9.65s
2024-12-27 19:28:26,070 - INFO - Training set processing completed in 9.65s
2024-12-27 19:28:26,071 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 19:28:26,072 - INFO - Memory usage at start_fit: CPU 3007.5 MB, GPU 48.1 MB
2024-12-27 19:28:26,072 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:28:26,073 - INFO - Number of unique classes: 43
2024-12-27 19:28:26,412 - INFO - Fitted scaler and transformed data
2024-12-27 19:28:26,412 - INFO - Scaling time: 0.34s
2024-12-27 19:28:27,525 - INFO - Epoch 1/25, Train Loss: 16.9821, Val Loss: 17.2812
2024-12-27 19:28:28,791 - INFO - Epoch 2/25, Train Loss: 4.1535, Val Loss: 14.2279
2024-12-27 19:28:30,156 - INFO - Epoch 3/25, Train Loss: 1.8359, Val Loss: 12.6701
2024-12-27 19:28:31,407 - INFO - Epoch 4/25, Train Loss: 1.1805, Val Loss: 12.4246
2024-12-27 19:28:32,682 - INFO - Epoch 5/25, Train Loss: 0.9144, Val Loss: 11.7417
2024-12-27 19:28:33,930 - INFO - Epoch 6/25, Train Loss: 0.8060, Val Loss: 11.7513
2024-12-27 19:28:35,260 - INFO - Epoch 7/25, Train Loss: 0.7783, Val Loss: 11.6441
2024-12-27 19:28:36,617 - INFO - Epoch 8/25, Train Loss: 0.7753, Val Loss: 12.7607
2024-12-27 19:28:37,834 - INFO - Epoch 9/25, Train Loss: 0.7082, Val Loss: 13.0769
2024-12-27 19:28:37,835 - INFO - Early stopping triggered at epoch 9
2024-12-27 19:28:37,835 - INFO - Training completed in 11.76s
2024-12-27 19:28:37,835 - INFO - Final memory usage: CPU 3104.3 MB, GPU 48.4 MB
2024-12-27 19:28:37,836 - INFO - Model training completed in 11.76s
2024-12-27 19:28:37,866 - INFO - Prediction completed in 0.03s
2024-12-27 19:28:37,878 - INFO - Poison rate 0.07 completed in 21.49s
2024-12-27 19:28:37,878 - INFO - 
Processing poison rate: 0.1
2024-12-27 19:28:37,913 - INFO - Total number of labels flipped: 1975
2024-12-27 19:28:37,913 - INFO - Label flipping completed in 0.04s
2024-12-27 19:28:37,913 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:28:37,913 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:28:39,772 - INFO - Feature scaling completed in 1.86s
2024-12-27 19:28:39,773 - INFO - Starting feature selection (k=50)
2024-12-27 19:28:39,823 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 19:28:39,824 - INFO - Starting anomaly detection
2024-12-27 19:28:46,963 - INFO - Anomaly detection completed in 7.14s
2024-12-27 19:28:46,963 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:28:46,964 - INFO - Total fit_transform time: 9.05s
2024-12-27 19:28:46,964 - INFO - Training set processing completed in 9.05s
2024-12-27 19:28:46,964 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 19:28:46,965 - INFO - Memory usage at start_fit: CPU 3007.9 MB, GPU 48.1 MB
2024-12-27 19:28:46,965 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:28:46,966 - INFO - Number of unique classes: 43
2024-12-27 19:28:47,329 - INFO - Fitted scaler and transformed data
2024-12-27 19:28:47,329 - INFO - Scaling time: 0.36s
2024-12-27 19:28:48,449 - INFO - Epoch 1/25, Train Loss: 21.9429, Val Loss: 19.2140
2024-12-27 19:28:49,647 - INFO - Epoch 2/25, Train Loss: 5.3963, Val Loss: 17.4077
2024-12-27 19:28:50,862 - INFO - Epoch 3/25, Train Loss: 2.6747, Val Loss: 16.0928
2024-12-27 19:28:52,140 - INFO - Epoch 4/25, Train Loss: 1.7689, Val Loss: 15.7319
2024-12-27 19:28:53,439 - INFO - Epoch 5/25, Train Loss: 1.3203, Val Loss: 15.2434
2024-12-27 19:28:54,671 - INFO - Epoch 6/25, Train Loss: 1.1271, Val Loss: 15.3635
2024-12-27 19:28:55,819 - INFO - Epoch 7/25, Train Loss: 1.0832, Val Loss: 15.3137
2024-12-27 19:28:55,820 - INFO - Early stopping triggered at epoch 7
2024-12-27 19:28:55,820 - INFO - Training completed in 8.86s
2024-12-27 19:28:55,820 - INFO - Final memory usage: CPU 3106.6 MB, GPU 48.4 MB
2024-12-27 19:28:55,821 - INFO - Model training completed in 8.86s
2024-12-27 19:28:55,858 - INFO - Prediction completed in 0.04s
2024-12-27 19:28:55,869 - INFO - Poison rate 0.1 completed in 17.99s
2024-12-27 19:28:55,869 - INFO - 
Processing poison rate: 0.2
2024-12-27 19:28:55,939 - INFO - Total number of labels flipped: 3951
2024-12-27 19:28:55,940 - INFO - Label flipping completed in 0.07s
2024-12-27 19:28:55,940 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:28:55,940 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:28:57,762 - INFO - Feature scaling completed in 1.82s
2024-12-27 19:28:57,763 - INFO - Starting feature selection (k=50)
2024-12-27 19:28:57,813 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 19:28:57,814 - INFO - Starting anomaly detection
2024-12-27 19:29:05,746 - INFO - Anomaly detection completed in 7.93s
2024-12-27 19:29:05,746 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:29:05,746 - INFO - Total fit_transform time: 9.81s
2024-12-27 19:29:05,746 - INFO - Training set processing completed in 9.81s
2024-12-27 19:29:05,747 - INFO - Fitting SVMWrapper model with data shape: (19755, 1280)
2024-12-27 19:29:05,747 - INFO - Memory usage at start_fit: CPU 3010.2 MB, GPU 48.1 MB
2024-12-27 19:29:05,748 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:29:05,749 - INFO - Number of unique classes: 43
2024-12-27 19:29:06,089 - INFO - Fitted scaler and transformed data
2024-12-27 19:29:06,089 - INFO - Scaling time: 0.34s
2024-12-27 19:29:07,265 - INFO - Epoch 1/25, Train Loss: 33.9232, Val Loss: 34.8743
2024-12-27 19:29:08,429 - INFO - Epoch 2/25, Train Loss: 11.1586, Val Loss: 32.2465
2024-12-27 19:29:09,589 - INFO - Epoch 3/25, Train Loss: 6.4147, Val Loss: 32.4552
2024-12-27 19:29:10,865 - INFO - Epoch 4/25, Train Loss: 4.6104, Val Loss: 32.7338
2024-12-27 19:29:10,865 - INFO - Early stopping triggered at epoch 4
2024-12-27 19:29:10,865 - INFO - Training completed in 5.12s
2024-12-27 19:29:10,866 - INFO - Final memory usage: CPU 3106.6 MB, GPU 48.4 MB
2024-12-27 19:29:10,866 - INFO - Model training completed in 5.12s
2024-12-27 19:29:10,910 - INFO - Prediction completed in 0.04s
2024-12-27 19:29:10,921 - INFO - Poison rate 0.2 completed in 15.05s
2024-12-27 19:29:10,922 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 19:29:10,923 - INFO - Total evaluation time: 157.31s
2024-12-27 19:29:10,929 - INFO - 
Progress: 28.1% - Evaluating GTSRB with LogisticRegression (standard mode, iteration 1/1)
2024-12-27 19:29:10,991 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 19:29:11,068 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 19:29:11,165 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 19:29:11,165 - INFO - Dataset type: image
2024-12-27 19:29:11,165 - INFO - Sample size: 39209
2024-12-27 19:29:11,165 - INFO - Using device: cuda
2024-12-27 19:29:11,165 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 19:29:11,167 - INFO - Loading datasets...
2024-12-27 19:29:28,806 - INFO - Dataset loading completed in 17.64s
2024-12-27 19:29:28,806 - INFO - Extracting validation features...
2024-12-27 19:29:28,806 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:30,  4.59it/s]Extracting features:   1%|▏         | 2/139 [00:00<00:20,  6.61it/s]Extracting features:   3%|▎         | 4/139 [00:00<00:12, 11.16it/s]Extracting features:   6%|▌         | 8/139 [00:00<00:06, 20.43it/s]Extracting features:   9%|▉         | 13/139 [00:00<00:04, 28.40it/s]Extracting features:  14%|█▎        | 19/139 [00:00<00:03, 36.61it/s]Extracting features:  18%|█▊        | 25/139 [00:00<00:02, 42.70it/s]Extracting features:  22%|██▏       | 31/139 [00:00<00:02, 44.70it/s]Extracting features:  26%|██▌       | 36/139 [00:01<00:02, 45.60it/s]Extracting features:  30%|███       | 42/139 [00:01<00:02, 47.53it/s]Extracting features:  35%|███▌      | 49/139 [00:01<00:01, 52.79it/s]Extracting features:  40%|███▉      | 55/139 [00:01<00:01, 54.42it/s]Extracting features:  44%|████▍     | 61/139 [00:01<00:01, 52.45it/s]Extracting features:  48%|████▊     | 67/139 [00:01<00:01, 48.96it/s]Extracting features:  52%|█████▏    | 72/139 [00:01<00:01, 45.06it/s]Extracting features:  55%|█████▌    | 77/139 [00:01<00:01, 41.12it/s]Extracting features:  59%|█████▉    | 82/139 [00:02<00:01, 40.75it/s]Extracting features:  63%|██████▎   | 88/139 [00:02<00:01, 44.68it/s]Extracting features:  68%|██████▊   | 94/139 [00:02<00:00, 47.90it/s]Extracting features:  72%|███████▏  | 100/139 [00:02<00:00, 50.77it/s]Extracting features:  76%|███████▋  | 106/139 [00:02<00:00, 50.63it/s]Extracting features:  81%|████████  | 112/139 [00:02<00:00, 46.34it/s]Extracting features:  84%|████████▍ | 117/139 [00:02<00:00, 45.67it/s]Extracting features:  88%|████████▊ | 122/139 [00:02<00:00, 44.08it/s]Extracting features:  93%|█████████▎| 129/139 [00:03<00:00, 50.70it/s]Extracting features:  97%|█████████▋| 135/139 [00:03<00:00, 52.95it/s]Extracting features: 100%|██████████| 139/139 [00:03<00:00, 41.99it/s]
2024-12-27 19:29:32,129 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 19:29:32,129 - INFO - Validation feature extraction completed in 3.32s
2024-12-27 19:29:32,129 - INFO - Extracting training features...
2024-12-27 19:29:32,129 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<02:06,  4.89it/s]Extracting features:   1%|          | 6/618 [00:00<00:26, 22.81it/s]Extracting features:   2%|▏         | 10/618 [00:00<00:21, 27.75it/s]Extracting features:   2%|▏         | 14/618 [00:00<00:20, 30.13it/s]Extracting features:   3%|▎         | 19/618 [00:00<00:16, 36.16it/s]Extracting features:   4%|▍         | 25/618 [00:00<00:13, 43.04it/s]Extracting features:   5%|▌         | 31/618 [00:00<00:12, 45.94it/s]Extracting features:   6%|▌         | 38/618 [00:00<00:11, 50.23it/s]Extracting features:   7%|▋         | 44/618 [00:01<00:11, 50.69it/s]Extracting features:   8%|▊         | 50/618 [00:01<00:12, 46.61it/s]Extracting features:   9%|▉         | 56/618 [00:01<00:11, 46.96it/s]Extracting features:  10%|▉         | 61/618 [00:01<00:11, 47.63it/s]Extracting features:  11%|█         | 66/618 [00:01<00:11, 46.80it/s]Extracting features:  11%|█▏        | 71/618 [00:01<00:12, 45.04it/s]Extracting features:  12%|█▏        | 76/618 [00:01<00:12, 43.19it/s]Extracting features:  13%|█▎        | 81/618 [00:01<00:12, 42.79it/s]Extracting features:  14%|█▍        | 86/618 [00:02<00:12, 44.25it/s]Extracting features:  15%|█▍        | 91/618 [00:02<00:12, 42.14it/s]Extracting features:  16%|█▌        | 96/618 [00:02<00:13, 38.84it/s]Extracting features:  16%|█▌        | 100/618 [00:02<00:13, 38.61it/s]Extracting features:  17%|█▋        | 105/618 [00:02<00:12, 40.73it/s]Extracting features:  18%|█▊        | 110/618 [00:02<00:13, 37.92it/s]Extracting features:  19%|█▊        | 115/618 [00:02<00:12, 39.10it/s]Extracting features:  19%|█▉        | 119/618 [00:02<00:13, 36.83it/s]Extracting features:  20%|██        | 124/618 [00:03<00:13, 37.98it/s]Extracting features:  21%|██        | 128/618 [00:03<00:13, 37.01it/s]Extracting features:  22%|██▏       | 133/618 [00:03<00:12, 38.90it/s]Extracting features:  22%|██▏       | 138/618 [00:03<00:11, 41.10it/s]Extracting features:  23%|██▎       | 143/618 [00:03<00:11, 42.27it/s]Extracting features:  24%|██▍       | 148/618 [00:03<00:11, 41.62it/s]Extracting features:  25%|██▍       | 153/618 [00:03<00:10, 42.83it/s]Extracting features:  26%|██▌       | 158/618 [00:03<00:11, 40.84it/s]Extracting features:  26%|██▋       | 163/618 [00:04<00:11, 40.65it/s]Extracting features:  27%|██▋       | 168/618 [00:04<00:11, 38.78it/s]Extracting features:  28%|██▊       | 172/618 [00:04<00:11, 39.08it/s]Extracting features:  28%|██▊       | 176/618 [00:04<00:11, 38.79it/s]Extracting features:  29%|██▉       | 181/618 [00:04<00:10, 40.73it/s]Extracting features:  30%|███       | 186/618 [00:04<00:10, 41.42it/s]Extracting features:  31%|███       | 191/618 [00:04<00:09, 43.38it/s]Extracting features:  32%|███▏      | 196/618 [00:04<00:09, 43.42it/s]Extracting features:  33%|███▎      | 201/618 [00:04<00:09, 42.03it/s]Extracting features:  33%|███▎      | 206/618 [00:05<00:10, 40.65it/s]Extracting features:  34%|███▍      | 211/618 [00:05<00:09, 41.10it/s]Extracting features:  35%|███▍      | 216/618 [00:05<00:10, 39.55it/s]Extracting features:  36%|███▌      | 220/618 [00:05<00:10, 37.70it/s]Extracting features:  36%|███▌      | 224/618 [00:05<00:10, 37.81it/s]Extracting features:  37%|███▋      | 228/618 [00:05<00:10, 36.09it/s]Extracting features:  38%|███▊      | 232/618 [00:05<00:10, 36.09it/s]Extracting features:  38%|███▊      | 236/618 [00:05<00:10, 36.21it/s]Extracting features:  39%|███▉      | 240/618 [00:06<00:10, 34.80it/s]Extracting features:  40%|███▉      | 245/618 [00:06<00:10, 36.43it/s]Extracting features:  40%|████      | 249/618 [00:06<00:09, 37.23it/s]Extracting features:  41%|████      | 253/618 [00:06<00:09, 37.21it/s]Extracting features:  42%|████▏     | 257/618 [00:06<00:09, 37.26it/s]Extracting features:  42%|████▏     | 262/618 [00:06<00:09, 39.01it/s]Extracting features:  43%|████▎     | 267/618 [00:06<00:08, 41.79it/s]Extracting features:  44%|████▍     | 272/618 [00:06<00:08, 40.80it/s]Extracting features:  45%|████▍     | 277/618 [00:06<00:08, 40.77it/s]Extracting features:  46%|████▌     | 282/618 [00:07<00:08, 40.37it/s]Extracting features:  46%|████▋     | 287/618 [00:07<00:08, 38.45it/s]Extracting features:  47%|████▋     | 291/618 [00:07<00:08, 38.48it/s]Extracting features:  48%|████▊     | 295/618 [00:07<00:08, 38.78it/s]Extracting features:  48%|████▊     | 299/618 [00:07<00:08, 36.62it/s]Extracting features:  49%|████▉     | 304/618 [00:07<00:08, 37.73it/s]Extracting features:  50%|████▉     | 308/618 [00:07<00:08, 36.96it/s]Extracting features:  50%|█████     | 312/618 [00:07<00:08, 37.10it/s]Extracting features:  51%|█████     | 316/618 [00:07<00:08, 36.28it/s]Extracting features:  52%|█████▏    | 321/618 [00:08<00:07, 38.83it/s]Extracting features:  53%|█████▎    | 325/618 [00:08<00:07, 37.44it/s]Extracting features:  53%|█████▎    | 329/618 [00:08<00:07, 37.88it/s]Extracting features:  54%|█████▍    | 334/618 [00:08<00:07, 40.54it/s]Extracting features:  55%|█████▍    | 339/618 [00:08<00:06, 41.49it/s]Extracting features:  56%|█████▌    | 344/618 [00:08<00:06, 40.67it/s]Extracting features:  56%|█████▋    | 349/618 [00:08<00:06, 39.91it/s]Extracting features:  57%|█████▋    | 354/618 [00:08<00:06, 38.76it/s]Extracting features:  58%|█████▊    | 358/618 [00:09<00:06, 37.18it/s]Extracting features:  59%|█████▊    | 362/618 [00:09<00:06, 37.48it/s]Extracting features:  59%|█████▉    | 367/618 [00:09<00:06, 40.60it/s]Extracting features:  60%|██████    | 372/618 [00:09<00:05, 41.70it/s]Extracting features:  61%|██████    | 377/618 [00:09<00:05, 41.13it/s]Extracting features:  62%|██████▏   | 384/618 [00:09<00:05, 46.07it/s]Extracting features:  63%|██████▎   | 389/618 [00:09<00:05, 43.44it/s]Extracting features:  64%|██████▍   | 394/618 [00:09<00:04, 45.03it/s]Extracting features:  65%|██████▍   | 399/618 [00:09<00:04, 45.79it/s]Extracting features:  65%|██████▌   | 404/618 [00:10<00:05, 40.45it/s]Extracting features:  66%|██████▌   | 409/618 [00:10<00:05, 40.05it/s]Extracting features:  67%|██████▋   | 414/618 [00:10<00:05, 39.25it/s]Extracting features:  68%|██████▊   | 418/618 [00:10<00:05, 38.10it/s]Extracting features:  68%|██████▊   | 422/618 [00:10<00:05, 38.23it/s]Extracting features:  69%|██████▉   | 426/618 [00:10<00:05, 37.63it/s]Extracting features:  70%|██████▉   | 431/618 [00:10<00:04, 40.37it/s]Extracting features:  71%|███████   | 436/618 [00:10<00:04, 40.10it/s]Extracting features:  71%|███████▏  | 441/618 [00:11<00:04, 41.39it/s]Extracting features:  72%|███████▏  | 446/618 [00:11<00:04, 40.34it/s]Extracting features:  73%|███████▎  | 451/618 [00:11<00:04, 40.78it/s]Extracting features:  74%|███████▍  | 456/618 [00:11<00:03, 40.76it/s]Extracting features:  75%|███████▍  | 461/618 [00:11<00:03, 42.43it/s]Extracting features:  75%|███████▌  | 466/618 [00:11<00:03, 41.63it/s]Extracting features:  76%|███████▌  | 471/618 [00:11<00:03, 39.14it/s]Extracting features:  77%|███████▋  | 475/618 [00:11<00:03, 37.56it/s]Extracting features:  78%|███████▊  | 479/618 [00:12<00:03, 36.84it/s]Extracting features:  78%|███████▊  | 483/618 [00:12<00:03, 35.41it/s]Extracting features:  79%|███████▉  | 487/618 [00:12<00:03, 35.96it/s]Extracting features:  80%|███████▉  | 492/618 [00:12<00:03, 38.50it/s]Extracting features:  80%|████████  | 497/618 [00:12<00:03, 40.28it/s]Extracting features:  81%|████████  | 502/618 [00:12<00:02, 40.01it/s]Extracting features:  82%|████████▏ | 507/618 [00:12<00:02, 37.23it/s]Extracting features:  83%|████████▎ | 511/618 [00:12<00:02, 36.06it/s]Extracting features:  83%|████████▎ | 515/618 [00:13<00:02, 36.73it/s]Extracting features:  84%|████████▍ | 519/618 [00:13<00:02, 37.36it/s]Extracting features:  85%|████████▍ | 525/618 [00:13<00:02, 40.29it/s]Extracting features:  86%|████████▌ | 530/618 [00:13<00:02, 41.72it/s]Extracting features:  87%|████████▋ | 535/618 [00:13<00:02, 41.15it/s]Extracting features:  87%|████████▋ | 540/618 [00:13<00:01, 39.35it/s]Extracting features:  88%|████████▊ | 545/618 [00:13<00:01, 39.22it/s]Extracting features:  89%|████████▉ | 549/618 [00:13<00:01, 38.13it/s]Extracting features:  89%|████████▉ | 553/618 [00:13<00:01, 37.61it/s]Extracting features:  90%|█████████ | 557/618 [00:14<00:01, 37.84it/s]Extracting features:  91%|█████████ | 561/618 [00:14<00:01, 38.18it/s]Extracting features:  91%|█████████▏| 565/618 [00:14<00:01, 37.27it/s]Extracting features:  92%|█████████▏| 569/618 [00:14<00:01, 36.48it/s]Extracting features:  93%|█████████▎| 574/618 [00:14<00:01, 39.14it/s]Extracting features:  94%|█████████▎| 579/618 [00:14<00:00, 40.25it/s]Extracting features:  94%|█████████▍| 584/618 [00:14<00:00, 39.62it/s]Extracting features:  95%|█████████▌| 589/618 [00:14<00:00, 39.84it/s]Extracting features:  96%|█████████▌| 593/618 [00:14<00:00, 38.66it/s]Extracting features:  97%|█████████▋| 598/618 [00:15<00:00, 39.07it/s]Extracting features:  97%|█████████▋| 602/618 [00:15<00:00, 38.68it/s]Extracting features:  98%|█████████▊| 607/618 [00:15<00:00, 38.89it/s]Extracting features:  99%|█████████▉| 611/618 [00:15<00:00, 38.01it/s]Extracting features: 100%|██████████| 618/618 [00:15<00:00, 43.80it/s]Extracting features: 100%|██████████| 618/618 [00:15<00:00, 39.50it/s]
2024-12-27 19:29:47,813 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 19:29:47,813 - INFO - Training feature extraction completed in 15.68s
2024-12-27 19:29:47,813 - INFO - Creating model for classifier: LogisticRegression
2024-12-27 19:29:47,813 - INFO - Using device: cuda
2024-12-27 19:29:47,813 - INFO - 
Processing poison rate: 0.0
2024-12-27 19:29:47,814 - INFO - Training set processing completed in 0.00s
2024-12-27 19:29:47,814 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 19:29:47,815 - INFO - Memory usage at start_fit: CPU 3004.8 MB, GPU 47.3 MB
2024-12-27 19:29:47,815 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:29:47,819 - INFO - Number of unique classes: 43
2024-12-27 19:29:48,213 - INFO - Fitted scaler and transformed data
2024-12-27 19:29:48,213 - INFO - Scaling time: 0.39s
2024-12-27 19:29:48,845 - INFO - Epoch 1/200, Train Loss: 1.4337, Val Loss: 1.0556
2024-12-27 19:29:49,649 - INFO - Epoch 2/200, Train Loss: 0.6067, Val Loss: 0.8901
2024-12-27 19:29:50,382 - INFO - Epoch 3/200, Train Loss: 0.4410, Val Loss: 0.8764
2024-12-27 19:29:51,254 - INFO - Epoch 4/200, Train Loss: 0.3520, Val Loss: 0.9380
2024-12-27 19:29:52,118 - INFO - Epoch 5/200, Train Loss: 0.3166, Val Loss: 0.8400
2024-12-27 19:29:52,965 - INFO - Epoch 6/200, Train Loss: 0.2524, Val Loss: 0.8624
2024-12-27 19:29:53,814 - INFO - Epoch 7/200, Train Loss: 0.2718, Val Loss: 1.0096
2024-12-27 19:29:53,814 - INFO - Early stopping triggered at epoch 7
2024-12-27 19:29:53,814 - INFO - Training completed in 6.00s
2024-12-27 19:29:53,815 - INFO - Final memory usage: CPU 3105.5 MB, GPU 48.4 MB
2024-12-27 19:29:53,815 - INFO - Model training completed in 6.00s
2024-12-27 19:29:53,846 - INFO - Prediction completed in 0.03s
2024-12-27 19:29:53,858 - INFO - Poison rate 0.0 completed in 6.04s
2024-12-27 19:29:53,858 - INFO - 
Processing poison rate: 0.01
2024-12-27 19:29:53,863 - INFO - Total number of labels flipped: 197
2024-12-27 19:29:53,863 - INFO - Label flipping completed in 0.01s
2024-12-27 19:29:53,863 - INFO - Training set processing completed in 0.00s
2024-12-27 19:29:53,863 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 19:29:53,864 - INFO - Memory usage at start_fit: CPU 3009.0 MB, GPU 48.1 MB
2024-12-27 19:29:53,864 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:29:53,865 - INFO - Number of unique classes: 43
2024-12-27 19:29:54,237 - INFO - Fitted scaler and transformed data
2024-12-27 19:29:54,238 - INFO - Scaling time: 0.37s
2024-12-27 19:29:54,967 - INFO - Epoch 1/200, Train Loss: 1.5726, Val Loss: 1.2114
2024-12-27 19:29:55,559 - INFO - Epoch 2/200, Train Loss: 0.7537, Val Loss: 1.1183
2024-12-27 19:29:56,138 - INFO - Epoch 3/200, Train Loss: 0.5556, Val Loss: 1.1250
2024-12-27 19:29:56,713 - INFO - Epoch 4/200, Train Loss: 0.4542, Val Loss: 1.1078
2024-12-27 19:29:57,376 - INFO - Epoch 5/200, Train Loss: 0.3853, Val Loss: 1.0262
2024-12-27 19:29:58,130 - INFO - Epoch 6/200, Train Loss: 0.3171, Val Loss: 1.2145
2024-12-27 19:29:58,724 - INFO - Epoch 7/200, Train Loss: 0.3145, Val Loss: 1.1594
2024-12-27 19:29:58,724 - INFO - Early stopping triggered at epoch 7
2024-12-27 19:29:58,724 - INFO - Training completed in 4.86s
2024-12-27 19:29:58,725 - INFO - Final memory usage: CPU 3106.9 MB, GPU 48.4 MB
2024-12-27 19:29:58,727 - INFO - Model training completed in 4.86s
2024-12-27 19:29:58,758 - INFO - Prediction completed in 0.03s
2024-12-27 19:29:58,769 - INFO - Poison rate 0.01 completed in 4.91s
2024-12-27 19:29:58,769 - INFO - 
Processing poison rate: 0.03
2024-12-27 19:29:58,781 - INFO - Total number of labels flipped: 592
2024-12-27 19:29:58,781 - INFO - Label flipping completed in 0.01s
2024-12-27 19:29:58,781 - INFO - Training set processing completed in 0.00s
2024-12-27 19:29:58,781 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 19:29:58,782 - INFO - Memory usage at start_fit: CPU 3010.4 MB, GPU 48.1 MB
2024-12-27 19:29:58,782 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:29:58,783 - INFO - Number of unique classes: 43
2024-12-27 19:29:59,166 - INFO - Fitted scaler and transformed data
2024-12-27 19:29:59,167 - INFO - Scaling time: 0.38s
2024-12-27 19:29:59,800 - INFO - Epoch 1/200, Train Loss: 1.8552, Val Loss: 1.4626
2024-12-27 19:30:00,359 - INFO - Epoch 2/200, Train Loss: 1.0080, Val Loss: 1.4717
2024-12-27 19:30:01,007 - INFO - Epoch 3/200, Train Loss: 0.7896, Val Loss: 1.6247
2024-12-27 19:30:01,007 - INFO - Early stopping triggered at epoch 3
2024-12-27 19:30:01,007 - INFO - Training completed in 2.23s
2024-12-27 19:30:01,007 - INFO - Final memory usage: CPU 3106.9 MB, GPU 48.4 MB
2024-12-27 19:30:01,008 - INFO - Model training completed in 2.23s
2024-12-27 19:30:01,037 - INFO - Prediction completed in 0.03s
2024-12-27 19:30:01,048 - INFO - Poison rate 0.03 completed in 2.28s
2024-12-27 19:30:01,049 - INFO - 
Processing poison rate: 0.05
2024-12-27 19:30:01,067 - INFO - Total number of labels flipped: 987
2024-12-27 19:30:01,068 - INFO - Label flipping completed in 0.02s
2024-12-27 19:30:01,068 - INFO - Training set processing completed in 0.00s
2024-12-27 19:30:01,068 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 19:30:01,069 - INFO - Memory usage at start_fit: CPU 3010.4 MB, GPU 48.1 MB
2024-12-27 19:30:01,069 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:30:01,069 - INFO - Number of unique classes: 43
2024-12-27 19:30:01,408 - INFO - Fitted scaler and transformed data
2024-12-27 19:30:01,409 - INFO - Scaling time: 0.34s
2024-12-27 19:30:02,020 - INFO - Epoch 1/200, Train Loss: 2.1067, Val Loss: 1.6520
2024-12-27 19:30:02,615 - INFO - Epoch 2/200, Train Loss: 1.2305, Val Loss: 1.6602
2024-12-27 19:30:03,199 - INFO - Epoch 3/200, Train Loss: 0.9956, Val Loss: 1.6651
2024-12-27 19:30:03,199 - INFO - Early stopping triggered at epoch 3
2024-12-27 19:30:03,199 - INFO - Training completed in 2.13s
2024-12-27 19:30:03,199 - INFO - Final memory usage: CPU 3106.9 MB, GPU 48.4 MB
2024-12-27 19:30:03,200 - INFO - Model training completed in 2.13s
2024-12-27 19:30:03,228 - INFO - Prediction completed in 0.03s
2024-12-27 19:30:03,239 - INFO - Poison rate 0.05 completed in 2.19s
2024-12-27 19:30:03,239 - INFO - 
Processing poison rate: 0.07
2024-12-27 19:30:03,288 - INFO - Total number of labels flipped: 1382
2024-12-27 19:30:03,288 - INFO - Label flipping completed in 0.05s
2024-12-27 19:30:03,288 - INFO - Training set processing completed in 0.00s
2024-12-27 19:30:03,288 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 19:30:03,289 - INFO - Memory usage at start_fit: CPU 3010.4 MB, GPU 48.1 MB
2024-12-27 19:30:03,289 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:30:03,291 - INFO - Number of unique classes: 43
2024-12-27 19:30:03,652 - INFO - Fitted scaler and transformed data
2024-12-27 19:30:03,652 - INFO - Scaling time: 0.36s
2024-12-27 19:30:04,315 - INFO - Epoch 1/200, Train Loss: 2.2863, Val Loss: 1.9719
2024-12-27 19:30:05,011 - INFO - Epoch 2/200, Train Loss: 1.4238, Val Loss: 2.0819
2024-12-27 19:30:05,595 - INFO - Epoch 3/200, Train Loss: 1.1704, Val Loss: 2.1892
2024-12-27 19:30:05,596 - INFO - Early stopping triggered at epoch 3
2024-12-27 19:30:05,596 - INFO - Training completed in 2.31s
2024-12-27 19:30:05,596 - INFO - Final memory usage: CPU 3107.2 MB, GPU 48.4 MB
2024-12-27 19:30:05,598 - INFO - Model training completed in 2.31s
2024-12-27 19:30:05,627 - INFO - Prediction completed in 0.03s
2024-12-27 19:30:05,654 - INFO - Poison rate 0.07 completed in 2.41s
2024-12-27 19:30:05,654 - INFO - 
Processing poison rate: 0.1
2024-12-27 19:30:05,689 - INFO - Total number of labels flipped: 1975
2024-12-27 19:30:05,690 - INFO - Label flipping completed in 0.04s
2024-12-27 19:30:05,690 - INFO - Training set processing completed in 0.00s
2024-12-27 19:30:05,690 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 19:30:05,691 - INFO - Memory usage at start_fit: CPU 3010.8 MB, GPU 48.1 MB
2024-12-27 19:30:05,691 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:30:05,692 - INFO - Number of unique classes: 43
2024-12-27 19:30:06,043 - INFO - Fitted scaler and transformed data
2024-12-27 19:30:06,043 - INFO - Scaling time: 0.35s
2024-12-27 19:30:06,737 - INFO - Epoch 1/200, Train Loss: 2.5164, Val Loss: 2.4265
2024-12-27 19:30:07,423 - INFO - Epoch 2/200, Train Loss: 1.6639, Val Loss: 2.3929
2024-12-27 19:30:07,972 - INFO - Epoch 3/200, Train Loss: 1.4172, Val Loss: 2.6801
2024-12-27 19:30:08,542 - INFO - Epoch 4/200, Train Loss: 1.2015, Val Loss: 2.7025
2024-12-27 19:30:08,542 - INFO - Early stopping triggered at epoch 4
2024-12-27 19:30:08,542 - INFO - Training completed in 2.85s
2024-12-27 19:30:08,543 - INFO - Final memory usage: CPU 3109.8 MB, GPU 48.4 MB
2024-12-27 19:30:08,543 - INFO - Model training completed in 2.85s
2024-12-27 19:30:08,571 - INFO - Prediction completed in 0.03s
2024-12-27 19:30:08,582 - INFO - Poison rate 0.1 completed in 2.93s
2024-12-27 19:30:08,582 - INFO - 
Processing poison rate: 0.2
2024-12-27 19:30:08,677 - INFO - Total number of labels flipped: 3951
2024-12-27 19:30:08,678 - INFO - Label flipping completed in 0.10s
2024-12-27 19:30:08,678 - INFO - Training set processing completed in 0.00s
2024-12-27 19:30:08,678 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 19:30:08,679 - INFO - Memory usage at start_fit: CPU 3013.3 MB, GPU 48.1 MB
2024-12-27 19:30:08,680 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:30:08,682 - INFO - Number of unique classes: 43
2024-12-27 19:30:09,031 - INFO - Fitted scaler and transformed data
2024-12-27 19:30:09,032 - INFO - Scaling time: 0.35s
2024-12-27 19:30:09,616 - INFO - Epoch 1/200, Train Loss: 3.2800, Val Loss: 3.2328
2024-12-27 19:30:10,145 - INFO - Epoch 2/200, Train Loss: 2.4366, Val Loss: 3.4295
2024-12-27 19:30:10,736 - INFO - Epoch 3/200, Train Loss: 2.1165, Val Loss: 3.6287
2024-12-27 19:30:10,736 - INFO - Early stopping triggered at epoch 3
2024-12-27 19:30:10,736 - INFO - Training completed in 2.06s
2024-12-27 19:30:10,737 - INFO - Final memory usage: CPU 3109.8 MB, GPU 48.4 MB
2024-12-27 19:30:10,737 - INFO - Model training completed in 2.06s
2024-12-27 19:30:10,770 - INFO - Prediction completed in 0.03s
2024-12-27 19:30:10,781 - INFO - Poison rate 0.2 completed in 2.20s
2024-12-27 19:30:10,783 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 19:30:10,783 - INFO - Total evaluation time: 59.62s
2024-12-27 19:30:10,789 - INFO - 
Progress: 29.2% - Evaluating GTSRB with LogisticRegression (dynadetect mode, iteration 1/1)
2024-12-27 19:30:10,862 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 19:30:10,941 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 19:30:11,035 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 19:30:11,036 - INFO - Dataset type: image
2024-12-27 19:30:11,036 - INFO - Sample size: 39209
2024-12-27 19:30:11,036 - INFO - Using device: cuda
2024-12-27 19:30:11,036 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 19:30:11,038 - INFO - Loading datasets...
2024-12-27 19:30:28,265 - INFO - Dataset loading completed in 17.23s
2024-12-27 19:30:28,265 - INFO - Extracting validation features...
2024-12-27 19:30:28,265 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:30,  4.57it/s]Extracting features:   3%|▎         | 4/139 [00:00<00:10, 12.69it/s]Extracting features:   4%|▍         | 6/139 [00:00<00:08, 15.06it/s]Extracting features:   6%|▋         | 9/139 [00:00<00:06, 18.93it/s]Extracting features:   9%|▉         | 13/139 [00:00<00:05, 23.33it/s]Extracting features:  14%|█▎        | 19/139 [00:00<00:03, 32.39it/s]Extracting features:  18%|█▊        | 25/139 [00:00<00:02, 39.86it/s]Extracting features:  23%|██▎       | 32/139 [00:01<00:02, 46.37it/s]Extracting features:  27%|██▋       | 38/139 [00:01<00:02, 48.65it/s]Extracting features:  32%|███▏      | 44/139 [00:01<00:01, 49.79it/s]Extracting features:  36%|███▌      | 50/139 [00:01<00:01, 50.35it/s]Extracting features:  40%|████      | 56/139 [00:01<00:01, 48.81it/s]Extracting features:  44%|████▍     | 61/139 [00:01<00:01, 48.12it/s]Extracting features:  49%|████▉     | 68/139 [00:01<00:01, 53.42it/s]Extracting features:  53%|█████▎    | 74/139 [00:01<00:01, 54.58it/s]Extracting features:  58%|█████▊    | 80/139 [00:01<00:01, 51.63it/s]Extracting features:  62%|██████▏   | 86/139 [00:02<00:00, 53.51it/s]Extracting features:  66%|██████▌   | 92/139 [00:02<00:00, 52.28it/s]Extracting features:  71%|███████   | 98/139 [00:02<00:00, 53.71it/s]Extracting features:  76%|███████▌  | 105/139 [00:02<00:00, 57.04it/s]Extracting features:  81%|████████  | 112/139 [00:02<00:00, 59.29it/s]Extracting features:  86%|████████▌ | 119/139 [00:02<00:00, 62.25it/s]Extracting features:  91%|█████████ | 126/139 [00:02<00:00, 62.35it/s]Extracting features:  96%|█████████▌| 133/139 [00:02<00:00, 60.92it/s]Extracting features: 100%|██████████| 139/139 [00:03<00:00, 45.70it/s]
2024-12-27 19:30:31,320 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 19:30:31,321 - INFO - Validation feature extraction completed in 3.06s
2024-12-27 19:30:31,321 - INFO - Extracting training features...
2024-12-27 19:30:31,321 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<02:01,  5.07it/s]Extracting features:   1%|          | 7/618 [00:00<00:22, 27.76it/s]Extracting features:   2%|▏         | 12/618 [00:00<00:17, 35.18it/s]Extracting features:   3%|▎         | 17/618 [00:00<00:16, 37.23it/s]Extracting features:   4%|▎         | 22/618 [00:00<00:14, 41.16it/s]Extracting features:   4%|▍         | 27/618 [00:00<00:13, 42.56it/s]Extracting features:   5%|▌         | 33/618 [00:00<00:12, 46.16it/s]Extracting features:   6%|▋         | 39/618 [00:00<00:11, 49.62it/s]Extracting features:   7%|▋         | 45/618 [00:01<00:11, 51.07it/s]Extracting features:   8%|▊         | 51/618 [00:01<00:12, 46.21it/s]Extracting features:   9%|▉         | 56/618 [00:01<00:12, 44.70it/s]Extracting features:  10%|▉         | 61/618 [00:01<00:12, 44.92it/s]Extracting features:  11%|█         | 67/618 [00:01<00:11, 47.74it/s]Extracting features:  12%|█▏        | 73/618 [00:01<00:11, 49.17it/s]Extracting features:  13%|█▎        | 79/618 [00:01<00:10, 51.28it/s]Extracting features:  14%|█▍        | 85/618 [00:01<00:09, 53.44it/s]Extracting features:  15%|█▍        | 91/618 [00:02<00:09, 52.72it/s]Extracting features:  16%|█▌        | 97/618 [00:02<00:09, 52.45it/s]Extracting features:  17%|█▋        | 103/618 [00:02<00:10, 51.25it/s]Extracting features:  18%|█▊        | 109/618 [00:02<00:09, 51.67it/s]Extracting features:  19%|█▊        | 115/618 [00:02<00:09, 52.53it/s]Extracting features:  20%|█▉        | 121/618 [00:02<00:09, 53.64it/s]Extracting features:  21%|██        | 127/618 [00:02<00:09, 52.66it/s]Extracting features:  22%|██▏       | 134/618 [00:02<00:09, 53.64it/s]Extracting features:  23%|██▎       | 140/618 [00:02<00:08, 53.19it/s]Extracting features:  24%|██▍       | 147/618 [00:03<00:08, 56.95it/s]Extracting features:  25%|██▍       | 154/618 [00:03<00:08, 56.26it/s]Extracting features:  26%|██▌       | 160/618 [00:03<00:08, 51.02it/s]Extracting features:  27%|██▋       | 166/618 [00:03<00:08, 53.10it/s]Extracting features:  28%|██▊       | 172/618 [00:03<00:08, 51.58it/s]Extracting features:  29%|██▉       | 178/618 [00:03<00:08, 52.06it/s]Extracting features:  30%|██▉       | 184/618 [00:03<00:08, 53.93it/s]Extracting features:  31%|███       | 190/618 [00:03<00:07, 53.61it/s]Extracting features:  32%|███▏      | 196/618 [00:04<00:08, 49.65it/s]Extracting features:  33%|███▎      | 202/618 [00:04<00:08, 50.96it/s]Extracting features:  34%|███▎      | 208/618 [00:04<00:07, 51.68it/s]Extracting features:  35%|███▍      | 214/618 [00:04<00:07, 52.15it/s]Extracting features:  36%|███▌      | 220/618 [00:04<00:07, 51.51it/s]Extracting features:  37%|███▋      | 226/618 [00:04<00:07, 53.30it/s]Extracting features:  38%|███▊      | 232/618 [00:04<00:07, 53.47it/s]Extracting features:  39%|███▊      | 238/618 [00:04<00:07, 51.67it/s]Extracting features:  40%|███▉      | 245/618 [00:04<00:06, 55.02it/s]Extracting features:  41%|████      | 251/618 [00:05<00:06, 55.40it/s]Extracting features:  42%|████▏     | 257/618 [00:05<00:06, 54.32it/s]Extracting features:  43%|████▎     | 263/618 [00:05<00:06, 54.84it/s]Extracting features:  44%|████▎     | 269/618 [00:05<00:06, 52.31it/s]Extracting features:  44%|████▍     | 275/618 [00:05<00:06, 52.39it/s]Extracting features:  45%|████▌     | 281/618 [00:05<00:06, 54.03it/s]Extracting features:  46%|████▋     | 287/618 [00:05<00:06, 54.87it/s]Extracting features:  47%|████▋     | 293/618 [00:05<00:05, 55.55it/s]Extracting features:  48%|████▊     | 299/618 [00:05<00:05, 56.38it/s]Extracting features:  49%|████▉     | 305/618 [00:06<00:05, 56.03it/s]Extracting features:  50%|█████     | 311/618 [00:06<00:05, 57.01it/s]Extracting features:  51%|█████▏    | 317/618 [00:06<00:05, 57.66it/s]Extracting features:  52%|█████▏    | 324/618 [00:06<00:04, 59.43it/s]Extracting features:  53%|█████▎    | 330/618 [00:06<00:05, 53.76it/s]Extracting features:  54%|█████▍    | 336/618 [00:06<00:05, 54.99it/s]Extracting features:  55%|█████▌    | 342/618 [00:06<00:05, 47.96it/s]Extracting features:  56%|█████▋    | 348/618 [00:06<00:06, 40.73it/s]Extracting features:  57%|█████▋    | 353/618 [00:07<00:06, 42.00it/s]Extracting features:  58%|█████▊    | 358/618 [00:07<00:05, 43.43it/s]Extracting features:  59%|█████▉    | 364/618 [00:07<00:05, 46.48it/s]Extracting features:  60%|██████    | 371/618 [00:07<00:04, 50.36it/s]Extracting features:  61%|██████    | 378/618 [00:07<00:04, 54.96it/s]Extracting features:  62%|██████▏   | 384/618 [00:07<00:04, 56.27it/s]Extracting features:  63%|██████▎   | 390/618 [00:07<00:04, 52.14it/s]Extracting features:  64%|██████▍   | 396/618 [00:07<00:04, 48.23it/s]Extracting features:  65%|██████▌   | 402/618 [00:07<00:04, 49.18it/s]Extracting features:  66%|██████▌   | 408/618 [00:08<00:04, 47.53it/s]Extracting features:  67%|██████▋   | 415/618 [00:08<00:03, 50.78it/s]Extracting features:  68%|██████▊   | 421/618 [00:08<00:03, 52.71it/s]Extracting features:  69%|██████▉   | 427/618 [00:08<00:03, 52.01it/s]Extracting features:  70%|███████   | 433/618 [00:08<00:03, 52.01it/s]Extracting features:  71%|███████   | 439/618 [00:08<00:03, 50.52it/s]Extracting features:  72%|███████▏  | 445/618 [00:08<00:03, 50.57it/s]Extracting features:  73%|███████▎  | 451/618 [00:08<00:03, 51.70it/s]Extracting features:  74%|███████▍  | 457/618 [00:09<00:03, 50.77it/s]Extracting features:  75%|███████▍  | 463/618 [00:09<00:03, 48.31it/s]Extracting features:  76%|███████▌  | 469/618 [00:09<00:03, 47.65it/s]Extracting features:  77%|███████▋  | 475/618 [00:09<00:02, 49.13it/s]Extracting features:  78%|███████▊  | 482/618 [00:09<00:02, 52.44it/s]Extracting features:  79%|███████▉  | 488/618 [00:09<00:02, 53.96it/s]Extracting features:  80%|███████▉  | 494/618 [00:09<00:02, 54.49it/s]Extracting features:  81%|████████  | 500/618 [00:09<00:02, 54.28it/s]Extracting features:  82%|████████▏ | 506/618 [00:09<00:02, 53.01it/s]Extracting features:  83%|████████▎ | 512/618 [00:10<00:01, 53.53it/s]Extracting features:  84%|████████▍ | 518/618 [00:10<00:01, 53.06it/s]Extracting features:  85%|████████▍ | 524/618 [00:10<00:01, 51.19it/s]Extracting features:  86%|████████▌ | 531/618 [00:10<00:01, 53.46it/s]Extracting features:  87%|████████▋ | 537/618 [00:10<00:01, 52.51it/s]Extracting features:  88%|████████▊ | 543/618 [00:10<00:01, 53.16it/s]Extracting features:  89%|████████▉ | 549/618 [00:10<00:01, 54.21it/s]Extracting features:  90%|████████▉ | 555/618 [00:10<00:01, 54.73it/s]Extracting features:  91%|█████████ | 562/618 [00:11<00:00, 56.51it/s]Extracting features:  92%|█████████▏| 568/618 [00:11<00:00, 56.82it/s]Extracting features:  93%|█████████▎| 574/618 [00:11<00:00, 56.88it/s]Extracting features:  94%|█████████▍| 580/618 [00:11<00:00, 54.08it/s]Extracting features:  95%|█████████▍| 587/618 [00:11<00:00, 57.20it/s]Extracting features:  96%|█████████▌| 593/618 [00:11<00:00, 56.11it/s]Extracting features:  97%|█████████▋| 599/618 [00:11<00:00, 56.35it/s]Extracting features:  98%|█████████▊| 605/618 [00:11<00:00, 56.97it/s]Extracting features:  99%|█████████▉| 611/618 [00:11<00:00, 56.80it/s]Extracting features: 100%|██████████| 618/618 [00:11<00:00, 59.32it/s]Extracting features: 100%|██████████| 618/618 [00:12<00:00, 51.33it/s]
2024-12-27 19:30:43,393 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 19:30:43,394 - INFO - Training feature extraction completed in 12.07s
2024-12-27 19:30:43,394 - INFO - Creating model for classifier: LogisticRegression
2024-12-27 19:30:43,394 - INFO - Using device: cuda
2024-12-27 19:30:43,394 - INFO - 
Processing poison rate: 0.0
2024-12-27 19:30:43,394 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:30:43,394 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:30:45,228 - INFO - Feature scaling completed in 1.83s
2024-12-27 19:30:45,229 - INFO - Starting feature selection (k=50)
2024-12-27 19:30:45,246 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 19:30:45,246 - INFO - Starting anomaly detection
2024-12-27 19:30:52,429 - INFO - Anomaly detection completed in 7.18s
2024-12-27 19:30:52,429 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:30:52,429 - INFO - Total fit_transform time: 9.03s
2024-12-27 19:30:52,429 - INFO - Training set processing completed in 9.04s
2024-12-27 19:30:52,429 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 19:30:52,431 - INFO - Memory usage at start_fit: CPU 3007.1 MB, GPU 47.3 MB
2024-12-27 19:30:52,431 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:30:52,436 - INFO - Number of unique classes: 43
2024-12-27 19:30:52,808 - INFO - Fitted scaler and transformed data
2024-12-27 19:30:52,809 - INFO - Scaling time: 0.37s
2024-12-27 19:30:53,368 - INFO - Epoch 1/200, Train Loss: 1.4660, Val Loss: 1.0591
2024-12-27 19:30:53,854 - INFO - Epoch 2/200, Train Loss: 0.6026, Val Loss: 0.9357
2024-12-27 19:30:54,329 - INFO - Epoch 3/200, Train Loss: 0.4555, Val Loss: 0.9362
2024-12-27 19:30:54,830 - INFO - Epoch 4/200, Train Loss: 0.3688, Val Loss: 0.9065
2024-12-27 19:30:55,322 - INFO - Epoch 5/200, Train Loss: 0.3246, Val Loss: 1.0007
2024-12-27 19:30:55,813 - INFO - Epoch 6/200, Train Loss: 0.2775, Val Loss: 0.9020
2024-12-27 19:30:55,813 - INFO - Early stopping triggered at epoch 6
2024-12-27 19:30:55,813 - INFO - Training completed in 3.38s
2024-12-27 19:30:55,814 - INFO - Final memory usage: CPU 3109.8 MB, GPU 48.4 MB
2024-12-27 19:30:55,814 - INFO - Model training completed in 3.38s
2024-12-27 19:30:55,845 - INFO - Prediction completed in 0.03s
2024-12-27 19:30:55,857 - INFO - Poison rate 0.0 completed in 12.46s
2024-12-27 19:30:55,857 - INFO - 
Processing poison rate: 0.01
2024-12-27 19:30:55,862 - INFO - Total number of labels flipped: 197
2024-12-27 19:30:55,862 - INFO - Label flipping completed in 0.01s
2024-12-27 19:30:55,862 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:30:55,862 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:30:57,758 - INFO - Feature scaling completed in 1.90s
2024-12-27 19:30:57,758 - INFO - Starting feature selection (k=50)
2024-12-27 19:30:57,808 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 19:30:57,809 - INFO - Starting anomaly detection
2024-12-27 19:31:05,620 - INFO - Anomaly detection completed in 7.81s
2024-12-27 19:31:05,620 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:31:05,620 - INFO - Total fit_transform time: 9.76s
2024-12-27 19:31:05,621 - INFO - Training set processing completed in 9.76s
2024-12-27 19:31:05,621 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 19:31:05,622 - INFO - Memory usage at start_fit: CPU 3013.4 MB, GPU 48.1 MB
2024-12-27 19:31:05,622 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:31:05,622 - INFO - Number of unique classes: 43
2024-12-27 19:31:05,976 - INFO - Fitted scaler and transformed data
2024-12-27 19:31:05,976 - INFO - Scaling time: 0.35s
2024-12-27 19:31:06,724 - INFO - Epoch 1/200, Train Loss: 1.5972, Val Loss: 1.1743
2024-12-27 19:31:07,613 - INFO - Epoch 2/200, Train Loss: 0.7456, Val Loss: 0.9986
2024-12-27 19:31:08,475 - INFO - Epoch 3/200, Train Loss: 0.5842, Val Loss: 1.0140
2024-12-27 19:31:09,349 - INFO - Epoch 4/200, Train Loss: 0.4924, Val Loss: 1.0558
2024-12-27 19:31:09,349 - INFO - Early stopping triggered at epoch 4
2024-12-27 19:31:09,349 - INFO - Training completed in 3.73s
2024-12-27 19:31:09,349 - INFO - Final memory usage: CPU 3110.3 MB, GPU 48.4 MB
2024-12-27 19:31:09,350 - INFO - Model training completed in 3.73s
2024-12-27 19:31:09,383 - INFO - Prediction completed in 0.03s
2024-12-27 19:31:09,394 - INFO - Poison rate 0.01 completed in 13.54s
2024-12-27 19:31:09,394 - INFO - 
Processing poison rate: 0.03
2024-12-27 19:31:09,406 - INFO - Total number of labels flipped: 592
2024-12-27 19:31:09,406 - INFO - Label flipping completed in 0.01s
2024-12-27 19:31:09,406 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:31:09,406 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:31:11,191 - INFO - Feature scaling completed in 1.78s
2024-12-27 19:31:11,191 - INFO - Starting feature selection (k=50)
2024-12-27 19:31:11,241 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 19:31:11,241 - INFO - Starting anomaly detection
2024-12-27 19:31:19,292 - INFO - Anomaly detection completed in 8.05s
2024-12-27 19:31:19,292 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:31:19,292 - INFO - Total fit_transform time: 9.89s
2024-12-27 19:31:19,293 - INFO - Training set processing completed in 9.89s
2024-12-27 19:31:19,293 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 19:31:19,294 - INFO - Memory usage at start_fit: CPU 3013.9 MB, GPU 48.1 MB
2024-12-27 19:31:19,295 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:31:19,296 - INFO - Number of unique classes: 43
2024-12-27 19:31:19,672 - INFO - Fitted scaler and transformed data
2024-12-27 19:31:19,672 - INFO - Scaling time: 0.37s
2024-12-27 19:31:20,377 - INFO - Epoch 1/200, Train Loss: 1.8543, Val Loss: 1.4415
2024-12-27 19:31:21,223 - INFO - Epoch 2/200, Train Loss: 0.9884, Val Loss: 1.4814
2024-12-27 19:31:21,973 - INFO - Epoch 3/200, Train Loss: 0.7451, Val Loss: 1.5009
2024-12-27 19:31:21,974 - INFO - Early stopping triggered at epoch 3
2024-12-27 19:31:21,974 - INFO - Training completed in 2.68s
2024-12-27 19:31:21,974 - INFO - Final memory usage: CPU 3110.3 MB, GPU 48.4 MB
2024-12-27 19:31:21,975 - INFO - Model training completed in 2.68s
2024-12-27 19:31:22,006 - INFO - Prediction completed in 0.03s
2024-12-27 19:31:22,017 - INFO - Poison rate 0.03 completed in 12.62s
2024-12-27 19:31:22,017 - INFO - 
Processing poison rate: 0.05
2024-12-27 19:31:22,035 - INFO - Total number of labels flipped: 987
2024-12-27 19:31:22,036 - INFO - Label flipping completed in 0.02s
2024-12-27 19:31:22,036 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:31:22,036 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:31:24,072 - INFO - Feature scaling completed in 2.04s
2024-12-27 19:31:24,072 - INFO - Starting feature selection (k=50)
2024-12-27 19:31:24,123 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 19:31:24,123 - INFO - Starting anomaly detection
2024-12-27 19:31:29,975 - INFO - Anomaly detection completed in 5.85s
2024-12-27 19:31:29,976 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:31:29,976 - INFO - Total fit_transform time: 7.94s
2024-12-27 19:31:29,976 - INFO - Training set processing completed in 7.94s
2024-12-27 19:31:29,976 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 19:31:29,977 - INFO - Memory usage at start_fit: CPU 3013.9 MB, GPU 48.1 MB
2024-12-27 19:31:29,978 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:31:29,978 - INFO - Number of unique classes: 43
2024-12-27 19:31:30,331 - INFO - Fitted scaler and transformed data
2024-12-27 19:31:30,331 - INFO - Scaling time: 0.35s
2024-12-27 19:31:30,835 - INFO - Epoch 1/200, Train Loss: 2.0791, Val Loss: 1.8063
2024-12-27 19:31:31,321 - INFO - Epoch 2/200, Train Loss: 1.1913, Val Loss: 1.8497
2024-12-27 19:31:31,806 - INFO - Epoch 3/200, Train Loss: 0.9327, Val Loss: 1.9090
2024-12-27 19:31:31,806 - INFO - Early stopping triggered at epoch 3
2024-12-27 19:31:31,806 - INFO - Training completed in 1.83s
2024-12-27 19:31:31,807 - INFO - Final memory usage: CPU 3112.1 MB, GPU 48.4 MB
2024-12-27 19:31:31,808 - INFO - Model training completed in 1.83s
2024-12-27 19:31:31,845 - INFO - Prediction completed in 0.04s
2024-12-27 19:31:31,860 - INFO - Poison rate 0.05 completed in 9.84s
2024-12-27 19:31:31,860 - INFO - 
Processing poison rate: 0.07
2024-12-27 19:31:31,885 - INFO - Total number of labels flipped: 1382
2024-12-27 19:31:31,885 - INFO - Label flipping completed in 0.03s
2024-12-27 19:31:31,885 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:31:31,886 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:31:33,829 - INFO - Feature scaling completed in 1.94s
2024-12-27 19:31:33,829 - INFO - Starting feature selection (k=50)
2024-12-27 19:31:33,879 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 19:31:33,879 - INFO - Starting anomaly detection
2024-12-27 19:31:41,829 - INFO - Anomaly detection completed in 7.95s
2024-12-27 19:31:41,829 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:31:41,829 - INFO - Total fit_transform time: 9.94s
2024-12-27 19:31:41,830 - INFO - Training set processing completed in 9.94s
2024-12-27 19:31:41,830 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 19:31:41,832 - INFO - Memory usage at start_fit: CPU 3015.7 MB, GPU 48.1 MB
2024-12-27 19:31:41,832 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:31:41,833 - INFO - Number of unique classes: 43
2024-12-27 19:31:42,181 - INFO - Fitted scaler and transformed data
2024-12-27 19:31:42,182 - INFO - Scaling time: 0.35s
2024-12-27 19:31:42,683 - INFO - Epoch 1/200, Train Loss: 2.2982, Val Loss: 1.8473
2024-12-27 19:31:43,203 - INFO - Epoch 2/200, Train Loss: 1.4057, Val Loss: 2.0447
2024-12-27 19:31:43,704 - INFO - Epoch 3/200, Train Loss: 1.1757, Val Loss: 2.1203
2024-12-27 19:31:43,704 - INFO - Early stopping triggered at epoch 3
2024-12-27 19:31:43,704 - INFO - Training completed in 1.87s
2024-12-27 19:31:43,705 - INFO - Final memory usage: CPU 3113.4 MB, GPU 48.4 MB
2024-12-27 19:31:43,705 - INFO - Model training completed in 1.88s
2024-12-27 19:31:43,735 - INFO - Prediction completed in 0.03s
2024-12-27 19:31:43,746 - INFO - Poison rate 0.07 completed in 11.89s
2024-12-27 19:31:43,747 - INFO - 
Processing poison rate: 0.1
2024-12-27 19:31:43,809 - INFO - Total number of labels flipped: 1975
2024-12-27 19:31:43,810 - INFO - Label flipping completed in 0.06s
2024-12-27 19:31:43,810 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:31:43,810 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:31:45,791 - INFO - Feature scaling completed in 1.98s
2024-12-27 19:31:45,791 - INFO - Starting feature selection (k=50)
2024-12-27 19:31:45,841 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 19:31:45,841 - INFO - Starting anomaly detection
2024-12-27 19:31:51,271 - INFO - Anomaly detection completed in 5.43s
2024-12-27 19:31:51,271 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:31:51,271 - INFO - Total fit_transform time: 7.46s
2024-12-27 19:31:51,272 - INFO - Training set processing completed in 7.46s
2024-12-27 19:31:51,272 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 19:31:51,273 - INFO - Memory usage at start_fit: CPU 3016.9 MB, GPU 48.1 MB
2024-12-27 19:31:51,273 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:31:51,275 - INFO - Number of unique classes: 43
2024-12-27 19:31:51,634 - INFO - Fitted scaler and transformed data
2024-12-27 19:31:51,635 - INFO - Scaling time: 0.36s
2024-12-27 19:31:52,116 - INFO - Epoch 1/200, Train Loss: 2.5857, Val Loss: 2.4243
2024-12-27 19:31:52,592 - INFO - Epoch 2/200, Train Loss: 1.6635, Val Loss: 2.4337
2024-12-27 19:31:53,050 - INFO - Epoch 3/200, Train Loss: 1.4395, Val Loss: 2.7312
2024-12-27 19:31:53,051 - INFO - Early stopping triggered at epoch 3
2024-12-27 19:31:53,051 - INFO - Training completed in 1.78s
2024-12-27 19:31:53,051 - INFO - Final memory usage: CPU 3113.4 MB, GPU 48.4 MB
2024-12-27 19:31:53,052 - INFO - Model training completed in 1.78s
2024-12-27 19:31:53,088 - INFO - Prediction completed in 0.04s
2024-12-27 19:31:53,099 - INFO - Poison rate 0.1 completed in 9.35s
2024-12-27 19:31:53,099 - INFO - 
Processing poison rate: 0.2
2024-12-27 19:31:53,167 - INFO - Total number of labels flipped: 3951
2024-12-27 19:31:53,167 - INFO - Label flipping completed in 0.07s
2024-12-27 19:31:53,167 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:31:53,167 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:31:55,010 - INFO - Feature scaling completed in 1.84s
2024-12-27 19:31:55,010 - INFO - Starting feature selection (k=50)
2024-12-27 19:31:55,060 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 19:31:55,060 - INFO - Starting anomaly detection
2024-12-27 19:32:02,430 - INFO - Anomaly detection completed in 7.37s
2024-12-27 19:32:02,431 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:32:02,431 - INFO - Total fit_transform time: 9.26s
2024-12-27 19:32:02,431 - INFO - Training set processing completed in 9.26s
2024-12-27 19:32:02,431 - INFO - Fitting LogisticRegressionWrapper model with data shape: (19755, 1280)
2024-12-27 19:32:02,433 - INFO - Memory usage at start_fit: CPU 3016.9 MB, GPU 48.1 MB
2024-12-27 19:32:02,433 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:32:02,435 - INFO - Number of unique classes: 43
2024-12-27 19:32:02,790 - INFO - Fitted scaler and transformed data
2024-12-27 19:32:02,791 - INFO - Scaling time: 0.35s
2024-12-27 19:32:03,560 - INFO - Epoch 1/200, Train Loss: 3.3077, Val Loss: 3.1925
2024-12-27 19:32:04,411 - INFO - Epoch 2/200, Train Loss: 2.4239, Val Loss: 3.4859
2024-12-27 19:32:05,258 - INFO - Epoch 3/200, Train Loss: 2.1553, Val Loss: 3.7230
2024-12-27 19:32:05,258 - INFO - Early stopping triggered at epoch 3
2024-12-27 19:32:05,258 - INFO - Training completed in 2.83s
2024-12-27 19:32:05,259 - INFO - Final memory usage: CPU 3114.7 MB, GPU 48.4 MB
2024-12-27 19:32:05,260 - INFO - Model training completed in 2.83s
2024-12-27 19:32:05,311 - INFO - Prediction completed in 0.05s
2024-12-27 19:32:05,322 - INFO - Poison rate 0.2 completed in 12.22s
2024-12-27 19:32:05,323 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 19:32:05,323 - INFO - Total evaluation time: 114.29s
2024-12-27 19:32:05,330 - INFO - 
Progress: 30.2% - Evaluating GTSRB with RandomForest (standard mode, iteration 1/1)
2024-12-27 19:32:05,389 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 19:32:05,461 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 19:32:05,559 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 19:32:05,560 - INFO - Dataset type: image
2024-12-27 19:32:05,560 - INFO - Sample size: 39209
2024-12-27 19:32:05,560 - INFO - Using device: cuda
2024-12-27 19:32:05,560 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 19:32:05,565 - INFO - Loading datasets...
2024-12-27 19:32:22,885 - INFO - Dataset loading completed in 17.32s
2024-12-27 19:32:22,885 - INFO - Extracting validation features...
2024-12-27 19:32:22,885 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:30,  4.47it/s]Extracting features:   2%|▏         | 3/139 [00:00<00:14,  9.38it/s]Extracting features:   4%|▎         | 5/139 [00:00<00:11, 12.00it/s]Extracting features:   8%|▊         | 11/139 [00:00<00:04, 26.66it/s]Extracting features:  12%|█▏        | 17/139 [00:00<00:03, 35.51it/s]Extracting features:  17%|█▋        | 23/139 [00:00<00:02, 42.13it/s]Extracting features:  21%|██        | 29/139 [00:00<00:02, 47.33it/s]Extracting features:  26%|██▌       | 36/139 [00:01<00:01, 52.98it/s]Extracting features:  30%|███       | 42/139 [00:01<00:01, 52.95it/s]Extracting features:  35%|███▌      | 49/139 [00:01<00:01, 55.95it/s]Extracting features:  40%|███▉      | 55/139 [00:01<00:01, 56.75it/s]Extracting features:  45%|████▍     | 62/139 [00:01<00:01, 59.27it/s]Extracting features:  49%|████▉     | 68/139 [00:01<00:01, 52.22it/s]Extracting features:  53%|█████▎    | 74/139 [00:01<00:01, 53.51it/s]Extracting features:  58%|█████▊    | 80/139 [00:01<00:01, 55.14it/s]Extracting features:  62%|██████▏   | 86/139 [00:01<00:00, 55.06it/s]Extracting features:  66%|██████▌   | 92/139 [00:02<00:00, 54.28it/s]Extracting features:  71%|███████   | 98/139 [00:02<00:00, 55.44it/s]Extracting features:  75%|███████▍  | 104/139 [00:02<00:00, 56.68it/s]Extracting features:  80%|███████▉  | 111/139 [00:02<00:00, 58.26it/s]Extracting features:  84%|████████▍ | 117/139 [00:02<00:00, 58.41it/s]Extracting features:  88%|████████▊ | 123/139 [00:02<00:00, 56.29it/s]Extracting features:  93%|█████████▎| 129/139 [00:02<00:00, 51.11it/s]Extracting features:  97%|█████████▋| 135/139 [00:02<00:00, 50.57it/s]Extracting features: 100%|██████████| 139/139 [00:02<00:00, 47.32it/s]
2024-12-27 19:32:25,836 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 19:32:25,837 - INFO - Validation feature extraction completed in 2.95s
2024-12-27 19:32:25,837 - INFO - Extracting training features...
2024-12-27 19:32:25,837 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<02:11,  4.68it/s]Extracting features:   1%|          | 6/618 [00:00<00:28, 21.80it/s]Extracting features:   2%|▏         | 11/618 [00:00<00:19, 30.83it/s]Extracting features:   3%|▎         | 16/618 [00:00<00:16, 36.81it/s]Extracting features:   4%|▎         | 23/618 [00:00<00:13, 45.18it/s]Extracting features:   5%|▍         | 30/618 [00:00<00:11, 51.60it/s]Extracting features:   6%|▌         | 37/618 [00:00<00:10, 54.52it/s]Extracting features:   7%|▋         | 43/618 [00:00<00:10, 56.01it/s]Extracting features:   8%|▊         | 49/618 [00:01<00:11, 50.98it/s]Extracting features:   9%|▉         | 55/618 [00:01<00:12, 45.90it/s]Extracting features:  10%|▉         | 60/618 [00:01<00:12, 44.19it/s]Extracting features:  11%|█         | 66/618 [00:01<00:11, 47.25it/s]Extracting features:  12%|█▏        | 72/618 [00:01<00:11, 49.54it/s]Extracting features:  13%|█▎        | 78/618 [00:01<00:10, 50.83it/s]Extracting features:  14%|█▎        | 84/618 [00:01<00:10, 52.89it/s]Extracting features:  15%|█▍        | 90/618 [00:01<00:10, 49.75it/s]Extracting features:  16%|█▌        | 96/618 [00:02<00:10, 47.95it/s]Extracting features:  16%|█▋        | 101/618 [00:02<00:10, 47.01it/s]Extracting features:  17%|█▋        | 106/618 [00:02<00:11, 44.54it/s]Extracting features:  18%|█▊        | 111/618 [00:02<00:11, 45.90it/s]Extracting features:  19%|█▉        | 116/618 [00:02<00:11, 43.44it/s]Extracting features:  20%|█▉        | 121/618 [00:02<00:11, 43.23it/s]Extracting features:  20%|██        | 126/618 [00:02<00:11, 41.29it/s]Extracting features:  21%|██▏       | 132/618 [00:02<00:10, 45.54it/s]Extracting features:  22%|██▏       | 138/618 [00:03<00:10, 46.11it/s]Extracting features:  23%|██▎       | 143/618 [00:03<00:11, 42.95it/s]Extracting features:  24%|██▍       | 148/618 [00:03<00:11, 42.18it/s]Extracting features:  25%|██▍       | 154/618 [00:03<00:10, 46.39it/s]Extracting features:  26%|██▌       | 160/618 [00:03<00:09, 48.02it/s]Extracting features:  27%|██▋       | 166/618 [00:03<00:09, 48.88it/s]Extracting features:  28%|██▊       | 172/618 [00:03<00:08, 50.86it/s]Extracting features:  29%|██▉       | 178/618 [00:03<00:08, 52.25it/s]Extracting features:  30%|██▉       | 184/618 [00:03<00:08, 53.19it/s]Extracting features:  31%|███       | 190/618 [00:04<00:07, 54.52it/s]Extracting features:  32%|███▏      | 196/618 [00:04<00:08, 49.90it/s]Extracting features:  33%|███▎      | 202/618 [00:04<00:08, 47.48it/s]Extracting features:  34%|███▎      | 208/618 [00:04<00:08, 49.69it/s]Extracting features:  35%|███▍      | 214/618 [00:04<00:08, 50.31it/s]Extracting features:  36%|███▌      | 220/618 [00:04<00:07, 51.02it/s]Extracting features:  37%|███▋      | 226/618 [00:04<00:07, 51.72it/s]Extracting features:  38%|███▊      | 232/618 [00:04<00:07, 51.72it/s]Extracting features:  39%|███▊      | 238/618 [00:05<00:07, 50.35it/s]Extracting features:  40%|███▉      | 245/618 [00:05<00:06, 53.94it/s]Extracting features:  41%|████      | 251/618 [00:05<00:07, 52.33it/s]Extracting features:  42%|████▏     | 257/618 [00:05<00:07, 49.84it/s]Extracting features:  43%|████▎     | 263/618 [00:05<00:06, 51.35it/s]Extracting features:  44%|████▎     | 269/618 [00:05<00:06, 52.55it/s]Extracting features:  45%|████▍     | 276/618 [00:05<00:06, 55.19it/s]Extracting features:  46%|████▌     | 282/618 [00:05<00:06, 51.51it/s]Extracting features:  47%|████▋     | 289/618 [00:06<00:06, 54.21it/s]Extracting features:  48%|████▊     | 295/618 [00:06<00:06, 53.74it/s]Extracting features:  49%|████▊     | 301/618 [00:06<00:06, 50.70it/s]Extracting features:  50%|████▉     | 307/618 [00:06<00:06, 50.34it/s]Extracting features:  51%|█████     | 313/618 [00:06<00:06, 46.54it/s]Extracting features:  51%|█████▏    | 318/618 [00:06<00:06, 46.24it/s]Extracting features:  52%|█████▏    | 324/618 [00:06<00:06, 48.99it/s]Extracting features:  54%|█████▎    | 331/618 [00:06<00:05, 53.71it/s]Extracting features:  55%|█████▍    | 338/618 [00:06<00:04, 56.45it/s]Extracting features:  56%|█████▌    | 344/618 [00:07<00:04, 54.92it/s]Extracting features:  57%|█████▋    | 350/618 [00:07<00:05, 51.88it/s]Extracting features:  58%|█████▊    | 356/618 [00:07<00:05, 45.50it/s]Extracting features:  59%|█████▊    | 362/618 [00:07<00:05, 46.50it/s]Extracting features:  59%|█████▉    | 367/618 [00:07<00:05, 47.13it/s]Extracting features:  60%|██████    | 372/618 [00:07<00:05, 46.74it/s]Extracting features:  61%|██████    | 378/618 [00:07<00:04, 48.72it/s]Extracting features:  62%|██████▏   | 384/618 [00:07<00:04, 51.13it/s]Extracting features:  63%|██████▎   | 390/618 [00:08<00:04, 51.03it/s]Extracting features:  64%|██████▍   | 396/618 [00:08<00:04, 52.60it/s]Extracting features:  65%|██████▌   | 402/618 [00:08<00:04, 51.18it/s]Extracting features:  66%|██████▌   | 409/618 [00:08<00:03, 54.33it/s]Extracting features:  67%|██████▋   | 415/618 [00:08<00:03, 53.68it/s]Extracting features:  68%|██████▊   | 421/618 [00:08<00:03, 49.85it/s]Extracting features:  69%|██████▉   | 427/618 [00:08<00:03, 48.59it/s]Extracting features:  70%|███████   | 433/618 [00:08<00:03, 49.37it/s]Extracting features:  71%|███████   | 439/618 [00:09<00:03, 48.92it/s]Extracting features:  72%|███████▏  | 445/618 [00:09<00:03, 51.35it/s]Extracting features:  73%|███████▎  | 451/618 [00:09<00:03, 51.70it/s]Extracting features:  74%|███████▍  | 457/618 [00:09<00:03, 50.29it/s]Extracting features:  75%|███████▍  | 463/618 [00:09<00:03, 51.54it/s]Extracting features:  76%|███████▌  | 469/618 [00:09<00:02, 53.60it/s]Extracting features:  77%|███████▋  | 475/618 [00:09<00:03, 46.98it/s]Extracting features:  78%|███████▊  | 481/618 [00:09<00:02, 49.92it/s]Extracting features:  79%|███████▉  | 488/618 [00:09<00:02, 54.80it/s]Extracting features:  80%|███████▉  | 494/618 [00:10<00:02, 55.58it/s]Extracting features:  81%|████████  | 500/618 [00:10<00:02, 56.20it/s]Extracting features:  82%|████████▏ | 506/618 [00:10<00:02, 52.60it/s]Extracting features:  83%|████████▎ | 512/618 [00:10<00:01, 53.89it/s]Extracting features:  84%|████████▍ | 518/618 [00:10<00:01, 54.82it/s]Extracting features:  85%|████████▍ | 524/618 [00:10<00:01, 55.54it/s]Extracting features:  86%|████████▌ | 531/618 [00:10<00:01, 57.73it/s]Extracting features:  87%|████████▋ | 538/618 [00:10<00:01, 60.35it/s]Extracting features:  88%|████████▊ | 545/618 [00:10<00:01, 59.05it/s]Extracting features:  89%|████████▉ | 552/618 [00:11<00:01, 59.16it/s]Extracting features:  90%|█████████ | 558/618 [00:11<00:01, 53.90it/s]Extracting features:  91%|█████████▏| 564/618 [00:11<00:00, 55.13it/s]Extracting features:  92%|█████████▏| 571/618 [00:11<00:00, 57.75it/s]Extracting features:  93%|█████████▎| 577/618 [00:11<00:00, 55.05it/s]Extracting features:  94%|█████████▍| 583/618 [00:11<00:00, 56.31it/s]Extracting features:  95%|█████████▌| 589/618 [00:11<00:00, 54.15it/s]Extracting features:  96%|█████████▋| 595/618 [00:11<00:00, 53.67it/s]Extracting features:  97%|█████████▋| 601/618 [00:11<00:00, 54.05it/s]Extracting features:  98%|█████████▊| 607/618 [00:12<00:00, 54.75it/s]Extracting features:  99%|█████████▉| 613/618 [00:12<00:00, 55.14it/s]Extracting features: 100%|██████████| 618/618 [00:12<00:00, 49.89it/s]
2024-12-27 19:32:38,265 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 19:32:38,266 - INFO - Training feature extraction completed in 12.43s
2024-12-27 19:32:38,266 - INFO - Creating model for classifier: RandomForest
2024-12-27 19:32:38,266 - INFO - Using device: cuda
2024-12-27 19:32:38,266 - INFO - 
Processing poison rate: 0.0
2024-12-27 19:32:38,266 - INFO - Training set processing completed in 0.00s
2024-12-27 19:32:38,266 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 19:32:38,268 - INFO - Memory usage at start_fit: CPU 3016.9 MB, GPU 47.3 MB
2024-12-27 19:32:38,268 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:32:38,558 - INFO - Fitted scaler and transformed data
2024-12-27 19:32:38,558 - INFO - Scaling time: 0.29s
2024-12-27 19:32:38,573 - INFO - Number of unique classes: 43
2024-12-27 19:32:51,068 - INFO - Epoch 1/15, Train Loss: 3.7580, Val Loss: 3.7541
2024-12-27 19:33:02,729 - INFO - Epoch 2/15, Train Loss: 3.7483, Val Loss: 3.7450
2024-12-27 19:33:16,421 - INFO - Epoch 3/15, Train Loss: 3.7368, Val Loss: 3.7345
2024-12-27 19:33:29,135 - INFO - Epoch 4/15, Train Loss: 3.7237, Val Loss: 3.7233
2024-12-27 19:33:39,901 - INFO - Epoch 5/15, Train Loss: 3.7101, Val Loss: 3.7126
2024-12-27 19:33:52,101 - INFO - Epoch 6/15, Train Loss: 3.6975, Val Loss: 3.7034
2024-12-27 19:34:02,904 - INFO - Epoch 7/15, Train Loss: 3.6865, Val Loss: 3.6959
2024-12-27 19:34:14,589 - INFO - Epoch 8/15, Train Loss: 3.6776, Val Loss: 3.6899
2024-12-27 19:34:28,488 - INFO - Epoch 9/15, Train Loss: 3.6703, Val Loss: 3.6852
2024-12-27 19:34:42,433 - INFO - Epoch 10/15, Train Loss: 3.6645, Val Loss: 3.6814
2024-12-27 19:34:55,769 - INFO - Epoch 11/15, Train Loss: 3.6600, Val Loss: 3.6784
2024-12-27 19:34:55,769 - INFO - Early stopping triggered at epoch 11
2024-12-27 19:34:55,769 - INFO - Training completed in 137.50s
2024-12-27 19:34:55,769 - INFO - Final memory usage: CPU 3022.1 MB, GPU 155.0 MB
2024-12-27 19:34:55,770 - INFO - Model training completed in 137.50s
2024-12-27 19:34:56,039 - INFO - Prediction completed in 0.27s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:34:56,068 - INFO - Poison rate 0.0 completed in 137.80s
2024-12-27 19:34:56,068 - INFO - 
Processing poison rate: 0.01
2024-12-27 19:34:56,078 - INFO - Total number of labels flipped: 197
2024-12-27 19:34:56,079 - INFO - Label flipping completed in 0.01s
2024-12-27 19:34:56,079 - INFO - Training set processing completed in 0.00s
2024-12-27 19:34:56,079 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 19:34:56,080 - INFO - Memory usage at start_fit: CPU 3022.1 MB, GPU 55.8 MB
2024-12-27 19:34:56,080 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:34:56,347 - INFO - Fitted scaler and transformed data
2024-12-27 19:34:56,348 - INFO - Scaling time: 0.27s
2024-12-27 19:34:56,383 - INFO - Number of unique classes: 43
2024-12-27 19:35:10,172 - INFO - Epoch 1/15, Train Loss: 3.7580, Val Loss: 3.7541
2024-12-27 19:35:22,793 - INFO - Epoch 2/15, Train Loss: 3.7485, Val Loss: 3.7449
2024-12-27 19:35:35,684 - INFO - Epoch 3/15, Train Loss: 3.7370, Val Loss: 3.7342
2024-12-27 19:35:48,346 - INFO - Epoch 4/15, Train Loss: 3.7239, Val Loss: 3.7226
2024-12-27 19:36:00,967 - INFO - Epoch 5/15, Train Loss: 3.7103, Val Loss: 3.7115
2024-12-27 19:36:13,968 - INFO - Epoch 6/15, Train Loss: 3.6977, Val Loss: 3.7019
2024-12-27 19:36:25,827 - INFO - Epoch 7/15, Train Loss: 3.6868, Val Loss: 3.6939
2024-12-27 19:36:38,337 - INFO - Epoch 8/15, Train Loss: 3.6779, Val Loss: 3.6876
2024-12-27 19:36:50,225 - INFO - Epoch 9/15, Train Loss: 3.6707, Val Loss: 3.6825
2024-12-27 19:37:03,086 - INFO - Epoch 10/15, Train Loss: 3.6650, Val Loss: 3.6785
2024-12-27 19:37:14,576 - INFO - Epoch 11/15, Train Loss: 3.6602, Val Loss: 3.6753
2024-12-27 19:37:14,576 - INFO - Early stopping triggered at epoch 11
2024-12-27 19:37:14,576 - INFO - Training completed in 138.50s
2024-12-27 19:37:14,577 - INFO - Final memory usage: CPU 3022.1 MB, GPU 155.0 MB
2024-12-27 19:37:14,577 - INFO - Model training completed in 138.50s
2024-12-27 19:37:14,713 - INFO - Prediction completed in 0.14s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:37:14,725 - INFO - Poison rate 0.01 completed in 138.66s
2024-12-27 19:37:14,725 - INFO - 
Processing poison rate: 0.03
2024-12-27 19:37:14,737 - INFO - Total number of labels flipped: 592
2024-12-27 19:37:14,737 - INFO - Label flipping completed in 0.01s
2024-12-27 19:37:14,738 - INFO - Training set processing completed in 0.00s
2024-12-27 19:37:14,738 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 19:37:14,738 - INFO - Memory usage at start_fit: CPU 3022.1 MB, GPU 55.8 MB
2024-12-27 19:37:14,738 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:37:15,003 - INFO - Fitted scaler and transformed data
2024-12-27 19:37:15,003 - INFO - Scaling time: 0.26s
2024-12-27 19:37:15,039 - INFO - Number of unique classes: 43
2024-12-27 19:37:27,569 - INFO - Epoch 1/15, Train Loss: 3.7582, Val Loss: 3.7546
2024-12-27 19:37:39,974 - INFO - Epoch 2/15, Train Loss: 3.7490, Val Loss: 3.7460
2024-12-27 19:37:53,332 - INFO - Epoch 3/15, Train Loss: 3.7381, Val Loss: 3.7360
2024-12-27 19:38:06,161 - INFO - Epoch 4/15, Train Loss: 3.7257, Val Loss: 3.7250
2024-12-27 19:38:20,030 - INFO - Epoch 5/15, Train Loss: 3.7127, Val Loss: 3.7142
2024-12-27 19:38:31,700 - INFO - Epoch 6/15, Train Loss: 3.7004, Val Loss: 3.7048
2024-12-27 19:38:44,461 - INFO - Epoch 7/15, Train Loss: 3.6897, Val Loss: 3.6970
2024-12-27 19:38:55,938 - INFO - Epoch 8/15, Train Loss: 3.6809, Val Loss: 3.6908
2024-12-27 19:39:07,863 - INFO - Epoch 9/15, Train Loss: 3.6738, Val Loss: 3.6858
2024-12-27 19:39:21,011 - INFO - Epoch 10/15, Train Loss: 3.6678, Val Loss: 3.6819
2024-12-27 19:39:33,825 - INFO - Epoch 11/15, Train Loss: 3.6632, Val Loss: 3.6788
2024-12-27 19:39:33,825 - INFO - Early stopping triggered at epoch 11
2024-12-27 19:39:33,825 - INFO - Training completed in 139.09s
2024-12-27 19:39:33,825 - INFO - Final memory usage: CPU 3022.1 MB, GPU 155.0 MB
2024-12-27 19:39:33,826 - INFO - Model training completed in 139.09s
2024-12-27 19:39:34,068 - INFO - Prediction completed in 0.24s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:39:34,080 - INFO - Poison rate 0.03 completed in 139.35s
2024-12-27 19:39:34,080 - INFO - 
Processing poison rate: 0.05
2024-12-27 19:39:34,099 - INFO - Total number of labels flipped: 987
2024-12-27 19:39:34,099 - INFO - Label flipping completed in 0.02s
2024-12-27 19:39:34,099 - INFO - Training set processing completed in 0.00s
2024-12-27 19:39:34,099 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 19:39:34,100 - INFO - Memory usage at start_fit: CPU 3022.1 MB, GPU 55.8 MB
2024-12-27 19:39:34,100 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:39:34,383 - INFO - Fitted scaler and transformed data
2024-12-27 19:39:34,383 - INFO - Scaling time: 0.28s
2024-12-27 19:39:34,418 - INFO - Number of unique classes: 43
2024-12-27 19:39:46,210 - INFO - Epoch 1/15, Train Loss: 3.7583, Val Loss: 3.7549
2024-12-27 19:39:58,745 - INFO - Epoch 2/15, Train Loss: 3.7495, Val Loss: 3.7467
2024-12-27 19:40:11,536 - INFO - Epoch 3/15, Train Loss: 3.7391, Val Loss: 3.7372
2024-12-27 19:40:24,090 - INFO - Epoch 4/15, Train Loss: 3.7272, Val Loss: 3.7268
2024-12-27 19:40:35,867 - INFO - Epoch 5/15, Train Loss: 3.7147, Val Loss: 3.7167
2024-12-27 19:40:49,054 - INFO - Epoch 6/15, Train Loss: 3.7028, Val Loss: 3.7078
2024-12-27 19:41:01,126 - INFO - Epoch 7/15, Train Loss: 3.6925, Val Loss: 3.7005
2024-12-27 19:41:14,193 - INFO - Epoch 8/15, Train Loss: 3.6838, Val Loss: 3.6946
2024-12-27 19:41:25,897 - INFO - Epoch 9/15, Train Loss: 3.6768, Val Loss: 3.6899
2024-12-27 19:41:38,323 - INFO - Epoch 10/15, Train Loss: 3.6711, Val Loss: 3.6862
2024-12-27 19:41:51,643 - INFO - Epoch 11/15, Train Loss: 3.6663, Val Loss: 3.6833
2024-12-27 19:41:51,643 - INFO - Early stopping triggered at epoch 11
2024-12-27 19:41:51,643 - INFO - Training completed in 137.54s
2024-12-27 19:41:51,644 - INFO - Final memory usage: CPU 3022.1 MB, GPU 155.0 MB
2024-12-27 19:41:51,644 - INFO - Model training completed in 137.55s
2024-12-27 19:41:51,779 - INFO - Prediction completed in 0.13s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:41:51,791 - INFO - Poison rate 0.05 completed in 137.71s
2024-12-27 19:41:51,791 - INFO - 
Processing poison rate: 0.07
2024-12-27 19:41:51,816 - INFO - Total number of labels flipped: 1382
2024-12-27 19:41:51,816 - INFO - Label flipping completed in 0.03s
2024-12-27 19:41:51,816 - INFO - Training set processing completed in 0.00s
2024-12-27 19:41:51,816 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 19:41:51,817 - INFO - Memory usage at start_fit: CPU 3022.1 MB, GPU 55.8 MB
2024-12-27 19:41:51,817 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:41:52,076 - INFO - Fitted scaler and transformed data
2024-12-27 19:41:52,076 - INFO - Scaling time: 0.26s
2024-12-27 19:41:52,112 - INFO - Number of unique classes: 43
2024-12-27 19:42:04,185 - INFO - Epoch 1/15, Train Loss: 3.7584, Val Loss: 3.7553
2024-12-27 19:42:16,126 - INFO - Epoch 2/15, Train Loss: 3.7501, Val Loss: 3.7478
2024-12-27 19:42:29,632 - INFO - Epoch 3/15, Train Loss: 3.7402, Val Loss: 3.7391
2024-12-27 19:42:41,515 - INFO - Epoch 4/15, Train Loss: 3.7289, Val Loss: 3.7293
2024-12-27 19:42:55,183 - INFO - Epoch 5/15, Train Loss: 3.7167, Val Loss: 3.7196
2024-12-27 19:43:07,104 - INFO - Epoch 6/15, Train Loss: 3.7050, Val Loss: 3.7109
2024-12-27 19:43:20,352 - INFO - Epoch 7/15, Train Loss: 3.6948, Val Loss: 3.7036
2024-12-27 19:43:33,916 - INFO - Epoch 8/15, Train Loss: 3.6860, Val Loss: 3.6978
2024-12-27 19:43:47,399 - INFO - Epoch 9/15, Train Loss: 3.6790, Val Loss: 3.6931
2024-12-27 19:43:59,925 - INFO - Epoch 10/15, Train Loss: 3.6733, Val Loss: 3.6894
2024-12-27 19:44:12,120 - INFO - Epoch 11/15, Train Loss: 3.6686, Val Loss: 3.6864
2024-12-27 19:44:12,121 - INFO - Early stopping triggered at epoch 11
2024-12-27 19:44:12,121 - INFO - Training completed in 140.30s
2024-12-27 19:44:12,121 - INFO - Final memory usage: CPU 3022.1 MB, GPU 155.0 MB
2024-12-27 19:44:12,121 - INFO - Model training completed in 140.31s
2024-12-27 19:44:12,257 - INFO - Prediction completed in 0.14s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:44:12,269 - INFO - Poison rate 0.07 completed in 140.48s
2024-12-27 19:44:12,269 - INFO - 
Processing poison rate: 0.1
2024-12-27 19:44:12,306 - INFO - Total number of labels flipped: 1975
2024-12-27 19:44:12,306 - INFO - Label flipping completed in 0.04s
2024-12-27 19:44:12,306 - INFO - Training set processing completed in 0.00s
2024-12-27 19:44:12,306 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 19:44:12,307 - INFO - Memory usage at start_fit: CPU 3022.1 MB, GPU 55.8 MB
2024-12-27 19:44:12,307 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:44:12,612 - INFO - Fitted scaler and transformed data
2024-12-27 19:44:12,612 - INFO - Scaling time: 0.31s
2024-12-27 19:44:12,647 - INFO - Number of unique classes: 43
2024-12-27 19:44:25,450 - INFO - Epoch 1/15, Train Loss: 3.7585, Val Loss: 3.7554
2024-12-27 19:44:37,048 - INFO - Epoch 2/15, Train Loss: 3.7504, Val Loss: 3.7481
2024-12-27 19:44:51,574 - INFO - Epoch 3/15, Train Loss: 3.7407, Val Loss: 3.7393
2024-12-27 19:45:02,829 - INFO - Epoch 4/15, Train Loss: 3.7296, Val Loss: 3.7298
2024-12-27 19:45:15,355 - INFO - Epoch 5/15, Train Loss: 3.7178, Val Loss: 3.7203
2024-12-27 19:45:25,861 - INFO - Epoch 6/15, Train Loss: 3.7065, Val Loss: 3.7119
2024-12-27 19:45:38,691 - INFO - Epoch 7/15, Train Loss: 3.6964, Val Loss: 3.7049
2024-12-27 19:45:49,607 - INFO - Epoch 8/15, Train Loss: 3.6881, Val Loss: 3.6992
2024-12-27 19:46:02,809 - INFO - Epoch 9/15, Train Loss: 3.6810, Val Loss: 3.6947
2024-12-27 19:46:13,763 - INFO - Epoch 10/15, Train Loss: 3.6754, Val Loss: 3.6911
2024-12-27 19:46:25,705 - INFO - Epoch 11/15, Train Loss: 3.6707, Val Loss: 3.6882
2024-12-27 19:46:25,705 - INFO - Early stopping triggered at epoch 11
2024-12-27 19:46:25,705 - INFO - Training completed in 133.40s
2024-12-27 19:46:25,705 - INFO - Final memory usage: CPU 3022.1 MB, GPU 155.0 MB
2024-12-27 19:46:25,706 - INFO - Model training completed in 133.40s
2024-12-27 19:46:25,853 - INFO - Prediction completed in 0.15s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:46:25,866 - INFO - Poison rate 0.1 completed in 133.60s
2024-12-27 19:46:25,866 - INFO - 
Processing poison rate: 0.2
2024-12-27 19:46:25,937 - INFO - Total number of labels flipped: 3951
2024-12-27 19:46:25,937 - INFO - Label flipping completed in 0.07s
2024-12-27 19:46:25,937 - INFO - Training set processing completed in 0.00s
2024-12-27 19:46:25,937 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 19:46:25,939 - INFO - Memory usage at start_fit: CPU 3022.1 MB, GPU 55.8 MB
2024-12-27 19:46:25,939 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:46:26,234 - INFO - Fitted scaler and transformed data
2024-12-27 19:46:26,234 - INFO - Scaling time: 0.29s
2024-12-27 19:46:26,269 - INFO - Number of unique classes: 43
2024-12-27 19:46:37,640 - INFO - Epoch 1/15, Train Loss: 3.7592, Val Loss: 3.7568
2024-12-27 19:46:49,370 - INFO - Epoch 2/15, Train Loss: 3.7526, Val Loss: 3.7512
2024-12-27 19:47:00,647 - INFO - Epoch 3/15, Train Loss: 3.7449, Val Loss: 3.7445
2024-12-27 19:47:12,382 - INFO - Epoch 4/15, Train Loss: 3.7360, Val Loss: 3.7369
2024-12-27 19:47:24,904 - INFO - Epoch 5/15, Train Loss: 3.7262, Val Loss: 3.7289
2024-12-27 19:47:37,410 - INFO - Epoch 6/15, Train Loss: 3.7164, Val Loss: 3.7213
2024-12-27 19:47:49,150 - INFO - Epoch 7/15, Train Loss: 3.7075, Val Loss: 3.7148
2024-12-27 19:48:01,784 - INFO - Epoch 8/15, Train Loss: 3.6995, Val Loss: 3.7095
2024-12-27 19:48:14,272 - INFO - Epoch 9/15, Train Loss: 3.6931, Val Loss: 3.7051
2024-12-27 19:48:14,272 - INFO - Early stopping triggered at epoch 9
2024-12-27 19:48:14,272 - INFO - Training completed in 108.33s
2024-12-27 19:48:14,272 - INFO - Final memory usage: CPU 3022.1 MB, GPU 155.0 MB
2024-12-27 19:48:14,273 - INFO - Model training completed in 108.34s
2024-12-27 19:48:14,411 - INFO - Prediction completed in 0.14s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:48:14,423 - INFO - Poison rate 0.2 completed in 108.56s
2024-12-27 19:48:14,424 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 19:48:14,424 - INFO - Total evaluation time: 968.86s
2024-12-27 19:48:14,431 - INFO - 
Progress: 31.2% - Evaluating GTSRB with RandomForest (dynadetect mode, iteration 1/1)
2024-12-27 19:48:14,490 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 19:48:14,697 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 19:48:14,821 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 19:48:14,821 - INFO - Dataset type: image
2024-12-27 19:48:14,821 - INFO - Sample size: 39209
2024-12-27 19:48:14,821 - INFO - Using device: cuda
2024-12-27 19:48:14,821 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 19:48:14,824 - INFO - Loading datasets...
2024-12-27 19:48:32,519 - INFO - Dataset loading completed in 17.69s
2024-12-27 19:48:32,519 - INFO - Extracting validation features...
2024-12-27 19:48:32,519 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:31,  4.42it/s]Extracting features:   2%|▏         | 3/139 [00:00<00:15,  8.60it/s]Extracting features:   4%|▍         | 6/139 [00:00<00:10, 13.28it/s]Extracting features:   9%|▊         | 12/139 [00:00<00:04, 25.81it/s]Extracting features:  13%|█▎        | 18/139 [00:00<00:03, 35.43it/s]Extracting features:  17%|█▋        | 24/139 [00:00<00:02, 41.72it/s]Extracting features:  21%|██        | 29/139 [00:00<00:02, 43.54it/s]Extracting features:  25%|██▌       | 35/139 [00:01<00:02, 46.47it/s]Extracting features:  30%|███       | 42/139 [00:01<00:01, 51.01it/s]Extracting features:  35%|███▍      | 48/139 [00:01<00:01, 48.36it/s]Extracting features:  39%|███▉      | 54/139 [00:01<00:01, 50.91it/s]Extracting features:  43%|████▎     | 60/139 [00:01<00:01, 50.90it/s]Extracting features:  48%|████▊     | 67/139 [00:01<00:01, 53.44it/s]Extracting features:  53%|█████▎    | 73/139 [00:01<00:01, 53.35it/s]Extracting features:  58%|█████▊    | 80/139 [00:01<00:01, 55.77it/s]Extracting features:  63%|██████▎   | 87/139 [00:01<00:00, 58.21it/s]Extracting features:  67%|██████▋   | 93/139 [00:02<00:00, 57.47it/s]Extracting features:  71%|███████   | 99/139 [00:02<00:00, 57.08it/s]Extracting features:  76%|███████▋  | 106/139 [00:02<00:00, 58.74it/s]Extracting features:  81%|████████▏ | 113/139 [00:02<00:00, 60.01it/s]Extracting features:  86%|████████▋ | 120/139 [00:02<00:00, 59.47it/s]Extracting features:  91%|█████████ | 126/139 [00:02<00:00, 56.43it/s]Extracting features:  95%|█████████▍| 132/139 [00:02<00:00, 54.88it/s]Extracting features: 100%|██████████| 139/139 [00:02<00:00, 51.25it/s]Extracting features: 100%|██████████| 139/139 [00:03<00:00, 46.33it/s]
2024-12-27 19:48:35,528 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 19:48:35,528 - INFO - Validation feature extraction completed in 3.01s
2024-12-27 19:48:35,529 - INFO - Extracting training features...
2024-12-27 19:48:35,529 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<02:04,  4.94it/s]Extracting features:   1%|▏         | 8/618 [00:00<00:19, 30.93it/s]Extracting features:   2%|▏         | 14/618 [00:00<00:14, 40.64it/s]Extracting features:   3%|▎         | 20/618 [00:00<00:13, 45.01it/s]Extracting features:   4%|▍         | 26/618 [00:00<00:11, 49.53it/s]Extracting features:   5%|▌         | 33/618 [00:00<00:10, 53.35it/s]Extracting features:   6%|▋         | 39/618 [00:00<00:11, 49.75it/s]Extracting features:   7%|▋         | 45/618 [00:01<00:12, 45.94it/s]Extracting features:   8%|▊         | 50/618 [00:01<00:12, 44.32it/s]Extracting features:   9%|▉         | 55/618 [00:01<00:12, 43.32it/s]Extracting features:  10%|▉         | 60/618 [00:01<00:13, 42.50it/s]Extracting features:  11%|█         | 65/618 [00:01<00:13, 41.06it/s]Extracting features:  11%|█▏        | 70/618 [00:01<00:13, 41.74it/s]Extracting features:  12%|█▏        | 75/618 [00:01<00:13, 40.44it/s]Extracting features:  13%|█▎        | 80/618 [00:01<00:12, 42.75it/s]Extracting features:  14%|█▍        | 85/618 [00:02<00:12, 42.05it/s]Extracting features:  15%|█▍        | 90/618 [00:02<00:12, 41.65it/s]Extracting features:  15%|█▌        | 95/618 [00:02<00:12, 41.13it/s]Extracting features:  16%|█▋        | 101/618 [00:02<00:11, 43.84it/s]Extracting features:  17%|█▋        | 106/618 [00:02<00:12, 41.81it/s]Extracting features:  18%|█▊        | 112/618 [00:02<00:11, 44.88it/s]Extracting features:  19%|█▉        | 117/618 [00:02<00:11, 44.02it/s]Extracting features:  20%|█▉        | 122/618 [00:02<00:11, 42.42it/s]Extracting features:  21%|██        | 127/618 [00:03<00:12, 39.98it/s]Extracting features:  21%|██▏       | 132/618 [00:03<00:11, 41.04it/s]Extracting features:  22%|██▏       | 137/618 [00:03<00:11, 42.00it/s]Extracting features:  23%|██▎       | 142/618 [00:03<00:10, 43.52it/s]Extracting features:  24%|██▍       | 149/618 [00:03<00:09, 47.73it/s]Extracting features:  25%|██▍       | 154/618 [00:03<00:10, 43.95it/s]Extracting features:  26%|██▌       | 161/618 [00:03<00:09, 47.83it/s]Extracting features:  27%|██▋       | 166/618 [00:03<00:09, 46.01it/s]Extracting features:  28%|██▊       | 171/618 [00:03<00:09, 46.05it/s]Extracting features:  28%|██▊       | 176/618 [00:04<00:10, 41.79it/s]Extracting features:  29%|██▉       | 181/618 [00:04<00:11, 39.69it/s]Extracting features:  30%|███       | 186/618 [00:04<00:11, 38.04it/s]Extracting features:  31%|███       | 190/618 [00:04<00:11, 36.73it/s]Extracting features:  32%|███▏      | 196/618 [00:04<00:10, 40.90it/s]Extracting features:  33%|███▎      | 201/618 [00:04<00:10, 39.08it/s]Extracting features:  33%|███▎      | 206/618 [00:04<00:10, 39.22it/s]Extracting features:  34%|███▍      | 211/618 [00:05<00:09, 41.26it/s]Extracting features:  35%|███▍      | 216/618 [00:05<00:09, 41.10it/s]Extracting features:  36%|███▌      | 222/618 [00:05<00:09, 43.92it/s]Extracting features:  37%|███▋      | 227/618 [00:05<00:08, 44.49it/s]Extracting features:  38%|███▊      | 232/618 [00:05<00:09, 42.54it/s]Extracting features:  38%|███▊      | 237/618 [00:05<00:09, 41.29it/s]Extracting features:  39%|███▉      | 242/618 [00:05<00:08, 42.67it/s]Extracting features:  40%|███▉      | 247/618 [00:05<00:08, 43.41it/s]Extracting features:  41%|████      | 252/618 [00:05<00:08, 44.36it/s]Extracting features:  42%|████▏     | 257/618 [00:06<00:08, 43.98it/s]Extracting features:  42%|████▏     | 262/618 [00:06<00:08, 43.32it/s]Extracting features:  43%|████▎     | 267/618 [00:06<00:08, 42.35it/s]Extracting features:  44%|████▍     | 272/618 [00:06<00:08, 40.22it/s]Extracting features:  45%|████▍     | 277/618 [00:06<00:08, 41.08it/s]Extracting features:  46%|████▌     | 282/618 [00:06<00:07, 42.81it/s]Extracting features:  46%|████▋     | 287/618 [00:06<00:07, 42.76it/s]Extracting features:  47%|████▋     | 292/618 [00:06<00:07, 41.37it/s]Extracting features:  48%|████▊     | 297/618 [00:07<00:07, 40.48it/s]Extracting features:  49%|████▉     | 303/618 [00:07<00:07, 44.11it/s]Extracting features:  50%|████▉     | 308/618 [00:07<00:07, 44.04it/s]Extracting features:  51%|█████     | 313/618 [00:07<00:07, 41.42it/s]Extracting features:  52%|█████▏    | 319/618 [00:07<00:06, 45.28it/s]Extracting features:  52%|█████▏    | 324/618 [00:07<00:06, 43.58it/s]Extracting features:  53%|█████▎    | 329/618 [00:07<00:07, 39.49it/s]Extracting features:  54%|█████▍    | 334/618 [00:07<00:07, 40.21it/s]Extracting features:  55%|█████▌    | 340/618 [00:08<00:06, 44.20it/s]Extracting features:  56%|█████▌    | 346/618 [00:08<00:05, 46.74it/s]Extracting features:  57%|█████▋    | 351/618 [00:08<00:05, 45.02it/s]Extracting features:  58%|█████▊    | 356/618 [00:08<00:05, 45.11it/s]Extracting features:  58%|█████▊    | 361/618 [00:08<00:06, 42.57it/s]Extracting features:  59%|█████▉    | 366/618 [00:08<00:05, 42.32it/s]Extracting features:  60%|██████    | 372/618 [00:08<00:05, 46.25it/s]Extracting features:  61%|██████    | 378/618 [00:08<00:04, 48.56it/s]Extracting features:  62%|██████▏   | 384/618 [00:08<00:04, 49.27it/s]Extracting features:  63%|██████▎   | 389/618 [00:09<00:05, 45.79it/s]Extracting features:  64%|██████▍   | 394/618 [00:09<00:05, 44.27it/s]Extracting features:  65%|██████▍   | 400/618 [00:09<00:04, 46.12it/s]Extracting features:  66%|██████▌   | 405/618 [00:09<00:04, 47.04it/s]Extracting features:  66%|██████▋   | 410/618 [00:09<00:04, 47.53it/s]Extracting features:  67%|██████▋   | 415/618 [00:09<00:04, 46.51it/s]Extracting features:  68%|██████▊   | 421/618 [00:09<00:04, 48.88it/s]Extracting features:  69%|██████▉   | 427/618 [00:09<00:03, 49.83it/s]Extracting features:  70%|██████▉   | 432/618 [00:09<00:03, 47.11it/s]Extracting features:  71%|███████   | 437/618 [00:10<00:04, 44.67it/s]Extracting features:  72%|███████▏  | 442/618 [00:10<00:03, 45.10it/s]Extracting features:  72%|███████▏  | 447/618 [00:10<00:03, 43.94it/s]Extracting features:  73%|███████▎  | 453/618 [00:10<00:03, 45.29it/s]Extracting features:  74%|███████▍  | 458/618 [00:10<00:03, 46.22it/s]Extracting features:  75%|███████▍  | 463/618 [00:10<00:03, 46.45it/s]Extracting features:  76%|███████▌  | 468/618 [00:10<00:03, 45.95it/s]Extracting features:  77%|███████▋  | 474/618 [00:10<00:03, 47.19it/s]Extracting features:  78%|███████▊  | 481/618 [00:11<00:02, 48.67it/s]Extracting features:  79%|███████▊  | 486/618 [00:11<00:02, 47.49it/s]Extracting features:  79%|███████▉  | 491/618 [00:11<00:03, 40.93it/s]Extracting features:  80%|████████  | 497/618 [00:11<00:02, 43.76it/s]Extracting features:  81%|████████  | 502/618 [00:11<00:02, 44.62it/s]Extracting features:  82%|████████▏ | 507/618 [00:11<00:02, 45.00it/s]Extracting features:  83%|████████▎ | 512/618 [00:11<00:02, 43.12it/s]Extracting features:  84%|████████▎ | 517/618 [00:11<00:02, 44.41it/s]Extracting features:  85%|████████▍ | 523/618 [00:11<00:01, 47.76it/s]Extracting features:  85%|████████▌ | 528/618 [00:12<00:01, 46.14it/s]Extracting features:  86%|████████▌ | 533/618 [00:12<00:01, 46.78it/s]Extracting features:  87%|████████▋ | 538/618 [00:12<00:01, 46.48it/s]Extracting features:  88%|████████▊ | 543/618 [00:12<00:01, 46.09it/s]Extracting features:  89%|████████▊ | 548/618 [00:12<00:01, 45.67it/s]Extracting features:  89%|████████▉ | 553/618 [00:12<00:01, 46.32it/s]Extracting features:  90%|█████████ | 558/618 [00:12<00:01, 47.25it/s]Extracting features:  91%|█████████ | 563/618 [00:12<00:01, 45.79it/s]Extracting features:  92%|█████████▏| 568/618 [00:12<00:01, 44.27it/s]Extracting features:  93%|█████████▎| 573/618 [00:13<00:01, 42.23it/s]Extracting features:  94%|█████████▎| 579/618 [00:13<00:00, 46.60it/s]Extracting features:  94%|█████████▍| 584/618 [00:13<00:00, 44.89it/s]Extracting features:  95%|█████████▌| 590/618 [00:13<00:00, 47.14it/s]Extracting features:  96%|█████████▋| 595/618 [00:13<00:00, 45.17it/s]Extracting features:  97%|█████████▋| 600/618 [00:13<00:00, 45.73it/s]Extracting features:  98%|█████████▊| 606/618 [00:13<00:00, 47.96it/s]Extracting features:  99%|█████████▉| 612/618 [00:13<00:00, 49.87it/s]Extracting features: 100%|██████████| 618/618 [00:14<00:00, 43.95it/s]
2024-12-27 19:48:49,627 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 19:48:49,627 - INFO - Training feature extraction completed in 14.10s
2024-12-27 19:48:49,627 - INFO - Creating model for classifier: RandomForest
2024-12-27 19:48:49,628 - INFO - Using device: cuda
2024-12-27 19:48:49,628 - INFO - 
Processing poison rate: 0.0
2024-12-27 19:48:49,628 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:48:49,628 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:48:51,471 - INFO - Feature scaling completed in 1.84s
2024-12-27 19:48:51,471 - INFO - Starting feature selection (k=50)
2024-12-27 19:48:51,499 - INFO - Feature selection completed in 0.03s. Output shape: (19755, 50)
2024-12-27 19:48:51,500 - INFO - Starting anomaly detection
2024-12-27 19:48:59,995 - INFO - Anomaly detection completed in 8.49s
2024-12-27 19:48:59,995 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:48:59,995 - INFO - Total fit_transform time: 10.37s
2024-12-27 19:48:59,995 - INFO - Training set processing completed in 10.37s
2024-12-27 19:48:59,996 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 19:48:59,997 - INFO - Memory usage at start_fit: CPU 3020.1 MB, GPU 47.3 MB
2024-12-27 19:48:59,997 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:49:00,254 - INFO - Fitted scaler and transformed data
2024-12-27 19:49:00,254 - INFO - Scaling time: 0.26s
2024-12-27 19:49:00,279 - INFO - Number of unique classes: 43
2024-12-27 19:49:13,313 - INFO - Epoch 1/15, Train Loss: 3.5679, Val Loss: 3.7539
2024-12-27 19:49:25,624 - INFO - Epoch 2/15, Train Loss: 3.5586, Val Loss: 3.7444
2024-12-27 19:49:38,123 - INFO - Epoch 3/15, Train Loss: 3.5475, Val Loss: 3.7332
2024-12-27 19:49:48,825 - INFO - Epoch 4/15, Train Loss: 3.5347, Val Loss: 3.7212
2024-12-27 19:50:01,594 - INFO - Epoch 5/15, Train Loss: 3.5213, Val Loss: 3.7095
2024-12-27 19:50:12,020 - INFO - Epoch 6/15, Train Loss: 3.5089, Val Loss: 3.6995
2024-12-27 19:50:24,156 - INFO - Epoch 7/15, Train Loss: 3.4985, Val Loss: 3.6915
2024-12-27 19:50:36,300 - INFO - Epoch 8/15, Train Loss: 3.4898, Val Loss: 3.6851
2024-12-27 19:50:48,481 - INFO - Epoch 9/15, Train Loss: 3.4829, Val Loss: 3.6802
2024-12-27 19:51:01,111 - INFO - Epoch 10/15, Train Loss: 3.4772, Val Loss: 3.6763
2024-12-27 19:51:12,253 - INFO - Epoch 11/15, Train Loss: 3.4728, Val Loss: 3.6731
2024-12-27 19:51:12,253 - INFO - Early stopping triggered at epoch 11
2024-12-27 19:51:12,253 - INFO - Training completed in 132.26s
2024-12-27 19:51:12,253 - INFO - Final memory usage: CPU 3023.1 MB, GPU 155.0 MB
2024-12-27 19:51:12,254 - INFO - Model training completed in 132.26s
2024-12-27 19:51:12,390 - INFO - Prediction completed in 0.14s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:51:12,403 - INFO - Poison rate 0.0 completed in 142.77s
2024-12-27 19:51:12,403 - INFO - 
Processing poison rate: 0.01
2024-12-27 19:51:12,408 - INFO - Total number of labels flipped: 197
2024-12-27 19:51:12,408 - INFO - Label flipping completed in 0.01s
2024-12-27 19:51:12,408 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:51:12,408 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:51:14,233 - INFO - Feature scaling completed in 1.82s
2024-12-27 19:51:14,233 - INFO - Starting feature selection (k=50)
2024-12-27 19:51:14,285 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 19:51:14,285 - INFO - Starting anomaly detection
2024-12-27 19:51:20,199 - INFO - Anomaly detection completed in 5.91s
2024-12-27 19:51:20,199 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:51:20,199 - INFO - Total fit_transform time: 7.79s
2024-12-27 19:51:20,199 - INFO - Training set processing completed in 7.79s
2024-12-27 19:51:20,200 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 19:51:20,200 - INFO - Memory usage at start_fit: CPU 3023.1 MB, GPU 55.8 MB
2024-12-27 19:51:20,200 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:51:20,468 - INFO - Fitted scaler and transformed data
2024-12-27 19:51:20,468 - INFO - Scaling time: 0.27s
2024-12-27 19:51:20,488 - INFO - Number of unique classes: 43
2024-12-27 19:51:34,189 - INFO - Epoch 1/15, Train Loss: 3.5707, Val Loss: 3.7544
2024-12-27 19:51:44,794 - INFO - Epoch 2/15, Train Loss: 3.5618, Val Loss: 3.7455
2024-12-27 19:51:57,372 - INFO - Epoch 3/15, Train Loss: 3.5511, Val Loss: 3.7350
2024-12-27 19:52:09,422 - INFO - Epoch 4/15, Train Loss: 3.5389, Val Loss: 3.7236
2024-12-27 19:52:22,292 - INFO - Epoch 5/15, Train Loss: 3.5263, Val Loss: 3.7126
2024-12-27 19:52:33,710 - INFO - Epoch 6/15, Train Loss: 3.5145, Val Loss: 3.7029
2024-12-27 19:52:45,613 - INFO - Epoch 7/15, Train Loss: 3.5043, Val Loss: 3.6950
2024-12-27 19:52:57,189 - INFO - Epoch 8/15, Train Loss: 3.4957, Val Loss: 3.6887
2024-12-27 19:53:08,820 - INFO - Epoch 9/15, Train Loss: 3.4888, Val Loss: 3.6836
2024-12-27 19:53:22,595 - INFO - Epoch 10/15, Train Loss: 3.4833, Val Loss: 3.6797
2024-12-27 19:53:36,057 - INFO - Epoch 11/15, Train Loss: 3.4787, Val Loss: 3.6765
2024-12-27 19:53:36,058 - INFO - Early stopping triggered at epoch 11
2024-12-27 19:53:36,058 - INFO - Training completed in 135.86s
2024-12-27 19:53:36,058 - INFO - Final memory usage: CPU 3023.1 MB, GPU 155.0 MB
2024-12-27 19:53:36,058 - INFO - Model training completed in 135.86s
2024-12-27 19:53:36,196 - INFO - Prediction completed in 0.14s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:53:36,208 - INFO - Poison rate 0.01 completed in 143.81s
2024-12-27 19:53:36,208 - INFO - 
Processing poison rate: 0.03
2024-12-27 19:53:36,220 - INFO - Total number of labels flipped: 592
2024-12-27 19:53:36,220 - INFO - Label flipping completed in 0.01s
2024-12-27 19:53:36,220 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:53:36,220 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:53:38,198 - INFO - Feature scaling completed in 1.98s
2024-12-27 19:53:38,199 - INFO - Starting feature selection (k=50)
2024-12-27 19:53:38,252 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 19:53:38,252 - INFO - Starting anomaly detection
2024-12-27 19:53:46,248 - INFO - Anomaly detection completed in 7.99s
2024-12-27 19:53:46,248 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:53:46,248 - INFO - Total fit_transform time: 10.03s
2024-12-27 19:53:46,248 - INFO - Training set processing completed in 10.03s
2024-12-27 19:53:46,248 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 19:53:46,249 - INFO - Memory usage at start_fit: CPU 3023.1 MB, GPU 55.8 MB
2024-12-27 19:53:46,249 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:53:46,506 - INFO - Fitted scaler and transformed data
2024-12-27 19:53:46,507 - INFO - Scaling time: 0.26s
2024-12-27 19:53:46,528 - INFO - Number of unique classes: 43
2024-12-27 19:54:00,552 - INFO - Epoch 1/15, Train Loss: 3.5708, Val Loss: 3.7547
2024-12-27 19:54:12,602 - INFO - Epoch 2/15, Train Loss: 3.5621, Val Loss: 3.7463
2024-12-27 19:54:25,363 - INFO - Epoch 3/15, Train Loss: 3.5518, Val Loss: 3.7364
2024-12-27 19:54:36,735 - INFO - Epoch 4/15, Train Loss: 3.5400, Val Loss: 3.7257
2024-12-27 19:54:48,501 - INFO - Epoch 5/15, Train Loss: 3.5278, Val Loss: 3.7154
2024-12-27 19:54:59,732 - INFO - Epoch 6/15, Train Loss: 3.5163, Val Loss: 3.7062
2024-12-27 19:55:11,674 - INFO - Epoch 7/15, Train Loss: 3.5064, Val Loss: 3.6988
2024-12-27 19:55:23,129 - INFO - Epoch 8/15, Train Loss: 3.4982, Val Loss: 3.6928
2024-12-27 19:55:34,306 - INFO - Epoch 9/15, Train Loss: 3.4916, Val Loss: 3.6881
2024-12-27 19:55:46,468 - INFO - Epoch 10/15, Train Loss: 3.4862, Val Loss: 3.6844
2024-12-27 19:55:58,023 - INFO - Epoch 11/15, Train Loss: 3.4816, Val Loss: 3.6814
2024-12-27 19:55:58,024 - INFO - Early stopping triggered at epoch 11
2024-12-27 19:55:58,024 - INFO - Training completed in 131.77s
2024-12-27 19:55:58,024 - INFO - Final memory usage: CPU 3023.1 MB, GPU 155.0 MB
2024-12-27 19:55:58,024 - INFO - Model training completed in 131.78s
2024-12-27 19:55:58,157 - INFO - Prediction completed in 0.13s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:55:58,169 - INFO - Poison rate 0.03 completed in 141.96s
2024-12-27 19:55:58,169 - INFO - 
Processing poison rate: 0.05
2024-12-27 19:55:58,188 - INFO - Total number of labels flipped: 987
2024-12-27 19:55:58,188 - INFO - Label flipping completed in 0.02s
2024-12-27 19:55:58,188 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:55:58,188 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:55:59,999 - INFO - Feature scaling completed in 1.81s
2024-12-27 19:56:00,000 - INFO - Starting feature selection (k=50)
2024-12-27 19:56:00,050 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 19:56:00,050 - INFO - Starting anomaly detection
2024-12-27 19:56:06,564 - INFO - Anomaly detection completed in 6.51s
2024-12-27 19:56:06,564 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:56:06,564 - INFO - Total fit_transform time: 8.38s
2024-12-27 19:56:06,565 - INFO - Training set processing completed in 8.38s
2024-12-27 19:56:06,565 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 19:56:06,566 - INFO - Memory usage at start_fit: CPU 3023.1 MB, GPU 55.8 MB
2024-12-27 19:56:06,566 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:56:06,818 - INFO - Fitted scaler and transformed data
2024-12-27 19:56:06,819 - INFO - Scaling time: 0.25s
2024-12-27 19:56:06,839 - INFO - Number of unique classes: 43
2024-12-27 19:56:17,874 - INFO - Epoch 1/15, Train Loss: 3.5679, Val Loss: 3.7548
2024-12-27 19:56:30,715 - INFO - Epoch 2/15, Train Loss: 3.5597, Val Loss: 3.7465
2024-12-27 19:56:41,861 - INFO - Epoch 3/15, Train Loss: 3.5500, Val Loss: 3.7369
2024-12-27 19:56:54,135 - INFO - Epoch 4/15, Train Loss: 3.5388, Val Loss: 3.7263
2024-12-27 19:57:06,396 - INFO - Epoch 5/15, Train Loss: 3.5271, Val Loss: 3.7159
2024-12-27 19:57:19,494 - INFO - Epoch 6/15, Train Loss: 3.5159, Val Loss: 3.7067
2024-12-27 19:57:31,562 - INFO - Epoch 7/15, Train Loss: 3.5059, Val Loss: 3.6992
2024-12-27 19:57:43,211 - INFO - Epoch 8/15, Train Loss: 3.4977, Val Loss: 3.6930
2024-12-27 19:57:55,690 - INFO - Epoch 9/15, Train Loss: 3.4911, Val Loss: 3.6881
2024-12-27 19:58:07,489 - INFO - Epoch 10/15, Train Loss: 3.4856, Val Loss: 3.6843
2024-12-27 19:58:19,868 - INFO - Epoch 11/15, Train Loss: 3.4812, Val Loss: 3.6812
2024-12-27 19:58:19,868 - INFO - Early stopping triggered at epoch 11
2024-12-27 19:58:19,868 - INFO - Training completed in 133.30s
2024-12-27 19:58:19,868 - INFO - Final memory usage: CPU 3023.1 MB, GPU 155.0 MB
2024-12-27 19:58:19,869 - INFO - Model training completed in 133.30s
2024-12-27 19:58:20,003 - INFO - Prediction completed in 0.13s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 19:58:20,016 - INFO - Poison rate 0.05 completed in 141.85s
2024-12-27 19:58:20,016 - INFO - 
Processing poison rate: 0.07
2024-12-27 19:58:20,041 - INFO - Total number of labels flipped: 1382
2024-12-27 19:58:20,041 - INFO - Label flipping completed in 0.03s
2024-12-27 19:58:20,041 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 19:58:20,041 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 19:58:21,957 - INFO - Feature scaling completed in 1.92s
2024-12-27 19:58:21,957 - INFO - Starting feature selection (k=50)
2024-12-27 19:58:22,009 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 19:58:22,009 - INFO - Starting anomaly detection
2024-12-27 19:58:28,426 - INFO - Anomaly detection completed in 6.42s
2024-12-27 19:58:28,426 - INFO - Found 1976 outliers (10.0%)
2024-12-27 19:58:28,426 - INFO - Total fit_transform time: 8.38s
2024-12-27 19:58:28,426 - INFO - Training set processing completed in 8.39s
2024-12-27 19:58:28,427 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 19:58:28,427 - INFO - Memory usage at start_fit: CPU 3023.1 MB, GPU 55.8 MB
2024-12-27 19:58:28,428 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 19:58:28,695 - INFO - Fitted scaler and transformed data
2024-12-27 19:58:28,695 - INFO - Scaling time: 0.27s
2024-12-27 19:58:28,715 - INFO - Number of unique classes: 43
2024-12-27 19:58:41,386 - INFO - Epoch 1/15, Train Loss: 3.5690, Val Loss: 3.7551
2024-12-27 19:58:54,891 - INFO - Epoch 2/15, Train Loss: 3.5610, Val Loss: 3.7471
2024-12-27 19:59:09,127 - INFO - Epoch 3/15, Train Loss: 3.5514, Val Loss: 3.7378
2024-12-27 19:59:22,022 - INFO - Epoch 4/15, Train Loss: 3.5405, Val Loss: 3.7274
2024-12-27 19:59:34,172 - INFO - Epoch 5/15, Train Loss: 3.5289, Val Loss: 3.7172
2024-12-27 19:59:47,729 - INFO - Epoch 6/15, Train Loss: 3.5179, Val Loss: 3.7082
2024-12-27 19:59:59,937 - INFO - Epoch 7/15, Train Loss: 3.5082, Val Loss: 3.7007
2024-12-27 20:00:13,085 - INFO - Epoch 8/15, Train Loss: 3.5001, Val Loss: 3.6947
2024-12-27 20:00:24,178 - INFO - Epoch 9/15, Train Loss: 3.4934, Val Loss: 3.6899
2024-12-27 20:00:36,445 - INFO - Epoch 10/15, Train Loss: 3.4880, Val Loss: 3.6860
2024-12-27 20:00:48,529 - INFO - Epoch 11/15, Train Loss: 3.4836, Val Loss: 3.6829
2024-12-27 20:00:48,529 - INFO - Early stopping triggered at epoch 11
2024-12-27 20:00:48,529 - INFO - Training completed in 140.10s
2024-12-27 20:00:48,529 - INFO - Final memory usage: CPU 3023.1 MB, GPU 155.0 MB
2024-12-27 20:00:48,530 - INFO - Model training completed in 140.10s
2024-12-27 20:00:48,662 - INFO - Prediction completed in 0.13s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:00:48,676 - INFO - Poison rate 0.07 completed in 148.66s
2024-12-27 20:00:48,676 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:00:48,711 - INFO - Total number of labels flipped: 1975
2024-12-27 20:00:48,712 - INFO - Label flipping completed in 0.04s
2024-12-27 20:00:48,712 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:00:48,712 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 20:00:50,673 - INFO - Feature scaling completed in 1.96s
2024-12-27 20:00:50,673 - INFO - Starting feature selection (k=50)
2024-12-27 20:00:50,724 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 20:00:50,724 - INFO - Starting anomaly detection
2024-12-27 20:00:58,779 - INFO - Anomaly detection completed in 8.05s
2024-12-27 20:00:58,779 - INFO - Found 1976 outliers (10.0%)
2024-12-27 20:00:58,779 - INFO - Total fit_transform time: 10.07s
2024-12-27 20:00:58,780 - INFO - Training set processing completed in 10.07s
2024-12-27 20:00:58,780 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 20:00:58,781 - INFO - Memory usage at start_fit: CPU 3023.1 MB, GPU 55.8 MB
2024-12-27 20:00:58,781 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 20:00:59,064 - INFO - Fitted scaler and transformed data
2024-12-27 20:00:59,064 - INFO - Scaling time: 0.28s
2024-12-27 20:00:59,085 - INFO - Number of unique classes: 43
2024-12-27 20:01:10,520 - INFO - Epoch 1/15, Train Loss: 3.5706, Val Loss: 3.7555
2024-12-27 20:01:22,018 - INFO - Epoch 2/15, Train Loss: 3.5630, Val Loss: 3.7482
2024-12-27 20:01:34,931 - INFO - Epoch 3/15, Train Loss: 3.5539, Val Loss: 3.7394
2024-12-27 20:01:45,882 - INFO - Epoch 4/15, Train Loss: 3.5433, Val Loss: 3.7296
2024-12-27 20:01:58,733 - INFO - Epoch 5/15, Train Loss: 3.5319, Val Loss: 3.7198
2024-12-27 20:02:11,287 - INFO - Epoch 6/15, Train Loss: 3.5210, Val Loss: 3.7110
2024-12-27 20:02:25,043 - INFO - Epoch 7/15, Train Loss: 3.5113, Val Loss: 3.7037
2024-12-27 20:02:38,411 - INFO - Epoch 8/15, Train Loss: 3.5032, Val Loss: 3.6977
2024-12-27 20:02:51,770 - INFO - Epoch 9/15, Train Loss: 3.4966, Val Loss: 3.6930
2024-12-27 20:03:03,839 - INFO - Epoch 10/15, Train Loss: 3.4912, Val Loss: 3.6892
2024-12-27 20:03:16,863 - INFO - Epoch 11/15, Train Loss: 3.4867, Val Loss: 3.6862
2024-12-27 20:03:16,863 - INFO - Early stopping triggered at epoch 11
2024-12-27 20:03:16,863 - INFO - Training completed in 138.08s
2024-12-27 20:03:16,863 - INFO - Final memory usage: CPU 3023.1 MB, GPU 155.0 MB
2024-12-27 20:03:16,864 - INFO - Model training completed in 138.08s
2024-12-27 20:03:16,998 - INFO - Prediction completed in 0.13s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:03:17,009 - INFO - Poison rate 0.1 completed in 148.33s
2024-12-27 20:03:17,010 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:03:17,079 - INFO - Total number of labels flipped: 3951
2024-12-27 20:03:17,079 - INFO - Label flipping completed in 0.07s
2024-12-27 20:03:17,079 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:03:17,079 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 20:03:18,914 - INFO - Feature scaling completed in 1.83s
2024-12-27 20:03:18,914 - INFO - Starting feature selection (k=50)
2024-12-27 20:03:18,965 - INFO - Feature selection completed in 0.05s. Output shape: (19755, 50)
2024-12-27 20:03:18,965 - INFO - Starting anomaly detection
2024-12-27 20:03:25,755 - INFO - Anomaly detection completed in 6.79s
2024-12-27 20:03:25,756 - INFO - Found 1976 outliers (10.0%)
2024-12-27 20:03:25,756 - INFO - Total fit_transform time: 8.68s
2024-12-27 20:03:25,756 - INFO - Training set processing completed in 8.68s
2024-12-27 20:03:25,757 - INFO - Fitting RandomForestWrapper model with data shape: (19755, 1280)
2024-12-27 20:03:25,758 - INFO - Memory usage at start_fit: CPU 3023.1 MB, GPU 55.8 MB
2024-12-27 20:03:25,758 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 20:03:26,011 - INFO - Fitted scaler and transformed data
2024-12-27 20:03:26,011 - INFO - Scaling time: 0.25s
2024-12-27 20:03:26,031 - INFO - Number of unique classes: 43
2024-12-27 20:03:36,992 - INFO - Epoch 1/15, Train Loss: 3.5730, Val Loss: 3.7566
2024-12-27 20:03:49,624 - INFO - Epoch 2/15, Train Loss: 3.5666, Val Loss: 3.7509
2024-12-27 20:04:01,387 - INFO - Epoch 3/15, Train Loss: 3.5593, Val Loss: 3.7440
2024-12-27 20:04:13,081 - INFO - Epoch 4/15, Train Loss: 3.5508, Val Loss: 3.7361
2024-12-27 20:04:23,837 - INFO - Epoch 5/15, Train Loss: 3.5415, Val Loss: 3.7280
2024-12-27 20:04:35,865 - INFO - Epoch 6/15, Train Loss: 3.5323, Val Loss: 3.7205
2024-12-27 20:04:47,599 - INFO - Epoch 7/15, Train Loss: 3.5239, Val Loss: 3.7140
2024-12-27 20:05:00,168 - INFO - Epoch 8/15, Train Loss: 3.5166, Val Loss: 3.7086
2024-12-27 20:05:12,645 - INFO - Epoch 9/15, Train Loss: 3.5105, Val Loss: 3.7042
2024-12-27 20:05:12,645 - INFO - Early stopping triggered at epoch 9
2024-12-27 20:05:12,645 - INFO - Training completed in 106.89s
2024-12-27 20:05:12,646 - INFO - Final memory usage: CPU 3023.1 MB, GPU 155.0 MB
2024-12-27 20:05:12,646 - INFO - Model training completed in 106.89s
2024-12-27 20:05:12,785 - INFO - Prediction completed in 0.14s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:05:12,797 - INFO - Poison rate 0.2 completed in 115.79s
2024-12-27 20:05:12,798 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:05:12,799 - INFO - Total evaluation time: 1017.97s
2024-12-27 20:05:12,805 - INFO - 
Progress: 32.3% - Evaluating GTSRB with KNeighbors (standard mode, iteration 1/1)
2024-12-27 20:05:12,864 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:05:13,054 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:05:13,152 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 20:05:13,152 - INFO - Dataset type: image
2024-12-27 20:05:13,152 - INFO - Sample size: 39209
2024-12-27 20:05:13,152 - INFO - Using device: cuda
2024-12-27 20:05:13,152 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 20:05:13,155 - INFO - Loading datasets...
2024-12-27 20:05:30,644 - INFO - Dataset loading completed in 17.49s
2024-12-27 20:05:30,644 - INFO - Extracting validation features...
2024-12-27 20:05:30,644 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:40,  3.40it/s]Extracting features:   3%|▎         | 4/139 [00:00<00:12, 10.42it/s]Extracting features:   6%|▌         | 8/139 [00:00<00:06, 18.77it/s]Extracting features:   9%|▉         | 13/139 [00:00<00:04, 26.78it/s]Extracting features:  14%|█▎        | 19/139 [00:00<00:03, 35.41it/s]Extracting features:  19%|█▊        | 26/139 [00:00<00:02, 45.16it/s]Extracting features:  24%|██▎       | 33/139 [00:00<00:02, 50.39it/s]Extracting features:  29%|██▉       | 40/139 [00:01<00:01, 55.66it/s]Extracting features:  33%|███▎      | 46/139 [00:01<00:01, 51.79it/s]Extracting features:  37%|███▋      | 52/139 [00:01<00:01, 53.69it/s]Extracting features:  42%|████▏     | 59/139 [00:01<00:01, 56.72it/s]Extracting features:  47%|████▋     | 65/139 [00:01<00:01, 56.21it/s]Extracting features:  51%|█████     | 71/139 [00:01<00:01, 56.19it/s]Extracting features:  55%|█████▌    | 77/139 [00:01<00:01, 54.81it/s]Extracting features:  60%|█████▉    | 83/139 [00:01<00:00, 56.17it/s]Extracting features:  65%|██████▍   | 90/139 [00:01<00:00, 57.82it/s]Extracting features:  69%|██████▉   | 96/139 [00:02<00:00, 57.98it/s]Extracting features:  73%|███████▎  | 102/139 [00:02<00:00, 53.62it/s]Extracting features:  78%|███████▊  | 108/139 [00:02<00:00, 54.35it/s]Extracting features:  83%|████████▎ | 115/139 [00:02<00:00, 56.31it/s]Extracting features:  88%|████████▊ | 123/139 [00:02<00:00, 61.68it/s]Extracting features:  94%|█████████▎| 130/139 [00:02<00:00, 60.94it/s]Extracting features:  99%|█████████▊| 137/139 [00:02<00:00, 63.29it/s]Extracting features: 100%|██████████| 139/139 [00:02<00:00, 48.73it/s]
2024-12-27 20:05:33,510 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 20:05:33,510 - INFO - Validation feature extraction completed in 2.87s
2024-12-27 20:05:33,511 - INFO - Extracting training features...
2024-12-27 20:05:33,511 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<02:02,  5.04it/s]Extracting features:   1%|          | 7/618 [00:00<00:22, 26.90it/s]Extracting features:   2%|▏         | 13/618 [00:00<00:15, 38.92it/s]Extracting features:   3%|▎         | 18/618 [00:00<00:14, 40.70it/s]Extracting features:   4%|▎         | 23/618 [00:00<00:14, 41.22it/s]Extracting features:   5%|▍         | 28/618 [00:00<00:14, 39.37it/s]Extracting features:   5%|▌         | 33/618 [00:00<00:14, 41.60it/s]Extracting features:   6%|▌         | 38/618 [00:00<00:13, 42.58it/s]Extracting features:   7%|▋         | 44/618 [00:01<00:12, 45.22it/s]Extracting features:   8%|▊         | 49/618 [00:01<00:12, 44.20it/s]Extracting features:   9%|▊         | 54/618 [00:01<00:12, 45.75it/s]Extracting features:  10%|▉         | 60/618 [00:01<00:11, 48.45it/s]Extracting features:  11%|█         | 66/618 [00:01<00:10, 51.55it/s]Extracting features:  12%|█▏        | 72/618 [00:01<00:10, 51.41it/s]Extracting features:  13%|█▎        | 78/618 [00:01<00:10, 52.69it/s]Extracting features:  14%|█▎        | 84/618 [00:01<00:09, 54.13it/s]Extracting features:  15%|█▍        | 90/618 [00:02<00:10, 48.57it/s]Extracting features:  15%|█▌        | 95/618 [00:02<00:10, 48.08it/s]Extracting features:  16%|█▌        | 100/618 [00:02<00:10, 47.95it/s]Extracting features:  17%|█▋        | 107/618 [00:02<00:10, 50.78it/s]Extracting features:  18%|█▊        | 114/618 [00:02<00:09, 53.02it/s]Extracting features:  20%|█▉        | 121/618 [00:02<00:08, 56.17it/s]Extracting features:  21%|██        | 127/618 [00:02<00:09, 54.23it/s]Extracting features:  22%|██▏       | 133/618 [00:02<00:08, 55.25it/s]Extracting features:  22%|██▏       | 139/618 [00:02<00:08, 53.81it/s]Extracting features:  23%|██▎       | 145/618 [00:03<00:09, 51.66it/s]Extracting features:  24%|██▍       | 151/618 [00:03<00:08, 52.97it/s]Extracting features:  25%|██▌       | 157/618 [00:03<00:09, 47.12it/s]Extracting features:  26%|██▌       | 162/618 [00:03<00:10, 45.59it/s]Extracting features:  27%|██▋       | 167/618 [00:03<00:09, 46.66it/s]Extracting features:  28%|██▊       | 173/618 [00:03<00:09, 49.36it/s]Extracting features:  29%|██▉       | 180/618 [00:03<00:08, 52.58it/s]Extracting features:  30%|███       | 187/618 [00:03<00:07, 54.41it/s]Extracting features:  31%|███       | 193/618 [00:04<00:08, 49.45it/s]Extracting features:  32%|███▏      | 199/618 [00:04<00:09, 45.09it/s]Extracting features:  33%|███▎      | 204/618 [00:04<00:09, 43.77it/s]Extracting features:  34%|███▍      | 209/618 [00:04<00:09, 41.84it/s]Extracting features:  35%|███▍      | 214/618 [00:04<00:09, 41.84it/s]Extracting features:  36%|███▌      | 220/618 [00:04<00:08, 45.23it/s]Extracting features:  36%|███▋      | 225/618 [00:04<00:08, 44.69it/s]Extracting features:  37%|███▋      | 230/618 [00:04<00:09, 42.70it/s]Extracting features:  38%|███▊      | 236/618 [00:05<00:08, 45.44it/s]Extracting features:  39%|███▉      | 243/618 [00:05<00:07, 49.12it/s]Extracting features:  40%|████      | 250/618 [00:05<00:06, 52.85it/s]Extracting features:  41%|████▏     | 256/618 [00:05<00:06, 53.49it/s]Extracting features:  42%|████▏     | 262/618 [00:05<00:06, 51.85it/s]Extracting features:  43%|████▎     | 268/618 [00:05<00:06, 53.04it/s]Extracting features:  44%|████▍     | 274/618 [00:05<00:06, 54.13it/s]Extracting features:  45%|████▌     | 280/618 [00:05<00:06, 50.75it/s]Extracting features:  46%|████▋     | 286/618 [00:05<00:06, 49.85it/s]Extracting features:  47%|████▋     | 292/618 [00:06<00:06, 49.77it/s]Extracting features:  48%|████▊     | 298/618 [00:06<00:06, 51.09it/s]Extracting features:  49%|████▉     | 304/618 [00:06<00:06, 46.05it/s]Extracting features:  50%|█████     | 310/618 [00:06<00:06, 46.84it/s]Extracting features:  51%|█████     | 315/618 [00:06<00:06, 46.90it/s]Extracting features:  52%|█████▏    | 322/618 [00:06<00:05, 51.19it/s]Extracting features:  53%|█████▎    | 329/618 [00:06<00:05, 55.18it/s]Extracting features:  54%|█████▍    | 336/618 [00:06<00:05, 55.86it/s]Extracting features:  55%|█████▌    | 342/618 [00:07<00:05, 52.19it/s]Extracting features:  56%|█████▋    | 348/618 [00:07<00:05, 49.51it/s]Extracting features:  57%|█████▋    | 355/618 [00:07<00:04, 53.22it/s]Extracting features:  58%|█████▊    | 361/618 [00:07<00:04, 54.92it/s]Extracting features:  60%|█████▉    | 368/618 [00:07<00:04, 58.21it/s]Extracting features:  61%|██████    | 374/618 [00:07<00:04, 58.69it/s]Extracting features:  61%|██████▏   | 380/618 [00:07<00:04, 58.40it/s]Extracting features:  63%|██████▎   | 387/618 [00:07<00:03, 59.34it/s]Extracting features:  64%|██████▎   | 393/618 [00:07<00:04, 55.20it/s]Extracting features:  65%|██████▍   | 399/618 [00:08<00:04, 51.35it/s]Extracting features:  66%|██████▌   | 405/618 [00:08<00:04, 52.39it/s]Extracting features:  67%|██████▋   | 412/618 [00:08<00:03, 55.82it/s]Extracting features:  68%|██████▊   | 418/618 [00:08<00:03, 54.93it/s]Extracting features:  69%|██████▉   | 425/618 [00:08<00:03, 56.28it/s]Extracting features:  70%|██████▉   | 432/618 [00:08<00:03, 58.40it/s]Extracting features:  71%|███████   | 438/618 [00:08<00:03, 57.36it/s]Extracting features:  72%|███████▏  | 444/618 [00:08<00:03, 54.24it/s]Extracting features:  73%|███████▎  | 450/618 [00:09<00:03, 52.06it/s]Extracting features:  74%|███████▍  | 456/618 [00:09<00:03, 51.76it/s]Extracting features:  75%|███████▍  | 462/618 [00:09<00:03, 51.99it/s]Extracting features:  76%|███████▌  | 468/618 [00:09<00:03, 45.94it/s]Extracting features:  77%|███████▋  | 473/618 [00:09<00:03, 45.69it/s]Extracting features:  78%|███████▊  | 479/618 [00:09<00:02, 48.28it/s]Extracting features:  78%|███████▊  | 485/618 [00:09<00:02, 50.15it/s]Extracting features:  79%|███████▉  | 491/618 [00:09<00:02, 52.11it/s]Extracting features:  80%|████████  | 497/618 [00:09<00:02, 53.33it/s]Extracting features:  81%|████████▏ | 503/618 [00:10<00:02, 53.66it/s]Extracting features:  82%|████████▏ | 509/618 [00:10<00:02, 52.46it/s]Extracting features:  83%|████████▎ | 515/618 [00:10<00:01, 53.49it/s]Extracting features:  84%|████████▍ | 521/618 [00:10<00:01, 51.40it/s]Extracting features:  85%|████████▌ | 528/618 [00:10<00:01, 53.24it/s]Extracting features:  87%|████████▋ | 535/618 [00:10<00:01, 55.39it/s]Extracting features:  88%|████████▊ | 542/618 [00:10<00:01, 56.92it/s]Extracting features:  89%|████████▊ | 548/618 [00:10<00:01, 55.17it/s]Extracting features:  90%|████████▉ | 554/618 [00:11<00:01, 55.64it/s]Extracting features:  91%|█████████ | 560/618 [00:11<00:01, 56.31it/s]Extracting features:  92%|█████████▏| 567/618 [00:11<00:00, 56.69it/s]Extracting features:  93%|█████████▎| 573/618 [00:11<00:00, 55.69it/s]Extracting features:  94%|█████████▍| 581/618 [00:11<00:00, 60.45it/s]Extracting features:  95%|█████████▌| 588/618 [00:11<00:00, 59.44it/s]Extracting features:  96%|█████████▋| 595/618 [00:11<00:00, 60.96it/s]Extracting features:  97%|█████████▋| 602/618 [00:11<00:00, 58.03it/s]Extracting features:  99%|█████████▊| 609/618 [00:11<00:00, 59.69it/s]Extracting features: 100%|█████████▉| 616/618 [00:12<00:00, 57.45it/s]Extracting features: 100%|██████████| 618/618 [00:12<00:00, 50.64it/s]
2024-12-27 20:05:45,754 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 20:05:45,755 - INFO - Training feature extraction completed in 12.24s
2024-12-27 20:05:45,755 - INFO - Creating model for classifier: KNeighbors
2024-12-27 20:05:45,755 - INFO - Using device: cuda
2024-12-27 20:05:45,755 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:05:45,755 - INFO - Training set processing completed in 0.00s
2024-12-27 20:05:45,755 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 20:05:45,756 - INFO - Memory usage at start_fit: CPU 3017.5 MB, GPU 47.3 MB
2024-12-27 20:05:45,757 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 20:05:46,055 - INFO - Fitted scaler and transformed data
2024-12-27 20:05:46,056 - INFO - Scaling time: 0.30s
2024-12-27 20:05:46,076 - INFO - Training completed in 0.32s
2024-12-27 20:05:46,076 - INFO - Final memory usage: CPU 3119.8 MB, GPU 143.9 MB
2024-12-27 20:05:46,077 - INFO - Model training completed in 0.32s
2024-12-27 20:05:46,196 - INFO - Prediction completed in 0.12s
2024-12-27 20:05:46,210 - INFO - Poison rate 0.0 completed in 0.45s
2024-12-27 20:05:46,210 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:05:46,216 - INFO - Total number of labels flipped: 197
2024-12-27 20:05:46,216 - INFO - Label flipping completed in 0.01s
2024-12-27 20:05:46,216 - INFO - Training set processing completed in 0.00s
2024-12-27 20:05:46,216 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 20:05:46,217 - INFO - Memory usage at start_fit: CPU 3023.3 MB, GPU 143.9 MB
2024-12-27 20:05:46,217 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 20:05:46,506 - INFO - Fitted scaler and transformed data
2024-12-27 20:05:46,506 - INFO - Scaling time: 0.29s
2024-12-27 20:05:46,528 - INFO - Training completed in 0.31s
2024-12-27 20:05:46,528 - INFO - Final memory usage: CPU 3119.8 MB, GPU 143.9 MB
2024-12-27 20:05:46,529 - INFO - Model training completed in 0.31s
2024-12-27 20:05:46,643 - INFO - Prediction completed in 0.11s
2024-12-27 20:05:46,654 - INFO - Poison rate 0.01 completed in 0.44s
2024-12-27 20:05:46,655 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:05:46,667 - INFO - Total number of labels flipped: 592
2024-12-27 20:05:46,667 - INFO - Label flipping completed in 0.01s
2024-12-27 20:05:46,667 - INFO - Training set processing completed in 0.00s
2024-12-27 20:05:46,667 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 20:05:46,669 - INFO - Memory usage at start_fit: CPU 3023.3 MB, GPU 143.9 MB
2024-12-27 20:05:46,669 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 20:05:46,915 - INFO - Fitted scaler and transformed data
2024-12-27 20:05:46,915 - INFO - Scaling time: 0.25s
2024-12-27 20:05:46,931 - INFO - Training completed in 0.26s
2024-12-27 20:05:46,931 - INFO - Final memory usage: CPU 3119.8 MB, GPU 143.9 MB
2024-12-27 20:05:46,932 - INFO - Model training completed in 0.26s
2024-12-27 20:05:47,061 - INFO - Prediction completed in 0.13s
2024-12-27 20:05:47,073 - INFO - Poison rate 0.03 completed in 0.42s
2024-12-27 20:05:47,073 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:05:47,092 - INFO - Total number of labels flipped: 987
2024-12-27 20:05:47,092 - INFO - Label flipping completed in 0.02s
2024-12-27 20:05:47,092 - INFO - Training set processing completed in 0.00s
2024-12-27 20:05:47,092 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 20:05:47,093 - INFO - Memory usage at start_fit: CPU 3023.3 MB, GPU 143.9 MB
2024-12-27 20:05:47,093 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 20:05:47,350 - INFO - Fitted scaler and transformed data
2024-12-27 20:05:47,350 - INFO - Scaling time: 0.26s
2024-12-27 20:05:47,366 - INFO - Training completed in 0.27s
2024-12-27 20:05:47,366 - INFO - Final memory usage: CPU 3119.8 MB, GPU 143.9 MB
2024-12-27 20:05:47,367 - INFO - Model training completed in 0.27s
2024-12-27 20:05:47,455 - INFO - Prediction completed in 0.09s
2024-12-27 20:05:47,467 - INFO - Poison rate 0.05 completed in 0.39s
2024-12-27 20:05:47,467 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:05:47,493 - INFO - Total number of labels flipped: 1382
2024-12-27 20:05:47,493 - INFO - Label flipping completed in 0.03s
2024-12-27 20:05:47,493 - INFO - Training set processing completed in 0.00s
2024-12-27 20:05:47,493 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 20:05:47,494 - INFO - Memory usage at start_fit: CPU 3023.3 MB, GPU 143.9 MB
2024-12-27 20:05:47,495 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 20:05:47,772 - INFO - Fitted scaler and transformed data
2024-12-27 20:05:47,773 - INFO - Scaling time: 0.28s
2024-12-27 20:05:47,793 - INFO - Training completed in 0.30s
2024-12-27 20:05:47,794 - INFO - Final memory usage: CPU 3119.8 MB, GPU 143.9 MB
2024-12-27 20:05:47,794 - INFO - Model training completed in 0.30s
2024-12-27 20:05:47,876 - INFO - Prediction completed in 0.08s
2024-12-27 20:05:47,887 - INFO - Poison rate 0.07 completed in 0.42s
2024-12-27 20:05:47,887 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:05:47,923 - INFO - Total number of labels flipped: 1975
2024-12-27 20:05:47,924 - INFO - Label flipping completed in 0.04s
2024-12-27 20:05:47,924 - INFO - Training set processing completed in 0.00s
2024-12-27 20:05:47,924 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 20:05:47,925 - INFO - Memory usage at start_fit: CPU 3023.3 MB, GPU 143.9 MB
2024-12-27 20:05:47,925 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 20:05:48,182 - INFO - Fitted scaler and transformed data
2024-12-27 20:05:48,183 - INFO - Scaling time: 0.26s
2024-12-27 20:05:48,199 - INFO - Training completed in 0.27s
2024-12-27 20:05:48,199 - INFO - Final memory usage: CPU 3119.8 MB, GPU 143.9 MB
2024-12-27 20:05:48,200 - INFO - Model training completed in 0.28s
2024-12-27 20:05:48,287 - INFO - Prediction completed in 0.09s
2024-12-27 20:05:48,299 - INFO - Poison rate 0.1 completed in 0.41s
2024-12-27 20:05:48,299 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:05:48,375 - INFO - Total number of labels flipped: 3951
2024-12-27 20:05:48,375 - INFO - Label flipping completed in 0.08s
2024-12-27 20:05:48,375 - INFO - Training set processing completed in 0.00s
2024-12-27 20:05:48,375 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 20:05:48,376 - INFO - Memory usage at start_fit: CPU 3023.3 MB, GPU 143.9 MB
2024-12-27 20:05:48,377 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 20:05:48,634 - INFO - Fitted scaler and transformed data
2024-12-27 20:05:48,635 - INFO - Scaling time: 0.26s
2024-12-27 20:05:48,665 - INFO - Training completed in 0.29s
2024-12-27 20:05:48,665 - INFO - Final memory usage: CPU 3119.8 MB, GPU 143.9 MB
2024-12-27 20:05:48,666 - INFO - Model training completed in 0.29s
2024-12-27 20:05:48,747 - INFO - Prediction completed in 0.08s
2024-12-27 20:05:48,759 - INFO - Poison rate 0.2 completed in 0.46s
2024-12-27 20:05:48,760 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:05:48,761 - INFO - Total evaluation time: 35.61s
2024-12-27 20:05:48,767 - INFO - 
Progress: 33.3% - Evaluating GTSRB with KNeighbors (dynadetect mode, iteration 1/1)
2024-12-27 20:05:48,849 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:05:48,922 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:05:49,021 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 20:05:49,021 - INFO - Dataset type: image
2024-12-27 20:05:49,021 - INFO - Sample size: 39209
2024-12-27 20:05:49,021 - INFO - Using device: cuda
2024-12-27 20:05:49,021 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 20:05:49,024 - INFO - Loading datasets...
2024-12-27 20:06:06,145 - INFO - Dataset loading completed in 17.12s
2024-12-27 20:06:06,145 - INFO - Extracting validation features...
2024-12-27 20:06:06,145 - INFO - Extracting features from 4435 samples using EfficientNetB0...
Extracting features:   0%|          | 0/139 [00:00<?, ?it/s]Extracting features:   1%|          | 1/139 [00:00<00:31,  4.33it/s]Extracting features:   2%|▏         | 3/139 [00:00<00:16,  8.04it/s]Extracting features:   4%|▍         | 6/139 [00:00<00:09, 14.35it/s]Extracting features:   7%|▋         | 10/139 [00:00<00:06, 20.96it/s]Extracting features:  12%|█▏        | 16/139 [00:00<00:04, 30.30it/s]Extracting features:  15%|█▌        | 21/139 [00:00<00:03, 35.74it/s]Extracting features:  19%|█▊        | 26/139 [00:00<00:03, 36.70it/s]Extracting features:  22%|██▏       | 31/139 [00:01<00:02, 38.67it/s]Extracting features:  26%|██▌       | 36/139 [00:01<00:02, 36.70it/s]Extracting features:  29%|██▉       | 41/139 [00:01<00:02, 38.18it/s]Extracting features:  33%|███▎      | 46/139 [00:01<00:02, 39.59it/s]Extracting features:  37%|███▋      | 51/139 [00:01<00:02, 40.31it/s]Extracting features:  40%|████      | 56/139 [00:01<00:02, 39.19it/s]Extracting features:  43%|████▎     | 60/139 [00:01<00:02, 38.83it/s]Extracting features:  46%|████▌     | 64/139 [00:01<00:02, 37.38it/s]Extracting features:  49%|████▉     | 68/139 [00:02<00:01, 37.82it/s]Extracting features:  52%|█████▏    | 72/139 [00:02<00:01, 37.61it/s]Extracting features:  55%|█████▍    | 76/139 [00:02<00:01, 36.84it/s]Extracting features:  58%|█████▊    | 80/139 [00:02<00:01, 35.40it/s]Extracting features:  61%|██████    | 85/139 [00:02<00:01, 39.11it/s]Extracting features:  65%|██████▌   | 91/139 [00:02<00:01, 44.07it/s]Extracting features:  70%|██████▉   | 97/139 [00:02<00:00, 48.29it/s]Extracting features:  74%|███████▍  | 103/139 [00:02<00:00, 51.21it/s]Extracting features:  80%|███████▉  | 111/139 [00:02<00:00, 57.63it/s]Extracting features:  85%|████████▍ | 118/139 [00:03<00:00, 59.55it/s]Extracting features:  89%|████████▉ | 124/139 [00:03<00:00, 59.41it/s]Extracting features:  94%|█████████▍| 131/139 [00:03<00:00, 58.72it/s]Extracting features:  99%|█████████▊| 137/139 [00:03<00:00, 56.39it/s]Extracting features: 100%|██████████| 139/139 [00:03<00:00, 39.49it/s]
2024-12-27 20:06:09,679 - INFO - Feature extraction completed. Final feature shape: (4435, 1280)
2024-12-27 20:06:09,679 - INFO - Validation feature extraction completed in 3.53s
2024-12-27 20:06:09,680 - INFO - Extracting training features...
2024-12-27 20:06:09,680 - INFO - Extracting features from 19755 samples using EfficientNetB0...
Extracting features:   0%|          | 0/618 [00:00<?, ?it/s]Extracting features:   0%|          | 1/618 [00:00<02:14,  4.59it/s]Extracting features:   1%|▏         | 8/618 [00:00<00:20, 29.19it/s]Extracting features:   2%|▏         | 14/618 [00:00<00:15, 38.12it/s]Extracting features:   3%|▎         | 20/618 [00:00<00:13, 44.35it/s]Extracting features:   4%|▍         | 26/618 [00:00<00:12, 49.21it/s]Extracting features:   5%|▌         | 33/618 [00:00<00:10, 54.65it/s]Extracting features:   6%|▋         | 39/618 [00:00<00:10, 55.16it/s]Extracting features:   7%|▋         | 45/618 [00:00<00:10, 55.60it/s]Extracting features:   8%|▊         | 51/618 [00:01<00:10, 52.79it/s]Extracting features:   9%|▉         | 58/618 [00:01<00:09, 56.13it/s]Extracting features:  11%|█         | 65/618 [00:01<00:09, 57.15it/s]Extracting features:  11%|█▏        | 71/618 [00:01<00:09, 57.61it/s]Extracting features:  13%|█▎        | 78/618 [00:01<00:08, 60.41it/s]Extracting features:  14%|█▍        | 85/618 [00:01<00:09, 58.99it/s]Extracting features:  15%|█▍        | 91/618 [00:01<00:09, 57.86it/s]Extracting features:  16%|█▌        | 97/618 [00:01<00:08, 58.41it/s]Extracting features:  17%|█▋        | 103/618 [00:01<00:08, 58.53it/s]Extracting features:  18%|█▊        | 109/618 [00:02<00:08, 58.66it/s]Extracting features:  19%|█▉        | 116/618 [00:02<00:08, 60.28it/s]Extracting features:  20%|█▉        | 123/618 [00:02<00:07, 62.58it/s]Extracting features:  21%|██        | 130/618 [00:02<00:08, 60.88it/s]Extracting features:  22%|██▏       | 137/618 [00:02<00:08, 56.54it/s]Extracting features:  23%|██▎       | 144/618 [00:02<00:07, 60.02it/s]Extracting features:  24%|██▍       | 151/618 [00:02<00:07, 61.45it/s]Extracting features:  26%|██▌       | 158/618 [00:02<00:07, 61.61it/s]Extracting features:  27%|██▋       | 165/618 [00:02<00:07, 60.83it/s]Extracting features:  28%|██▊       | 172/618 [00:03<00:07, 61.98it/s]Extracting features:  29%|██▉       | 179/618 [00:03<00:07, 59.76it/s]Extracting features:  30%|███       | 186/618 [00:03<00:07, 59.89it/s]Extracting features:  31%|███▏      | 194/618 [00:03<00:06, 62.83it/s]Extracting features:  33%|███▎      | 201/618 [00:03<00:06, 61.38it/s]Extracting features:  34%|███▎      | 208/618 [00:03<00:06, 59.36it/s]Extracting features:  35%|███▍      | 215/618 [00:03<00:06, 60.20it/s]Extracting features:  36%|███▌      | 223/618 [00:03<00:06, 63.22it/s]Extracting features:  37%|███▋      | 230/618 [00:04<00:06, 59.62it/s]Extracting features:  38%|███▊      | 237/618 [00:04<00:06, 60.83it/s]Extracting features:  39%|███▉      | 244/618 [00:04<00:05, 62.64it/s]Extracting features:  41%|████      | 251/618 [00:04<00:05, 62.29it/s]Extracting features:  42%|████▏     | 258/618 [00:04<00:05, 60.36it/s]Extracting features:  43%|████▎     | 265/618 [00:04<00:05, 59.24it/s]Extracting features:  44%|████▍     | 271/618 [00:04<00:06, 54.50it/s]Extracting features:  45%|████▍     | 277/618 [00:04<00:06, 53.68it/s]Extracting features:  46%|████▌     | 284/618 [00:05<00:06, 55.15it/s]Extracting features:  47%|████▋     | 290/618 [00:05<00:06, 54.53it/s]Extracting features:  48%|████▊     | 297/618 [00:05<00:05, 57.06it/s]Extracting features:  49%|████▉     | 304/618 [00:05<00:05, 59.99it/s]Extracting features:  50%|█████     | 311/618 [00:05<00:05, 58.92it/s]Extracting features:  51%|█████▏    | 317/618 [00:05<00:05, 58.15it/s]Extracting features:  52%|█████▏    | 323/618 [00:05<00:05, 57.35it/s]Extracting features:  53%|█████▎    | 330/618 [00:05<00:04, 60.11it/s]Extracting features:  55%|█████▍    | 337/618 [00:05<00:04, 57.56it/s]Extracting features:  56%|█████▌    | 343/618 [00:06<00:04, 55.78it/s]Extracting features:  56%|█████▋    | 349/618 [00:06<00:04, 55.75it/s]Extracting features:  57%|█████▋    | 355/618 [00:06<00:05, 49.58it/s]Extracting features:  58%|█████▊    | 361/618 [00:06<00:05, 49.68it/s]Extracting features:  59%|█████▉    | 367/618 [00:06<00:05, 49.12it/s]Extracting features:  60%|██████    | 373/618 [00:06<00:04, 50.97it/s]Extracting features:  61%|██████▏   | 380/618 [00:06<00:04, 53.62it/s]Extracting features:  63%|██████▎   | 387/618 [00:06<00:04, 56.64it/s]Extracting features:  64%|██████▎   | 393/618 [00:06<00:03, 57.38it/s]Extracting features:  65%|██████▍   | 399/618 [00:07<00:04, 53.89it/s]Extracting features:  66%|██████▌   | 405/618 [00:07<00:03, 53.76it/s]Extracting features:  67%|██████▋   | 412/618 [00:07<00:03, 57.82it/s]Extracting features:  68%|██████▊   | 418/618 [00:07<00:03, 56.15it/s]Extracting features:  69%|██████▉   | 425/618 [00:07<00:03, 56.92it/s]Extracting features:  70%|██████▉   | 432/618 [00:07<00:03, 59.54it/s]Extracting features:  71%|███████   | 438/618 [00:07<00:03, 58.83it/s]Extracting features:  72%|███████▏  | 444/618 [00:07<00:03, 56.01it/s]Extracting features:  73%|███████▎  | 450/618 [00:07<00:02, 56.51it/s]Extracting features:  74%|███████▍  | 456/618 [00:08<00:02, 56.05it/s]Extracting features:  75%|███████▍  | 462/618 [00:08<00:02, 56.46it/s]Extracting features:  76%|███████▌  | 469/618 [00:08<00:02, 58.18it/s]Extracting features:  77%|███████▋  | 476/618 [00:08<00:02, 59.46it/s]Extracting features:  78%|███████▊  | 482/618 [00:08<00:02, 58.04it/s]Extracting features:  79%|███████▉  | 489/618 [00:08<00:02, 59.46it/s]Extracting features:  80%|████████  | 495/618 [00:08<00:02, 55.18it/s]Extracting features:  81%|████████  | 502/618 [00:08<00:01, 58.91it/s]Extracting features:  82%|████████▏ | 508/618 [00:08<00:01, 58.96it/s]Extracting features:  83%|████████▎ | 514/618 [00:09<00:01, 57.20it/s]Extracting features:  84%|████████▍ | 521/618 [00:09<00:01, 58.07it/s]Extracting features:  85%|████████▌ | 527/618 [00:09<00:01, 57.40it/s]Extracting features:  86%|████████▌ | 533/618 [00:09<00:01, 56.95it/s]Extracting features:  87%|████████▋ | 539/618 [00:09<00:01, 57.46it/s]Extracting features:  88%|████████▊ | 546/618 [00:09<00:01, 60.19it/s]Extracting features:  89%|████████▉ | 553/618 [00:09<00:01, 60.33it/s]Extracting features:  91%|█████████ | 560/618 [00:09<00:00, 61.67it/s]Extracting features:  92%|█████████▏| 567/618 [00:09<00:00, 55.83it/s]Extracting features:  93%|█████████▎| 574/618 [00:10<00:00, 56.74it/s]Extracting features:  94%|█████████▍| 580/618 [00:10<00:00, 56.94it/s]Extracting features:  95%|█████████▍| 587/618 [00:10<00:00, 59.51it/s]Extracting features:  96%|█████████▌| 594/618 [00:10<00:00, 60.35it/s]Extracting features:  97%|█████████▋| 601/618 [00:10<00:00, 57.66it/s]Extracting features:  98%|█████████▊| 608/618 [00:10<00:00, 59.42it/s]Extracting features: 100%|█████████▉| 615/618 [00:10<00:00, 62.16it/s]Extracting features: 100%|██████████| 618/618 [00:10<00:00, 56.64it/s]
2024-12-27 20:06:20,625 - INFO - Feature extraction completed. Final feature shape: (19755, 1280)
2024-12-27 20:06:20,626 - INFO - Training feature extraction completed in 10.95s
2024-12-27 20:06:20,626 - INFO - Creating model for classifier: KNeighbors
2024-12-27 20:06:20,626 - INFO - Using device: cuda
2024-12-27 20:06:20,626 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:06:20,626 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:06:20,626 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 20:06:22,455 - INFO - Feature scaling completed in 1.83s
2024-12-27 20:06:22,455 - INFO - Starting feature selection (k=50)
2024-12-27 20:06:22,476 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 20:06:22,477 - INFO - Starting anomaly detection
2024-12-27 20:06:28,917 - INFO - Anomaly detection completed in 6.44s
2024-12-27 20:06:28,917 - INFO - Found 1976 outliers (10.0%)
2024-12-27 20:06:28,917 - INFO - Total fit_transform time: 8.29s
2024-12-27 20:06:28,917 - INFO - Training set processing completed in 8.29s
2024-12-27 20:06:28,917 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 20:06:28,919 - INFO - Memory usage at start_fit: CPU 3020.1 MB, GPU 47.3 MB
2024-12-27 20:06:28,919 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 20:06:29,199 - INFO - Fitted scaler and transformed data
2024-12-27 20:06:29,199 - INFO - Scaling time: 0.28s
2024-12-27 20:06:29,218 - INFO - Training completed in 0.30s
2024-12-27 20:06:29,218 - INFO - Final memory usage: CPU 3120.7 MB, GPU 143.9 MB
2024-12-27 20:06:29,218 - INFO - Model training completed in 0.30s
2024-12-27 20:06:29,531 - INFO - Prediction completed in 0.31s
2024-12-27 20:06:29,542 - INFO - Poison rate 0.0 completed in 8.92s
2024-12-27 20:06:29,543 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:06:29,548 - INFO - Total number of labels flipped: 197
2024-12-27 20:06:29,548 - INFO - Label flipping completed in 0.01s
2024-12-27 20:06:29,548 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:06:29,548 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 20:06:31,368 - INFO - Feature scaling completed in 1.82s
2024-12-27 20:06:31,368 - INFO - Starting feature selection (k=50)
2024-12-27 20:06:31,386 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 20:06:31,386 - INFO - Starting anomaly detection
2024-12-27 20:06:37,201 - INFO - Anomaly detection completed in 5.81s
2024-12-27 20:06:37,201 - INFO - Found 1976 outliers (10.0%)
2024-12-27 20:06:37,201 - INFO - Total fit_transform time: 7.65s
2024-12-27 20:06:37,201 - INFO - Training set processing completed in 7.65s
2024-12-27 20:06:37,202 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 20:06:37,203 - INFO - Memory usage at start_fit: CPU 3024.2 MB, GPU 143.9 MB
2024-12-27 20:06:37,203 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 20:06:37,449 - INFO - Fitted scaler and transformed data
2024-12-27 20:06:37,449 - INFO - Scaling time: 0.25s
2024-12-27 20:06:37,468 - INFO - Training completed in 0.27s
2024-12-27 20:06:37,469 - INFO - Final memory usage: CPU 3120.7 MB, GPU 143.9 MB
2024-12-27 20:06:37,469 - INFO - Model training completed in 0.27s
2024-12-27 20:06:37,733 - INFO - Prediction completed in 0.26s
2024-12-27 20:06:37,744 - INFO - Poison rate 0.01 completed in 8.20s
2024-12-27 20:06:37,745 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:06:37,757 - INFO - Total number of labels flipped: 592
2024-12-27 20:06:37,757 - INFO - Label flipping completed in 0.01s
2024-12-27 20:06:37,757 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:06:37,757 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 20:06:39,538 - INFO - Feature scaling completed in 1.78s
2024-12-27 20:06:39,538 - INFO - Starting feature selection (k=50)
2024-12-27 20:06:39,554 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 20:06:39,554 - INFO - Starting anomaly detection
2024-12-27 20:06:46,859 - INFO - Anomaly detection completed in 7.30s
2024-12-27 20:06:46,860 - INFO - Found 1976 outliers (10.0%)
2024-12-27 20:06:46,860 - INFO - Total fit_transform time: 9.10s
2024-12-27 20:06:46,860 - INFO - Training set processing completed in 9.10s
2024-12-27 20:06:46,860 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 20:06:46,861 - INFO - Memory usage at start_fit: CPU 3024.2 MB, GPU 143.9 MB
2024-12-27 20:06:46,862 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 20:06:47,116 - INFO - Fitted scaler and transformed data
2024-12-27 20:06:47,116 - INFO - Scaling time: 0.25s
2024-12-27 20:06:47,140 - INFO - Training completed in 0.28s
2024-12-27 20:06:47,140 - INFO - Final memory usage: CPU 3120.7 MB, GPU 143.9 MB
2024-12-27 20:06:47,141 - INFO - Model training completed in 0.28s
2024-12-27 20:06:47,522 - INFO - Prediction completed in 0.38s
2024-12-27 20:06:47,545 - INFO - Poison rate 0.03 completed in 9.80s
2024-12-27 20:06:47,545 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:06:47,566 - INFO - Total number of labels flipped: 987
2024-12-27 20:06:47,566 - INFO - Label flipping completed in 0.02s
2024-12-27 20:06:47,566 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:06:47,566 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 20:06:49,409 - INFO - Feature scaling completed in 1.84s
2024-12-27 20:06:49,409 - INFO - Starting feature selection (k=50)
2024-12-27 20:06:49,427 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 20:06:49,427 - INFO - Starting anomaly detection
2024-12-27 20:06:57,453 - INFO - Anomaly detection completed in 8.03s
2024-12-27 20:06:57,453 - INFO - Found 1976 outliers (10.0%)
2024-12-27 20:06:57,453 - INFO - Total fit_transform time: 9.89s
2024-12-27 20:06:57,454 - INFO - Training set processing completed in 9.89s
2024-12-27 20:06:57,454 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 20:06:57,455 - INFO - Memory usage at start_fit: CPU 3024.2 MB, GPU 143.9 MB
2024-12-27 20:06:57,455 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 20:06:57,716 - INFO - Fitted scaler and transformed data
2024-12-27 20:06:57,717 - INFO - Scaling time: 0.26s
2024-12-27 20:06:57,736 - INFO - Training completed in 0.28s
2024-12-27 20:06:57,737 - INFO - Final memory usage: CPU 3120.7 MB, GPU 143.9 MB
2024-12-27 20:06:57,737 - INFO - Model training completed in 0.28s
2024-12-27 20:06:58,119 - INFO - Prediction completed in 0.38s
2024-12-27 20:06:58,130 - INFO - Poison rate 0.05 completed in 10.59s
2024-12-27 20:06:58,130 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:06:58,156 - INFO - Total number of labels flipped: 1382
2024-12-27 20:06:58,156 - INFO - Label flipping completed in 0.03s
2024-12-27 20:06:58,156 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:06:58,156 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 20:06:59,980 - INFO - Feature scaling completed in 1.82s
2024-12-27 20:06:59,981 - INFO - Starting feature selection (k=50)
2024-12-27 20:06:59,998 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 20:06:59,998 - INFO - Starting anomaly detection
2024-12-27 20:07:07,795 - INFO - Anomaly detection completed in 7.80s
2024-12-27 20:07:07,795 - INFO - Found 1976 outliers (10.0%)
2024-12-27 20:07:07,795 - INFO - Total fit_transform time: 9.64s
2024-12-27 20:07:07,795 - INFO - Training set processing completed in 9.64s
2024-12-27 20:07:07,796 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 20:07:07,797 - INFO - Memory usage at start_fit: CPU 3024.2 MB, GPU 143.9 MB
2024-12-27 20:07:07,797 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 20:07:08,062 - INFO - Fitted scaler and transformed data
2024-12-27 20:07:08,062 - INFO - Scaling time: 0.26s
2024-12-27 20:07:08,094 - INFO - Training completed in 0.30s
2024-12-27 20:07:08,094 - INFO - Final memory usage: CPU 3120.7 MB, GPU 143.9 MB
2024-12-27 20:07:08,094 - INFO - Model training completed in 0.30s
2024-12-27 20:07:08,376 - INFO - Prediction completed in 0.28s
2024-12-27 20:07:08,387 - INFO - Poison rate 0.07 completed in 10.26s
2024-12-27 20:07:08,387 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:07:08,423 - INFO - Total number of labels flipped: 1975
2024-12-27 20:07:08,423 - INFO - Label flipping completed in 0.04s
2024-12-27 20:07:08,423 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:07:08,423 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 20:07:10,322 - INFO - Feature scaling completed in 1.90s
2024-12-27 20:07:10,323 - INFO - Starting feature selection (k=50)
2024-12-27 20:07:10,339 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 20:07:10,340 - INFO - Starting anomaly detection
2024-12-27 20:07:16,991 - INFO - Anomaly detection completed in 6.65s
2024-12-27 20:07:16,991 - INFO - Found 1976 outliers (10.0%)
2024-12-27 20:07:16,991 - INFO - Total fit_transform time: 8.57s
2024-12-27 20:07:16,992 - INFO - Training set processing completed in 8.57s
2024-12-27 20:07:16,992 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 20:07:16,993 - INFO - Memory usage at start_fit: CPU 3024.2 MB, GPU 143.9 MB
2024-12-27 20:07:16,994 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 20:07:17,250 - INFO - Fitted scaler and transformed data
2024-12-27 20:07:17,251 - INFO - Scaling time: 0.26s
2024-12-27 20:07:17,270 - INFO - Training completed in 0.28s
2024-12-27 20:07:17,270 - INFO - Final memory usage: CPU 3120.7 MB, GPU 143.9 MB
2024-12-27 20:07:17,271 - INFO - Model training completed in 0.28s
2024-12-27 20:07:17,523 - INFO - Prediction completed in 0.25s
2024-12-27 20:07:17,534 - INFO - Poison rate 0.1 completed in 9.15s
2024-12-27 20:07:17,534 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:07:17,603 - INFO - Total number of labels flipped: 3951
2024-12-27 20:07:17,603 - INFO - Label flipping completed in 0.07s
2024-12-27 20:07:17,603 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:07:17,604 - INFO - Starting feature scaling on shape (19755, 1280)
2024-12-27 20:07:19,464 - INFO - Feature scaling completed in 1.86s
2024-12-27 20:07:19,464 - INFO - Starting feature selection (k=50)
2024-12-27 20:07:19,481 - INFO - Feature selection completed in 0.02s. Output shape: (19755, 50)
2024-12-27 20:07:19,481 - INFO - Starting anomaly detection
2024-12-27 20:07:27,543 - INFO - Anomaly detection completed in 8.06s
2024-12-27 20:07:27,543 - INFO - Found 1976 outliers (10.0%)
2024-12-27 20:07:27,543 - INFO - Total fit_transform time: 9.94s
2024-12-27 20:07:27,544 - INFO - Training set processing completed in 9.94s
2024-12-27 20:07:27,545 - INFO - Fitting KNeighborsWrapper model with data shape: (19755, 1280)
2024-12-27 20:07:27,546 - INFO - Memory usage at start_fit: CPU 3024.2 MB, GPU 143.9 MB
2024-12-27 20:07:27,546 - INFO - Input data shape: (19755, 1280), labels shape: (19755,)
2024-12-27 20:07:27,802 - INFO - Fitted scaler and transformed data
2024-12-27 20:07:27,802 - INFO - Scaling time: 0.26s
2024-12-27 20:07:27,823 - INFO - Training completed in 0.28s
2024-12-27 20:07:27,823 - INFO - Final memory usage: CPU 3120.7 MB, GPU 143.9 MB
2024-12-27 20:07:27,824 - INFO - Model training completed in 0.28s
2024-12-27 20:07:28,114 - INFO - Prediction completed in 0.29s
2024-12-27 20:07:28,125 - INFO - Poison rate 0.2 completed in 10.59s
2024-12-27 20:07:28,127 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:07:28,127 - INFO - Total evaluation time: 99.10s
2024-12-27 20:07:28,134 - INFO - Completed evaluation for GTSRB
2024-12-27 20:07:28,134 - INFO - 
Processing dataset: CIFAR100
2024-12-27 20:07:28,194 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:07:28,266 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:07:28,329 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:07:28,329 - INFO - Dataset type: image
2024-12-27 20:07:28,329 - INFO - Sample size: 5000
2024-12-27 20:07:28,329 - INFO - Using device: cuda
2024-12-27 20:07:28,332 - INFO - 
Progress: 34.4% - Evaluating CIFAR100 with SVM (standard mode, iteration 1/1)
2024-12-27 20:07:28,394 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:07:28,473 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:07:28,548 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:07:28,548 - INFO - Dataset type: image
2024-12-27 20:07:28,548 - INFO - Sample size: 5000
2024-12-27 20:07:28,548 - INFO - Using device: cuda
2024-12-27 20:07:28,551 - INFO - Loading datasets...
2024-12-27 20:07:29,838 - INFO - Dataset loading completed in 1.29s
2024-12-27 20:07:29,839 - INFO - Extracting validation features...
2024-12-27 20:07:29,839 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:13,  2.28it/s]Extracting features:  12%|█▎        | 4/32 [00:00<00:03,  9.03it/s]Extracting features:  25%|██▌       | 8/32 [00:00<00:01, 16.03it/s]Extracting features:  38%|███▊      | 12/32 [00:00<00:00, 21.76it/s]Extracting features:  53%|█████▎    | 17/32 [00:00<00:00, 28.65it/s]Extracting features:  66%|██████▌   | 21/32 [00:00<00:00, 31.41it/s]Extracting features:  78%|███████▊  | 25/32 [00:01<00:00, 33.63it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 35.71it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 24.00it/s]
2024-12-27 20:07:31,178 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:07:31,178 - INFO - Validation feature extraction completed in 1.34s
2024-12-27 20:07:31,179 - INFO - Extracting training features...
2024-12-27 20:07:31,179 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:46,  3.33it/s]Extracting features:   3%|▎         | 5/157 [00:00<00:10, 13.91it/s]Extracting features:   6%|▌         | 9/157 [00:00<00:06, 21.15it/s]Extracting features:   9%|▉         | 14/157 [00:00<00:05, 28.22it/s]Extracting features:  11%|█▏        | 18/157 [00:00<00:04, 30.53it/s]Extracting features:  14%|█▍        | 22/157 [00:00<00:04, 32.39it/s]Extracting features:  17%|█▋        | 26/157 [00:00<00:03, 33.91it/s]Extracting features:  20%|██        | 32/157 [00:01<00:03, 38.85it/s]Extracting features:  24%|██▎       | 37/157 [00:01<00:03, 37.72it/s]Extracting features:  27%|██▋       | 43/157 [00:01<00:02, 42.96it/s]Extracting features:  31%|███       | 48/157 [00:01<00:02, 42.53it/s]Extracting features:  34%|███▍      | 53/157 [00:01<00:02, 42.17it/s]Extracting features:  37%|███▋      | 58/157 [00:01<00:02, 42.45it/s]Extracting features:  40%|████      | 63/157 [00:01<00:02, 39.96it/s]Extracting features:  43%|████▎     | 68/157 [00:01<00:02, 39.73it/s]Extracting features:  46%|████▋     | 73/157 [00:02<00:02, 39.01it/s]Extracting features:  50%|████▉     | 78/157 [00:02<00:01, 41.47it/s]Extracting features:  53%|█████▎    | 83/157 [00:02<00:01, 39.75it/s]Extracting features:  56%|█████▌    | 88/157 [00:02<00:01, 41.26it/s]Extracting features:  59%|█████▉    | 93/157 [00:02<00:01, 39.49it/s]Extracting features:  62%|██████▏   | 98/157 [00:02<00:01, 37.36it/s]Extracting features:  66%|██████▌   | 103/157 [00:02<00:01, 38.22it/s]Extracting features:  68%|██████▊   | 107/157 [00:02<00:01, 37.91it/s]Extracting features:  71%|███████▏  | 112/157 [00:03<00:01, 39.46it/s]Extracting features:  75%|███████▍  | 117/157 [00:03<00:01, 39.89it/s]Extracting features:  78%|███████▊  | 122/157 [00:03<00:00, 39.16it/s]Extracting features:  82%|████████▏ | 128/157 [00:03<00:00, 41.81it/s]Extracting features:  85%|████████▍ | 133/157 [00:03<00:00, 42.37it/s]Extracting features:  88%|████████▊ | 138/157 [00:03<00:00, 42.21it/s]Extracting features:  91%|█████████ | 143/157 [00:03<00:00, 42.73it/s]Extracting features:  94%|█████████▍| 148/157 [00:03<00:00, 41.27it/s]Extracting features:  99%|█████████▊| 155/157 [00:04<00:00, 47.04it/s]Extracting features: 100%|██████████| 157/157 [00:04<00:00, 37.50it/s]
2024-12-27 20:07:35,381 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:07:35,381 - INFO - Training feature extraction completed in 4.20s
2024-12-27 20:07:35,381 - INFO - Creating model for classifier: SVM
2024-12-27 20:07:35,381 - INFO - Using device: cuda
2024-12-27 20:07:35,382 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-27 20:07:35,382 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:07:35,382 - INFO - Training set processing completed in 0.00s
2024-12-27 20:07:35,382 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:07:35,383 - INFO - Memory usage at start_fit: CPU 3267.9 MB, GPU 47.3 MB
2024-12-27 20:07:35,384 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:07:35,385 - INFO - Number of unique classes: 100
2024-12-27 20:07:35,486 - INFO - Fitted scaler and transformed data
2024-12-27 20:07:35,486 - INFO - Scaling time: 0.10s
2024-12-27 20:07:35,697 - INFO - Epoch 1/25, Train Loss: 22.9321, Val Loss: 12.0922
2024-12-27 20:07:35,886 - INFO - Epoch 2/25, Train Loss: 1.9153, Val Loss: 11.4479
2024-12-27 20:07:36,098 - INFO - Epoch 3/25, Train Loss: 0.6887, Val Loss: 10.8597
2024-12-27 20:07:36,281 - INFO - Epoch 4/25, Train Loss: 0.3183, Val Loss: 10.3895
2024-12-27 20:07:36,470 - INFO - Epoch 5/25, Train Loss: 0.1593, Val Loss: 10.2926
2024-12-27 20:07:36,623 - INFO - Epoch 6/25, Train Loss: 0.0789, Val Loss: 10.3060
2024-12-27 20:07:36,800 - INFO - Epoch 7/25, Train Loss: 0.0387, Val Loss: 10.2150
2024-12-27 20:07:36,980 - INFO - Epoch 8/25, Train Loss: 0.0227, Val Loss: 10.2335
2024-12-27 20:07:37,166 - INFO - Epoch 9/25, Train Loss: 0.0195, Val Loss: 10.2399
2024-12-27 20:07:37,166 - INFO - Early stopping triggered at epoch 9
2024-12-27 20:07:37,166 - INFO - Training completed in 1.78s
2024-12-27 20:07:37,166 - INFO - Final memory usage: CPU 3294.6 MB, GPU 49.9 MB
2024-12-27 20:07:37,167 - INFO - Model training completed in 1.79s
2024-12-27 20:07:37,174 - INFO - Prediction completed in 0.01s
2024-12-27 20:07:37,184 - INFO - Poison rate 0.0 completed in 1.80s
2024-12-27 20:07:37,184 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:07:37,187 - INFO - Total number of labels flipped: 50
2024-12-27 20:07:37,187 - INFO - Label flipping completed in 0.00s
2024-12-27 20:07:37,187 - INFO - Training set processing completed in 0.00s
2024-12-27 20:07:37,187 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:07:37,188 - INFO - Memory usage at start_fit: CPU 3294.6 MB, GPU 49.3 MB
2024-12-27 20:07:37,188 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:07:37,188 - INFO - Number of unique classes: 100
2024-12-27 20:07:37,284 - INFO - Fitted scaler and transformed data
2024-12-27 20:07:37,284 - INFO - Scaling time: 0.09s
2024-12-27 20:07:37,482 - INFO - Epoch 1/25, Train Loss: 24.5399, Val Loss: 18.4868
2024-12-27 20:07:37,671 - INFO - Epoch 2/25, Train Loss: 2.1896, Val Loss: 17.3782
2024-12-27 20:07:37,845 - INFO - Epoch 3/25, Train Loss: 0.7739, Val Loss: 16.7406
2024-12-27 20:07:38,099 - INFO - Epoch 4/25, Train Loss: 0.3622, Val Loss: 16.3234
2024-12-27 20:07:38,295 - INFO - Epoch 5/25, Train Loss: 0.1762, Val Loss: 16.3516
2024-12-27 20:07:38,490 - INFO - Epoch 6/25, Train Loss: 0.0835, Val Loss: 16.2323
2024-12-27 20:07:38,684 - INFO - Epoch 7/25, Train Loss: 0.0352, Val Loss: 16.1770
2024-12-27 20:07:38,863 - INFO - Epoch 8/25, Train Loss: 0.0146, Val Loss: 16.0880
2024-12-27 20:07:39,041 - INFO - Epoch 9/25, Train Loss: 0.0088, Val Loss: 16.1314
2024-12-27 20:07:39,234 - INFO - Epoch 10/25, Train Loss: 0.0062, Val Loss: 16.0975
2024-12-27 20:07:39,234 - INFO - Early stopping triggered at epoch 10
2024-12-27 20:07:39,234 - INFO - Training completed in 2.05s
2024-12-27 20:07:39,235 - INFO - Final memory usage: CPU 3294.6 MB, GPU 49.9 MB
2024-12-27 20:07:39,235 - INFO - Model training completed in 2.05s
2024-12-27 20:07:39,242 - INFO - Prediction completed in 0.01s
2024-12-27 20:07:39,250 - INFO - Poison rate 0.01 completed in 2.07s
2024-12-27 20:07:39,250 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:07:39,257 - INFO - Total number of labels flipped: 150
2024-12-27 20:07:39,257 - INFO - Label flipping completed in 0.01s
2024-12-27 20:07:39,257 - INFO - Training set processing completed in 0.00s
2024-12-27 20:07:39,257 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:07:39,258 - INFO - Memory usage at start_fit: CPU 3294.6 MB, GPU 49.3 MB
2024-12-27 20:07:39,258 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:07:39,258 - INFO - Number of unique classes: 100
2024-12-27 20:07:39,358 - INFO - Fitted scaler and transformed data
2024-12-27 20:07:39,358 - INFO - Scaling time: 0.10s
2024-12-27 20:07:39,558 - INFO - Epoch 1/25, Train Loss: 30.5449, Val Loss: 26.2791
2024-12-27 20:07:39,754 - INFO - Epoch 2/25, Train Loss: 2.4281, Val Loss: 26.8926
2024-12-27 20:07:39,930 - INFO - Epoch 3/25, Train Loss: 0.8912, Val Loss: 26.3253
2024-12-27 20:07:39,930 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:07:39,930 - INFO - Training completed in 0.67s
2024-12-27 20:07:39,931 - INFO - Final memory usage: CPU 3294.6 MB, GPU 49.9 MB
2024-12-27 20:07:39,931 - INFO - Model training completed in 0.67s
2024-12-27 20:07:39,937 - INFO - Prediction completed in 0.01s
2024-12-27 20:07:39,946 - INFO - Poison rate 0.03 completed in 0.70s
2024-12-27 20:07:39,947 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:07:39,954 - INFO - Total number of labels flipped: 250
2024-12-27 20:07:39,954 - INFO - Label flipping completed in 0.01s
2024-12-27 20:07:39,954 - INFO - Training set processing completed in 0.00s
2024-12-27 20:07:39,954 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:07:39,955 - INFO - Memory usage at start_fit: CPU 3294.6 MB, GPU 49.3 MB
2024-12-27 20:07:39,955 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:07:39,956 - INFO - Number of unique classes: 100
2024-12-27 20:07:40,050 - INFO - Fitted scaler and transformed data
2024-12-27 20:07:40,050 - INFO - Scaling time: 0.09s
2024-12-27 20:07:40,263 - INFO - Epoch 1/25, Train Loss: 37.2463, Val Loss: 27.0186
2024-12-27 20:07:40,451 - INFO - Epoch 2/25, Train Loss: 2.8721, Val Loss: 26.7367
2024-12-27 20:07:40,644 - INFO - Epoch 3/25, Train Loss: 0.9801, Val Loss: 25.4735
2024-12-27 20:07:40,863 - INFO - Epoch 4/25, Train Loss: 0.4890, Val Loss: 25.1611
2024-12-27 20:07:41,058 - INFO - Epoch 5/25, Train Loss: 0.2695, Val Loss: 25.2064
2024-12-27 20:07:41,280 - INFO - Epoch 6/25, Train Loss: 0.1400, Val Loss: 24.6972
2024-12-27 20:07:41,507 - INFO - Epoch 7/25, Train Loss: 0.0770, Val Loss: 24.6343
2024-12-27 20:07:41,714 - INFO - Epoch 8/25, Train Loss: 0.0491, Val Loss: 24.7453
2024-12-27 20:07:41,926 - INFO - Epoch 9/25, Train Loss: 0.0561, Val Loss: 24.9100
2024-12-27 20:07:41,926 - INFO - Early stopping triggered at epoch 9
2024-12-27 20:07:41,926 - INFO - Training completed in 1.97s
2024-12-27 20:07:41,927 - INFO - Final memory usage: CPU 3294.6 MB, GPU 49.9 MB
2024-12-27 20:07:41,927 - INFO - Model training completed in 1.97s
2024-12-27 20:07:41,934 - INFO - Prediction completed in 0.01s
2024-12-27 20:07:41,944 - INFO - Poison rate 0.05 completed in 2.00s
2024-12-27 20:07:41,945 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:07:41,974 - INFO - Total number of labels flipped: 350
2024-12-27 20:07:41,974 - INFO - Label flipping completed in 0.03s
2024-12-27 20:07:41,975 - INFO - Training set processing completed in 0.00s
2024-12-27 20:07:41,975 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:07:41,976 - INFO - Memory usage at start_fit: CPU 3294.6 MB, GPU 49.3 MB
2024-12-27 20:07:41,976 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:07:41,977 - INFO - Number of unique classes: 100
2024-12-27 20:07:42,085 - INFO - Fitted scaler and transformed data
2024-12-27 20:07:42,085 - INFO - Scaling time: 0.11s
2024-12-27 20:07:42,324 - INFO - Epoch 1/25, Train Loss: 41.7817, Val Loss: 37.9390
2024-12-27 20:07:42,530 - INFO - Epoch 2/25, Train Loss: 3.2301, Val Loss: 39.3799
2024-12-27 20:07:42,751 - INFO - Epoch 3/25, Train Loss: 1.1977, Val Loss: 37.5242
2024-12-27 20:07:42,961 - INFO - Epoch 4/25, Train Loss: 0.5817, Val Loss: 37.0418
2024-12-27 20:07:43,180 - INFO - Epoch 5/25, Train Loss: 0.3087, Val Loss: 36.5797
2024-12-27 20:07:43,385 - INFO - Epoch 6/25, Train Loss: 0.1674, Val Loss: 36.1596
2024-12-27 20:07:43,588 - INFO - Epoch 7/25, Train Loss: 0.0899, Val Loss: 35.8809
2024-12-27 20:07:43,802 - INFO - Epoch 8/25, Train Loss: 0.0576, Val Loss: 35.6994
2024-12-27 20:07:44,001 - INFO - Epoch 9/25, Train Loss: 0.0327, Val Loss: 35.6487
2024-12-27 20:07:44,230 - INFO - Epoch 10/25, Train Loss: 0.0168, Val Loss: 35.6781
2024-12-27 20:07:44,445 - INFO - Epoch 11/25, Train Loss: 0.0137, Val Loss: 35.6642
2024-12-27 20:07:44,446 - INFO - Early stopping triggered at epoch 11
2024-12-27 20:07:44,446 - INFO - Training completed in 2.47s
2024-12-27 20:07:44,446 - INFO - Final memory usage: CPU 3294.6 MB, GPU 49.9 MB
2024-12-27 20:07:44,446 - INFO - Model training completed in 2.47s
2024-12-27 20:07:44,454 - INFO - Prediction completed in 0.01s
2024-12-27 20:07:44,470 - INFO - Poison rate 0.07 completed in 2.53s
2024-12-27 20:07:44,470 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:07:44,486 - INFO - Total number of labels flipped: 500
2024-12-27 20:07:44,487 - INFO - Label flipping completed in 0.02s
2024-12-27 20:07:44,487 - INFO - Training set processing completed in 0.00s
2024-12-27 20:07:44,487 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:07:44,488 - INFO - Memory usage at start_fit: CPU 3294.6 MB, GPU 49.3 MB
2024-12-27 20:07:44,488 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:07:44,489 - INFO - Number of unique classes: 100
2024-12-27 20:07:44,602 - INFO - Fitted scaler and transformed data
2024-12-27 20:07:44,602 - INFO - Scaling time: 0.11s
2024-12-27 20:07:44,826 - INFO - Epoch 1/25, Train Loss: 52.2863, Val Loss: 51.9672
2024-12-27 20:07:45,053 - INFO - Epoch 2/25, Train Loss: 3.8464, Val Loss: 52.8036
2024-12-27 20:07:45,269 - INFO - Epoch 3/25, Train Loss: 1.3310, Val Loss: 51.0885
2024-12-27 20:07:45,497 - INFO - Epoch 4/25, Train Loss: 0.6548, Val Loss: 50.9001
2024-12-27 20:07:45,716 - INFO - Epoch 5/25, Train Loss: 0.3421, Val Loss: 49.9959
2024-12-27 20:07:45,948 - INFO - Epoch 6/25, Train Loss: 0.1962, Val Loss: 49.9909
2024-12-27 20:07:46,188 - INFO - Epoch 7/25, Train Loss: 0.1225, Val Loss: 49.6934
2024-12-27 20:07:46,423 - INFO - Epoch 8/25, Train Loss: 0.0650, Val Loss: 49.2245
2024-12-27 20:07:46,648 - INFO - Epoch 9/25, Train Loss: 0.0400, Val Loss: 49.5407
2024-12-27 20:07:46,857 - INFO - Epoch 10/25, Train Loss: 0.0296, Val Loss: 49.6403
2024-12-27 20:07:46,857 - INFO - Early stopping triggered at epoch 10
2024-12-27 20:07:46,857 - INFO - Training completed in 2.37s
2024-12-27 20:07:46,857 - INFO - Final memory usage: CPU 3294.6 MB, GPU 49.9 MB
2024-12-27 20:07:46,858 - INFO - Model training completed in 2.37s
2024-12-27 20:07:46,874 - INFO - Prediction completed in 0.02s
2024-12-27 20:07:46,890 - INFO - Poison rate 0.1 completed in 2.42s
2024-12-27 20:07:46,891 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:07:46,922 - INFO - Total number of labels flipped: 1000
2024-12-27 20:07:46,923 - INFO - Label flipping completed in 0.03s
2024-12-27 20:07:46,923 - INFO - Training set processing completed in 0.00s
2024-12-27 20:07:46,923 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:07:46,924 - INFO - Memory usage at start_fit: CPU 3294.6 MB, GPU 49.3 MB
2024-12-27 20:07:46,924 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:07:46,924 - INFO - Number of unique classes: 100
2024-12-27 20:07:47,032 - INFO - Fitted scaler and transformed data
2024-12-27 20:07:47,033 - INFO - Scaling time: 0.11s
2024-12-27 20:07:47,273 - INFO - Epoch 1/25, Train Loss: 75.4590, Val Loss: 75.1651
2024-12-27 20:07:47,505 - INFO - Epoch 2/25, Train Loss: 5.9845, Val Loss: 79.6129
2024-12-27 20:07:47,718 - INFO - Epoch 3/25, Train Loss: 1.8624, Val Loss: 75.5222
2024-12-27 20:07:47,718 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:07:47,718 - INFO - Training completed in 0.79s
2024-12-27 20:07:47,718 - INFO - Final memory usage: CPU 3294.6 MB, GPU 49.9 MB
2024-12-27 20:07:47,718 - INFO - Model training completed in 0.80s
2024-12-27 20:07:47,726 - INFO - Prediction completed in 0.01s
2024-12-27 20:07:47,736 - INFO - Poison rate 0.2 completed in 0.85s
2024-12-27 20:07:47,738 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:07:47,738 - INFO - Total evaluation time: 19.19s
2024-12-27 20:07:47,739 - INFO - 
Progress: 35.4% - Evaluating CIFAR100 with SVM (dynadetect mode, iteration 1/1)
2024-12-27 20:07:47,823 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:07:47,895 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:07:47,993 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:07:47,994 - INFO - Dataset type: image
2024-12-27 20:07:47,994 - INFO - Sample size: 5000
2024-12-27 20:07:47,994 - INFO - Using device: cuda
2024-12-27 20:07:47,996 - INFO - Loading datasets...
2024-12-27 20:07:49,329 - INFO - Dataset loading completed in 1.33s
2024-12-27 20:07:49,329 - INFO - Extracting validation features...
2024-12-27 20:07:49,329 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:16,  1.92it/s]Extracting features:  19%|█▉        | 6/32 [00:00<00:02, 11.71it/s]Extracting features:  31%|███▏      | 10/32 [00:00<00:01, 17.61it/s]Extracting features:  44%|████▍     | 14/32 [00:00<00:00, 22.12it/s]Extracting features:  59%|█████▉    | 19/32 [00:00<00:00, 27.46it/s]Extracting features:  75%|███████▌  | 24/32 [00:01<00:00, 31.88it/s]Extracting features:  97%|█████████▋| 31/32 [00:01<00:00, 41.35it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 25.02it/s]
2024-12-27 20:07:50,614 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:07:50,615 - INFO - Validation feature extraction completed in 1.29s
2024-12-27 20:07:50,615 - INFO - Extracting training features...
2024-12-27 20:07:50,615 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:39,  3.93it/s]Extracting features:   4%|▍         | 6/157 [00:00<00:07, 19.50it/s]Extracting features:   6%|▋         | 10/157 [00:00<00:05, 25.21it/s]Extracting features:   9%|▉         | 14/157 [00:00<00:04, 28.63it/s]Extracting features:  12%|█▏        | 19/157 [00:00<00:04, 33.30it/s]Extracting features:  15%|█▌        | 24/157 [00:00<00:03, 37.05it/s]Extracting features:  19%|█▉        | 30/157 [00:00<00:02, 42.37it/s]Extracting features:  23%|██▎       | 36/157 [00:01<00:02, 46.42it/s]Extracting features:  27%|██▋       | 42/157 [00:01<00:02, 47.60it/s]Extracting features:  30%|██▉       | 47/157 [00:01<00:02, 47.41it/s]Extracting features:  34%|███▍      | 53/157 [00:01<00:02, 49.02it/s]Extracting features:  37%|███▋      | 58/157 [00:01<00:02, 48.78it/s]Extracting features:  40%|████      | 63/157 [00:01<00:01, 47.45it/s]Extracting features:  43%|████▎     | 68/157 [00:01<00:01, 45.18it/s]Extracting features:  46%|████▋     | 73/157 [00:01<00:01, 45.73it/s]Extracting features:  50%|████▉     | 78/157 [00:01<00:01, 44.69it/s]Extracting features:  54%|█████▎    | 84/157 [00:02<00:01, 44.73it/s]Extracting features:  57%|█████▋    | 89/157 [00:02<00:01, 45.77it/s]Extracting features:  60%|█████▉    | 94/157 [00:02<00:01, 44.97it/s]Extracting features:  63%|██████▎   | 99/157 [00:02<00:01, 45.42it/s]Extracting features:  66%|██████▌   | 104/157 [00:02<00:01, 40.63it/s]Extracting features:  69%|██████▉   | 109/157 [00:02<00:01, 40.62it/s]Extracting features:  73%|███████▎  | 114/157 [00:02<00:01, 40.95it/s]Extracting features:  76%|███████▋  | 120/157 [00:02<00:00, 43.35it/s]Extracting features:  80%|███████▉  | 125/157 [00:03<00:00, 42.18it/s]Extracting features:  83%|████████▎ | 130/157 [00:03<00:00, 41.01it/s]Extracting features:  86%|████████▌ | 135/157 [00:03<00:00, 38.84it/s]Extracting features:  89%|████████▊ | 139/157 [00:03<00:00, 37.63it/s]Extracting features:  91%|█████████ | 143/157 [00:03<00:00, 37.37it/s]Extracting features:  94%|█████████▍| 148/157 [00:03<00:00, 37.98it/s]Extracting features:  97%|█████████▋| 153/157 [00:03<00:00, 38.91it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 39.77it/s]
2024-12-27 20:07:54,579 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:07:54,579 - INFO - Training feature extraction completed in 3.96s
2024-12-27 20:07:54,579 - INFO - Creating model for classifier: SVM
2024-12-27 20:07:54,579 - INFO - Using device: cuda
2024-12-27 20:07:54,579 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-27 20:07:54,580 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:07:54,580 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:07:54,580 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:07:55,202 - INFO - Feature scaling completed in 0.62s
2024-12-27 20:07:55,202 - INFO - Starting feature selection (k=50)
2024-12-27 20:07:55,211 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:07:55,211 - INFO - Starting anomaly detection
2024-12-27 20:07:56,381 - INFO - Anomaly detection completed in 1.17s
2024-12-27 20:07:56,381 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:07:56,381 - INFO - Total fit_transform time: 1.80s
2024-12-27 20:07:56,381 - INFO - Training set processing completed in 1.80s
2024-12-27 20:07:56,382 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:07:56,383 - INFO - Memory usage at start_fit: CPU 3289.6 MB, GPU 47.3 MB
2024-12-27 20:07:56,384 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:07:56,385 - INFO - Number of unique classes: 100
2024-12-27 20:07:56,491 - INFO - Fitted scaler and transformed data
2024-12-27 20:07:56,491 - INFO - Scaling time: 0.10s
2024-12-27 20:07:56,679 - INFO - Epoch 1/25, Train Loss: 21.5435, Val Loss: 13.7578
2024-12-27 20:07:56,842 - INFO - Epoch 2/25, Train Loss: 1.7859, Val Loss: 12.5055
2024-12-27 20:07:57,007 - INFO - Epoch 3/25, Train Loss: 0.6441, Val Loss: 11.6971
2024-12-27 20:07:57,189 - INFO - Epoch 4/25, Train Loss: 0.2910, Val Loss: 11.7065
2024-12-27 20:07:57,360 - INFO - Epoch 5/25, Train Loss: 0.1212, Val Loss: 11.7925
2024-12-27 20:07:57,361 - INFO - Early stopping triggered at epoch 5
2024-12-27 20:07:57,361 - INFO - Training completed in 0.98s
2024-12-27 20:07:57,361 - INFO - Final memory usage: CPU 3292.6 MB, GPU 49.9 MB
2024-12-27 20:07:57,361 - INFO - Model training completed in 0.98s
2024-12-27 20:07:57,368 - INFO - Prediction completed in 0.01s
2024-12-27 20:07:57,377 - INFO - Poison rate 0.0 completed in 2.80s
2024-12-27 20:07:57,378 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:07:57,379 - INFO - Total number of labels flipped: 50
2024-12-27 20:07:57,380 - INFO - Label flipping completed in 0.00s
2024-12-27 20:07:57,380 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:07:57,380 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:07:57,970 - INFO - Feature scaling completed in 0.59s
2024-12-27 20:07:57,970 - INFO - Starting feature selection (k=50)
2024-12-27 20:07:57,976 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:07:57,976 - INFO - Starting anomaly detection
2024-12-27 20:07:59,508 - INFO - Anomaly detection completed in 1.53s
2024-12-27 20:07:59,509 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:07:59,509 - INFO - Total fit_transform time: 2.13s
2024-12-27 20:07:59,509 - INFO - Training set processing completed in 2.13s
2024-12-27 20:07:59,509 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:07:59,510 - INFO - Memory usage at start_fit: CPU 3292.6 MB, GPU 49.3 MB
2024-12-27 20:07:59,510 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:07:59,510 - INFO - Number of unique classes: 100
2024-12-27 20:07:59,603 - INFO - Fitted scaler and transformed data
2024-12-27 20:07:59,603 - INFO - Scaling time: 0.09s
2024-12-27 20:07:59,788 - INFO - Epoch 1/25, Train Loss: 25.2516, Val Loss: 19.0945
2024-12-27 20:07:59,955 - INFO - Epoch 2/25, Train Loss: 1.8905, Val Loss: 19.0445
2024-12-27 20:08:00,124 - INFO - Epoch 3/25, Train Loss: 0.6838, Val Loss: 18.7709
2024-12-27 20:08:00,307 - INFO - Epoch 4/25, Train Loss: 0.2999, Val Loss: 18.4032
2024-12-27 20:08:00,497 - INFO - Epoch 5/25, Train Loss: 0.1454, Val Loss: 18.4232
2024-12-27 20:08:00,689 - INFO - Epoch 6/25, Train Loss: 0.0705, Val Loss: 18.2534
2024-12-27 20:08:00,859 - INFO - Epoch 7/25, Train Loss: 0.0320, Val Loss: 18.4387
2024-12-27 20:08:01,024 - INFO - Epoch 8/25, Train Loss: 0.0165, Val Loss: 18.4173
2024-12-27 20:08:01,024 - INFO - Early stopping triggered at epoch 8
2024-12-27 20:08:01,025 - INFO - Training completed in 1.52s
2024-12-27 20:08:01,025 - INFO - Final memory usage: CPU 3292.6 MB, GPU 49.9 MB
2024-12-27 20:08:01,025 - INFO - Model training completed in 1.52s
2024-12-27 20:08:01,032 - INFO - Prediction completed in 0.01s
2024-12-27 20:08:01,040 - INFO - Poison rate 0.01 completed in 3.66s
2024-12-27 20:08:01,041 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:08:01,045 - INFO - Total number of labels flipped: 150
2024-12-27 20:08:01,046 - INFO - Label flipping completed in 0.00s
2024-12-27 20:08:01,046 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:08:01,046 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:08:01,696 - INFO - Feature scaling completed in 0.65s
2024-12-27 20:08:01,696 - INFO - Starting feature selection (k=50)
2024-12-27 20:08:01,704 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:08:01,704 - INFO - Starting anomaly detection
2024-12-27 20:08:03,038 - INFO - Anomaly detection completed in 1.33s
2024-12-27 20:08:03,038 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:08:03,038 - INFO - Total fit_transform time: 1.99s
2024-12-27 20:08:03,038 - INFO - Training set processing completed in 1.99s
2024-12-27 20:08:03,038 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:08:03,040 - INFO - Memory usage at start_fit: CPU 3292.6 MB, GPU 49.3 MB
2024-12-27 20:08:03,040 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:08:03,041 - INFO - Number of unique classes: 100
2024-12-27 20:08:03,152 - INFO - Fitted scaler and transformed data
2024-12-27 20:08:03,152 - INFO - Scaling time: 0.11s
2024-12-27 20:08:03,330 - INFO - Epoch 1/25, Train Loss: 30.2516, Val Loss: 25.1549
2024-12-27 20:08:03,544 - INFO - Epoch 2/25, Train Loss: 2.3941, Val Loss: 23.7878
2024-12-27 20:08:03,722 - INFO - Epoch 3/25, Train Loss: 0.8638, Val Loss: 22.9531
2024-12-27 20:08:03,888 - INFO - Epoch 4/25, Train Loss: 0.4469, Val Loss: 22.5924
2024-12-27 20:08:04,066 - INFO - Epoch 5/25, Train Loss: 0.2211, Val Loss: 22.7731
2024-12-27 20:08:04,238 - INFO - Epoch 6/25, Train Loss: 0.1315, Val Loss: 22.4530
2024-12-27 20:08:04,404 - INFO - Epoch 7/25, Train Loss: 0.0581, Val Loss: 22.5577
2024-12-27 20:08:04,572 - INFO - Epoch 8/25, Train Loss: 0.0243, Val Loss: 22.4839
2024-12-27 20:08:04,573 - INFO - Early stopping triggered at epoch 8
2024-12-27 20:08:04,573 - INFO - Training completed in 1.53s
2024-12-27 20:08:04,573 - INFO - Final memory usage: CPU 3292.6 MB, GPU 49.9 MB
2024-12-27 20:08:04,573 - INFO - Model training completed in 1.53s
2024-12-27 20:08:04,584 - INFO - Prediction completed in 0.01s
2024-12-27 20:08:04,595 - INFO - Poison rate 0.03 completed in 3.55s
2024-12-27 20:08:04,595 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:08:04,609 - INFO - Total number of labels flipped: 250
2024-12-27 20:08:04,609 - INFO - Label flipping completed in 0.01s
2024-12-27 20:08:04,610 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:08:04,610 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:08:05,178 - INFO - Feature scaling completed in 0.57s
2024-12-27 20:08:05,178 - INFO - Starting feature selection (k=50)
2024-12-27 20:08:05,192 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:08:05,192 - INFO - Starting anomaly detection
2024-12-27 20:08:06,430 - INFO - Anomaly detection completed in 1.24s
2024-12-27 20:08:06,430 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:08:06,430 - INFO - Total fit_transform time: 1.82s
2024-12-27 20:08:06,430 - INFO - Training set processing completed in 1.82s
2024-12-27 20:08:06,430 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:08:06,431 - INFO - Memory usage at start_fit: CPU 3292.6 MB, GPU 49.3 MB
2024-12-27 20:08:06,431 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:08:06,432 - INFO - Number of unique classes: 100
2024-12-27 20:08:06,526 - INFO - Fitted scaler and transformed data
2024-12-27 20:08:06,526 - INFO - Scaling time: 0.09s
2024-12-27 20:08:06,700 - INFO - Epoch 1/25, Train Loss: 36.2576, Val Loss: 24.5209
2024-12-27 20:08:06,900 - INFO - Epoch 2/25, Train Loss: 2.6265, Val Loss: 24.3947
2024-12-27 20:08:07,078 - INFO - Epoch 3/25, Train Loss: 0.9094, Val Loss: 23.6666
2024-12-27 20:08:07,289 - INFO - Epoch 4/25, Train Loss: 0.4227, Val Loss: 23.5157
2024-12-27 20:08:07,498 - INFO - Epoch 5/25, Train Loss: 0.2176, Val Loss: 23.7850
2024-12-27 20:08:07,679 - INFO - Epoch 6/25, Train Loss: 0.1094, Val Loss: 23.8184
2024-12-27 20:08:07,679 - INFO - Early stopping triggered at epoch 6
2024-12-27 20:08:07,679 - INFO - Training completed in 1.25s
2024-12-27 20:08:07,679 - INFO - Final memory usage: CPU 3292.6 MB, GPU 49.9 MB
2024-12-27 20:08:07,679 - INFO - Model training completed in 1.25s
2024-12-27 20:08:07,686 - INFO - Prediction completed in 0.01s
2024-12-27 20:08:07,695 - INFO - Poison rate 0.05 completed in 3.10s
2024-12-27 20:08:07,695 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:08:07,705 - INFO - Total number of labels flipped: 350
2024-12-27 20:08:07,705 - INFO - Label flipping completed in 0.01s
2024-12-27 20:08:07,707 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:08:07,707 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:08:08,293 - INFO - Feature scaling completed in 0.59s
2024-12-27 20:08:08,293 - INFO - Starting feature selection (k=50)
2024-12-27 20:08:08,306 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:08:08,306 - INFO - Starting anomaly detection
2024-12-27 20:08:10,182 - INFO - Anomaly detection completed in 1.88s
2024-12-27 20:08:10,182 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:08:10,182 - INFO - Total fit_transform time: 2.48s
2024-12-27 20:08:10,182 - INFO - Training set processing completed in 2.48s
2024-12-27 20:08:10,183 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:08:10,184 - INFO - Memory usage at start_fit: CPU 3292.6 MB, GPU 49.3 MB
2024-12-27 20:08:10,184 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:08:10,184 - INFO - Number of unique classes: 100
2024-12-27 20:08:10,280 - INFO - Fitted scaler and transformed data
2024-12-27 20:08:10,280 - INFO - Scaling time: 0.09s
2024-12-27 20:08:10,471 - INFO - Epoch 1/25, Train Loss: 39.4580, Val Loss: 37.8533
2024-12-27 20:08:10,659 - INFO - Epoch 2/25, Train Loss: 2.9238, Val Loss: 37.3817
2024-12-27 20:08:10,851 - INFO - Epoch 3/25, Train Loss: 1.0153, Val Loss: 36.4323
2024-12-27 20:08:11,020 - INFO - Epoch 4/25, Train Loss: 0.5023, Val Loss: 35.3257
2024-12-27 20:08:11,197 - INFO - Epoch 5/25, Train Loss: 0.2923, Val Loss: 35.3203
2024-12-27 20:08:11,379 - INFO - Epoch 6/25, Train Loss: 0.1667, Val Loss: 35.1125
2024-12-27 20:08:11,571 - INFO - Epoch 7/25, Train Loss: 0.0829, Val Loss: 35.1625
2024-12-27 20:08:11,763 - INFO - Epoch 8/25, Train Loss: 0.0485, Val Loss: 35.1024
2024-12-27 20:08:11,939 - INFO - Epoch 9/25, Train Loss: 0.0417, Val Loss: 35.2213
2024-12-27 20:08:12,157 - INFO - Epoch 10/25, Train Loss: 0.0132, Val Loss: 35.1159
2024-12-27 20:08:12,157 - INFO - Early stopping triggered at epoch 10
2024-12-27 20:08:12,157 - INFO - Training completed in 1.97s
2024-12-27 20:08:12,157 - INFO - Final memory usage: CPU 3292.6 MB, GPU 49.9 MB
2024-12-27 20:08:12,157 - INFO - Model training completed in 1.97s
2024-12-27 20:08:12,166 - INFO - Prediction completed in 0.01s
2024-12-27 20:08:12,175 - INFO - Poison rate 0.07 completed in 4.48s
2024-12-27 20:08:12,175 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:08:12,190 - INFO - Total number of labels flipped: 500
2024-12-27 20:08:12,190 - INFO - Label flipping completed in 0.01s
2024-12-27 20:08:12,190 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:08:12,190 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:08:12,799 - INFO - Feature scaling completed in 0.61s
2024-12-27 20:08:12,799 - INFO - Starting feature selection (k=50)
2024-12-27 20:08:12,813 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:08:12,814 - INFO - Starting anomaly detection
2024-12-27 20:08:14,285 - INFO - Anomaly detection completed in 1.47s
2024-12-27 20:08:14,286 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:08:14,286 - INFO - Total fit_transform time: 2.10s
2024-12-27 20:08:14,286 - INFO - Training set processing completed in 2.10s
2024-12-27 20:08:14,286 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:08:14,287 - INFO - Memory usage at start_fit: CPU 3292.6 MB, GPU 49.3 MB
2024-12-27 20:08:14,287 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:08:14,288 - INFO - Number of unique classes: 100
2024-12-27 20:08:14,399 - INFO - Fitted scaler and transformed data
2024-12-27 20:08:14,399 - INFO - Scaling time: 0.11s
2024-12-27 20:08:14,600 - INFO - Epoch 1/25, Train Loss: 48.0470, Val Loss: 46.6029
2024-12-27 20:08:14,784 - INFO - Epoch 2/25, Train Loss: 3.3444, Val Loss: 52.0246
2024-12-27 20:08:14,950 - INFO - Epoch 3/25, Train Loss: 1.2108, Val Loss: 50.6028
2024-12-27 20:08:14,951 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:08:14,951 - INFO - Training completed in 0.66s
2024-12-27 20:08:14,951 - INFO - Final memory usage: CPU 3292.6 MB, GPU 49.9 MB
2024-12-27 20:08:14,951 - INFO - Model training completed in 0.67s
2024-12-27 20:08:14,960 - INFO - Prediction completed in 0.01s
2024-12-27 20:08:14,972 - INFO - Poison rate 0.1 completed in 2.80s
2024-12-27 20:08:14,973 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:08:15,020 - INFO - Total number of labels flipped: 1000
2024-12-27 20:08:15,020 - INFO - Label flipping completed in 0.05s
2024-12-27 20:08:15,020 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:08:15,020 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:08:15,638 - INFO - Feature scaling completed in 0.62s
2024-12-27 20:08:15,639 - INFO - Starting feature selection (k=50)
2024-12-27 20:08:15,647 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:08:15,648 - INFO - Starting anomaly detection
2024-12-27 20:08:17,601 - INFO - Anomaly detection completed in 1.95s
2024-12-27 20:08:17,602 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:08:17,602 - INFO - Total fit_transform time: 2.58s
2024-12-27 20:08:17,602 - INFO - Training set processing completed in 2.58s
2024-12-27 20:08:17,602 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:08:17,603 - INFO - Memory usage at start_fit: CPU 3292.6 MB, GPU 49.3 MB
2024-12-27 20:08:17,604 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:08:17,605 - INFO - Number of unique classes: 100
2024-12-27 20:08:17,699 - INFO - Fitted scaler and transformed data
2024-12-27 20:08:17,699 - INFO - Scaling time: 0.09s
2024-12-27 20:08:17,867 - INFO - Epoch 1/25, Train Loss: 71.2956, Val Loss: 88.6639
2024-12-27 20:08:18,018 - INFO - Epoch 2/25, Train Loss: 4.9466, Val Loss: 91.6983
2024-12-27 20:08:18,184 - INFO - Epoch 3/25, Train Loss: 1.6078, Val Loss: 90.9382
2024-12-27 20:08:18,185 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:08:18,185 - INFO - Training completed in 0.58s
2024-12-27 20:08:18,185 - INFO - Final memory usage: CPU 3292.6 MB, GPU 49.9 MB
2024-12-27 20:08:18,185 - INFO - Model training completed in 0.58s
2024-12-27 20:08:18,193 - INFO - Prediction completed in 0.01s
2024-12-27 20:08:18,204 - INFO - Poison rate 0.2 completed in 3.23s
2024-12-27 20:08:18,207 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:08:18,207 - INFO - Total evaluation time: 30.21s
2024-12-27 20:08:18,209 - INFO - 
Progress: 36.5% - Evaluating CIFAR100 with LogisticRegression (standard mode, iteration 1/1)
2024-12-27 20:08:18,270 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:08:18,345 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:08:18,424 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:08:18,424 - INFO - Dataset type: image
2024-12-27 20:08:18,424 - INFO - Sample size: 5000
2024-12-27 20:08:18,424 - INFO - Using device: cuda
2024-12-27 20:08:18,426 - INFO - Loading datasets...
2024-12-27 20:08:19,758 - INFO - Dataset loading completed in 1.33s
2024-12-27 20:08:19,758 - INFO - Extracting validation features...
2024-12-27 20:08:19,758 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:12,  2.51it/s]Extracting features:   6%|▋         | 2/32 [00:00<00:06,  4.35it/s]Extracting features:  19%|█▉        | 6/32 [00:00<00:01, 13.16it/s]Extracting features:  38%|███▊      | 12/32 [00:00<00:00, 25.03it/s]Extracting features:  50%|█████     | 16/32 [00:00<00:00, 28.71it/s]Extracting features:  66%|██████▌   | 21/32 [00:00<00:00, 33.98it/s]Extracting features:  81%|████████▏ | 26/32 [00:01<00:00, 37.03it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 26.76it/s]
2024-12-27 20:08:20,958 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:08:20,959 - INFO - Validation feature extraction completed in 1.20s
2024-12-27 20:08:20,959 - INFO - Extracting training features...
2024-12-27 20:08:20,959 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:42,  3.67it/s]Extracting features:   4%|▍         | 6/157 [00:00<00:07, 19.39it/s]Extracting features:   7%|▋         | 11/157 [00:00<00:05, 28.70it/s]Extracting features:  11%|█         | 17/157 [00:00<00:03, 37.72it/s]Extracting features:  14%|█▍        | 22/157 [00:00<00:03, 41.02it/s]Extracting features:  18%|█▊        | 28/157 [00:00<00:02, 45.18it/s]Extracting features:  22%|██▏       | 34/157 [00:00<00:02, 47.71it/s]Extracting features:  25%|██▌       | 40/157 [00:01<00:02, 44.92it/s]Extracting features:  29%|██▊       | 45/157 [00:01<00:02, 44.22it/s]Extracting features:  32%|███▏      | 51/157 [00:01<00:02, 47.68it/s]Extracting features:  36%|███▋      | 57/157 [00:01<00:01, 50.48it/s]Extracting features:  40%|████      | 63/157 [00:01<00:01, 52.11it/s]Extracting features:  44%|████▍     | 69/157 [00:01<00:01, 52.34it/s]Extracting features:  48%|████▊     | 75/157 [00:01<00:01, 53.04it/s]Extracting features:  52%|█████▏    | 81/157 [00:01<00:01, 52.87it/s]Extracting features:  55%|█████▌    | 87/157 [00:01<00:01, 50.25it/s]Extracting features:  59%|█████▉    | 93/157 [00:02<00:01, 51.40it/s]Extracting features:  63%|██████▎   | 99/157 [00:02<00:01, 52.17it/s]Extracting features:  67%|██████▋   | 105/157 [00:02<00:01, 49.53it/s]Extracting features:  71%|███████   | 111/157 [00:02<00:00, 50.18it/s]Extracting features:  75%|███████▌  | 118/157 [00:02<00:00, 53.39it/s]Extracting features:  79%|███████▉  | 124/157 [00:02<00:00, 52.18it/s]Extracting features:  83%|████████▎ | 130/157 [00:02<00:00, 52.25it/s]Extracting features:  87%|████████▋ | 136/157 [00:02<00:00, 53.01it/s]Extracting features:  90%|█████████ | 142/157 [00:03<00:00, 52.64it/s]Extracting features:  95%|█████████▍| 149/157 [00:03<00:00, 54.18it/s]Extracting features:  99%|█████████▊| 155/157 [00:03<00:00, 55.33it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 47.22it/s]
2024-12-27 20:08:24,293 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:08:24,294 - INFO - Training feature extraction completed in 3.33s
2024-12-27 20:08:24,294 - INFO - Creating model for classifier: LogisticRegression
2024-12-27 20:08:24,294 - INFO - Using device: cuda
2024-12-27 20:08:24,294 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:08:24,294 - INFO - Training set processing completed in 0.00s
2024-12-27 20:08:24,294 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:08:24,295 - INFO - Memory usage at start_fit: CPU 3274.6 MB, GPU 47.3 MB
2024-12-27 20:08:24,295 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:08:24,296 - INFO - Number of unique classes: 100
2024-12-27 20:08:24,412 - INFO - Fitted scaler and transformed data
2024-12-27 20:08:24,412 - INFO - Scaling time: 0.11s
2024-12-27 20:08:24,553 - INFO - Epoch 1/200, Train Loss: 2.6313, Val Loss: 2.8280
2024-12-27 20:08:24,677 - INFO - Epoch 2/200, Train Loss: 0.4842, Val Loss: 2.8126
2024-12-27 20:08:24,782 - INFO - Epoch 3/200, Train Loss: 0.1550, Val Loss: 2.8848
2024-12-27 20:08:24,907 - INFO - Epoch 4/200, Train Loss: 0.0726, Val Loss: 3.1160
2024-12-27 20:08:24,908 - INFO - Early stopping triggered at epoch 4
2024-12-27 20:08:24,908 - INFO - Training completed in 0.61s
2024-12-27 20:08:24,908 - INFO - Final memory usage: CPU 3299.1 MB, GPU 49.9 MB
2024-12-27 20:08:24,908 - INFO - Model training completed in 0.61s
2024-12-27 20:08:24,919 - INFO - Prediction completed in 0.01s
2024-12-27 20:08:24,945 - INFO - Poison rate 0.0 completed in 0.65s
2024-12-27 20:08:24,945 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:08:24,951 - INFO - Total number of labels flipped: 50
2024-12-27 20:08:24,951 - INFO - Label flipping completed in 0.01s
2024-12-27 20:08:24,951 - INFO - Training set processing completed in 0.00s
2024-12-27 20:08:24,951 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:08:24,953 - INFO - Memory usage at start_fit: CPU 3299.1 MB, GPU 49.3 MB
2024-12-27 20:08:24,953 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:08:24,954 - INFO - Number of unique classes: 100
2024-12-27 20:08:25,042 - INFO - Fitted scaler and transformed data
2024-12-27 20:08:25,043 - INFO - Scaling time: 0.08s
2024-12-27 20:08:25,176 - INFO - Epoch 1/200, Train Loss: 2.7057, Val Loss: 2.8510
2024-12-27 20:08:25,286 - INFO - Epoch 2/200, Train Loss: 0.5907, Val Loss: 2.8498
2024-12-27 20:08:25,410 - INFO - Epoch 3/200, Train Loss: 0.1934, Val Loss: 3.1572
2024-12-27 20:08:25,410 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:08:25,410 - INFO - Training completed in 0.46s
2024-12-27 20:08:25,410 - INFO - Final memory usage: CPU 3299.1 MB, GPU 49.9 MB
2024-12-27 20:08:25,411 - INFO - Model training completed in 0.46s
2024-12-27 20:08:25,418 - INFO - Prediction completed in 0.01s
2024-12-27 20:08:25,442 - INFO - Poison rate 0.01 completed in 0.50s
2024-12-27 20:08:25,442 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:08:25,456 - INFO - Total number of labels flipped: 150
2024-12-27 20:08:25,456 - INFO - Label flipping completed in 0.01s
2024-12-27 20:08:25,456 - INFO - Training set processing completed in 0.00s
2024-12-27 20:08:25,456 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:08:25,458 - INFO - Memory usage at start_fit: CPU 3299.1 MB, GPU 49.3 MB
2024-12-27 20:08:25,458 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:08:25,459 - INFO - Number of unique classes: 100
2024-12-27 20:08:25,544 - INFO - Fitted scaler and transformed data
2024-12-27 20:08:25,544 - INFO - Scaling time: 0.08s
2024-12-27 20:08:25,670 - INFO - Epoch 1/200, Train Loss: 3.0627, Val Loss: 2.8488
2024-12-27 20:08:25,784 - INFO - Epoch 2/200, Train Loss: 0.6509, Val Loss: 3.1508
2024-12-27 20:08:25,913 - INFO - Epoch 3/200, Train Loss: 0.2085, Val Loss: 3.1289
2024-12-27 20:08:25,913 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:08:25,914 - INFO - Training completed in 0.46s
2024-12-27 20:08:25,915 - INFO - Final memory usage: CPU 3299.1 MB, GPU 49.9 MB
2024-12-27 20:08:25,916 - INFO - Model training completed in 0.46s
2024-12-27 20:08:25,923 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:08:25,949 - INFO - Poison rate 0.03 completed in 0.51s
2024-12-27 20:08:25,949 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:08:25,969 - INFO - Total number of labels flipped: 250
2024-12-27 20:08:25,970 - INFO - Label flipping completed in 0.02s
2024-12-27 20:08:25,970 - INFO - Training set processing completed in 0.00s
2024-12-27 20:08:25,970 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:08:25,971 - INFO - Memory usage at start_fit: CPU 3299.1 MB, GPU 49.3 MB
2024-12-27 20:08:25,972 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:08:25,972 - INFO - Number of unique classes: 100
2024-12-27 20:08:26,072 - INFO - Fitted scaler and transformed data
2024-12-27 20:08:26,072 - INFO - Scaling time: 0.10s
2024-12-27 20:08:26,383 - INFO - Epoch 1/200, Train Loss: 3.1703, Val Loss: 3.2419
2024-12-27 20:08:26,578 - INFO - Epoch 2/200, Train Loss: 0.6870, Val Loss: 3.4923
2024-12-27 20:08:26,686 - INFO - Epoch 3/200, Train Loss: 0.2039, Val Loss: 3.4987
2024-12-27 20:08:26,687 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:08:26,687 - INFO - Training completed in 0.72s
2024-12-27 20:08:26,687 - INFO - Final memory usage: CPU 3299.1 MB, GPU 49.9 MB
2024-12-27 20:08:26,687 - INFO - Model training completed in 0.72s
2024-12-27 20:08:26,694 - INFO - Prediction completed in 0.01s
2024-12-27 20:08:26,708 - INFO - Poison rate 0.05 completed in 0.76s
2024-12-27 20:08:26,709 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:08:26,734 - INFO - Total number of labels flipped: 350
2024-12-27 20:08:26,735 - INFO - Label flipping completed in 0.03s
2024-12-27 20:08:26,735 - INFO - Training set processing completed in 0.00s
2024-12-27 20:08:26,735 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:08:26,736 - INFO - Memory usage at start_fit: CPU 3299.1 MB, GPU 49.3 MB
2024-12-27 20:08:26,736 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:08:26,737 - INFO - Number of unique classes: 100
2024-12-27 20:08:26,849 - INFO - Fitted scaler and transformed data
2024-12-27 20:08:26,849 - INFO - Scaling time: 0.11s
2024-12-27 20:08:26,986 - INFO - Epoch 1/200, Train Loss: 3.4221, Val Loss: 3.2660
2024-12-27 20:08:27,118 - INFO - Epoch 2/200, Train Loss: 0.7965, Val Loss: 3.5866
2024-12-27 20:08:27,224 - INFO - Epoch 3/200, Train Loss: 0.2635, Val Loss: 3.8763
2024-12-27 20:08:27,224 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:08:27,224 - INFO - Training completed in 0.49s
2024-12-27 20:08:27,224 - INFO - Final memory usage: CPU 3299.1 MB, GPU 49.9 MB
2024-12-27 20:08:27,225 - INFO - Model training completed in 0.49s
2024-12-27 20:08:27,232 - INFO - Prediction completed in 0.01s
2024-12-27 20:08:27,240 - INFO - Poison rate 0.07 completed in 0.53s
2024-12-27 20:08:27,240 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:08:27,261 - INFO - Total number of labels flipped: 500
2024-12-27 20:08:27,261 - INFO - Label flipping completed in 0.02s
2024-12-27 20:08:27,261 - INFO - Training set processing completed in 0.00s
2024-12-27 20:08:27,261 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:08:27,262 - INFO - Memory usage at start_fit: CPU 3299.1 MB, GPU 49.3 MB
2024-12-27 20:08:27,262 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:08:27,263 - INFO - Number of unique classes: 100
2024-12-27 20:08:27,346 - INFO - Fitted scaler and transformed data
2024-12-27 20:08:27,346 - INFO - Scaling time: 0.08s
2024-12-27 20:08:27,476 - INFO - Epoch 1/200, Train Loss: 3.6678, Val Loss: 3.4770
2024-12-27 20:08:27,602 - INFO - Epoch 2/200, Train Loss: 0.9426, Val Loss: 3.5782
2024-12-27 20:08:27,714 - INFO - Epoch 3/200, Train Loss: 0.2750, Val Loss: 3.7867
2024-12-27 20:08:27,715 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:08:27,715 - INFO - Training completed in 0.45s
2024-12-27 20:08:27,715 - INFO - Final memory usage: CPU 3299.1 MB, GPU 49.9 MB
2024-12-27 20:08:27,715 - INFO - Model training completed in 0.45s
2024-12-27 20:08:27,722 - INFO - Prediction completed in 0.01s
2024-12-27 20:08:27,731 - INFO - Poison rate 0.1 completed in 0.49s
2024-12-27 20:08:27,731 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:08:27,782 - INFO - Total number of labels flipped: 1000
2024-12-27 20:08:27,783 - INFO - Label flipping completed in 0.05s
2024-12-27 20:08:27,783 - INFO - Training set processing completed in 0.00s
2024-12-27 20:08:27,783 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:08:27,784 - INFO - Memory usage at start_fit: CPU 3299.1 MB, GPU 49.3 MB
2024-12-27 20:08:27,784 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:08:27,784 - INFO - Number of unique classes: 100
2024-12-27 20:08:27,871 - INFO - Fitted scaler and transformed data
2024-12-27 20:08:27,871 - INFO - Scaling time: 0.08s
2024-12-27 20:08:28,050 - INFO - Epoch 1/200, Train Loss: 4.3268, Val Loss: 4.6619
2024-12-27 20:08:28,286 - INFO - Epoch 2/200, Train Loss: 1.1039, Val Loss: 4.7382
2024-12-27 20:08:28,498 - INFO - Epoch 3/200, Train Loss: 0.3702, Val Loss: 4.9978
2024-12-27 20:08:28,499 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:08:28,499 - INFO - Training completed in 0.72s
2024-12-27 20:08:28,500 - INFO - Final memory usage: CPU 3299.1 MB, GPU 49.9 MB
2024-12-27 20:08:28,500 - INFO - Model training completed in 0.72s
2024-12-27 20:08:28,515 - INFO - Prediction completed in 0.01s
2024-12-27 20:08:28,532 - INFO - Poison rate 0.2 completed in 0.80s
2024-12-27 20:08:28,535 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:08:28,535 - INFO - Total evaluation time: 10.11s
2024-12-27 20:08:28,536 - INFO - 
Progress: 37.5% - Evaluating CIFAR100 with LogisticRegression (dynadetect mode, iteration 1/1)
2024-12-27 20:08:28,598 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:08:28,671 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:08:28,753 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:08:28,753 - INFO - Dataset type: image
2024-12-27 20:08:28,753 - INFO - Sample size: 5000
2024-12-27 20:08:28,753 - INFO - Using device: cuda
2024-12-27 20:08:28,755 - INFO - Loading datasets...
2024-12-27 20:08:30,017 - INFO - Dataset loading completed in 1.26s
2024-12-27 20:08:30,017 - INFO - Extracting validation features...
2024-12-27 20:08:30,017 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:13,  2.33it/s]Extracting features:   6%|▋         | 2/32 [00:00<00:07,  3.85it/s]Extracting features:  12%|█▎        | 4/32 [00:00<00:03,  7.71it/s]Extracting features:  28%|██▊       | 9/32 [00:00<00:01, 18.01it/s]Extracting features:  47%|████▋     | 15/32 [00:00<00:00, 28.58it/s]Extracting features:  59%|█████▉    | 19/32 [00:01<00:00, 29.91it/s]Extracting features:  72%|███████▏  | 23/32 [00:01<00:00, 31.15it/s]Extracting features:  91%|█████████ | 29/32 [00:01<00:00, 38.00it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 23.59it/s]
2024-12-27 20:08:31,380 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:08:31,381 - INFO - Validation feature extraction completed in 1.36s
2024-12-27 20:08:31,381 - INFO - Extracting training features...
2024-12-27 20:08:31,381 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:45,  3.46it/s]Extracting features:   4%|▍         | 7/157 [00:00<00:06, 21.69it/s]Extracting features:   8%|▊         | 13/157 [00:00<00:04, 32.41it/s]Extracting features:  12%|█▏        | 19/157 [00:00<00:03, 39.63it/s]Extracting features:  16%|█▌        | 25/157 [00:00<00:02, 44.51it/s]Extracting features:  20%|█▉        | 31/157 [00:00<00:02, 47.79it/s]Extracting features:  24%|██▎       | 37/157 [00:00<00:02, 51.05it/s]Extracting features:  27%|██▋       | 43/157 [00:01<00:02, 53.24it/s]Extracting features:  31%|███       | 49/157 [00:01<00:02, 53.39it/s]Extracting features:  35%|███▌      | 55/157 [00:01<00:01, 53.18it/s]Extracting features:  39%|███▉      | 61/157 [00:01<00:01, 54.70it/s]Extracting features:  43%|████▎     | 67/157 [00:01<00:01, 53.55it/s]Extracting features:  47%|████▋     | 74/157 [00:01<00:01, 55.62it/s]Extracting features:  51%|█████     | 80/157 [00:01<00:01, 54.34it/s]Extracting features:  55%|█████▌    | 87/157 [00:01<00:01, 56.62it/s]Extracting features:  59%|█████▉    | 93/157 [00:01<00:01, 56.46it/s]Extracting features:  63%|██████▎   | 99/157 [00:02<00:01, 56.05it/s]Extracting features:  67%|██████▋   | 105/157 [00:02<00:00, 57.12it/s]Extracting features:  71%|███████   | 111/157 [00:02<00:00, 56.70it/s]Extracting features:  75%|███████▍  | 117/157 [00:02<00:00, 55.45it/s]Extracting features:  78%|███████▊  | 123/157 [00:02<00:00, 55.03it/s]Extracting features:  82%|████████▏ | 129/157 [00:02<00:00, 54.53it/s]Extracting features:  87%|████████▋ | 136/157 [00:02<00:00, 56.59it/s]Extracting features:  90%|█████████ | 142/157 [00:02<00:00, 55.06it/s]Extracting features:  95%|█████████▍| 149/157 [00:02<00:00, 56.37it/s]Extracting features:  99%|█████████▊| 155/157 [00:03<00:00, 52.86it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 49.25it/s]
2024-12-27 20:08:34,578 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:08:34,578 - INFO - Training feature extraction completed in 3.20s
2024-12-27 20:08:34,578 - INFO - Creating model for classifier: LogisticRegression
2024-12-27 20:08:34,578 - INFO - Using device: cuda
2024-12-27 20:08:34,578 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:08:34,579 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:08:34,579 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:08:35,205 - INFO - Feature scaling completed in 0.63s
2024-12-27 20:08:35,205 - INFO - Starting feature selection (k=50)
2024-12-27 20:08:35,214 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:08:35,215 - INFO - Starting anomaly detection
2024-12-27 20:08:37,148 - INFO - Anomaly detection completed in 1.93s
2024-12-27 20:08:37,148 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:08:37,149 - INFO - Total fit_transform time: 2.57s
2024-12-27 20:08:37,149 - INFO - Training set processing completed in 2.57s
2024-12-27 20:08:37,149 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:08:37,150 - INFO - Memory usage at start_fit: CPU 3296.4 MB, GPU 47.3 MB
2024-12-27 20:08:37,150 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:08:37,151 - INFO - Number of unique classes: 100
2024-12-27 20:08:37,244 - INFO - Fitted scaler and transformed data
2024-12-27 20:08:37,244 - INFO - Scaling time: 0.09s
2024-12-27 20:08:37,373 - INFO - Epoch 1/200, Train Loss: 2.7498, Val Loss: 2.5463
2024-12-27 20:08:37,513 - INFO - Epoch 2/200, Train Loss: 0.5269, Val Loss: 2.7720
2024-12-27 20:08:37,621 - INFO - Epoch 3/200, Train Loss: 0.1495, Val Loss: 2.5342
2024-12-27 20:08:37,749 - INFO - Epoch 4/200, Train Loss: 0.0591, Val Loss: 2.6204
2024-12-27 20:08:37,894 - INFO - Epoch 5/200, Train Loss: 0.0381, Val Loss: 2.6180
2024-12-27 20:08:37,894 - INFO - Early stopping triggered at epoch 5
2024-12-27 20:08:37,894 - INFO - Training completed in 0.74s
2024-12-27 20:08:37,895 - INFO - Final memory usage: CPU 3296.4 MB, GPU 49.9 MB
2024-12-27 20:08:37,896 - INFO - Model training completed in 0.75s
2024-12-27 20:08:37,911 - INFO - Prediction completed in 0.01s
2024-12-27 20:08:37,929 - INFO - Poison rate 0.0 completed in 3.35s
2024-12-27 20:08:37,929 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:08:37,931 - INFO - Total number of labels flipped: 50
2024-12-27 20:08:37,931 - INFO - Label flipping completed in 0.00s
2024-12-27 20:08:37,931 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:08:37,931 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:08:38,594 - INFO - Feature scaling completed in 0.66s
2024-12-27 20:08:38,594 - INFO - Starting feature selection (k=50)
2024-12-27 20:08:38,599 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:08:38,599 - INFO - Starting anomaly detection
2024-12-27 20:08:39,776 - INFO - Anomaly detection completed in 1.18s
2024-12-27 20:08:39,776 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:08:39,776 - INFO - Total fit_transform time: 1.84s
2024-12-27 20:08:39,776 - INFO - Training set processing completed in 1.84s
2024-12-27 20:08:39,776 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:08:39,777 - INFO - Memory usage at start_fit: CPU 3296.4 MB, GPU 49.3 MB
2024-12-27 20:08:39,777 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:08:39,778 - INFO - Number of unique classes: 100
2024-12-27 20:08:39,876 - INFO - Fitted scaler and transformed data
2024-12-27 20:08:39,876 - INFO - Scaling time: 0.10s
2024-12-27 20:08:40,002 - INFO - Epoch 1/200, Train Loss: 2.8546, Val Loss: 2.6568
2024-12-27 20:08:40,130 - INFO - Epoch 2/200, Train Loss: 0.5760, Val Loss: 2.9022
2024-12-27 20:08:40,256 - INFO - Epoch 3/200, Train Loss: 0.1731, Val Loss: 2.8733
2024-12-27 20:08:40,256 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:08:40,256 - INFO - Training completed in 0.48s
2024-12-27 20:08:40,257 - INFO - Final memory usage: CPU 3296.4 MB, GPU 49.9 MB
2024-12-27 20:08:40,257 - INFO - Model training completed in 0.48s
2024-12-27 20:08:40,263 - INFO - Prediction completed in 0.01s
2024-12-27 20:08:40,285 - INFO - Poison rate 0.01 completed in 2.36s
2024-12-27 20:08:40,286 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:08:40,293 - INFO - Total number of labels flipped: 150
2024-12-27 20:08:40,294 - INFO - Label flipping completed in 0.01s
2024-12-27 20:08:40,294 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:08:40,294 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:08:40,949 - INFO - Feature scaling completed in 0.66s
2024-12-27 20:08:40,949 - INFO - Starting feature selection (k=50)
2024-12-27 20:08:40,959 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:08:40,959 - INFO - Starting anomaly detection
2024-12-27 20:08:42,933 - INFO - Anomaly detection completed in 1.97s
2024-12-27 20:08:42,934 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:08:42,934 - INFO - Total fit_transform time: 2.64s
2024-12-27 20:08:42,934 - INFO - Training set processing completed in 2.64s
2024-12-27 20:08:42,934 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:08:42,935 - INFO - Memory usage at start_fit: CPU 3296.4 MB, GPU 49.3 MB
2024-12-27 20:08:42,936 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:08:42,937 - INFO - Number of unique classes: 100
2024-12-27 20:08:43,036 - INFO - Fitted scaler and transformed data
2024-12-27 20:08:43,036 - INFO - Scaling time: 0.10s
2024-12-27 20:08:43,207 - INFO - Epoch 1/200, Train Loss: 2.9953, Val Loss: 3.0284
2024-12-27 20:08:43,422 - INFO - Epoch 2/200, Train Loss: 0.6284, Val Loss: 3.2096
2024-12-27 20:08:43,647 - INFO - Epoch 3/200, Train Loss: 0.1975, Val Loss: 3.1058
2024-12-27 20:08:43,648 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:08:43,648 - INFO - Training completed in 0.71s
2024-12-27 20:08:43,648 - INFO - Final memory usage: CPU 3296.4 MB, GPU 49.9 MB
2024-12-27 20:08:43,649 - INFO - Model training completed in 0.71s
2024-12-27 20:08:43,659 - INFO - Prediction completed in 0.01s
2024-12-27 20:08:43,668 - INFO - Poison rate 0.03 completed in 3.38s
2024-12-27 20:08:43,668 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:08:43,676 - INFO - Total number of labels flipped: 250
2024-12-27 20:08:43,676 - INFO - Label flipping completed in 0.01s
2024-12-27 20:08:43,676 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:08:43,676 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:08:44,298 - INFO - Feature scaling completed in 0.62s
2024-12-27 20:08:44,298 - INFO - Starting feature selection (k=50)
2024-12-27 20:08:44,311 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:08:44,311 - INFO - Starting anomaly detection
2024-12-27 20:08:45,907 - INFO - Anomaly detection completed in 1.60s
2024-12-27 20:08:45,908 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:08:45,908 - INFO - Total fit_transform time: 2.23s
2024-12-27 20:08:45,908 - INFO - Training set processing completed in 2.23s
2024-12-27 20:08:45,908 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:08:45,909 - INFO - Memory usage at start_fit: CPU 3296.4 MB, GPU 49.3 MB
2024-12-27 20:08:45,909 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:08:45,910 - INFO - Number of unique classes: 100
2024-12-27 20:08:46,022 - INFO - Fitted scaler and transformed data
2024-12-27 20:08:46,022 - INFO - Scaling time: 0.11s
2024-12-27 20:08:46,171 - INFO - Epoch 1/200, Train Loss: 3.2505, Val Loss: 2.9964
2024-12-27 20:08:46,278 - INFO - Epoch 2/200, Train Loss: 0.7463, Val Loss: 2.9580
2024-12-27 20:08:46,383 - INFO - Epoch 3/200, Train Loss: 0.2116, Val Loss: 3.1120
2024-12-27 20:08:46,490 - INFO - Epoch 4/200, Train Loss: 0.0732, Val Loss: 3.1591
2024-12-27 20:08:46,490 - INFO - Early stopping triggered at epoch 4
2024-12-27 20:08:46,490 - INFO - Training completed in 0.58s
2024-12-27 20:08:46,490 - INFO - Final memory usage: CPU 3296.4 MB, GPU 49.9 MB
2024-12-27 20:08:46,491 - INFO - Model training completed in 0.58s
2024-12-27 20:08:46,506 - INFO - Prediction completed in 0.02s
2024-12-27 20:08:46,524 - INFO - Poison rate 0.05 completed in 2.86s
2024-12-27 20:08:46,524 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:08:46,535 - INFO - Total number of labels flipped: 350
2024-12-27 20:08:46,535 - INFO - Label flipping completed in 0.01s
2024-12-27 20:08:46,535 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:08:46,535 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:08:47,150 - INFO - Feature scaling completed in 0.61s
2024-12-27 20:08:47,150 - INFO - Starting feature selection (k=50)
2024-12-27 20:08:47,158 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:08:47,158 - INFO - Starting anomaly detection
2024-12-27 20:08:48,894 - INFO - Anomaly detection completed in 1.74s
2024-12-27 20:08:48,894 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:08:48,894 - INFO - Total fit_transform time: 2.36s
2024-12-27 20:08:48,894 - INFO - Training set processing completed in 2.36s
2024-12-27 20:08:48,894 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:08:48,896 - INFO - Memory usage at start_fit: CPU 3296.4 MB, GPU 49.3 MB
2024-12-27 20:08:48,896 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:08:48,897 - INFO - Number of unique classes: 100
2024-12-27 20:08:49,005 - INFO - Fitted scaler and transformed data
2024-12-27 20:08:49,006 - INFO - Scaling time: 0.10s
2024-12-27 20:08:49,220 - INFO - Epoch 1/200, Train Loss: 3.4586, Val Loss: 3.2501
2024-12-27 20:08:49,446 - INFO - Epoch 2/200, Train Loss: 0.8216, Val Loss: 3.5343
2024-12-27 20:08:49,685 - INFO - Epoch 3/200, Train Loss: 0.1795, Val Loss: 3.4552
2024-12-27 20:08:49,685 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:08:49,685 - INFO - Training completed in 0.79s
2024-12-27 20:08:49,686 - INFO - Final memory usage: CPU 3296.4 MB, GPU 49.9 MB
2024-12-27 20:08:49,686 - INFO - Model training completed in 0.79s
2024-12-27 20:08:49,703 - INFO - Prediction completed in 0.02s
2024-12-27 20:08:49,717 - INFO - Poison rate 0.07 completed in 3.19s
2024-12-27 20:08:49,717 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:08:49,732 - INFO - Total number of labels flipped: 500
2024-12-27 20:08:49,732 - INFO - Label flipping completed in 0.02s
2024-12-27 20:08:49,732 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:08:49,733 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:08:50,363 - INFO - Feature scaling completed in 0.63s
2024-12-27 20:08:50,363 - INFO - Starting feature selection (k=50)
2024-12-27 20:08:50,376 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:08:50,377 - INFO - Starting anomaly detection
2024-12-27 20:08:52,503 - INFO - Anomaly detection completed in 2.13s
2024-12-27 20:08:52,504 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:08:52,504 - INFO - Total fit_transform time: 2.77s
2024-12-27 20:08:52,504 - INFO - Training set processing completed in 2.77s
2024-12-27 20:08:52,504 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:08:52,505 - INFO - Memory usage at start_fit: CPU 3296.4 MB, GPU 49.3 MB
2024-12-27 20:08:52,506 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:08:52,507 - INFO - Number of unique classes: 100
2024-12-27 20:08:52,619 - INFO - Fitted scaler and transformed data
2024-12-27 20:08:52,619 - INFO - Scaling time: 0.11s
2024-12-27 20:08:52,791 - INFO - Epoch 1/200, Train Loss: 3.6307, Val Loss: 3.6518
2024-12-27 20:08:52,937 - INFO - Epoch 2/200, Train Loss: 0.9224, Val Loss: 3.8004
2024-12-27 20:08:53,106 - INFO - Epoch 3/200, Train Loss: 0.2490, Val Loss: 3.9223
2024-12-27 20:08:53,106 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:08:53,106 - INFO - Training completed in 0.60s
2024-12-27 20:08:53,107 - INFO - Final memory usage: CPU 3296.4 MB, GPU 49.9 MB
2024-12-27 20:08:53,107 - INFO - Model training completed in 0.60s
2024-12-27 20:08:53,114 - INFO - Prediction completed in 0.01s
2024-12-27 20:08:53,136 - INFO - Poison rate 0.1 completed in 3.42s
2024-12-27 20:08:53,136 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:08:53,173 - INFO - Total number of labels flipped: 1000
2024-12-27 20:08:53,174 - INFO - Label flipping completed in 0.04s
2024-12-27 20:08:53,174 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:08:53,174 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:08:53,847 - INFO - Feature scaling completed in 0.67s
2024-12-27 20:08:53,847 - INFO - Starting feature selection (k=50)
2024-12-27 20:08:53,855 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:08:53,855 - INFO - Starting anomaly detection
2024-12-27 20:08:55,959 - INFO - Anomaly detection completed in 2.10s
2024-12-27 20:08:55,960 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:08:55,960 - INFO - Total fit_transform time: 2.79s
2024-12-27 20:08:55,960 - INFO - Training set processing completed in 2.79s
2024-12-27 20:08:55,961 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:08:55,962 - INFO - Memory usage at start_fit: CPU 3296.4 MB, GPU 49.3 MB
2024-12-27 20:08:55,962 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:08:55,963 - INFO - Number of unique classes: 100
2024-12-27 20:08:56,073 - INFO - Fitted scaler and transformed data
2024-12-27 20:08:56,074 - INFO - Scaling time: 0.11s
2024-12-27 20:08:56,213 - INFO - Epoch 1/200, Train Loss: 4.3878, Val Loss: 4.5075
2024-12-27 20:08:56,335 - INFO - Epoch 2/200, Train Loss: 1.0783, Val Loss: 4.6778
2024-12-27 20:08:56,453 - INFO - Epoch 3/200, Train Loss: 0.3564, Val Loss: 4.9760
2024-12-27 20:08:56,453 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:08:56,454 - INFO - Training completed in 0.49s
2024-12-27 20:08:56,454 - INFO - Final memory usage: CPU 3296.4 MB, GPU 49.9 MB
2024-12-27 20:08:56,454 - INFO - Model training completed in 0.49s
2024-12-27 20:08:56,461 - INFO - Prediction completed in 0.01s
2024-12-27 20:08:56,485 - INFO - Poison rate 0.2 completed in 3.35s
2024-12-27 20:08:56,489 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:08:56,489 - INFO - Total evaluation time: 27.73s
2024-12-27 20:08:56,491 - INFO - 
Progress: 38.5% - Evaluating CIFAR100 with RandomForest (standard mode, iteration 1/1)
2024-12-27 20:08:56,555 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:08:56,635 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:08:56,712 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:08:56,712 - INFO - Dataset type: image
2024-12-27 20:08:56,712 - INFO - Sample size: 5000
2024-12-27 20:08:56,712 - INFO - Using device: cuda
2024-12-27 20:08:56,714 - INFO - Loading datasets...
2024-12-27 20:08:57,997 - INFO - Dataset loading completed in 1.28s
2024-12-27 20:08:57,997 - INFO - Extracting validation features...
2024-12-27 20:08:57,997 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:15,  1.95it/s]Extracting features:  19%|█▉        | 6/32 [00:00<00:02, 12.38it/s]Extracting features:  38%|███▊      | 12/32 [00:00<00:00, 23.51it/s]Extracting features:  53%|█████▎    | 17/32 [00:00<00:00, 29.60it/s]Extracting features:  72%|███████▏  | 23/32 [00:00<00:00, 35.26it/s]Extracting features:  94%|█████████▍| 30/32 [00:01<00:00, 43.68it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 28.26it/s]
2024-12-27 20:08:59,135 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:08:59,136 - INFO - Validation feature extraction completed in 1.14s
2024-12-27 20:08:59,137 - INFO - Extracting training features...
2024-12-27 20:08:59,137 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:41,  3.79it/s]Extracting features:   4%|▍         | 7/157 [00:00<00:06, 23.41it/s]Extracting features:   8%|▊         | 12/157 [00:00<00:04, 31.99it/s]Extracting features:  11%|█▏        | 18/157 [00:00<00:03, 40.50it/s]Extracting features:  15%|█▌        | 24/157 [00:00<00:02, 44.78it/s]Extracting features:  19%|█▉        | 30/157 [00:00<00:02, 48.90it/s]Extracting features:  23%|██▎       | 36/157 [00:00<00:02, 50.88it/s]Extracting features:  27%|██▋       | 43/157 [00:01<00:02, 53.72it/s]Extracting features:  32%|███▏      | 50/157 [00:01<00:01, 55.36it/s]Extracting features:  36%|███▌      | 56/157 [00:01<00:01, 52.64it/s]Extracting features:  39%|███▉      | 62/157 [00:01<00:01, 53.73it/s]Extracting features:  43%|████▎     | 68/157 [00:01<00:01, 55.15it/s]Extracting features:  47%|████▋     | 74/157 [00:01<00:01, 54.12it/s]Extracting features:  51%|█████     | 80/157 [00:01<00:01, 55.44it/s]Extracting features:  55%|█████▍    | 86/157 [00:01<00:01, 54.31it/s]Extracting features:  59%|█████▊    | 92/157 [00:01<00:01, 53.53it/s]Extracting features:  63%|██████▎   | 99/157 [00:02<00:01, 55.86it/s]Extracting features:  67%|██████▋   | 105/157 [00:02<00:00, 55.24it/s]Extracting features:  71%|███████   | 111/157 [00:02<00:00, 53.36it/s]Extracting features:  75%|███████▍  | 117/157 [00:02<00:00, 54.98it/s]Extracting features:  78%|███████▊  | 123/157 [00:02<00:00, 55.81it/s]Extracting features:  82%|████████▏ | 129/157 [00:02<00:00, 56.40it/s]Extracting features:  86%|████████▌ | 135/157 [00:02<00:00, 56.36it/s]Extracting features:  90%|████████▉ | 141/157 [00:02<00:00, 56.57it/s]Extracting features:  94%|█████████▎| 147/157 [00:02<00:00, 57.10it/s]Extracting features:  97%|█████████▋| 153/157 [00:02<00:00, 57.48it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 50.53it/s]
2024-12-27 20:09:02,262 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:09:02,262 - INFO - Training feature extraction completed in 3.13s
2024-12-27 20:09:02,262 - INFO - Creating model for classifier: RandomForest
2024-12-27 20:09:02,263 - INFO - Using device: cuda
2024-12-27 20:09:02,263 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:09:02,263 - INFO - Training set processing completed in 0.00s
2024-12-27 20:09:02,263 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:09:02,264 - INFO - Memory usage at start_fit: CPU 3267.5 MB, GPU 47.3 MB
2024-12-27 20:09:02,265 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:09:02,364 - INFO - Fitted scaler and transformed data
2024-12-27 20:09:02,365 - INFO - Scaling time: 0.10s
2024-12-27 20:09:02,371 - INFO - Number of unique classes: 100
2024-12-27 20:09:05,500 - INFO - Epoch 1/15, Train Loss: 4.6050, Val Loss: 4.6049
2024-12-27 20:09:08,809 - INFO - Epoch 2/15, Train Loss: 4.6040, Val Loss: 4.6044
2024-12-27 20:09:12,506 - INFO - Epoch 3/15, Train Loss: 4.6029, Val Loss: 4.6040
2024-12-27 20:09:12,507 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:09:12,507 - INFO - Training completed in 10.24s
2024-12-27 20:09:12,507 - INFO - Final memory usage: CPU 3292.0 MB, GPU 97.7 MB
2024-12-27 20:09:12,507 - INFO - Model training completed in 10.24s
2024-12-27 20:09:12,742 - INFO - Prediction completed in 0.23s
2024-12-27 20:09:12,755 - INFO - Poison rate 0.0 completed in 10.49s
2024-12-27 20:09:12,755 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:09:12,758 - INFO - Total number of labels flipped: 50
2024-12-27 20:09:12,758 - INFO - Label flipping completed in 0.00s
2024-12-27 20:09:12,758 - INFO - Training set processing completed in 0.00s
2024-12-27 20:09:12,758 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:09:12,759 - INFO - Memory usage at start_fit: CPU 3292.0 MB, GPU 66.9 MB
2024-12-27 20:09:12,759 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:09:12,823 - INFO - Fitted scaler and transformed data
2024-12-27 20:09:12,823 - INFO - Scaling time: 0.06s
2024-12-27 20:09:12,833 - INFO - Number of unique classes: 100
2024-12-27 20:09:16,889 - INFO - Epoch 1/15, Train Loss: 4.6050, Val Loss: 4.6049
2024-12-27 20:09:20,041 - INFO - Epoch 2/15, Train Loss: 4.6040, Val Loss: 4.6045
2024-12-27 20:09:23,524 - INFO - Epoch 3/15, Train Loss: 4.6029, Val Loss: 4.6040
2024-12-27 20:09:23,524 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:09:23,524 - INFO - Training completed in 10.77s
2024-12-27 20:09:23,525 - INFO - Final memory usage: CPU 3292.0 MB, GPU 97.7 MB
2024-12-27 20:09:23,525 - INFO - Model training completed in 10.77s
2024-12-27 20:09:23,632 - INFO - Prediction completed in 0.11s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:09:23,641 - INFO - Poison rate 0.01 completed in 10.89s
2024-12-27 20:09:23,641 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:09:23,646 - INFO - Total number of labels flipped: 150
2024-12-27 20:09:23,646 - INFO - Label flipping completed in 0.00s
2024-12-27 20:09:23,646 - INFO - Training set processing completed in 0.00s
2024-12-27 20:09:23,646 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:09:23,647 - INFO - Memory usage at start_fit: CPU 3292.0 MB, GPU 66.9 MB
2024-12-27 20:09:23,647 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:09:23,712 - INFO - Fitted scaler and transformed data
2024-12-27 20:09:23,713 - INFO - Scaling time: 0.07s
2024-12-27 20:09:23,725 - INFO - Number of unique classes: 100
2024-12-27 20:09:26,781 - INFO - Epoch 1/15, Train Loss: 4.6050, Val Loss: 4.6049
2024-12-27 20:09:29,803 - INFO - Epoch 2/15, Train Loss: 4.6040, Val Loss: 4.6045
2024-12-27 20:09:32,475 - INFO - Epoch 3/15, Train Loss: 4.6029, Val Loss: 4.6041
2024-12-27 20:09:32,475 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:09:32,475 - INFO - Training completed in 8.83s
2024-12-27 20:09:32,476 - INFO - Final memory usage: CPU 3292.0 MB, GPU 97.7 MB
2024-12-27 20:09:32,476 - INFO - Model training completed in 8.83s
2024-12-27 20:09:32,574 - INFO - Prediction completed in 0.10s
2024-12-27 20:09:32,582 - INFO - Poison rate 0.03 completed in 8.94s
2024-12-27 20:09:32,583 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:09:32,590 - INFO - Total number of labels flipped: 250
2024-12-27 20:09:32,591 - INFO - Label flipping completed in 0.01s
2024-12-27 20:09:32,591 - INFO - Training set processing completed in 0.00s
2024-12-27 20:09:32,591 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:09:32,591 - INFO - Memory usage at start_fit: CPU 3292.0 MB, GPU 66.9 MB
2024-12-27 20:09:32,592 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:09:32,658 - INFO - Fitted scaler and transformed data
2024-12-27 20:09:32,659 - INFO - Scaling time: 0.07s
2024-12-27 20:09:32,669 - INFO - Number of unique classes: 100
2024-12-27 20:09:35,856 - INFO - Epoch 1/15, Train Loss: 4.6050, Val Loss: 4.6049
2024-12-27 20:09:38,977 - INFO - Epoch 2/15, Train Loss: 4.6040, Val Loss: 4.6045
2024-12-27 20:09:42,495 - INFO - Epoch 3/15, Train Loss: 4.6029, Val Loss: 4.6041
2024-12-27 20:09:42,496 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:09:42,496 - INFO - Training completed in 9.90s
2024-12-27 20:09:42,496 - INFO - Final memory usage: CPU 3292.0 MB, GPU 97.7 MB
2024-12-27 20:09:42,496 - INFO - Model training completed in 9.91s
2024-12-27 20:09:42,603 - INFO - Prediction completed in 0.11s
2024-12-27 20:09:42,612 - INFO - Poison rate 0.05 completed in 10.03s
2024-12-27 20:09:42,612 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:09:42,622 - INFO - Total number of labels flipped: 350
2024-12-27 20:09:42,623 - INFO - Label flipping completed in 0.01s
2024-12-27 20:09:42,623 - INFO - Training set processing completed in 0.00s
2024-12-27 20:09:42,623 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:09:42,624 - INFO - Memory usage at start_fit: CPU 3292.0 MB, GPU 66.9 MB
2024-12-27 20:09:42,624 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:09:42,688 - INFO - Fitted scaler and transformed data
2024-12-27 20:09:42,688 - INFO - Scaling time: 0.06s
2024-12-27 20:09:42,699 - INFO - Number of unique classes: 100
2024-12-27 20:09:46,234 - INFO - Epoch 1/15, Train Loss: 4.6051, Val Loss: 4.6049
2024-12-27 20:09:49,562 - INFO - Epoch 2/15, Train Loss: 4.6040, Val Loss: 4.6046
2024-12-27 20:09:52,804 - INFO - Epoch 3/15, Train Loss: 4.6030, Val Loss: 4.6042
2024-12-27 20:09:52,804 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:09:52,806 - INFO - Training completed in 10.18s
2024-12-27 20:09:52,807 - INFO - Final memory usage: CPU 3292.0 MB, GPU 97.7 MB
2024-12-27 20:09:52,807 - INFO - Model training completed in 10.18s
2024-12-27 20:09:52,903 - INFO - Prediction completed in 0.10s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:09:52,912 - INFO - Poison rate 0.07 completed in 10.30s
2024-12-27 20:09:52,912 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:09:52,926 - INFO - Total number of labels flipped: 500
2024-12-27 20:09:52,927 - INFO - Label flipping completed in 0.01s
2024-12-27 20:09:52,927 - INFO - Training set processing completed in 0.00s
2024-12-27 20:09:52,927 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:09:52,928 - INFO - Memory usage at start_fit: CPU 3292.0 MB, GPU 66.9 MB
2024-12-27 20:09:52,928 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:09:52,993 - INFO - Fitted scaler and transformed data
2024-12-27 20:09:52,993 - INFO - Scaling time: 0.07s
2024-12-27 20:09:53,004 - INFO - Number of unique classes: 100
2024-12-27 20:09:56,437 - INFO - Epoch 1/15, Train Loss: 4.6051, Val Loss: 4.6049
2024-12-27 20:09:59,588 - INFO - Epoch 2/15, Train Loss: 4.6041, Val Loss: 4.6046
2024-12-27 20:10:02,775 - INFO - Epoch 3/15, Train Loss: 4.6030, Val Loss: 4.6043
2024-12-27 20:10:02,776 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:10:02,776 - INFO - Training completed in 9.85s
2024-12-27 20:10:02,776 - INFO - Final memory usage: CPU 3292.0 MB, GPU 97.7 MB
2024-12-27 20:10:02,776 - INFO - Model training completed in 9.85s
2024-12-27 20:10:02,902 - INFO - Prediction completed in 0.13s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:10:02,911 - INFO - Poison rate 0.1 completed in 10.00s
2024-12-27 20:10:02,911 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:10:02,940 - INFO - Total number of labels flipped: 1000
2024-12-27 20:10:02,940 - INFO - Label flipping completed in 0.03s
2024-12-27 20:10:02,940 - INFO - Training set processing completed in 0.00s
2024-12-27 20:10:02,940 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:10:02,941 - INFO - Memory usage at start_fit: CPU 3292.0 MB, GPU 66.9 MB
2024-12-27 20:10:02,941 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:10:03,009 - INFO - Fitted scaler and transformed data
2024-12-27 20:10:03,009 - INFO - Scaling time: 0.07s
2024-12-27 20:10:03,020 - INFO - Number of unique classes: 100
2024-12-27 20:10:05,608 - INFO - Epoch 1/15, Train Loss: 4.6051, Val Loss: 4.6050
2024-12-27 20:10:08,414 - INFO - Epoch 2/15, Train Loss: 4.6041, Val Loss: 4.6047
2024-12-27 20:10:12,138 - INFO - Epoch 3/15, Train Loss: 4.6031, Val Loss: 4.6044
2024-12-27 20:10:12,138 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:10:12,139 - INFO - Training completed in 9.20s
2024-12-27 20:10:12,139 - INFO - Final memory usage: CPU 3292.0 MB, GPU 97.7 MB
2024-12-27 20:10:12,139 - INFO - Model training completed in 9.20s
2024-12-27 20:10:12,394 - INFO - Prediction completed in 0.25s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:10:12,403 - INFO - Poison rate 0.2 completed in 9.49s
2024-12-27 20:10:12,405 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:10:12,405 - INFO - Total evaluation time: 75.69s
2024-12-27 20:10:12,406 - INFO - 
Progress: 39.6% - Evaluating CIFAR100 with RandomForest (dynadetect mode, iteration 1/1)
2024-12-27 20:10:12,468 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:10:12,544 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:10:12,645 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:10:12,645 - INFO - Dataset type: image
2024-12-27 20:10:12,645 - INFO - Sample size: 5000
2024-12-27 20:10:12,645 - INFO - Using device: cuda
2024-12-27 20:10:12,648 - INFO - Loading datasets...
2024-12-27 20:10:14,001 - INFO - Dataset loading completed in 1.35s
2024-12-27 20:10:14,001 - INFO - Extracting validation features...
2024-12-27 20:10:14,001 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:13,  2.25it/s]Extracting features:  16%|█▌        | 5/32 [00:00<00:02, 11.24it/s]Extracting features:  34%|███▍      | 11/32 [00:00<00:00, 23.09it/s]Extracting features:  50%|█████     | 16/32 [00:00<00:00, 29.81it/s]Extracting features:  69%|██████▉   | 22/32 [00:00<00:00, 36.21it/s]Extracting features:  91%|█████████ | 29/32 [00:01<00:00, 43.16it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 28.52it/s]
2024-12-27 20:10:15,128 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:10:15,128 - INFO - Validation feature extraction completed in 1.13s
2024-12-27 20:10:15,128 - INFO - Extracting training features...
2024-12-27 20:10:15,128 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:42,  3.65it/s]Extracting features:   4%|▍         | 7/157 [00:00<00:06, 22.28it/s]Extracting features:   8%|▊         | 13/157 [00:00<00:04, 33.63it/s]Extracting features:  12%|█▏        | 19/157 [00:00<00:03, 40.45it/s]Extracting features:  15%|█▌        | 24/157 [00:00<00:03, 42.52it/s]Extracting features:  19%|█▉        | 30/157 [00:00<00:02, 45.97it/s]Extracting features:  22%|██▏       | 35/157 [00:00<00:02, 47.06it/s]Extracting features:  26%|██▌       | 41/157 [00:01<00:02, 49.88it/s]Extracting features:  30%|██▉       | 47/157 [00:01<00:02, 51.65it/s]Extracting features:  34%|███▍      | 54/157 [00:01<00:01, 53.28it/s]Extracting features:  38%|███▊      | 60/157 [00:01<00:01, 51.64it/s]Extracting features:  42%|████▏     | 66/157 [00:01<00:01, 52.03it/s]Extracting features:  46%|████▌     | 72/157 [00:01<00:01, 51.03it/s]Extracting features:  50%|████▉     | 78/157 [00:01<00:01, 52.01it/s]Extracting features:  54%|█████▎    | 84/157 [00:01<00:01, 52.65it/s]Extracting features:  57%|█████▋    | 90/157 [00:01<00:01, 54.14it/s]Extracting features:  61%|██████    | 96/157 [00:02<00:01, 52.92it/s]Extracting features:  65%|██████▍   | 102/157 [00:02<00:01, 52.06it/s]Extracting features:  69%|██████▉   | 108/157 [00:02<00:00, 53.15it/s]Extracting features:  73%|███████▎  | 114/157 [00:02<00:00, 50.51it/s]Extracting features:  76%|███████▋  | 120/157 [00:02<00:00, 51.59it/s]Extracting features:  80%|████████  | 126/157 [00:02<00:00, 48.16it/s]Extracting features:  85%|████████▍ | 133/157 [00:02<00:00, 52.24it/s]Extracting features:  89%|████████▉ | 140/157 [00:02<00:00, 55.71it/s]Extracting features:  93%|█████████▎| 146/157 [00:03<00:00, 53.12it/s]Extracting features:  97%|█████████▋| 152/157 [00:03<00:00, 53.29it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 47.54it/s]
2024-12-27 20:10:18,445 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:10:18,445 - INFO - Training feature extraction completed in 3.32s
2024-12-27 20:10:18,445 - INFO - Creating model for classifier: RandomForest
2024-12-27 20:10:18,445 - INFO - Using device: cuda
2024-12-27 20:10:18,445 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:10:18,445 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:10:18,445 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:10:19,045 - INFO - Feature scaling completed in 0.60s
2024-12-27 20:10:19,045 - INFO - Starting feature selection (k=50)
2024-12-27 20:10:19,050 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:10:19,051 - INFO - Starting anomaly detection
2024-12-27 20:10:20,977 - INFO - Anomaly detection completed in 1.93s
2024-12-27 20:10:20,977 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:10:20,977 - INFO - Total fit_transform time: 2.53s
2024-12-27 20:10:20,977 - INFO - Training set processing completed in 2.53s
2024-12-27 20:10:20,977 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:10:20,978 - INFO - Memory usage at start_fit: CPU 3293.0 MB, GPU 47.3 MB
2024-12-27 20:10:20,978 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:10:21,057 - INFO - Fitted scaler and transformed data
2024-12-27 20:10:21,057 - INFO - Scaling time: 0.08s
2024-12-27 20:10:21,063 - INFO - Number of unique classes: 100
2024-12-27 20:10:24,585 - INFO - Epoch 1/15, Train Loss: 4.3772, Val Loss: 4.6049
2024-12-27 20:10:27,930 - INFO - Epoch 2/15, Train Loss: 4.3762, Val Loss: 4.6045
2024-12-27 20:10:31,997 - INFO - Epoch 3/15, Train Loss: 4.3751, Val Loss: 4.6040
2024-12-27 20:10:31,997 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:10:31,997 - INFO - Training completed in 11.02s
2024-12-27 20:10:31,998 - INFO - Final memory usage: CPU 3293.0 MB, GPU 97.9 MB
2024-12-27 20:10:31,999 - INFO - Model training completed in 11.02s
2024-12-27 20:10:32,209 - INFO - Prediction completed in 0.21s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:10:32,219 - INFO - Poison rate 0.0 completed in 13.77s
2024-12-27 20:10:32,219 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:10:32,221 - INFO - Total number of labels flipped: 50
2024-12-27 20:10:32,221 - INFO - Label flipping completed in 0.00s
2024-12-27 20:10:32,221 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:10:32,221 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:10:32,779 - INFO - Feature scaling completed in 0.56s
2024-12-27 20:10:32,779 - INFO - Starting feature selection (k=50)
2024-12-27 20:10:32,792 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:10:32,792 - INFO - Starting anomaly detection
2024-12-27 20:10:34,983 - INFO - Anomaly detection completed in 2.19s
2024-12-27 20:10:34,983 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:10:34,983 - INFO - Total fit_transform time: 2.76s
2024-12-27 20:10:34,984 - INFO - Training set processing completed in 2.76s
2024-12-27 20:10:34,984 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:10:34,985 - INFO - Memory usage at start_fit: CPU 3293.0 MB, GPU 66.9 MB
2024-12-27 20:10:34,985 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:10:35,072 - INFO - Fitted scaler and transformed data
2024-12-27 20:10:35,072 - INFO - Scaling time: 0.09s
2024-12-27 20:10:35,078 - INFO - Number of unique classes: 100
2024-12-27 20:10:37,994 - INFO - Epoch 1/15, Train Loss: 4.3700, Val Loss: 4.6049
2024-12-27 20:10:42,037 - INFO - Epoch 2/15, Train Loss: 4.3690, Val Loss: 4.6045
2024-12-27 20:10:45,179 - INFO - Epoch 3/15, Train Loss: 4.3680, Val Loss: 4.6040
2024-12-27 20:10:45,179 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:10:45,179 - INFO - Training completed in 10.19s
2024-12-27 20:10:45,179 - INFO - Final memory usage: CPU 3293.0 MB, GPU 97.9 MB
2024-12-27 20:10:45,180 - INFO - Model training completed in 10.20s
2024-12-27 20:10:45,335 - INFO - Prediction completed in 0.16s
2024-12-27 20:10:45,344 - INFO - Poison rate 0.01 completed in 13.12s
2024-12-27 20:10:45,344 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:10:45,349 - INFO - Total number of labels flipped: 150
2024-12-27 20:10:45,349 - INFO - Label flipping completed in 0.00s
2024-12-27 20:10:45,349 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:10:45,349 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:10:45,963 - INFO - Feature scaling completed in 0.61s
2024-12-27 20:10:45,964 - INFO - Starting feature selection (k=50)
2024-12-27 20:10:45,977 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:10:45,977 - INFO - Starting anomaly detection
2024-12-27 20:10:47,249 - INFO - Anomaly detection completed in 1.27s
2024-12-27 20:10:47,249 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:10:47,249 - INFO - Total fit_transform time: 1.90s
2024-12-27 20:10:47,249 - INFO - Training set processing completed in 1.90s
2024-12-27 20:10:47,249 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:10:47,250 - INFO - Memory usage at start_fit: CPU 3293.0 MB, GPU 66.9 MB
2024-12-27 20:10:47,250 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:10:47,317 - INFO - Fitted scaler and transformed data
2024-12-27 20:10:47,317 - INFO - Scaling time: 0.07s
2024-12-27 20:10:47,323 - INFO - Number of unique classes: 100
2024-12-27 20:10:50,733 - INFO - Epoch 1/15, Train Loss: 4.3681, Val Loss: 4.6049
2024-12-27 20:10:53,566 - INFO - Epoch 2/15, Train Loss: 4.3671, Val Loss: 4.6045
2024-12-27 20:10:56,976 - INFO - Epoch 3/15, Train Loss: 4.3661, Val Loss: 4.6040
2024-12-27 20:10:56,977 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:10:56,977 - INFO - Training completed in 9.73s
2024-12-27 20:10:56,978 - INFO - Final memory usage: CPU 3293.0 MB, GPU 97.9 MB
2024-12-27 20:10:56,978 - INFO - Model training completed in 9.73s
2024-12-27 20:10:57,146 - INFO - Prediction completed in 0.17s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:10:57,155 - INFO - Poison rate 0.03 completed in 11.81s
2024-12-27 20:10:57,156 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:10:57,163 - INFO - Total number of labels flipped: 250
2024-12-27 20:10:57,163 - INFO - Label flipping completed in 0.01s
2024-12-27 20:10:57,163 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:10:57,163 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:10:57,723 - INFO - Feature scaling completed in 0.56s
2024-12-27 20:10:57,724 - INFO - Starting feature selection (k=50)
2024-12-27 20:10:57,736 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:10:57,736 - INFO - Starting anomaly detection
2024-12-27 20:10:59,310 - INFO - Anomaly detection completed in 1.57s
2024-12-27 20:10:59,310 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:10:59,310 - INFO - Total fit_transform time: 2.15s
2024-12-27 20:10:59,310 - INFO - Training set processing completed in 2.15s
2024-12-27 20:10:59,310 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:10:59,311 - INFO - Memory usage at start_fit: CPU 3293.0 MB, GPU 66.9 MB
2024-12-27 20:10:59,311 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:10:59,377 - INFO - Fitted scaler and transformed data
2024-12-27 20:10:59,377 - INFO - Scaling time: 0.07s
2024-12-27 20:10:59,383 - INFO - Number of unique classes: 100
2024-12-27 20:11:02,105 - INFO - Epoch 1/15, Train Loss: 4.3824, Val Loss: 4.6049
2024-12-27 20:11:05,042 - INFO - Epoch 2/15, Train Loss: 4.3814, Val Loss: 4.6045
2024-12-27 20:11:08,414 - INFO - Epoch 3/15, Train Loss: 4.3804, Val Loss: 4.6042
2024-12-27 20:11:08,415 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:11:08,415 - INFO - Training completed in 9.10s
2024-12-27 20:11:08,415 - INFO - Final memory usage: CPU 3293.0 MB, GPU 97.9 MB
2024-12-27 20:11:08,415 - INFO - Model training completed in 9.11s
2024-12-27 20:11:08,647 - INFO - Prediction completed in 0.23s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:11:08,656 - INFO - Poison rate 0.05 completed in 11.50s
2024-12-27 20:11:08,656 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:11:08,666 - INFO - Total number of labels flipped: 350
2024-12-27 20:11:08,666 - INFO - Label flipping completed in 0.01s
2024-12-27 20:11:08,666 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:11:08,667 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:11:09,296 - INFO - Feature scaling completed in 0.63s
2024-12-27 20:11:09,296 - INFO - Starting feature selection (k=50)
2024-12-27 20:11:09,309 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:11:09,309 - INFO - Starting anomaly detection
2024-12-27 20:11:10,615 - INFO - Anomaly detection completed in 1.31s
2024-12-27 20:11:10,615 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:11:10,615 - INFO - Total fit_transform time: 1.95s
2024-12-27 20:11:10,615 - INFO - Training set processing completed in 1.95s
2024-12-27 20:11:10,615 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:11:10,616 - INFO - Memory usage at start_fit: CPU 3293.0 MB, GPU 66.9 MB
2024-12-27 20:11:10,616 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:11:10,681 - INFO - Fitted scaler and transformed data
2024-12-27 20:11:10,681 - INFO - Scaling time: 0.07s
2024-12-27 20:11:10,689 - INFO - Number of unique classes: 100
2024-12-27 20:11:14,015 - INFO - Epoch 1/15, Train Loss: 4.3767, Val Loss: 4.6049
2024-12-27 20:11:16,637 - INFO - Epoch 2/15, Train Loss: 4.3758, Val Loss: 4.6046
2024-12-27 20:11:19,396 - INFO - Epoch 3/15, Train Loss: 4.3748, Val Loss: 4.6042
2024-12-27 20:11:19,397 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:11:19,397 - INFO - Training completed in 8.78s
2024-12-27 20:11:19,397 - INFO - Final memory usage: CPU 3293.0 MB, GPU 97.9 MB
2024-12-27 20:11:19,397 - INFO - Model training completed in 8.78s
2024-12-27 20:11:19,494 - INFO - Prediction completed in 0.10s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:11:19,504 - INFO - Poison rate 0.07 completed in 10.85s
2024-12-27 20:11:19,504 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:11:19,519 - INFO - Total number of labels flipped: 500
2024-12-27 20:11:19,520 - INFO - Label flipping completed in 0.02s
2024-12-27 20:11:19,520 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:11:19,520 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:11:20,129 - INFO - Feature scaling completed in 0.61s
2024-12-27 20:11:20,129 - INFO - Starting feature selection (k=50)
2024-12-27 20:11:20,142 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:11:20,142 - INFO - Starting anomaly detection
2024-12-27 20:11:21,495 - INFO - Anomaly detection completed in 1.35s
2024-12-27 20:11:21,495 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:11:21,496 - INFO - Total fit_transform time: 1.98s
2024-12-27 20:11:21,496 - INFO - Training set processing completed in 1.98s
2024-12-27 20:11:21,496 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:11:21,497 - INFO - Memory usage at start_fit: CPU 3293.0 MB, GPU 66.9 MB
2024-12-27 20:11:21,497 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:11:21,570 - INFO - Fitted scaler and transformed data
2024-12-27 20:11:21,571 - INFO - Scaling time: 0.07s
2024-12-27 20:11:21,576 - INFO - Number of unique classes: 100
2024-12-27 20:11:24,260 - INFO - Epoch 1/15, Train Loss: 4.3694, Val Loss: 4.6049
2024-12-27 20:11:27,352 - INFO - Epoch 2/15, Train Loss: 4.3684, Val Loss: 4.6046
2024-12-27 20:11:31,055 - INFO - Epoch 3/15, Train Loss: 4.3674, Val Loss: 4.6042
2024-12-27 20:11:31,055 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:11:31,055 - INFO - Training completed in 9.56s
2024-12-27 20:11:31,055 - INFO - Final memory usage: CPU 3293.0 MB, GPU 97.9 MB
2024-12-27 20:11:31,055 - INFO - Model training completed in 9.56s
2024-12-27 20:11:31,182 - INFO - Prediction completed in 0.13s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:11:31,191 - INFO - Poison rate 0.1 completed in 11.69s
2024-12-27 20:11:31,191 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:11:31,241 - INFO - Total number of labels flipped: 1000
2024-12-27 20:11:31,241 - INFO - Label flipping completed in 0.05s
2024-12-27 20:11:31,242 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:11:31,242 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:11:31,814 - INFO - Feature scaling completed in 0.57s
2024-12-27 20:11:31,814 - INFO - Starting feature selection (k=50)
2024-12-27 20:11:31,827 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:11:31,827 - INFO - Starting anomaly detection
2024-12-27 20:11:33,961 - INFO - Anomaly detection completed in 2.13s
2024-12-27 20:11:33,962 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:11:33,962 - INFO - Total fit_transform time: 2.72s
2024-12-27 20:11:33,962 - INFO - Training set processing completed in 2.72s
2024-12-27 20:11:33,962 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:11:33,963 - INFO - Memory usage at start_fit: CPU 3293.0 MB, GPU 66.9 MB
2024-12-27 20:11:33,963 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:11:34,041 - INFO - Fitted scaler and transformed data
2024-12-27 20:11:34,041 - INFO - Scaling time: 0.08s
2024-12-27 20:11:34,051 - INFO - Number of unique classes: 100
2024-12-27 20:11:37,264 - INFO - Epoch 1/15, Train Loss: 4.3775, Val Loss: 4.6050
2024-12-27 20:11:40,358 - INFO - Epoch 2/15, Train Loss: 4.3766, Val Loss: 4.6047
2024-12-27 20:11:42,988 - INFO - Epoch 3/15, Train Loss: 4.3757, Val Loss: 4.6044
2024-12-27 20:11:42,989 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:11:42,989 - INFO - Training completed in 9.03s
2024-12-27 20:11:42,989 - INFO - Final memory usage: CPU 3293.0 MB, GPU 97.9 MB
2024-12-27 20:11:42,989 - INFO - Model training completed in 9.03s
2024-12-27 20:11:43,113 - INFO - Prediction completed in 0.12s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:11:43,126 - INFO - Poison rate 0.2 completed in 11.93s
2024-12-27 20:11:43,128 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:11:43,128 - INFO - Total evaluation time: 90.48s
2024-12-27 20:11:43,129 - INFO - 
Progress: 40.6% - Evaluating CIFAR100 with KNeighbors (standard mode, iteration 1/1)
2024-12-27 20:11:43,191 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:11:43,263 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:11:43,322 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:11:43,322 - INFO - Dataset type: image
2024-12-27 20:11:43,322 - INFO - Sample size: 5000
2024-12-27 20:11:43,323 - INFO - Using device: cuda
2024-12-27 20:11:43,325 - INFO - Loading datasets...
2024-12-27 20:11:44,605 - INFO - Dataset loading completed in 1.28s
2024-12-27 20:11:44,606 - INFO - Extracting validation features...
2024-12-27 20:11:44,606 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:17,  1.79it/s]Extracting features:  12%|█▎        | 4/32 [00:00<00:03,  7.34it/s]Extracting features:  28%|██▊       | 9/32 [00:00<00:01, 16.36it/s]Extracting features:  47%|████▋     | 15/32 [00:00<00:00, 25.71it/s]Extracting features:  66%|██████▌   | 21/32 [00:01<00:00, 33.75it/s]Extracting features:  88%|████████▊ | 28/32 [00:01<00:00, 41.67it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 26.12it/s]
2024-12-27 20:11:45,836 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:11:45,837 - INFO - Validation feature extraction completed in 1.23s
2024-12-27 20:11:45,837 - INFO - Extracting training features...
2024-12-27 20:11:45,838 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:43,  3.58it/s]Extracting features:   4%|▍         | 7/157 [00:00<00:06, 21.59it/s]Extracting features:   8%|▊         | 13/157 [00:00<00:04, 32.86it/s]Extracting features:  12%|█▏        | 19/157 [00:00<00:03, 40.38it/s]Extracting features:  16%|█▌        | 25/157 [00:00<00:02, 45.47it/s]Extracting features:  20%|█▉        | 31/157 [00:00<00:02, 48.86it/s]Extracting features:  24%|██▎       | 37/157 [00:00<00:02, 48.59it/s]Extracting features:  27%|██▋       | 43/157 [00:01<00:02, 48.52it/s]Extracting features:  32%|███▏      | 50/157 [00:01<00:02, 52.12it/s]Extracting features:  36%|███▌      | 56/157 [00:01<00:01, 51.89it/s]Extracting features:  39%|███▉      | 62/157 [00:01<00:01, 52.93it/s]Extracting features:  43%|████▎     | 68/157 [00:01<00:01, 53.00it/s]Extracting features:  47%|████▋     | 74/157 [00:01<00:01, 54.39it/s]Extracting features:  51%|█████     | 80/157 [00:01<00:01, 53.76it/s]Extracting features:  55%|█████▍    | 86/157 [00:01<00:01, 54.35it/s]Extracting features:  59%|█████▊    | 92/157 [00:01<00:01, 55.27it/s]Extracting features:  62%|██████▏   | 98/157 [00:02<00:01, 56.01it/s]Extracting features:  66%|██████▌   | 104/157 [00:02<00:00, 56.99it/s]Extracting features:  70%|███████   | 110/157 [00:02<00:00, 55.58it/s]Extracting features:  74%|███████▍  | 116/157 [00:02<00:00, 55.71it/s]Extracting features:  78%|███████▊  | 122/157 [00:02<00:00, 55.30it/s]Extracting features:  82%|████████▏ | 128/157 [00:02<00:00, 55.08it/s]Extracting features:  85%|████████▌ | 134/157 [00:02<00:00, 53.75it/s]Extracting features:  89%|████████▉ | 140/157 [00:02<00:00, 55.32it/s]Extracting features:  93%|█████████▎| 146/157 [00:02<00:00, 56.08it/s]Extracting features:  97%|█████████▋| 153/157 [00:03<00:00, 58.49it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 49.93it/s]
2024-12-27 20:11:48,995 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:11:48,996 - INFO - Training feature extraction completed in 3.16s
2024-12-27 20:11:48,996 - INFO - Creating model for classifier: KNeighbors
2024-12-27 20:11:48,996 - INFO - Using device: cuda
2024-12-27 20:11:48,996 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:11:48,996 - INFO - Training set processing completed in 0.00s
2024-12-27 20:11:48,996 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:11:48,998 - INFO - Memory usage at start_fit: CPU 3273.5 MB, GPU 47.3 MB
2024-12-27 20:11:48,998 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:11:49,075 - INFO - Fitted scaler and transformed data
2024-12-27 20:11:49,075 - INFO - Scaling time: 0.08s
2024-12-27 20:11:49,080 - INFO - Training completed in 0.08s
2024-12-27 20:11:49,080 - INFO - Final memory usage: CPU 3298.0 MB, GPU 71.8 MB
2024-12-27 20:11:49,081 - INFO - Model training completed in 0.08s
2024-12-27 20:11:49,096 - INFO - Prediction completed in 0.02s
2024-12-27 20:11:49,105 - INFO - Poison rate 0.0 completed in 0.11s
2024-12-27 20:11:49,106 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:11:49,108 - INFO - Total number of labels flipped: 50
2024-12-27 20:11:49,108 - INFO - Label flipping completed in 0.00s
2024-12-27 20:11:49,108 - INFO - Training set processing completed in 0.00s
2024-12-27 20:11:49,108 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:11:49,109 - INFO - Memory usage at start_fit: CPU 3298.0 MB, GPU 71.8 MB
2024-12-27 20:11:49,109 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:11:49,172 - INFO - Fitted scaler and transformed data
2024-12-27 20:11:49,172 - INFO - Scaling time: 0.06s
2024-12-27 20:11:49,177 - INFO - Training completed in 0.07s
2024-12-27 20:11:49,178 - INFO - Final memory usage: CPU 3298.0 MB, GPU 71.8 MB
2024-12-27 20:11:49,178 - INFO - Model training completed in 0.07s
2024-12-27 20:11:49,192 - INFO - Prediction completed in 0.01s
2024-12-27 20:11:49,201 - INFO - Poison rate 0.01 completed in 0.10s
2024-12-27 20:11:49,201 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:11:49,206 - INFO - Total number of labels flipped: 150
2024-12-27 20:11:49,206 - INFO - Label flipping completed in 0.00s
2024-12-27 20:11:49,206 - INFO - Training set processing completed in 0.00s
2024-12-27 20:11:49,206 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:11:49,207 - INFO - Memory usage at start_fit: CPU 3298.0 MB, GPU 71.8 MB
2024-12-27 20:11:49,207 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:11:49,277 - INFO - Fitted scaler and transformed data
2024-12-27 20:11:49,277 - INFO - Scaling time: 0.07s
2024-12-27 20:11:49,287 - INFO - Training completed in 0.08s
2024-12-27 20:11:49,288 - INFO - Final memory usage: CPU 3298.0 MB, GPU 71.8 MB
2024-12-27 20:11:49,289 - INFO - Model training completed in 0.08s
2024-12-27 20:11:49,314 - INFO - Prediction completed in 0.03s
2024-12-27 20:11:49,323 - INFO - Poison rate 0.03 completed in 0.12s
2024-12-27 20:11:49,324 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:11:49,331 - INFO - Total number of labels flipped: 250
2024-12-27 20:11:49,331 - INFO - Label flipping completed in 0.01s
2024-12-27 20:11:49,331 - INFO - Training set processing completed in 0.00s
2024-12-27 20:11:49,331 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:11:49,332 - INFO - Memory usage at start_fit: CPU 3298.0 MB, GPU 71.8 MB
2024-12-27 20:11:49,332 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:11:49,392 - INFO - Fitted scaler and transformed data
2024-12-27 20:11:49,392 - INFO - Scaling time: 0.06s
2024-12-27 20:11:49,399 - INFO - Training completed in 0.07s
2024-12-27 20:11:49,399 - INFO - Final memory usage: CPU 3298.0 MB, GPU 71.8 MB
2024-12-27 20:11:49,399 - INFO - Model training completed in 0.07s
2024-12-27 20:11:49,418 - INFO - Prediction completed in 0.02s
2024-12-27 20:11:49,428 - INFO - Poison rate 0.05 completed in 0.10s
2024-12-27 20:11:49,428 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:11:49,438 - INFO - Total number of labels flipped: 350
2024-12-27 20:11:49,439 - INFO - Label flipping completed in 0.01s
2024-12-27 20:11:49,439 - INFO - Training set processing completed in 0.00s
2024-12-27 20:11:49,439 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:11:49,440 - INFO - Memory usage at start_fit: CPU 3298.0 MB, GPU 71.8 MB
2024-12-27 20:11:49,440 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:11:49,509 - INFO - Fitted scaler and transformed data
2024-12-27 20:11:49,509 - INFO - Scaling time: 0.07s
2024-12-27 20:11:49,514 - INFO - Training completed in 0.07s
2024-12-27 20:11:49,514 - INFO - Final memory usage: CPU 3298.0 MB, GPU 71.8 MB
2024-12-27 20:11:49,514 - INFO - Model training completed in 0.08s
2024-12-27 20:11:49,528 - INFO - Prediction completed in 0.01s
2024-12-27 20:11:49,537 - INFO - Poison rate 0.07 completed in 0.11s
2024-12-27 20:11:49,537 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:11:49,551 - INFO - Total number of labels flipped: 500
2024-12-27 20:11:49,551 - INFO - Label flipping completed in 0.01s
2024-12-27 20:11:49,552 - INFO - Training set processing completed in 0.00s
2024-12-27 20:11:49,552 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:11:49,552 - INFO - Memory usage at start_fit: CPU 3298.0 MB, GPU 71.8 MB
2024-12-27 20:11:49,553 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:11:49,612 - INFO - Fitted scaler and transformed data
2024-12-27 20:11:49,612 - INFO - Scaling time: 0.06s
2024-12-27 20:11:49,617 - INFO - Training completed in 0.06s
2024-12-27 20:11:49,617 - INFO - Final memory usage: CPU 3298.0 MB, GPU 71.8 MB
2024-12-27 20:11:49,618 - INFO - Model training completed in 0.07s
2024-12-27 20:11:49,632 - INFO - Prediction completed in 0.01s
2024-12-27 20:11:49,640 - INFO - Poison rate 0.1 completed in 0.10s
2024-12-27 20:11:49,640 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:11:49,677 - INFO - Total number of labels flipped: 1000
2024-12-27 20:11:49,677 - INFO - Label flipping completed in 0.04s
2024-12-27 20:11:49,678 - INFO - Training set processing completed in 0.00s
2024-12-27 20:11:49,678 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:11:49,678 - INFO - Memory usage at start_fit: CPU 3298.0 MB, GPU 71.8 MB
2024-12-27 20:11:49,679 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:11:49,737 - INFO - Fitted scaler and transformed data
2024-12-27 20:11:49,738 - INFO - Scaling time: 0.06s
2024-12-27 20:11:49,744 - INFO - Training completed in 0.07s
2024-12-27 20:11:49,744 - INFO - Final memory usage: CPU 3298.0 MB, GPU 71.8 MB
2024-12-27 20:11:49,744 - INFO - Model training completed in 0.07s
2024-12-27 20:11:49,767 - INFO - Prediction completed in 0.02s
2024-12-27 20:11:49,775 - INFO - Poison rate 0.2 completed in 0.13s
2024-12-27 20:11:49,777 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:11:49,778 - INFO - Total evaluation time: 6.45s
2024-12-27 20:11:49,779 - INFO - 
Progress: 41.7% - Evaluating CIFAR100 with KNeighbors (dynadetect mode, iteration 1/1)
2024-12-27 20:11:49,840 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:11:49,913 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:11:50,030 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:11:50,030 - INFO - Dataset type: image
2024-12-27 20:11:50,030 - INFO - Sample size: 5000
2024-12-27 20:11:50,030 - INFO - Using device: cuda
2024-12-27 20:11:50,033 - INFO - Loading datasets...
2024-12-27 20:11:51,322 - INFO - Dataset loading completed in 1.29s
2024-12-27 20:11:51,322 - INFO - Extracting validation features...
2024-12-27 20:11:51,322 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:09,  3.31it/s]Extracting features:  12%|█▎        | 4/32 [00:00<00:02, 11.31it/s]Extracting features:  25%|██▌       | 8/32 [00:00<00:01, 19.31it/s]Extracting features:  41%|████      | 13/32 [00:00<00:00, 27.40it/s]Extracting features:  59%|█████▉    | 19/32 [00:00<00:00, 36.34it/s]Extracting features:  78%|███████▊  | 25/32 [00:00<00:00, 42.22it/s]Extracting features: 100%|██████████| 32/32 [00:00<00:00, 47.25it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 30.90it/s]
2024-12-27 20:11:52,363 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:11:52,364 - INFO - Validation feature extraction completed in 1.04s
2024-12-27 20:11:52,364 - INFO - Extracting training features...
2024-12-27 20:11:52,364 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:43,  3.62it/s]Extracting features:   4%|▍         | 7/157 [00:00<00:07, 21.38it/s]Extracting features:   8%|▊         | 13/157 [00:00<00:04, 32.41it/s]Extracting features:  12%|█▏        | 19/157 [00:00<00:03, 39.75it/s]Extracting features:  16%|█▌        | 25/157 [00:00<00:02, 44.92it/s]Extracting features:  20%|█▉        | 31/157 [00:00<00:02, 47.84it/s]Extracting features:  24%|██▎       | 37/157 [00:00<00:02, 50.13it/s]Extracting features:  27%|██▋       | 43/157 [00:01<00:02, 49.90it/s]Extracting features:  31%|███       | 49/157 [00:01<00:02, 52.19it/s]Extracting features:  35%|███▌      | 55/157 [00:01<00:01, 53.12it/s]Extracting features:  39%|███▉      | 61/157 [00:01<00:01, 55.00it/s]Extracting features:  43%|████▎     | 67/157 [00:01<00:01, 54.30it/s]Extracting features:  46%|████▋     | 73/157 [00:01<00:01, 54.76it/s]Extracting features:  51%|█████     | 80/157 [00:01<00:01, 56.20it/s]Extracting features:  55%|█████▍    | 86/157 [00:01<00:01, 56.15it/s]Extracting features:  59%|█████▊    | 92/157 [00:01<00:01, 52.97it/s]Extracting features:  62%|██████▏   | 98/157 [00:02<00:01, 54.15it/s]Extracting features:  66%|██████▌   | 104/157 [00:02<00:00, 54.14it/s]Extracting features:  70%|███████   | 110/157 [00:02<00:00, 54.60it/s]Extracting features:  74%|███████▍  | 116/157 [00:02<00:00, 55.67it/s]Extracting features:  78%|███████▊  | 122/157 [00:02<00:00, 54.24it/s]Extracting features:  82%|████████▏ | 128/157 [00:02<00:00, 54.10it/s]Extracting features:  85%|████████▌ | 134/157 [00:02<00:00, 54.90it/s]Extracting features:  89%|████████▉ | 140/157 [00:02<00:00, 55.75it/s]Extracting features:  93%|█████████▎| 146/157 [00:02<00:00, 55.02it/s]Extracting features:  97%|█████████▋| 152/157 [00:03<00:00, 54.93it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 49.70it/s]
2024-12-27 20:11:55,536 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:11:55,537 - INFO - Training feature extraction completed in 3.17s
2024-12-27 20:11:55,537 - INFO - Creating model for classifier: KNeighbors
2024-12-27 20:11:55,537 - INFO - Using device: cuda
2024-12-27 20:11:55,537 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:11:55,537 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:11:55,537 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:11:56,206 - INFO - Feature scaling completed in 0.67s
2024-12-27 20:11:56,206 - INFO - Starting feature selection (k=50)
2024-12-27 20:11:56,213 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:11:56,214 - INFO - Starting anomaly detection
2024-12-27 20:11:57,406 - INFO - Anomaly detection completed in 1.19s
2024-12-27 20:11:57,407 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:11:57,407 - INFO - Total fit_transform time: 1.87s
2024-12-27 20:11:57,407 - INFO - Training set processing completed in 1.87s
2024-12-27 20:11:57,407 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:11:57,408 - INFO - Memory usage at start_fit: CPU 3287.7 MB, GPU 47.3 MB
2024-12-27 20:11:57,408 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:11:57,501 - INFO - Fitted scaler and transformed data
2024-12-27 20:11:57,501 - INFO - Scaling time: 0.09s
2024-12-27 20:11:57,506 - INFO - Training completed in 0.10s
2024-12-27 20:11:57,506 - INFO - Final memory usage: CPU 3287.7 MB, GPU 71.8 MB
2024-12-27 20:11:57,506 - INFO - Model training completed in 0.10s
2024-12-27 20:11:57,528 - INFO - Prediction completed in 0.02s
2024-12-27 20:11:57,537 - INFO - Poison rate 0.0 completed in 2.00s
2024-12-27 20:11:57,537 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:11:57,539 - INFO - Total number of labels flipped: 50
2024-12-27 20:11:57,540 - INFO - Label flipping completed in 0.00s
2024-12-27 20:11:57,540 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:11:57,540 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:11:58,141 - INFO - Feature scaling completed in 0.60s
2024-12-27 20:11:58,141 - INFO - Starting feature selection (k=50)
2024-12-27 20:11:58,147 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:11:58,147 - INFO - Starting anomaly detection
2024-12-27 20:12:00,278 - INFO - Anomaly detection completed in 2.13s
2024-12-27 20:12:00,278 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:12:00,278 - INFO - Total fit_transform time: 2.74s
2024-12-27 20:12:00,278 - INFO - Training set processing completed in 2.74s
2024-12-27 20:12:00,278 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:12:00,280 - INFO - Memory usage at start_fit: CPU 3287.7 MB, GPU 71.8 MB
2024-12-27 20:12:00,280 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:12:00,372 - INFO - Fitted scaler and transformed data
2024-12-27 20:12:00,373 - INFO - Scaling time: 0.09s
2024-12-27 20:12:00,380 - INFO - Training completed in 0.10s
2024-12-27 20:12:00,381 - INFO - Final memory usage: CPU 3287.7 MB, GPU 71.8 MB
2024-12-27 20:12:00,381 - INFO - Model training completed in 0.10s
2024-12-27 20:12:00,396 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:12:00,406 - INFO - Poison rate 0.01 completed in 2.87s
2024-12-27 20:12:00,406 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:12:00,410 - INFO - Total number of labels flipped: 150
2024-12-27 20:12:00,410 - INFO - Label flipping completed in 0.00s
2024-12-27 20:12:00,411 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:12:00,411 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:12:00,993 - INFO - Feature scaling completed in 0.58s
2024-12-27 20:12:00,993 - INFO - Starting feature selection (k=50)
2024-12-27 20:12:00,999 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:12:00,999 - INFO - Starting anomaly detection
2024-12-27 20:12:03,192 - INFO - Anomaly detection completed in 2.19s
2024-12-27 20:12:03,193 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:12:03,193 - INFO - Total fit_transform time: 2.78s
2024-12-27 20:12:03,193 - INFO - Training set processing completed in 2.78s
2024-12-27 20:12:03,193 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:12:03,194 - INFO - Memory usage at start_fit: CPU 3287.7 MB, GPU 71.8 MB
2024-12-27 20:12:03,195 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:12:03,275 - INFO - Fitted scaler and transformed data
2024-12-27 20:12:03,276 - INFO - Scaling time: 0.08s
2024-12-27 20:12:03,283 - INFO - Training completed in 0.09s
2024-12-27 20:12:03,284 - INFO - Final memory usage: CPU 3287.7 MB, GPU 71.8 MB
2024-12-27 20:12:03,284 - INFO - Model training completed in 0.09s
2024-12-27 20:12:03,309 - INFO - Prediction completed in 0.03s
2024-12-27 20:12:03,318 - INFO - Poison rate 0.03 completed in 2.91s
2024-12-27 20:12:03,318 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:12:03,326 - INFO - Total number of labels flipped: 250
2024-12-27 20:12:03,326 - INFO - Label flipping completed in 0.01s
2024-12-27 20:12:03,326 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:12:03,326 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:12:03,937 - INFO - Feature scaling completed in 0.61s
2024-12-27 20:12:03,937 - INFO - Starting feature selection (k=50)
2024-12-27 20:12:03,953 - INFO - Feature selection completed in 0.02s. Output shape: (5000, 50)
2024-12-27 20:12:03,953 - INFO - Starting anomaly detection
2024-12-27 20:12:06,237 - INFO - Anomaly detection completed in 2.28s
2024-12-27 20:12:06,237 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:12:06,237 - INFO - Total fit_transform time: 2.91s
2024-12-27 20:12:06,238 - INFO - Training set processing completed in 2.91s
2024-12-27 20:12:06,238 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:12:06,239 - INFO - Memory usage at start_fit: CPU 3287.7 MB, GPU 71.8 MB
2024-12-27 20:12:06,240 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:12:06,308 - INFO - Fitted scaler and transformed data
2024-12-27 20:12:06,308 - INFO - Scaling time: 0.07s
2024-12-27 20:12:06,314 - INFO - Training completed in 0.08s
2024-12-27 20:12:06,315 - INFO - Final memory usage: CPU 3287.7 MB, GPU 71.8 MB
2024-12-27 20:12:06,315 - INFO - Model training completed in 0.08s
2024-12-27 20:12:06,340 - INFO - Prediction completed in 0.02s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:12:06,348 - INFO - Poison rate 0.05 completed in 3.03s
2024-12-27 20:12:06,349 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:12:06,359 - INFO - Total number of labels flipped: 350
2024-12-27 20:12:06,359 - INFO - Label flipping completed in 0.01s
2024-12-27 20:12:06,359 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:12:06,359 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:12:06,942 - INFO - Feature scaling completed in 0.58s
2024-12-27 20:12:06,942 - INFO - Starting feature selection (k=50)
2024-12-27 20:12:06,949 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:12:06,950 - INFO - Starting anomaly detection
2024-12-27 20:12:08,343 - INFO - Anomaly detection completed in 1.39s
2024-12-27 20:12:08,343 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:12:08,343 - INFO - Total fit_transform time: 1.98s
2024-12-27 20:12:08,343 - INFO - Training set processing completed in 1.98s
2024-12-27 20:12:08,343 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:12:08,344 - INFO - Memory usage at start_fit: CPU 3287.7 MB, GPU 71.8 MB
2024-12-27 20:12:08,344 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:12:08,423 - INFO - Fitted scaler and transformed data
2024-12-27 20:12:08,423 - INFO - Scaling time: 0.08s
2024-12-27 20:12:08,429 - INFO - Training completed in 0.09s
2024-12-27 20:12:08,429 - INFO - Final memory usage: CPU 3287.7 MB, GPU 71.8 MB
2024-12-27 20:12:08,430 - INFO - Model training completed in 0.09s
2024-12-27 20:12:08,455 - INFO - Prediction completed in 0.03s
2024-12-27 20:12:08,467 - INFO - Poison rate 0.07 completed in 2.12s
2024-12-27 20:12:08,468 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:12:08,482 - INFO - Total number of labels flipped: 500
2024-12-27 20:12:08,482 - INFO - Label flipping completed in 0.01s
2024-12-27 20:12:08,482 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:12:08,482 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:12:09,081 - INFO - Feature scaling completed in 0.60s
2024-12-27 20:12:09,082 - INFO - Starting feature selection (k=50)
2024-12-27 20:12:09,089 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:12:09,089 - INFO - Starting anomaly detection
2024-12-27 20:12:11,143 - INFO - Anomaly detection completed in 2.05s
2024-12-27 20:12:11,144 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:12:11,144 - INFO - Total fit_transform time: 2.66s
2024-12-27 20:12:11,144 - INFO - Training set processing completed in 2.66s
2024-12-27 20:12:11,144 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:12:11,145 - INFO - Memory usage at start_fit: CPU 3287.7 MB, GPU 71.8 MB
2024-12-27 20:12:11,145 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:12:11,216 - INFO - Fitted scaler and transformed data
2024-12-27 20:12:11,216 - INFO - Scaling time: 0.07s
2024-12-27 20:12:11,222 - INFO - Training completed in 0.08s
2024-12-27 20:12:11,223 - INFO - Final memory usage: CPU 3287.7 MB, GPU 71.8 MB
2024-12-27 20:12:11,223 - INFO - Model training completed in 0.08s
2024-12-27 20:12:11,248 - INFO - Prediction completed in 0.02s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:12:11,257 - INFO - Poison rate 0.1 completed in 2.79s
2024-12-27 20:12:11,257 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:12:11,295 - INFO - Total number of labels flipped: 1000
2024-12-27 20:12:11,295 - INFO - Label flipping completed in 0.04s
2024-12-27 20:12:11,296 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:12:11,296 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:12:11,919 - INFO - Feature scaling completed in 0.62s
2024-12-27 20:12:11,919 - INFO - Starting feature selection (k=50)
2024-12-27 20:12:11,932 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:12:11,932 - INFO - Starting anomaly detection
2024-12-27 20:12:14,284 - INFO - Anomaly detection completed in 2.35s
2024-12-27 20:12:14,284 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:12:14,284 - INFO - Total fit_transform time: 2.99s
2024-12-27 20:12:14,284 - INFO - Training set processing completed in 2.99s
2024-12-27 20:12:14,284 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:12:14,286 - INFO - Memory usage at start_fit: CPU 3287.7 MB, GPU 71.8 MB
2024-12-27 20:12:14,286 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:12:14,358 - INFO - Fitted scaler and transformed data
2024-12-27 20:12:14,359 - INFO - Scaling time: 0.07s
2024-12-27 20:12:14,365 - INFO - Training completed in 0.08s
2024-12-27 20:12:14,366 - INFO - Final memory usage: CPU 3287.7 MB, GPU 71.8 MB
2024-12-27 20:12:14,366 - INFO - Model training completed in 0.08s
2024-12-27 20:12:14,393 - INFO - Prediction completed in 0.03s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:12:14,402 - INFO - Poison rate 0.2 completed in 3.14s
2024-12-27 20:12:14,404 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:12:14,404 - INFO - Total evaluation time: 24.37s
2024-12-27 20:12:14,405 - INFO - Completed evaluation for CIFAR100
2024-12-27 20:12:14,406 - INFO - 
Processing dataset: CIFAR100
2024-12-27 20:12:14,466 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:12:14,544 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:12:14,662 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:12:14,662 - INFO - Dataset type: image
2024-12-27 20:12:14,662 - INFO - Sample size: 5000
2024-12-27 20:12:14,662 - INFO - Using device: cuda
2024-12-27 20:12:14,666 - INFO - 
Progress: 42.7% - Evaluating CIFAR100 with SVM (standard mode, iteration 1/1)
2024-12-27 20:12:14,730 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:12:14,889 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:12:14,990 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:12:14,990 - INFO - Dataset type: image
2024-12-27 20:12:14,990 - INFO - Sample size: 5000
2024-12-27 20:12:14,991 - INFO - Using device: cuda
2024-12-27 20:12:14,993 - INFO - Loading datasets...
2024-12-27 20:12:16,412 - INFO - Dataset loading completed in 1.42s
2024-12-27 20:12:16,413 - INFO - Extracting validation features...
2024-12-27 20:12:16,413 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:17,  1.77it/s]Extracting features:  16%|█▌        | 5/32 [00:00<00:02,  9.15it/s]Extracting features:  31%|███▏      | 10/32 [00:00<00:01, 17.70it/s]Extracting features:  50%|█████     | 16/32 [00:00<00:00, 26.89it/s]Extracting features:  69%|██████▉   | 22/32 [00:01<00:00, 34.60it/s]Extracting features:  88%|████████▊ | 28/32 [00:01<00:00, 40.30it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 24.80it/s]
2024-12-27 20:12:17,709 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:12:17,710 - INFO - Validation feature extraction completed in 1.30s
2024-12-27 20:12:17,710 - INFO - Extracting training features...
2024-12-27 20:12:17,710 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:42,  3.69it/s]Extracting features:   4%|▍         | 6/157 [00:00<00:07, 19.48it/s]Extracting features:   8%|▊         | 12/157 [00:00<00:04, 32.44it/s]Extracting features:  11%|█▏        | 18/157 [00:00<00:03, 40.23it/s]Extracting features:  15%|█▌        | 24/157 [00:00<00:02, 45.03it/s]Extracting features:  19%|█▉        | 30/157 [00:00<00:02, 49.13it/s]Extracting features:  23%|██▎       | 36/157 [00:00<00:02, 50.62it/s]Extracting features:  27%|██▋       | 42/157 [00:01<00:02, 52.98it/s]Extracting features:  31%|███       | 48/157 [00:01<00:02, 53.51it/s]Extracting features:  34%|███▍      | 54/157 [00:01<00:01, 52.90it/s]Extracting features:  38%|███▊      | 60/157 [00:01<00:01, 51.55it/s]Extracting features:  43%|████▎     | 67/157 [00:01<00:01, 54.93it/s]Extracting features:  46%|████▋     | 73/157 [00:01<00:01, 52.51it/s]Extracting features:  50%|█████     | 79/157 [00:01<00:01, 52.72it/s]Extracting features:  54%|█████▍    | 85/157 [00:01<00:01, 53.03it/s]Extracting features:  58%|█████▊    | 91/157 [00:01<00:01, 52.59it/s]Extracting features:  62%|██████▏   | 97/157 [00:02<00:01, 54.11it/s]Extracting features:  66%|██████▌   | 103/157 [00:02<00:00, 54.89it/s]Extracting features:  69%|██████▉   | 109/157 [00:02<00:00, 54.11it/s]Extracting features:  74%|███████▍  | 116/157 [00:02<00:00, 55.79it/s]Extracting features:  78%|███████▊  | 122/157 [00:02<00:00, 50.66it/s]Extracting features:  82%|████████▏ | 128/157 [00:02<00:00, 52.53it/s]Extracting features:  85%|████████▌ | 134/157 [00:02<00:00, 53.48it/s]Extracting features:  89%|████████▉ | 140/157 [00:02<00:00, 50.69it/s]Extracting features:  94%|█████████▎| 147/157 [00:02<00:00, 53.38it/s]Extracting features:  98%|█████████▊| 154/157 [00:03<00:00, 54.77it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 48.93it/s]
2024-12-27 20:12:20,934 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:12:20,935 - INFO - Training feature extraction completed in 3.22s
2024-12-27 20:12:20,935 - INFO - Creating model for classifier: SVM
2024-12-27 20:12:20,935 - INFO - Using device: cuda
2024-12-27 20:12:20,935 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-27 20:12:20,935 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:12:20,935 - INFO - Training set processing completed in 0.00s
2024-12-27 20:12:20,935 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:12:20,936 - INFO - Memory usage at start_fit: CPU 3272.9 MB, GPU 47.3 MB
2024-12-27 20:12:20,937 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:12:20,937 - INFO - Number of unique classes: 100
2024-12-27 20:12:21,039 - INFO - Fitted scaler and transformed data
2024-12-27 20:12:21,039 - INFO - Scaling time: 0.10s
2024-12-27 20:12:21,257 - INFO - Epoch 1/25, Train Loss: 22.9772, Val Loss: 18.3549
2024-12-27 20:12:21,455 - INFO - Epoch 2/25, Train Loss: 1.9737, Val Loss: 18.3027
2024-12-27 20:12:21,640 - INFO - Epoch 3/25, Train Loss: 0.7239, Val Loss: 17.6459
2024-12-27 20:12:21,825 - INFO - Epoch 4/25, Train Loss: 0.3088, Val Loss: 17.4021
2024-12-27 20:12:22,011 - INFO - Epoch 5/25, Train Loss: 0.1510, Val Loss: 17.1753
2024-12-27 20:12:22,214 - INFO - Epoch 6/25, Train Loss: 0.0686, Val Loss: 17.2060
2024-12-27 20:12:22,401 - INFO - Epoch 7/25, Train Loss: 0.0260, Val Loss: 17.2813
2024-12-27 20:12:22,402 - INFO - Early stopping triggered at epoch 7
2024-12-27 20:12:22,402 - INFO - Training completed in 1.47s
2024-12-27 20:12:22,402 - INFO - Final memory usage: CPU 3297.4 MB, GPU 49.9 MB
2024-12-27 20:12:22,403 - INFO - Model training completed in 1.47s
2024-12-27 20:12:22,410 - INFO - Prediction completed in 0.01s
2024-12-27 20:12:22,421 - INFO - Poison rate 0.0 completed in 1.49s
2024-12-27 20:12:22,421 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:12:22,422 - INFO - Total number of labels flipped: 48
2024-12-27 20:12:22,422 - INFO - Label flipping completed in 0.00s
2024-12-27 20:12:22,422 - INFO - Training set processing completed in 0.00s
2024-12-27 20:12:22,422 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:12:22,423 - INFO - Memory usage at start_fit: CPU 3297.4 MB, GPU 49.3 MB
2024-12-27 20:12:22,423 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:12:22,424 - INFO - Number of unique classes: 100
2024-12-27 20:12:22,510 - INFO - Fitted scaler and transformed data
2024-12-27 20:12:22,510 - INFO - Scaling time: 0.08s
2024-12-27 20:12:22,697 - INFO - Epoch 1/25, Train Loss: 25.4794, Val Loss: 21.8052
2024-12-27 20:12:22,894 - INFO - Epoch 2/25, Train Loss: 2.5161, Val Loss: 22.2231
2024-12-27 20:12:23,095 - INFO - Epoch 3/25, Train Loss: 0.9250, Val Loss: 20.8468
2024-12-27 20:12:23,261 - INFO - Epoch 4/25, Train Loss: 0.4243, Val Loss: 20.3140
2024-12-27 20:12:23,439 - INFO - Epoch 5/25, Train Loss: 0.1980, Val Loss: 19.9547
2024-12-27 20:12:23,616 - INFO - Epoch 6/25, Train Loss: 0.0996, Val Loss: 19.7742
2024-12-27 20:12:23,783 - INFO - Epoch 7/25, Train Loss: 0.0456, Val Loss: 19.8249
2024-12-27 20:12:23,988 - INFO - Epoch 8/25, Train Loss: 0.0283, Val Loss: 19.7749
2024-12-27 20:12:23,988 - INFO - Early stopping triggered at epoch 8
2024-12-27 20:12:23,988 - INFO - Training completed in 1.57s
2024-12-27 20:12:23,988 - INFO - Final memory usage: CPU 3297.4 MB, GPU 49.9 MB
2024-12-27 20:12:23,989 - INFO - Model training completed in 1.57s
2024-12-27 20:12:23,997 - INFO - Prediction completed in 0.01s
2024-12-27 20:12:24,007 - INFO - Poison rate 0.01 completed in 1.59s
2024-12-27 20:12:24,007 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:12:24,008 - INFO - Total number of labels flipped: 150
2024-12-27 20:12:24,008 - INFO - Label flipping completed in 0.00s
2024-12-27 20:12:24,008 - INFO - Training set processing completed in 0.00s
2024-12-27 20:12:24,009 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:12:24,009 - INFO - Memory usage at start_fit: CPU 3297.4 MB, GPU 49.3 MB
2024-12-27 20:12:24,009 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:12:24,010 - INFO - Number of unique classes: 100
2024-12-27 20:12:24,105 - INFO - Fitted scaler and transformed data
2024-12-27 20:12:24,106 - INFO - Scaling time: 0.09s
2024-12-27 20:12:24,281 - INFO - Epoch 1/25, Train Loss: 31.1923, Val Loss: 30.4407
2024-12-27 20:12:24,481 - INFO - Epoch 2/25, Train Loss: 5.3611, Val Loss: 26.2228
2024-12-27 20:12:24,654 - INFO - Epoch 3/25, Train Loss: 2.1927, Val Loss: 26.3205
2024-12-27 20:12:24,819 - INFO - Epoch 4/25, Train Loss: 0.9717, Val Loss: 26.1671
2024-12-27 20:12:25,003 - INFO - Epoch 5/25, Train Loss: 0.4968, Val Loss: 25.9181
2024-12-27 20:12:25,187 - INFO - Epoch 6/25, Train Loss: 0.2743, Val Loss: 25.9854
2024-12-27 20:12:25,375 - INFO - Epoch 7/25, Train Loss: 0.1623, Val Loss: 26.0487
2024-12-27 20:12:25,375 - INFO - Early stopping triggered at epoch 7
2024-12-27 20:12:25,375 - INFO - Training completed in 1.37s
2024-12-27 20:12:25,376 - INFO - Final memory usage: CPU 3297.4 MB, GPU 49.9 MB
2024-12-27 20:12:25,376 - INFO - Model training completed in 1.37s
2024-12-27 20:12:25,382 - INFO - Prediction completed in 0.01s
2024-12-27 20:12:25,396 - INFO - Poison rate 0.03 completed in 1.39s
2024-12-27 20:12:25,396 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:12:25,397 - INFO - Total number of labels flipped: 249
2024-12-27 20:12:25,397 - INFO - Label flipping completed in 0.00s
2024-12-27 20:12:25,398 - INFO - Training set processing completed in 0.00s
2024-12-27 20:12:25,398 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:12:25,398 - INFO - Memory usage at start_fit: CPU 3297.4 MB, GPU 49.3 MB
2024-12-27 20:12:25,398 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:12:25,399 - INFO - Number of unique classes: 100
2024-12-27 20:12:25,479 - INFO - Fitted scaler and transformed data
2024-12-27 20:12:25,479 - INFO - Scaling time: 0.08s
2024-12-27 20:12:25,690 - INFO - Epoch 1/25, Train Loss: 33.7462, Val Loss: 28.9946
2024-12-27 20:12:25,866 - INFO - Epoch 2/25, Train Loss: 8.1251, Val Loss: 28.3218
2024-12-27 20:12:26,052 - INFO - Epoch 3/25, Train Loss: 3.3693, Val Loss: 24.5649
2024-12-27 20:12:26,236 - INFO - Epoch 4/25, Train Loss: 1.4837, Val Loss: 24.8056
2024-12-27 20:12:26,416 - INFO - Epoch 5/25, Train Loss: 0.7062, Val Loss: 25.2203
2024-12-27 20:12:26,416 - INFO - Early stopping triggered at epoch 5
2024-12-27 20:12:26,416 - INFO - Training completed in 1.02s
2024-12-27 20:12:26,416 - INFO - Final memory usage: CPU 3297.4 MB, GPU 49.9 MB
2024-12-27 20:12:26,417 - INFO - Model training completed in 1.02s
2024-12-27 20:12:26,423 - INFO - Prediction completed in 0.01s
2024-12-27 20:12:26,432 - INFO - Poison rate 0.05 completed in 1.04s
2024-12-27 20:12:26,432 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:12:26,433 - INFO - Total number of labels flipped: 350
2024-12-27 20:12:26,433 - INFO - Label flipping completed in 0.00s
2024-12-27 20:12:26,433 - INFO - Training set processing completed in 0.00s
2024-12-27 20:12:26,433 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:12:26,434 - INFO - Memory usage at start_fit: CPU 3297.4 MB, GPU 49.3 MB
2024-12-27 20:12:26,434 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:12:26,434 - INFO - Number of unique classes: 100
2024-12-27 20:12:26,546 - INFO - Fitted scaler and transformed data
2024-12-27 20:12:26,546 - INFO - Scaling time: 0.11s
2024-12-27 20:12:26,764 - INFO - Epoch 1/25, Train Loss: 39.3903, Val Loss: 33.1924
2024-12-27 20:12:26,951 - INFO - Epoch 2/25, Train Loss: 12.0408, Val Loss: 31.5285
2024-12-27 20:12:27,149 - INFO - Epoch 3/25, Train Loss: 5.2766, Val Loss: 28.0069
2024-12-27 20:12:27,346 - INFO - Epoch 4/25, Train Loss: 2.1669, Val Loss: 29.0603
2024-12-27 20:12:27,548 - INFO - Epoch 5/25, Train Loss: 0.9730, Val Loss: 29.0931
2024-12-27 20:12:27,549 - INFO - Early stopping triggered at epoch 5
2024-12-27 20:12:27,549 - INFO - Training completed in 1.12s
2024-12-27 20:12:27,549 - INFO - Final memory usage: CPU 3297.4 MB, GPU 49.9 MB
2024-12-27 20:12:27,550 - INFO - Model training completed in 1.12s
2024-12-27 20:12:27,557 - INFO - Prediction completed in 0.01s
2024-12-27 20:12:27,565 - INFO - Poison rate 0.07 completed in 1.13s
2024-12-27 20:12:27,565 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:12:27,566 - INFO - Total number of labels flipped: 494
2024-12-27 20:12:27,566 - INFO - Label flipping completed in 0.00s
2024-12-27 20:12:27,566 - INFO - Training set processing completed in 0.00s
2024-12-27 20:12:27,566 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:12:27,568 - INFO - Memory usage at start_fit: CPU 3297.4 MB, GPU 49.3 MB
2024-12-27 20:12:27,568 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:12:27,569 - INFO - Number of unique classes: 100
2024-12-27 20:12:27,652 - INFO - Fitted scaler and transformed data
2024-12-27 20:12:27,652 - INFO - Scaling time: 0.08s
2024-12-27 20:12:27,892 - INFO - Epoch 1/25, Train Loss: 43.7519, Val Loss: 30.6623
2024-12-27 20:12:28,084 - INFO - Epoch 2/25, Train Loss: 14.3243, Val Loss: 25.9777
2024-12-27 20:12:28,285 - INFO - Epoch 3/25, Train Loss: 6.9687, Val Loss: 29.2029
2024-12-27 20:12:28,500 - INFO - Epoch 4/25, Train Loss: 3.5894, Val Loss: 27.7160
2024-12-27 20:12:28,500 - INFO - Early stopping triggered at epoch 4
2024-12-27 20:12:28,500 - INFO - Training completed in 0.93s
2024-12-27 20:12:28,501 - INFO - Final memory usage: CPU 3297.4 MB, GPU 49.9 MB
2024-12-27 20:12:28,501 - INFO - Model training completed in 0.93s
2024-12-27 20:12:28,508 - INFO - Prediction completed in 0.01s
2024-12-27 20:12:28,518 - INFO - Poison rate 0.1 completed in 0.95s
2024-12-27 20:12:28,518 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:12:28,519 - INFO - Total number of labels flipped: 989
2024-12-27 20:12:28,519 - INFO - Label flipping completed in 0.00s
2024-12-27 20:12:28,519 - INFO - Training set processing completed in 0.00s
2024-12-27 20:12:28,519 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:12:28,520 - INFO - Memory usage at start_fit: CPU 3297.4 MB, GPU 49.3 MB
2024-12-27 20:12:28,520 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:12:28,526 - INFO - Number of unique classes: 100
2024-12-27 20:12:28,636 - INFO - Fitted scaler and transformed data
2024-12-27 20:12:28,636 - INFO - Scaling time: 0.10s
2024-12-27 20:12:28,883 - INFO - Epoch 1/25, Train Loss: 62.8971, Val Loss: 52.6296
2024-12-27 20:12:29,089 - INFO - Epoch 2/25, Train Loss: 28.1003, Val Loss: 48.0818
2024-12-27 20:12:29,312 - INFO - Epoch 3/25, Train Loss: 14.9042, Val Loss: 44.3952
2024-12-27 20:12:29,533 - INFO - Epoch 4/25, Train Loss: 8.4711, Val Loss: 42.6794
2024-12-27 20:12:29,749 - INFO - Epoch 5/25, Train Loss: 4.2923, Val Loss: 43.1039
2024-12-27 20:12:29,966 - INFO - Epoch 6/25, Train Loss: 2.5841, Val Loss: 41.2140
2024-12-27 20:12:30,188 - INFO - Epoch 7/25, Train Loss: 1.3220, Val Loss: 40.5114
2024-12-27 20:12:30,412 - INFO - Epoch 8/25, Train Loss: 0.8444, Val Loss: 40.6125
2024-12-27 20:12:30,612 - INFO - Epoch 9/25, Train Loss: 0.6952, Val Loss: 41.3125
2024-12-27 20:12:30,612 - INFO - Early stopping triggered at epoch 9
2024-12-27 20:12:30,612 - INFO - Training completed in 2.09s
2024-12-27 20:12:30,613 - INFO - Final memory usage: CPU 3297.4 MB, GPU 49.9 MB
2024-12-27 20:12:30,613 - INFO - Model training completed in 2.09s
2024-12-27 20:12:30,620 - INFO - Prediction completed in 0.01s
2024-12-27 20:12:30,629 - INFO - Poison rate 0.2 completed in 2.11s
2024-12-27 20:12:30,631 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:12:30,631 - INFO - Total evaluation time: 15.64s
2024-12-27 20:12:30,632 - INFO - 
Progress: 43.8% - Evaluating CIFAR100 with SVM (dynadetect mode, iteration 1/1)
2024-12-27 20:12:30,696 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:12:30,816 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:12:30,924 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:12:30,924 - INFO - Dataset type: image
2024-12-27 20:12:30,924 - INFO - Sample size: 5000
2024-12-27 20:12:30,924 - INFO - Using device: cuda
2024-12-27 20:12:30,928 - INFO - Loading datasets...
2024-12-27 20:12:32,318 - INFO - Dataset loading completed in 1.39s
2024-12-27 20:12:32,318 - INFO - Extracting validation features...
2024-12-27 20:12:32,318 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:15,  2.05it/s]Extracting features:  19%|█▉        | 6/32 [00:00<00:02, 11.93it/s]Extracting features:  31%|███▏      | 10/32 [00:00<00:01, 18.19it/s]Extracting features:  47%|████▋     | 15/32 [00:00<00:00, 25.84it/s]Extracting features:  62%|██████▎   | 20/32 [00:00<00:00, 31.61it/s]Extracting features:  81%|████████▏ | 26/32 [00:01<00:00, 38.85it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 27.11it/s]
2024-12-27 20:12:33,505 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:12:33,506 - INFO - Validation feature extraction completed in 1.19s
2024-12-27 20:12:33,506 - INFO - Extracting training features...
2024-12-27 20:12:33,506 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:42,  3.70it/s]Extracting features:   4%|▍         | 7/157 [00:00<00:06, 22.00it/s]Extracting features:   8%|▊         | 13/157 [00:00<00:04, 32.77it/s]Extracting features:  11%|█▏        | 18/157 [00:00<00:03, 35.40it/s]Extracting features:  15%|█▌        | 24/157 [00:00<00:03, 40.77it/s]Extracting features:  19%|█▉        | 30/157 [00:00<00:02, 45.51it/s]Extracting features:  23%|██▎       | 36/157 [00:00<00:02, 48.91it/s]Extracting features:  27%|██▋       | 42/157 [00:01<00:02, 49.15it/s]Extracting features:  31%|███       | 49/157 [00:01<00:02, 53.18it/s]Extracting features:  35%|███▌      | 55/157 [00:01<00:01, 51.02it/s]Extracting features:  39%|███▉      | 61/157 [00:01<00:01, 52.90it/s]Extracting features:  43%|████▎     | 67/157 [00:01<00:01, 51.19it/s]Extracting features:  47%|████▋     | 74/157 [00:01<00:01, 54.14it/s]Extracting features:  51%|█████     | 80/157 [00:01<00:01, 53.32it/s]Extracting features:  55%|█████▌    | 87/157 [00:01<00:01, 55.16it/s]Extracting features:  59%|█████▉    | 93/157 [00:01<00:01, 56.39it/s]Extracting features:  63%|██████▎   | 99/157 [00:02<00:01, 55.39it/s]Extracting features:  67%|██████▋   | 105/157 [00:02<00:00, 53.50it/s]Extracting features:  71%|███████   | 111/157 [00:02<00:00, 52.98it/s]Extracting features:  75%|███████▍  | 117/157 [00:02<00:00, 53.39it/s]Extracting features:  78%|███████▊  | 123/157 [00:02<00:00, 53.40it/s]Extracting features:  82%|████████▏ | 129/157 [00:02<00:00, 51.54it/s]Extracting features:  87%|████████▋ | 136/157 [00:02<00:00, 53.72it/s]Extracting features:  90%|█████████ | 142/157 [00:02<00:00, 53.63it/s]Extracting features:  94%|█████████▍| 148/157 [00:03<00:00, 52.46it/s]Extracting features:  99%|█████████▊| 155/157 [00:03<00:00, 56.29it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 48.69it/s]
2024-12-27 20:12:36,744 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:12:36,744 - INFO - Training feature extraction completed in 3.24s
2024-12-27 20:12:36,744 - INFO - Creating model for classifier: SVM
2024-12-27 20:12:36,744 - INFO - Using device: cuda
2024-12-27 20:12:36,744 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-27 20:12:36,744 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:12:36,744 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:12:36,744 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:12:37,306 - INFO - Feature scaling completed in 0.56s
2024-12-27 20:12:37,306 - INFO - Starting feature selection (k=50)
2024-12-27 20:12:37,314 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:12:37,315 - INFO - Starting anomaly detection
2024-12-27 20:12:39,353 - INFO - Anomaly detection completed in 2.04s
2024-12-27 20:12:39,353 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:12:39,353 - INFO - Total fit_transform time: 2.61s
2024-12-27 20:12:39,353 - INFO - Training set processing completed in 2.61s
2024-12-27 20:12:39,353 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:12:39,355 - INFO - Memory usage at start_fit: CPU 3289.8 MB, GPU 47.3 MB
2024-12-27 20:12:39,355 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:12:39,356 - INFO - Number of unique classes: 100
2024-12-27 20:12:39,453 - INFO - Fitted scaler and transformed data
2024-12-27 20:12:39,453 - INFO - Scaling time: 0.09s
2024-12-27 20:12:39,642 - INFO - Epoch 1/25, Train Loss: 20.5207, Val Loss: 16.1757
2024-12-27 20:12:39,803 - INFO - Epoch 2/25, Train Loss: 1.5735, Val Loss: 15.6136
2024-12-27 20:12:39,980 - INFO - Epoch 3/25, Train Loss: 0.5458, Val Loss: 15.2247
2024-12-27 20:12:40,159 - INFO - Epoch 4/25, Train Loss: 0.2383, Val Loss: 14.9700
2024-12-27 20:12:40,342 - INFO - Epoch 5/25, Train Loss: 0.1056, Val Loss: 14.8937
2024-12-27 20:12:40,510 - INFO - Epoch 6/25, Train Loss: 0.0448, Val Loss: 14.7107
2024-12-27 20:12:40,674 - INFO - Epoch 7/25, Train Loss: 0.0190, Val Loss: 14.7245
2024-12-27 20:12:40,836 - INFO - Epoch 8/25, Train Loss: 0.0068, Val Loss: 14.6753
2024-12-27 20:12:41,034 - INFO - Epoch 9/25, Train Loss: 0.0047, Val Loss: 14.5810
2024-12-27 20:12:41,221 - INFO - Epoch 10/25, Train Loss: 0.0030, Val Loss: 14.5222
2024-12-27 20:12:41,406 - INFO - Epoch 11/25, Train Loss: 0.0013, Val Loss: 14.4896
2024-12-27 20:12:41,617 - INFO - Epoch 12/25, Train Loss: 0.0016, Val Loss: 14.4988
2024-12-27 20:12:41,796 - INFO - Epoch 13/25, Train Loss: 0.0015, Val Loss: 14.4130
2024-12-27 20:12:41,970 - INFO - Epoch 14/25, Train Loss: 0.0012, Val Loss: 14.3912
2024-12-27 20:12:42,149 - INFO - Epoch 15/25, Train Loss: 0.0015, Val Loss: 14.3565
2024-12-27 20:12:42,322 - INFO - Epoch 16/25, Train Loss: 0.0121, Val Loss: 14.4056
2024-12-27 20:12:42,490 - INFO - Epoch 17/25, Train Loss: 0.0288, Val Loss: 14.4292
2024-12-27 20:12:42,491 - INFO - Early stopping triggered at epoch 17
2024-12-27 20:12:42,491 - INFO - Training completed in 3.14s
2024-12-27 20:12:42,491 - INFO - Final memory usage: CPU 3293.6 MB, GPU 49.9 MB
2024-12-27 20:12:42,491 - INFO - Model training completed in 3.14s
2024-12-27 20:12:42,498 - INFO - Prediction completed in 0.01s
2024-12-27 20:12:42,507 - INFO - Poison rate 0.0 completed in 5.76s
2024-12-27 20:12:42,507 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:12:42,508 - INFO - Total number of labels flipped: 50
2024-12-27 20:12:42,508 - INFO - Label flipping completed in 0.00s
2024-12-27 20:12:42,508 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:12:42,508 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:12:43,172 - INFO - Feature scaling completed in 0.66s
2024-12-27 20:12:43,173 - INFO - Starting feature selection (k=50)
2024-12-27 20:12:43,184 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:12:43,185 - INFO - Starting anomaly detection
2024-12-27 20:12:44,346 - INFO - Anomaly detection completed in 1.16s
2024-12-27 20:12:44,346 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:12:44,346 - INFO - Total fit_transform time: 1.84s
2024-12-27 20:12:44,346 - INFO - Training set processing completed in 1.84s
2024-12-27 20:12:44,346 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:12:44,347 - INFO - Memory usage at start_fit: CPU 3293.6 MB, GPU 49.3 MB
2024-12-27 20:12:44,348 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:12:44,348 - INFO - Number of unique classes: 100
2024-12-27 20:12:44,441 - INFO - Fitted scaler and transformed data
2024-12-27 20:12:44,442 - INFO - Scaling time: 0.09s
2024-12-27 20:12:44,649 - INFO - Epoch 1/25, Train Loss: 22.6453, Val Loss: 16.9180
2024-12-27 20:12:44,869 - INFO - Epoch 2/25, Train Loss: 2.1425, Val Loss: 16.7689
2024-12-27 20:12:45,072 - INFO - Epoch 3/25, Train Loss: 0.7644, Val Loss: 15.7037
2024-12-27 20:12:45,257 - INFO - Epoch 4/25, Train Loss: 0.3661, Val Loss: 15.5171
2024-12-27 20:12:45,449 - INFO - Epoch 5/25, Train Loss: 0.1867, Val Loss: 15.3891
2024-12-27 20:12:45,621 - INFO - Epoch 6/25, Train Loss: 0.0992, Val Loss: 15.2508
2024-12-27 20:12:45,814 - INFO - Epoch 7/25, Train Loss: 0.0743, Val Loss: 15.1914
2024-12-27 20:12:45,998 - INFO - Epoch 8/25, Train Loss: 0.0330, Val Loss: 15.1321
2024-12-27 20:12:46,175 - INFO - Epoch 9/25, Train Loss: 0.0264, Val Loss: 15.1556
2024-12-27 20:12:46,338 - INFO - Epoch 10/25, Train Loss: 0.0176, Val Loss: 15.1792
2024-12-27 20:12:46,338 - INFO - Early stopping triggered at epoch 10
2024-12-27 20:12:46,338 - INFO - Training completed in 1.99s
2024-12-27 20:12:46,338 - INFO - Final memory usage: CPU 3293.6 MB, GPU 49.9 MB
2024-12-27 20:12:46,339 - INFO - Model training completed in 1.99s
2024-12-27 20:12:46,345 - INFO - Prediction completed in 0.01s
2024-12-27 20:12:46,354 - INFO - Poison rate 0.01 completed in 3.85s
2024-12-27 20:12:46,354 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:12:46,355 - INFO - Total number of labels flipped: 149
2024-12-27 20:12:46,355 - INFO - Label flipping completed in 0.00s
2024-12-27 20:12:46,355 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:12:46,355 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:12:46,974 - INFO - Feature scaling completed in 0.62s
2024-12-27 20:12:46,974 - INFO - Starting feature selection (k=50)
2024-12-27 20:12:46,982 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:12:46,982 - INFO - Starting anomaly detection
2024-12-27 20:12:48,879 - INFO - Anomaly detection completed in 1.90s
2024-12-27 20:12:48,880 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:12:48,880 - INFO - Total fit_transform time: 2.52s
2024-12-27 20:12:48,880 - INFO - Training set processing completed in 2.53s
2024-12-27 20:12:48,880 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:12:48,881 - INFO - Memory usage at start_fit: CPU 3293.6 MB, GPU 49.3 MB
2024-12-27 20:12:48,882 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:12:48,882 - INFO - Number of unique classes: 100
2024-12-27 20:12:48,981 - INFO - Fitted scaler and transformed data
2024-12-27 20:12:48,981 - INFO - Scaling time: 0.10s
2024-12-27 20:12:49,190 - INFO - Epoch 1/25, Train Loss: 27.6093, Val Loss: 21.7313
2024-12-27 20:12:49,369 - INFO - Epoch 2/25, Train Loss: 4.2041, Val Loss: 20.4804
2024-12-27 20:12:49,552 - INFO - Epoch 3/25, Train Loss: 1.6073, Val Loss: 19.4926
2024-12-27 20:12:49,756 - INFO - Epoch 4/25, Train Loss: 0.7207, Val Loss: 19.6644
2024-12-27 20:12:49,935 - INFO - Epoch 5/25, Train Loss: 0.3789, Val Loss: 20.0546
2024-12-27 20:12:49,935 - INFO - Early stopping triggered at epoch 5
2024-12-27 20:12:49,935 - INFO - Training completed in 1.05s
2024-12-27 20:12:49,936 - INFO - Final memory usage: CPU 3293.6 MB, GPU 49.9 MB
2024-12-27 20:12:49,936 - INFO - Model training completed in 1.06s
2024-12-27 20:12:49,944 - INFO - Prediction completed in 0.01s
2024-12-27 20:12:49,953 - INFO - Poison rate 0.03 completed in 3.60s
2024-12-27 20:12:49,953 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:12:49,954 - INFO - Total number of labels flipped: 247
2024-12-27 20:12:49,954 - INFO - Label flipping completed in 0.00s
2024-12-27 20:12:49,954 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:12:49,954 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:12:50,531 - INFO - Feature scaling completed in 0.58s
2024-12-27 20:12:50,532 - INFO - Starting feature selection (k=50)
2024-12-27 20:12:50,545 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:12:50,545 - INFO - Starting anomaly detection
2024-12-27 20:12:52,509 - INFO - Anomaly detection completed in 1.96s
2024-12-27 20:12:52,509 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:12:52,509 - INFO - Total fit_transform time: 2.56s
2024-12-27 20:12:52,509 - INFO - Training set processing completed in 2.56s
2024-12-27 20:12:52,509 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:12:52,510 - INFO - Memory usage at start_fit: CPU 3293.6 MB, GPU 49.3 MB
2024-12-27 20:12:52,511 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:12:52,511 - INFO - Number of unique classes: 100
2024-12-27 20:12:52,605 - INFO - Fitted scaler and transformed data
2024-12-27 20:12:52,605 - INFO - Scaling time: 0.09s
2024-12-27 20:12:52,810 - INFO - Epoch 1/25, Train Loss: 30.0016, Val Loss: 34.4742
2024-12-27 20:12:52,985 - INFO - Epoch 2/25, Train Loss: 6.7729, Val Loss: 31.4932
2024-12-27 20:12:53,196 - INFO - Epoch 3/25, Train Loss: 2.6852, Val Loss: 31.6312
2024-12-27 20:12:53,374 - INFO - Epoch 4/25, Train Loss: 1.1599, Val Loss: 31.7283
2024-12-27 20:12:53,374 - INFO - Early stopping triggered at epoch 4
2024-12-27 20:12:53,375 - INFO - Training completed in 0.86s
2024-12-27 20:12:53,375 - INFO - Final memory usage: CPU 3293.6 MB, GPU 49.9 MB
2024-12-27 20:12:53,375 - INFO - Model training completed in 0.87s
2024-12-27 20:12:53,383 - INFO - Prediction completed in 0.01s
2024-12-27 20:12:53,392 - INFO - Poison rate 0.05 completed in 3.44s
2024-12-27 20:12:53,392 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:12:53,393 - INFO - Total number of labels flipped: 347
2024-12-27 20:12:53,393 - INFO - Label flipping completed in 0.00s
2024-12-27 20:12:53,393 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:12:53,393 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:12:54,036 - INFO - Feature scaling completed in 0.64s
2024-12-27 20:12:54,036 - INFO - Starting feature selection (k=50)
2024-12-27 20:12:54,051 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:12:54,051 - INFO - Starting anomaly detection
2024-12-27 20:12:56,145 - INFO - Anomaly detection completed in 2.09s
2024-12-27 20:12:56,145 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:12:56,145 - INFO - Total fit_transform time: 2.75s
2024-12-27 20:12:56,145 - INFO - Training set processing completed in 2.75s
2024-12-27 20:12:56,146 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:12:56,146 - INFO - Memory usage at start_fit: CPU 3293.6 MB, GPU 49.3 MB
2024-12-27 20:12:56,147 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:12:56,147 - INFO - Number of unique classes: 100
2024-12-27 20:12:56,240 - INFO - Fitted scaler and transformed data
2024-12-27 20:12:56,241 - INFO - Scaling time: 0.09s
2024-12-27 20:12:56,475 - INFO - Epoch 1/25, Train Loss: 35.2792, Val Loss: 34.1921
2024-12-27 20:12:56,663 - INFO - Epoch 2/25, Train Loss: 10.0955, Val Loss: 35.8618
2024-12-27 20:12:56,878 - INFO - Epoch 3/25, Train Loss: 4.2064, Val Loss: 34.4947
2024-12-27 20:12:56,879 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:12:56,879 - INFO - Training completed in 0.73s
2024-12-27 20:12:56,879 - INFO - Final memory usage: CPU 3293.6 MB, GPU 49.9 MB
2024-12-27 20:12:56,879 - INFO - Model training completed in 0.73s
2024-12-27 20:12:56,894 - INFO - Prediction completed in 0.01s
2024-12-27 20:12:56,910 - INFO - Poison rate 0.07 completed in 3.52s
2024-12-27 20:12:56,910 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:12:56,911 - INFO - Total number of labels flipped: 498
2024-12-27 20:12:56,911 - INFO - Label flipping completed in 0.00s
2024-12-27 20:12:56,911 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:12:56,911 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:12:57,518 - INFO - Feature scaling completed in 0.61s
2024-12-27 20:12:57,519 - INFO - Starting feature selection (k=50)
2024-12-27 20:12:57,534 - INFO - Feature selection completed in 0.02s. Output shape: (5000, 50)
2024-12-27 20:12:57,535 - INFO - Starting anomaly detection
2024-12-27 20:12:59,136 - INFO - Anomaly detection completed in 1.60s
2024-12-27 20:12:59,137 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:12:59,137 - INFO - Total fit_transform time: 2.23s
2024-12-27 20:12:59,137 - INFO - Training set processing completed in 2.23s
2024-12-27 20:12:59,137 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:12:59,138 - INFO - Memory usage at start_fit: CPU 3293.6 MB, GPU 49.3 MB
2024-12-27 20:12:59,138 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:12:59,138 - INFO - Number of unique classes: 100
2024-12-27 20:12:59,232 - INFO - Fitted scaler and transformed data
2024-12-27 20:12:59,232 - INFO - Scaling time: 0.09s
2024-12-27 20:12:59,411 - INFO - Epoch 1/25, Train Loss: 40.7966, Val Loss: 37.7790
2024-12-27 20:12:59,578 - INFO - Epoch 2/25, Train Loss: 13.8047, Val Loss: 39.3488
2024-12-27 20:12:59,748 - INFO - Epoch 3/25, Train Loss: 6.5685, Val Loss: 38.5371
2024-12-27 20:12:59,748 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:12:59,749 - INFO - Training completed in 0.61s
2024-12-27 20:12:59,749 - INFO - Final memory usage: CPU 3293.6 MB, GPU 49.9 MB
2024-12-27 20:12:59,749 - INFO - Model training completed in 0.61s
2024-12-27 20:12:59,763 - INFO - Prediction completed in 0.01s
2024-12-27 20:12:59,778 - INFO - Poison rate 0.1 completed in 2.87s
2024-12-27 20:12:59,778 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:12:59,779 - INFO - Total number of labels flipped: 996
2024-12-27 20:12:59,779 - INFO - Label flipping completed in 0.00s
2024-12-27 20:12:59,779 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:12:59,779 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:13:00,343 - INFO - Feature scaling completed in 0.56s
2024-12-27 20:13:00,344 - INFO - Starting feature selection (k=50)
2024-12-27 20:13:00,349 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:13:00,349 - INFO - Starting anomaly detection
2024-12-27 20:13:01,921 - INFO - Anomaly detection completed in 1.57s
2024-12-27 20:13:01,921 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:13:01,922 - INFO - Total fit_transform time: 2.14s
2024-12-27 20:13:01,922 - INFO - Training set processing completed in 2.14s
2024-12-27 20:13:01,922 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:13:01,922 - INFO - Memory usage at start_fit: CPU 3293.6 MB, GPU 49.3 MB
2024-12-27 20:13:01,922 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:13:01,923 - INFO - Number of unique classes: 100
2024-12-27 20:13:02,017 - INFO - Fitted scaler and transformed data
2024-12-27 20:13:02,018 - INFO - Scaling time: 0.09s
2024-12-27 20:13:02,211 - INFO - Epoch 1/25, Train Loss: 57.2692, Val Loss: 62.1804
2024-12-27 20:13:02,384 - INFO - Epoch 2/25, Train Loss: 26.2007, Val Loss: 53.6132
2024-12-27 20:13:02,565 - INFO - Epoch 3/25, Train Loss: 13.3520, Val Loss: 51.2462
2024-12-27 20:13:02,741 - INFO - Epoch 4/25, Train Loss: 7.2759, Val Loss: 50.7843
2024-12-27 20:13:02,948 - INFO - Epoch 5/25, Train Loss: 3.4154, Val Loss: 47.9369
2024-12-27 20:13:03,123 - INFO - Epoch 6/25, Train Loss: 1.8916, Val Loss: 48.8220
2024-12-27 20:13:03,317 - INFO - Epoch 7/25, Train Loss: 1.2424, Val Loss: 45.9036
2024-12-27 20:13:03,498 - INFO - Epoch 8/25, Train Loss: 0.9962, Val Loss: 46.9490
2024-12-27 20:13:03,694 - INFO - Epoch 9/25, Train Loss: 0.6192, Val Loss: 49.2723
2024-12-27 20:13:03,694 - INFO - Early stopping triggered at epoch 9
2024-12-27 20:13:03,694 - INFO - Training completed in 1.77s
2024-12-27 20:13:03,694 - INFO - Final memory usage: CPU 3293.6 MB, GPU 49.9 MB
2024-12-27 20:13:03,694 - INFO - Model training completed in 1.77s
2024-12-27 20:13:03,703 - INFO - Prediction completed in 0.01s
2024-12-27 20:13:03,714 - INFO - Poison rate 0.2 completed in 3.94s
2024-12-27 20:13:03,717 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:13:03,717 - INFO - Total evaluation time: 32.79s
2024-12-27 20:13:03,718 - INFO - 
Progress: 44.8% - Evaluating CIFAR100 with LogisticRegression (standard mode, iteration 1/1)
2024-12-27 20:13:03,778 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:13:03,852 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:13:03,929 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:13:03,929 - INFO - Dataset type: image
2024-12-27 20:13:03,929 - INFO - Sample size: 5000
2024-12-27 20:13:03,930 - INFO - Using device: cuda
2024-12-27 20:13:03,932 - INFO - Loading datasets...
2024-12-27 20:13:05,407 - INFO - Dataset loading completed in 1.47s
2024-12-27 20:13:05,407 - INFO - Extracting validation features...
2024-12-27 20:13:05,407 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:16,  1.85it/s]Extracting features:  12%|█▎        | 4/32 [00:00<00:03,  7.68it/s]Extracting features:  31%|███▏      | 10/32 [00:00<00:01, 19.24it/s]Extracting features:  47%|████▋     | 15/32 [00:00<00:00, 26.53it/s]Extracting features:  66%|██████▌   | 21/32 [00:00<00:00, 33.62it/s]Extracting features:  84%|████████▍ | 27/32 [00:01<00:00, 39.52it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 26.56it/s]
2024-12-27 20:13:06,618 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:13:06,619 - INFO - Validation feature extraction completed in 1.21s
2024-12-27 20:13:06,619 - INFO - Extracting training features...
2024-12-27 20:13:06,620 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:42,  3.66it/s]Extracting features:   4%|▍         | 7/157 [00:00<00:06, 22.58it/s]Extracting features:   8%|▊         | 13/157 [00:00<00:04, 34.63it/s]Extracting features:  12%|█▏        | 19/157 [00:00<00:03, 41.24it/s]Extracting features:  16%|█▌        | 25/157 [00:00<00:03, 43.03it/s]Extracting features:  20%|█▉        | 31/157 [00:00<00:02, 46.05it/s]Extracting features:  24%|██▎       | 37/157 [00:00<00:02, 47.24it/s]Extracting features:  27%|██▋       | 43/157 [00:01<00:02, 47.61it/s]Extracting features:  31%|███       | 48/157 [00:01<00:02, 47.99it/s]Extracting features:  34%|███▍      | 54/157 [00:01<00:02, 50.41it/s]Extracting features:  38%|███▊      | 60/157 [00:01<00:01, 52.94it/s]Extracting features:  42%|████▏     | 66/157 [00:01<00:01, 53.98it/s]Extracting features:  46%|████▌     | 72/157 [00:01<00:01, 54.79it/s]Extracting features:  50%|████▉     | 78/157 [00:01<00:01, 55.52it/s]Extracting features:  54%|█████▎    | 84/157 [00:01<00:01, 54.59it/s]Extracting features:  57%|█████▋    | 90/157 [00:01<00:01, 54.35it/s]Extracting features:  61%|██████    | 96/157 [00:02<00:01, 54.67it/s]Extracting features:  65%|██████▍   | 102/157 [00:02<00:00, 55.11it/s]Extracting features:  69%|██████▉   | 108/157 [00:02<00:00, 55.76it/s]Extracting features:  73%|███████▎  | 114/157 [00:02<00:00, 56.67it/s]Extracting features:  76%|███████▋  | 120/157 [00:02<00:00, 54.94it/s]Extracting features:  81%|████████  | 127/157 [00:02<00:00, 57.28it/s]Extracting features:  85%|████████▍ | 133/157 [00:02<00:00, 54.04it/s]Extracting features:  89%|████████▊ | 139/157 [00:02<00:00, 54.32it/s]Extracting features:  92%|█████████▏| 145/157 [00:02<00:00, 55.09it/s]Extracting features:  97%|█████████▋| 152/157 [00:03<00:00, 57.30it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 48.48it/s]
2024-12-27 20:13:09,874 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:13:09,874 - INFO - Training feature extraction completed in 3.25s
2024-12-27 20:13:09,874 - INFO - Creating model for classifier: LogisticRegression
2024-12-27 20:13:09,875 - INFO - Using device: cuda
2024-12-27 20:13:09,875 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:13:09,875 - INFO - Training set processing completed in 0.00s
2024-12-27 20:13:09,875 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:13:09,877 - INFO - Memory usage at start_fit: CPU 3266.5 MB, GPU 47.3 MB
2024-12-27 20:13:09,877 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:13:09,878 - INFO - Number of unique classes: 100
2024-12-27 20:13:09,976 - INFO - Fitted scaler and transformed data
2024-12-27 20:13:09,977 - INFO - Scaling time: 0.09s
2024-12-27 20:13:10,115 - INFO - Epoch 1/200, Train Loss: 2.7145, Val Loss: 2.7450
2024-12-27 20:13:10,248 - INFO - Epoch 2/200, Train Loss: 0.5137, Val Loss: 2.8376
2024-12-27 20:13:10,378 - INFO - Epoch 3/200, Train Loss: 0.1816, Val Loss: 2.7724
2024-12-27 20:13:10,379 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:13:10,379 - INFO - Training completed in 0.50s
2024-12-27 20:13:10,380 - INFO - Final memory usage: CPU 3293.8 MB, GPU 49.9 MB
2024-12-27 20:13:10,381 - INFO - Model training completed in 0.51s
2024-12-27 20:13:10,396 - INFO - Prediction completed in 0.01s
2024-12-27 20:13:10,409 - INFO - Poison rate 0.0 completed in 0.53s
2024-12-27 20:13:10,409 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:13:10,410 - INFO - Total number of labels flipped: 50
2024-12-27 20:13:10,410 - INFO - Label flipping completed in 0.00s
2024-12-27 20:13:10,410 - INFO - Training set processing completed in 0.00s
2024-12-27 20:13:10,410 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:13:10,411 - INFO - Memory usage at start_fit: CPU 3293.8 MB, GPU 49.3 MB
2024-12-27 20:13:10,411 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:13:10,411 - INFO - Number of unique classes: 100
2024-12-27 20:13:10,495 - INFO - Fitted scaler and transformed data
2024-12-27 20:13:10,495 - INFO - Scaling time: 0.08s
2024-12-27 20:13:10,645 - INFO - Epoch 1/200, Train Loss: 2.7817, Val Loss: 2.3448
2024-12-27 20:13:10,756 - INFO - Epoch 2/200, Train Loss: 0.5506, Val Loss: 2.4673
2024-12-27 20:13:10,865 - INFO - Epoch 3/200, Train Loss: 0.1732, Val Loss: 2.5336
2024-12-27 20:13:10,865 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:13:10,866 - INFO - Training completed in 0.46s
2024-12-27 20:13:10,866 - INFO - Final memory usage: CPU 3293.8 MB, GPU 49.9 MB
2024-12-27 20:13:10,867 - INFO - Model training completed in 0.46s
2024-12-27 20:13:10,874 - INFO - Prediction completed in 0.01s
2024-12-27 20:13:10,887 - INFO - Poison rate 0.01 completed in 0.48s
2024-12-27 20:13:10,887 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:13:10,889 - INFO - Total number of labels flipped: 145
2024-12-27 20:13:10,889 - INFO - Label flipping completed in 0.00s
2024-12-27 20:13:10,889 - INFO - Training set processing completed in 0.00s
2024-12-27 20:13:10,889 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:13:10,891 - INFO - Memory usage at start_fit: CPU 3293.8 MB, GPU 49.3 MB
2024-12-27 20:13:10,891 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:13:10,892 - INFO - Number of unique classes: 100
2024-12-27 20:13:10,996 - INFO - Fitted scaler and transformed data
2024-12-27 20:13:10,996 - INFO - Scaling time: 0.10s
2024-12-27 20:13:11,136 - INFO - Epoch 1/200, Train Loss: 2.9694, Val Loss: 2.5665
2024-12-27 20:13:11,270 - INFO - Epoch 2/200, Train Loss: 0.7335, Val Loss: 2.7618
2024-12-27 20:13:11,377 - INFO - Epoch 3/200, Train Loss: 0.3098, Val Loss: 2.7873
2024-12-27 20:13:11,377 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:13:11,377 - INFO - Training completed in 0.49s
2024-12-27 20:13:11,377 - INFO - Final memory usage: CPU 3293.8 MB, GPU 49.9 MB
2024-12-27 20:13:11,378 - INFO - Model training completed in 0.49s
2024-12-27 20:13:11,384 - INFO - Prediction completed in 0.01s
2024-12-27 20:13:11,400 - INFO - Poison rate 0.03 completed in 0.51s
2024-12-27 20:13:11,400 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:13:11,402 - INFO - Total number of labels flipped: 244
2024-12-27 20:13:11,402 - INFO - Label flipping completed in 0.00s
2024-12-27 20:13:11,402 - INFO - Training set processing completed in 0.00s
2024-12-27 20:13:11,402 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:13:11,403 - INFO - Memory usage at start_fit: CPU 3293.8 MB, GPU 49.3 MB
2024-12-27 20:13:11,404 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:13:11,405 - INFO - Number of unique classes: 100
2024-12-27 20:13:11,493 - INFO - Fitted scaler and transformed data
2024-12-27 20:13:11,494 - INFO - Scaling time: 0.09s
2024-12-27 20:13:11,639 - INFO - Epoch 1/200, Train Loss: 3.1014, Val Loss: 3.3493
2024-12-27 20:13:11,758 - INFO - Epoch 2/200, Train Loss: 0.8917, Val Loss: 3.5294
2024-12-27 20:13:11,866 - INFO - Epoch 3/200, Train Loss: 0.4146, Val Loss: 3.4931
2024-12-27 20:13:11,866 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:13:11,866 - INFO - Training completed in 0.46s
2024-12-27 20:13:11,867 - INFO - Final memory usage: CPU 3293.8 MB, GPU 49.9 MB
2024-12-27 20:13:11,868 - INFO - Model training completed in 0.47s
2024-12-27 20:13:11,874 - INFO - Prediction completed in 0.01s
2024-12-27 20:13:11,897 - INFO - Poison rate 0.05 completed in 0.50s
2024-12-27 20:13:11,898 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:13:11,899 - INFO - Total number of labels flipped: 347
2024-12-27 20:13:11,900 - INFO - Label flipping completed in 0.00s
2024-12-27 20:13:11,900 - INFO - Training set processing completed in 0.00s
2024-12-27 20:13:11,900 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:13:11,901 - INFO - Memory usage at start_fit: CPU 3293.8 MB, GPU 49.3 MB
2024-12-27 20:13:11,902 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:13:11,902 - INFO - Number of unique classes: 100
2024-12-27 20:13:11,986 - INFO - Fitted scaler and transformed data
2024-12-27 20:13:11,987 - INFO - Scaling time: 0.08s
2024-12-27 20:13:12,121 - INFO - Epoch 1/200, Train Loss: 3.2199, Val Loss: 3.6945
2024-12-27 20:13:12,235 - INFO - Epoch 2/200, Train Loss: 1.0748, Val Loss: 3.8561
2024-12-27 20:13:12,344 - INFO - Epoch 3/200, Train Loss: 0.5222, Val Loss: 3.9667
2024-12-27 20:13:12,345 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:13:12,345 - INFO - Training completed in 0.44s
2024-12-27 20:13:12,345 - INFO - Final memory usage: CPU 3293.8 MB, GPU 49.9 MB
2024-12-27 20:13:12,345 - INFO - Model training completed in 0.45s
2024-12-27 20:13:12,353 - INFO - Prediction completed in 0.01s
2024-12-27 20:13:12,368 - INFO - Poison rate 0.07 completed in 0.47s
2024-12-27 20:13:12,368 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:13:12,370 - INFO - Total number of labels flipped: 495
2024-12-27 20:13:12,370 - INFO - Label flipping completed in 0.00s
2024-12-27 20:13:12,371 - INFO - Training set processing completed in 0.00s
2024-12-27 20:13:12,371 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:13:12,372 - INFO - Memory usage at start_fit: CPU 3293.8 MB, GPU 49.3 MB
2024-12-27 20:13:12,372 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:13:12,373 - INFO - Number of unique classes: 100
2024-12-27 20:13:12,471 - INFO - Fitted scaler and transformed data
2024-12-27 20:13:12,471 - INFO - Scaling time: 0.09s
2024-12-27 20:13:12,604 - INFO - Epoch 1/200, Train Loss: 3.5262, Val Loss: 3.5314
2024-12-27 20:13:12,721 - INFO - Epoch 2/200, Train Loss: 1.3091, Val Loss: 3.7130
2024-12-27 20:13:12,854 - INFO - Epoch 3/200, Train Loss: 0.7133, Val Loss: 3.5674
2024-12-27 20:13:12,854 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:13:12,854 - INFO - Training completed in 0.48s
2024-12-27 20:13:12,855 - INFO - Final memory usage: CPU 3293.8 MB, GPU 49.9 MB
2024-12-27 20:13:12,855 - INFO - Model training completed in 0.48s
2024-12-27 20:13:12,868 - INFO - Prediction completed in 0.01s
2024-12-27 20:13:12,893 - INFO - Poison rate 0.1 completed in 0.52s
2024-12-27 20:13:12,893 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:13:12,895 - INFO - Total number of labels flipped: 985
2024-12-27 20:13:12,895 - INFO - Label flipping completed in 0.00s
2024-12-27 20:13:12,895 - INFO - Training set processing completed in 0.00s
2024-12-27 20:13:12,896 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:13:12,897 - INFO - Memory usage at start_fit: CPU 3293.8 MB, GPU 49.3 MB
2024-12-27 20:13:12,897 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:13:12,898 - INFO - Number of unique classes: 100
2024-12-27 20:13:12,988 - INFO - Fitted scaler and transformed data
2024-12-27 20:13:12,988 - INFO - Scaling time: 0.09s
2024-12-27 20:13:13,122 - INFO - Epoch 1/200, Train Loss: 4.2508, Val Loss: 4.2025
2024-12-27 20:13:13,245 - INFO - Epoch 2/200, Train Loss: 1.9935, Val Loss: 4.1279
2024-12-27 20:13:13,393 - INFO - Epoch 3/200, Train Loss: 1.1827, Val Loss: 3.9401
2024-12-27 20:13:13,525 - INFO - Epoch 4/200, Train Loss: 0.8104, Val Loss: 3.9201
2024-12-27 20:13:13,659 - INFO - Epoch 5/200, Train Loss: 0.5958, Val Loss: 3.6955
2024-12-27 20:13:13,775 - INFO - Epoch 6/200, Train Loss: 0.4566, Val Loss: 3.6440
2024-12-27 20:13:13,910 - INFO - Epoch 7/200, Train Loss: 0.3652, Val Loss: 3.6335
2024-12-27 20:13:14,056 - INFO - Epoch 8/200, Train Loss: 0.3057, Val Loss: 3.5843
2024-12-27 20:13:14,199 - INFO - Epoch 9/200, Train Loss: 0.2601, Val Loss: 3.6213
2024-12-27 20:13:14,336 - INFO - Epoch 10/200, Train Loss: 0.2414, Val Loss: 3.6338
2024-12-27 20:13:14,337 - INFO - Early stopping triggered at epoch 10
2024-12-27 20:13:14,337 - INFO - Training completed in 1.44s
2024-12-27 20:13:14,337 - INFO - Final memory usage: CPU 3293.8 MB, GPU 49.9 MB
2024-12-27 20:13:14,337 - INFO - Model training completed in 1.44s
2024-12-27 20:13:14,346 - INFO - Prediction completed in 0.01s
2024-12-27 20:13:14,370 - INFO - Poison rate 0.2 completed in 1.48s
2024-12-27 20:13:14,375 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:13:14,376 - INFO - Total evaluation time: 10.44s
2024-12-27 20:13:14,378 - INFO - 
Progress: 45.8% - Evaluating CIFAR100 with LogisticRegression (dynadetect mode, iteration 1/1)
2024-12-27 20:13:14,467 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:13:14,565 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:13:14,639 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:13:14,639 - INFO - Dataset type: image
2024-12-27 20:13:14,639 - INFO - Sample size: 5000
2024-12-27 20:13:14,639 - INFO - Using device: cuda
2024-12-27 20:13:14,641 - INFO - Loading datasets...
2024-12-27 20:13:15,935 - INFO - Dataset loading completed in 1.29s
2024-12-27 20:13:15,936 - INFO - Extracting validation features...
2024-12-27 20:13:15,936 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:12,  2.50it/s]Extracting features:  16%|█▌        | 5/32 [00:00<00:02, 11.50it/s]Extracting features:  31%|███▏      | 10/32 [00:00<00:01, 20.74it/s]Extracting features:  53%|█████▎    | 17/32 [00:00<00:00, 32.33it/s]Extracting features:  72%|███████▏  | 23/32 [00:00<00:00, 39.56it/s]Extracting features:  94%|█████████▍| 30/32 [00:00<00:00, 47.49it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 30.55it/s]
2024-12-27 20:13:16,990 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:13:16,991 - INFO - Validation feature extraction completed in 1.05s
2024-12-27 20:13:16,991 - INFO - Extracting training features...
2024-12-27 20:13:16,991 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:42,  3.64it/s]Extracting features:   4%|▍         | 7/157 [00:00<00:06, 22.57it/s]Extracting features:   8%|▊         | 13/157 [00:00<00:04, 33.98it/s]Extracting features:  11%|█▏        | 18/157 [00:00<00:03, 37.97it/s]Extracting features:  15%|█▍        | 23/157 [00:00<00:03, 40.65it/s]Extracting features:  18%|█▊        | 29/157 [00:00<00:02, 45.94it/s]Extracting features:  22%|██▏       | 35/157 [00:00<00:02, 49.96it/s]Extracting features:  26%|██▌       | 41/157 [00:01<00:02, 52.60it/s]Extracting features:  30%|██▉       | 47/157 [00:01<00:02, 54.16it/s]Extracting features:  34%|███▍      | 53/157 [00:01<00:01, 53.59it/s]Extracting features:  38%|███▊      | 60/157 [00:01<00:01, 55.53it/s]Extracting features:  42%|████▏     | 66/157 [00:01<00:01, 56.24it/s]Extracting features:  46%|████▋     | 73/157 [00:01<00:01, 57.82it/s]Extracting features:  50%|█████     | 79/157 [00:01<00:01, 53.31it/s]Extracting features:  54%|█████▍    | 85/157 [00:01<00:01, 54.24it/s]Extracting features:  58%|█████▊    | 91/157 [00:01<00:01, 55.56it/s]Extracting features:  62%|██████▏   | 97/157 [00:02<00:01, 56.39it/s]Extracting features:  66%|██████▌   | 104/157 [00:02<00:00, 56.64it/s]Extracting features:  70%|███████   | 110/157 [00:02<00:00, 56.55it/s]Extracting features:  74%|███████▍  | 116/157 [00:02<00:00, 56.69it/s]Extracting features:  78%|███████▊  | 122/157 [00:02<00:00, 56.06it/s]Extracting features:  82%|████████▏ | 129/157 [00:02<00:00, 57.36it/s]Extracting features:  86%|████████▌ | 135/157 [00:02<00:00, 55.34it/s]Extracting features:  90%|████████▉ | 141/157 [00:02<00:00, 56.07it/s]Extracting features:  94%|█████████▎| 147/157 [00:02<00:00, 55.19it/s]Extracting features:  97%|█████████▋| 153/157 [00:03<00:00, 51.73it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 49.10it/s]
2024-12-27 20:13:20,202 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:13:20,203 - INFO - Training feature extraction completed in 3.21s
2024-12-27 20:13:20,203 - INFO - Creating model for classifier: LogisticRegression
2024-12-27 20:13:20,203 - INFO - Using device: cuda
2024-12-27 20:13:20,203 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:13:20,203 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:13:20,203 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:13:20,826 - INFO - Feature scaling completed in 0.62s
2024-12-27 20:13:20,827 - INFO - Starting feature selection (k=50)
2024-12-27 20:13:20,834 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:13:20,834 - INFO - Starting anomaly detection
2024-12-27 20:13:23,018 - INFO - Anomaly detection completed in 2.18s
2024-12-27 20:13:23,018 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:13:23,018 - INFO - Total fit_transform time: 2.81s
2024-12-27 20:13:23,018 - INFO - Training set processing completed in 2.82s
2024-12-27 20:13:23,018 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:13:23,019 - INFO - Memory usage at start_fit: CPU 3294.5 MB, GPU 47.3 MB
2024-12-27 20:13:23,019 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:13:23,020 - INFO - Number of unique classes: 100
2024-12-27 20:13:23,122 - INFO - Fitted scaler and transformed data
2024-12-27 20:13:23,123 - INFO - Scaling time: 0.10s
2024-12-27 20:13:23,255 - INFO - Epoch 1/200, Train Loss: 2.6266, Val Loss: 2.5823
2024-12-27 20:13:23,380 - INFO - Epoch 2/200, Train Loss: 0.5427, Val Loss: 2.6688
2024-12-27 20:13:23,494 - INFO - Epoch 3/200, Train Loss: 0.2486, Val Loss: 2.7476
2024-12-27 20:13:23,495 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:13:23,495 - INFO - Training completed in 0.48s
2024-12-27 20:13:23,496 - INFO - Final memory usage: CPU 3294.5 MB, GPU 49.9 MB
2024-12-27 20:13:23,496 - INFO - Model training completed in 0.48s
2024-12-27 20:13:23,512 - INFO - Prediction completed in 0.01s
2024-12-27 20:13:23,532 - INFO - Poison rate 0.0 completed in 3.33s
2024-12-27 20:13:23,533 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:13:23,534 - INFO - Total number of labels flipped: 50
2024-12-27 20:13:23,534 - INFO - Label flipping completed in 0.00s
2024-12-27 20:13:23,534 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:13:23,534 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:13:24,123 - INFO - Feature scaling completed in 0.59s
2024-12-27 20:13:24,124 - INFO - Starting feature selection (k=50)
2024-12-27 20:13:24,132 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:13:24,132 - INFO - Starting anomaly detection
2024-12-27 20:13:26,143 - INFO - Anomaly detection completed in 2.01s
2024-12-27 20:13:26,144 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:13:26,144 - INFO - Total fit_transform time: 2.61s
2024-12-27 20:13:26,144 - INFO - Training set processing completed in 2.61s
2024-12-27 20:13:26,144 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:13:26,145 - INFO - Memory usage at start_fit: CPU 3294.5 MB, GPU 49.3 MB
2024-12-27 20:13:26,146 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:13:26,147 - INFO - Number of unique classes: 100
2024-12-27 20:13:26,264 - INFO - Fitted scaler and transformed data
2024-12-27 20:13:26,265 - INFO - Scaling time: 0.11s
2024-12-27 20:13:26,418 - INFO - Epoch 1/200, Train Loss: 2.8356, Val Loss: 2.6083
2024-12-27 20:13:26,540 - INFO - Epoch 2/200, Train Loss: 0.5707, Val Loss: 2.6969
2024-12-27 20:13:26,680 - INFO - Epoch 3/200, Train Loss: 0.2331, Val Loss: 2.8871
2024-12-27 20:13:26,681 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:13:26,681 - INFO - Training completed in 0.54s
2024-12-27 20:13:26,682 - INFO - Final memory usage: CPU 3294.5 MB, GPU 49.9 MB
2024-12-27 20:13:26,682 - INFO - Model training completed in 0.54s
2024-12-27 20:13:26,695 - INFO - Prediction completed in 0.01s
2024-12-27 20:13:26,709 - INFO - Poison rate 0.01 completed in 3.18s
2024-12-27 20:13:26,709 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:13:26,710 - INFO - Total number of labels flipped: 150
2024-12-27 20:13:26,711 - INFO - Label flipping completed in 0.00s
2024-12-27 20:13:26,711 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:13:26,711 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:13:27,308 - INFO - Feature scaling completed in 0.60s
2024-12-27 20:13:27,308 - INFO - Starting feature selection (k=50)
2024-12-27 20:13:27,317 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:13:27,317 - INFO - Starting anomaly detection
2024-12-27 20:13:29,058 - INFO - Anomaly detection completed in 1.74s
2024-12-27 20:13:29,059 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:13:29,059 - INFO - Total fit_transform time: 2.35s
2024-12-27 20:13:29,059 - INFO - Training set processing completed in 2.35s
2024-12-27 20:13:29,059 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:13:29,060 - INFO - Memory usage at start_fit: CPU 3294.5 MB, GPU 49.3 MB
2024-12-27 20:13:29,060 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:13:29,060 - INFO - Number of unique classes: 100
2024-12-27 20:13:29,153 - INFO - Fitted scaler and transformed data
2024-12-27 20:13:29,154 - INFO - Scaling time: 0.09s
2024-12-27 20:13:29,275 - INFO - Epoch 1/200, Train Loss: 2.9775, Val Loss: 2.4633
2024-12-27 20:13:29,385 - INFO - Epoch 2/200, Train Loss: 0.7439, Val Loss: 2.8514
2024-12-27 20:13:29,515 - INFO - Epoch 3/200, Train Loss: 0.3416, Val Loss: 2.8264
2024-12-27 20:13:29,515 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:13:29,515 - INFO - Training completed in 0.46s
2024-12-27 20:13:29,515 - INFO - Final memory usage: CPU 3294.5 MB, GPU 49.9 MB
2024-12-27 20:13:29,516 - INFO - Model training completed in 0.46s
2024-12-27 20:13:29,524 - INFO - Prediction completed in 0.01s
2024-12-27 20:13:29,539 - INFO - Poison rate 0.03 completed in 2.83s
2024-12-27 20:13:29,539 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:13:29,539 - INFO - Total number of labels flipped: 248
2024-12-27 20:13:29,540 - INFO - Label flipping completed in 0.00s
2024-12-27 20:13:29,540 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:13:29,540 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:13:30,162 - INFO - Feature scaling completed in 0.62s
2024-12-27 20:13:30,162 - INFO - Starting feature selection (k=50)
2024-12-27 20:13:30,170 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:13:30,170 - INFO - Starting anomaly detection
2024-12-27 20:13:31,776 - INFO - Anomaly detection completed in 1.60s
2024-12-27 20:13:31,776 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:13:31,776 - INFO - Total fit_transform time: 2.24s
2024-12-27 20:13:31,776 - INFO - Training set processing completed in 2.24s
2024-12-27 20:13:31,776 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:13:31,777 - INFO - Memory usage at start_fit: CPU 3294.5 MB, GPU 49.3 MB
2024-12-27 20:13:31,777 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:13:31,777 - INFO - Number of unique classes: 100
2024-12-27 20:13:31,901 - INFO - Fitted scaler and transformed data
2024-12-27 20:13:31,901 - INFO - Scaling time: 0.12s
2024-12-27 20:13:32,068 - INFO - Epoch 1/200, Train Loss: 3.1139, Val Loss: 3.3647
2024-12-27 20:13:32,261 - INFO - Epoch 2/200, Train Loss: 0.9540, Val Loss: 3.4479
2024-12-27 20:13:32,378 - INFO - Epoch 3/200, Train Loss: 0.4422, Val Loss: 3.5143
2024-12-27 20:13:32,378 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:13:32,378 - INFO - Training completed in 0.60s
2024-12-27 20:13:32,379 - INFO - Final memory usage: CPU 3294.5 MB, GPU 49.9 MB
2024-12-27 20:13:32,380 - INFO - Model training completed in 0.60s
2024-12-27 20:13:32,394 - INFO - Prediction completed in 0.01s
2024-12-27 20:13:32,411 - INFO - Poison rate 0.05 completed in 2.87s
2024-12-27 20:13:32,412 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:13:32,413 - INFO - Total number of labels flipped: 344
2024-12-27 20:13:32,413 - INFO - Label flipping completed in 0.00s
2024-12-27 20:13:32,413 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:13:32,413 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:13:33,024 - INFO - Feature scaling completed in 0.61s
2024-12-27 20:13:33,024 - INFO - Starting feature selection (k=50)
2024-12-27 20:13:33,033 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:13:33,033 - INFO - Starting anomaly detection
2024-12-27 20:13:34,094 - INFO - Anomaly detection completed in 1.06s
2024-12-27 20:13:34,095 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:13:34,095 - INFO - Total fit_transform time: 1.68s
2024-12-27 20:13:34,095 - INFO - Training set processing completed in 1.68s
2024-12-27 20:13:34,095 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:13:34,096 - INFO - Memory usage at start_fit: CPU 3294.5 MB, GPU 49.3 MB
2024-12-27 20:13:34,096 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:13:34,096 - INFO - Number of unique classes: 100
2024-12-27 20:13:34,190 - INFO - Fitted scaler and transformed data
2024-12-27 20:13:34,190 - INFO - Scaling time: 0.09s
2024-12-27 20:13:34,342 - INFO - Epoch 1/200, Train Loss: 3.2791, Val Loss: 3.7770
2024-12-27 20:13:34,486 - INFO - Epoch 2/200, Train Loss: 1.0965, Val Loss: 3.7933
2024-12-27 20:13:34,644 - INFO - Epoch 3/200, Train Loss: 0.4946, Val Loss: 3.9292
2024-12-27 20:13:34,645 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:13:34,645 - INFO - Training completed in 0.55s
2024-12-27 20:13:34,646 - INFO - Final memory usage: CPU 3294.5 MB, GPU 49.9 MB
2024-12-27 20:13:34,646 - INFO - Model training completed in 0.55s
2024-12-27 20:13:34,661 - INFO - Prediction completed in 0.01s
2024-12-27 20:13:34,680 - INFO - Poison rate 0.07 completed in 2.27s
2024-12-27 20:13:34,680 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:13:34,682 - INFO - Total number of labels flipped: 497
2024-12-27 20:13:34,682 - INFO - Label flipping completed in 0.00s
2024-12-27 20:13:34,682 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:13:34,682 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:13:35,329 - INFO - Feature scaling completed in 0.65s
2024-12-27 20:13:35,329 - INFO - Starting feature selection (k=50)
2024-12-27 20:13:35,337 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:13:35,337 - INFO - Starting anomaly detection
2024-12-27 20:13:37,437 - INFO - Anomaly detection completed in 2.10s
2024-12-27 20:13:37,437 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:13:37,437 - INFO - Total fit_transform time: 2.76s
2024-12-27 20:13:37,437 - INFO - Training set processing completed in 2.76s
2024-12-27 20:13:37,437 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:13:37,438 - INFO - Memory usage at start_fit: CPU 3294.5 MB, GPU 49.3 MB
2024-12-27 20:13:37,439 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:13:37,439 - INFO - Number of unique classes: 100
2024-12-27 20:13:37,535 - INFO - Fitted scaler and transformed data
2024-12-27 20:13:37,535 - INFO - Scaling time: 0.09s
2024-12-27 20:13:37,667 - INFO - Epoch 1/200, Train Loss: 3.6148, Val Loss: 3.6501
2024-12-27 20:13:37,792 - INFO - Epoch 2/200, Train Loss: 1.3402, Val Loss: 3.6361
2024-12-27 20:13:37,935 - INFO - Epoch 3/200, Train Loss: 0.6978, Val Loss: 3.4864
2024-12-27 20:13:38,061 - INFO - Epoch 4/200, Train Loss: 0.4409, Val Loss: 3.5035
2024-12-27 20:13:38,214 - INFO - Epoch 5/200, Train Loss: 0.3009, Val Loss: 3.5470
2024-12-27 20:13:38,215 - INFO - Early stopping triggered at epoch 5
2024-12-27 20:13:38,215 - INFO - Training completed in 0.78s
2024-12-27 20:13:38,216 - INFO - Final memory usage: CPU 3294.5 MB, GPU 49.9 MB
2024-12-27 20:13:38,217 - INFO - Model training completed in 0.78s
2024-12-27 20:13:38,233 - INFO - Prediction completed in 0.02s
2024-12-27 20:13:38,253 - INFO - Poison rate 0.1 completed in 3.57s
2024-12-27 20:13:38,253 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:13:38,257 - INFO - Total number of labels flipped: 983
2024-12-27 20:13:38,257 - INFO - Label flipping completed in 0.00s
2024-12-27 20:13:38,258 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:13:38,258 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:13:38,889 - INFO - Feature scaling completed in 0.63s
2024-12-27 20:13:38,889 - INFO - Starting feature selection (k=50)
2024-12-27 20:13:38,903 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:13:38,903 - INFO - Starting anomaly detection
2024-12-27 20:13:40,118 - INFO - Anomaly detection completed in 1.21s
2024-12-27 20:13:40,118 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:13:40,118 - INFO - Total fit_transform time: 1.86s
2024-12-27 20:13:40,118 - INFO - Training set processing completed in 1.86s
2024-12-27 20:13:40,118 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:13:40,119 - INFO - Memory usage at start_fit: CPU 3294.5 MB, GPU 49.3 MB
2024-12-27 20:13:40,119 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:13:40,120 - INFO - Number of unique classes: 100
2024-12-27 20:13:40,215 - INFO - Fitted scaler and transformed data
2024-12-27 20:13:40,215 - INFO - Scaling time: 0.09s
2024-12-27 20:13:40,346 - INFO - Epoch 1/200, Train Loss: 4.2273, Val Loss: 4.4784
2024-12-27 20:13:40,459 - INFO - Epoch 2/200, Train Loss: 1.9071, Val Loss: 4.2670
2024-12-27 20:13:40,580 - INFO - Epoch 3/200, Train Loss: 1.1993, Val Loss: 4.0771
2024-12-27 20:13:40,689 - INFO - Epoch 4/200, Train Loss: 0.8094, Val Loss: 3.9387
2024-12-27 20:13:40,798 - INFO - Epoch 5/200, Train Loss: 0.5774, Val Loss: 3.8034
2024-12-27 20:13:40,905 - INFO - Epoch 6/200, Train Loss: 0.4104, Val Loss: 3.6699
2024-12-27 20:13:41,022 - INFO - Epoch 7/200, Train Loss: 0.3272, Val Loss: 3.6477
2024-12-27 20:13:41,134 - INFO - Epoch 8/200, Train Loss: 0.2958, Val Loss: 3.6481
2024-12-27 20:13:41,253 - INFO - Epoch 9/200, Train Loss: 0.2396, Val Loss: 3.7256
2024-12-27 20:13:41,253 - INFO - Early stopping triggered at epoch 9
2024-12-27 20:13:41,253 - INFO - Training completed in 1.13s
2024-12-27 20:13:41,253 - INFO - Final memory usage: CPU 3294.5 MB, GPU 49.9 MB
2024-12-27 20:13:41,253 - INFO - Model training completed in 1.14s
2024-12-27 20:13:41,266 - INFO - Prediction completed in 0.01s
2024-12-27 20:13:41,290 - INFO - Poison rate 0.2 completed in 3.04s
2024-12-27 20:13:41,295 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:13:41,295 - INFO - Total evaluation time: 26.65s
2024-12-27 20:13:41,297 - INFO - 
Progress: 46.9% - Evaluating CIFAR100 with RandomForest (standard mode, iteration 1/1)
2024-12-27 20:13:41,381 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:13:41,452 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:13:41,540 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:13:41,540 - INFO - Dataset type: image
2024-12-27 20:13:41,540 - INFO - Sample size: 5000
2024-12-27 20:13:41,540 - INFO - Using device: cuda
2024-12-27 20:13:41,542 - INFO - Loading datasets...
2024-12-27 20:13:42,923 - INFO - Dataset loading completed in 1.38s
2024-12-27 20:13:42,923 - INFO - Extracting validation features...
2024-12-27 20:13:42,923 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:14,  2.19it/s]Extracting features:  16%|█▌        | 5/32 [00:00<00:02, 11.16it/s]Extracting features:  28%|██▊       | 9/32 [00:00<00:01, 18.06it/s]Extracting features:  38%|███▊      | 12/32 [00:00<00:00, 21.13it/s]Extracting features:  50%|█████     | 16/32 [00:00<00:00, 25.22it/s]Extracting features:  62%|██████▎   | 20/32 [00:00<00:00, 29.15it/s]Extracting features:  75%|███████▌  | 24/32 [00:01<00:00, 30.94it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 43.44it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 25.47it/s]
2024-12-27 20:13:44,185 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:13:44,186 - INFO - Validation feature extraction completed in 1.26s
2024-12-27 20:13:44,186 - INFO - Extracting training features...
2024-12-27 20:13:44,186 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:46,  3.36it/s]Extracting features:   4%|▍         | 6/157 [00:00<00:08, 17.51it/s]Extracting features:   7%|▋         | 11/157 [00:00<00:05, 26.49it/s]Extracting features:  10%|█         | 16/157 [00:00<00:04, 32.38it/s]Extracting features:  13%|█▎        | 20/157 [00:00<00:04, 33.16it/s]Extracting features:  16%|█▌        | 25/157 [00:00<00:03, 37.50it/s]Extracting features:  19%|█▉        | 30/157 [00:01<00:03, 36.53it/s]Extracting features:  22%|██▏       | 35/157 [00:01<00:03, 39.75it/s]Extracting features:  25%|██▌       | 40/157 [00:01<00:02, 41.80it/s]Extracting features:  29%|██▊       | 45/157 [00:01<00:02, 42.63it/s]Extracting features:  32%|███▏      | 50/157 [00:01<00:02, 41.85it/s]Extracting features:  35%|███▌      | 55/157 [00:01<00:02, 39.77it/s]Extracting features:  38%|███▊      | 60/157 [00:01<00:02, 39.85it/s]Extracting features:  41%|████▏     | 65/157 [00:01<00:02, 41.08it/s]Extracting features:  45%|████▍     | 70/157 [00:01<00:02, 39.88it/s]Extracting features:  48%|████▊     | 75/157 [00:02<00:02, 38.51it/s]Extracting features:  51%|█████     | 80/157 [00:02<00:01, 40.25it/s]Extracting features:  54%|█████▍    | 85/157 [00:02<00:01, 41.32it/s]Extracting features:  58%|█████▊    | 91/157 [00:02<00:01, 45.97it/s]Extracting features:  62%|██████▏   | 97/157 [00:02<00:01, 48.74it/s]Extracting features:  66%|██████▌   | 103/157 [00:02<00:01, 49.71it/s]Extracting features:  70%|███████   | 110/157 [00:02<00:00, 53.14it/s]Extracting features:  74%|███████▍  | 116/157 [00:02<00:00, 51.74it/s]Extracting features:  78%|███████▊  | 122/157 [00:02<00:00, 53.62it/s]Extracting features:  82%|████████▏ | 128/157 [00:03<00:00, 53.80it/s]Extracting features:  86%|████████▌ | 135/157 [00:03<00:00, 56.33it/s]Extracting features:  90%|████████▉ | 141/157 [00:03<00:00, 55.03it/s]Extracting features:  94%|█████████▎| 147/157 [00:03<00:00, 53.89it/s]Extracting features:  98%|█████████▊| 154/157 [00:03<00:00, 56.82it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 42.82it/s]
2024-12-27 20:13:47,862 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:13:47,863 - INFO - Training feature extraction completed in 3.68s
2024-12-27 20:13:47,863 - INFO - Creating model for classifier: RandomForest
2024-12-27 20:13:47,863 - INFO - Using device: cuda
2024-12-27 20:13:47,863 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:13:47,863 - INFO - Training set processing completed in 0.00s
2024-12-27 20:13:47,863 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:13:47,864 - INFO - Memory usage at start_fit: CPU 3266.9 MB, GPU 47.3 MB
2024-12-27 20:13:47,864 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:13:47,954 - INFO - Fitted scaler and transformed data
2024-12-27 20:13:47,955 - INFO - Scaling time: 0.09s
2024-12-27 20:13:47,962 - INFO - Number of unique classes: 100
2024-12-27 20:13:51,527 - INFO - Epoch 1/15, Train Loss: 4.6050, Val Loss: 4.6049
2024-12-27 20:13:54,576 - INFO - Epoch 2/15, Train Loss: 4.6040, Val Loss: 4.6045
2024-12-27 20:13:58,439 - INFO - Epoch 3/15, Train Loss: 4.6029, Val Loss: 4.6041
2024-12-27 20:13:58,440 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:13:58,440 - INFO - Training completed in 10.58s
2024-12-27 20:13:58,440 - INFO - Final memory usage: CPU 3291.4 MB, GPU 97.4 MB
2024-12-27 20:13:58,440 - INFO - Model training completed in 10.58s
2024-12-27 20:13:58,554 - INFO - Prediction completed in 0.11s
2024-12-27 20:13:58,563 - INFO - Poison rate 0.0 completed in 10.70s
2024-12-27 20:13:58,563 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:13:58,564 - INFO - Total number of labels flipped: 50
2024-12-27 20:13:58,564 - INFO - Label flipping completed in 0.00s
2024-12-27 20:13:58,564 - INFO - Training set processing completed in 0.00s
2024-12-27 20:13:58,564 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:13:58,565 - INFO - Memory usage at start_fit: CPU 3291.4 MB, GPU 66.9 MB
2024-12-27 20:13:58,565 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:13:58,631 - INFO - Fitted scaler and transformed data
2024-12-27 20:13:58,632 - INFO - Scaling time: 0.07s
2024-12-27 20:13:58,643 - INFO - Number of unique classes: 100
2024-12-27 20:14:02,162 - INFO - Epoch 1/15, Train Loss: 4.6050, Val Loss: 4.6049
2024-12-27 20:14:05,234 - INFO - Epoch 2/15, Train Loss: 4.6040, Val Loss: 4.6045
2024-12-27 20:14:08,567 - INFO - Epoch 3/15, Train Loss: 4.6029, Val Loss: 4.6040
2024-12-27 20:14:08,567 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:14:08,567 - INFO - Training completed in 10.00s
2024-12-27 20:14:08,567 - INFO - Final memory usage: CPU 3291.4 MB, GPU 97.4 MB
2024-12-27 20:14:08,568 - INFO - Model training completed in 10.00s
2024-12-27 20:14:08,837 - INFO - Prediction completed in 0.27s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:14:08,846 - INFO - Poison rate 0.01 completed in 10.28s
2024-12-27 20:14:08,846 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:14:08,847 - INFO - Total number of labels flipped: 148
2024-12-27 20:14:08,847 - INFO - Label flipping completed in 0.00s
2024-12-27 20:14:08,847 - INFO - Training set processing completed in 0.00s
2024-12-27 20:14:08,847 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:14:08,848 - INFO - Memory usage at start_fit: CPU 3291.4 MB, GPU 66.9 MB
2024-12-27 20:14:08,848 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:14:08,914 - INFO - Fitted scaler and transformed data
2024-12-27 20:14:08,914 - INFO - Scaling time: 0.07s
2024-12-27 20:14:08,925 - INFO - Number of unique classes: 100
2024-12-27 20:14:12,783 - INFO - Epoch 1/15, Train Loss: 4.6050, Val Loss: 4.6049
2024-12-27 20:14:16,318 - INFO - Epoch 2/15, Train Loss: 4.6040, Val Loss: 4.6045
2024-12-27 20:14:19,855 - INFO - Epoch 3/15, Train Loss: 4.6029, Val Loss: 4.6040
2024-12-27 20:14:19,855 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:14:19,856 - INFO - Training completed in 11.01s
2024-12-27 20:14:19,856 - INFO - Final memory usage: CPU 3291.4 MB, GPU 97.4 MB
2024-12-27 20:14:19,856 - INFO - Model training completed in 11.01s
2024-12-27 20:14:19,958 - INFO - Prediction completed in 0.10s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:14:19,967 - INFO - Poison rate 0.03 completed in 11.12s
2024-12-27 20:14:19,967 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:14:19,968 - INFO - Total number of labels flipped: 248
2024-12-27 20:14:19,968 - INFO - Label flipping completed in 0.00s
2024-12-27 20:14:19,968 - INFO - Training set processing completed in 0.00s
2024-12-27 20:14:19,968 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:14:19,969 - INFO - Memory usage at start_fit: CPU 3291.4 MB, GPU 66.9 MB
2024-12-27 20:14:19,969 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:14:20,034 - INFO - Fitted scaler and transformed data
2024-12-27 20:14:20,034 - INFO - Scaling time: 0.07s
2024-12-27 20:14:20,045 - INFO - Number of unique classes: 100
2024-12-27 20:14:23,707 - INFO - Epoch 1/15, Train Loss: 4.6050, Val Loss: 4.6048
2024-12-27 20:14:26,590 - INFO - Epoch 2/15, Train Loss: 4.6040, Val Loss: 4.6044
2024-12-27 20:14:30,160 - INFO - Epoch 3/15, Train Loss: 4.6029, Val Loss: 4.6040
2024-12-27 20:14:30,161 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:14:30,161 - INFO - Training completed in 10.19s
2024-12-27 20:14:30,161 - INFO - Final memory usage: CPU 3291.4 MB, GPU 97.4 MB
2024-12-27 20:14:30,161 - INFO - Model training completed in 10.19s
2024-12-27 20:14:30,314 - INFO - Prediction completed in 0.15s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:14:30,334 - INFO - Poison rate 0.05 completed in 10.37s
2024-12-27 20:14:30,334 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:14:30,335 - INFO - Total number of labels flipped: 348
2024-12-27 20:14:30,335 - INFO - Label flipping completed in 0.00s
2024-12-27 20:14:30,335 - INFO - Training set processing completed in 0.00s
2024-12-27 20:14:30,335 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:14:30,336 - INFO - Memory usage at start_fit: CPU 3291.4 MB, GPU 66.9 MB
2024-12-27 20:14:30,337 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:14:30,404 - INFO - Fitted scaler and transformed data
2024-12-27 20:14:30,404 - INFO - Scaling time: 0.07s
2024-12-27 20:14:30,415 - INFO - Number of unique classes: 100
2024-12-27 20:14:33,509 - INFO - Epoch 1/15, Train Loss: 4.6050, Val Loss: 4.6048
2024-12-27 20:14:37,429 - INFO - Epoch 2/15, Train Loss: 4.6039, Val Loss: 4.6044
2024-12-27 20:14:41,477 - INFO - Epoch 3/15, Train Loss: 4.6028, Val Loss: 4.6039
2024-12-27 20:14:41,477 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:14:41,477 - INFO - Training completed in 11.14s
2024-12-27 20:14:41,478 - INFO - Final memory usage: CPU 3291.4 MB, GPU 97.4 MB
2024-12-27 20:14:41,478 - INFO - Model training completed in 11.14s
2024-12-27 20:14:41,615 - INFO - Prediction completed in 0.14s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:14:41,624 - INFO - Poison rate 0.07 completed in 11.29s
2024-12-27 20:14:41,624 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:14:41,625 - INFO - Total number of labels flipped: 493
2024-12-27 20:14:41,625 - INFO - Label flipping completed in 0.00s
2024-12-27 20:14:41,625 - INFO - Training set processing completed in 0.00s
2024-12-27 20:14:41,625 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:14:41,626 - INFO - Memory usage at start_fit: CPU 3291.4 MB, GPU 66.9 MB
2024-12-27 20:14:41,626 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:14:41,698 - INFO - Fitted scaler and transformed data
2024-12-27 20:14:41,698 - INFO - Scaling time: 0.07s
2024-12-27 20:14:41,708 - INFO - Number of unique classes: 100
2024-12-27 20:14:45,180 - INFO - Epoch 1/15, Train Loss: 4.6050, Val Loss: 4.6048
2024-12-27 20:14:48,236 - INFO - Epoch 2/15, Train Loss: 4.6039, Val Loss: 4.6043
2024-12-27 20:14:51,567 - INFO - Epoch 3/15, Train Loss: 4.6027, Val Loss: 4.6037
2024-12-27 20:14:51,567 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:14:51,567 - INFO - Training completed in 9.94s
2024-12-27 20:14:51,568 - INFO - Final memory usage: CPU 3291.4 MB, GPU 97.4 MB
2024-12-27 20:14:51,568 - INFO - Model training completed in 9.94s
2024-12-27 20:14:51,725 - INFO - Prediction completed in 0.16s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:14:51,734 - INFO - Poison rate 0.1 completed in 10.11s
2024-12-27 20:14:51,734 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:14:51,735 - INFO - Total number of labels flipped: 988
2024-12-27 20:14:51,735 - INFO - Label flipping completed in 0.00s
2024-12-27 20:14:51,735 - INFO - Training set processing completed in 0.00s
2024-12-27 20:14:51,735 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:14:51,736 - INFO - Memory usage at start_fit: CPU 3291.4 MB, GPU 66.9 MB
2024-12-27 20:14:51,736 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:14:51,803 - INFO - Fitted scaler and transformed data
2024-12-27 20:14:51,804 - INFO - Scaling time: 0.07s
2024-12-27 20:14:51,814 - INFO - Number of unique classes: 100
2024-12-27 20:14:55,304 - INFO - Epoch 1/15, Train Loss: 4.6049, Val Loss: 4.6046
2024-12-27 20:14:57,978 - INFO - Epoch 2/15, Train Loss: 4.6037, Val Loss: 4.6040
2024-12-27 20:15:01,926 - INFO - Epoch 3/15, Train Loss: 4.6023, Val Loss: 4.6032
2024-12-27 20:15:01,926 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:15:01,926 - INFO - Training completed in 10.19s
2024-12-27 20:15:01,927 - INFO - Final memory usage: CPU 3291.4 MB, GPU 97.4 MB
2024-12-27 20:15:01,927 - INFO - Model training completed in 10.19s
2024-12-27 20:15:02,094 - INFO - Prediction completed in 0.17s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:15:02,103 - INFO - Poison rate 0.2 completed in 10.37s
2024-12-27 20:15:02,105 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:15:02,105 - INFO - Total evaluation time: 80.56s
2024-12-27 20:15:02,106 - INFO - 
Progress: 47.9% - Evaluating CIFAR100 with RandomForest (dynadetect mode, iteration 1/1)
2024-12-27 20:15:02,167 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:15:02,243 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:15:02,343 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:15:02,343 - INFO - Dataset type: image
2024-12-27 20:15:02,343 - INFO - Sample size: 5000
2024-12-27 20:15:02,343 - INFO - Using device: cuda
2024-12-27 20:15:02,346 - INFO - Loading datasets...
2024-12-27 20:15:03,700 - INFO - Dataset loading completed in 1.35s
2024-12-27 20:15:03,700 - INFO - Extracting validation features...
2024-12-27 20:15:03,700 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:14,  2.19it/s]Extracting features:  19%|█▉        | 6/32 [00:00<00:01, 13.22it/s]Extracting features:  38%|███▊      | 12/32 [00:00<00:00, 24.73it/s]Extracting features:  56%|█████▋    | 18/32 [00:00<00:00, 33.45it/s]Extracting features:  75%|███████▌  | 24/32 [00:00<00:00, 39.64it/s]Extracting features:  97%|█████████▋| 31/32 [00:00<00:00, 47.69it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 30.23it/s]
2024-12-27 20:15:04,763 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:15:04,763 - INFO - Validation feature extraction completed in 1.06s
2024-12-27 20:15:04,763 - INFO - Extracting training features...
2024-12-27 20:15:04,763 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:49,  3.18it/s]Extracting features:   4%|▍         | 7/157 [00:00<00:07, 19.74it/s]Extracting features:   8%|▊         | 12/157 [00:00<00:05, 28.05it/s]Extracting features:  10%|█         | 16/157 [00:00<00:04, 31.01it/s]Extracting features:  13%|█▎        | 21/157 [00:00<00:03, 34.26it/s]Extracting features:  17%|█▋        | 27/157 [00:00<00:03, 39.03it/s]Extracting features:  22%|██▏       | 34/157 [00:01<00:02, 43.91it/s]Extracting features:  26%|██▌       | 41/157 [00:01<00:02, 48.10it/s]Extracting features:  30%|██▉       | 47/157 [00:01<00:02, 49.56it/s]Extracting features:  34%|███▍      | 53/157 [00:01<00:02, 50.38it/s]Extracting features:  38%|███▊      | 59/157 [00:01<00:01, 52.08it/s]Extracting features:  41%|████▏     | 65/157 [00:01<00:01, 53.15it/s]Extracting features:  45%|████▌     | 71/157 [00:01<00:01, 53.24it/s]Extracting features:  49%|████▉     | 77/157 [00:01<00:01, 53.46it/s]Extracting features:  53%|█████▎    | 83/157 [00:01<00:01, 54.06it/s]Extracting features:  57%|█████▋    | 89/157 [00:02<00:01, 54.64it/s]Extracting features:  61%|██████    | 96/157 [00:02<00:01, 56.52it/s]Extracting features:  66%|██████▌   | 103/157 [00:02<00:00, 57.31it/s]Extracting features:  69%|██████▉   | 109/157 [00:02<00:00, 56.62it/s]Extracting features:  73%|███████▎  | 115/157 [00:02<00:00, 56.60it/s]Extracting features:  77%|███████▋  | 121/157 [00:02<00:00, 55.85it/s]Extracting features:  81%|████████  | 127/157 [00:02<00:00, 56.49it/s]Extracting features:  85%|████████▌ | 134/157 [00:02<00:00, 57.72it/s]Extracting features:  89%|████████▉ | 140/157 [00:02<00:00, 56.35it/s]Extracting features:  93%|█████████▎| 146/157 [00:03<00:00, 56.69it/s]Extracting features:  97%|█████████▋| 152/157 [00:03<00:00, 56.74it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 47.75it/s]
2024-12-27 20:15:08,063 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:15:08,064 - INFO - Training feature extraction completed in 3.30s
2024-12-27 20:15:08,064 - INFO - Creating model for classifier: RandomForest
2024-12-27 20:15:08,064 - INFO - Using device: cuda
2024-12-27 20:15:08,064 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:15:08,064 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:15:08,064 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:15:08,677 - INFO - Feature scaling completed in 0.61s
2024-12-27 20:15:08,678 - INFO - Starting feature selection (k=50)
2024-12-27 20:15:08,683 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:15:08,684 - INFO - Starting anomaly detection
2024-12-27 20:15:10,881 - INFO - Anomaly detection completed in 2.20s
2024-12-27 20:15:10,882 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:15:10,882 - INFO - Total fit_transform time: 2.82s
2024-12-27 20:15:10,882 - INFO - Training set processing completed in 2.82s
2024-12-27 20:15:10,882 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:15:10,883 - INFO - Memory usage at start_fit: CPU 3288.8 MB, GPU 47.3 MB
2024-12-27 20:15:10,883 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:15:10,951 - INFO - Fitted scaler and transformed data
2024-12-27 20:15:10,951 - INFO - Scaling time: 0.07s
2024-12-27 20:15:10,957 - INFO - Number of unique classes: 100
2024-12-27 20:15:14,610 - INFO - Epoch 1/15, Train Loss: 4.3828, Val Loss: 4.6049
2024-12-27 20:15:18,276 - INFO - Epoch 2/15, Train Loss: 4.3819, Val Loss: 4.6045
2024-12-27 20:15:21,360 - INFO - Epoch 3/15, Train Loss: 4.3808, Val Loss: 4.6041
2024-12-27 20:15:21,360 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:15:21,361 - INFO - Training completed in 10.48s
2024-12-27 20:15:21,361 - INFO - Final memory usage: CPU 3288.8 MB, GPU 97.4 MB
2024-12-27 20:15:21,361 - INFO - Model training completed in 10.48s
2024-12-27 20:15:21,494 - INFO - Prediction completed in 0.13s
2024-12-27 20:15:21,503 - INFO - Poison rate 0.0 completed in 13.44s
2024-12-27 20:15:21,504 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:15:21,504 - INFO - Total number of labels flipped: 48
2024-12-27 20:15:21,504 - INFO - Label flipping completed in 0.00s
2024-12-27 20:15:21,505 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:15:21,505 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:15:22,134 - INFO - Feature scaling completed in 0.63s
2024-12-27 20:15:22,134 - INFO - Starting feature selection (k=50)
2024-12-27 20:15:22,146 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:15:22,147 - INFO - Starting anomaly detection
2024-12-27 20:15:23,329 - INFO - Anomaly detection completed in 1.18s
2024-12-27 20:15:23,330 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:15:23,330 - INFO - Total fit_transform time: 1.83s
2024-12-27 20:15:23,330 - INFO - Training set processing completed in 1.83s
2024-12-27 20:15:23,330 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:15:23,331 - INFO - Memory usage at start_fit: CPU 3288.8 MB, GPU 66.9 MB
2024-12-27 20:15:23,331 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:15:23,399 - INFO - Fitted scaler and transformed data
2024-12-27 20:15:23,400 - INFO - Scaling time: 0.07s
2024-12-27 20:15:23,405 - INFO - Number of unique classes: 100
2024-12-27 20:15:27,712 - INFO - Epoch 1/15, Train Loss: 4.3701, Val Loss: 4.6049
2024-12-27 20:15:32,047 - INFO - Epoch 2/15, Train Loss: 4.3691, Val Loss: 4.6045
2024-12-27 20:15:35,391 - INFO - Epoch 3/15, Train Loss: 4.3681, Val Loss: 4.6041
2024-12-27 20:15:35,391 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:15:35,391 - INFO - Training completed in 12.06s
2024-12-27 20:15:35,391 - INFO - Final memory usage: CPU 3288.8 MB, GPU 97.4 MB
2024-12-27 20:15:35,392 - INFO - Model training completed in 12.06s
2024-12-27 20:15:35,491 - INFO - Prediction completed in 0.10s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:15:35,500 - INFO - Poison rate 0.01 completed in 14.00s
2024-12-27 20:15:35,501 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:15:35,501 - INFO - Total number of labels flipped: 150
2024-12-27 20:15:35,501 - INFO - Label flipping completed in 0.00s
2024-12-27 20:15:35,501 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:15:35,502 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:15:36,115 - INFO - Feature scaling completed in 0.61s
2024-12-27 20:15:36,115 - INFO - Starting feature selection (k=50)
2024-12-27 20:15:36,128 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:15:36,128 - INFO - Starting anomaly detection
2024-12-27 20:15:37,783 - INFO - Anomaly detection completed in 1.66s
2024-12-27 20:15:37,783 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:15:37,784 - INFO - Total fit_transform time: 2.28s
2024-12-27 20:15:37,784 - INFO - Training set processing completed in 2.28s
2024-12-27 20:15:37,784 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:15:37,785 - INFO - Memory usage at start_fit: CPU 3288.8 MB, GPU 66.9 MB
2024-12-27 20:15:37,785 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:15:37,848 - INFO - Fitted scaler and transformed data
2024-12-27 20:15:37,848 - INFO - Scaling time: 0.06s
2024-12-27 20:15:37,854 - INFO - Number of unique classes: 100
2024-12-27 20:15:40,978 - INFO - Epoch 1/15, Train Loss: 4.3778, Val Loss: 4.6049
2024-12-27 20:15:44,212 - INFO - Epoch 2/15, Train Loss: 4.3768, Val Loss: 4.6045
2024-12-27 20:15:47,135 - INFO - Epoch 3/15, Train Loss: 4.3758, Val Loss: 4.6041
2024-12-27 20:15:47,136 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:15:47,136 - INFO - Training completed in 9.35s
2024-12-27 20:15:47,136 - INFO - Final memory usage: CPU 3288.8 MB, GPU 97.4 MB
2024-12-27 20:15:47,136 - INFO - Model training completed in 9.35s
2024-12-27 20:15:47,235 - INFO - Prediction completed in 0.10s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:15:47,244 - INFO - Poison rate 0.03 completed in 11.74s
2024-12-27 20:15:47,244 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:15:47,245 - INFO - Total number of labels flipped: 248
2024-12-27 20:15:47,245 - INFO - Label flipping completed in 0.00s
2024-12-27 20:15:47,245 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:15:47,245 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:15:47,837 - INFO - Feature scaling completed in 0.59s
2024-12-27 20:15:47,837 - INFO - Starting feature selection (k=50)
2024-12-27 20:15:47,849 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:15:47,849 - INFO - Starting anomaly detection
2024-12-27 20:15:50,150 - INFO - Anomaly detection completed in 2.30s
2024-12-27 20:15:50,151 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:15:50,151 - INFO - Total fit_transform time: 2.91s
2024-12-27 20:15:50,151 - INFO - Training set processing completed in 2.91s
2024-12-27 20:15:50,151 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:15:50,152 - INFO - Memory usage at start_fit: CPU 3288.8 MB, GPU 66.9 MB
2024-12-27 20:15:50,152 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:15:50,220 - INFO - Fitted scaler and transformed data
2024-12-27 20:15:50,220 - INFO - Scaling time: 0.07s
2024-12-27 20:15:50,226 - INFO - Number of unique classes: 100
2024-12-27 20:15:53,057 - INFO - Epoch 1/15, Train Loss: 4.3740, Val Loss: 4.6049
2024-12-27 20:15:56,646 - INFO - Epoch 2/15, Train Loss: 4.3730, Val Loss: 4.6045
2024-12-27 20:16:00,577 - INFO - Epoch 3/15, Train Loss: 4.3719, Val Loss: 4.6040
2024-12-27 20:16:00,577 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:16:00,577 - INFO - Training completed in 10.43s
2024-12-27 20:16:00,578 - INFO - Final memory usage: CPU 3288.8 MB, GPU 97.4 MB
2024-12-27 20:16:00,578 - INFO - Model training completed in 10.43s
2024-12-27 20:16:00,735 - INFO - Prediction completed in 0.16s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:16:00,744 - INFO - Poison rate 0.05 completed in 13.50s
2024-12-27 20:16:00,744 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:16:00,745 - INFO - Total number of labels flipped: 348
2024-12-27 20:16:00,745 - INFO - Label flipping completed in 0.00s
2024-12-27 20:16:00,745 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:16:00,745 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:16:01,374 - INFO - Feature scaling completed in 0.63s
2024-12-27 20:16:01,374 - INFO - Starting feature selection (k=50)
2024-12-27 20:16:01,388 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:16:01,389 - INFO - Starting anomaly detection
2024-12-27 20:16:02,838 - INFO - Anomaly detection completed in 1.45s
2024-12-27 20:16:02,838 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:16:02,838 - INFO - Total fit_transform time: 2.09s
2024-12-27 20:16:02,838 - INFO - Training set processing completed in 2.09s
2024-12-27 20:16:02,838 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:16:02,839 - INFO - Memory usage at start_fit: CPU 3288.8 MB, GPU 66.9 MB
2024-12-27 20:16:02,839 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:16:02,904 - INFO - Fitted scaler and transformed data
2024-12-27 20:16:02,904 - INFO - Scaling time: 0.07s
2024-12-27 20:16:02,912 - INFO - Number of unique classes: 100
2024-12-27 20:16:06,007 - INFO - Epoch 1/15, Train Loss: 4.3780, Val Loss: 4.6048
2024-12-27 20:16:09,726 - INFO - Epoch 2/15, Train Loss: 4.3770, Val Loss: 4.6043
2024-12-27 20:16:13,018 - INFO - Epoch 3/15, Train Loss: 4.3759, Val Loss: 4.6038
2024-12-27 20:16:13,018 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:16:13,018 - INFO - Training completed in 10.18s
2024-12-27 20:16:13,018 - INFO - Final memory usage: CPU 3288.8 MB, GPU 97.4 MB
2024-12-27 20:16:13,019 - INFO - Model training completed in 10.18s
2024-12-27 20:16:13,130 - INFO - Prediction completed in 0.11s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:16:13,138 - INFO - Poison rate 0.07 completed in 12.39s
2024-12-27 20:16:13,138 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:16:13,139 - INFO - Total number of labels flipped: 496
2024-12-27 20:16:13,139 - INFO - Label flipping completed in 0.00s
2024-12-27 20:16:13,139 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:16:13,139 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:16:13,744 - INFO - Feature scaling completed in 0.60s
2024-12-27 20:16:13,744 - INFO - Starting feature selection (k=50)
2024-12-27 20:16:13,757 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:16:13,757 - INFO - Starting anomaly detection
2024-12-27 20:16:15,476 - INFO - Anomaly detection completed in 1.72s
2024-12-27 20:16:15,476 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:16:15,476 - INFO - Total fit_transform time: 2.34s
2024-12-27 20:16:15,476 - INFO - Training set processing completed in 2.34s
2024-12-27 20:16:15,476 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:16:15,477 - INFO - Memory usage at start_fit: CPU 3288.8 MB, GPU 66.9 MB
2024-12-27 20:16:15,478 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:16:15,543 - INFO - Fitted scaler and transformed data
2024-12-27 20:16:15,543 - INFO - Scaling time: 0.07s
2024-12-27 20:16:15,550 - INFO - Number of unique classes: 100
2024-12-27 20:16:19,006 - INFO - Epoch 1/15, Train Loss: 4.3732, Val Loss: 4.6048
2024-12-27 20:16:22,694 - INFO - Epoch 2/15, Train Loss: 4.3722, Val Loss: 4.6044
2024-12-27 20:16:26,080 - INFO - Epoch 3/15, Train Loss: 4.3711, Val Loss: 4.6039
2024-12-27 20:16:26,081 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:16:26,081 - INFO - Training completed in 10.60s
2024-12-27 20:16:26,081 - INFO - Final memory usage: CPU 3288.8 MB, GPU 97.4 MB
2024-12-27 20:16:26,081 - INFO - Model training completed in 10.60s
2024-12-27 20:16:26,190 - INFO - Prediction completed in 0.11s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:16:26,199 - INFO - Poison rate 0.1 completed in 13.06s
2024-12-27 20:16:26,199 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:16:26,200 - INFO - Total number of labels flipped: 990
2024-12-27 20:16:26,200 - INFO - Label flipping completed in 0.00s
2024-12-27 20:16:26,200 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:16:26,200 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:16:26,748 - INFO - Feature scaling completed in 0.55s
2024-12-27 20:16:26,748 - INFO - Starting feature selection (k=50)
2024-12-27 20:16:26,761 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:16:26,761 - INFO - Starting anomaly detection
2024-12-27 20:16:28,862 - INFO - Anomaly detection completed in 2.10s
2024-12-27 20:16:28,862 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:16:28,862 - INFO - Total fit_transform time: 2.66s
2024-12-27 20:16:28,862 - INFO - Training set processing completed in 2.66s
2024-12-27 20:16:28,862 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:16:28,863 - INFO - Memory usage at start_fit: CPU 3288.8 MB, GPU 66.9 MB
2024-12-27 20:16:28,863 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:16:28,931 - INFO - Fitted scaler and transformed data
2024-12-27 20:16:28,932 - INFO - Scaling time: 0.07s
2024-12-27 20:16:28,938 - INFO - Number of unique classes: 100
2024-12-27 20:16:32,153 - INFO - Epoch 1/15, Train Loss: 4.3775, Val Loss: 4.6046
2024-12-27 20:16:35,532 - INFO - Epoch 2/15, Train Loss: 4.3763, Val Loss: 4.6039
2024-12-27 20:16:38,461 - INFO - Epoch 3/15, Train Loss: 4.3751, Val Loss: 4.6031
2024-12-27 20:16:38,461 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:16:38,462 - INFO - Training completed in 9.60s
2024-12-27 20:16:38,462 - INFO - Final memory usage: CPU 3288.8 MB, GPU 97.4 MB
2024-12-27 20:16:38,462 - INFO - Model training completed in 9.60s
2024-12-27 20:16:38,560 - INFO - Prediction completed in 0.10s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:16:38,568 - INFO - Poison rate 0.2 completed in 12.37s
2024-12-27 20:16:38,570 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:16:38,570 - INFO - Total evaluation time: 96.22s
2024-12-27 20:16:38,571 - INFO - 
Progress: 49.0% - Evaluating CIFAR100 with KNeighbors (standard mode, iteration 1/1)
2024-12-27 20:16:38,632 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:16:38,727 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:16:38,812 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:16:38,812 - INFO - Dataset type: image
2024-12-27 20:16:38,812 - INFO - Sample size: 5000
2024-12-27 20:16:38,812 - INFO - Using device: cuda
2024-12-27 20:16:38,815 - INFO - Loading datasets...
2024-12-27 20:16:40,179 - INFO - Dataset loading completed in 1.36s
2024-12-27 20:16:40,180 - INFO - Extracting validation features...
2024-12-27 20:16:40,180 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:15,  1.94it/s]Extracting features:  16%|█▌        | 5/32 [00:00<00:02,  9.93it/s]Extracting features:  34%|███▍      | 11/32 [00:00<00:00, 21.29it/s]Extracting features:  53%|█████▎    | 17/32 [00:00<00:00, 30.53it/s]Extracting features:  75%|███████▌  | 24/32 [00:00<00:00, 39.46it/s]Extracting features:  94%|█████████▍| 30/32 [00:01<00:00, 41.79it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 27.36it/s]
2024-12-27 20:16:41,355 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:16:41,356 - INFO - Validation feature extraction completed in 1.18s
2024-12-27 20:16:41,356 - INFO - Extracting training features...
2024-12-27 20:16:41,356 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:47,  3.27it/s]Extracting features:   4%|▍         | 6/157 [00:00<00:08, 17.97it/s]Extracting features:   8%|▊         | 12/157 [00:00<00:04, 29.15it/s]Extracting features:  11%|█▏        | 18/157 [00:00<00:03, 35.94it/s]Extracting features:  16%|█▌        | 25/157 [00:00<00:03, 43.90it/s]Extracting features:  20%|█▉        | 31/157 [00:00<00:02, 46.77it/s]Extracting features:  24%|██▎       | 37/157 [00:00<00:02, 50.34it/s]Extracting features:  28%|██▊       | 44/157 [00:01<00:02, 52.65it/s]Extracting features:  32%|███▏      | 50/157 [00:01<00:02, 50.59it/s]Extracting features:  36%|███▌      | 56/157 [00:01<00:01, 51.85it/s]Extracting features:  39%|███▉      | 62/157 [00:01<00:01, 52.52it/s]Extracting features:  43%|████▎     | 68/157 [00:01<00:01, 53.26it/s]Extracting features:  47%|████▋     | 74/157 [00:01<00:01, 54.94it/s]Extracting features:  51%|█████     | 80/157 [00:01<00:01, 53.13it/s]Extracting features:  55%|█████▍    | 86/157 [00:01<00:01, 48.83it/s]Extracting features:  58%|█████▊    | 91/157 [00:02<00:01, 46.96it/s]Extracting features:  61%|██████    | 96/157 [00:02<00:01, 47.54it/s]Extracting features:  65%|██████▍   | 102/157 [00:02<00:01, 49.34it/s]Extracting features:  68%|██████▊   | 107/157 [00:02<00:01, 48.24it/s]Extracting features:  71%|███████▏  | 112/157 [00:02<00:00, 47.63it/s]Extracting features:  75%|███████▍  | 117/157 [00:02<00:00, 45.00it/s]Extracting features:  78%|███████▊  | 122/157 [00:02<00:00, 45.38it/s]Extracting features:  81%|████████  | 127/157 [00:02<00:00, 45.22it/s]Extracting features:  84%|████████▍ | 132/157 [00:02<00:00, 46.10it/s]Extracting features:  87%|████████▋ | 137/157 [00:03<00:00, 44.71it/s]Extracting features:  90%|█████████ | 142/157 [00:03<00:00, 44.66it/s]Extracting features:  94%|█████████▍| 148/157 [00:03<00:00, 47.56it/s]Extracting features:  98%|█████████▊| 154/157 [00:03<00:00, 50.06it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 45.20it/s]
2024-12-27 20:16:44,844 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:16:44,845 - INFO - Training feature extraction completed in 3.49s
2024-12-27 20:16:44,845 - INFO - Creating model for classifier: KNeighbors
2024-12-27 20:16:44,845 - INFO - Using device: cuda
2024-12-27 20:16:44,845 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:16:44,845 - INFO - Training set processing completed in 0.00s
2024-12-27 20:16:44,845 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:16:44,847 - INFO - Memory usage at start_fit: CPU 3268.4 MB, GPU 47.3 MB
2024-12-27 20:16:44,847 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:16:44,936 - INFO - Fitted scaler and transformed data
2024-12-27 20:16:44,936 - INFO - Scaling time: 0.09s
2024-12-27 20:16:44,941 - INFO - Training completed in 0.10s
2024-12-27 20:16:44,941 - INFO - Final memory usage: CPU 3292.8 MB, GPU 71.8 MB
2024-12-27 20:16:44,941 - INFO - Model training completed in 0.10s
2024-12-27 20:16:44,956 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:16:44,966 - INFO - Poison rate 0.0 completed in 0.12s
2024-12-27 20:16:44,966 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:16:44,967 - INFO - Total number of labels flipped: 50
2024-12-27 20:16:44,967 - INFO - Label flipping completed in 0.00s
2024-12-27 20:16:44,967 - INFO - Training set processing completed in 0.00s
2024-12-27 20:16:44,967 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:16:44,968 - INFO - Memory usage at start_fit: CPU 3292.8 MB, GPU 71.8 MB
2024-12-27 20:16:44,968 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:16:45,032 - INFO - Fitted scaler and transformed data
2024-12-27 20:16:45,032 - INFO - Scaling time: 0.06s
2024-12-27 20:16:45,037 - INFO - Training completed in 0.07s
2024-12-27 20:16:45,037 - INFO - Final memory usage: CPU 3292.8 MB, GPU 71.8 MB
2024-12-27 20:16:45,038 - INFO - Model training completed in 0.07s
2024-12-27 20:16:45,052 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:16:45,061 - INFO - Poison rate 0.01 completed in 0.09s
2024-12-27 20:16:45,061 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:16:45,061 - INFO - Total number of labels flipped: 148
2024-12-27 20:16:45,061 - INFO - Label flipping completed in 0.00s
2024-12-27 20:16:45,062 - INFO - Training set processing completed in 0.00s
2024-12-27 20:16:45,062 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:16:45,062 - INFO - Memory usage at start_fit: CPU 3292.8 MB, GPU 71.8 MB
2024-12-27 20:16:45,063 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:16:45,123 - INFO - Fitted scaler and transformed data
2024-12-27 20:16:45,123 - INFO - Scaling time: 0.06s
2024-12-27 20:16:45,129 - INFO - Training completed in 0.07s
2024-12-27 20:16:45,129 - INFO - Final memory usage: CPU 3292.8 MB, GPU 71.8 MB
2024-12-27 20:16:45,129 - INFO - Model training completed in 0.07s
2024-12-27 20:16:45,144 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:16:45,153 - INFO - Poison rate 0.03 completed in 0.09s
2024-12-27 20:16:45,153 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:16:45,154 - INFO - Total number of labels flipped: 250
2024-12-27 20:16:45,154 - INFO - Label flipping completed in 0.00s
2024-12-27 20:16:45,154 - INFO - Training set processing completed in 0.00s
2024-12-27 20:16:45,154 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:16:45,155 - INFO - Memory usage at start_fit: CPU 3292.8 MB, GPU 71.8 MB
2024-12-27 20:16:45,155 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:16:45,214 - INFO - Fitted scaler and transformed data
2024-12-27 20:16:45,214 - INFO - Scaling time: 0.06s
2024-12-27 20:16:45,219 - INFO - Training completed in 0.06s
2024-12-27 20:16:45,220 - INFO - Final memory usage: CPU 3292.8 MB, GPU 71.8 MB
2024-12-27 20:16:45,220 - INFO - Model training completed in 0.07s
2024-12-27 20:16:45,234 - INFO - Prediction completed in 0.01s
2024-12-27 20:16:45,243 - INFO - Poison rate 0.05 completed in 0.09s
2024-12-27 20:16:45,243 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:16:45,244 - INFO - Total number of labels flipped: 347
2024-12-27 20:16:45,244 - INFO - Label flipping completed in 0.00s
2024-12-27 20:16:45,244 - INFO - Training set processing completed in 0.00s
2024-12-27 20:16:45,244 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:16:45,245 - INFO - Memory usage at start_fit: CPU 3292.8 MB, GPU 71.8 MB
2024-12-27 20:16:45,245 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:16:45,304 - INFO - Fitted scaler and transformed data
2024-12-27 20:16:45,304 - INFO - Scaling time: 0.06s
2024-12-27 20:16:45,309 - INFO - Training completed in 0.06s
2024-12-27 20:16:45,309 - INFO - Final memory usage: CPU 3292.8 MB, GPU 71.8 MB
2024-12-27 20:16:45,310 - INFO - Model training completed in 0.07s
2024-12-27 20:16:45,323 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:16:45,331 - INFO - Poison rate 0.07 completed in 0.09s
2024-12-27 20:16:45,332 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:16:45,332 - INFO - Total number of labels flipped: 497
2024-12-27 20:16:45,333 - INFO - Label flipping completed in 0.00s
2024-12-27 20:16:45,333 - INFO - Training set processing completed in 0.00s
2024-12-27 20:16:45,333 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:16:45,333 - INFO - Memory usage at start_fit: CPU 3292.8 MB, GPU 71.8 MB
2024-12-27 20:16:45,334 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:16:45,392 - INFO - Fitted scaler and transformed data
2024-12-27 20:16:45,392 - INFO - Scaling time: 0.06s
2024-12-27 20:16:45,398 - INFO - Training completed in 0.06s
2024-12-27 20:16:45,398 - INFO - Final memory usage: CPU 3292.8 MB, GPU 71.8 MB
2024-12-27 20:16:45,398 - INFO - Model training completed in 0.07s
2024-12-27 20:16:45,413 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:16:45,422 - INFO - Poison rate 0.1 completed in 0.09s
2024-12-27 20:16:45,422 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:16:45,423 - INFO - Total number of labels flipped: 991
2024-12-27 20:16:45,424 - INFO - Label flipping completed in 0.00s
2024-12-27 20:16:45,424 - INFO - Training set processing completed in 0.00s
2024-12-27 20:16:45,424 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:16:45,425 - INFO - Memory usage at start_fit: CPU 3292.8 MB, GPU 71.8 MB
2024-12-27 20:16:45,425 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:16:45,493 - INFO - Fitted scaler and transformed data
2024-12-27 20:16:45,493 - INFO - Scaling time: 0.07s
2024-12-27 20:16:45,498 - INFO - Training completed in 0.07s
2024-12-27 20:16:45,499 - INFO - Final memory usage: CPU 3292.8 MB, GPU 71.8 MB
2024-12-27 20:16:45,499 - INFO - Model training completed in 0.08s
2024-12-27 20:16:45,514 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:16:45,523 - INFO - Poison rate 0.2 completed in 0.10s
2024-12-27 20:16:45,524 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:16:45,525 - INFO - Total evaluation time: 6.71s
2024-12-27 20:16:45,526 - INFO - 
Progress: 50.0% - Evaluating CIFAR100 with KNeighbors (dynadetect mode, iteration 1/1)
2024-12-27 20:16:45,588 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:16:45,663 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:16:45,745 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:16:45,745 - INFO - Dataset type: image
2024-12-27 20:16:45,745 - INFO - Sample size: 5000
2024-12-27 20:16:45,745 - INFO - Using device: cuda
2024-12-27 20:16:45,747 - INFO - Loading datasets...
2024-12-27 20:16:47,005 - INFO - Dataset loading completed in 1.26s
2024-12-27 20:16:47,005 - INFO - Extracting validation features...
2024-12-27 20:16:47,005 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:09,  3.43it/s]Extracting features:  12%|█▎        | 4/32 [00:00<00:02, 12.04it/s]Extracting features:  25%|██▌       | 8/32 [00:00<00:01, 19.13it/s]Extracting features:  44%|████▍     | 14/32 [00:00<00:00, 30.31it/s]Extracting features:  59%|█████▉    | 19/32 [00:00<00:00, 35.54it/s]Extracting features:  75%|███████▌  | 24/32 [00:00<00:00, 37.63it/s]Extracting features:  97%|█████████▋| 31/32 [00:00<00:00, 45.80it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 30.97it/s]
2024-12-27 20:16:48,044 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:16:48,045 - INFO - Validation feature extraction completed in 1.04s
2024-12-27 20:16:48,045 - INFO - Extracting training features...
2024-12-27 20:16:48,045 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:49,  3.17it/s]Extracting features:   4%|▍         | 7/157 [00:00<00:07, 19.55it/s]Extracting features:   8%|▊         | 13/157 [00:00<00:04, 30.30it/s]Extracting features:  11%|█▏        | 18/157 [00:00<00:03, 35.72it/s]Extracting features:  15%|█▌        | 24/157 [00:00<00:03, 40.67it/s]Extracting features:  18%|█▊        | 29/157 [00:00<00:03, 42.48it/s]Extracting features:  22%|██▏       | 35/157 [00:00<00:02, 47.13it/s]Extracting features:  26%|██▌       | 41/157 [00:01<00:02, 48.31it/s]Extracting features:  30%|██▉       | 47/157 [00:01<00:02, 50.38it/s]Extracting features:  34%|███▍      | 53/157 [00:01<00:02, 46.92it/s]Extracting features:  38%|███▊      | 59/157 [00:01<00:01, 49.43it/s]Extracting features:  41%|████▏     | 65/157 [00:01<00:01, 51.41it/s]Extracting features:  45%|████▌     | 71/157 [00:01<00:01, 52.16it/s]Extracting features:  49%|████▉     | 77/157 [00:01<00:01, 53.38it/s]Extracting features:  53%|█████▎    | 83/157 [00:01<00:01, 52.38it/s]Extracting features:  57%|█████▋    | 90/157 [00:02<00:01, 54.96it/s]Extracting features:  62%|██████▏   | 97/157 [00:02<00:01, 56.64it/s]Extracting features:  66%|██████▌   | 103/157 [00:02<00:00, 56.17it/s]Extracting features:  70%|███████   | 110/157 [00:02<00:00, 57.14it/s]Extracting features:  74%|███████▍  | 116/157 [00:02<00:00, 54.16it/s]Extracting features:  78%|███████▊  | 122/157 [00:02<00:00, 54.09it/s]Extracting features:  82%|████████▏ | 128/157 [00:02<00:00, 54.66it/s]Extracting features:  85%|████████▌ | 134/157 [00:02<00:00, 51.87it/s]Extracting features:  90%|████████▉ | 141/157 [00:02<00:00, 54.91it/s]Extracting features:  94%|█████████▎| 147/157 [00:03<00:00, 53.39it/s]Extracting features:  98%|█████████▊| 154/157 [00:03<00:00, 56.11it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 47.86it/s]
2024-12-27 20:16:51,343 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:16:51,343 - INFO - Training feature extraction completed in 3.30s
2024-12-27 20:16:51,343 - INFO - Creating model for classifier: KNeighbors
2024-12-27 20:16:51,343 - INFO - Using device: cuda
2024-12-27 20:16:51,343 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:16:51,343 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:16:51,343 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:16:51,993 - INFO - Feature scaling completed in 0.65s
2024-12-27 20:16:51,994 - INFO - Starting feature selection (k=50)
2024-12-27 20:16:51,999 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:16:51,999 - INFO - Starting anomaly detection
2024-12-27 20:16:54,149 - INFO - Anomaly detection completed in 2.15s
2024-12-27 20:16:54,149 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:16:54,149 - INFO - Total fit_transform time: 2.81s
2024-12-27 20:16:54,149 - INFO - Training set processing completed in 2.81s
2024-12-27 20:16:54,149 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:16:54,151 - INFO - Memory usage at start_fit: CPU 3290.2 MB, GPU 47.3 MB
2024-12-27 20:16:54,151 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:16:54,220 - INFO - Fitted scaler and transformed data
2024-12-27 20:16:54,220 - INFO - Scaling time: 0.07s
2024-12-27 20:16:54,227 - INFO - Training completed in 0.08s
2024-12-27 20:16:54,228 - INFO - Final memory usage: CPU 3290.2 MB, GPU 71.8 MB
2024-12-27 20:16:54,228 - INFO - Model training completed in 0.08s
2024-12-27 20:16:54,250 - INFO - Prediction completed in 0.02s
2024-12-27 20:16:54,267 - INFO - Poison rate 0.0 completed in 2.92s
2024-12-27 20:16:54,268 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:16:54,269 - INFO - Total number of labels flipped: 49
2024-12-27 20:16:54,269 - INFO - Label flipping completed in 0.00s
2024-12-27 20:16:54,269 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:16:54,269 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:16:54,831 - INFO - Feature scaling completed in 0.56s
2024-12-27 20:16:54,832 - INFO - Starting feature selection (k=50)
2024-12-27 20:16:54,843 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:16:54,843 - INFO - Starting anomaly detection
2024-12-27 20:16:56,671 - INFO - Anomaly detection completed in 1.83s
2024-12-27 20:16:56,672 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:16:56,672 - INFO - Total fit_transform time: 2.40s
2024-12-27 20:16:56,672 - INFO - Training set processing completed in 2.40s
2024-12-27 20:16:56,672 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:16:56,673 - INFO - Memory usage at start_fit: CPU 3290.2 MB, GPU 71.8 MB
2024-12-27 20:16:56,673 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:16:56,740 - INFO - Fitted scaler and transformed data
2024-12-27 20:16:56,741 - INFO - Scaling time: 0.07s
2024-12-27 20:16:56,746 - INFO - Training completed in 0.07s
2024-12-27 20:16:56,747 - INFO - Final memory usage: CPU 3290.2 MB, GPU 71.8 MB
2024-12-27 20:16:56,747 - INFO - Model training completed in 0.07s
2024-12-27 20:16:56,760 - INFO - Prediction completed in 0.01s
2024-12-27 20:16:56,769 - INFO - Poison rate 0.01 completed in 2.50s
2024-12-27 20:16:56,769 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:16:56,770 - INFO - Total number of labels flipped: 147
2024-12-27 20:16:56,770 - INFO - Label flipping completed in 0.00s
2024-12-27 20:16:56,770 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:16:56,770 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:16:57,308 - INFO - Feature scaling completed in 0.54s
2024-12-27 20:16:57,308 - INFO - Starting feature selection (k=50)
2024-12-27 20:16:57,314 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:16:57,314 - INFO - Starting anomaly detection
2024-12-27 20:16:58,882 - INFO - Anomaly detection completed in 1.57s
2024-12-27 20:16:58,882 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:16:58,882 - INFO - Total fit_transform time: 2.11s
2024-12-27 20:16:58,882 - INFO - Training set processing completed in 2.11s
2024-12-27 20:16:58,882 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:16:58,883 - INFO - Memory usage at start_fit: CPU 3290.2 MB, GPU 71.8 MB
2024-12-27 20:16:58,883 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:16:58,954 - INFO - Fitted scaler and transformed data
2024-12-27 20:16:58,954 - INFO - Scaling time: 0.07s
2024-12-27 20:16:58,959 - INFO - Training completed in 0.08s
2024-12-27 20:16:58,960 - INFO - Final memory usage: CPU 3290.2 MB, GPU 71.8 MB
2024-12-27 20:16:58,960 - INFO - Model training completed in 0.08s
2024-12-27 20:16:58,975 - INFO - Prediction completed in 0.01s
2024-12-27 20:16:58,985 - INFO - Poison rate 0.03 completed in 2.22s
2024-12-27 20:16:58,985 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:16:58,986 - INFO - Total number of labels flipped: 247
2024-12-27 20:16:58,986 - INFO - Label flipping completed in 0.00s
2024-12-27 20:16:58,986 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:16:58,986 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:16:59,549 - INFO - Feature scaling completed in 0.56s
2024-12-27 20:16:59,549 - INFO - Starting feature selection (k=50)
2024-12-27 20:16:59,556 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:16:59,557 - INFO - Starting anomaly detection
2024-12-27 20:17:01,658 - INFO - Anomaly detection completed in 2.10s
2024-12-27 20:17:01,658 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:17:01,658 - INFO - Total fit_transform time: 2.67s
2024-12-27 20:17:01,659 - INFO - Training set processing completed in 2.67s
2024-12-27 20:17:01,659 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:17:01,660 - INFO - Memory usage at start_fit: CPU 3290.2 MB, GPU 71.8 MB
2024-12-27 20:17:01,660 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:17:01,736 - INFO - Fitted scaler and transformed data
2024-12-27 20:17:01,736 - INFO - Scaling time: 0.08s
2024-12-27 20:17:01,742 - INFO - Training completed in 0.08s
2024-12-27 20:17:01,743 - INFO - Final memory usage: CPU 3290.2 MB, GPU 71.8 MB
2024-12-27 20:17:01,743 - INFO - Model training completed in 0.08s
2024-12-27 20:17:01,769 - INFO - Prediction completed in 0.03s
2024-12-27 20:17:01,777 - INFO - Poison rate 0.05 completed in 2.79s
2024-12-27 20:17:01,777 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:17:01,778 - INFO - Total number of labels flipped: 346
2024-12-27 20:17:01,778 - INFO - Label flipping completed in 0.00s
2024-12-27 20:17:01,778 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:17:01,778 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:17:02,370 - INFO - Feature scaling completed in 0.59s
2024-12-27 20:17:02,370 - INFO - Starting feature selection (k=50)
2024-12-27 20:17:02,378 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:17:02,378 - INFO - Starting anomaly detection
2024-12-27 20:17:04,320 - INFO - Anomaly detection completed in 1.94s
2024-12-27 20:17:04,320 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:17:04,320 - INFO - Total fit_transform time: 2.54s
2024-12-27 20:17:04,320 - INFO - Training set processing completed in 2.54s
2024-12-27 20:17:04,320 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:17:04,321 - INFO - Memory usage at start_fit: CPU 3290.2 MB, GPU 71.8 MB
2024-12-27 20:17:04,322 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:17:04,399 - INFO - Fitted scaler and transformed data
2024-12-27 20:17:04,399 - INFO - Scaling time: 0.08s
2024-12-27 20:17:04,405 - INFO - Training completed in 0.08s
2024-12-27 20:17:04,405 - INFO - Final memory usage: CPU 3290.2 MB, GPU 71.8 MB
2024-12-27 20:17:04,406 - INFO - Model training completed in 0.09s
2024-12-27 20:17:04,433 - INFO - Prediction completed in 0.03s
2024-12-27 20:17:04,442 - INFO - Poison rate 0.07 completed in 2.66s
2024-12-27 20:17:04,442 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:17:04,443 - INFO - Total number of labels flipped: 492
2024-12-27 20:17:04,443 - INFO - Label flipping completed in 0.00s
2024-12-27 20:17:04,443 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:17:04,443 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:17:05,065 - INFO - Feature scaling completed in 0.62s
2024-12-27 20:17:05,065 - INFO - Starting feature selection (k=50)
2024-12-27 20:17:05,073 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:17:05,074 - INFO - Starting anomaly detection
2024-12-27 20:17:07,280 - INFO - Anomaly detection completed in 2.21s
2024-12-27 20:17:07,280 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:17:07,280 - INFO - Total fit_transform time: 2.84s
2024-12-27 20:17:07,281 - INFO - Training set processing completed in 2.84s
2024-12-27 20:17:07,281 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:17:07,282 - INFO - Memory usage at start_fit: CPU 3290.2 MB, GPU 71.8 MB
2024-12-27 20:17:07,282 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:17:07,347 - INFO - Fitted scaler and transformed data
2024-12-27 20:17:07,347 - INFO - Scaling time: 0.06s
2024-12-27 20:17:07,355 - INFO - Training completed in 0.07s
2024-12-27 20:17:07,356 - INFO - Final memory usage: CPU 3290.2 MB, GPU 71.8 MB
2024-12-27 20:17:07,356 - INFO - Model training completed in 0.08s
2024-12-27 20:17:07,381 - INFO - Prediction completed in 0.02s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:17:07,390 - INFO - Poison rate 0.1 completed in 2.95s
2024-12-27 20:17:07,390 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:17:07,391 - INFO - Total number of labels flipped: 989
2024-12-27 20:17:07,391 - INFO - Label flipping completed in 0.00s
2024-12-27 20:17:07,391 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:17:07,391 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:17:08,043 - INFO - Feature scaling completed in 0.65s
2024-12-27 20:17:08,044 - INFO - Starting feature selection (k=50)
2024-12-27 20:17:08,052 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:17:08,052 - INFO - Starting anomaly detection
2024-12-27 20:17:10,059 - INFO - Anomaly detection completed in 2.01s
2024-12-27 20:17:10,059 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:17:10,060 - INFO - Total fit_transform time: 2.67s
2024-12-27 20:17:10,060 - INFO - Training set processing completed in 2.67s
2024-12-27 20:17:10,060 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:17:10,061 - INFO - Memory usage at start_fit: CPU 3290.2 MB, GPU 71.8 MB
2024-12-27 20:17:10,061 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:17:10,127 - INFO - Fitted scaler and transformed data
2024-12-27 20:17:10,127 - INFO - Scaling time: 0.07s
2024-12-27 20:17:10,133 - INFO - Training completed in 0.07s
2024-12-27 20:17:10,134 - INFO - Final memory usage: CPU 3290.2 MB, GPU 71.8 MB
2024-12-27 20:17:10,134 - INFO - Model training completed in 0.07s
2024-12-27 20:17:10,159 - INFO - Prediction completed in 0.02s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:17:10,168 - INFO - Poison rate 0.2 completed in 2.78s
2024-12-27 20:17:10,170 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:17:10,170 - INFO - Total evaluation time: 24.42s
2024-12-27 20:17:10,171 - INFO - Completed evaluation for CIFAR100
2024-12-27 20:17:10,172 - INFO - 
Processing dataset: CIFAR100
2024-12-27 20:17:10,233 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:17:10,311 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:17:10,393 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:17:10,394 - INFO - Dataset type: image
2024-12-27 20:17:10,394 - INFO - Sample size: 5000
2024-12-27 20:17:10,394 - INFO - Using device: cuda
2024-12-27 20:17:10,396 - INFO - 
Progress: 51.0% - Evaluating CIFAR100 with SVM (standard mode, iteration 1/1)
2024-12-27 20:17:10,455 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:17:10,538 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:17:10,617 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:17:10,618 - INFO - Dataset type: image
2024-12-27 20:17:10,618 - INFO - Sample size: 5000
2024-12-27 20:17:10,618 - INFO - Using device: cuda
2024-12-27 20:17:10,620 - INFO - Loading datasets...
2024-12-27 20:17:12,034 - INFO - Dataset loading completed in 1.41s
2024-12-27 20:17:12,034 - INFO - Extracting validation features...
2024-12-27 20:17:12,034 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:15,  1.99it/s]Extracting features:  16%|█▌        | 5/32 [00:00<00:02, 10.36it/s]Extracting features:  34%|███▍      | 11/32 [00:00<00:00, 21.70it/s]Extracting features:  50%|█████     | 16/32 [00:00<00:00, 28.27it/s]Extracting features:  69%|██████▉   | 22/32 [00:00<00:00, 35.49it/s]Extracting features:  88%|████████▊ | 28/32 [00:01<00:00, 40.87it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 27.78it/s]
2024-12-27 20:17:13,189 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:17:13,189 - INFO - Validation feature extraction completed in 1.16s
2024-12-27 20:17:13,190 - INFO - Extracting training features...
2024-12-27 20:17:13,190 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:46,  3.35it/s]Extracting features:   4%|▍         | 6/157 [00:00<00:08, 17.70it/s]Extracting features:   7%|▋         | 11/157 [00:00<00:05, 27.08it/s]Extracting features:  11%|█         | 17/157 [00:00<00:03, 36.14it/s]Extracting features:  14%|█▍        | 22/157 [00:00<00:03, 40.00it/s]Extracting features:  18%|█▊        | 28/157 [00:00<00:02, 44.35it/s]Extracting features:  22%|██▏       | 34/157 [00:00<00:02, 47.40it/s]Extracting features:  25%|██▌       | 40/157 [00:01<00:02, 50.91it/s]Extracting features:  29%|██▉       | 46/157 [00:01<00:02, 51.90it/s]Extracting features:  33%|███▎      | 52/157 [00:01<00:02, 52.41it/s]Extracting features:  37%|███▋      | 58/157 [00:01<00:01, 51.68it/s]Extracting features:  41%|████      | 64/157 [00:01<00:01, 52.33it/s]Extracting features:  45%|████▍     | 70/157 [00:01<00:01, 52.51it/s]Extracting features:  48%|████▊     | 76/157 [00:01<00:01, 51.60it/s]Extracting features:  52%|█████▏    | 82/157 [00:01<00:01, 51.97it/s]Extracting features:  56%|█████▌    | 88/157 [00:01<00:01, 51.43it/s]Extracting features:  60%|█████▉    | 94/157 [00:02<00:01, 52.67it/s]Extracting features:  64%|██████▎   | 100/157 [00:02<00:01, 53.55it/s]Extracting features:  68%|██████▊   | 106/157 [00:02<00:00, 53.74it/s]Extracting features:  71%|███████▏  | 112/157 [00:02<00:00, 51.99it/s]Extracting features:  75%|███████▌  | 118/157 [00:02<00:00, 51.11it/s]Extracting features:  79%|███████▉  | 124/157 [00:02<00:00, 47.94it/s]Extracting features:  83%|████████▎ | 130/157 [00:02<00:00, 49.60it/s]Extracting features:  87%|████████▋ | 136/157 [00:02<00:00, 47.47it/s]Extracting features:  90%|█████████ | 142/157 [00:03<00:00, 50.55it/s]Extracting features:  94%|█████████▍| 148/157 [00:03<00:00, 51.40it/s]Extracting features:  98%|█████████▊| 154/157 [00:03<00:00, 52.39it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 46.15it/s]
2024-12-27 20:17:16,601 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:17:16,601 - INFO - Training feature extraction completed in 3.41s
2024-12-27 20:17:16,602 - INFO - Creating model for classifier: SVM
2024-12-27 20:17:16,602 - INFO - Using device: cuda
2024-12-27 20:17:16,602 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-27 20:17:16,602 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:17:16,602 - INFO - Training set processing completed in 0.00s
2024-12-27 20:17:16,602 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:17:16,603 - INFO - Memory usage at start_fit: CPU 3267.6 MB, GPU 47.3 MB
2024-12-27 20:17:16,603 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:17:16,603 - INFO - Number of unique classes: 100
2024-12-27 20:17:16,702 - INFO - Fitted scaler and transformed data
2024-12-27 20:17:16,702 - INFO - Scaling time: 0.10s
2024-12-27 20:17:16,900 - INFO - Epoch 1/25, Train Loss: 23.6373, Val Loss: 13.7522
2024-12-27 20:17:17,072 - INFO - Epoch 2/25, Train Loss: 2.0861, Val Loss: 13.2028
2024-12-27 20:17:17,260 - INFO - Epoch 3/25, Train Loss: 0.8118, Val Loss: 12.5793
2024-12-27 20:17:17,429 - INFO - Epoch 4/25, Train Loss: 0.3600, Val Loss: 12.3260
2024-12-27 20:17:17,588 - INFO - Epoch 5/25, Train Loss: 0.1605, Val Loss: 12.3830
2024-12-27 20:17:17,760 - INFO - Epoch 6/25, Train Loss: 0.0840, Val Loss: 12.4063
2024-12-27 20:17:17,760 - INFO - Early stopping triggered at epoch 6
2024-12-27 20:17:17,760 - INFO - Training completed in 1.16s
2024-12-27 20:17:17,760 - INFO - Final memory usage: CPU 3292.1 MB, GPU 49.9 MB
2024-12-27 20:17:17,761 - INFO - Model training completed in 1.16s
2024-12-27 20:17:17,767 - INFO - Prediction completed in 0.01s
2024-12-27 20:17:17,777 - INFO - Poison rate 0.0 completed in 1.18s
2024-12-27 20:17:17,777 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:17:17,778 - INFO - Label flipping details:
2024-12-27 20:17:17,778 - INFO - - Source class: 1
2024-12-27 20:17:17,778 - INFO - - Target class: 0
2024-12-27 20:17:17,778 - INFO - - Available samples in source class: 50
2024-12-27 20:17:17,778 - INFO - - Requested samples to poison: 50
2024-12-27 20:17:17,778 - INFO - - Actual samples to flip: 49
2024-12-27 20:17:17,778 - INFO - - Samples remaining in source class: 1
2024-12-27 20:17:17,778 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:17:17,778 - INFO - Total number of labels flipped: 49
2024-12-27 20:17:17,778 - INFO - Label flipping completed in 0.00s
2024-12-27 20:17:17,778 - INFO - Training set processing completed in 0.00s
2024-12-27 20:17:17,778 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:17:17,779 - INFO - Memory usage at start_fit: CPU 3292.1 MB, GPU 49.3 MB
2024-12-27 20:17:17,779 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:17:17,779 - INFO - Number of unique classes: 100
2024-12-27 20:17:17,863 - INFO - Fitted scaler and transformed data
2024-12-27 20:17:17,863 - INFO - Scaling time: 0.08s
2024-12-27 20:17:18,065 - INFO - Epoch 1/25, Train Loss: 23.6047, Val Loss: 14.6315
2024-12-27 20:17:18,237 - INFO - Epoch 2/25, Train Loss: 1.9489, Val Loss: 15.6239
2024-12-27 20:17:18,429 - INFO - Epoch 3/25, Train Loss: 0.7605, Val Loss: 14.5035
2024-12-27 20:17:18,596 - INFO - Epoch 4/25, Train Loss: 0.3349, Val Loss: 14.0758
2024-12-27 20:17:18,782 - INFO - Epoch 5/25, Train Loss: 0.1559, Val Loss: 14.4587
2024-12-27 20:17:18,953 - INFO - Epoch 6/25, Train Loss: 0.0790, Val Loss: 14.6548
2024-12-27 20:17:18,954 - INFO - Early stopping triggered at epoch 6
2024-12-27 20:17:18,954 - INFO - Training completed in 1.18s
2024-12-27 20:17:18,954 - INFO - Final memory usage: CPU 3292.1 MB, GPU 49.9 MB
2024-12-27 20:17:18,954 - INFO - Model training completed in 1.18s
2024-12-27 20:17:18,961 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:17:18,970 - INFO - Poison rate 0.01 completed in 1.19s
2024-12-27 20:17:18,971 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:17:18,971 - INFO - Label flipping details:
2024-12-27 20:17:18,971 - INFO - - Source class: 1
2024-12-27 20:17:18,971 - INFO - - Target class: 0
2024-12-27 20:17:18,971 - INFO - - Available samples in source class: 50
2024-12-27 20:17:18,971 - INFO - - Requested samples to poison: 150
2024-12-27 20:17:18,971 - INFO - - Actual samples to flip: 49
2024-12-27 20:17:18,971 - INFO - - Samples remaining in source class: 1
2024-12-27 20:17:18,971 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:17:18,972 - INFO - Total number of labels flipped: 49
2024-12-27 20:17:18,972 - INFO - Label flipping completed in 0.00s
2024-12-27 20:17:18,972 - INFO - Training set processing completed in 0.00s
2024-12-27 20:17:18,972 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:17:18,973 - INFO - Memory usage at start_fit: CPU 3292.1 MB, GPU 49.3 MB
2024-12-27 20:17:18,973 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:17:18,973 - INFO - Number of unique classes: 100
2024-12-27 20:17:19,068 - INFO - Fitted scaler and transformed data
2024-12-27 20:17:19,068 - INFO - Scaling time: 0.09s
2024-12-27 20:17:19,250 - INFO - Epoch 1/25, Train Loss: 22.3172, Val Loss: 19.9477
2024-12-27 20:17:19,425 - INFO - Epoch 2/25, Train Loss: 2.0147, Val Loss: 18.5469
2024-12-27 20:17:19,597 - INFO - Epoch 3/25, Train Loss: 0.6882, Val Loss: 17.9218
2024-12-27 20:17:19,789 - INFO - Epoch 4/25, Train Loss: 0.2896, Val Loss: 17.8034
2024-12-27 20:17:19,964 - INFO - Epoch 5/25, Train Loss: 0.1340, Val Loss: 17.6141
2024-12-27 20:17:20,159 - INFO - Epoch 6/25, Train Loss: 0.0612, Val Loss: 17.6311
2024-12-27 20:17:20,333 - INFO - Epoch 7/25, Train Loss: 0.0271, Val Loss: 17.6045
2024-12-27 20:17:20,333 - INFO - Early stopping triggered at epoch 7
2024-12-27 20:17:20,333 - INFO - Training completed in 1.36s
2024-12-27 20:17:20,334 - INFO - Final memory usage: CPU 3292.1 MB, GPU 49.9 MB
2024-12-27 20:17:20,334 - INFO - Model training completed in 1.36s
2024-12-27 20:17:20,340 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:17:20,349 - INFO - Poison rate 0.03 completed in 1.38s
2024-12-27 20:17:20,349 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:17:20,350 - INFO - Label flipping details:
2024-12-27 20:17:20,350 - INFO - - Source class: 1
2024-12-27 20:17:20,350 - INFO - - Target class: 0
2024-12-27 20:17:20,350 - INFO - - Available samples in source class: 50
2024-12-27 20:17:20,350 - INFO - - Requested samples to poison: 250
2024-12-27 20:17:20,350 - INFO - - Actual samples to flip: 49
2024-12-27 20:17:20,350 - INFO - - Samples remaining in source class: 1
2024-12-27 20:17:20,350 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:17:20,350 - INFO - Total number of labels flipped: 49
2024-12-27 20:17:20,350 - INFO - Label flipping completed in 0.00s
2024-12-27 20:17:20,350 - INFO - Training set processing completed in 0.00s
2024-12-27 20:17:20,350 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:17:20,351 - INFO - Memory usage at start_fit: CPU 3292.1 MB, GPU 49.3 MB
2024-12-27 20:17:20,351 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:17:20,352 - INFO - Number of unique classes: 100
2024-12-27 20:17:20,439 - INFO - Fitted scaler and transformed data
2024-12-27 20:17:20,439 - INFO - Scaling time: 0.09s
2024-12-27 20:17:20,634 - INFO - Epoch 1/25, Train Loss: 22.6374, Val Loss: 14.4917
2024-12-27 20:17:20,821 - INFO - Epoch 2/25, Train Loss: 2.1828, Val Loss: 15.5474
2024-12-27 20:17:21,000 - INFO - Epoch 3/25, Train Loss: 0.7852, Val Loss: 14.6686
2024-12-27 20:17:21,000 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:17:21,000 - INFO - Training completed in 0.65s
2024-12-27 20:17:21,000 - INFO - Final memory usage: CPU 3292.1 MB, GPU 49.9 MB
2024-12-27 20:17:21,000 - INFO - Model training completed in 0.65s
2024-12-27 20:17:21,007 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:17:21,016 - INFO - Poison rate 0.05 completed in 0.67s
2024-12-27 20:17:21,016 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:17:21,016 - INFO - Label flipping details:
2024-12-27 20:17:21,017 - INFO - - Source class: 1
2024-12-27 20:17:21,017 - INFO - - Target class: 0
2024-12-27 20:17:21,017 - INFO - - Available samples in source class: 50
2024-12-27 20:17:21,017 - INFO - - Requested samples to poison: 350
2024-12-27 20:17:21,017 - INFO - - Actual samples to flip: 49
2024-12-27 20:17:21,017 - INFO - - Samples remaining in source class: 1
2024-12-27 20:17:21,017 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:17:21,017 - INFO - Total number of labels flipped: 49
2024-12-27 20:17:21,017 - INFO - Label flipping completed in 0.00s
2024-12-27 20:17:21,017 - INFO - Training set processing completed in 0.00s
2024-12-27 20:17:21,017 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:17:21,018 - INFO - Memory usage at start_fit: CPU 3292.1 MB, GPU 49.3 MB
2024-12-27 20:17:21,018 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:17:21,019 - INFO - Number of unique classes: 100
2024-12-27 20:17:21,114 - INFO - Fitted scaler and transformed data
2024-12-27 20:17:21,115 - INFO - Scaling time: 0.09s
2024-12-27 20:17:21,314 - INFO - Epoch 1/25, Train Loss: 23.0616, Val Loss: 13.2537
2024-12-27 20:17:21,483 - INFO - Epoch 2/25, Train Loss: 1.9682, Val Loss: 12.6561
2024-12-27 20:17:21,657 - INFO - Epoch 3/25, Train Loss: 0.7188, Val Loss: 11.7210
2024-12-27 20:17:21,836 - INFO - Epoch 4/25, Train Loss: 0.3122, Val Loss: 11.5432
2024-12-27 20:17:22,038 - INFO - Epoch 5/25, Train Loss: 0.1448, Val Loss: 11.5406
2024-12-27 20:17:22,224 - INFO - Epoch 6/25, Train Loss: 0.0854, Val Loss: 11.4558
2024-12-27 20:17:22,410 - INFO - Epoch 7/25, Train Loss: 0.0435, Val Loss: 11.3829
2024-12-27 20:17:22,603 - INFO - Epoch 8/25, Train Loss: 0.0151, Val Loss: 11.3649
2024-12-27 20:17:22,802 - INFO - Epoch 9/25, Train Loss: 0.0082, Val Loss: 11.2397
2024-12-27 20:17:22,992 - INFO - Epoch 10/25, Train Loss: 0.0058, Val Loss: 11.2677
2024-12-27 20:17:23,195 - INFO - Epoch 11/25, Train Loss: 0.0026, Val Loss: 11.3043
2024-12-27 20:17:23,195 - INFO - Early stopping triggered at epoch 11
2024-12-27 20:17:23,195 - INFO - Training completed in 2.18s
2024-12-27 20:17:23,195 - INFO - Final memory usage: CPU 3292.1 MB, GPU 49.9 MB
2024-12-27 20:17:23,195 - INFO - Model training completed in 2.18s
2024-12-27 20:17:23,202 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:17:23,211 - INFO - Poison rate 0.07 completed in 2.20s
2024-12-27 20:17:23,211 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:17:23,212 - INFO - Label flipping details:
2024-12-27 20:17:23,212 - INFO - - Source class: 1
2024-12-27 20:17:23,212 - INFO - - Target class: 0
2024-12-27 20:17:23,212 - INFO - - Available samples in source class: 50
2024-12-27 20:17:23,212 - INFO - - Requested samples to poison: 500
2024-12-27 20:17:23,212 - INFO - - Actual samples to flip: 49
2024-12-27 20:17:23,212 - INFO - - Samples remaining in source class: 1
2024-12-27 20:17:23,212 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:17:23,212 - INFO - Total number of labels flipped: 49
2024-12-27 20:17:23,212 - INFO - Label flipping completed in 0.00s
2024-12-27 20:17:23,212 - INFO - Training set processing completed in 0.00s
2024-12-27 20:17:23,212 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:17:23,213 - INFO - Memory usage at start_fit: CPU 3292.1 MB, GPU 49.3 MB
2024-12-27 20:17:23,213 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:17:23,214 - INFO - Number of unique classes: 100
2024-12-27 20:17:23,309 - INFO - Fitted scaler and transformed data
2024-12-27 20:17:23,310 - INFO - Scaling time: 0.09s
2024-12-27 20:17:23,532 - INFO - Epoch 1/25, Train Loss: 23.3418, Val Loss: 13.8341
2024-12-27 20:17:23,735 - INFO - Epoch 2/25, Train Loss: 2.2492, Val Loss: 13.2742
2024-12-27 20:17:23,939 - INFO - Epoch 3/25, Train Loss: 0.8469, Val Loss: 12.2424
2024-12-27 20:17:24,132 - INFO - Epoch 4/25, Train Loss: 0.3651, Val Loss: 12.1069
2024-12-27 20:17:24,334 - INFO - Epoch 5/25, Train Loss: 0.1593, Val Loss: 12.1942
2024-12-27 20:17:24,542 - INFO - Epoch 6/25, Train Loss: 0.0685, Val Loss: 12.1401
2024-12-27 20:17:24,542 - INFO - Early stopping triggered at epoch 6
2024-12-27 20:17:24,542 - INFO - Training completed in 1.33s
2024-12-27 20:17:24,543 - INFO - Final memory usage: CPU 3292.1 MB, GPU 49.9 MB
2024-12-27 20:17:24,543 - INFO - Model training completed in 1.33s
2024-12-27 20:17:24,551 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:17:24,560 - INFO - Poison rate 0.1 completed in 1.35s
2024-12-27 20:17:24,561 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:17:24,561 - INFO - Label flipping details:
2024-12-27 20:17:24,561 - INFO - - Source class: 1
2024-12-27 20:17:24,561 - INFO - - Target class: 0
2024-12-27 20:17:24,561 - INFO - - Available samples in source class: 50
2024-12-27 20:17:24,561 - INFO - - Requested samples to poison: 1000
2024-12-27 20:17:24,561 - INFO - - Actual samples to flip: 49
2024-12-27 20:17:24,561 - INFO - - Samples remaining in source class: 1
2024-12-27 20:17:24,562 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:17:24,562 - INFO - Total number of labels flipped: 49
2024-12-27 20:17:24,562 - INFO - Label flipping completed in 0.00s
2024-12-27 20:17:24,562 - INFO - Training set processing completed in 0.00s
2024-12-27 20:17:24,562 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:17:24,563 - INFO - Memory usage at start_fit: CPU 3292.1 MB, GPU 49.3 MB
2024-12-27 20:17:24,563 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:17:24,563 - INFO - Number of unique classes: 100
2024-12-27 20:17:24,641 - INFO - Fitted scaler and transformed data
2024-12-27 20:17:24,642 - INFO - Scaling time: 0.08s
2024-12-27 20:17:24,865 - INFO - Epoch 1/25, Train Loss: 21.9568, Val Loss: 20.3276
2024-12-27 20:17:25,074 - INFO - Epoch 2/25, Train Loss: 1.7840, Val Loss: 18.5672
2024-12-27 20:17:25,266 - INFO - Epoch 3/25, Train Loss: 0.6641, Val Loss: 18.4211
2024-12-27 20:17:25,481 - INFO - Epoch 4/25, Train Loss: 0.3223, Val Loss: 18.0668
2024-12-27 20:17:25,693 - INFO - Epoch 5/25, Train Loss: 0.1528, Val Loss: 17.9478
2024-12-27 20:17:25,927 - INFO - Epoch 6/25, Train Loss: 0.0685, Val Loss: 18.1694
2024-12-27 20:17:26,149 - INFO - Epoch 7/25, Train Loss: 0.0412, Val Loss: 18.1390
2024-12-27 20:17:26,149 - INFO - Early stopping triggered at epoch 7
2024-12-27 20:17:26,149 - INFO - Training completed in 1.59s
2024-12-27 20:17:26,149 - INFO - Final memory usage: CPU 3292.1 MB, GPU 49.9 MB
2024-12-27 20:17:26,150 - INFO - Model training completed in 1.59s
2024-12-27 20:17:26,163 - INFO - Prediction completed in 0.01s
2024-12-27 20:17:26,174 - INFO - Poison rate 0.2 completed in 1.61s
2024-12-27 20:17:26,176 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:17:26,176 - INFO - Total evaluation time: 15.56s
2024-12-27 20:17:26,178 - INFO - 
Progress: 52.1% - Evaluating CIFAR100 with SVM (dynadetect mode, iteration 1/1)
2024-12-27 20:17:26,249 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:17:26,322 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:17:26,409 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:17:26,409 - INFO - Dataset type: image
2024-12-27 20:17:26,409 - INFO - Sample size: 5000
2024-12-27 20:17:26,409 - INFO - Using device: cuda
2024-12-27 20:17:26,411 - INFO - Loading datasets...
2024-12-27 20:17:27,801 - INFO - Dataset loading completed in 1.39s
2024-12-27 20:17:27,801 - INFO - Extracting validation features...
2024-12-27 20:17:27,801 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:15,  2.04it/s]Extracting features:  16%|█▌        | 5/32 [00:00<00:02,  9.96it/s]Extracting features:  31%|███▏      | 10/32 [00:00<00:01, 19.18it/s]Extracting features:  50%|█████     | 16/32 [00:00<00:00, 28.29it/s]Extracting features:  69%|██████▉   | 22/32 [00:00<00:00, 35.05it/s]Extracting features:  88%|████████▊ | 28/32 [00:01<00:00, 40.56it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 26.52it/s]
2024-12-27 20:17:29,013 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:17:29,014 - INFO - Validation feature extraction completed in 1.21s
2024-12-27 20:17:29,014 - INFO - Extracting training features...
2024-12-27 20:17:29,015 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:42,  3.69it/s]Extracting features:   4%|▍         | 7/157 [00:00<00:07, 21.22it/s]Extracting features:   8%|▊         | 13/157 [00:00<00:04, 31.78it/s]Extracting features:  12%|█▏        | 19/157 [00:00<00:03, 38.82it/s]Extracting features:  16%|█▌        | 25/157 [00:00<00:02, 44.50it/s]Extracting features:  19%|█▉        | 30/157 [00:00<00:02, 45.89it/s]Extracting features:  23%|██▎       | 36/157 [00:00<00:02, 47.92it/s]Extracting features:  27%|██▋       | 42/157 [00:01<00:02, 50.95it/s]Extracting features:  31%|███       | 48/157 [00:01<00:02, 51.26it/s]Extracting features:  34%|███▍      | 54/157 [00:01<00:01, 52.78it/s]Extracting features:  38%|███▊      | 60/157 [00:01<00:01, 54.34it/s]Extracting features:  42%|████▏     | 66/157 [00:01<00:01, 53.77it/s]Extracting features:  46%|████▌     | 72/157 [00:01<00:01, 52.91it/s]Extracting features:  50%|████▉     | 78/157 [00:01<00:01, 51.87it/s]Extracting features:  54%|█████▎    | 84/157 [00:01<00:01, 48.23it/s]Extracting features:  57%|█████▋    | 90/157 [00:01<00:01, 50.80it/s]Extracting features:  62%|██████▏   | 97/157 [00:02<00:01, 54.17it/s]Extracting features:  66%|██████▌   | 103/157 [00:02<00:01, 51.31it/s]Extracting features:  69%|██████▉   | 109/157 [00:02<00:00, 51.59it/s]Extracting features:  74%|███████▍  | 116/157 [00:02<00:00, 54.01it/s]Extracting features:  78%|███████▊  | 123/157 [00:02<00:00, 55.96it/s]Extracting features:  83%|████████▎ | 130/157 [00:02<00:00, 57.12it/s]Extracting features:  87%|████████▋ | 136/157 [00:02<00:00, 55.42it/s]Extracting features:  90%|█████████ | 142/157 [00:02<00:00, 55.97it/s]Extracting features:  94%|█████████▍| 148/157 [00:03<00:00, 55.90it/s]Extracting features:  99%|█████████▊| 155/157 [00:03<00:00, 57.72it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 49.00it/s]
2024-12-27 20:17:32,234 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:17:32,234 - INFO - Training feature extraction completed in 3.22s
2024-12-27 20:17:32,235 - INFO - Creating model for classifier: SVM
2024-12-27 20:17:32,235 - INFO - Using device: cuda
2024-12-27 20:17:32,235 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-27 20:17:32,235 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:17:32,235 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:17:32,235 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:17:32,835 - INFO - Feature scaling completed in 0.60s
2024-12-27 20:17:32,835 - INFO - Starting feature selection (k=50)
2024-12-27 20:17:32,848 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:17:32,848 - INFO - Starting anomaly detection
2024-12-27 20:17:34,387 - INFO - Anomaly detection completed in 1.54s
2024-12-27 20:17:34,387 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:17:34,387 - INFO - Total fit_transform time: 2.15s
2024-12-27 20:17:34,387 - INFO - Training set processing completed in 2.15s
2024-12-27 20:17:34,387 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:17:34,388 - INFO - Memory usage at start_fit: CPU 3292.9 MB, GPU 47.3 MB
2024-12-27 20:17:34,389 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:17:34,389 - INFO - Number of unique classes: 100
2024-12-27 20:17:34,485 - INFO - Fitted scaler and transformed data
2024-12-27 20:17:34,485 - INFO - Scaling time: 0.09s
2024-12-27 20:17:34,694 - INFO - Epoch 1/25, Train Loss: 20.9734, Val Loss: 16.1896
2024-12-27 20:17:34,852 - INFO - Epoch 2/25, Train Loss: 1.8355, Val Loss: 15.8306
2024-12-27 20:17:35,020 - INFO - Epoch 3/25, Train Loss: 0.6831, Val Loss: 14.9977
2024-12-27 20:17:35,190 - INFO - Epoch 4/25, Train Loss: 0.3029, Val Loss: 14.8095
2024-12-27 20:17:35,366 - INFO - Epoch 5/25, Train Loss: 0.1356, Val Loss: 14.8519
2024-12-27 20:17:35,545 - INFO - Epoch 6/25, Train Loss: 0.0623, Val Loss: 14.8219
2024-12-27 20:17:35,546 - INFO - Early stopping triggered at epoch 6
2024-12-27 20:17:35,546 - INFO - Training completed in 1.16s
2024-12-27 20:17:35,546 - INFO - Final memory usage: CPU 3292.9 MB, GPU 49.9 MB
2024-12-27 20:17:35,546 - INFO - Model training completed in 1.16s
2024-12-27 20:17:35,553 - INFO - Prediction completed in 0.01s
2024-12-27 20:17:35,562 - INFO - Poison rate 0.0 completed in 3.33s
2024-12-27 20:17:35,563 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:17:35,563 - INFO - Label flipping details:
2024-12-27 20:17:35,563 - INFO - - Source class: 1
2024-12-27 20:17:35,563 - INFO - - Target class: 0
2024-12-27 20:17:35,563 - INFO - - Available samples in source class: 50
2024-12-27 20:17:35,563 - INFO - - Requested samples to poison: 50
2024-12-27 20:17:35,563 - INFO - - Actual samples to flip: 49
2024-12-27 20:17:35,563 - INFO - - Samples remaining in source class: 1
2024-12-27 20:17:35,563 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:17:35,563 - INFO - Total number of labels flipped: 49
2024-12-27 20:17:35,564 - INFO - Label flipping completed in 0.00s
2024-12-27 20:17:35,564 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:17:35,564 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:17:36,201 - INFO - Feature scaling completed in 0.64s
2024-12-27 20:17:36,202 - INFO - Starting feature selection (k=50)
2024-12-27 20:17:36,207 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:17:36,207 - INFO - Starting anomaly detection
2024-12-27 20:17:38,208 - INFO - Anomaly detection completed in 2.00s
2024-12-27 20:17:38,208 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:17:38,208 - INFO - Total fit_transform time: 2.64s
2024-12-27 20:17:38,208 - INFO - Training set processing completed in 2.64s
2024-12-27 20:17:38,208 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:17:38,209 - INFO - Memory usage at start_fit: CPU 3292.9 MB, GPU 49.3 MB
2024-12-27 20:17:38,209 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:17:38,210 - INFO - Number of unique classes: 100
2024-12-27 20:17:38,297 - INFO - Fitted scaler and transformed data
2024-12-27 20:17:38,297 - INFO - Scaling time: 0.09s
2024-12-27 20:17:38,487 - INFO - Epoch 1/25, Train Loss: 20.9602, Val Loss: 15.4276
2024-12-27 20:17:38,665 - INFO - Epoch 2/25, Train Loss: 1.8790, Val Loss: 14.0865
2024-12-27 20:17:38,847 - INFO - Epoch 3/25, Train Loss: 0.6716, Val Loss: 13.6460
2024-12-27 20:17:39,013 - INFO - Epoch 4/25, Train Loss: 0.2829, Val Loss: 13.5119
2024-12-27 20:17:39,226 - INFO - Epoch 5/25, Train Loss: 0.1284, Val Loss: 13.2942
2024-12-27 20:17:39,397 - INFO - Epoch 6/25, Train Loss: 0.0695, Val Loss: 13.3001
2024-12-27 20:17:39,575 - INFO - Epoch 7/25, Train Loss: 0.0527, Val Loss: 13.4192
2024-12-27 20:17:39,576 - INFO - Early stopping triggered at epoch 7
2024-12-27 20:17:39,576 - INFO - Training completed in 1.37s
2024-12-27 20:17:39,576 - INFO - Final memory usage: CPU 3292.9 MB, GPU 49.9 MB
2024-12-27 20:17:39,577 - INFO - Model training completed in 1.37s
2024-12-27 20:17:39,586 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:17:39,599 - INFO - Poison rate 0.01 completed in 4.04s
2024-12-27 20:17:39,599 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:17:39,600 - INFO - Label flipping details:
2024-12-27 20:17:39,600 - INFO - - Source class: 1
2024-12-27 20:17:39,600 - INFO - - Target class: 0
2024-12-27 20:17:39,600 - INFO - - Available samples in source class: 50
2024-12-27 20:17:39,600 - INFO - - Requested samples to poison: 150
2024-12-27 20:17:39,600 - INFO - - Actual samples to flip: 49
2024-12-27 20:17:39,600 - INFO - - Samples remaining in source class: 1
2024-12-27 20:17:39,600 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:17:39,600 - INFO - Total number of labels flipped: 49
2024-12-27 20:17:39,600 - INFO - Label flipping completed in 0.00s
2024-12-27 20:17:39,601 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:17:39,601 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:17:40,192 - INFO - Feature scaling completed in 0.59s
2024-12-27 20:17:40,192 - INFO - Starting feature selection (k=50)
2024-12-27 20:17:40,206 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:17:40,206 - INFO - Starting anomaly detection
2024-12-27 20:17:42,135 - INFO - Anomaly detection completed in 1.93s
2024-12-27 20:17:42,135 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:17:42,135 - INFO - Total fit_transform time: 2.53s
2024-12-27 20:17:42,135 - INFO - Training set processing completed in 2.53s
2024-12-27 20:17:42,135 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:17:42,137 - INFO - Memory usage at start_fit: CPU 3292.9 MB, GPU 49.3 MB
2024-12-27 20:17:42,137 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:17:42,137 - INFO - Number of unique classes: 100
2024-12-27 20:17:42,235 - INFO - Fitted scaler and transformed data
2024-12-27 20:17:42,235 - INFO - Scaling time: 0.10s
2024-12-27 20:17:42,433 - INFO - Epoch 1/25, Train Loss: 20.9801, Val Loss: 16.1947
2024-12-27 20:17:42,615 - INFO - Epoch 2/25, Train Loss: 1.7689, Val Loss: 15.7962
2024-12-27 20:17:42,785 - INFO - Epoch 3/25, Train Loss: 0.6571, Val Loss: 15.0780
2024-12-27 20:17:42,946 - INFO - Epoch 4/25, Train Loss: 0.2816, Val Loss: 14.8607
2024-12-27 20:17:43,109 - INFO - Epoch 5/25, Train Loss: 0.1355, Val Loss: 14.7056
2024-12-27 20:17:43,300 - INFO - Epoch 6/25, Train Loss: 0.0614, Val Loss: 14.6918
2024-12-27 20:17:43,494 - INFO - Epoch 7/25, Train Loss: 0.0301, Val Loss: 14.6388
2024-12-27 20:17:43,673 - INFO - Epoch 8/25, Train Loss: 0.0142, Val Loss: 14.6070
2024-12-27 20:17:43,862 - INFO - Epoch 9/25, Train Loss: 0.0080, Val Loss: 14.7523
2024-12-27 20:17:44,046 - INFO - Epoch 10/25, Train Loss: 0.0045, Val Loss: 14.7387
2024-12-27 20:17:44,046 - INFO - Early stopping triggered at epoch 10
2024-12-27 20:17:44,046 - INFO - Training completed in 1.91s
2024-12-27 20:17:44,047 - INFO - Final memory usage: CPU 3292.9 MB, GPU 49.9 MB
2024-12-27 20:17:44,047 - INFO - Model training completed in 1.91s
2024-12-27 20:17:44,055 - INFO - Prediction completed in 0.01s
2024-12-27 20:17:44,065 - INFO - Poison rate 0.03 completed in 4.47s
2024-12-27 20:17:44,065 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:17:44,066 - INFO - Label flipping details:
2024-12-27 20:17:44,066 - INFO - - Source class: 1
2024-12-27 20:17:44,066 - INFO - - Target class: 0
2024-12-27 20:17:44,066 - INFO - - Available samples in source class: 50
2024-12-27 20:17:44,066 - INFO - - Requested samples to poison: 250
2024-12-27 20:17:44,066 - INFO - - Actual samples to flip: 49
2024-12-27 20:17:44,066 - INFO - - Samples remaining in source class: 1
2024-12-27 20:17:44,066 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:17:44,066 - INFO - Total number of labels flipped: 49
2024-12-27 20:17:44,066 - INFO - Label flipping completed in 0.00s
2024-12-27 20:17:44,066 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:17:44,067 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:17:44,721 - INFO - Feature scaling completed in 0.65s
2024-12-27 20:17:44,722 - INFO - Starting feature selection (k=50)
2024-12-27 20:17:44,737 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:17:44,737 - INFO - Starting anomaly detection
2024-12-27 20:17:46,207 - INFO - Anomaly detection completed in 1.47s
2024-12-27 20:17:46,207 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:17:46,208 - INFO - Total fit_transform time: 2.14s
2024-12-27 20:17:46,208 - INFO - Training set processing completed in 2.14s
2024-12-27 20:17:46,208 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:17:46,209 - INFO - Memory usage at start_fit: CPU 3292.9 MB, GPU 49.3 MB
2024-12-27 20:17:46,210 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:17:46,210 - INFO - Number of unique classes: 100
2024-12-27 20:17:46,308 - INFO - Fitted scaler and transformed data
2024-12-27 20:17:46,308 - INFO - Scaling time: 0.09s
2024-12-27 20:17:46,498 - INFO - Epoch 1/25, Train Loss: 20.2550, Val Loss: 19.3174
2024-12-27 20:17:46,685 - INFO - Epoch 2/25, Train Loss: 1.7690, Val Loss: 17.2829
2024-12-27 20:17:46,881 - INFO - Epoch 3/25, Train Loss: 0.6467, Val Loss: 16.4443
2024-12-27 20:17:47,045 - INFO - Epoch 4/25, Train Loss: 0.2796, Val Loss: 16.4576
2024-12-27 20:17:47,231 - INFO - Epoch 5/25, Train Loss: 0.1316, Val Loss: 16.5523
2024-12-27 20:17:47,231 - INFO - Early stopping triggered at epoch 5
2024-12-27 20:17:47,231 - INFO - Training completed in 1.02s
2024-12-27 20:17:47,231 - INFO - Final memory usage: CPU 3292.9 MB, GPU 49.9 MB
2024-12-27 20:17:47,232 - INFO - Model training completed in 1.02s
2024-12-27 20:17:47,238 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:17:47,247 - INFO - Poison rate 0.05 completed in 3.18s
2024-12-27 20:17:47,247 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:17:47,248 - INFO - Label flipping details:
2024-12-27 20:17:47,248 - INFO - - Source class: 1
2024-12-27 20:17:47,248 - INFO - - Target class: 0
2024-12-27 20:17:47,248 - INFO - - Available samples in source class: 50
2024-12-27 20:17:47,248 - INFO - - Requested samples to poison: 350
2024-12-27 20:17:47,248 - INFO - - Actual samples to flip: 49
2024-12-27 20:17:47,248 - INFO - - Samples remaining in source class: 1
2024-12-27 20:17:47,248 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:17:47,248 - INFO - Total number of labels flipped: 49
2024-12-27 20:17:47,248 - INFO - Label flipping completed in 0.00s
2024-12-27 20:17:47,248 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:17:47,248 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:17:47,816 - INFO - Feature scaling completed in 0.57s
2024-12-27 20:17:47,816 - INFO - Starting feature selection (k=50)
2024-12-27 20:17:47,829 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:17:47,829 - INFO - Starting anomaly detection
2024-12-27 20:17:49,760 - INFO - Anomaly detection completed in 1.93s
2024-12-27 20:17:49,760 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:17:49,760 - INFO - Total fit_transform time: 2.51s
2024-12-27 20:17:49,760 - INFO - Training set processing completed in 2.51s
2024-12-27 20:17:49,760 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:17:49,761 - INFO - Memory usage at start_fit: CPU 3292.9 MB, GPU 49.3 MB
2024-12-27 20:17:49,761 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:17:49,762 - INFO - Number of unique classes: 100
2024-12-27 20:17:49,854 - INFO - Fitted scaler and transformed data
2024-12-27 20:17:49,854 - INFO - Scaling time: 0.09s
2024-12-27 20:17:50,045 - INFO - Epoch 1/25, Train Loss: 24.1643, Val Loss: 15.5447
2024-12-27 20:17:50,217 - INFO - Epoch 2/25, Train Loss: 1.9335, Val Loss: 14.6950
2024-12-27 20:17:50,398 - INFO - Epoch 3/25, Train Loss: 0.7035, Val Loss: 14.0025
2024-12-27 20:17:50,607 - INFO - Epoch 4/25, Train Loss: 0.3016, Val Loss: 13.9747
2024-12-27 20:17:50,814 - INFO - Epoch 5/25, Train Loss: 0.1452, Val Loss: 13.9857
2024-12-27 20:17:51,010 - INFO - Epoch 6/25, Train Loss: 0.0696, Val Loss: 13.9788
2024-12-27 20:17:51,010 - INFO - Early stopping triggered at epoch 6
2024-12-27 20:17:51,010 - INFO - Training completed in 1.25s
2024-12-27 20:17:51,011 - INFO - Final memory usage: CPU 3292.9 MB, GPU 49.9 MB
2024-12-27 20:17:51,011 - INFO - Model training completed in 1.25s
2024-12-27 20:17:51,019 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:17:51,028 - INFO - Poison rate 0.07 completed in 3.78s
2024-12-27 20:17:51,028 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:17:51,029 - INFO - Label flipping details:
2024-12-27 20:17:51,029 - INFO - - Source class: 1
2024-12-27 20:17:51,029 - INFO - - Target class: 0
2024-12-27 20:17:51,029 - INFO - - Available samples in source class: 50
2024-12-27 20:17:51,029 - INFO - - Requested samples to poison: 500
2024-12-27 20:17:51,029 - INFO - - Actual samples to flip: 49
2024-12-27 20:17:51,029 - INFO - - Samples remaining in source class: 1
2024-12-27 20:17:51,029 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:17:51,029 - INFO - Total number of labels flipped: 49
2024-12-27 20:17:51,029 - INFO - Label flipping completed in 0.00s
2024-12-27 20:17:51,030 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:17:51,030 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:17:51,597 - INFO - Feature scaling completed in 0.57s
2024-12-27 20:17:51,597 - INFO - Starting feature selection (k=50)
2024-12-27 20:17:51,611 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:17:51,611 - INFO - Starting anomaly detection
2024-12-27 20:17:53,443 - INFO - Anomaly detection completed in 1.83s
2024-12-27 20:17:53,443 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:17:53,443 - INFO - Total fit_transform time: 2.41s
2024-12-27 20:17:53,444 - INFO - Training set processing completed in 2.41s
2024-12-27 20:17:53,444 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:17:53,445 - INFO - Memory usage at start_fit: CPU 3292.9 MB, GPU 49.3 MB
2024-12-27 20:17:53,445 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:17:53,446 - INFO - Number of unique classes: 100
2024-12-27 20:17:53,540 - INFO - Fitted scaler and transformed data
2024-12-27 20:17:53,540 - INFO - Scaling time: 0.09s
2024-12-27 20:17:53,729 - INFO - Epoch 1/25, Train Loss: 21.6338, Val Loss: 13.1164
2024-12-27 20:17:53,892 - INFO - Epoch 2/25, Train Loss: 1.8441, Val Loss: 12.1327
2024-12-27 20:17:54,056 - INFO - Epoch 3/25, Train Loss: 0.6830, Val Loss: 11.5280
2024-12-27 20:17:54,247 - INFO - Epoch 4/25, Train Loss: 0.2966, Val Loss: 11.2362
2024-12-27 20:17:54,439 - INFO - Epoch 5/25, Train Loss: 0.1297, Val Loss: 11.0814
2024-12-27 20:17:54,618 - INFO - Epoch 6/25, Train Loss: 0.0610, Val Loss: 11.2187
2024-12-27 20:17:54,829 - INFO - Epoch 7/25, Train Loss: 0.0291, Val Loss: 11.3417
2024-12-27 20:17:54,829 - INFO - Early stopping triggered at epoch 7
2024-12-27 20:17:54,829 - INFO - Training completed in 1.38s
2024-12-27 20:17:54,829 - INFO - Final memory usage: CPU 3292.9 MB, GPU 49.9 MB
2024-12-27 20:17:54,829 - INFO - Model training completed in 1.39s
2024-12-27 20:17:54,837 - INFO - Prediction completed in 0.01s
2024-12-27 20:17:54,846 - INFO - Poison rate 0.1 completed in 3.82s
2024-12-27 20:17:54,846 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:17:54,847 - INFO - Label flipping details:
2024-12-27 20:17:54,847 - INFO - - Source class: 1
2024-12-27 20:17:54,847 - INFO - - Target class: 0
2024-12-27 20:17:54,847 - INFO - - Available samples in source class: 50
2024-12-27 20:17:54,847 - INFO - - Requested samples to poison: 1000
2024-12-27 20:17:54,847 - INFO - - Actual samples to flip: 49
2024-12-27 20:17:54,847 - INFO - - Samples remaining in source class: 1
2024-12-27 20:17:54,847 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:17:54,847 - INFO - Total number of labels flipped: 49
2024-12-27 20:17:54,847 - INFO - Label flipping completed in 0.00s
2024-12-27 20:17:54,847 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:17:54,847 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:17:55,403 - INFO - Feature scaling completed in 0.56s
2024-12-27 20:17:55,403 - INFO - Starting feature selection (k=50)
2024-12-27 20:17:55,416 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:17:55,417 - INFO - Starting anomaly detection
2024-12-27 20:17:56,612 - INFO - Anomaly detection completed in 1.20s
2024-12-27 20:17:56,612 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:17:56,612 - INFO - Total fit_transform time: 1.76s
2024-12-27 20:17:56,612 - INFO - Training set processing completed in 1.77s
2024-12-27 20:17:56,613 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:17:56,614 - INFO - Memory usage at start_fit: CPU 3292.9 MB, GPU 49.3 MB
2024-12-27 20:17:56,614 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:17:56,614 - INFO - Number of unique classes: 100
2024-12-27 20:17:56,707 - INFO - Fitted scaler and transformed data
2024-12-27 20:17:56,708 - INFO - Scaling time: 0.09s
2024-12-27 20:17:56,898 - INFO - Epoch 1/25, Train Loss: 21.4008, Val Loss: 16.3455
2024-12-27 20:17:57,081 - INFO - Epoch 2/25, Train Loss: 1.7770, Val Loss: 16.8979
2024-12-27 20:17:57,264 - INFO - Epoch 3/25, Train Loss: 0.6012, Val Loss: 16.0094
2024-12-27 20:17:57,440 - INFO - Epoch 4/25, Train Loss: 0.2538, Val Loss: 15.7211
2024-12-27 20:17:57,629 - INFO - Epoch 5/25, Train Loss: 0.1282, Val Loss: 15.8515
2024-12-27 20:17:57,814 - INFO - Epoch 6/25, Train Loss: 0.0585, Val Loss: 15.4093
2024-12-27 20:17:57,987 - INFO - Epoch 7/25, Train Loss: 0.0307, Val Loss: 15.2921
2024-12-27 20:17:58,197 - INFO - Epoch 8/25, Train Loss: 0.0143, Val Loss: 15.0919
2024-12-27 20:17:58,400 - INFO - Epoch 9/25, Train Loss: 0.0100, Val Loss: 15.0156
2024-12-27 20:17:58,593 - INFO - Epoch 10/25, Train Loss: 0.0071, Val Loss: 15.1033
2024-12-27 20:17:58,796 - INFO - Epoch 11/25, Train Loss: 0.0031, Val Loss: 15.0548
2024-12-27 20:17:58,797 - INFO - Early stopping triggered at epoch 11
2024-12-27 20:17:58,797 - INFO - Training completed in 2.18s
2024-12-27 20:17:58,797 - INFO - Final memory usage: CPU 3292.9 MB, GPU 49.9 MB
2024-12-27 20:17:58,797 - INFO - Model training completed in 2.18s
2024-12-27 20:17:58,804 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:17:58,813 - INFO - Poison rate 0.2 completed in 3.97s
2024-12-27 20:17:58,815 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:17:58,815 - INFO - Total evaluation time: 32.40s
2024-12-27 20:17:58,816 - INFO - 
Progress: 53.1% - Evaluating CIFAR100 with LogisticRegression (standard mode, iteration 1/1)
2024-12-27 20:17:58,878 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:17:59,117 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:17:59,200 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:17:59,200 - INFO - Dataset type: image
2024-12-27 20:17:59,200 - INFO - Sample size: 5000
2024-12-27 20:17:59,200 - INFO - Using device: cuda
2024-12-27 20:17:59,202 - INFO - Loading datasets...
2024-12-27 20:18:00,471 - INFO - Dataset loading completed in 1.27s
2024-12-27 20:18:00,471 - INFO - Extracting validation features...
2024-12-27 20:18:00,471 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:17,  1.80it/s]Extracting features:   9%|▉         | 3/32 [00:00<00:05,  5.46it/s]Extracting features:  22%|██▏       | 7/32 [00:00<00:01, 12.78it/s]Extracting features:  41%|████      | 13/32 [00:00<00:00, 23.42it/s]Extracting features:  62%|██████▎   | 20/32 [00:01<00:00, 33.60it/s]Extracting features:  81%|████████▏ | 26/32 [00:01<00:00, 39.34it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 41.68it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 24.50it/s]
2024-12-27 20:18:01,780 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:18:01,781 - INFO - Validation feature extraction completed in 1.31s
2024-12-27 20:18:01,781 - INFO - Extracting training features...
2024-12-27 20:18:01,781 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:47,  3.27it/s]Extracting features:   4%|▍         | 7/157 [00:00<00:07, 20.36it/s]Extracting features:   8%|▊         | 13/157 [00:00<00:04, 30.12it/s]Extracting features:  11%|█▏        | 18/157 [00:00<00:04, 33.22it/s]Extracting features:  15%|█▍        | 23/157 [00:00<00:03, 35.87it/s]Extracting features:  18%|█▊        | 28/157 [00:00<00:03, 36.91it/s]Extracting features:  21%|██        | 33/157 [00:01<00:03, 40.18it/s]Extracting features:  24%|██▍       | 38/157 [00:01<00:02, 42.23it/s]Extracting features:  27%|██▋       | 43/157 [00:01<00:02, 44.17it/s]Extracting features:  31%|███       | 48/157 [00:01<00:02, 45.04it/s]Extracting features:  34%|███▍      | 54/157 [00:01<00:02, 46.32it/s]Extracting features:  38%|███▊      | 60/157 [00:01<00:02, 47.49it/s]Extracting features:  41%|████▏     | 65/157 [00:01<00:01, 46.99it/s]Extracting features:  45%|████▍     | 70/157 [00:01<00:01, 45.32it/s]Extracting features:  48%|████▊     | 76/157 [00:01<00:01, 47.50it/s]Extracting features:  52%|█████▏    | 81/157 [00:02<00:01, 47.89it/s]Extracting features:  55%|█████▌    | 87/157 [00:02<00:01, 49.11it/s]Extracting features:  59%|█████▉    | 93/157 [00:02<00:01, 50.55it/s]Extracting features:  63%|██████▎   | 99/157 [00:02<00:01, 49.26it/s]Extracting features:  66%|██████▌   | 104/157 [00:02<00:01, 47.98it/s]Extracting features:  69%|██████▉   | 109/157 [00:02<00:00, 48.22it/s]Extracting features:  73%|███████▎  | 114/157 [00:02<00:00, 47.83it/s]Extracting features:  76%|███████▋  | 120/157 [00:02<00:00, 49.19it/s]Extracting features:  81%|████████  | 127/157 [00:02<00:00, 52.78it/s]Extracting features:  85%|████████▍ | 133/157 [00:03<00:00, 52.84it/s]Extracting features:  89%|████████▊ | 139/157 [00:03<00:00, 51.92it/s]Extracting features:  92%|█████████▏| 145/157 [00:03<00:00, 52.41it/s]Extracting features:  96%|█████████▌| 151/157 [00:03<00:00, 53.25it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 44.49it/s]
2024-12-27 20:18:05,325 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:18:05,325 - INFO - Training feature extraction completed in 3.54s
2024-12-27 20:18:05,325 - INFO - Creating model for classifier: LogisticRegression
2024-12-27 20:18:05,325 - INFO - Using device: cuda
2024-12-27 20:18:05,326 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:18:05,326 - INFO - Training set processing completed in 0.00s
2024-12-27 20:18:05,326 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:18:05,327 - INFO - Memory usage at start_fit: CPU 3269.2 MB, GPU 47.3 MB
2024-12-27 20:18:05,328 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:18:05,329 - INFO - Number of unique classes: 100
2024-12-27 20:18:05,431 - INFO - Fitted scaler and transformed data
2024-12-27 20:18:05,431 - INFO - Scaling time: 0.10s
2024-12-27 20:18:05,600 - INFO - Epoch 1/200, Train Loss: 2.6699, Val Loss: 2.2552
2024-12-27 20:18:05,770 - INFO - Epoch 2/200, Train Loss: 0.5020, Val Loss: 2.4241
2024-12-27 20:18:05,931 - INFO - Epoch 3/200, Train Loss: 0.1684, Val Loss: 2.3436
2024-12-27 20:18:05,931 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:18:05,931 - INFO - Training completed in 0.60s
2024-12-27 20:18:05,932 - INFO - Final memory usage: CPU 3293.7 MB, GPU 49.9 MB
2024-12-27 20:18:05,932 - INFO - Model training completed in 0.61s
2024-12-27 20:18:05,945 - INFO - Prediction completed in 0.01s
2024-12-27 20:18:05,963 - INFO - Poison rate 0.0 completed in 0.64s
2024-12-27 20:18:05,963 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:18:05,964 - INFO - Label flipping details:
2024-12-27 20:18:05,964 - INFO - - Source class: 1
2024-12-27 20:18:05,964 - INFO - - Target class: 0
2024-12-27 20:18:05,964 - INFO - - Available samples in source class: 50
2024-12-27 20:18:05,964 - INFO - - Requested samples to poison: 50
2024-12-27 20:18:05,964 - INFO - - Actual samples to flip: 49
2024-12-27 20:18:05,964 - INFO - - Samples remaining in source class: 1
2024-12-27 20:18:05,964 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:18:05,964 - INFO - Total number of labels flipped: 49
2024-12-27 20:18:05,964 - INFO - Label flipping completed in 0.00s
2024-12-27 20:18:05,964 - INFO - Training set processing completed in 0.00s
2024-12-27 20:18:05,965 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:18:05,965 - INFO - Memory usage at start_fit: CPU 3293.7 MB, GPU 49.3 MB
2024-12-27 20:18:05,965 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:18:05,966 - INFO - Number of unique classes: 100
2024-12-27 20:18:06,050 - INFO - Fitted scaler and transformed data
2024-12-27 20:18:06,050 - INFO - Scaling time: 0.08s
2024-12-27 20:18:06,211 - INFO - Epoch 1/200, Train Loss: 2.5793, Val Loss: 2.6338
2024-12-27 20:18:06,356 - INFO - Epoch 2/200, Train Loss: 0.5066, Val Loss: 2.5406
2024-12-27 20:18:06,551 - INFO - Epoch 3/200, Train Loss: 0.1769, Val Loss: 2.6697
2024-12-27 20:18:06,718 - INFO - Epoch 4/200, Train Loss: 0.0855, Val Loss: 2.7404
2024-12-27 20:18:06,719 - INFO - Early stopping triggered at epoch 4
2024-12-27 20:18:06,719 - INFO - Training completed in 0.75s
2024-12-27 20:18:06,719 - INFO - Final memory usage: CPU 3293.7 MB, GPU 49.9 MB
2024-12-27 20:18:06,719 - INFO - Model training completed in 0.75s
2024-12-27 20:18:06,732 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:18:06,749 - INFO - Poison rate 0.01 completed in 0.79s
2024-12-27 20:18:06,749 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:18:06,750 - INFO - Label flipping details:
2024-12-27 20:18:06,750 - INFO - - Source class: 1
2024-12-27 20:18:06,750 - INFO - - Target class: 0
2024-12-27 20:18:06,750 - INFO - - Available samples in source class: 50
2024-12-27 20:18:06,750 - INFO - - Requested samples to poison: 150
2024-12-27 20:18:06,750 - INFO - - Actual samples to flip: 49
2024-12-27 20:18:06,750 - INFO - - Samples remaining in source class: 1
2024-12-27 20:18:06,750 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:18:06,750 - INFO - Total number of labels flipped: 49
2024-12-27 20:18:06,751 - INFO - Label flipping completed in 0.00s
2024-12-27 20:18:06,751 - INFO - Training set processing completed in 0.00s
2024-12-27 20:18:06,751 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:18:06,752 - INFO - Memory usage at start_fit: CPU 3293.7 MB, GPU 49.3 MB
2024-12-27 20:18:06,752 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:18:06,752 - INFO - Number of unique classes: 100
2024-12-27 20:18:06,853 - INFO - Fitted scaler and transformed data
2024-12-27 20:18:06,853 - INFO - Scaling time: 0.10s
2024-12-27 20:18:07,041 - INFO - Epoch 1/200, Train Loss: 2.5942, Val Loss: 2.3830
2024-12-27 20:18:07,254 - INFO - Epoch 2/200, Train Loss: 0.5049, Val Loss: 2.6098
2024-12-27 20:18:07,464 - INFO - Epoch 3/200, Train Loss: 0.1422, Val Loss: 2.6020
2024-12-27 20:18:07,465 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:18:07,465 - INFO - Training completed in 0.71s
2024-12-27 20:18:07,465 - INFO - Final memory usage: CPU 3293.7 MB, GPU 49.9 MB
2024-12-27 20:18:07,465 - INFO - Model training completed in 0.71s
2024-12-27 20:18:07,480 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:18:07,499 - INFO - Poison rate 0.03 completed in 0.75s
2024-12-27 20:18:07,499 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:18:07,500 - INFO - Label flipping details:
2024-12-27 20:18:07,500 - INFO - - Source class: 1
2024-12-27 20:18:07,500 - INFO - - Target class: 0
2024-12-27 20:18:07,500 - INFO - - Available samples in source class: 50
2024-12-27 20:18:07,500 - INFO - - Requested samples to poison: 250
2024-12-27 20:18:07,500 - INFO - - Actual samples to flip: 49
2024-12-27 20:18:07,500 - INFO - - Samples remaining in source class: 1
2024-12-27 20:18:07,501 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:18:07,501 - INFO - Total number of labels flipped: 49
2024-12-27 20:18:07,501 - INFO - Label flipping completed in 0.00s
2024-12-27 20:18:07,501 - INFO - Training set processing completed in 0.00s
2024-12-27 20:18:07,501 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:18:07,502 - INFO - Memory usage at start_fit: CPU 3293.7 MB, GPU 49.3 MB
2024-12-27 20:18:07,503 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:18:07,503 - INFO - Number of unique classes: 100
2024-12-27 20:18:07,587 - INFO - Fitted scaler and transformed data
2024-12-27 20:18:07,588 - INFO - Scaling time: 0.08s
2024-12-27 20:18:07,771 - INFO - Epoch 1/200, Train Loss: 2.6455, Val Loss: 2.4818
2024-12-27 20:18:07,990 - INFO - Epoch 2/200, Train Loss: 0.5122, Val Loss: 2.6518
2024-12-27 20:18:08,209 - INFO - Epoch 3/200, Train Loss: 0.1546, Val Loss: 2.6677
2024-12-27 20:18:08,209 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:18:08,210 - INFO - Training completed in 0.71s
2024-12-27 20:18:08,210 - INFO - Final memory usage: CPU 3293.7 MB, GPU 49.9 MB
2024-12-27 20:18:08,211 - INFO - Model training completed in 0.71s
2024-12-27 20:18:08,219 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:18:08,229 - INFO - Poison rate 0.05 completed in 0.73s
2024-12-27 20:18:08,229 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:18:08,230 - INFO - Label flipping details:
2024-12-27 20:18:08,230 - INFO - - Source class: 1
2024-12-27 20:18:08,230 - INFO - - Target class: 0
2024-12-27 20:18:08,230 - INFO - - Available samples in source class: 50
2024-12-27 20:18:08,230 - INFO - - Requested samples to poison: 350
2024-12-27 20:18:08,230 - INFO - - Actual samples to flip: 49
2024-12-27 20:18:08,230 - INFO - - Samples remaining in source class: 1
2024-12-27 20:18:08,230 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:18:08,230 - INFO - Total number of labels flipped: 49
2024-12-27 20:18:08,230 - INFO - Label flipping completed in 0.00s
2024-12-27 20:18:08,230 - INFO - Training set processing completed in 0.00s
2024-12-27 20:18:08,230 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:18:08,232 - INFO - Memory usage at start_fit: CPU 3293.7 MB, GPU 49.3 MB
2024-12-27 20:18:08,232 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:18:08,233 - INFO - Number of unique classes: 100
2024-12-27 20:18:08,335 - INFO - Fitted scaler and transformed data
2024-12-27 20:18:08,335 - INFO - Scaling time: 0.10s
2024-12-27 20:18:08,496 - INFO - Epoch 1/200, Train Loss: 2.6570, Val Loss: 2.9284
2024-12-27 20:18:08,694 - INFO - Epoch 2/200, Train Loss: 0.5327, Val Loss: 2.7984
2024-12-27 20:18:08,872 - INFO - Epoch 3/200, Train Loss: 0.1488, Val Loss: 2.8540
2024-12-27 20:18:09,052 - INFO - Epoch 4/200, Train Loss: 0.0712, Val Loss: 3.0470
2024-12-27 20:18:09,052 - INFO - Early stopping triggered at epoch 4
2024-12-27 20:18:09,052 - INFO - Training completed in 0.82s
2024-12-27 20:18:09,053 - INFO - Final memory usage: CPU 3293.7 MB, GPU 49.9 MB
2024-12-27 20:18:09,053 - INFO - Model training completed in 0.82s
2024-12-27 20:18:09,068 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:18:09,087 - INFO - Poison rate 0.07 completed in 0.86s
2024-12-27 20:18:09,087 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:18:09,088 - INFO - Label flipping details:
2024-12-27 20:18:09,088 - INFO - - Source class: 1
2024-12-27 20:18:09,088 - INFO - - Target class: 0
2024-12-27 20:18:09,088 - INFO - - Available samples in source class: 50
2024-12-27 20:18:09,088 - INFO - - Requested samples to poison: 500
2024-12-27 20:18:09,088 - INFO - - Actual samples to flip: 49
2024-12-27 20:18:09,088 - INFO - - Samples remaining in source class: 1
2024-12-27 20:18:09,089 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:18:09,089 - INFO - Total number of labels flipped: 49
2024-12-27 20:18:09,089 - INFO - Label flipping completed in 0.00s
2024-12-27 20:18:09,089 - INFO - Training set processing completed in 0.00s
2024-12-27 20:18:09,089 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:18:09,090 - INFO - Memory usage at start_fit: CPU 3293.7 MB, GPU 49.3 MB
2024-12-27 20:18:09,091 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:18:09,091 - INFO - Number of unique classes: 100
2024-12-27 20:18:09,198 - INFO - Fitted scaler and transformed data
2024-12-27 20:18:09,199 - INFO - Scaling time: 0.10s
2024-12-27 20:18:09,405 - INFO - Epoch 1/200, Train Loss: 2.6284, Val Loss: 2.8353
2024-12-27 20:18:09,573 - INFO - Epoch 2/200, Train Loss: 0.4982, Val Loss: 2.9729
2024-12-27 20:18:09,768 - INFO - Epoch 3/200, Train Loss: 0.1417, Val Loss: 2.8066
2024-12-27 20:18:09,973 - INFO - Epoch 4/200, Train Loss: 0.0702, Val Loss: 2.9751
2024-12-27 20:18:10,158 - INFO - Epoch 5/200, Train Loss: 0.0470, Val Loss: 2.9665
2024-12-27 20:18:10,159 - INFO - Early stopping triggered at epoch 5
2024-12-27 20:18:10,159 - INFO - Training completed in 1.07s
2024-12-27 20:18:10,159 - INFO - Final memory usage: CPU 3293.7 MB, GPU 49.9 MB
2024-12-27 20:18:10,159 - INFO - Model training completed in 1.07s
2024-12-27 20:18:10,175 - INFO - Prediction completed in 0.02s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:18:10,190 - INFO - Poison rate 0.1 completed in 1.10s
2024-12-27 20:18:10,190 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:18:10,190 - INFO - Label flipping details:
2024-12-27 20:18:10,190 - INFO - - Source class: 1
2024-12-27 20:18:10,190 - INFO - - Target class: 0
2024-12-27 20:18:10,190 - INFO - - Available samples in source class: 50
2024-12-27 20:18:10,190 - INFO - - Requested samples to poison: 1000
2024-12-27 20:18:10,191 - INFO - - Actual samples to flip: 49
2024-12-27 20:18:10,191 - INFO - - Samples remaining in source class: 1
2024-12-27 20:18:10,191 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:18:10,191 - INFO - Total number of labels flipped: 49
2024-12-27 20:18:10,191 - INFO - Label flipping completed in 0.00s
2024-12-27 20:18:10,191 - INFO - Training set processing completed in 0.00s
2024-12-27 20:18:10,191 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:18:10,192 - INFO - Memory usage at start_fit: CPU 3293.7 MB, GPU 49.3 MB
2024-12-27 20:18:10,192 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:18:10,192 - INFO - Number of unique classes: 100
2024-12-27 20:18:10,274 - INFO - Fitted scaler and transformed data
2024-12-27 20:18:10,275 - INFO - Scaling time: 0.08s
2024-12-27 20:18:10,464 - INFO - Epoch 1/200, Train Loss: 2.6959, Val Loss: 2.3091
2024-12-27 20:18:10,684 - INFO - Epoch 2/200, Train Loss: 0.5822, Val Loss: 2.5100
2024-12-27 20:18:10,849 - INFO - Epoch 3/200, Train Loss: 0.1762, Val Loss: 2.5996
2024-12-27 20:18:10,849 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:18:10,849 - INFO - Training completed in 0.66s
2024-12-27 20:18:10,850 - INFO - Final memory usage: CPU 3293.7 MB, GPU 49.9 MB
2024-12-27 20:18:10,850 - INFO - Model training completed in 0.66s
2024-12-27 20:18:10,857 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:18:10,874 - INFO - Poison rate 0.2 completed in 0.68s
2024-12-27 20:18:10,876 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:18:10,877 - INFO - Total evaluation time: 11.67s
2024-12-27 20:18:10,878 - INFO - 
Progress: 54.2% - Evaluating CIFAR100 with LogisticRegression (dynadetect mode, iteration 1/1)
2024-12-27 20:18:10,941 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:18:11,016 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:18:11,077 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:18:11,077 - INFO - Dataset type: image
2024-12-27 20:18:11,077 - INFO - Sample size: 5000
2024-12-27 20:18:11,077 - INFO - Using device: cuda
2024-12-27 20:18:11,079 - INFO - Loading datasets...
2024-12-27 20:18:12,338 - INFO - Dataset loading completed in 1.26s
2024-12-27 20:18:12,338 - INFO - Extracting validation features...
2024-12-27 20:18:12,338 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:12,  2.48it/s]Extracting features:   6%|▋         | 2/32 [00:00<00:07,  4.15it/s]Extracting features:  22%|██▏       | 7/32 [00:00<00:01, 15.89it/s]Extracting features:  41%|████      | 13/32 [00:00<00:00, 27.32it/s]Extracting features:  59%|█████▉    | 19/32 [00:00<00:00, 34.79it/s]Extracting features:  75%|███████▌  | 24/32 [00:00<00:00, 38.89it/s]Extracting features:  91%|█████████ | 29/32 [00:01<00:00, 40.47it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 26.98it/s]
2024-12-27 20:18:13,530 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:18:13,531 - INFO - Validation feature extraction completed in 1.19s
2024-12-27 20:18:13,531 - INFO - Extracting training features...
2024-12-27 20:18:13,531 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:45,  3.42it/s]Extracting features:   4%|▍         | 6/157 [00:00<00:08, 18.63it/s]Extracting features:   8%|▊         | 13/157 [00:00<00:04, 33.71it/s]Extracting features:  11%|█▏        | 18/157 [00:00<00:03, 37.82it/s]Extracting features:  15%|█▍        | 23/157 [00:00<00:03, 40.64it/s]Extracting features:  18%|█▊        | 29/157 [00:00<00:02, 46.05it/s]Extracting features:  22%|██▏       | 35/157 [00:00<00:02, 45.85it/s]Extracting features:  26%|██▌       | 41/157 [00:01<00:02, 49.50it/s]Extracting features:  30%|██▉       | 47/157 [00:01<00:02, 49.82it/s]Extracting features:  34%|███▍      | 53/157 [00:01<00:02, 50.03it/s]Extracting features:  38%|███▊      | 59/157 [00:01<00:01, 50.77it/s]Extracting features:  41%|████▏     | 65/157 [00:01<00:01, 49.19it/s]Extracting features:  45%|████▌     | 71/157 [00:01<00:01, 50.82it/s]Extracting features:  49%|████▉     | 77/157 [00:01<00:01, 45.12it/s]Extracting features:  52%|█████▏    | 82/157 [00:01<00:01, 45.07it/s]Extracting features:  55%|█████▌    | 87/157 [00:02<00:01, 45.14it/s]Extracting features:  59%|█████▊    | 92/157 [00:02<00:01, 45.47it/s]Extracting features:  62%|██████▏   | 98/157 [00:02<00:01, 47.22it/s]Extracting features:  66%|██████▌   | 104/157 [00:02<00:01, 47.16it/s]Extracting features:  69%|██████▉   | 109/157 [00:02<00:01, 47.75it/s]Extracting features:  73%|███████▎  | 114/157 [00:02<00:00, 46.50it/s]Extracting features:  76%|███████▌  | 119/157 [00:02<00:00, 42.99it/s]Extracting features:  79%|███████▉  | 124/157 [00:02<00:00, 43.82it/s]Extracting features:  82%|████████▏ | 129/157 [00:02<00:00, 41.00it/s]Extracting features:  85%|████████▌ | 134/157 [00:03<00:00, 39.88it/s]Extracting features:  89%|████████▉ | 140/157 [00:03<00:00, 44.74it/s]Extracting features:  92%|█████████▏| 145/157 [00:03<00:00, 43.31it/s]Extracting features:  96%|█████████▌| 150/157 [00:03<00:00, 43.57it/s]Extracting features:  99%|█████████▊| 155/157 [00:03<00:00, 42.54it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 42.44it/s]
2024-12-27 20:18:17,249 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:18:17,250 - INFO - Training feature extraction completed in 3.72s
2024-12-27 20:18:17,250 - INFO - Creating model for classifier: LogisticRegression
2024-12-27 20:18:17,250 - INFO - Using device: cuda
2024-12-27 20:18:17,250 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:18:17,250 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:18:17,250 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:18:17,821 - INFO - Feature scaling completed in 0.57s
2024-12-27 20:18:17,822 - INFO - Starting feature selection (k=50)
2024-12-27 20:18:17,827 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:18:17,827 - INFO - Starting anomaly detection
2024-12-27 20:18:19,257 - INFO - Anomaly detection completed in 1.43s
2024-12-27 20:18:19,257 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:18:19,257 - INFO - Total fit_transform time: 2.01s
2024-12-27 20:18:19,257 - INFO - Training set processing completed in 2.01s
2024-12-27 20:18:19,257 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:18:19,259 - INFO - Memory usage at start_fit: CPU 3290.9 MB, GPU 47.3 MB
2024-12-27 20:18:19,259 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:18:19,260 - INFO - Number of unique classes: 100
2024-12-27 20:18:19,357 - INFO - Fitted scaler and transformed data
2024-12-27 20:18:19,357 - INFO - Scaling time: 0.09s
2024-12-27 20:18:19,503 - INFO - Epoch 1/200, Train Loss: 2.6233, Val Loss: 2.6200
2024-12-27 20:18:19,696 - INFO - Epoch 2/200, Train Loss: 0.5509, Val Loss: 2.7364
2024-12-27 20:18:19,855 - INFO - Epoch 3/200, Train Loss: 0.1784, Val Loss: 2.7753
2024-12-27 20:18:19,856 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:18:19,856 - INFO - Training completed in 0.60s
2024-12-27 20:18:19,856 - INFO - Final memory usage: CPU 3290.9 MB, GPU 49.9 MB
2024-12-27 20:18:19,856 - INFO - Model training completed in 0.60s
2024-12-27 20:18:19,875 - INFO - Prediction completed in 0.02s
2024-12-27 20:18:19,890 - INFO - Poison rate 0.0 completed in 2.64s
2024-12-27 20:18:19,890 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:18:19,890 - INFO - Label flipping details:
2024-12-27 20:18:19,890 - INFO - - Source class: 1
2024-12-27 20:18:19,891 - INFO - - Target class: 0
2024-12-27 20:18:19,891 - INFO - - Available samples in source class: 50
2024-12-27 20:18:19,891 - INFO - - Requested samples to poison: 50
2024-12-27 20:18:19,891 - INFO - - Actual samples to flip: 49
2024-12-27 20:18:19,891 - INFO - - Samples remaining in source class: 1
2024-12-27 20:18:19,891 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:18:19,891 - INFO - Total number of labels flipped: 49
2024-12-27 20:18:19,891 - INFO - Label flipping completed in 0.00s
2024-12-27 20:18:19,891 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:18:19,891 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:18:20,485 - INFO - Feature scaling completed in 0.59s
2024-12-27 20:18:20,485 - INFO - Starting feature selection (k=50)
2024-12-27 20:18:20,491 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:18:20,491 - INFO - Starting anomaly detection
2024-12-27 20:18:21,996 - INFO - Anomaly detection completed in 1.50s
2024-12-27 20:18:21,996 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:18:21,996 - INFO - Total fit_transform time: 2.11s
2024-12-27 20:18:21,996 - INFO - Training set processing completed in 2.11s
2024-12-27 20:18:21,996 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:18:21,997 - INFO - Memory usage at start_fit: CPU 3290.9 MB, GPU 49.3 MB
2024-12-27 20:18:21,997 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:18:21,998 - INFO - Number of unique classes: 100
2024-12-27 20:18:22,098 - INFO - Fitted scaler and transformed data
2024-12-27 20:18:22,098 - INFO - Scaling time: 0.10s
2024-12-27 20:18:22,233 - INFO - Epoch 1/200, Train Loss: 2.7328, Val Loss: 2.6242
2024-12-27 20:18:22,348 - INFO - Epoch 2/200, Train Loss: 0.5166, Val Loss: 2.8581
2024-12-27 20:18:22,467 - INFO - Epoch 3/200, Train Loss: 0.1408, Val Loss: 2.8568
2024-12-27 20:18:22,467 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:18:22,467 - INFO - Training completed in 0.47s
2024-12-27 20:18:22,468 - INFO - Final memory usage: CPU 3290.9 MB, GPU 49.9 MB
2024-12-27 20:18:22,468 - INFO - Model training completed in 0.47s
2024-12-27 20:18:22,481 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:18:22,501 - INFO - Poison rate 0.01 completed in 2.61s
2024-12-27 20:18:22,501 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:18:22,502 - INFO - Label flipping details:
2024-12-27 20:18:22,502 - INFO - - Source class: 1
2024-12-27 20:18:22,502 - INFO - - Target class: 0
2024-12-27 20:18:22,502 - INFO - - Available samples in source class: 50
2024-12-27 20:18:22,502 - INFO - - Requested samples to poison: 150
2024-12-27 20:18:22,503 - INFO - - Actual samples to flip: 49
2024-12-27 20:18:22,503 - INFO - - Samples remaining in source class: 1
2024-12-27 20:18:22,503 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:18:22,503 - INFO - Total number of labels flipped: 49
2024-12-27 20:18:22,503 - INFO - Label flipping completed in 0.00s
2024-12-27 20:18:22,503 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:18:22,503 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:18:23,061 - INFO - Feature scaling completed in 0.56s
2024-12-27 20:18:23,061 - INFO - Starting feature selection (k=50)
2024-12-27 20:18:23,067 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:18:23,067 - INFO - Starting anomaly detection
2024-12-27 20:18:24,993 - INFO - Anomaly detection completed in 1.93s
2024-12-27 20:18:24,993 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:18:24,994 - INFO - Total fit_transform time: 2.49s
2024-12-27 20:18:24,994 - INFO - Training set processing completed in 2.49s
2024-12-27 20:18:24,994 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:18:24,995 - INFO - Memory usage at start_fit: CPU 3290.9 MB, GPU 49.3 MB
2024-12-27 20:18:24,995 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:18:24,996 - INFO - Number of unique classes: 100
2024-12-27 20:18:25,103 - INFO - Fitted scaler and transformed data
2024-12-27 20:18:25,103 - INFO - Scaling time: 0.10s
2024-12-27 20:18:25,325 - INFO - Epoch 1/200, Train Loss: 2.6916, Val Loss: 2.5223
2024-12-27 20:18:25,540 - INFO - Epoch 2/200, Train Loss: 0.5089, Val Loss: 2.6750
2024-12-27 20:18:25,701 - INFO - Epoch 3/200, Train Loss: 0.1410, Val Loss: 2.6358
2024-12-27 20:18:25,701 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:18:25,701 - INFO - Training completed in 0.71s
2024-12-27 20:18:25,701 - INFO - Final memory usage: CPU 3290.9 MB, GPU 49.9 MB
2024-12-27 20:18:25,702 - INFO - Model training completed in 0.71s
2024-12-27 20:18:25,718 - INFO - Prediction completed in 0.02s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:18:25,732 - INFO - Poison rate 0.03 completed in 3.23s
2024-12-27 20:18:25,732 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:18:25,732 - INFO - Label flipping details:
2024-12-27 20:18:25,732 - INFO - - Source class: 1
2024-12-27 20:18:25,732 - INFO - - Target class: 0
2024-12-27 20:18:25,732 - INFO - - Available samples in source class: 50
2024-12-27 20:18:25,732 - INFO - - Requested samples to poison: 250
2024-12-27 20:18:25,732 - INFO - - Actual samples to flip: 49
2024-12-27 20:18:25,733 - INFO - - Samples remaining in source class: 1
2024-12-27 20:18:25,733 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:18:25,733 - INFO - Total number of labels flipped: 49
2024-12-27 20:18:25,733 - INFO - Label flipping completed in 0.00s
2024-12-27 20:18:25,733 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:18:25,733 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:18:26,414 - INFO - Feature scaling completed in 0.68s
2024-12-27 20:18:26,414 - INFO - Starting feature selection (k=50)
2024-12-27 20:18:26,427 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:18:26,428 - INFO - Starting anomaly detection
2024-12-27 20:18:28,345 - INFO - Anomaly detection completed in 1.92s
2024-12-27 20:18:28,345 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:18:28,345 - INFO - Total fit_transform time: 2.61s
2024-12-27 20:18:28,345 - INFO - Training set processing completed in 2.61s
2024-12-27 20:18:28,345 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:18:28,346 - INFO - Memory usage at start_fit: CPU 3290.9 MB, GPU 49.3 MB
2024-12-27 20:18:28,347 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:18:28,348 - INFO - Number of unique classes: 100
2024-12-27 20:18:28,444 - INFO - Fitted scaler and transformed data
2024-12-27 20:18:28,445 - INFO - Scaling time: 0.09s
2024-12-27 20:18:28,624 - INFO - Epoch 1/200, Train Loss: 2.7102, Val Loss: 2.4666
2024-12-27 20:18:28,782 - INFO - Epoch 2/200, Train Loss: 0.5185, Val Loss: 2.5592
2024-12-27 20:18:28,976 - INFO - Epoch 3/200, Train Loss: 0.1720, Val Loss: 2.5698
2024-12-27 20:18:28,976 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:18:28,977 - INFO - Training completed in 0.63s
2024-12-27 20:18:28,977 - INFO - Final memory usage: CPU 3290.9 MB, GPU 49.9 MB
2024-12-27 20:18:28,978 - INFO - Model training completed in 0.63s
2024-12-27 20:18:28,993 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:18:29,011 - INFO - Poison rate 0.05 completed in 3.28s
2024-12-27 20:18:29,011 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:18:29,012 - INFO - Label flipping details:
2024-12-27 20:18:29,012 - INFO - - Source class: 1
2024-12-27 20:18:29,012 - INFO - - Target class: 0
2024-12-27 20:18:29,012 - INFO - - Available samples in source class: 50
2024-12-27 20:18:29,012 - INFO - - Requested samples to poison: 350
2024-12-27 20:18:29,012 - INFO - - Actual samples to flip: 49
2024-12-27 20:18:29,012 - INFO - - Samples remaining in source class: 1
2024-12-27 20:18:29,012 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:18:29,012 - INFO - Total number of labels flipped: 49
2024-12-27 20:18:29,012 - INFO - Label flipping completed in 0.00s
2024-12-27 20:18:29,012 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:18:29,012 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:18:29,571 - INFO - Feature scaling completed in 0.56s
2024-12-27 20:18:29,572 - INFO - Starting feature selection (k=50)
2024-12-27 20:18:29,585 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:18:29,585 - INFO - Starting anomaly detection
2024-12-27 20:18:30,949 - INFO - Anomaly detection completed in 1.36s
2024-12-27 20:18:30,949 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:18:30,949 - INFO - Total fit_transform time: 1.94s
2024-12-27 20:18:30,949 - INFO - Training set processing completed in 1.94s
2024-12-27 20:18:30,949 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:18:30,950 - INFO - Memory usage at start_fit: CPU 3290.9 MB, GPU 49.3 MB
2024-12-27 20:18:30,951 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:18:30,951 - INFO - Number of unique classes: 100
2024-12-27 20:18:31,059 - INFO - Fitted scaler and transformed data
2024-12-27 20:18:31,059 - INFO - Scaling time: 0.10s
2024-12-27 20:18:31,208 - INFO - Epoch 1/200, Train Loss: 2.7001, Val Loss: 2.5193
2024-12-27 20:18:31,379 - INFO - Epoch 2/200, Train Loss: 0.4941, Val Loss: 2.7124
2024-12-27 20:18:31,546 - INFO - Epoch 3/200, Train Loss: 0.1366, Val Loss: 2.6768
2024-12-27 20:18:31,547 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:18:31,547 - INFO - Training completed in 0.60s
2024-12-27 20:18:31,548 - INFO - Final memory usage: CPU 3290.9 MB, GPU 49.9 MB
2024-12-27 20:18:31,548 - INFO - Model training completed in 0.60s
2024-12-27 20:18:31,563 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:18:31,575 - INFO - Poison rate 0.07 completed in 2.56s
2024-12-27 20:18:31,575 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:18:31,576 - INFO - Label flipping details:
2024-12-27 20:18:31,576 - INFO - - Source class: 1
2024-12-27 20:18:31,576 - INFO - - Target class: 0
2024-12-27 20:18:31,576 - INFO - - Available samples in source class: 50
2024-12-27 20:18:31,576 - INFO - - Requested samples to poison: 500
2024-12-27 20:18:31,576 - INFO - - Actual samples to flip: 49
2024-12-27 20:18:31,576 - INFO - - Samples remaining in source class: 1
2024-12-27 20:18:31,576 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:18:31,576 - INFO - Total number of labels flipped: 49
2024-12-27 20:18:31,576 - INFO - Label flipping completed in 0.00s
2024-12-27 20:18:31,576 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:18:31,577 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:18:32,129 - INFO - Feature scaling completed in 0.55s
2024-12-27 20:18:32,129 - INFO - Starting feature selection (k=50)
2024-12-27 20:18:32,137 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:18:32,137 - INFO - Starting anomaly detection
2024-12-27 20:18:34,014 - INFO - Anomaly detection completed in 1.88s
2024-12-27 20:18:34,014 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:18:34,014 - INFO - Total fit_transform time: 2.44s
2024-12-27 20:18:34,014 - INFO - Training set processing completed in 2.44s
2024-12-27 20:18:34,014 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:18:34,015 - INFO - Memory usage at start_fit: CPU 3290.9 MB, GPU 49.3 MB
2024-12-27 20:18:34,015 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:18:34,016 - INFO - Number of unique classes: 100
2024-12-27 20:18:34,109 - INFO - Fitted scaler and transformed data
2024-12-27 20:18:34,110 - INFO - Scaling time: 0.09s
2024-12-27 20:18:34,263 - INFO - Epoch 1/200, Train Loss: 2.7397, Val Loss: 2.8687
2024-12-27 20:18:34,382 - INFO - Epoch 2/200, Train Loss: 0.5307, Val Loss: 2.8165
2024-12-27 20:18:34,493 - INFO - Epoch 3/200, Train Loss: 0.1881, Val Loss: 2.8981
2024-12-27 20:18:34,628 - INFO - Epoch 4/200, Train Loss: 0.0553, Val Loss: 2.6740
2024-12-27 20:18:34,749 - INFO - Epoch 5/200, Train Loss: 0.0342, Val Loss: 2.7834
2024-12-27 20:18:34,893 - INFO - Epoch 6/200, Train Loss: 0.0163, Val Loss: 2.7210
2024-12-27 20:18:34,893 - INFO - Early stopping triggered at epoch 6
2024-12-27 20:18:34,894 - INFO - Training completed in 0.88s
2024-12-27 20:18:34,895 - INFO - Final memory usage: CPU 3290.9 MB, GPU 49.9 MB
2024-12-27 20:18:34,895 - INFO - Model training completed in 0.88s
2024-12-27 20:18:34,909 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:18:34,931 - INFO - Poison rate 0.1 completed in 3.36s
2024-12-27 20:18:34,932 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:18:34,932 - INFO - Label flipping details:
2024-12-27 20:18:34,932 - INFO - - Source class: 1
2024-12-27 20:18:34,932 - INFO - - Target class: 0
2024-12-27 20:18:34,933 - INFO - - Available samples in source class: 50
2024-12-27 20:18:34,933 - INFO - - Requested samples to poison: 1000
2024-12-27 20:18:34,933 - INFO - - Actual samples to flip: 49
2024-12-27 20:18:34,933 - INFO - - Samples remaining in source class: 1
2024-12-27 20:18:34,933 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:18:34,933 - INFO - Total number of labels flipped: 49
2024-12-27 20:18:34,933 - INFO - Label flipping completed in 0.00s
2024-12-27 20:18:34,933 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:18:34,933 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:18:35,506 - INFO - Feature scaling completed in 0.57s
2024-12-27 20:18:35,506 - INFO - Starting feature selection (k=50)
2024-12-27 20:18:35,520 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:18:35,520 - INFO - Starting anomaly detection
2024-12-27 20:18:37,672 - INFO - Anomaly detection completed in 2.15s
2024-12-27 20:18:37,672 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:18:37,672 - INFO - Total fit_transform time: 2.74s
2024-12-27 20:18:37,672 - INFO - Training set processing completed in 2.74s
2024-12-27 20:18:37,672 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:18:37,673 - INFO - Memory usage at start_fit: CPU 3290.9 MB, GPU 49.3 MB
2024-12-27 20:18:37,674 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:18:37,674 - INFO - Number of unique classes: 100
2024-12-27 20:18:37,770 - INFO - Fitted scaler and transformed data
2024-12-27 20:18:37,770 - INFO - Scaling time: 0.09s
2024-12-27 20:18:37,914 - INFO - Epoch 1/200, Train Loss: 2.6880, Val Loss: 2.2767
2024-12-27 20:18:38,077 - INFO - Epoch 2/200, Train Loss: 0.5105, Val Loss: 2.4122
2024-12-27 20:18:38,226 - INFO - Epoch 3/200, Train Loss: 0.1446, Val Loss: 2.2053
2024-12-27 20:18:38,391 - INFO - Epoch 4/200, Train Loss: 0.0487, Val Loss: 2.2995
2024-12-27 20:18:38,563 - INFO - Epoch 5/200, Train Loss: 0.0289, Val Loss: 2.1639
2024-12-27 20:18:38,696 - INFO - Epoch 6/200, Train Loss: 0.0315, Val Loss: 2.2139
2024-12-27 20:18:38,824 - INFO - Epoch 7/200, Train Loss: 0.0194, Val Loss: 2.1249
2024-12-27 20:18:38,958 - INFO - Epoch 8/200, Train Loss: 0.0115, Val Loss: 2.0870
2024-12-27 20:18:39,090 - INFO - Epoch 9/200, Train Loss: 0.0260, Val Loss: 2.2248
2024-12-27 20:18:39,214 - INFO - Epoch 10/200, Train Loss: 0.0386, Val Loss: 2.1474
2024-12-27 20:18:39,214 - INFO - Early stopping triggered at epoch 10
2024-12-27 20:18:39,214 - INFO - Training completed in 1.54s
2024-12-27 20:18:39,214 - INFO - Final memory usage: CPU 3290.9 MB, GPU 49.9 MB
2024-12-27 20:18:39,215 - INFO - Model training completed in 1.54s
2024-12-27 20:18:39,222 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:18:39,249 - INFO - Poison rate 0.2 completed in 4.32s
2024-12-27 20:18:39,254 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:18:39,254 - INFO - Total evaluation time: 28.18s
2024-12-27 20:18:39,256 - INFO - 
Progress: 55.2% - Evaluating CIFAR100 with RandomForest (standard mode, iteration 1/1)
2024-12-27 20:18:39,328 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:18:39,407 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:18:39,514 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:18:39,514 - INFO - Dataset type: image
2024-12-27 20:18:39,514 - INFO - Sample size: 5000
2024-12-27 20:18:39,514 - INFO - Using device: cuda
2024-12-27 20:18:39,516 - INFO - Loading datasets...
2024-12-27 20:18:40,882 - INFO - Dataset loading completed in 1.37s
2024-12-27 20:18:40,882 - INFO - Extracting validation features...
2024-12-27 20:18:40,882 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:16,  1.93it/s]Extracting features:   9%|▉         | 3/32 [00:00<00:05,  5.74it/s]Extracting features:  25%|██▌       | 8/32 [00:00<00:01, 15.59it/s]Extracting features:  41%|████      | 13/32 [00:00<00:00, 23.76it/s]Extracting features:  59%|█████▉    | 19/32 [00:00<00:00, 31.34it/s]Extracting features:  78%|███████▊  | 25/32 [00:01<00:00, 37.84it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 26.05it/s]
2024-12-27 20:18:42,115 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:18:42,116 - INFO - Validation feature extraction completed in 1.23s
2024-12-27 20:18:42,116 - INFO - Extracting training features...
2024-12-27 20:18:42,116 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:46,  3.38it/s]Extracting features:   4%|▍         | 6/157 [00:00<00:08, 17.92it/s]Extracting features:   8%|▊         | 12/157 [00:00<00:04, 29.97it/s]Extracting features:  11%|█▏        | 18/157 [00:00<00:03, 36.65it/s]Extracting features:  15%|█▌        | 24/157 [00:00<00:03, 41.43it/s]Extracting features:  20%|█▉        | 31/157 [00:00<00:02, 47.82it/s]Extracting features:  24%|██▎       | 37/157 [00:01<00:02, 45.65it/s]Extracting features:  27%|██▋       | 43/157 [00:01<00:02, 48.24it/s]Extracting features:  31%|███       | 49/157 [00:01<00:02, 46.83it/s]Extracting features:  34%|███▍      | 54/157 [00:01<00:02, 47.05it/s]Extracting features:  38%|███▊      | 60/157 [00:01<00:01, 50.46it/s]Extracting features:  42%|████▏     | 66/157 [00:01<00:01, 50.86it/s]Extracting features:  46%|████▌     | 72/157 [00:01<00:01, 51.08it/s]Extracting features:  50%|████▉     | 78/157 [00:01<00:01, 51.78it/s]Extracting features:  54%|█████▎    | 84/157 [00:01<00:01, 49.77it/s]Extracting features:  57%|█████▋    | 90/157 [00:02<00:01, 49.76it/s]Extracting features:  61%|██████    | 96/157 [00:02<00:01, 50.20it/s]Extracting features:  65%|██████▍   | 102/157 [00:02<00:01, 50.75it/s]Extracting features:  69%|██████▉   | 108/157 [00:02<00:00, 52.98it/s]Extracting features:  73%|███████▎  | 114/157 [00:02<00:00, 52.60it/s]Extracting features:  76%|███████▋  | 120/157 [00:02<00:00, 53.84it/s]Extracting features:  80%|████████  | 126/157 [00:02<00:00, 54.38it/s]Extracting features:  84%|████████▍ | 132/157 [00:02<00:00, 54.80it/s]Extracting features:  88%|████████▊ | 138/157 [00:02<00:00, 55.94it/s]Extracting features:  92%|█████████▏| 144/157 [00:03<00:00, 55.79it/s]Extracting features:  96%|█████████▌| 150/157 [00:03<00:00, 55.86it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 59.04it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 47.47it/s]
2024-12-27 20:18:45,436 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:18:45,436 - INFO - Training feature extraction completed in 3.32s
2024-12-27 20:18:45,436 - INFO - Creating model for classifier: RandomForest
2024-12-27 20:18:45,437 - INFO - Using device: cuda
2024-12-27 20:18:45,437 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:18:45,437 - INFO - Training set processing completed in 0.00s
2024-12-27 20:18:45,437 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:18:45,438 - INFO - Memory usage at start_fit: CPU 3263.5 MB, GPU 47.3 MB
2024-12-27 20:18:45,439 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:18:45,516 - INFO - Fitted scaler and transformed data
2024-12-27 20:18:45,516 - INFO - Scaling time: 0.08s
2024-12-27 20:18:45,522 - INFO - Number of unique classes: 100
2024-12-27 20:18:49,668 - INFO - Epoch 1/15, Train Loss: 4.6050, Val Loss: 4.6049
2024-12-27 20:18:53,412 - INFO - Epoch 2/15, Train Loss: 4.6040, Val Loss: 4.6045
2024-12-27 20:18:56,379 - INFO - Epoch 3/15, Train Loss: 4.6029, Val Loss: 4.6040
2024-12-27 20:18:56,379 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:18:56,380 - INFO - Training completed in 10.94s
2024-12-27 20:18:56,380 - INFO - Final memory usage: CPU 3288.0 MB, GPU 97.4 MB
2024-12-27 20:18:56,380 - INFO - Model training completed in 10.94s
2024-12-27 20:18:56,477 - INFO - Prediction completed in 0.10s
2024-12-27 20:18:56,487 - INFO - Poison rate 0.0 completed in 11.05s
2024-12-27 20:18:56,487 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:18:56,488 - INFO - Label flipping details:
2024-12-27 20:18:56,488 - INFO - - Source class: 1
2024-12-27 20:18:56,488 - INFO - - Target class: 0
2024-12-27 20:18:56,488 - INFO - - Available samples in source class: 50
2024-12-27 20:18:56,488 - INFO - - Requested samples to poison: 50
2024-12-27 20:18:56,488 - INFO - - Actual samples to flip: 49
2024-12-27 20:18:56,488 - INFO - - Samples remaining in source class: 1
2024-12-27 20:18:56,488 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:18:56,488 - INFO - Total number of labels flipped: 49
2024-12-27 20:18:56,488 - INFO - Label flipping completed in 0.00s
2024-12-27 20:18:56,488 - INFO - Training set processing completed in 0.00s
2024-12-27 20:18:56,488 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:18:56,489 - INFO - Memory usage at start_fit: CPU 3288.0 MB, GPU 66.9 MB
2024-12-27 20:18:56,489 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:18:56,556 - INFO - Fitted scaler and transformed data
2024-12-27 20:18:56,557 - INFO - Scaling time: 0.07s
2024-12-27 20:18:56,568 - INFO - Number of unique classes: 100
2024-12-27 20:18:59,973 - INFO - Epoch 1/15, Train Loss: 4.6050, Val Loss: 4.6049
2024-12-27 20:19:03,651 - INFO - Epoch 2/15, Train Loss: 4.6040, Val Loss: 4.6045
2024-12-27 20:19:07,134 - INFO - Epoch 3/15, Train Loss: 4.6029, Val Loss: 4.6040
2024-12-27 20:19:07,134 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:19:07,134 - INFO - Training completed in 10.65s
2024-12-27 20:19:07,135 - INFO - Final memory usage: CPU 3288.0 MB, GPU 97.4 MB
2024-12-27 20:19:07,135 - INFO - Model training completed in 10.65s
2024-12-27 20:19:07,235 - INFO - Prediction completed in 0.10s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:19:07,245 - INFO - Poison rate 0.01 completed in 10.76s
2024-12-27 20:19:07,245 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:19:07,245 - INFO - Label flipping details:
2024-12-27 20:19:07,245 - INFO - - Source class: 1
2024-12-27 20:19:07,246 - INFO - - Target class: 0
2024-12-27 20:19:07,246 - INFO - - Available samples in source class: 50
2024-12-27 20:19:07,246 - INFO - - Requested samples to poison: 150
2024-12-27 20:19:07,246 - INFO - - Actual samples to flip: 49
2024-12-27 20:19:07,246 - INFO - - Samples remaining in source class: 1
2024-12-27 20:19:07,246 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:19:07,246 - INFO - Total number of labels flipped: 49
2024-12-27 20:19:07,246 - INFO - Label flipping completed in 0.00s
2024-12-27 20:19:07,246 - INFO - Training set processing completed in 0.00s
2024-12-27 20:19:07,246 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:19:07,247 - INFO - Memory usage at start_fit: CPU 3288.0 MB, GPU 66.9 MB
2024-12-27 20:19:07,247 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:19:07,311 - INFO - Fitted scaler and transformed data
2024-12-27 20:19:07,311 - INFO - Scaling time: 0.06s
2024-12-27 20:19:07,322 - INFO - Number of unique classes: 100
2024-12-27 20:19:10,764 - INFO - Epoch 1/15, Train Loss: 4.6050, Val Loss: 4.6049
2024-12-27 20:19:13,926 - INFO - Epoch 2/15, Train Loss: 4.6040, Val Loss: 4.6045
2024-12-27 20:19:17,372 - INFO - Epoch 3/15, Train Loss: 4.6029, Val Loss: 4.6041
2024-12-27 20:19:17,373 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:19:17,375 - INFO - Training completed in 10.13s
2024-12-27 20:19:17,375 - INFO - Final memory usage: CPU 3288.0 MB, GPU 97.4 MB
2024-12-27 20:19:17,376 - INFO - Model training completed in 10.13s
2024-12-27 20:19:17,492 - INFO - Prediction completed in 0.12s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:19:17,502 - INFO - Poison rate 0.03 completed in 10.26s
2024-12-27 20:19:17,502 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:19:17,502 - INFO - Label flipping details:
2024-12-27 20:19:17,502 - INFO - - Source class: 1
2024-12-27 20:19:17,502 - INFO - - Target class: 0
2024-12-27 20:19:17,502 - INFO - - Available samples in source class: 50
2024-12-27 20:19:17,502 - INFO - - Requested samples to poison: 250
2024-12-27 20:19:17,503 - INFO - - Actual samples to flip: 49
2024-12-27 20:19:17,503 - INFO - - Samples remaining in source class: 1
2024-12-27 20:19:17,503 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:19:17,503 - INFO - Total number of labels flipped: 49
2024-12-27 20:19:17,503 - INFO - Label flipping completed in 0.00s
2024-12-27 20:19:17,503 - INFO - Training set processing completed in 0.00s
2024-12-27 20:19:17,503 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:19:17,504 - INFO - Memory usage at start_fit: CPU 3288.0 MB, GPU 66.9 MB
2024-12-27 20:19:17,504 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:19:17,582 - INFO - Fitted scaler and transformed data
2024-12-27 20:19:17,582 - INFO - Scaling time: 0.08s
2024-12-27 20:19:17,595 - INFO - Number of unique classes: 100
2024-12-27 20:19:20,859 - INFO - Epoch 1/15, Train Loss: 4.6050, Val Loss: 4.6048
2024-12-27 20:19:23,923 - INFO - Epoch 2/15, Train Loss: 4.6040, Val Loss: 4.6044
2024-12-27 20:19:27,136 - INFO - Epoch 3/15, Train Loss: 4.6029, Val Loss: 4.6040
2024-12-27 20:19:27,137 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:19:27,137 - INFO - Training completed in 9.63s
2024-12-27 20:19:27,138 - INFO - Final memory usage: CPU 3288.0 MB, GPU 97.4 MB
2024-12-27 20:19:27,138 - INFO - Model training completed in 9.64s
2024-12-27 20:19:27,309 - INFO - Prediction completed in 0.17s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:19:27,318 - INFO - Poison rate 0.05 completed in 9.82s
2024-12-27 20:19:27,318 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:19:27,318 - INFO - Label flipping details:
2024-12-27 20:19:27,318 - INFO - - Source class: 1
2024-12-27 20:19:27,318 - INFO - - Target class: 0
2024-12-27 20:19:27,318 - INFO - - Available samples in source class: 50
2024-12-27 20:19:27,319 - INFO - - Requested samples to poison: 350
2024-12-27 20:19:27,319 - INFO - - Actual samples to flip: 49
2024-12-27 20:19:27,319 - INFO - - Samples remaining in source class: 1
2024-12-27 20:19:27,319 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:19:27,319 - INFO - Total number of labels flipped: 49
2024-12-27 20:19:27,319 - INFO - Label flipping completed in 0.00s
2024-12-27 20:19:27,319 - INFO - Training set processing completed in 0.00s
2024-12-27 20:19:27,319 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:19:27,320 - INFO - Memory usage at start_fit: CPU 3288.0 MB, GPU 66.9 MB
2024-12-27 20:19:27,320 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:19:27,392 - INFO - Fitted scaler and transformed data
2024-12-27 20:19:27,392 - INFO - Scaling time: 0.07s
2024-12-27 20:19:27,403 - INFO - Number of unique classes: 100
2024-12-27 20:19:31,470 - INFO - Epoch 1/15, Train Loss: 4.6050, Val Loss: 4.6048
2024-12-27 20:19:34,762 - INFO - Epoch 2/15, Train Loss: 4.6040, Val Loss: 4.6044
2024-12-27 20:19:37,746 - INFO - Epoch 3/15, Train Loss: 4.6029, Val Loss: 4.6040
2024-12-27 20:19:37,746 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:19:37,746 - INFO - Training completed in 10.43s
2024-12-27 20:19:37,747 - INFO - Final memory usage: CPU 3288.0 MB, GPU 97.4 MB
2024-12-27 20:19:37,747 - INFO - Model training completed in 10.43s
2024-12-27 20:19:37,945 - INFO - Prediction completed in 0.20s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:19:37,959 - INFO - Poison rate 0.07 completed in 10.64s
2024-12-27 20:19:37,959 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:19:37,959 - INFO - Label flipping details:
2024-12-27 20:19:37,959 - INFO - - Source class: 1
2024-12-27 20:19:37,959 - INFO - - Target class: 0
2024-12-27 20:19:37,959 - INFO - - Available samples in source class: 50
2024-12-27 20:19:37,959 - INFO - - Requested samples to poison: 500
2024-12-27 20:19:37,959 - INFO - - Actual samples to flip: 49
2024-12-27 20:19:37,959 - INFO - - Samples remaining in source class: 1
2024-12-27 20:19:37,959 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:19:37,960 - INFO - Total number of labels flipped: 49
2024-12-27 20:19:37,960 - INFO - Label flipping completed in 0.00s
2024-12-27 20:19:37,960 - INFO - Training set processing completed in 0.00s
2024-12-27 20:19:37,960 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:19:37,961 - INFO - Memory usage at start_fit: CPU 3288.0 MB, GPU 66.9 MB
2024-12-27 20:19:37,961 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:19:38,027 - INFO - Fitted scaler and transformed data
2024-12-27 20:19:38,028 - INFO - Scaling time: 0.07s
2024-12-27 20:19:38,038 - INFO - Number of unique classes: 100
2024-12-27 20:19:41,283 - INFO - Epoch 1/15, Train Loss: 4.6050, Val Loss: 4.6049
2024-12-27 20:19:44,464 - INFO - Epoch 2/15, Train Loss: 4.6040, Val Loss: 4.6044
2024-12-27 20:19:47,471 - INFO - Epoch 3/15, Train Loss: 4.6029, Val Loss: 4.6040
2024-12-27 20:19:47,472 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:19:47,472 - INFO - Training completed in 9.51s
2024-12-27 20:19:47,472 - INFO - Final memory usage: CPU 3288.0 MB, GPU 97.4 MB
2024-12-27 20:19:47,473 - INFO - Model training completed in 9.51s
2024-12-27 20:19:47,659 - INFO - Prediction completed in 0.19s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:19:47,668 - INFO - Poison rate 0.1 completed in 9.71s
2024-12-27 20:19:47,668 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:19:47,669 - INFO - Label flipping details:
2024-12-27 20:19:47,669 - INFO - - Source class: 1
2024-12-27 20:19:47,669 - INFO - - Target class: 0
2024-12-27 20:19:47,669 - INFO - - Available samples in source class: 50
2024-12-27 20:19:47,669 - INFO - - Requested samples to poison: 1000
2024-12-27 20:19:47,669 - INFO - - Actual samples to flip: 49
2024-12-27 20:19:47,669 - INFO - - Samples remaining in source class: 1
2024-12-27 20:19:47,669 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:19:47,669 - INFO - Total number of labels flipped: 49
2024-12-27 20:19:47,669 - INFO - Label flipping completed in 0.00s
2024-12-27 20:19:47,669 - INFO - Training set processing completed in 0.00s
2024-12-27 20:19:47,669 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:19:47,670 - INFO - Memory usage at start_fit: CPU 3288.0 MB, GPU 66.9 MB
2024-12-27 20:19:47,670 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:19:47,736 - INFO - Fitted scaler and transformed data
2024-12-27 20:19:47,736 - INFO - Scaling time: 0.07s
2024-12-27 20:19:47,748 - INFO - Number of unique classes: 100
2024-12-27 20:19:50,507 - INFO - Epoch 1/15, Train Loss: 4.6050, Val Loss: 4.6049
2024-12-27 20:19:54,308 - INFO - Epoch 2/15, Train Loss: 4.6040, Val Loss: 4.6045
2024-12-27 20:19:58,003 - INFO - Epoch 3/15, Train Loss: 4.6029, Val Loss: 4.6040
2024-12-27 20:19:58,003 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:19:58,004 - INFO - Training completed in 10.33s
2024-12-27 20:19:58,004 - INFO - Final memory usage: CPU 3288.0 MB, GPU 97.4 MB
2024-12-27 20:19:58,004 - INFO - Model training completed in 10.33s
2024-12-27 20:19:58,222 - INFO - Prediction completed in 0.22s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:19:58,231 - INFO - Poison rate 0.2 completed in 10.56s
2024-12-27 20:19:58,233 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:19:58,233 - INFO - Total evaluation time: 78.72s
2024-12-27 20:19:58,234 - INFO - 
Progress: 56.2% - Evaluating CIFAR100 with RandomForest (dynadetect mode, iteration 1/1)
2024-12-27 20:19:58,295 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:19:58,367 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:19:58,449 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:19:58,449 - INFO - Dataset type: image
2024-12-27 20:19:58,449 - INFO - Sample size: 5000
2024-12-27 20:19:58,449 - INFO - Using device: cuda
2024-12-27 20:19:58,452 - INFO - Loading datasets...
2024-12-27 20:19:59,812 - INFO - Dataset loading completed in 1.36s
2024-12-27 20:19:59,813 - INFO - Extracting validation features...
2024-12-27 20:19:59,813 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:18,  1.71it/s]Extracting features:   9%|▉         | 3/32 [00:00<00:05,  5.23it/s]Extracting features:  25%|██▌       | 8/32 [00:00<00:01, 14.68it/s]Extracting features:  44%|████▍     | 14/32 [00:00<00:00, 24.53it/s]Extracting features:  62%|██████▎   | 20/32 [00:01<00:00, 32.45it/s]Extracting features:  78%|███████▊  | 25/32 [00:01<00:00, 36.81it/s]Extracting features:  94%|█████████▍| 30/32 [00:01<00:00, 39.63it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 23.91it/s]
2024-12-27 20:20:01,157 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:20:01,158 - INFO - Validation feature extraction completed in 1.35s
2024-12-27 20:20:01,158 - INFO - Extracting training features...
2024-12-27 20:20:01,158 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:42,  3.69it/s]Extracting features:   4%|▍         | 6/157 [00:00<00:08, 18.25it/s]Extracting features:   8%|▊         | 12/157 [00:00<00:04, 30.32it/s]Extracting features:  11%|█▏        | 18/157 [00:00<00:03, 38.68it/s]Extracting features:  15%|█▌        | 24/157 [00:00<00:02, 44.78it/s]Extracting features:  19%|█▉        | 30/157 [00:00<00:02, 48.42it/s]Extracting features:  24%|██▎       | 37/157 [00:00<00:02, 52.49it/s]Extracting features:  27%|██▋       | 43/157 [00:01<00:02, 52.19it/s]Extracting features:  31%|███       | 49/157 [00:01<00:02, 53.32it/s]Extracting features:  35%|███▌      | 55/157 [00:01<00:01, 54.61it/s]Extracting features:  39%|███▉      | 61/157 [00:01<00:01, 54.12it/s]Extracting features:  43%|████▎     | 67/157 [00:01<00:01, 54.09it/s]Extracting features:  46%|████▋     | 73/157 [00:01<00:01, 54.03it/s]Extracting features:  50%|█████     | 79/157 [00:01<00:01, 54.28it/s]Extracting features:  55%|█████▍    | 86/157 [00:01<00:01, 56.26it/s]Extracting features:  59%|█████▊    | 92/157 [00:01<00:01, 55.46it/s]Extracting features:  63%|██████▎   | 99/157 [00:02<00:01, 57.34it/s]Extracting features:  67%|██████▋   | 105/157 [00:02<00:00, 54.05it/s]Extracting features:  71%|███████   | 111/157 [00:02<00:00, 55.43it/s]Extracting features:  75%|███████▍  | 117/157 [00:02<00:00, 53.00it/s]Extracting features:  79%|███████▉  | 124/157 [00:02<00:00, 55.78it/s]Extracting features:  83%|████████▎ | 130/157 [00:02<00:00, 56.20it/s]Extracting features:  87%|████████▋ | 136/157 [00:02<00:00, 55.98it/s]Extracting features:  90%|█████████ | 142/157 [00:02<00:00, 55.15it/s]Extracting features:  94%|█████████▍| 148/157 [00:02<00:00, 56.02it/s]Extracting features:  98%|█████████▊| 154/157 [00:03<00:00, 56.03it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 49.54it/s]
2024-12-27 20:20:04,342 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:20:04,343 - INFO - Training feature extraction completed in 3.18s
2024-12-27 20:20:04,343 - INFO - Creating model for classifier: RandomForest
2024-12-27 20:20:04,343 - INFO - Using device: cuda
2024-12-27 20:20:04,343 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:20:04,343 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:20:04,343 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:20:04,898 - INFO - Feature scaling completed in 0.56s
2024-12-27 20:20:04,899 - INFO - Starting feature selection (k=50)
2024-12-27 20:20:04,906 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:20:04,906 - INFO - Starting anomaly detection
2024-12-27 20:20:06,131 - INFO - Anomaly detection completed in 1.22s
2024-12-27 20:20:06,131 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:20:06,131 - INFO - Total fit_transform time: 1.79s
2024-12-27 20:20:06,131 - INFO - Training set processing completed in 1.79s
2024-12-27 20:20:06,131 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:20:06,133 - INFO - Memory usage at start_fit: CPU 3295.8 MB, GPU 47.3 MB
2024-12-27 20:20:06,133 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:20:06,211 - INFO - Fitted scaler and transformed data
2024-12-27 20:20:06,211 - INFO - Scaling time: 0.08s
2024-12-27 20:20:06,219 - INFO - Number of unique classes: 100
2024-12-27 20:20:09,932 - INFO - Epoch 1/15, Train Loss: 4.3795, Val Loss: 4.6049
2024-12-27 20:20:12,894 - INFO - Epoch 2/15, Train Loss: 4.3785, Val Loss: 4.6045
2024-12-27 20:20:16,124 - INFO - Epoch 3/15, Train Loss: 4.3774, Val Loss: 4.6041
2024-12-27 20:20:16,124 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:20:16,124 - INFO - Training completed in 9.99s
2024-12-27 20:20:16,125 - INFO - Final memory usage: CPU 3295.8 MB, GPU 97.4 MB
2024-12-27 20:20:16,125 - INFO - Model training completed in 9.99s
2024-12-27 20:20:16,248 - INFO - Prediction completed in 0.12s
2024-12-27 20:20:16,257 - INFO - Poison rate 0.0 completed in 11.91s
2024-12-27 20:20:16,258 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:20:16,258 - INFO - Label flipping details:
2024-12-27 20:20:16,258 - INFO - - Source class: 1
2024-12-27 20:20:16,258 - INFO - - Target class: 0
2024-12-27 20:20:16,258 - INFO - - Available samples in source class: 50
2024-12-27 20:20:16,258 - INFO - - Requested samples to poison: 50
2024-12-27 20:20:16,258 - INFO - - Actual samples to flip: 49
2024-12-27 20:20:16,259 - INFO - - Samples remaining in source class: 1
2024-12-27 20:20:16,259 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:20:16,259 - INFO - Total number of labels flipped: 49
2024-12-27 20:20:16,259 - INFO - Label flipping completed in 0.00s
2024-12-27 20:20:16,259 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:20:16,259 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:20:16,861 - INFO - Feature scaling completed in 0.60s
2024-12-27 20:20:16,861 - INFO - Starting feature selection (k=50)
2024-12-27 20:20:16,874 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:20:16,874 - INFO - Starting anomaly detection
2024-12-27 20:20:18,076 - INFO - Anomaly detection completed in 1.20s
2024-12-27 20:20:18,076 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:20:18,076 - INFO - Total fit_transform time: 1.82s
2024-12-27 20:20:18,076 - INFO - Training set processing completed in 1.82s
2024-12-27 20:20:18,076 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:20:18,078 - INFO - Memory usage at start_fit: CPU 3295.8 MB, GPU 66.9 MB
2024-12-27 20:20:18,078 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:20:18,147 - INFO - Fitted scaler and transformed data
2024-12-27 20:20:18,148 - INFO - Scaling time: 0.07s
2024-12-27 20:20:18,154 - INFO - Number of unique classes: 100
2024-12-27 20:20:22,083 - INFO - Epoch 1/15, Train Loss: 4.3738, Val Loss: 4.6049
2024-12-27 20:20:25,554 - INFO - Epoch 2/15, Train Loss: 4.3728, Val Loss: 4.6044
2024-12-27 20:20:28,779 - INFO - Epoch 3/15, Train Loss: 4.3718, Val Loss: 4.6040
2024-12-27 20:20:28,780 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:20:28,780 - INFO - Training completed in 10.70s
2024-12-27 20:20:28,780 - INFO - Final memory usage: CPU 3295.8 MB, GPU 97.4 MB
2024-12-27 20:20:28,780 - INFO - Model training completed in 10.70s
2024-12-27 20:20:28,906 - INFO - Prediction completed in 0.13s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:20:28,915 - INFO - Poison rate 0.01 completed in 12.66s
2024-12-27 20:20:28,915 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:20:28,916 - INFO - Label flipping details:
2024-12-27 20:20:28,916 - INFO - - Source class: 1
2024-12-27 20:20:28,916 - INFO - - Target class: 0
2024-12-27 20:20:28,916 - INFO - - Available samples in source class: 50
2024-12-27 20:20:28,916 - INFO - - Requested samples to poison: 150
2024-12-27 20:20:28,916 - INFO - - Actual samples to flip: 49
2024-12-27 20:20:28,916 - INFO - - Samples remaining in source class: 1
2024-12-27 20:20:28,916 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:20:28,916 - INFO - Total number of labels flipped: 49
2024-12-27 20:20:28,916 - INFO - Label flipping completed in 0.00s
2024-12-27 20:20:28,916 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:20:28,916 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:20:29,537 - INFO - Feature scaling completed in 0.62s
2024-12-27 20:20:29,537 - INFO - Starting feature selection (k=50)
2024-12-27 20:20:29,550 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:20:29,550 - INFO - Starting anomaly detection
2024-12-27 20:20:31,002 - INFO - Anomaly detection completed in 1.45s
2024-12-27 20:20:31,002 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:20:31,003 - INFO - Total fit_transform time: 2.09s
2024-12-27 20:20:31,003 - INFO - Training set processing completed in 2.09s
2024-12-27 20:20:31,003 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:20:31,004 - INFO - Memory usage at start_fit: CPU 3295.8 MB, GPU 66.9 MB
2024-12-27 20:20:31,004 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:20:31,079 - INFO - Fitted scaler and transformed data
2024-12-27 20:20:31,079 - INFO - Scaling time: 0.07s
2024-12-27 20:20:31,084 - INFO - Number of unique classes: 100
2024-12-27 20:20:34,335 - INFO - Epoch 1/15, Train Loss: 4.3735, Val Loss: 4.6049
2024-12-27 20:20:37,633 - INFO - Epoch 2/15, Train Loss: 4.3725, Val Loss: 4.6045
2024-12-27 20:20:40,747 - INFO - Epoch 3/15, Train Loss: 4.3715, Val Loss: 4.6040
2024-12-27 20:20:40,748 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:20:40,748 - INFO - Training completed in 9.74s
2024-12-27 20:20:40,748 - INFO - Final memory usage: CPU 3295.8 MB, GPU 97.4 MB
2024-12-27 20:20:40,748 - INFO - Model training completed in 9.75s
2024-12-27 20:20:40,862 - INFO - Prediction completed in 0.11s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:20:40,871 - INFO - Poison rate 0.03 completed in 11.96s
2024-12-27 20:20:40,871 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:20:40,872 - INFO - Label flipping details:
2024-12-27 20:20:40,872 - INFO - - Source class: 1
2024-12-27 20:20:40,872 - INFO - - Target class: 0
2024-12-27 20:20:40,872 - INFO - - Available samples in source class: 50
2024-12-27 20:20:40,872 - INFO - - Requested samples to poison: 250
2024-12-27 20:20:40,872 - INFO - - Actual samples to flip: 49
2024-12-27 20:20:40,872 - INFO - - Samples remaining in source class: 1
2024-12-27 20:20:40,872 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:20:40,872 - INFO - Total number of labels flipped: 49
2024-12-27 20:20:40,872 - INFO - Label flipping completed in 0.00s
2024-12-27 20:20:40,873 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:20:40,873 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:20:41,422 - INFO - Feature scaling completed in 0.55s
2024-12-27 20:20:41,422 - INFO - Starting feature selection (k=50)
2024-12-27 20:20:41,434 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:20:41,435 - INFO - Starting anomaly detection
2024-12-27 20:20:43,745 - INFO - Anomaly detection completed in 2.31s
2024-12-27 20:20:43,746 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:20:43,746 - INFO - Total fit_transform time: 2.87s
2024-12-27 20:20:43,746 - INFO - Training set processing completed in 2.87s
2024-12-27 20:20:43,746 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:20:43,747 - INFO - Memory usage at start_fit: CPU 3295.8 MB, GPU 66.9 MB
2024-12-27 20:20:43,747 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:20:43,814 - INFO - Fitted scaler and transformed data
2024-12-27 20:20:43,814 - INFO - Scaling time: 0.07s
2024-12-27 20:20:43,820 - INFO - Number of unique classes: 100
2024-12-27 20:20:47,653 - INFO - Epoch 1/15, Train Loss: 4.3686, Val Loss: 4.6048
2024-12-27 20:20:50,927 - INFO - Epoch 2/15, Train Loss: 4.3676, Val Loss: 4.6044
2024-12-27 20:20:54,173 - INFO - Epoch 3/15, Train Loss: 4.3666, Val Loss: 4.6039
2024-12-27 20:20:54,174 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:20:54,174 - INFO - Training completed in 10.43s
2024-12-27 20:20:54,174 - INFO - Final memory usage: CPU 3295.8 MB, GPU 97.4 MB
2024-12-27 20:20:54,175 - INFO - Model training completed in 10.43s
2024-12-27 20:20:54,319 - INFO - Prediction completed in 0.14s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:20:54,328 - INFO - Poison rate 0.05 completed in 13.46s
2024-12-27 20:20:54,329 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:20:54,329 - INFO - Label flipping details:
2024-12-27 20:20:54,329 - INFO - - Source class: 1
2024-12-27 20:20:54,329 - INFO - - Target class: 0
2024-12-27 20:20:54,329 - INFO - - Available samples in source class: 50
2024-12-27 20:20:54,329 - INFO - - Requested samples to poison: 350
2024-12-27 20:20:54,329 - INFO - - Actual samples to flip: 49
2024-12-27 20:20:54,329 - INFO - - Samples remaining in source class: 1
2024-12-27 20:20:54,329 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:20:54,329 - INFO - Total number of labels flipped: 49
2024-12-27 20:20:54,330 - INFO - Label flipping completed in 0.00s
2024-12-27 20:20:54,330 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:20:54,330 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:20:54,940 - INFO - Feature scaling completed in 0.61s
2024-12-27 20:20:54,940 - INFO - Starting feature selection (k=50)
2024-12-27 20:20:54,952 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:20:54,952 - INFO - Starting anomaly detection
2024-12-27 20:20:57,232 - INFO - Anomaly detection completed in 2.28s
2024-12-27 20:20:57,232 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:20:57,232 - INFO - Total fit_transform time: 2.90s
2024-12-27 20:20:57,232 - INFO - Training set processing completed in 2.90s
2024-12-27 20:20:57,232 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:20:57,233 - INFO - Memory usage at start_fit: CPU 3295.8 MB, GPU 66.9 MB
2024-12-27 20:20:57,233 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:20:57,302 - INFO - Fitted scaler and transformed data
2024-12-27 20:20:57,303 - INFO - Scaling time: 0.07s
2024-12-27 20:20:57,310 - INFO - Number of unique classes: 100
2024-12-27 20:21:00,384 - INFO - Epoch 1/15, Train Loss: 4.3759, Val Loss: 4.6049
2024-12-27 20:21:03,341 - INFO - Epoch 2/15, Train Loss: 4.3749, Val Loss: 4.6045
2024-12-27 20:21:06,427 - INFO - Epoch 3/15, Train Loss: 4.3739, Val Loss: 4.6040
2024-12-27 20:21:06,427 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:21:06,427 - INFO - Training completed in 9.19s
2024-12-27 20:21:06,427 - INFO - Final memory usage: CPU 3295.8 MB, GPU 97.4 MB
2024-12-27 20:21:06,428 - INFO - Model training completed in 9.20s
2024-12-27 20:21:06,549 - INFO - Prediction completed in 0.12s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:21:06,558 - INFO - Poison rate 0.07 completed in 12.23s
2024-12-27 20:21:06,558 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:21:06,558 - INFO - Label flipping details:
2024-12-27 20:21:06,559 - INFO - - Source class: 1
2024-12-27 20:21:06,559 - INFO - - Target class: 0
2024-12-27 20:21:06,559 - INFO - - Available samples in source class: 50
2024-12-27 20:21:06,559 - INFO - - Requested samples to poison: 500
2024-12-27 20:21:06,559 - INFO - - Actual samples to flip: 49
2024-12-27 20:21:06,559 - INFO - - Samples remaining in source class: 1
2024-12-27 20:21:06,559 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:21:06,559 - INFO - Total number of labels flipped: 49
2024-12-27 20:21:06,559 - INFO - Label flipping completed in 0.00s
2024-12-27 20:21:06,559 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:21:06,559 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:21:07,103 - INFO - Feature scaling completed in 0.54s
2024-12-27 20:21:07,103 - INFO - Starting feature selection (k=50)
2024-12-27 20:21:07,116 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:21:07,117 - INFO - Starting anomaly detection
2024-12-27 20:21:09,182 - INFO - Anomaly detection completed in 2.07s
2024-12-27 20:21:09,183 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:21:09,183 - INFO - Total fit_transform time: 2.62s
2024-12-27 20:21:09,183 - INFO - Training set processing completed in 2.62s
2024-12-27 20:21:09,183 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:21:09,184 - INFO - Memory usage at start_fit: CPU 3295.8 MB, GPU 66.9 MB
2024-12-27 20:21:09,184 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:21:09,249 - INFO - Fitted scaler and transformed data
2024-12-27 20:21:09,250 - INFO - Scaling time: 0.07s
2024-12-27 20:21:09,256 - INFO - Number of unique classes: 100
2024-12-27 20:21:12,112 - INFO - Epoch 1/15, Train Loss: 4.3769, Val Loss: 4.6048
2024-12-27 20:21:15,553 - INFO - Epoch 2/15, Train Loss: 4.3760, Val Loss: 4.6044
2024-12-27 20:21:18,370 - INFO - Epoch 3/15, Train Loss: 4.3749, Val Loss: 4.6040
2024-12-27 20:21:18,370 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:21:18,370 - INFO - Training completed in 9.19s
2024-12-27 20:21:18,371 - INFO - Final memory usage: CPU 3295.8 MB, GPU 97.4 MB
2024-12-27 20:21:18,371 - INFO - Model training completed in 9.19s
2024-12-27 20:21:18,520 - INFO - Prediction completed in 0.15s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:21:18,530 - INFO - Poison rate 0.1 completed in 11.97s
2024-12-27 20:21:18,530 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:21:18,531 - INFO - Label flipping details:
2024-12-27 20:21:18,531 - INFO - - Source class: 1
2024-12-27 20:21:18,531 - INFO - - Target class: 0
2024-12-27 20:21:18,531 - INFO - - Available samples in source class: 50
2024-12-27 20:21:18,531 - INFO - - Requested samples to poison: 1000
2024-12-27 20:21:18,531 - INFO - - Actual samples to flip: 49
2024-12-27 20:21:18,531 - INFO - - Samples remaining in source class: 1
2024-12-27 20:21:18,531 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:21:18,532 - INFO - Total number of labels flipped: 49
2024-12-27 20:21:18,532 - INFO - Label flipping completed in 0.00s
2024-12-27 20:21:18,532 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:21:18,532 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:21:19,131 - INFO - Feature scaling completed in 0.60s
2024-12-27 20:21:19,131 - INFO - Starting feature selection (k=50)
2024-12-27 20:21:19,144 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:21:19,144 - INFO - Starting anomaly detection
2024-12-27 20:21:20,915 - INFO - Anomaly detection completed in 1.77s
2024-12-27 20:21:20,915 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:21:20,915 - INFO - Total fit_transform time: 2.38s
2024-12-27 20:21:20,915 - INFO - Training set processing completed in 2.38s
2024-12-27 20:21:20,915 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:21:20,916 - INFO - Memory usage at start_fit: CPU 3295.8 MB, GPU 66.9 MB
2024-12-27 20:21:20,916 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:21:20,983 - INFO - Fitted scaler and transformed data
2024-12-27 20:21:20,983 - INFO - Scaling time: 0.07s
2024-12-27 20:21:20,989 - INFO - Number of unique classes: 100
2024-12-27 20:21:24,074 - INFO - Epoch 1/15, Train Loss: 4.3717, Val Loss: 4.6049
2024-12-27 20:21:26,908 - INFO - Epoch 2/15, Train Loss: 4.3707, Val Loss: 4.6045
2024-12-27 20:21:29,623 - INFO - Epoch 3/15, Train Loss: 4.3697, Val Loss: 4.6040
2024-12-27 20:21:29,623 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:21:29,623 - INFO - Training completed in 8.71s
2024-12-27 20:21:29,624 - INFO - Final memory usage: CPU 3295.8 MB, GPU 97.4 MB
2024-12-27 20:21:29,624 - INFO - Model training completed in 8.71s
2024-12-27 20:21:29,800 - INFO - Prediction completed in 0.18s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:21:29,809 - INFO - Poison rate 0.2 completed in 11.28s
2024-12-27 20:21:29,811 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:21:29,811 - INFO - Total evaluation time: 91.36s
2024-12-27 20:21:29,812 - INFO - 
Progress: 57.3% - Evaluating CIFAR100 with KNeighbors (standard mode, iteration 1/1)
2024-12-27 20:21:29,873 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:21:29,954 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:21:30,045 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:21:30,045 - INFO - Dataset type: image
2024-12-27 20:21:30,046 - INFO - Sample size: 5000
2024-12-27 20:21:30,046 - INFO - Using device: cuda
2024-12-27 20:21:30,048 - INFO - Loading datasets...
2024-12-27 20:21:31,360 - INFO - Dataset loading completed in 1.31s
2024-12-27 20:21:31,361 - INFO - Extracting validation features...
2024-12-27 20:21:31,361 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:18,  1.66it/s]Extracting features:  12%|█▎        | 4/32 [00:00<00:04,  6.97it/s]Extracting features:  28%|██▊       | 9/32 [00:00<00:01, 15.67it/s]Extracting features:  47%|████▋     | 15/32 [00:00<00:00, 25.33it/s]Extracting features:  66%|██████▌   | 21/32 [00:01<00:00, 33.69it/s]Extracting features:  84%|████████▍ | 27/32 [00:01<00:00, 39.54it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 25.11it/s]
2024-12-27 20:21:32,641 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:21:32,642 - INFO - Validation feature extraction completed in 1.28s
2024-12-27 20:21:32,642 - INFO - Extracting training features...
2024-12-27 20:21:32,642 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:41,  3.72it/s]Extracting features:   4%|▍         | 7/157 [00:00<00:06, 21.82it/s]Extracting features:   8%|▊         | 13/157 [00:00<00:04, 32.89it/s]Extracting features:  12%|█▏        | 19/157 [00:00<00:03, 40.31it/s]Extracting features:  17%|█▋        | 26/157 [00:00<00:02, 47.33it/s]Extracting features:  20%|██        | 32/157 [00:00<00:02, 50.41it/s]Extracting features:  24%|██▍       | 38/157 [00:00<00:02, 50.02it/s]Extracting features:  28%|██▊       | 44/157 [00:01<00:02, 51.04it/s]Extracting features:  32%|███▏      | 50/157 [00:01<00:02, 51.13it/s]Extracting features:  36%|███▌      | 56/157 [00:01<00:01, 50.97it/s]Extracting features:  39%|███▉      | 62/157 [00:01<00:01, 51.66it/s]Extracting features:  43%|████▎     | 68/157 [00:01<00:01, 52.70it/s]Extracting features:  47%|████▋     | 74/157 [00:01<00:01, 52.79it/s]Extracting features:  51%|█████     | 80/157 [00:01<00:01, 52.12it/s]Extracting features:  55%|█████▍    | 86/157 [00:01<00:01, 52.59it/s]Extracting features:  59%|█████▊    | 92/157 [00:01<00:01, 50.86it/s]Extracting features:  62%|██████▏   | 98/157 [00:02<00:01, 51.62it/s]Extracting features:  66%|██████▌   | 104/157 [00:02<00:01, 51.25it/s]Extracting features:  70%|███████   | 110/157 [00:02<00:00, 51.44it/s]Extracting features:  74%|███████▍  | 116/157 [00:02<00:00, 52.46it/s]Extracting features:  78%|███████▊  | 122/157 [00:02<00:00, 52.68it/s]Extracting features:  82%|████████▏ | 128/157 [00:02<00:00, 53.94it/s]Extracting features:  85%|████████▌ | 134/157 [00:02<00:00, 51.60it/s]Extracting features:  89%|████████▉ | 140/157 [00:02<00:00, 52.15it/s]Extracting features:  93%|█████████▎| 146/157 [00:03<00:00, 51.94it/s]Extracting features:  97%|█████████▋| 153/157 [00:03<00:00, 55.42it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 47.60it/s]
2024-12-27 20:21:35,955 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:21:35,955 - INFO - Training feature extraction completed in 3.31s
2024-12-27 20:21:35,955 - INFO - Creating model for classifier: KNeighbors
2024-12-27 20:21:35,956 - INFO - Using device: cuda
2024-12-27 20:21:35,956 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:21:35,956 - INFO - Training set processing completed in 0.00s
2024-12-27 20:21:35,956 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:21:35,957 - INFO - Memory usage at start_fit: CPU 3268.9 MB, GPU 47.3 MB
2024-12-27 20:21:35,958 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:21:36,037 - INFO - Fitted scaler and transformed data
2024-12-27 20:21:36,037 - INFO - Scaling time: 0.08s
2024-12-27 20:21:36,042 - INFO - Training completed in 0.09s
2024-12-27 20:21:36,043 - INFO - Final memory usage: CPU 3293.3 MB, GPU 71.8 MB
2024-12-27 20:21:36,043 - INFO - Model training completed in 0.09s
2024-12-27 20:21:36,059 - INFO - Prediction completed in 0.02s
2024-12-27 20:21:36,068 - INFO - Poison rate 0.0 completed in 0.11s
2024-12-27 20:21:36,068 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:21:36,069 - INFO - Label flipping details:
2024-12-27 20:21:36,069 - INFO - - Source class: 1
2024-12-27 20:21:36,069 - INFO - - Target class: 0
2024-12-27 20:21:36,069 - INFO - - Available samples in source class: 50
2024-12-27 20:21:36,069 - INFO - - Requested samples to poison: 50
2024-12-27 20:21:36,069 - INFO - - Actual samples to flip: 49
2024-12-27 20:21:36,069 - INFO - - Samples remaining in source class: 1
2024-12-27 20:21:36,069 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:21:36,069 - INFO - Total number of labels flipped: 49
2024-12-27 20:21:36,069 - INFO - Label flipping completed in 0.00s
2024-12-27 20:21:36,069 - INFO - Training set processing completed in 0.00s
2024-12-27 20:21:36,069 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:21:36,070 - INFO - Memory usage at start_fit: CPU 3293.3 MB, GPU 71.8 MB
2024-12-27 20:21:36,071 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:21:36,148 - INFO - Fitted scaler and transformed data
2024-12-27 20:21:36,148 - INFO - Scaling time: 0.08s
2024-12-27 20:21:36,154 - INFO - Training completed in 0.08s
2024-12-27 20:21:36,155 - INFO - Final memory usage: CPU 3293.3 MB, GPU 71.8 MB
2024-12-27 20:21:36,155 - INFO - Model training completed in 0.09s
2024-12-27 20:21:36,177 - INFO - Prediction completed in 0.02s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:21:36,186 - INFO - Poison rate 0.01 completed in 0.12s
2024-12-27 20:21:36,187 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:21:36,187 - INFO - Label flipping details:
2024-12-27 20:21:36,187 - INFO - - Source class: 1
2024-12-27 20:21:36,187 - INFO - - Target class: 0
2024-12-27 20:21:36,187 - INFO - - Available samples in source class: 50
2024-12-27 20:21:36,187 - INFO - - Requested samples to poison: 150
2024-12-27 20:21:36,187 - INFO - - Actual samples to flip: 49
2024-12-27 20:21:36,187 - INFO - - Samples remaining in source class: 1
2024-12-27 20:21:36,187 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:21:36,188 - INFO - Total number of labels flipped: 49
2024-12-27 20:21:36,188 - INFO - Label flipping completed in 0.00s
2024-12-27 20:21:36,188 - INFO - Training set processing completed in 0.00s
2024-12-27 20:21:36,188 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:21:36,189 - INFO - Memory usage at start_fit: CPU 3293.3 MB, GPU 71.8 MB
2024-12-27 20:21:36,189 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:21:36,251 - INFO - Fitted scaler and transformed data
2024-12-27 20:21:36,252 - INFO - Scaling time: 0.06s
2024-12-27 20:21:36,257 - INFO - Training completed in 0.07s
2024-12-27 20:21:36,258 - INFO - Final memory usage: CPU 3293.3 MB, GPU 71.8 MB
2024-12-27 20:21:36,258 - INFO - Model training completed in 0.07s
2024-12-27 20:21:36,281 - INFO - Prediction completed in 0.02s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:21:36,290 - INFO - Poison rate 0.03 completed in 0.10s
2024-12-27 20:21:36,291 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:21:36,291 - INFO - Label flipping details:
2024-12-27 20:21:36,291 - INFO - - Source class: 1
2024-12-27 20:21:36,291 - INFO - - Target class: 0
2024-12-27 20:21:36,291 - INFO - - Available samples in source class: 50
2024-12-27 20:21:36,291 - INFO - - Requested samples to poison: 250
2024-12-27 20:21:36,291 - INFO - - Actual samples to flip: 49
2024-12-27 20:21:36,291 - INFO - - Samples remaining in source class: 1
2024-12-27 20:21:36,291 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:21:36,291 - INFO - Total number of labels flipped: 49
2024-12-27 20:21:36,291 - INFO - Label flipping completed in 0.00s
2024-12-27 20:21:36,291 - INFO - Training set processing completed in 0.00s
2024-12-27 20:21:36,291 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:21:36,292 - INFO - Memory usage at start_fit: CPU 3293.3 MB, GPU 71.8 MB
2024-12-27 20:21:36,292 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:21:36,355 - INFO - Fitted scaler and transformed data
2024-12-27 20:21:36,356 - INFO - Scaling time: 0.06s
2024-12-27 20:21:36,361 - INFO - Training completed in 0.07s
2024-12-27 20:21:36,361 - INFO - Final memory usage: CPU 3293.3 MB, GPU 71.8 MB
2024-12-27 20:21:36,361 - INFO - Model training completed in 0.07s
2024-12-27 20:21:36,374 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:21:36,383 - INFO - Poison rate 0.05 completed in 0.09s
2024-12-27 20:21:36,383 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:21:36,384 - INFO - Label flipping details:
2024-12-27 20:21:36,384 - INFO - - Source class: 1
2024-12-27 20:21:36,384 - INFO - - Target class: 0
2024-12-27 20:21:36,384 - INFO - - Available samples in source class: 50
2024-12-27 20:21:36,384 - INFO - - Requested samples to poison: 350
2024-12-27 20:21:36,384 - INFO - - Actual samples to flip: 49
2024-12-27 20:21:36,384 - INFO - - Samples remaining in source class: 1
2024-12-27 20:21:36,384 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:21:36,384 - INFO - Total number of labels flipped: 49
2024-12-27 20:21:36,384 - INFO - Label flipping completed in 0.00s
2024-12-27 20:21:36,384 - INFO - Training set processing completed in 0.00s
2024-12-27 20:21:36,384 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:21:36,385 - INFO - Memory usage at start_fit: CPU 3293.3 MB, GPU 71.8 MB
2024-12-27 20:21:36,385 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:21:36,445 - INFO - Fitted scaler and transformed data
2024-12-27 20:21:36,445 - INFO - Scaling time: 0.06s
2024-12-27 20:21:36,450 - INFO - Training completed in 0.07s
2024-12-27 20:21:36,451 - INFO - Final memory usage: CPU 3293.3 MB, GPU 71.8 MB
2024-12-27 20:21:36,451 - INFO - Model training completed in 0.07s
2024-12-27 20:21:36,464 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:21:36,473 - INFO - Poison rate 0.07 completed in 0.09s
2024-12-27 20:21:36,473 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:21:36,474 - INFO - Label flipping details:
2024-12-27 20:21:36,474 - INFO - - Source class: 1
2024-12-27 20:21:36,474 - INFO - - Target class: 0
2024-12-27 20:21:36,474 - INFO - - Available samples in source class: 50
2024-12-27 20:21:36,474 - INFO - - Requested samples to poison: 500
2024-12-27 20:21:36,474 - INFO - - Actual samples to flip: 49
2024-12-27 20:21:36,474 - INFO - - Samples remaining in source class: 1
2024-12-27 20:21:36,474 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:21:36,474 - INFO - Total number of labels flipped: 49
2024-12-27 20:21:36,474 - INFO - Label flipping completed in 0.00s
2024-12-27 20:21:36,474 - INFO - Training set processing completed in 0.00s
2024-12-27 20:21:36,474 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:21:36,475 - INFO - Memory usage at start_fit: CPU 3293.3 MB, GPU 71.8 MB
2024-12-27 20:21:36,475 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:21:36,537 - INFO - Fitted scaler and transformed data
2024-12-27 20:21:36,537 - INFO - Scaling time: 0.06s
2024-12-27 20:21:36,543 - INFO - Training completed in 0.07s
2024-12-27 20:21:36,544 - INFO - Final memory usage: CPU 3293.3 MB, GPU 71.8 MB
2024-12-27 20:21:36,544 - INFO - Model training completed in 0.07s
2024-12-27 20:21:36,557 - INFO - Prediction completed in 0.01s
2024-12-27 20:21:36,566 - INFO - Poison rate 0.1 completed in 0.09s
2024-12-27 20:21:36,566 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:21:36,566 - INFO - Label flipping details:
2024-12-27 20:21:36,566 - INFO - - Source class: 1
2024-12-27 20:21:36,567 - INFO - - Target class: 0
2024-12-27 20:21:36,567 - INFO - - Available samples in source class: 50
2024-12-27 20:21:36,567 - INFO - - Requested samples to poison: 1000
2024-12-27 20:21:36,567 - INFO - - Actual samples to flip: 49
2024-12-27 20:21:36,567 - INFO - - Samples remaining in source class: 1
2024-12-27 20:21:36,567 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:21:36,567 - INFO - Total number of labels flipped: 49
2024-12-27 20:21:36,567 - INFO - Label flipping completed in 0.00s
2024-12-27 20:21:36,567 - INFO - Training set processing completed in 0.00s
2024-12-27 20:21:36,567 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:21:36,568 - INFO - Memory usage at start_fit: CPU 3293.3 MB, GPU 71.8 MB
2024-12-27 20:21:36,568 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:21:36,636 - INFO - Fitted scaler and transformed data
2024-12-27 20:21:36,636 - INFO - Scaling time: 0.07s
2024-12-27 20:21:36,641 - INFO - Training completed in 0.07s
2024-12-27 20:21:36,641 - INFO - Final memory usage: CPU 3293.3 MB, GPU 71.8 MB
2024-12-27 20:21:36,641 - INFO - Model training completed in 0.07s
2024-12-27 20:21:36,666 - INFO - Prediction completed in 0.02s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:21:36,675 - INFO - Poison rate 0.2 completed in 0.11s
2024-12-27 20:21:36,677 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:21:36,677 - INFO - Total evaluation time: 6.63s
2024-12-27 20:21:36,678 - INFO - 
Progress: 58.3% - Evaluating CIFAR100 with KNeighbors (dynadetect mode, iteration 1/1)
2024-12-27 20:21:36,750 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:21:36,823 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:21:36,906 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:21:36,906 - INFO - Dataset type: image
2024-12-27 20:21:36,906 - INFO - Sample size: 5000
2024-12-27 20:21:36,906 - INFO - Using device: cuda
2024-12-27 20:21:36,908 - INFO - Loading datasets...
2024-12-27 20:21:38,253 - INFO - Dataset loading completed in 1.34s
2024-12-27 20:21:38,253 - INFO - Extracting validation features...
2024-12-27 20:21:38,253 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:08,  3.67it/s]Extracting features:  12%|█▎        | 4/32 [00:00<00:02, 12.40it/s]Extracting features:  22%|██▏       | 7/32 [00:00<00:01, 17.96it/s]Extracting features:  34%|███▍      | 11/32 [00:00<00:00, 24.84it/s]Extracting features:  50%|█████     | 16/32 [00:00<00:00, 32.13it/s]Extracting features:  69%|██████▉   | 22/32 [00:00<00:00, 39.74it/s]Extracting features:  91%|█████████ | 29/32 [00:00<00:00, 47.53it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 31.98it/s]
2024-12-27 20:21:39,257 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:21:39,257 - INFO - Validation feature extraction completed in 1.00s
2024-12-27 20:21:39,257 - INFO - Extracting training features...
2024-12-27 20:21:39,257 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:46,  3.37it/s]Extracting features:   4%|▍         | 7/157 [00:00<00:07, 20.86it/s]Extracting features:   8%|▊         | 12/157 [00:00<00:04, 29.34it/s]Extracting features:  11%|█▏        | 18/157 [00:00<00:03, 36.43it/s]Extracting features:  15%|█▍        | 23/157 [00:00<00:03, 39.50it/s]Extracting features:  18%|█▊        | 28/157 [00:00<00:03, 42.11it/s]Extracting features:  22%|██▏       | 34/157 [00:00<00:02, 45.62it/s]Extracting features:  25%|██▌       | 40/157 [00:01<00:02, 49.44it/s]Extracting features:  29%|██▉       | 46/157 [00:01<00:02, 51.48it/s]Extracting features:  33%|███▎      | 52/157 [00:01<00:02, 52.12it/s]Extracting features:  37%|███▋      | 58/157 [00:01<00:01, 51.13it/s]Extracting features:  41%|████      | 64/157 [00:01<00:01, 53.25it/s]Extracting features:  45%|████▍     | 70/157 [00:01<00:01, 51.76it/s]Extracting features:  48%|████▊     | 76/157 [00:01<00:01, 50.78it/s]Extracting features:  52%|█████▏    | 82/157 [00:01<00:01, 52.67it/s]Extracting features:  56%|█████▌    | 88/157 [00:01<00:01, 52.71it/s]Extracting features:  60%|█████▉    | 94/157 [00:02<00:01, 52.83it/s]Extracting features:  64%|██████▎   | 100/157 [00:02<00:01, 54.23it/s]Extracting features:  68%|██████▊   | 106/157 [00:02<00:00, 54.91it/s]Extracting features:  71%|███████▏  | 112/157 [00:02<00:00, 51.77it/s]Extracting features:  75%|███████▌  | 118/157 [00:02<00:00, 52.22it/s]Extracting features:  79%|███████▉  | 124/157 [00:02<00:00, 50.87it/s]Extracting features:  83%|████████▎ | 130/157 [00:02<00:00, 52.37it/s]Extracting features:  87%|████████▋ | 136/157 [00:02<00:00, 52.70it/s]Extracting features:  90%|█████████ | 142/157 [00:02<00:00, 53.05it/s]Extracting features:  94%|█████████▍| 148/157 [00:03<00:00, 54.28it/s]Extracting features:  99%|█████████▊| 155/157 [00:03<00:00, 57.40it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 47.83it/s]
2024-12-27 20:21:42,553 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:21:42,553 - INFO - Training feature extraction completed in 3.30s
2024-12-27 20:21:42,553 - INFO - Creating model for classifier: KNeighbors
2024-12-27 20:21:42,553 - INFO - Using device: cuda
2024-12-27 20:21:42,553 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:21:42,553 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:21:42,554 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:21:43,146 - INFO - Feature scaling completed in 0.59s
2024-12-27 20:21:43,146 - INFO - Starting feature selection (k=50)
2024-12-27 20:21:43,152 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:21:43,152 - INFO - Starting anomaly detection
2024-12-27 20:21:44,546 - INFO - Anomaly detection completed in 1.39s
2024-12-27 20:21:44,547 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:21:44,547 - INFO - Total fit_transform time: 1.99s
2024-12-27 20:21:44,547 - INFO - Training set processing completed in 1.99s
2024-12-27 20:21:44,547 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:21:44,548 - INFO - Memory usage at start_fit: CPU 3290.1 MB, GPU 47.3 MB
2024-12-27 20:21:44,548 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:21:44,621 - INFO - Fitted scaler and transformed data
2024-12-27 20:21:44,621 - INFO - Scaling time: 0.07s
2024-12-27 20:21:44,628 - INFO - Training completed in 0.08s
2024-12-27 20:21:44,628 - INFO - Final memory usage: CPU 3290.1 MB, GPU 71.8 MB
2024-12-27 20:21:44,628 - INFO - Model training completed in 0.08s
2024-12-27 20:21:44,647 - INFO - Prediction completed in 0.02s
2024-12-27 20:21:44,663 - INFO - Poison rate 0.0 completed in 2.11s
2024-12-27 20:21:44,664 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:21:44,664 - INFO - Label flipping details:
2024-12-27 20:21:44,664 - INFO - - Source class: 1
2024-12-27 20:21:44,665 - INFO - - Target class: 0
2024-12-27 20:21:44,665 - INFO - - Available samples in source class: 50
2024-12-27 20:21:44,665 - INFO - - Requested samples to poison: 50
2024-12-27 20:21:44,665 - INFO - - Actual samples to flip: 49
2024-12-27 20:21:44,665 - INFO - - Samples remaining in source class: 1
2024-12-27 20:21:44,665 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:21:44,665 - INFO - Total number of labels flipped: 49
2024-12-27 20:21:44,665 - INFO - Label flipping completed in 0.00s
2024-12-27 20:21:44,665 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:21:44,665 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:21:45,274 - INFO - Feature scaling completed in 0.61s
2024-12-27 20:21:45,274 - INFO - Starting feature selection (k=50)
2024-12-27 20:21:45,279 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:21:45,280 - INFO - Starting anomaly detection
2024-12-27 20:21:46,659 - INFO - Anomaly detection completed in 1.38s
2024-12-27 20:21:46,659 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:21:46,660 - INFO - Total fit_transform time: 1.99s
2024-12-27 20:21:46,660 - INFO - Training set processing completed in 1.99s
2024-12-27 20:21:46,660 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:21:46,661 - INFO - Memory usage at start_fit: CPU 3290.1 MB, GPU 71.8 MB
2024-12-27 20:21:46,661 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:21:46,742 - INFO - Fitted scaler and transformed data
2024-12-27 20:21:46,742 - INFO - Scaling time: 0.08s
2024-12-27 20:21:46,747 - INFO - Training completed in 0.09s
2024-12-27 20:21:46,748 - INFO - Final memory usage: CPU 3290.1 MB, GPU 71.8 MB
2024-12-27 20:21:46,748 - INFO - Model training completed in 0.09s
2024-12-27 20:21:46,768 - INFO - Prediction completed in 0.02s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:21:46,777 - INFO - Poison rate 0.01 completed in 2.11s
2024-12-27 20:21:46,777 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:21:46,778 - INFO - Label flipping details:
2024-12-27 20:21:46,778 - INFO - - Source class: 1
2024-12-27 20:21:46,778 - INFO - - Target class: 0
2024-12-27 20:21:46,778 - INFO - - Available samples in source class: 50
2024-12-27 20:21:46,778 - INFO - - Requested samples to poison: 150
2024-12-27 20:21:46,778 - INFO - - Actual samples to flip: 49
2024-12-27 20:21:46,778 - INFO - - Samples remaining in source class: 1
2024-12-27 20:21:46,778 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:21:46,778 - INFO - Total number of labels flipped: 49
2024-12-27 20:21:46,778 - INFO - Label flipping completed in 0.00s
2024-12-27 20:21:46,778 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:21:46,778 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:21:47,357 - INFO - Feature scaling completed in 0.58s
2024-12-27 20:21:47,357 - INFO - Starting feature selection (k=50)
2024-12-27 20:21:47,362 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:21:47,363 - INFO - Starting anomaly detection
2024-12-27 20:21:49,317 - INFO - Anomaly detection completed in 1.95s
2024-12-27 20:21:49,317 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:21:49,317 - INFO - Total fit_transform time: 2.54s
2024-12-27 20:21:49,317 - INFO - Training set processing completed in 2.54s
2024-12-27 20:21:49,317 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:21:49,319 - INFO - Memory usage at start_fit: CPU 3290.1 MB, GPU 71.8 MB
2024-12-27 20:21:49,319 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:21:49,389 - INFO - Fitted scaler and transformed data
2024-12-27 20:21:49,389 - INFO - Scaling time: 0.07s
2024-12-27 20:21:49,395 - INFO - Training completed in 0.08s
2024-12-27 20:21:49,396 - INFO - Final memory usage: CPU 3290.1 MB, GPU 71.8 MB
2024-12-27 20:21:49,396 - INFO - Model training completed in 0.08s
2024-12-27 20:21:49,421 - INFO - Prediction completed in 0.02s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:21:49,430 - INFO - Poison rate 0.03 completed in 2.65s
2024-12-27 20:21:49,430 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:21:49,430 - INFO - Label flipping details:
2024-12-27 20:21:49,430 - INFO - - Source class: 1
2024-12-27 20:21:49,430 - INFO - - Target class: 0
2024-12-27 20:21:49,430 - INFO - - Available samples in source class: 50
2024-12-27 20:21:49,430 - INFO - - Requested samples to poison: 250
2024-12-27 20:21:49,430 - INFO - - Actual samples to flip: 49
2024-12-27 20:21:49,430 - INFO - - Samples remaining in source class: 1
2024-12-27 20:21:49,431 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:21:49,431 - INFO - Total number of labels flipped: 49
2024-12-27 20:21:49,431 - INFO - Label flipping completed in 0.00s
2024-12-27 20:21:49,431 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:21:49,431 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:21:50,065 - INFO - Feature scaling completed in 0.63s
2024-12-27 20:21:50,065 - INFO - Starting feature selection (k=50)
2024-12-27 20:21:50,073 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:21:50,074 - INFO - Starting anomaly detection
2024-12-27 20:21:51,796 - INFO - Anomaly detection completed in 1.72s
2024-12-27 20:21:51,796 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:21:51,796 - INFO - Total fit_transform time: 2.37s
2024-12-27 20:21:51,796 - INFO - Training set processing completed in 2.37s
2024-12-27 20:21:51,796 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:21:51,797 - INFO - Memory usage at start_fit: CPU 3290.1 MB, GPU 71.8 MB
2024-12-27 20:21:51,797 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:21:51,874 - INFO - Fitted scaler and transformed data
2024-12-27 20:21:51,874 - INFO - Scaling time: 0.08s
2024-12-27 20:21:51,883 - INFO - Training completed in 0.09s
2024-12-27 20:21:51,883 - INFO - Final memory usage: CPU 3290.1 MB, GPU 71.8 MB
2024-12-27 20:21:51,884 - INFO - Model training completed in 0.09s
2024-12-27 20:21:51,908 - INFO - Prediction completed in 0.02s
2024-12-27 20:21:51,917 - INFO - Poison rate 0.05 completed in 2.49s
2024-12-27 20:21:51,917 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:21:51,918 - INFO - Label flipping details:
2024-12-27 20:21:51,918 - INFO - - Source class: 1
2024-12-27 20:21:51,918 - INFO - - Target class: 0
2024-12-27 20:21:51,918 - INFO - - Available samples in source class: 50
2024-12-27 20:21:51,918 - INFO - - Requested samples to poison: 350
2024-12-27 20:21:51,918 - INFO - - Actual samples to flip: 49
2024-12-27 20:21:51,918 - INFO - - Samples remaining in source class: 1
2024-12-27 20:21:51,918 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:21:51,918 - INFO - Total number of labels flipped: 49
2024-12-27 20:21:51,918 - INFO - Label flipping completed in 0.00s
2024-12-27 20:21:51,918 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:21:51,918 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:21:52,523 - INFO - Feature scaling completed in 0.60s
2024-12-27 20:21:52,523 - INFO - Starting feature selection (k=50)
2024-12-27 20:21:52,534 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:21:52,534 - INFO - Starting anomaly detection
2024-12-27 20:21:54,481 - INFO - Anomaly detection completed in 1.95s
2024-12-27 20:21:54,481 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:21:54,481 - INFO - Total fit_transform time: 2.56s
2024-12-27 20:21:54,481 - INFO - Training set processing completed in 2.56s
2024-12-27 20:21:54,481 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:21:54,482 - INFO - Memory usage at start_fit: CPU 3290.1 MB, GPU 71.8 MB
2024-12-27 20:21:54,482 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:21:54,550 - INFO - Fitted scaler and transformed data
2024-12-27 20:21:54,550 - INFO - Scaling time: 0.07s
2024-12-27 20:21:54,556 - INFO - Training completed in 0.07s
2024-12-27 20:21:54,556 - INFO - Final memory usage: CPU 3290.1 MB, GPU 71.8 MB
2024-12-27 20:21:54,557 - INFO - Model training completed in 0.08s
2024-12-27 20:21:54,582 - INFO - Prediction completed in 0.03s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:21:54,591 - INFO - Poison rate 0.07 completed in 2.67s
2024-12-27 20:21:54,591 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:21:54,592 - INFO - Label flipping details:
2024-12-27 20:21:54,592 - INFO - - Source class: 1
2024-12-27 20:21:54,592 - INFO - - Target class: 0
2024-12-27 20:21:54,592 - INFO - - Available samples in source class: 50
2024-12-27 20:21:54,592 - INFO - - Requested samples to poison: 500
2024-12-27 20:21:54,592 - INFO - - Actual samples to flip: 49
2024-12-27 20:21:54,592 - INFO - - Samples remaining in source class: 1
2024-12-27 20:21:54,592 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:21:54,592 - INFO - Total number of labels flipped: 49
2024-12-27 20:21:54,592 - INFO - Label flipping completed in 0.00s
2024-12-27 20:21:54,592 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:21:54,592 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:21:55,139 - INFO - Feature scaling completed in 0.55s
2024-12-27 20:21:55,139 - INFO - Starting feature selection (k=50)
2024-12-27 20:21:55,147 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:21:55,147 - INFO - Starting anomaly detection
2024-12-27 20:21:56,687 - INFO - Anomaly detection completed in 1.54s
2024-12-27 20:21:56,687 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:21:56,687 - INFO - Total fit_transform time: 2.10s
2024-12-27 20:21:56,687 - INFO - Training set processing completed in 2.10s
2024-12-27 20:21:56,687 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:21:56,688 - INFO - Memory usage at start_fit: CPU 3290.1 MB, GPU 71.8 MB
2024-12-27 20:21:56,688 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:21:56,756 - INFO - Fitted scaler and transformed data
2024-12-27 20:21:56,756 - INFO - Scaling time: 0.07s
2024-12-27 20:21:56,764 - INFO - Training completed in 0.08s
2024-12-27 20:21:56,765 - INFO - Final memory usage: CPU 3290.1 MB, GPU 71.8 MB
2024-12-27 20:21:56,765 - INFO - Model training completed in 0.08s
2024-12-27 20:21:56,791 - INFO - Prediction completed in 0.03s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:21:56,799 - INFO - Poison rate 0.1 completed in 2.21s
2024-12-27 20:21:56,800 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:21:56,800 - INFO - Label flipping details:
2024-12-27 20:21:56,800 - INFO - - Source class: 1
2024-12-27 20:21:56,800 - INFO - - Target class: 0
2024-12-27 20:21:56,800 - INFO - - Available samples in source class: 50
2024-12-27 20:21:56,800 - INFO - - Requested samples to poison: 1000
2024-12-27 20:21:56,800 - INFO - - Actual samples to flip: 49
2024-12-27 20:21:56,800 - INFO - - Samples remaining in source class: 1
2024-12-27 20:21:56,800 - INFO - Successfully flipped 49 labels from class 1 to 0
2024-12-27 20:21:56,801 - INFO - Total number of labels flipped: 49
2024-12-27 20:21:56,801 - INFO - Label flipping completed in 0.00s
2024-12-27 20:21:56,801 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:21:56,801 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:21:57,380 - INFO - Feature scaling completed in 0.58s
2024-12-27 20:21:57,380 - INFO - Starting feature selection (k=50)
2024-12-27 20:21:57,388 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:21:57,388 - INFO - Starting anomaly detection
2024-12-27 20:21:59,505 - INFO - Anomaly detection completed in 2.12s
2024-12-27 20:21:59,505 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:21:59,505 - INFO - Total fit_transform time: 2.70s
2024-12-27 20:21:59,505 - INFO - Training set processing completed in 2.70s
2024-12-27 20:21:59,505 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:21:59,507 - INFO - Memory usage at start_fit: CPU 3290.1 MB, GPU 71.8 MB
2024-12-27 20:21:59,507 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:21:59,598 - INFO - Fitted scaler and transformed data
2024-12-27 20:21:59,599 - INFO - Scaling time: 0.09s
2024-12-27 20:21:59,605 - INFO - Training completed in 0.10s
2024-12-27 20:21:59,605 - INFO - Final memory usage: CPU 3290.1 MB, GPU 71.8 MB
2024-12-27 20:21:59,606 - INFO - Model training completed in 0.10s
2024-12-27 20:21:59,630 - INFO - Prediction completed in 0.02s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:21:59,639 - INFO - Poison rate 0.2 completed in 2.84s
2024-12-27 20:21:59,641 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:21:59,641 - INFO - Total evaluation time: 22.73s
2024-12-27 20:21:59,642 - INFO - Completed evaluation for CIFAR100
2024-12-27 20:21:59,642 - INFO - 
Processing dataset: CIFAR100
2024-12-27 20:21:59,715 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:21:59,798 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:21:59,873 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:21:59,874 - INFO - Dataset type: image
2024-12-27 20:21:59,874 - INFO - Sample size: 5000
2024-12-27 20:21:59,874 - INFO - Using device: cuda
2024-12-27 20:21:59,876 - INFO - 
Progress: 59.4% - Evaluating CIFAR100 with SVM (standard mode, iteration 1/1)
2024-12-27 20:21:59,934 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:22:00,009 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:22:00,068 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:22:00,068 - INFO - Dataset type: image
2024-12-27 20:22:00,068 - INFO - Sample size: 5000
2024-12-27 20:22:00,068 - INFO - Using device: cuda
2024-12-27 20:22:00,070 - INFO - Loading datasets...
2024-12-27 20:22:01,438 - INFO - Dataset loading completed in 1.37s
2024-12-27 20:22:01,438 - INFO - Extracting validation features...
2024-12-27 20:22:01,438 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:17,  1.82it/s]Extracting features:  19%|█▉        | 6/32 [00:00<00:02, 11.26it/s]Extracting features:  34%|███▍      | 11/32 [00:00<00:01, 19.54it/s]Extracting features:  50%|█████     | 16/32 [00:00<00:00, 26.09it/s]Extracting features:  66%|██████▌   | 21/32 [00:00<00:00, 31.62it/s]Extracting features:  84%|████████▍ | 27/32 [00:01<00:00, 38.33it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 26.19it/s]
2024-12-27 20:22:02,666 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:22:02,666 - INFO - Validation feature extraction completed in 1.23s
2024-12-27 20:22:02,666 - INFO - Extracting training features...
2024-12-27 20:22:02,666 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:39,  3.94it/s]Extracting features:   4%|▍         | 6/157 [00:00<00:07, 20.43it/s]Extracting features:   8%|▊         | 12/157 [00:00<00:04, 32.24it/s]Extracting features:  12%|█▏        | 19/157 [00:00<00:03, 41.31it/s]Extracting features:  16%|█▌        | 25/157 [00:00<00:02, 44.81it/s]Extracting features:  20%|██        | 32/157 [00:00<00:02, 49.81it/s]Extracting features:  24%|██▍       | 38/157 [00:00<00:02, 49.27it/s]Extracting features:  28%|██▊       | 44/157 [00:01<00:02, 49.42it/s]Extracting features:  32%|███▏      | 51/157 [00:01<00:02, 52.38it/s]Extracting features:  36%|███▋      | 57/157 [00:01<00:01, 54.40it/s]Extracting features:  40%|████      | 63/157 [00:01<00:01, 53.00it/s]Extracting features:  44%|████▍     | 69/157 [00:01<00:01, 52.86it/s]Extracting features:  48%|████▊     | 76/157 [00:01<00:01, 54.97it/s]Extracting features:  52%|█████▏    | 82/157 [00:01<00:01, 53.14it/s]Extracting features:  57%|█████▋    | 89/157 [00:01<00:01, 55.46it/s]Extracting features:  61%|██████    | 95/157 [00:01<00:01, 55.08it/s]Extracting features:  64%|██████▍   | 101/157 [00:02<00:00, 56.05it/s]Extracting features:  68%|██████▊   | 107/157 [00:02<00:00, 55.98it/s]Extracting features:  73%|███████▎  | 114/157 [00:02<00:00, 56.88it/s]Extracting features:  76%|███████▋  | 120/157 [00:02<00:00, 57.08it/s]Extracting features:  80%|████████  | 126/157 [00:02<00:00, 56.83it/s]Extracting features:  85%|████████▍ | 133/157 [00:02<00:00, 58.49it/s]Extracting features:  89%|████████▊ | 139/157 [00:02<00:00, 58.83it/s]Extracting features:  92%|█████████▏| 145/157 [00:02<00:00, 57.15it/s]Extracting features:  96%|█████████▌| 151/157 [00:02<00:00, 57.74it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 55.78it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 50.06it/s]
2024-12-27 20:22:05,815 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:22:05,816 - INFO - Training feature extraction completed in 3.15s
2024-12-27 20:22:05,816 - INFO - Creating model for classifier: SVM
2024-12-27 20:22:05,816 - INFO - Using device: cuda
2024-12-27 20:22:05,816 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-27 20:22:05,816 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:22:05,816 - INFO - Training set processing completed in 0.00s
2024-12-27 20:22:05,816 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:22:05,818 - INFO - Memory usage at start_fit: CPU 3270.9 MB, GPU 47.3 MB
2024-12-27 20:22:05,818 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:22:05,819 - INFO - Number of unique classes: 100
2024-12-27 20:22:05,932 - INFO - Fitted scaler and transformed data
2024-12-27 20:22:05,932 - INFO - Scaling time: 0.11s
2024-12-27 20:22:06,119 - INFO - Epoch 1/25, Train Loss: 21.5880, Val Loss: 13.0109
2024-12-27 20:22:06,297 - INFO - Epoch 2/25, Train Loss: 2.0677, Val Loss: 12.2348
2024-12-27 20:22:06,473 - INFO - Epoch 3/25, Train Loss: 0.7120, Val Loss: 11.3302
2024-12-27 20:22:06,670 - INFO - Epoch 4/25, Train Loss: 0.2968, Val Loss: 11.1715
2024-12-27 20:22:06,853 - INFO - Epoch 5/25, Train Loss: 0.1423, Val Loss: 11.2105
2024-12-27 20:22:07,017 - INFO - Epoch 6/25, Train Loss: 0.0660, Val Loss: 10.9897
2024-12-27 20:22:07,189 - INFO - Epoch 7/25, Train Loss: 0.0287, Val Loss: 10.9641
2024-12-27 20:22:07,359 - INFO - Epoch 8/25, Train Loss: 0.0112, Val Loss: 10.9397
2024-12-27 20:22:07,587 - INFO - Epoch 9/25, Train Loss: 0.0069, Val Loss: 10.9279
2024-12-27 20:22:07,772 - INFO - Epoch 10/25, Train Loss: 0.0071, Val Loss: 10.9474
2024-12-27 20:22:07,974 - INFO - Epoch 11/25, Train Loss: 0.0018, Val Loss: 10.9347
2024-12-27 20:22:07,975 - INFO - Early stopping triggered at epoch 11
2024-12-27 20:22:07,975 - INFO - Training completed in 2.16s
2024-12-27 20:22:07,975 - INFO - Final memory usage: CPU 3299.3 MB, GPU 49.9 MB
2024-12-27 20:22:07,975 - INFO - Model training completed in 2.16s
2024-12-27 20:22:07,982 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:22:07,992 - INFO - Poison rate 0.0 completed in 2.18s
2024-12-27 20:22:07,992 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:22:07,994 - INFO - Total number of labels flipped: 50
2024-12-27 20:22:07,994 - INFO - Label flipping completed in 0.00s
2024-12-27 20:22:07,994 - INFO - Training set processing completed in 0.00s
2024-12-27 20:22:07,994 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:22:07,995 - INFO - Memory usage at start_fit: CPU 3299.3 MB, GPU 49.3 MB
2024-12-27 20:22:07,995 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:22:07,995 - INFO - Number of unique classes: 100
2024-12-27 20:22:08,089 - INFO - Fitted scaler and transformed data
2024-12-27 20:22:08,090 - INFO - Scaling time: 0.09s
2024-12-27 20:22:08,299 - INFO - Epoch 1/25, Train Loss: 23.4292, Val Loss: 19.3568
2024-12-27 20:22:08,494 - INFO - Epoch 2/25, Train Loss: 1.9936, Val Loss: 20.4263
2024-12-27 20:22:08,677 - INFO - Epoch 3/25, Train Loss: 0.7324, Val Loss: 19.4358
2024-12-27 20:22:08,677 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:22:08,677 - INFO - Training completed in 0.68s
2024-12-27 20:22:08,677 - INFO - Final memory usage: CPU 3299.3 MB, GPU 49.9 MB
2024-12-27 20:22:08,678 - INFO - Model training completed in 0.68s
2024-12-27 20:22:08,684 - INFO - Prediction completed in 0.01s
2024-12-27 20:22:08,693 - INFO - Poison rate 0.01 completed in 0.70s
2024-12-27 20:22:08,694 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:22:08,698 - INFO - Total number of labels flipped: 150
2024-12-27 20:22:08,698 - INFO - Label flipping completed in 0.00s
2024-12-27 20:22:08,699 - INFO - Training set processing completed in 0.00s
2024-12-27 20:22:08,699 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:22:08,699 - INFO - Memory usage at start_fit: CPU 3299.3 MB, GPU 49.3 MB
2024-12-27 20:22:08,699 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:22:08,700 - INFO - Number of unique classes: 100
2024-12-27 20:22:08,778 - INFO - Fitted scaler and transformed data
2024-12-27 20:22:08,779 - INFO - Scaling time: 0.08s
2024-12-27 20:22:08,988 - INFO - Epoch 1/25, Train Loss: 31.3059, Val Loss: 20.8543
2024-12-27 20:22:09,166 - INFO - Epoch 2/25, Train Loss: 2.7541, Val Loss: 20.3963
2024-12-27 20:22:09,335 - INFO - Epoch 3/25, Train Loss: 0.9251, Val Loss: 18.7182
2024-12-27 20:22:09,510 - INFO - Epoch 4/25, Train Loss: 0.4168, Val Loss: 18.2792
2024-12-27 20:22:09,705 - INFO - Epoch 5/25, Train Loss: 0.2245, Val Loss: 18.2783
2024-12-27 20:22:09,894 - INFO - Epoch 6/25, Train Loss: 0.1142, Val Loss: 18.1333
2024-12-27 20:22:10,084 - INFO - Epoch 7/25, Train Loss: 0.0538, Val Loss: 18.1964
2024-12-27 20:22:10,279 - INFO - Epoch 8/25, Train Loss: 0.0365, Val Loss: 18.0313
2024-12-27 20:22:10,482 - INFO - Epoch 9/25, Train Loss: 0.0199, Val Loss: 18.0884
2024-12-27 20:22:10,679 - INFO - Epoch 10/25, Train Loss: 0.0172, Val Loss: 18.2286
2024-12-27 20:22:10,680 - INFO - Early stopping triggered at epoch 10
2024-12-27 20:22:10,680 - INFO - Training completed in 1.98s
2024-12-27 20:22:10,680 - INFO - Final memory usage: CPU 3299.3 MB, GPU 49.9 MB
2024-12-27 20:22:10,680 - INFO - Model training completed in 1.98s
2024-12-27 20:22:10,686 - INFO - Prediction completed in 0.01s
2024-12-27 20:22:10,695 - INFO - Poison rate 0.03 completed in 2.00s
2024-12-27 20:22:10,695 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:22:10,703 - INFO - Total number of labels flipped: 250
2024-12-27 20:22:10,704 - INFO - Label flipping completed in 0.01s
2024-12-27 20:22:10,704 - INFO - Training set processing completed in 0.00s
2024-12-27 20:22:10,704 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:22:10,705 - INFO - Memory usage at start_fit: CPU 3299.3 MB, GPU 49.3 MB
2024-12-27 20:22:10,705 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:22:10,705 - INFO - Number of unique classes: 100
2024-12-27 20:22:10,821 - INFO - Fitted scaler and transformed data
2024-12-27 20:22:10,821 - INFO - Scaling time: 0.11s
2024-12-27 20:22:11,040 - INFO - Epoch 1/25, Train Loss: 36.1548, Val Loss: 32.6870
2024-12-27 20:22:11,242 - INFO - Epoch 2/25, Train Loss: 2.8576, Val Loss: 34.2141
2024-12-27 20:22:11,419 - INFO - Epoch 3/25, Train Loss: 1.0051, Val Loss: 32.2774
2024-12-27 20:22:11,617 - INFO - Epoch 4/25, Train Loss: 0.4804, Val Loss: 31.6212
2024-12-27 20:22:11,826 - INFO - Epoch 5/25, Train Loss: 0.2418, Val Loss: 31.3060
2024-12-27 20:22:12,004 - INFO - Epoch 6/25, Train Loss: 0.1256, Val Loss: 31.2655
2024-12-27 20:22:12,221 - INFO - Epoch 7/25, Train Loss: 0.0724, Val Loss: 31.1111
2024-12-27 20:22:12,421 - INFO - Epoch 8/25, Train Loss: 0.0417, Val Loss: 31.0271
2024-12-27 20:22:12,636 - INFO - Epoch 9/25, Train Loss: 0.0206, Val Loss: 31.0620
2024-12-27 20:22:12,832 - INFO - Epoch 10/25, Train Loss: 0.0128, Val Loss: 30.8829
2024-12-27 20:22:13,044 - INFO - Epoch 11/25, Train Loss: 0.0086, Val Loss: 30.9938
2024-12-27 20:22:13,248 - INFO - Epoch 12/25, Train Loss: 0.0112, Val Loss: 30.8403
2024-12-27 20:22:13,481 - INFO - Epoch 13/25, Train Loss: 0.0029, Val Loss: 30.7753
2024-12-27 20:22:13,714 - INFO - Epoch 14/25, Train Loss: 0.0025, Val Loss: 30.6377
2024-12-27 20:22:13,940 - INFO - Epoch 15/25, Train Loss: 0.0018, Val Loss: 30.6359
2024-12-27 20:22:14,156 - INFO - Epoch 16/25, Train Loss: 0.0014, Val Loss: 30.6310
2024-12-27 20:22:14,156 - INFO - Early stopping triggered at epoch 16
2024-12-27 20:22:14,156 - INFO - Training completed in 3.45s
2024-12-27 20:22:14,156 - INFO - Final memory usage: CPU 3299.3 MB, GPU 49.9 MB
2024-12-27 20:22:14,157 - INFO - Model training completed in 3.45s
2024-12-27 20:22:14,165 - INFO - Prediction completed in 0.01s
2024-12-27 20:22:14,173 - INFO - Poison rate 0.05 completed in 3.48s
2024-12-27 20:22:14,173 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:22:14,184 - INFO - Total number of labels flipped: 350
2024-12-27 20:22:14,184 - INFO - Label flipping completed in 0.01s
2024-12-27 20:22:14,184 - INFO - Training set processing completed in 0.00s
2024-12-27 20:22:14,184 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:22:14,185 - INFO - Memory usage at start_fit: CPU 3299.3 MB, GPU 49.3 MB
2024-12-27 20:22:14,185 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:22:14,186 - INFO - Number of unique classes: 100
2024-12-27 20:22:14,295 - INFO - Fitted scaler and transformed data
2024-12-27 20:22:14,295 - INFO - Scaling time: 0.11s
2024-12-27 20:22:14,524 - INFO - Epoch 1/25, Train Loss: 40.9378, Val Loss: 36.9027
2024-12-27 20:22:14,737 - INFO - Epoch 2/25, Train Loss: 3.3169, Val Loss: 38.1303
2024-12-27 20:22:14,970 - INFO - Epoch 3/25, Train Loss: 1.1475, Val Loss: 37.1777
2024-12-27 20:22:14,970 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:22:14,970 - INFO - Training completed in 0.79s
2024-12-27 20:22:14,970 - INFO - Final memory usage: CPU 3299.3 MB, GPU 49.9 MB
2024-12-27 20:22:14,970 - INFO - Model training completed in 0.79s
2024-12-27 20:22:14,978 - INFO - Prediction completed in 0.01s
2024-12-27 20:22:14,987 - INFO - Poison rate 0.07 completed in 0.81s
2024-12-27 20:22:14,987 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:22:15,002 - INFO - Total number of labels flipped: 500
2024-12-27 20:22:15,002 - INFO - Label flipping completed in 0.01s
2024-12-27 20:22:15,002 - INFO - Training set processing completed in 0.00s
2024-12-27 20:22:15,002 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:22:15,003 - INFO - Memory usage at start_fit: CPU 3299.3 MB, GPU 49.3 MB
2024-12-27 20:22:15,003 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:22:15,004 - INFO - Number of unique classes: 100
2024-12-27 20:22:15,099 - INFO - Fitted scaler and transformed data
2024-12-27 20:22:15,099 - INFO - Scaling time: 0.09s
2024-12-27 20:22:15,354 - INFO - Epoch 1/25, Train Loss: 47.1438, Val Loss: 51.7003
2024-12-27 20:22:15,575 - INFO - Epoch 2/25, Train Loss: 3.6727, Val Loss: 51.1173
2024-12-27 20:22:15,776 - INFO - Epoch 3/25, Train Loss: 1.2361, Val Loss: 49.0769
2024-12-27 20:22:16,014 - INFO - Epoch 4/25, Train Loss: 0.6255, Val Loss: 48.9394
2024-12-27 20:22:16,221 - INFO - Epoch 5/25, Train Loss: 0.3224, Val Loss: 48.7673
2024-12-27 20:22:16,473 - INFO - Epoch 6/25, Train Loss: 0.1761, Val Loss: 48.7590
2024-12-27 20:22:16,719 - INFO - Epoch 7/25, Train Loss: 0.1052, Val Loss: 48.9484
2024-12-27 20:22:16,719 - INFO - Early stopping triggered at epoch 7
2024-12-27 20:22:16,719 - INFO - Training completed in 1.72s
2024-12-27 20:22:16,720 - INFO - Final memory usage: CPU 3299.3 MB, GPU 49.9 MB
2024-12-27 20:22:16,720 - INFO - Model training completed in 1.72s
2024-12-27 20:22:16,728 - INFO - Prediction completed in 0.01s
2024-12-27 20:22:16,736 - INFO - Poison rate 0.1 completed in 1.75s
2024-12-27 20:22:16,737 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:22:16,765 - INFO - Total number of labels flipped: 1000
2024-12-27 20:22:16,765 - INFO - Label flipping completed in 0.03s
2024-12-27 20:22:16,765 - INFO - Training set processing completed in 0.00s
2024-12-27 20:22:16,765 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:22:16,766 - INFO - Memory usage at start_fit: CPU 3299.3 MB, GPU 49.3 MB
2024-12-27 20:22:16,766 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:22:16,766 - INFO - Number of unique classes: 100
2024-12-27 20:22:16,870 - INFO - Fitted scaler and transformed data
2024-12-27 20:22:16,871 - INFO - Scaling time: 0.10s
2024-12-27 20:22:17,085 - INFO - Epoch 1/25, Train Loss: 71.1386, Val Loss: 81.4444
2024-12-27 20:22:17,287 - INFO - Epoch 2/25, Train Loss: 5.6474, Val Loss: 84.2362
2024-12-27 20:22:17,490 - INFO - Epoch 3/25, Train Loss: 1.8088, Val Loss: 82.8123
2024-12-27 20:22:17,490 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:22:17,490 - INFO - Training completed in 0.72s
2024-12-27 20:22:17,491 - INFO - Final memory usage: CPU 3299.3 MB, GPU 49.9 MB
2024-12-27 20:22:17,491 - INFO - Model training completed in 0.73s
2024-12-27 20:22:17,499 - INFO - Prediction completed in 0.01s
2024-12-27 20:22:17,507 - INFO - Poison rate 0.2 completed in 0.77s
2024-12-27 20:22:17,509 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:22:17,510 - INFO - Total evaluation time: 17.44s
2024-12-27 20:22:17,511 - INFO - 
Progress: 60.4% - Evaluating CIFAR100 with SVM (dynadetect mode, iteration 1/1)
2024-12-27 20:22:17,571 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:22:17,644 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:22:17,740 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:22:17,741 - INFO - Dataset type: image
2024-12-27 20:22:17,741 - INFO - Sample size: 5000
2024-12-27 20:22:17,741 - INFO - Using device: cuda
2024-12-27 20:22:17,743 - INFO - Loading datasets...
2024-12-27 20:22:19,105 - INFO - Dataset loading completed in 1.36s
2024-12-27 20:22:19,105 - INFO - Extracting validation features...
2024-12-27 20:22:19,105 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:15,  2.00it/s]Extracting features:  19%|█▉        | 6/32 [00:00<00:02, 12.38it/s]Extracting features:  34%|███▍      | 11/32 [00:00<00:00, 21.19it/s]Extracting features:  53%|█████▎    | 17/32 [00:00<00:00, 30.29it/s]Extracting features:  72%|███████▏  | 23/32 [00:00<00:00, 37.93it/s]Extracting features:  94%|█████████▍| 30/32 [00:01<00:00, 44.98it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 28.60it/s]
2024-12-27 20:22:20,230 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:22:20,231 - INFO - Validation feature extraction completed in 1.13s
2024-12-27 20:22:20,231 - INFO - Extracting training features...
2024-12-27 20:22:20,231 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:47,  3.31it/s]Extracting features:   4%|▍         | 7/157 [00:00<00:07, 20.74it/s]Extracting features:   8%|▊         | 12/157 [00:00<00:05, 28.69it/s]Extracting features:  11%|█▏        | 18/157 [00:00<00:03, 36.70it/s]Extracting features:  15%|█▌        | 24/157 [00:00<00:03, 42.22it/s]Extracting features:  20%|█▉        | 31/157 [00:00<00:02, 47.75it/s]Extracting features:  24%|██▎       | 37/157 [00:00<00:02, 49.88it/s]Extracting features:  27%|██▋       | 43/157 [00:01<00:02, 52.26it/s]Extracting features:  31%|███       | 49/157 [00:01<00:02, 51.61it/s]Extracting features:  35%|███▌      | 55/157 [00:01<00:01, 53.82it/s]Extracting features:  39%|███▉      | 61/157 [00:01<00:01, 54.27it/s]Extracting features:  43%|████▎     | 67/157 [00:01<00:01, 54.48it/s]Extracting features:  46%|████▋     | 73/157 [00:01<00:01, 53.74it/s]Extracting features:  50%|█████     | 79/157 [00:01<00:01, 52.79it/s]Extracting features:  54%|█████▍    | 85/157 [00:01<00:01, 54.59it/s]Extracting features:  58%|█████▊    | 91/157 [00:01<00:01, 54.26it/s]Extracting features:  62%|██████▏   | 97/157 [00:02<00:01, 55.40it/s]Extracting features:  66%|██████▌   | 103/157 [00:02<00:01, 53.49it/s]Extracting features:  69%|██████▉   | 109/157 [00:02<00:00, 53.34it/s]Extracting features:  73%|███████▎  | 115/157 [00:02<00:00, 50.55it/s]Extracting features:  77%|███████▋  | 121/157 [00:02<00:00, 50.86it/s]Extracting features:  81%|████████  | 127/157 [00:02<00:00, 51.10it/s]Extracting features:  85%|████████▌ | 134/157 [00:02<00:00, 53.70it/s]Extracting features:  89%|████████▉ | 140/157 [00:02<00:00, 51.27it/s]Extracting features:  93%|█████████▎| 146/157 [00:03<00:00, 53.39it/s]Extracting features:  97%|█████████▋| 153/157 [00:03<00:00, 55.88it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 48.47it/s]
2024-12-27 20:22:23,480 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:22:23,480 - INFO - Training feature extraction completed in 3.25s
2024-12-27 20:22:23,480 - INFO - Creating model for classifier: SVM
2024-12-27 20:22:23,480 - INFO - Using device: cuda
2024-12-27 20:22:23,480 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-27 20:22:23,480 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:22:23,481 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:22:23,481 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:22:24,130 - INFO - Feature scaling completed in 0.65s
2024-12-27 20:22:24,130 - INFO - Starting feature selection (k=50)
2024-12-27 20:22:24,139 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:22:24,139 - INFO - Starting anomaly detection
2024-12-27 20:22:26,282 - INFO - Anomaly detection completed in 2.14s
2024-12-27 20:22:26,282 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:22:26,282 - INFO - Total fit_transform time: 2.80s
2024-12-27 20:22:26,282 - INFO - Training set processing completed in 2.80s
2024-12-27 20:22:26,283 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:22:26,284 - INFO - Memory usage at start_fit: CPU 3292.0 MB, GPU 47.3 MB
2024-12-27 20:22:26,285 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:22:26,286 - INFO - Number of unique classes: 100
2024-12-27 20:22:26,424 - INFO - Fitted scaler and transformed data
2024-12-27 20:22:26,424 - INFO - Scaling time: 0.13s
2024-12-27 20:22:26,639 - INFO - Epoch 1/25, Train Loss: 19.9679, Val Loss: 16.0087
2024-12-27 20:22:26,843 - INFO - Epoch 2/25, Train Loss: 1.7518, Val Loss: 13.4736
2024-12-27 20:22:27,034 - INFO - Epoch 3/25, Train Loss: 0.6449, Val Loss: 13.3608
2024-12-27 20:22:27,228 - INFO - Epoch 4/25, Train Loss: 0.2709, Val Loss: 13.3114
2024-12-27 20:22:27,398 - INFO - Epoch 5/25, Train Loss: 0.1356, Val Loss: 12.8680
2024-12-27 20:22:27,581 - INFO - Epoch 6/25, Train Loss: 0.0618, Val Loss: 12.8764
2024-12-27 20:22:27,758 - INFO - Epoch 7/25, Train Loss: 0.0310, Val Loss: 12.8314
2024-12-27 20:22:27,962 - INFO - Epoch 8/25, Train Loss: 0.0130, Val Loss: 12.8867
2024-12-27 20:22:28,157 - INFO - Epoch 9/25, Train Loss: 0.0061, Val Loss: 12.8142
2024-12-27 20:22:28,337 - INFO - Epoch 10/25, Train Loss: 0.0029, Val Loss: 12.8363
2024-12-27 20:22:28,536 - INFO - Epoch 11/25, Train Loss: 0.0054, Val Loss: 12.8293
2024-12-27 20:22:28,536 - INFO - Early stopping triggered at epoch 11
2024-12-27 20:22:28,536 - INFO - Training completed in 2.25s
2024-12-27 20:22:28,536 - INFO - Final memory usage: CPU 3292.0 MB, GPU 49.9 MB
2024-12-27 20:22:28,537 - INFO - Model training completed in 2.25s
2024-12-27 20:22:28,544 - INFO - Prediction completed in 0.01s
2024-12-27 20:22:28,553 - INFO - Poison rate 0.0 completed in 5.07s
2024-12-27 20:22:28,554 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:22:28,556 - INFO - Total number of labels flipped: 50
2024-12-27 20:22:28,556 - INFO - Label flipping completed in 0.00s
2024-12-27 20:22:28,556 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:22:28,556 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:22:29,144 - INFO - Feature scaling completed in 0.59s
2024-12-27 20:22:29,144 - INFO - Starting feature selection (k=50)
2024-12-27 20:22:29,150 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:22:29,151 - INFO - Starting anomaly detection
2024-12-27 20:22:31,049 - INFO - Anomaly detection completed in 1.90s
2024-12-27 20:22:31,050 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:22:31,050 - INFO - Total fit_transform time: 2.49s
2024-12-27 20:22:31,050 - INFO - Training set processing completed in 2.49s
2024-12-27 20:22:31,050 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:22:31,051 - INFO - Memory usage at start_fit: CPU 3292.0 MB, GPU 49.3 MB
2024-12-27 20:22:31,052 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:22:31,052 - INFO - Number of unique classes: 100
2024-12-27 20:22:31,161 - INFO - Fitted scaler and transformed data
2024-12-27 20:22:31,161 - INFO - Scaling time: 0.11s
2024-12-27 20:22:31,415 - INFO - Epoch 1/25, Train Loss: 23.0930, Val Loss: 16.4375
2024-12-27 20:22:31,642 - INFO - Epoch 2/25, Train Loss: 2.0055, Val Loss: 16.8290
2024-12-27 20:22:31,822 - INFO - Epoch 3/25, Train Loss: 0.7412, Val Loss: 16.2702
2024-12-27 20:22:32,006 - INFO - Epoch 4/25, Train Loss: 0.3458, Val Loss: 16.2023
2024-12-27 20:22:32,201 - INFO - Epoch 5/25, Train Loss: 0.1795, Val Loss: 15.9809
2024-12-27 20:22:32,390 - INFO - Epoch 6/25, Train Loss: 0.0834, Val Loss: 15.9972
2024-12-27 20:22:32,604 - INFO - Epoch 7/25, Train Loss: 0.0414, Val Loss: 15.9648
2024-12-27 20:22:32,813 - INFO - Epoch 8/25, Train Loss: 0.0263, Val Loss: 15.7560
2024-12-27 20:22:33,012 - INFO - Epoch 9/25, Train Loss: 0.0176, Val Loss: 15.7748
2024-12-27 20:22:33,247 - INFO - Epoch 10/25, Train Loss: 0.0095, Val Loss: 15.7703
2024-12-27 20:22:33,247 - INFO - Early stopping triggered at epoch 10
2024-12-27 20:22:33,247 - INFO - Training completed in 2.20s
2024-12-27 20:22:33,247 - INFO - Final memory usage: CPU 3292.0 MB, GPU 49.9 MB
2024-12-27 20:22:33,248 - INFO - Model training completed in 2.20s
2024-12-27 20:22:33,257 - INFO - Prediction completed in 0.01s
2024-12-27 20:22:33,266 - INFO - Poison rate 0.01 completed in 4.71s
2024-12-27 20:22:33,266 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:22:33,271 - INFO - Total number of labels flipped: 150
2024-12-27 20:22:33,272 - INFO - Label flipping completed in 0.01s
2024-12-27 20:22:33,272 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:22:33,272 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:22:33,833 - INFO - Feature scaling completed in 0.56s
2024-12-27 20:22:33,833 - INFO - Starting feature selection (k=50)
2024-12-27 20:22:33,846 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:22:33,847 - INFO - Starting anomaly detection
2024-12-27 20:22:35,678 - INFO - Anomaly detection completed in 1.83s
2024-12-27 20:22:35,679 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:22:35,679 - INFO - Total fit_transform time: 2.41s
2024-12-27 20:22:35,679 - INFO - Training set processing completed in 2.41s
2024-12-27 20:22:35,679 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:22:35,680 - INFO - Memory usage at start_fit: CPU 3292.0 MB, GPU 49.3 MB
2024-12-27 20:22:35,680 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:22:35,680 - INFO - Number of unique classes: 100
2024-12-27 20:22:35,779 - INFO - Fitted scaler and transformed data
2024-12-27 20:22:35,779 - INFO - Scaling time: 0.10s
2024-12-27 20:22:35,992 - INFO - Epoch 1/25, Train Loss: 28.6561, Val Loss: 23.3392
2024-12-27 20:22:36,166 - INFO - Epoch 2/25, Train Loss: 2.3391, Val Loss: 23.5148
2024-12-27 20:22:36,374 - INFO - Epoch 3/25, Train Loss: 0.7865, Val Loss: 22.9880
2024-12-27 20:22:36,547 - INFO - Epoch 4/25, Train Loss: 0.3644, Val Loss: 22.8456
2024-12-27 20:22:36,749 - INFO - Epoch 5/25, Train Loss: 0.1866, Val Loss: 22.8861
2024-12-27 20:22:36,970 - INFO - Epoch 6/25, Train Loss: 0.1087, Val Loss: 22.8139
2024-12-27 20:22:37,160 - INFO - Epoch 7/25, Train Loss: 0.0494, Val Loss: 22.6205
2024-12-27 20:22:37,356 - INFO - Epoch 8/25, Train Loss: 0.0216, Val Loss: 22.9588
2024-12-27 20:22:37,534 - INFO - Epoch 9/25, Train Loss: 0.0100, Val Loss: 22.8981
2024-12-27 20:22:37,534 - INFO - Early stopping triggered at epoch 9
2024-12-27 20:22:37,534 - INFO - Training completed in 1.85s
2024-12-27 20:22:37,534 - INFO - Final memory usage: CPU 3292.0 MB, GPU 49.9 MB
2024-12-27 20:22:37,535 - INFO - Model training completed in 1.86s
2024-12-27 20:22:37,543 - INFO - Prediction completed in 0.01s
2024-12-27 20:22:37,551 - INFO - Poison rate 0.03 completed in 4.29s
2024-12-27 20:22:37,552 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:22:37,559 - INFO - Total number of labels flipped: 250
2024-12-27 20:22:37,559 - INFO - Label flipping completed in 0.01s
2024-12-27 20:22:37,560 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:22:37,560 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:22:38,166 - INFO - Feature scaling completed in 0.61s
2024-12-27 20:22:38,166 - INFO - Starting feature selection (k=50)
2024-12-27 20:22:38,179 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:22:38,179 - INFO - Starting anomaly detection
2024-12-27 20:22:40,200 - INFO - Anomaly detection completed in 2.02s
2024-12-27 20:22:40,200 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:22:40,200 - INFO - Total fit_transform time: 2.64s
2024-12-27 20:22:40,200 - INFO - Training set processing completed in 2.64s
2024-12-27 20:22:40,201 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:22:40,201 - INFO - Memory usage at start_fit: CPU 3292.0 MB, GPU 49.3 MB
2024-12-27 20:22:40,202 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:22:40,202 - INFO - Number of unique classes: 100
2024-12-27 20:22:40,316 - INFO - Fitted scaler and transformed data
2024-12-27 20:22:40,316 - INFO - Scaling time: 0.11s
2024-12-27 20:22:40,483 - INFO - Epoch 1/25, Train Loss: 33.8063, Val Loss: 31.3381
2024-12-27 20:22:40,648 - INFO - Epoch 2/25, Train Loss: 3.0204, Val Loss: 34.9551
2024-12-27 20:22:40,828 - INFO - Epoch 3/25, Train Loss: 1.0733, Val Loss: 32.4039
2024-12-27 20:22:40,829 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:22:40,829 - INFO - Training completed in 0.63s
2024-12-27 20:22:40,829 - INFO - Final memory usage: CPU 3292.0 MB, GPU 49.9 MB
2024-12-27 20:22:40,829 - INFO - Model training completed in 0.63s
2024-12-27 20:22:40,836 - INFO - Prediction completed in 0.01s
2024-12-27 20:22:40,847 - INFO - Poison rate 0.05 completed in 3.30s
2024-12-27 20:22:40,847 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:22:40,864 - INFO - Total number of labels flipped: 350
2024-12-27 20:22:40,864 - INFO - Label flipping completed in 0.02s
2024-12-27 20:22:40,864 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:22:40,864 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:22:41,500 - INFO - Feature scaling completed in 0.64s
2024-12-27 20:22:41,500 - INFO - Starting feature selection (k=50)
2024-12-27 20:22:41,508 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:22:41,508 - INFO - Starting anomaly detection
2024-12-27 20:22:43,216 - INFO - Anomaly detection completed in 1.71s
2024-12-27 20:22:43,216 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:22:43,216 - INFO - Total fit_transform time: 2.35s
2024-12-27 20:22:43,216 - INFO - Training set processing completed in 2.35s
2024-12-27 20:22:43,217 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:22:43,218 - INFO - Memory usage at start_fit: CPU 3292.0 MB, GPU 49.3 MB
2024-12-27 20:22:43,218 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:22:43,219 - INFO - Number of unique classes: 100
2024-12-27 20:22:43,322 - INFO - Fitted scaler and transformed data
2024-12-27 20:22:43,322 - INFO - Scaling time: 0.10s
2024-12-27 20:22:43,510 - INFO - Epoch 1/25, Train Loss: 38.6780, Val Loss: 47.4932
2024-12-27 20:22:43,679 - INFO - Epoch 2/25, Train Loss: 3.1311, Val Loss: 46.9117
2024-12-27 20:22:43,866 - INFO - Epoch 3/25, Train Loss: 1.0918, Val Loss: 45.2542
2024-12-27 20:22:44,039 - INFO - Epoch 4/25, Train Loss: 0.5648, Val Loss: 44.6418
2024-12-27 20:22:44,222 - INFO - Epoch 5/25, Train Loss: 0.3149, Val Loss: 44.5618
2024-12-27 20:22:44,406 - INFO - Epoch 6/25, Train Loss: 0.1708, Val Loss: 44.5847
2024-12-27 20:22:44,594 - INFO - Epoch 7/25, Train Loss: 0.0932, Val Loss: 44.3349
2024-12-27 20:22:44,779 - INFO - Epoch 8/25, Train Loss: 0.0518, Val Loss: 44.3382
2024-12-27 20:22:44,995 - INFO - Epoch 9/25, Train Loss: 0.0424, Val Loss: 44.2296
2024-12-27 20:22:45,185 - INFO - Epoch 10/25, Train Loss: 0.0268, Val Loss: 44.0162
2024-12-27 20:22:45,375 - INFO - Epoch 11/25, Train Loss: 0.0100, Val Loss: 43.7223
2024-12-27 20:22:45,559 - INFO - Epoch 12/25, Train Loss: 0.0046, Val Loss: 43.6822
2024-12-27 20:22:45,745 - INFO - Epoch 13/25, Train Loss: 0.0047, Val Loss: 43.5760
2024-12-27 20:22:45,936 - INFO - Epoch 14/25, Train Loss: 0.0036, Val Loss: 43.3947
2024-12-27 20:22:46,178 - INFO - Epoch 15/25, Train Loss: 0.0019, Val Loss: 43.4764
2024-12-27 20:22:46,429 - INFO - Epoch 16/25, Train Loss: 0.0013, Val Loss: 43.4793
2024-12-27 20:22:46,429 - INFO - Early stopping triggered at epoch 16
2024-12-27 20:22:46,430 - INFO - Training completed in 3.21s
2024-12-27 20:22:46,430 - INFO - Final memory usage: CPU 3292.0 MB, GPU 49.9 MB
2024-12-27 20:22:46,430 - INFO - Model training completed in 3.21s
2024-12-27 20:22:46,440 - INFO - Prediction completed in 0.01s
2024-12-27 20:22:46,449 - INFO - Poison rate 0.07 completed in 5.60s
2024-12-27 20:22:46,450 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:22:46,464 - INFO - Total number of labels flipped: 500
2024-12-27 20:22:46,464 - INFO - Label flipping completed in 0.01s
2024-12-27 20:22:46,464 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:22:46,464 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:22:47,071 - INFO - Feature scaling completed in 0.61s
2024-12-27 20:22:47,071 - INFO - Starting feature selection (k=50)
2024-12-27 20:22:47,085 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:22:47,085 - INFO - Starting anomaly detection
2024-12-27 20:22:49,313 - INFO - Anomaly detection completed in 2.23s
2024-12-27 20:22:49,313 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:22:49,314 - INFO - Total fit_transform time: 2.85s
2024-12-27 20:22:49,314 - INFO - Training set processing completed in 2.85s
2024-12-27 20:22:49,314 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:22:49,314 - INFO - Memory usage at start_fit: CPU 3292.0 MB, GPU 49.3 MB
2024-12-27 20:22:49,315 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:22:49,315 - INFO - Number of unique classes: 100
2024-12-27 20:22:49,411 - INFO - Fitted scaler and transformed data
2024-12-27 20:22:49,411 - INFO - Scaling time: 0.09s
2024-12-27 20:22:49,600 - INFO - Epoch 1/25, Train Loss: 48.6084, Val Loss: 43.3233
2024-12-27 20:22:49,756 - INFO - Epoch 2/25, Train Loss: 4.0941, Val Loss: 45.4543
2024-12-27 20:22:49,918 - INFO - Epoch 3/25, Train Loss: 1.3779, Val Loss: 43.0307
2024-12-27 20:22:50,097 - INFO - Epoch 4/25, Train Loss: 0.6896, Val Loss: 42.4089
2024-12-27 20:22:50,296 - INFO - Epoch 5/25, Train Loss: 0.3710, Val Loss: 41.9469
2024-12-27 20:22:50,492 - INFO - Epoch 6/25, Train Loss: 0.2203, Val Loss: 41.3920
2024-12-27 20:22:50,674 - INFO - Epoch 7/25, Train Loss: 0.1249, Val Loss: 41.3887
2024-12-27 20:22:50,898 - INFO - Epoch 8/25, Train Loss: 0.0659, Val Loss: 41.2654
2024-12-27 20:22:51,105 - INFO - Epoch 9/25, Train Loss: 0.0368, Val Loss: 41.3224
2024-12-27 20:22:51,290 - INFO - Epoch 10/25, Train Loss: 0.0263, Val Loss: 41.5144
2024-12-27 20:22:51,290 - INFO - Early stopping triggered at epoch 10
2024-12-27 20:22:51,291 - INFO - Training completed in 1.98s
2024-12-27 20:22:51,291 - INFO - Final memory usage: CPU 3292.0 MB, GPU 49.9 MB
2024-12-27 20:22:51,291 - INFO - Model training completed in 1.98s
2024-12-27 20:22:51,306 - INFO - Prediction completed in 0.01s
2024-12-27 20:22:51,322 - INFO - Poison rate 0.1 completed in 4.87s
2024-12-27 20:22:51,322 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:22:51,357 - INFO - Total number of labels flipped: 1000
2024-12-27 20:22:51,357 - INFO - Label flipping completed in 0.04s
2024-12-27 20:22:51,357 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:22:51,357 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:22:51,955 - INFO - Feature scaling completed in 0.60s
2024-12-27 20:22:51,956 - INFO - Starting feature selection (k=50)
2024-12-27 20:22:51,968 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:22:51,969 - INFO - Starting anomaly detection
2024-12-27 20:22:54,183 - INFO - Anomaly detection completed in 2.21s
2024-12-27 20:22:54,183 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:22:54,183 - INFO - Total fit_transform time: 2.83s
2024-12-27 20:22:54,183 - INFO - Training set processing completed in 2.83s
2024-12-27 20:22:54,183 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:22:54,184 - INFO - Memory usage at start_fit: CPU 3292.0 MB, GPU 49.3 MB
2024-12-27 20:22:54,184 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:22:54,184 - INFO - Number of unique classes: 100
2024-12-27 20:22:54,279 - INFO - Fitted scaler and transformed data
2024-12-27 20:22:54,279 - INFO - Scaling time: 0.09s
2024-12-27 20:22:54,459 - INFO - Epoch 1/25, Train Loss: 70.8870, Val Loss: 91.8223
2024-12-27 20:22:54,631 - INFO - Epoch 2/25, Train Loss: 5.2760, Val Loss: 94.8963
2024-12-27 20:22:54,835 - INFO - Epoch 3/25, Train Loss: 1.7715, Val Loss: 93.0478
2024-12-27 20:22:54,835 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:22:54,835 - INFO - Training completed in 0.65s
2024-12-27 20:22:54,836 - INFO - Final memory usage: CPU 3292.0 MB, GPU 49.9 MB
2024-12-27 20:22:54,836 - INFO - Model training completed in 0.65s
2024-12-27 20:22:54,843 - INFO - Prediction completed in 0.01s
2024-12-27 20:22:54,851 - INFO - Poison rate 0.2 completed in 3.53s
2024-12-27 20:22:54,853 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:22:54,853 - INFO - Total evaluation time: 37.11s
2024-12-27 20:22:54,855 - INFO - 
Progress: 61.5% - Evaluating CIFAR100 with LogisticRegression (standard mode, iteration 1/1)
2024-12-27 20:22:54,916 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:22:55,002 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:22:55,092 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:22:55,092 - INFO - Dataset type: image
2024-12-27 20:22:55,092 - INFO - Sample size: 5000
2024-12-27 20:22:55,092 - INFO - Using device: cuda
2024-12-27 20:22:55,094 - INFO - Loading datasets...
2024-12-27 20:22:56,509 - INFO - Dataset loading completed in 1.41s
2024-12-27 20:22:56,509 - INFO - Extracting validation features...
2024-12-27 20:22:56,509 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:14,  2.16it/s]Extracting features:  19%|█▉        | 6/32 [00:00<00:01, 13.20it/s]Extracting features:  31%|███▏      | 10/32 [00:00<00:01, 19.74it/s]Extracting features:  50%|█████     | 16/32 [00:00<00:00, 28.72it/s]Extracting features:  66%|██████▌   | 21/32 [00:00<00:00, 33.67it/s]Extracting features:  84%|████████▍ | 27/32 [00:01<00:00, 39.74it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 27.65it/s]
2024-12-27 20:22:57,672 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:22:57,673 - INFO - Validation feature extraction completed in 1.16s
2024-12-27 20:22:57,673 - INFO - Extracting training features...
2024-12-27 20:22:57,673 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:40,  3.84it/s]Extracting features:   4%|▍         | 6/157 [00:00<00:07, 19.93it/s]Extracting features:   8%|▊         | 12/157 [00:00<00:04, 31.64it/s]Extracting features:  11%|█▏        | 18/157 [00:00<00:03, 38.55it/s]Extracting features:  15%|█▌        | 24/157 [00:00<00:03, 43.68it/s]Extracting features:  18%|█▊        | 29/157 [00:00<00:02, 44.69it/s]Extracting features:  22%|██▏       | 35/157 [00:00<00:02, 45.86it/s]Extracting features:  26%|██▌       | 41/157 [00:01<00:02, 47.22it/s]Extracting features:  31%|███       | 48/157 [00:01<00:02, 51.28it/s]Extracting features:  34%|███▍      | 54/157 [00:01<00:01, 52.74it/s]Extracting features:  38%|███▊      | 60/157 [00:01<00:01, 53.55it/s]Extracting features:  42%|████▏     | 66/157 [00:01<00:01, 54.90it/s]Extracting features:  46%|████▌     | 72/157 [00:01<00:01, 54.63it/s]Extracting features:  50%|████▉     | 78/157 [00:01<00:01, 52.26it/s]Extracting features:  54%|█████▎    | 84/157 [00:01<00:01, 53.51it/s]Extracting features:  57%|█████▋    | 90/157 [00:01<00:01, 54.87it/s]Extracting features:  61%|██████    | 96/157 [00:02<00:01, 55.34it/s]Extracting features:  65%|██████▍   | 102/157 [00:02<00:00, 55.32it/s]Extracting features:  69%|██████▉   | 108/157 [00:02<00:00, 55.97it/s]Extracting features:  73%|███████▎  | 114/157 [00:02<00:00, 56.44it/s]Extracting features:  76%|███████▋  | 120/157 [00:02<00:00, 56.18it/s]Extracting features:  80%|████████  | 126/157 [00:02<00:00, 55.09it/s]Extracting features:  85%|████████▍ | 133/157 [00:02<00:00, 56.73it/s]Extracting features:  89%|████████▊ | 139/157 [00:02<00:00, 53.83it/s]Extracting features:  92%|█████████▏| 145/157 [00:02<00:00, 53.30it/s]Extracting features:  96%|█████████▌| 151/157 [00:03<00:00, 51.76it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 48.97it/s]
2024-12-27 20:23:00,894 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:23:00,895 - INFO - Training feature extraction completed in 3.22s
2024-12-27 20:23:00,895 - INFO - Creating model for classifier: LogisticRegression
2024-12-27 20:23:00,895 - INFO - Using device: cuda
2024-12-27 20:23:00,895 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:23:00,895 - INFO - Training set processing completed in 0.00s
2024-12-27 20:23:00,895 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:23:00,897 - INFO - Memory usage at start_fit: CPU 3268.6 MB, GPU 47.3 MB
2024-12-27 20:23:00,897 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:23:00,898 - INFO - Number of unique classes: 100
2024-12-27 20:23:00,999 - INFO - Fitted scaler and transformed data
2024-12-27 20:23:00,999 - INFO - Scaling time: 0.10s
2024-12-27 20:23:01,127 - INFO - Epoch 1/200, Train Loss: 2.6274, Val Loss: 2.3786
2024-12-27 20:23:01,245 - INFO - Epoch 2/200, Train Loss: 0.5256, Val Loss: 2.3599
2024-12-27 20:23:01,370 - INFO - Epoch 3/200, Train Loss: 0.1481, Val Loss: 2.2651
2024-12-27 20:23:01,486 - INFO - Epoch 4/200, Train Loss: 0.1030, Val Loss: 2.4171
2024-12-27 20:23:01,623 - INFO - Epoch 5/200, Train Loss: 0.0320, Val Loss: 2.3581
2024-12-27 20:23:01,624 - INFO - Early stopping triggered at epoch 5
2024-12-27 20:23:01,624 - INFO - Training completed in 0.73s
2024-12-27 20:23:01,625 - INFO - Final memory usage: CPU 3293.1 MB, GPU 49.9 MB
2024-12-27 20:23:01,626 - INFO - Model training completed in 0.73s
2024-12-27 20:23:01,641 - INFO - Prediction completed in 0.01s
2024-12-27 20:23:01,661 - INFO - Poison rate 0.0 completed in 0.77s
2024-12-27 20:23:01,661 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:23:01,664 - INFO - Total number of labels flipped: 50
2024-12-27 20:23:01,664 - INFO - Label flipping completed in 0.00s
2024-12-27 20:23:01,665 - INFO - Training set processing completed in 0.00s
2024-12-27 20:23:01,665 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:23:01,666 - INFO - Memory usage at start_fit: CPU 3293.1 MB, GPU 49.3 MB
2024-12-27 20:23:01,666 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:23:01,666 - INFO - Number of unique classes: 100
2024-12-27 20:23:01,751 - INFO - Fitted scaler and transformed data
2024-12-27 20:23:01,751 - INFO - Scaling time: 0.08s
2024-12-27 20:23:01,888 - INFO - Epoch 1/200, Train Loss: 2.8092, Val Loss: 2.5415
2024-12-27 20:23:02,005 - INFO - Epoch 2/200, Train Loss: 0.4920, Val Loss: 2.7224
2024-12-27 20:23:02,124 - INFO - Epoch 3/200, Train Loss: 0.1518, Val Loss: 2.7528
2024-12-27 20:23:02,125 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:23:02,125 - INFO - Training completed in 0.46s
2024-12-27 20:23:02,126 - INFO - Final memory usage: CPU 3293.1 MB, GPU 49.9 MB
2024-12-27 20:23:02,126 - INFO - Model training completed in 0.46s
2024-12-27 20:23:02,141 - INFO - Prediction completed in 0.01s
2024-12-27 20:23:02,160 - INFO - Poison rate 0.01 completed in 0.50s
2024-12-27 20:23:02,160 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:23:02,167 - INFO - Total number of labels flipped: 150
2024-12-27 20:23:02,167 - INFO - Label flipping completed in 0.01s
2024-12-27 20:23:02,167 - INFO - Training set processing completed in 0.00s
2024-12-27 20:23:02,167 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:23:02,168 - INFO - Memory usage at start_fit: CPU 3293.1 MB, GPU 49.3 MB
2024-12-27 20:23:02,168 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:23:02,169 - INFO - Number of unique classes: 100
2024-12-27 20:23:02,263 - INFO - Fitted scaler and transformed data
2024-12-27 20:23:02,263 - INFO - Scaling time: 0.09s
2024-12-27 20:23:02,444 - INFO - Epoch 1/200, Train Loss: 2.9339, Val Loss: 3.0017
2024-12-27 20:23:02,632 - INFO - Epoch 2/200, Train Loss: 0.6338, Val Loss: 3.0245
2024-12-27 20:23:02,774 - INFO - Epoch 3/200, Train Loss: 0.1666, Val Loss: 3.1218
2024-12-27 20:23:02,774 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:23:02,775 - INFO - Training completed in 0.61s
2024-12-27 20:23:02,775 - INFO - Final memory usage: CPU 3293.1 MB, GPU 49.9 MB
2024-12-27 20:23:02,776 - INFO - Model training completed in 0.61s
2024-12-27 20:23:02,791 - INFO - Prediction completed in 0.01s
2024-12-27 20:23:02,813 - INFO - Poison rate 0.03 completed in 0.65s
2024-12-27 20:23:02,814 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:23:02,822 - INFO - Total number of labels flipped: 250
2024-12-27 20:23:02,822 - INFO - Label flipping completed in 0.01s
2024-12-27 20:23:02,822 - INFO - Training set processing completed in 0.00s
2024-12-27 20:23:02,822 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:23:02,823 - INFO - Memory usage at start_fit: CPU 3293.1 MB, GPU 49.3 MB
2024-12-27 20:23:02,823 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:23:02,823 - INFO - Number of unique classes: 100
2024-12-27 20:23:02,919 - INFO - Fitted scaler and transformed data
2024-12-27 20:23:02,919 - INFO - Scaling time: 0.09s
2024-12-27 20:23:03,068 - INFO - Epoch 1/200, Train Loss: 3.1011, Val Loss: 3.0275
2024-12-27 20:23:03,190 - INFO - Epoch 2/200, Train Loss: 0.6507, Val Loss: 3.3159
2024-12-27 20:23:03,307 - INFO - Epoch 3/200, Train Loss: 0.1844, Val Loss: 3.3719
2024-12-27 20:23:03,307 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:23:03,307 - INFO - Training completed in 0.48s
2024-12-27 20:23:03,308 - INFO - Final memory usage: CPU 3293.1 MB, GPU 49.9 MB
2024-12-27 20:23:03,308 - INFO - Model training completed in 0.49s
2024-12-27 20:23:03,322 - INFO - Prediction completed in 0.01s
2024-12-27 20:23:03,345 - INFO - Poison rate 0.05 completed in 0.53s
2024-12-27 20:23:03,345 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:23:03,361 - INFO - Total number of labels flipped: 350
2024-12-27 20:23:03,361 - INFO - Label flipping completed in 0.02s
2024-12-27 20:23:03,361 - INFO - Training set processing completed in 0.00s
2024-12-27 20:23:03,361 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:23:03,362 - INFO - Memory usage at start_fit: CPU 3293.1 MB, GPU 49.3 MB
2024-12-27 20:23:03,362 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:23:03,362 - INFO - Number of unique classes: 100
2024-12-27 20:23:03,442 - INFO - Fitted scaler and transformed data
2024-12-27 20:23:03,443 - INFO - Scaling time: 0.08s
2024-12-27 20:23:03,576 - INFO - Epoch 1/200, Train Loss: 3.3426, Val Loss: 3.2042
2024-12-27 20:23:03,746 - INFO - Epoch 2/200, Train Loss: 0.7791, Val Loss: 3.3313
2024-12-27 20:23:03,897 - INFO - Epoch 3/200, Train Loss: 0.2448, Val Loss: 3.4947
2024-12-27 20:23:03,897 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:23:03,897 - INFO - Training completed in 0.54s
2024-12-27 20:23:03,898 - INFO - Final memory usage: CPU 3293.1 MB, GPU 49.9 MB
2024-12-27 20:23:03,899 - INFO - Model training completed in 0.54s
2024-12-27 20:23:03,913 - INFO - Prediction completed in 0.01s
2024-12-27 20:23:03,930 - INFO - Poison rate 0.07 completed in 0.58s
2024-12-27 20:23:03,930 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:23:03,950 - INFO - Total number of labels flipped: 500
2024-12-27 20:23:03,950 - INFO - Label flipping completed in 0.02s
2024-12-27 20:23:03,950 - INFO - Training set processing completed in 0.00s
2024-12-27 20:23:03,950 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:23:03,951 - INFO - Memory usage at start_fit: CPU 3293.1 MB, GPU 49.3 MB
2024-12-27 20:23:03,951 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:23:03,952 - INFO - Number of unique classes: 100
2024-12-27 20:23:04,044 - INFO - Fitted scaler and transformed data
2024-12-27 20:23:04,044 - INFO - Scaling time: 0.09s
2024-12-27 20:23:04,194 - INFO - Epoch 1/200, Train Loss: 3.5597, Val Loss: 3.7828
2024-12-27 20:23:04,309 - INFO - Epoch 2/200, Train Loss: 0.8304, Val Loss: 3.9660
2024-12-27 20:23:04,426 - INFO - Epoch 3/200, Train Loss: 0.2802, Val Loss: 4.1805
2024-12-27 20:23:04,427 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:23:04,427 - INFO - Training completed in 0.48s
2024-12-27 20:23:04,428 - INFO - Final memory usage: CPU 3293.1 MB, GPU 49.9 MB
2024-12-27 20:23:04,429 - INFO - Model training completed in 0.48s
2024-12-27 20:23:04,442 - INFO - Prediction completed in 0.01s
2024-12-27 20:23:04,454 - INFO - Poison rate 0.1 completed in 0.52s
2024-12-27 20:23:04,454 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:23:04,506 - INFO - Total number of labels flipped: 1000
2024-12-27 20:23:04,506 - INFO - Label flipping completed in 0.05s
2024-12-27 20:23:04,506 - INFO - Training set processing completed in 0.00s
2024-12-27 20:23:04,506 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:23:04,507 - INFO - Memory usage at start_fit: CPU 3293.1 MB, GPU 49.3 MB
2024-12-27 20:23:04,507 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:23:04,508 - INFO - Number of unique classes: 100
2024-12-27 20:23:04,589 - INFO - Fitted scaler and transformed data
2024-12-27 20:23:04,589 - INFO - Scaling time: 0.08s
2024-12-27 20:23:04,742 - INFO - Epoch 1/200, Train Loss: 4.3800, Val Loss: 4.2792
2024-12-27 20:23:04,877 - INFO - Epoch 2/200, Train Loss: 1.0711, Val Loss: 4.6403
2024-12-27 20:23:05,062 - INFO - Epoch 3/200, Train Loss: 0.4196, Val Loss: 4.8889
2024-12-27 20:23:05,062 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:23:05,063 - INFO - Training completed in 0.56s
2024-12-27 20:23:05,063 - INFO - Final memory usage: CPU 3293.1 MB, GPU 49.9 MB
2024-12-27 20:23:05,064 - INFO - Model training completed in 0.56s
2024-12-27 20:23:05,077 - INFO - Prediction completed in 0.01s
2024-12-27 20:23:05,088 - INFO - Poison rate 0.2 completed in 0.63s
2024-12-27 20:23:05,090 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:23:05,090 - INFO - Total evaluation time: 10.00s
2024-12-27 20:23:05,091 - INFO - 
Progress: 62.5% - Evaluating CIFAR100 with LogisticRegression (dynadetect mode, iteration 1/1)
2024-12-27 20:23:05,154 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:23:05,249 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:23:05,329 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:23:05,330 - INFO - Dataset type: image
2024-12-27 20:23:05,330 - INFO - Sample size: 5000
2024-12-27 20:23:05,330 - INFO - Using device: cuda
2024-12-27 20:23:05,332 - INFO - Loading datasets...
2024-12-27 20:23:06,783 - INFO - Dataset loading completed in 1.45s
2024-12-27 20:23:06,783 - INFO - Extracting validation features...
2024-12-27 20:23:06,784 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:11,  2.75it/s]Extracting features:  16%|█▌        | 5/32 [00:00<00:02, 13.13it/s]Extracting features:  28%|██▊       | 9/32 [00:00<00:01, 19.69it/s]Extracting features:  38%|███▊      | 12/32 [00:00<00:00, 22.56it/s]Extracting features:  50%|█████     | 16/32 [00:00<00:00, 25.87it/s]Extracting features:  66%|██████▌   | 21/32 [00:00<00:00, 31.11it/s]Extracting features:  78%|███████▊  | 25/32 [00:01<00:00, 30.58it/s]Extracting features:  91%|█████████ | 29/32 [00:01<00:00, 32.75it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 24.38it/s]
2024-12-27 20:23:08,102 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:23:08,103 - INFO - Validation feature extraction completed in 1.32s
2024-12-27 20:23:08,103 - INFO - Extracting training features...
2024-12-27 20:23:08,103 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:47,  3.30it/s]Extracting features:   4%|▍         | 7/157 [00:00<00:07, 20.94it/s]Extracting features:   8%|▊         | 12/157 [00:00<00:04, 29.91it/s]Extracting features:  11%|█▏        | 18/157 [00:00<00:03, 37.60it/s]Extracting features:  15%|█▌        | 24/157 [00:00<00:03, 44.00it/s]Extracting features:  20%|█▉        | 31/157 [00:00<00:02, 49.30it/s]Extracting features:  24%|██▎       | 37/157 [00:00<00:02, 51.49it/s]Extracting features:  27%|██▋       | 43/157 [00:01<00:02, 50.55it/s]Extracting features:  31%|███       | 49/157 [00:01<00:02, 49.75it/s]Extracting features:  35%|███▌      | 55/157 [00:01<00:01, 51.65it/s]Extracting features:  39%|███▉      | 61/157 [00:01<00:01, 48.87it/s]Extracting features:  43%|████▎     | 68/157 [00:01<00:01, 52.66it/s]Extracting features:  48%|████▊     | 75/157 [00:01<00:01, 55.30it/s]Extracting features:  52%|█████▏    | 81/157 [00:01<00:01, 56.46it/s]Extracting features:  55%|█████▌    | 87/157 [00:01<00:01, 57.18it/s]Extracting features:  59%|█████▉    | 93/157 [00:01<00:01, 53.82it/s]Extracting features:  63%|██████▎   | 99/157 [00:02<00:01, 53.17it/s]Extracting features:  67%|██████▋   | 105/157 [00:02<00:00, 53.39it/s]Extracting features:  71%|███████   | 111/157 [00:02<00:00, 51.26it/s]Extracting features:  75%|███████▍  | 117/157 [00:02<00:00, 52.82it/s]Extracting features:  78%|███████▊  | 123/157 [00:02<00:00, 51.27it/s]Extracting features:  82%|████████▏ | 129/157 [00:02<00:00, 53.60it/s]Extracting features:  86%|████████▌ | 135/157 [00:02<00:00, 53.47it/s]Extracting features:  90%|████████▉ | 141/157 [00:02<00:00, 54.74it/s]Extracting features:  94%|█████████▎| 147/157 [00:03<00:00, 55.36it/s]Extracting features:  97%|█████████▋| 153/157 [00:03<00:00, 56.59it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 48.08it/s]
2024-12-27 20:23:11,387 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:23:11,388 - INFO - Training feature extraction completed in 3.28s
2024-12-27 20:23:11,388 - INFO - Creating model for classifier: LogisticRegression
2024-12-27 20:23:11,388 - INFO - Using device: cuda
2024-12-27 20:23:11,388 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:23:11,388 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:23:11,388 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:23:12,012 - INFO - Feature scaling completed in 0.62s
2024-12-27 20:23:12,012 - INFO - Starting feature selection (k=50)
2024-12-27 20:23:12,018 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:23:12,018 - INFO - Starting anomaly detection
2024-12-27 20:23:14,034 - INFO - Anomaly detection completed in 2.02s
2024-12-27 20:23:14,035 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:23:14,035 - INFO - Total fit_transform time: 2.65s
2024-12-27 20:23:14,035 - INFO - Training set processing completed in 2.65s
2024-12-27 20:23:14,035 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:23:14,036 - INFO - Memory usage at start_fit: CPU 3293.9 MB, GPU 47.3 MB
2024-12-27 20:23:14,036 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:23:14,037 - INFO - Number of unique classes: 100
2024-12-27 20:23:14,131 - INFO - Fitted scaler and transformed data
2024-12-27 20:23:14,132 - INFO - Scaling time: 0.09s
2024-12-27 20:23:14,287 - INFO - Epoch 1/200, Train Loss: 2.6386, Val Loss: 2.5723
2024-12-27 20:23:14,443 - INFO - Epoch 2/200, Train Loss: 0.4835, Val Loss: 2.6704
2024-12-27 20:23:14,613 - INFO - Epoch 3/200, Train Loss: 0.1341, Val Loss: 2.5882
2024-12-27 20:23:14,614 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:23:14,614 - INFO - Training completed in 0.58s
2024-12-27 20:23:14,614 - INFO - Final memory usage: CPU 3293.9 MB, GPU 49.9 MB
2024-12-27 20:23:14,614 - INFO - Model training completed in 0.58s
2024-12-27 20:23:14,628 - INFO - Prediction completed in 0.01s
2024-12-27 20:23:14,650 - INFO - Poison rate 0.0 completed in 3.26s
2024-12-27 20:23:14,650 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:23:14,653 - INFO - Total number of labels flipped: 50
2024-12-27 20:23:14,653 - INFO - Label flipping completed in 0.00s
2024-12-27 20:23:14,653 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:23:14,653 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:23:15,308 - INFO - Feature scaling completed in 0.65s
2024-12-27 20:23:15,308 - INFO - Starting feature selection (k=50)
2024-12-27 20:23:15,315 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:23:15,315 - INFO - Starting anomaly detection
2024-12-27 20:23:17,426 - INFO - Anomaly detection completed in 2.11s
2024-12-27 20:23:17,426 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:23:17,426 - INFO - Total fit_transform time: 2.77s
2024-12-27 20:23:17,427 - INFO - Training set processing completed in 2.77s
2024-12-27 20:23:17,427 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:23:17,428 - INFO - Memory usage at start_fit: CPU 3293.9 MB, GPU 49.3 MB
2024-12-27 20:23:17,428 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:23:17,429 - INFO - Number of unique classes: 100
2024-12-27 20:23:17,536 - INFO - Fitted scaler and transformed data
2024-12-27 20:23:17,536 - INFO - Scaling time: 0.10s
2024-12-27 20:23:17,702 - INFO - Epoch 1/200, Train Loss: 2.7983, Val Loss: 2.7470
2024-12-27 20:23:17,845 - INFO - Epoch 2/200, Train Loss: 0.5826, Val Loss: 2.8332
2024-12-27 20:23:17,987 - INFO - Epoch 3/200, Train Loss: 0.2189, Val Loss: 2.8828
2024-12-27 20:23:17,987 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:23:17,987 - INFO - Training completed in 0.56s
2024-12-27 20:23:17,988 - INFO - Final memory usage: CPU 3293.9 MB, GPU 49.9 MB
2024-12-27 20:23:17,988 - INFO - Model training completed in 0.56s
2024-12-27 20:23:17,995 - INFO - Prediction completed in 0.01s
2024-12-27 20:23:18,006 - INFO - Poison rate 0.01 completed in 3.36s
2024-12-27 20:23:18,006 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:23:18,013 - INFO - Total number of labels flipped: 150
2024-12-27 20:23:18,013 - INFO - Label flipping completed in 0.01s
2024-12-27 20:23:18,013 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:23:18,013 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:23:18,550 - INFO - Feature scaling completed in 0.54s
2024-12-27 20:23:18,550 - INFO - Starting feature selection (k=50)
2024-12-27 20:23:18,559 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:23:18,560 - INFO - Starting anomaly detection
2024-12-27 20:23:19,764 - INFO - Anomaly detection completed in 1.20s
2024-12-27 20:23:19,765 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:23:19,765 - INFO - Total fit_transform time: 1.75s
2024-12-27 20:23:19,765 - INFO - Training set processing completed in 1.75s
2024-12-27 20:23:19,765 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:23:19,766 - INFO - Memory usage at start_fit: CPU 3293.9 MB, GPU 49.3 MB
2024-12-27 20:23:19,767 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:23:19,767 - INFO - Number of unique classes: 100
2024-12-27 20:23:19,870 - INFO - Fitted scaler and transformed data
2024-12-27 20:23:19,870 - INFO - Scaling time: 0.10s
2024-12-27 20:23:20,022 - INFO - Epoch 1/200, Train Loss: 3.0431, Val Loss: 3.0700
2024-12-27 20:23:20,137 - INFO - Epoch 2/200, Train Loss: 0.6292, Val Loss: 3.1785
2024-12-27 20:23:20,254 - INFO - Epoch 3/200, Train Loss: 0.2223, Val Loss: 3.1057
2024-12-27 20:23:20,254 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:23:20,254 - INFO - Training completed in 0.49s
2024-12-27 20:23:20,254 - INFO - Final memory usage: CPU 3293.9 MB, GPU 49.9 MB
2024-12-27 20:23:20,255 - INFO - Model training completed in 0.49s
2024-12-27 20:23:20,261 - INFO - Prediction completed in 0.01s
2024-12-27 20:23:20,285 - INFO - Poison rate 0.03 completed in 2.28s
2024-12-27 20:23:20,285 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:23:20,304 - INFO - Total number of labels flipped: 250
2024-12-27 20:23:20,304 - INFO - Label flipping completed in 0.02s
2024-12-27 20:23:20,305 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:23:20,305 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:23:20,946 - INFO - Feature scaling completed in 0.64s
2024-12-27 20:23:20,946 - INFO - Starting feature selection (k=50)
2024-12-27 20:23:20,956 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:23:20,956 - INFO - Starting anomaly detection
2024-12-27 20:23:22,733 - INFO - Anomaly detection completed in 1.78s
2024-12-27 20:23:22,733 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:23:22,733 - INFO - Total fit_transform time: 2.43s
2024-12-27 20:23:22,733 - INFO - Training set processing completed in 2.43s
2024-12-27 20:23:22,733 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:23:22,734 - INFO - Memory usage at start_fit: CPU 3293.9 MB, GPU 49.3 MB
2024-12-27 20:23:22,735 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:23:22,735 - INFO - Number of unique classes: 100
2024-12-27 20:23:22,830 - INFO - Fitted scaler and transformed data
2024-12-27 20:23:22,831 - INFO - Scaling time: 0.09s
2024-12-27 20:23:23,011 - INFO - Epoch 1/200, Train Loss: 3.1762, Val Loss: 3.3052
2024-12-27 20:23:23,118 - INFO - Epoch 2/200, Train Loss: 0.6696, Val Loss: 3.6050
2024-12-27 20:23:23,261 - INFO - Epoch 3/200, Train Loss: 0.1809, Val Loss: 3.6843
2024-12-27 20:23:23,261 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:23:23,261 - INFO - Training completed in 0.53s
2024-12-27 20:23:23,262 - INFO - Final memory usage: CPU 3293.9 MB, GPU 49.9 MB
2024-12-27 20:23:23,262 - INFO - Model training completed in 0.53s
2024-12-27 20:23:23,277 - INFO - Prediction completed in 0.01s
2024-12-27 20:23:23,298 - INFO - Poison rate 0.05 completed in 3.01s
2024-12-27 20:23:23,298 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:23:23,311 - INFO - Total number of labels flipped: 350
2024-12-27 20:23:23,311 - INFO - Label flipping completed in 0.01s
2024-12-27 20:23:23,311 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:23:23,311 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:23:23,910 - INFO - Feature scaling completed in 0.60s
2024-12-27 20:23:23,910 - INFO - Starting feature selection (k=50)
2024-12-27 20:23:23,917 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:23:23,918 - INFO - Starting anomaly detection
2024-12-27 20:23:25,937 - INFO - Anomaly detection completed in 2.02s
2024-12-27 20:23:25,938 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:23:25,938 - INFO - Total fit_transform time: 2.63s
2024-12-27 20:23:25,938 - INFO - Training set processing completed in 2.63s
2024-12-27 20:23:25,938 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:23:25,939 - INFO - Memory usage at start_fit: CPU 3293.9 MB, GPU 49.3 MB
2024-12-27 20:23:25,940 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:23:25,941 - INFO - Number of unique classes: 100
2024-12-27 20:23:26,056 - INFO - Fitted scaler and transformed data
2024-12-27 20:23:26,057 - INFO - Scaling time: 0.11s
2024-12-27 20:23:26,220 - INFO - Epoch 1/200, Train Loss: 3.3242, Val Loss: 3.1014
2024-12-27 20:23:26,343 - INFO - Epoch 2/200, Train Loss: 0.7824, Val Loss: 3.3876
2024-12-27 20:23:26,470 - INFO - Epoch 3/200, Train Loss: 0.2837, Val Loss: 3.5676
2024-12-27 20:23:26,471 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:23:26,471 - INFO - Training completed in 0.53s
2024-12-27 20:23:26,472 - INFO - Final memory usage: CPU 3293.9 MB, GPU 49.9 MB
2024-12-27 20:23:26,472 - INFO - Model training completed in 0.53s
2024-12-27 20:23:26,487 - INFO - Prediction completed in 0.01s
2024-12-27 20:23:26,511 - INFO - Poison rate 0.07 completed in 3.21s
2024-12-27 20:23:26,511 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:23:26,531 - INFO - Total number of labels flipped: 500
2024-12-27 20:23:26,532 - INFO - Label flipping completed in 0.02s
2024-12-27 20:23:26,532 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:23:26,532 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:23:27,174 - INFO - Feature scaling completed in 0.64s
2024-12-27 20:23:27,175 - INFO - Starting feature selection (k=50)
2024-12-27 20:23:27,188 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:23:27,188 - INFO - Starting anomaly detection
2024-12-27 20:23:29,227 - INFO - Anomaly detection completed in 2.04s
2024-12-27 20:23:29,228 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:23:29,228 - INFO - Total fit_transform time: 2.70s
2024-12-27 20:23:29,228 - INFO - Training set processing completed in 2.70s
2024-12-27 20:23:29,228 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:23:29,229 - INFO - Memory usage at start_fit: CPU 3293.9 MB, GPU 49.3 MB
2024-12-27 20:23:29,229 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:23:29,229 - INFO - Number of unique classes: 100
2024-12-27 20:23:29,326 - INFO - Fitted scaler and transformed data
2024-12-27 20:23:29,326 - INFO - Scaling time: 0.10s
2024-12-27 20:23:29,482 - INFO - Epoch 1/200, Train Loss: 3.7252, Val Loss: 3.6008
2024-12-27 20:23:29,644 - INFO - Epoch 2/200, Train Loss: 0.8276, Val Loss: 3.7756
2024-12-27 20:23:29,838 - INFO - Epoch 3/200, Train Loss: 0.2460, Val Loss: 3.9826
2024-12-27 20:23:29,838 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:23:29,839 - INFO - Training completed in 0.61s
2024-12-27 20:23:29,839 - INFO - Final memory usage: CPU 3293.9 MB, GPU 49.9 MB
2024-12-27 20:23:29,839 - INFO - Model training completed in 0.61s
2024-12-27 20:23:29,855 - INFO - Prediction completed in 0.02s
2024-12-27 20:23:29,876 - INFO - Poison rate 0.1 completed in 3.36s
2024-12-27 20:23:29,876 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:23:29,906 - INFO - Total number of labels flipped: 1000
2024-12-27 20:23:29,906 - INFO - Label flipping completed in 0.03s
2024-12-27 20:23:29,906 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:23:29,906 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:23:30,570 - INFO - Feature scaling completed in 0.66s
2024-12-27 20:23:30,570 - INFO - Starting feature selection (k=50)
2024-12-27 20:23:30,584 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:23:30,584 - INFO - Starting anomaly detection
2024-12-27 20:23:32,830 - INFO - Anomaly detection completed in 2.25s
2024-12-27 20:23:32,831 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:23:32,831 - INFO - Total fit_transform time: 2.92s
2024-12-27 20:23:32,831 - INFO - Training set processing completed in 2.92s
2024-12-27 20:23:32,831 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:23:32,832 - INFO - Memory usage at start_fit: CPU 3293.9 MB, GPU 49.3 MB
2024-12-27 20:23:32,832 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:23:32,833 - INFO - Number of unique classes: 100
2024-12-27 20:23:32,929 - INFO - Fitted scaler and transformed data
2024-12-27 20:23:32,929 - INFO - Scaling time: 0.09s
2024-12-27 20:23:33,122 - INFO - Epoch 1/200, Train Loss: 4.3549, Val Loss: 4.6209
2024-12-27 20:23:33,319 - INFO - Epoch 2/200, Train Loss: 1.1199, Val Loss: 4.9515
2024-12-27 20:23:33,550 - INFO - Epoch 3/200, Train Loss: 0.4292, Val Loss: 5.1503
2024-12-27 20:23:33,550 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:23:33,550 - INFO - Training completed in 0.72s
2024-12-27 20:23:33,551 - INFO - Final memory usage: CPU 3293.9 MB, GPU 49.9 MB
2024-12-27 20:23:33,551 - INFO - Model training completed in 0.72s
2024-12-27 20:23:33,560 - INFO - Prediction completed in 0.01s
2024-12-27 20:23:33,570 - INFO - Poison rate 0.2 completed in 3.69s
2024-12-27 20:23:33,573 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:23:33,573 - INFO - Total evaluation time: 28.24s
2024-12-27 20:23:33,575 - INFO - 
Progress: 63.5% - Evaluating CIFAR100 with RandomForest (standard mode, iteration 1/1)
2024-12-27 20:23:33,647 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:23:33,721 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:23:33,820 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:23:33,820 - INFO - Dataset type: image
2024-12-27 20:23:33,820 - INFO - Sample size: 5000
2024-12-27 20:23:33,821 - INFO - Using device: cuda
2024-12-27 20:23:33,823 - INFO - Loading datasets...
2024-12-27 20:23:35,200 - INFO - Dataset loading completed in 1.38s
2024-12-27 20:23:35,200 - INFO - Extracting validation features...
2024-12-27 20:23:35,200 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:16,  1.88it/s]Extracting features:   9%|▉         | 3/32 [00:00<00:05,  5.59it/s]Extracting features:  25%|██▌       | 8/32 [00:00<00:01, 15.55it/s]Extracting features:  44%|████▍     | 14/32 [00:00<00:00, 25.75it/s]Extracting features:  62%|██████▎   | 20/32 [00:00<00:00, 34.13it/s]Extracting features:  78%|███████▊  | 25/32 [00:01<00:00, 36.91it/s]Extracting features:  97%|█████████▋| 31/32 [00:01<00:00, 41.93it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 25.14it/s]
2024-12-27 20:23:36,479 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:23:36,480 - INFO - Validation feature extraction completed in 1.28s
2024-12-27 20:23:36,480 - INFO - Extracting training features...
2024-12-27 20:23:36,480 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:38,  4.02it/s]Extracting features:   4%|▍         | 6/157 [00:00<00:07, 19.94it/s]Extracting features:   8%|▊         | 12/157 [00:00<00:04, 32.74it/s]Extracting features:  11%|█▏        | 18/157 [00:00<00:03, 40.67it/s]Extracting features:  16%|█▌        | 25/157 [00:00<00:02, 48.14it/s]Extracting features:  20%|█▉        | 31/157 [00:00<00:02, 48.30it/s]Extracting features:  24%|██▎       | 37/157 [00:00<00:02, 50.40it/s]Extracting features:  27%|██▋       | 43/157 [00:01<00:02, 52.24it/s]Extracting features:  31%|███       | 49/157 [00:01<00:02, 53.34it/s]Extracting features:  35%|███▌      | 55/157 [00:01<00:01, 54.09it/s]Extracting features:  39%|███▉      | 61/157 [00:01<00:01, 55.72it/s]Extracting features:  43%|████▎     | 67/157 [00:01<00:01, 53.67it/s]Extracting features:  46%|████▋     | 73/157 [00:01<00:01, 54.22it/s]Extracting features:  50%|█████     | 79/157 [00:01<00:01, 53.28it/s]Extracting features:  54%|█████▍    | 85/157 [00:01<00:01, 53.43it/s]Extracting features:  58%|█████▊    | 91/157 [00:01<00:01, 52.30it/s]Extracting features:  62%|██████▏   | 97/157 [00:02<00:01, 51.69it/s]Extracting features:  66%|██████▌   | 103/157 [00:02<00:01, 51.32it/s]Extracting features:  69%|██████▉   | 109/157 [00:02<00:00, 48.89it/s]Extracting features:  73%|███████▎  | 115/157 [00:02<00:00, 51.10it/s]Extracting features:  77%|███████▋  | 121/157 [00:02<00:00, 49.82it/s]Extracting features:  81%|████████  | 127/157 [00:02<00:00, 49.50it/s]Extracting features:  84%|████████▍ | 132/157 [00:02<00:00, 48.82it/s]Extracting features:  88%|████████▊ | 138/157 [00:02<00:00, 50.26it/s]Extracting features:  92%|█████████▏| 144/157 [00:02<00:00, 51.52it/s]Extracting features:  96%|█████████▌| 150/157 [00:03<00:00, 50.73it/s]Extracting features:  99%|█████████▉| 156/157 [00:03<00:00, 50.03it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 47.37it/s]
2024-12-27 20:23:39,812 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:23:39,813 - INFO - Training feature extraction completed in 3.33s
2024-12-27 20:23:39,813 - INFO - Creating model for classifier: RandomForest
2024-12-27 20:23:39,813 - INFO - Using device: cuda
2024-12-27 20:23:39,813 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:23:39,813 - INFO - Training set processing completed in 0.00s
2024-12-27 20:23:39,813 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:23:39,815 - INFO - Memory usage at start_fit: CPU 3262.8 MB, GPU 47.3 MB
2024-12-27 20:23:39,815 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:23:39,898 - INFO - Fitted scaler and transformed data
2024-12-27 20:23:39,899 - INFO - Scaling time: 0.08s
2024-12-27 20:23:39,905 - INFO - Number of unique classes: 100
2024-12-27 20:23:43,413 - INFO - Epoch 1/15, Train Loss: 4.6050, Val Loss: 4.6048
2024-12-27 20:23:46,483 - INFO - Epoch 2/15, Train Loss: 4.6040, Val Loss: 4.6044
2024-12-27 20:23:50,536 - INFO - Epoch 3/15, Train Loss: 4.6029, Val Loss: 4.6039
2024-12-27 20:23:50,536 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:23:50,536 - INFO - Training completed in 10.72s
2024-12-27 20:23:50,537 - INFO - Final memory usage: CPU 3287.3 MB, GPU 97.4 MB
2024-12-27 20:23:50,537 - INFO - Model training completed in 10.72s
2024-12-27 20:23:50,719 - INFO - Prediction completed in 0.18s
2024-12-27 20:23:50,728 - INFO - Poison rate 0.0 completed in 10.91s
2024-12-27 20:23:50,728 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:23:50,730 - INFO - Total number of labels flipped: 50
2024-12-27 20:23:50,730 - INFO - Label flipping completed in 0.00s
2024-12-27 20:23:50,730 - INFO - Training set processing completed in 0.00s
2024-12-27 20:23:50,731 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:23:50,731 - INFO - Memory usage at start_fit: CPU 3287.3 MB, GPU 66.9 MB
2024-12-27 20:23:50,732 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:23:50,798 - INFO - Fitted scaler and transformed data
2024-12-27 20:23:50,798 - INFO - Scaling time: 0.07s
2024-12-27 20:23:50,809 - INFO - Number of unique classes: 100
2024-12-27 20:23:54,261 - INFO - Epoch 1/15, Train Loss: 4.6050, Val Loss: 4.6049
2024-12-27 20:23:57,829 - INFO - Epoch 2/15, Train Loss: 4.6040, Val Loss: 4.6045
2024-12-27 20:24:01,194 - INFO - Epoch 3/15, Train Loss: 4.6029, Val Loss: 4.6041
2024-12-27 20:24:01,195 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:24:01,195 - INFO - Training completed in 10.46s
2024-12-27 20:24:01,195 - INFO - Final memory usage: CPU 3287.3 MB, GPU 97.4 MB
2024-12-27 20:24:01,195 - INFO - Model training completed in 10.46s
2024-12-27 20:24:01,326 - INFO - Prediction completed in 0.13s
2024-12-27 20:24:01,334 - INFO - Poison rate 0.01 completed in 10.61s
2024-12-27 20:24:01,335 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:24:01,339 - INFO - Total number of labels flipped: 150
2024-12-27 20:24:01,340 - INFO - Label flipping completed in 0.00s
2024-12-27 20:24:01,340 - INFO - Training set processing completed in 0.00s
2024-12-27 20:24:01,340 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:24:01,341 - INFO - Memory usage at start_fit: CPU 3287.3 MB, GPU 66.9 MB
2024-12-27 20:24:01,341 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:24:01,413 - INFO - Fitted scaler and transformed data
2024-12-27 20:24:01,413 - INFO - Scaling time: 0.07s
2024-12-27 20:24:01,425 - INFO - Number of unique classes: 100
2024-12-27 20:24:04,816 - INFO - Epoch 1/15, Train Loss: 4.6050, Val Loss: 4.6049
2024-12-27 20:24:07,789 - INFO - Epoch 2/15, Train Loss: 4.6040, Val Loss: 4.6045
2024-12-27 20:24:11,030 - INFO - Epoch 3/15, Train Loss: 4.6029, Val Loss: 4.6041
2024-12-27 20:24:11,030 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:24:11,030 - INFO - Training completed in 9.69s
2024-12-27 20:24:11,031 - INFO - Final memory usage: CPU 3287.3 MB, GPU 97.4 MB
2024-12-27 20:24:11,031 - INFO - Model training completed in 9.69s
2024-12-27 20:24:11,127 - INFO - Prediction completed in 0.10s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:24:11,136 - INFO - Poison rate 0.03 completed in 9.80s
2024-12-27 20:24:11,137 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:24:11,144 - INFO - Total number of labels flipped: 250
2024-12-27 20:24:11,144 - INFO - Label flipping completed in 0.01s
2024-12-27 20:24:11,144 - INFO - Training set processing completed in 0.00s
2024-12-27 20:24:11,144 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:24:11,145 - INFO - Memory usage at start_fit: CPU 3287.3 MB, GPU 66.9 MB
2024-12-27 20:24:11,145 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:24:11,211 - INFO - Fitted scaler and transformed data
2024-12-27 20:24:11,211 - INFO - Scaling time: 0.07s
2024-12-27 20:24:11,221 - INFO - Number of unique classes: 100
2024-12-27 20:24:14,589 - INFO - Epoch 1/15, Train Loss: 4.6051, Val Loss: 4.6049
2024-12-27 20:24:17,871 - INFO - Epoch 2/15, Train Loss: 4.6040, Val Loss: 4.6045
2024-12-27 20:24:21,385 - INFO - Epoch 3/15, Train Loss: 4.6029, Val Loss: 4.6041
2024-12-27 20:24:21,385 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:24:21,385 - INFO - Training completed in 10.24s
2024-12-27 20:24:21,386 - INFO - Final memory usage: CPU 3287.3 MB, GPU 97.4 MB
2024-12-27 20:24:21,386 - INFO - Model training completed in 10.24s
2024-12-27 20:24:21,526 - INFO - Prediction completed in 0.14s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:24:21,535 - INFO - Poison rate 0.05 completed in 10.40s
2024-12-27 20:24:21,535 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:24:21,545 - INFO - Total number of labels flipped: 350
2024-12-27 20:24:21,546 - INFO - Label flipping completed in 0.01s
2024-12-27 20:24:21,546 - INFO - Training set processing completed in 0.00s
2024-12-27 20:24:21,546 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:24:21,547 - INFO - Memory usage at start_fit: CPU 3287.3 MB, GPU 66.9 MB
2024-12-27 20:24:21,547 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:24:21,613 - INFO - Fitted scaler and transformed data
2024-12-27 20:24:21,613 - INFO - Scaling time: 0.07s
2024-12-27 20:24:21,624 - INFO - Number of unique classes: 100
2024-12-27 20:24:24,198 - INFO - Epoch 1/15, Train Loss: 4.6051, Val Loss: 4.6049
2024-12-27 20:24:27,009 - INFO - Epoch 2/15, Train Loss: 4.6040, Val Loss: 4.6046
2024-12-27 20:24:30,195 - INFO - Epoch 3/15, Train Loss: 4.6030, Val Loss: 4.6042
2024-12-27 20:24:30,195 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:24:30,195 - INFO - Training completed in 8.65s
2024-12-27 20:24:30,196 - INFO - Final memory usage: CPU 3287.3 MB, GPU 97.4 MB
2024-12-27 20:24:30,196 - INFO - Model training completed in 8.65s
2024-12-27 20:24:30,291 - INFO - Prediction completed in 0.09s
2024-12-27 20:24:30,299 - INFO - Poison rate 0.07 completed in 8.76s
2024-12-27 20:24:30,300 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:24:30,313 - INFO - Total number of labels flipped: 500
2024-12-27 20:24:30,313 - INFO - Label flipping completed in 0.01s
2024-12-27 20:24:30,314 - INFO - Training set processing completed in 0.00s
2024-12-27 20:24:30,314 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:24:30,314 - INFO - Memory usage at start_fit: CPU 3287.3 MB, GPU 66.9 MB
2024-12-27 20:24:30,315 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:24:30,387 - INFO - Fitted scaler and transformed data
2024-12-27 20:24:30,387 - INFO - Scaling time: 0.07s
2024-12-27 20:24:30,397 - INFO - Number of unique classes: 100
2024-12-27 20:24:33,874 - INFO - Epoch 1/15, Train Loss: 4.6051, Val Loss: 4.6049
2024-12-27 20:24:37,608 - INFO - Epoch 2/15, Train Loss: 4.6040, Val Loss: 4.6045
2024-12-27 20:24:41,625 - INFO - Epoch 3/15, Train Loss: 4.6030, Val Loss: 4.6041
2024-12-27 20:24:41,626 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:24:41,626 - INFO - Training completed in 11.31s
2024-12-27 20:24:41,626 - INFO - Final memory usage: CPU 3287.3 MB, GPU 97.4 MB
2024-12-27 20:24:41,626 - INFO - Model training completed in 11.31s
2024-12-27 20:24:41,739 - INFO - Prediction completed in 0.11s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:24:41,748 - INFO - Poison rate 0.1 completed in 11.45s
2024-12-27 20:24:41,748 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:24:41,776 - INFO - Total number of labels flipped: 1000
2024-12-27 20:24:41,776 - INFO - Label flipping completed in 0.03s
2024-12-27 20:24:41,776 - INFO - Training set processing completed in 0.00s
2024-12-27 20:24:41,776 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:24:41,777 - INFO - Memory usage at start_fit: CPU 3287.3 MB, GPU 66.9 MB
2024-12-27 20:24:41,777 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:24:41,841 - INFO - Fitted scaler and transformed data
2024-12-27 20:24:41,841 - INFO - Scaling time: 0.06s
2024-12-27 20:24:41,851 - INFO - Number of unique classes: 100
2024-12-27 20:24:45,331 - INFO - Epoch 1/15, Train Loss: 4.6051, Val Loss: 4.6050
2024-12-27 20:24:48,352 - INFO - Epoch 2/15, Train Loss: 4.6041, Val Loss: 4.6047
2024-12-27 20:24:51,627 - INFO - Epoch 3/15, Train Loss: 4.6031, Val Loss: 4.6044
2024-12-27 20:24:51,627 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:24:51,627 - INFO - Training completed in 9.85s
2024-12-27 20:24:51,628 - INFO - Final memory usage: CPU 3287.3 MB, GPU 97.4 MB
2024-12-27 20:24:51,628 - INFO - Model training completed in 9.85s
2024-12-27 20:24:51,744 - INFO - Prediction completed in 0.12s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:24:51,753 - INFO - Poison rate 0.2 completed in 10.01s
2024-12-27 20:24:51,755 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:24:51,755 - INFO - Total evaluation time: 77.93s
2024-12-27 20:24:51,756 - INFO - 
Progress: 64.6% - Evaluating CIFAR100 with RandomForest (dynadetect mode, iteration 1/1)
2024-12-27 20:24:51,816 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:24:51,886 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:24:51,965 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:24:51,965 - INFO - Dataset type: image
2024-12-27 20:24:51,965 - INFO - Sample size: 5000
2024-12-27 20:24:51,965 - INFO - Using device: cuda
2024-12-27 20:24:51,968 - INFO - Loading datasets...
2024-12-27 20:24:53,366 - INFO - Dataset loading completed in 1.40s
2024-12-27 20:24:53,366 - INFO - Extracting validation features...
2024-12-27 20:24:53,366 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:16,  1.87it/s]Extracting features:  12%|█▎        | 4/32 [00:00<00:03,  7.68it/s]Extracting features:  28%|██▊       | 9/32 [00:00<00:01, 17.03it/s]Extracting features:  47%|████▋     | 15/32 [00:00<00:00, 26.72it/s]Extracting features:  66%|██████▌   | 21/32 [00:00<00:00, 34.09it/s]Extracting features:  88%|████████▊ | 28/32 [00:01<00:00, 42.10it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 26.85it/s]
2024-12-27 20:24:54,564 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:24:54,565 - INFO - Validation feature extraction completed in 1.20s
2024-12-27 20:24:54,565 - INFO - Extracting training features...
2024-12-27 20:24:54,565 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:43,  3.56it/s]Extracting features:   4%|▍         | 6/157 [00:00<00:08, 18.78it/s]Extracting features:   8%|▊         | 12/157 [00:00<00:04, 30.45it/s]Extracting features:  11%|█▏        | 18/157 [00:00<00:03, 37.39it/s]Extracting features:  15%|█▌        | 24/157 [00:00<00:03, 43.85it/s]Extracting features:  19%|█▉        | 30/157 [00:00<00:02, 47.38it/s]Extracting features:  23%|██▎       | 36/157 [00:00<00:02, 48.94it/s]Extracting features:  27%|██▋       | 42/157 [00:01<00:02, 48.52it/s]Extracting features:  31%|███       | 48/157 [00:01<00:02, 50.01it/s]Extracting features:  34%|███▍      | 54/157 [00:01<00:01, 52.07it/s]Extracting features:  38%|███▊      | 60/157 [00:01<00:01, 51.83it/s]Extracting features:  42%|████▏     | 66/157 [00:01<00:01, 51.88it/s]Extracting features:  46%|████▌     | 72/157 [00:01<00:01, 51.91it/s]Extracting features:  50%|████▉     | 78/157 [00:01<00:01, 53.67it/s]Extracting features:  54%|█████▎    | 84/157 [00:01<00:01, 53.24it/s]Extracting features:  57%|█████▋    | 90/157 [00:01<00:01, 54.38it/s]Extracting features:  61%|██████    | 96/157 [00:02<00:01, 55.43it/s]Extracting features:  65%|██████▍   | 102/157 [00:02<00:00, 55.62it/s]Extracting features:  69%|██████▉   | 108/157 [00:02<00:00, 54.62it/s]Extracting features:  73%|███████▎  | 114/157 [00:02<00:00, 53.76it/s]Extracting features:  76%|███████▋  | 120/157 [00:02<00:00, 55.48it/s]Extracting features:  80%|████████  | 126/157 [00:02<00:00, 55.71it/s]Extracting features:  84%|████████▍ | 132/157 [00:02<00:00, 56.07it/s]Extracting features:  88%|████████▊ | 138/157 [00:02<00:00, 57.00it/s]Extracting features:  92%|█████████▏| 144/157 [00:02<00:00, 54.47it/s]Extracting features:  96%|█████████▌| 150/157 [00:03<00:00, 52.44it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 56.45it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 48.70it/s]
2024-12-27 20:24:57,800 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:24:57,800 - INFO - Training feature extraction completed in 3.23s
2024-12-27 20:24:57,800 - INFO - Creating model for classifier: RandomForest
2024-12-27 20:24:57,800 - INFO - Using device: cuda
2024-12-27 20:24:57,801 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:24:57,801 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:24:57,801 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:24:58,388 - INFO - Feature scaling completed in 0.59s
2024-12-27 20:24:58,388 - INFO - Starting feature selection (k=50)
2024-12-27 20:24:58,397 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:24:58,397 - INFO - Starting anomaly detection
2024-12-27 20:24:59,820 - INFO - Anomaly detection completed in 1.42s
2024-12-27 20:24:59,820 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:24:59,820 - INFO - Total fit_transform time: 2.02s
2024-12-27 20:24:59,821 - INFO - Training set processing completed in 2.02s
2024-12-27 20:24:59,821 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:24:59,822 - INFO - Memory usage at start_fit: CPU 3288.6 MB, GPU 47.3 MB
2024-12-27 20:24:59,822 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:24:59,920 - INFO - Fitted scaler and transformed data
2024-12-27 20:24:59,920 - INFO - Scaling time: 0.10s
2024-12-27 20:24:59,929 - INFO - Number of unique classes: 100
2024-12-27 20:25:03,457 - INFO - Epoch 1/15, Train Loss: 4.3717, Val Loss: 4.6048
2024-12-27 20:25:07,010 - INFO - Epoch 2/15, Train Loss: 4.3707, Val Loss: 4.6044
2024-12-27 20:25:10,715 - INFO - Epoch 3/15, Train Loss: 4.3697, Val Loss: 4.6040
2024-12-27 20:25:10,715 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:25:10,715 - INFO - Training completed in 10.89s
2024-12-27 20:25:10,715 - INFO - Final memory usage: CPU 3288.6 MB, GPU 97.4 MB
2024-12-27 20:25:10,716 - INFO - Model training completed in 10.89s
2024-12-27 20:25:10,811 - INFO - Prediction completed in 0.10s
2024-12-27 20:25:10,820 - INFO - Poison rate 0.0 completed in 13.02s
2024-12-27 20:25:10,820 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:25:10,822 - INFO - Total number of labels flipped: 50
2024-12-27 20:25:10,822 - INFO - Label flipping completed in 0.00s
2024-12-27 20:25:10,822 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:25:10,822 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:25:11,458 - INFO - Feature scaling completed in 0.64s
2024-12-27 20:25:11,458 - INFO - Starting feature selection (k=50)
2024-12-27 20:25:11,471 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:25:11,471 - INFO - Starting anomaly detection
2024-12-27 20:25:13,814 - INFO - Anomaly detection completed in 2.34s
2024-12-27 20:25:13,815 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:25:13,815 - INFO - Total fit_transform time: 2.99s
2024-12-27 20:25:13,815 - INFO - Training set processing completed in 2.99s
2024-12-27 20:25:13,815 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:25:13,816 - INFO - Memory usage at start_fit: CPU 3288.6 MB, GPU 66.9 MB
2024-12-27 20:25:13,816 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:25:13,883 - INFO - Fitted scaler and transformed data
2024-12-27 20:25:13,883 - INFO - Scaling time: 0.07s
2024-12-27 20:25:13,890 - INFO - Number of unique classes: 100
2024-12-27 20:25:17,628 - INFO - Epoch 1/15, Train Loss: 4.3769, Val Loss: 4.6049
2024-12-27 20:25:21,285 - INFO - Epoch 2/15, Train Loss: 4.3759, Val Loss: 4.6045
2024-12-27 20:25:25,430 - INFO - Epoch 3/15, Train Loss: 4.3748, Val Loss: 4.6040
2024-12-27 20:25:25,430 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:25:25,430 - INFO - Training completed in 11.61s
2024-12-27 20:25:25,430 - INFO - Final memory usage: CPU 3288.6 MB, GPU 97.4 MB
2024-12-27 20:25:25,431 - INFO - Model training completed in 11.62s
2024-12-27 20:25:25,674 - INFO - Prediction completed in 0.24s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:25:25,683 - INFO - Poison rate 0.01 completed in 14.86s
2024-12-27 20:25:25,683 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:25:25,688 - INFO - Total number of labels flipped: 150
2024-12-27 20:25:25,688 - INFO - Label flipping completed in 0.01s
2024-12-27 20:25:25,689 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:25:25,689 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:25:26,272 - INFO - Feature scaling completed in 0.58s
2024-12-27 20:25:26,272 - INFO - Starting feature selection (k=50)
2024-12-27 20:25:26,285 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:25:26,285 - INFO - Starting anomaly detection
2024-12-27 20:25:27,775 - INFO - Anomaly detection completed in 1.49s
2024-12-27 20:25:27,775 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:25:27,775 - INFO - Total fit_transform time: 2.09s
2024-12-27 20:25:27,775 - INFO - Training set processing completed in 2.09s
2024-12-27 20:25:27,775 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:25:27,777 - INFO - Memory usage at start_fit: CPU 3288.6 MB, GPU 66.9 MB
2024-12-27 20:25:27,777 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:25:27,845 - INFO - Fitted scaler and transformed data
2024-12-27 20:25:27,845 - INFO - Scaling time: 0.07s
2024-12-27 20:25:27,850 - INFO - Number of unique classes: 100
2024-12-27 20:25:30,831 - INFO - Epoch 1/15, Train Loss: 4.3808, Val Loss: 4.6049
2024-12-27 20:25:34,568 - INFO - Epoch 2/15, Train Loss: 4.3798, Val Loss: 4.6045
2024-12-27 20:25:37,944 - INFO - Epoch 3/15, Train Loss: 4.3788, Val Loss: 4.6040
2024-12-27 20:25:37,944 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:25:37,944 - INFO - Training completed in 10.17s
2024-12-27 20:25:37,945 - INFO - Final memory usage: CPU 3288.6 MB, GPU 97.4 MB
2024-12-27 20:25:37,945 - INFO - Model training completed in 10.17s
2024-12-27 20:25:38,058 - INFO - Prediction completed in 0.11s
2024-12-27 20:25:38,066 - INFO - Poison rate 0.03 completed in 12.38s
2024-12-27 20:25:38,066 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:25:38,074 - INFO - Total number of labels flipped: 250
2024-12-27 20:25:38,074 - INFO - Label flipping completed in 0.01s
2024-12-27 20:25:38,074 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:25:38,074 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:25:38,618 - INFO - Feature scaling completed in 0.54s
2024-12-27 20:25:38,618 - INFO - Starting feature selection (k=50)
2024-12-27 20:25:38,631 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:25:38,631 - INFO - Starting anomaly detection
2024-12-27 20:25:40,654 - INFO - Anomaly detection completed in 2.02s
2024-12-27 20:25:40,655 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:25:40,655 - INFO - Total fit_transform time: 2.58s
2024-12-27 20:25:40,655 - INFO - Training set processing completed in 2.58s
2024-12-27 20:25:40,655 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:25:40,656 - INFO - Memory usage at start_fit: CPU 3288.6 MB, GPU 66.9 MB
2024-12-27 20:25:40,657 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:25:40,728 - INFO - Fitted scaler and transformed data
2024-12-27 20:25:40,729 - INFO - Scaling time: 0.07s
2024-12-27 20:25:40,735 - INFO - Number of unique classes: 100
2024-12-27 20:25:43,857 - INFO - Epoch 1/15, Train Loss: 4.3767, Val Loss: 4.6049
2024-12-27 20:25:47,123 - INFO - Epoch 2/15, Train Loss: 4.3758, Val Loss: 4.6046
2024-12-27 20:25:50,413 - INFO - Epoch 3/15, Train Loss: 4.3748, Val Loss: 4.6042
2024-12-27 20:25:50,413 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:25:50,413 - INFO - Training completed in 9.76s
2024-12-27 20:25:50,413 - INFO - Final memory usage: CPU 3288.6 MB, GPU 97.4 MB
2024-12-27 20:25:50,413 - INFO - Model training completed in 9.76s
2024-12-27 20:25:50,525 - INFO - Prediction completed in 0.11s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:25:50,534 - INFO - Poison rate 0.05 completed in 12.47s
2024-12-27 20:25:50,534 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:25:50,545 - INFO - Total number of labels flipped: 350
2024-12-27 20:25:50,545 - INFO - Label flipping completed in 0.01s
2024-12-27 20:25:50,545 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:25:50,545 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:25:51,170 - INFO - Feature scaling completed in 0.62s
2024-12-27 20:25:51,170 - INFO - Starting feature selection (k=50)
2024-12-27 20:25:51,183 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:25:51,183 - INFO - Starting anomaly detection
2024-12-27 20:25:52,422 - INFO - Anomaly detection completed in 1.24s
2024-12-27 20:25:52,423 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:25:52,423 - INFO - Total fit_transform time: 1.88s
2024-12-27 20:25:52,423 - INFO - Training set processing completed in 1.88s
2024-12-27 20:25:52,423 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:25:52,424 - INFO - Memory usage at start_fit: CPU 3288.6 MB, GPU 66.9 MB
2024-12-27 20:25:52,425 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:25:52,496 - INFO - Fitted scaler and transformed data
2024-12-27 20:25:52,496 - INFO - Scaling time: 0.07s
2024-12-27 20:25:52,502 - INFO - Number of unique classes: 100
2024-12-27 20:25:55,538 - INFO - Epoch 1/15, Train Loss: 4.3739, Val Loss: 4.6049
2024-12-27 20:25:58,385 - INFO - Epoch 2/15, Train Loss: 4.3729, Val Loss: 4.6046
2024-12-27 20:26:01,199 - INFO - Epoch 3/15, Train Loss: 4.3719, Val Loss: 4.6042
2024-12-27 20:26:01,199 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:26:01,199 - INFO - Training completed in 8.78s
2024-12-27 20:26:01,199 - INFO - Final memory usage: CPU 3288.6 MB, GPU 97.4 MB
2024-12-27 20:26:01,200 - INFO - Model training completed in 8.78s
2024-12-27 20:26:01,304 - INFO - Prediction completed in 0.10s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:26:01,313 - INFO - Poison rate 0.07 completed in 10.78s
2024-12-27 20:26:01,313 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:26:01,327 - INFO - Total number of labels flipped: 500
2024-12-27 20:26:01,327 - INFO - Label flipping completed in 0.01s
2024-12-27 20:26:01,328 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:26:01,328 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:26:01,893 - INFO - Feature scaling completed in 0.57s
2024-12-27 20:26:01,893 - INFO - Starting feature selection (k=50)
2024-12-27 20:26:01,905 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:26:01,906 - INFO - Starting anomaly detection
2024-12-27 20:26:03,262 - INFO - Anomaly detection completed in 1.36s
2024-12-27 20:26:03,263 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:26:03,263 - INFO - Total fit_transform time: 1.94s
2024-12-27 20:26:03,263 - INFO - Training set processing completed in 1.94s
2024-12-27 20:26:03,263 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:26:03,264 - INFO - Memory usage at start_fit: CPU 3288.6 MB, GPU 66.9 MB
2024-12-27 20:26:03,265 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:26:03,336 - INFO - Fitted scaler and transformed data
2024-12-27 20:26:03,336 - INFO - Scaling time: 0.07s
2024-12-27 20:26:03,345 - INFO - Number of unique classes: 100
2024-12-27 20:26:06,315 - INFO - Epoch 1/15, Train Loss: 4.3775, Val Loss: 4.6049
2024-12-27 20:26:09,038 - INFO - Epoch 2/15, Train Loss: 4.3766, Val Loss: 4.6046
2024-12-27 20:26:11,807 - INFO - Epoch 3/15, Train Loss: 4.3756, Val Loss: 4.6042
2024-12-27 20:26:11,807 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:26:11,808 - INFO - Training completed in 8.54s
2024-12-27 20:26:11,808 - INFO - Final memory usage: CPU 3288.6 MB, GPU 97.4 MB
2024-12-27 20:26:11,808 - INFO - Model training completed in 8.55s
2024-12-27 20:26:11,910 - INFO - Prediction completed in 0.10s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:26:11,919 - INFO - Poison rate 0.1 completed in 10.61s
2024-12-27 20:26:11,919 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:26:11,947 - INFO - Total number of labels flipped: 1000
2024-12-27 20:26:11,947 - INFO - Label flipping completed in 0.03s
2024-12-27 20:26:11,948 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:26:11,948 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:26:12,496 - INFO - Feature scaling completed in 0.55s
2024-12-27 20:26:12,496 - INFO - Starting feature selection (k=50)
2024-12-27 20:26:12,508 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:26:12,509 - INFO - Starting anomaly detection
2024-12-27 20:26:14,842 - INFO - Anomaly detection completed in 2.33s
2024-12-27 20:26:14,842 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:26:14,843 - INFO - Total fit_transform time: 2.89s
2024-12-27 20:26:14,843 - INFO - Training set processing completed in 2.90s
2024-12-27 20:26:14,843 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:26:14,844 - INFO - Memory usage at start_fit: CPU 3288.6 MB, GPU 66.9 MB
2024-12-27 20:26:14,845 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:26:14,917 - INFO - Fitted scaler and transformed data
2024-12-27 20:26:14,917 - INFO - Scaling time: 0.07s
2024-12-27 20:26:14,923 - INFO - Number of unique classes: 100
2024-12-27 20:26:17,906 - INFO - Epoch 1/15, Train Loss: 4.3753, Val Loss: 4.6050
2024-12-27 20:26:20,849 - INFO - Epoch 2/15, Train Loss: 4.3743, Val Loss: 4.6047
2024-12-27 20:26:23,766 - INFO - Epoch 3/15, Train Loss: 4.3734, Val Loss: 4.6044
2024-12-27 20:26:23,766 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:26:23,766 - INFO - Training completed in 8.92s
2024-12-27 20:26:23,766 - INFO - Final memory usage: CPU 3288.6 MB, GPU 97.4 MB
2024-12-27 20:26:23,767 - INFO - Model training completed in 8.92s
2024-12-27 20:26:23,871 - INFO - Prediction completed in 0.10s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:26:23,880 - INFO - Poison rate 0.2 completed in 11.96s
2024-12-27 20:26:23,882 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:26:23,882 - INFO - Total evaluation time: 91.91s
2024-12-27 20:26:23,883 - INFO - 
Progress: 65.6% - Evaluating CIFAR100 with KNeighbors (standard mode, iteration 1/1)
2024-12-27 20:26:23,948 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:26:24,055 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:26:24,139 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:26:24,139 - INFO - Dataset type: image
2024-12-27 20:26:24,139 - INFO - Sample size: 5000
2024-12-27 20:26:24,139 - INFO - Using device: cuda
2024-12-27 20:26:24,142 - INFO - Loading datasets...
2024-12-27 20:26:25,469 - INFO - Dataset loading completed in 1.33s
2024-12-27 20:26:25,469 - INFO - Extracting validation features...
2024-12-27 20:26:25,470 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:14,  2.14it/s]Extracting features:  22%|██▏       | 7/32 [00:00<00:01, 14.91it/s]Extracting features:  38%|███▊      | 12/32 [00:00<00:00, 23.14it/s]Extracting features:  56%|█████▋    | 18/32 [00:00<00:00, 32.00it/s]Extracting features:  78%|███████▊  | 25/32 [00:00<00:00, 40.12it/s]Extracting features:  97%|█████████▋| 31/32 [00:01<00:00, 44.92it/s]Extracting features: 100%|██████████| 32/32 [00:01<00:00, 28.83it/s]
2024-12-27 20:26:26,584 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:26:26,585 - INFO - Validation feature extraction completed in 1.12s
2024-12-27 20:26:26,585 - INFO - Extracting training features...
2024-12-27 20:26:26,585 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:50,  3.09it/s]Extracting features:   4%|▍         | 7/157 [00:00<00:07, 19.48it/s]Extracting features:   8%|▊         | 13/157 [00:00<00:04, 31.21it/s]Extracting features:  12%|█▏        | 19/157 [00:00<00:03, 38.92it/s]Extracting features:  16%|█▌        | 25/157 [00:00<00:03, 43.24it/s]Extracting features:  20%|█▉        | 31/157 [00:00<00:02, 47.20it/s]Extracting features:  24%|██▎       | 37/157 [00:00<00:02, 47.83it/s]Extracting features:  27%|██▋       | 43/157 [00:01<00:02, 50.48it/s]Extracting features:  31%|███       | 49/157 [00:01<00:02, 49.90it/s]Extracting features:  35%|███▌      | 55/157 [00:01<00:02, 50.43it/s]Extracting features:  39%|███▉      | 61/157 [00:01<00:01, 48.95it/s]Extracting features:  43%|████▎     | 67/157 [00:01<00:01, 50.19it/s]Extracting features:  46%|████▋     | 73/157 [00:01<00:01, 51.08it/s]Extracting features:  50%|█████     | 79/157 [00:01<00:01, 50.28it/s]Extracting features:  54%|█████▍    | 85/157 [00:01<00:01, 51.84it/s]Extracting features:  58%|█████▊    | 91/157 [00:02<00:01, 48.02it/s]Extracting features:  62%|██████▏   | 97/157 [00:02<00:01, 50.43it/s]Extracting features:  66%|██████▌   | 103/157 [00:02<00:01, 48.08it/s]Extracting features:  69%|██████▉   | 108/157 [00:02<00:01, 48.39it/s]Extracting features:  73%|███████▎  | 114/157 [00:02<00:00, 49.16it/s]Extracting features:  76%|███████▌  | 119/157 [00:02<00:00, 48.62it/s]Extracting features:  80%|███████▉  | 125/157 [00:02<00:00, 50.20it/s]Extracting features:  83%|████████▎ | 131/157 [00:02<00:00, 52.84it/s]Extracting features:  87%|████████▋ | 137/157 [00:02<00:00, 54.25it/s]Extracting features:  91%|█████████ | 143/157 [00:03<00:00, 53.19it/s]Extracting features:  95%|█████████▍| 149/157 [00:03<00:00, 48.06it/s]Extracting features:  99%|█████████▊| 155/157 [00:03<00:00, 49.43it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 45.92it/s]
2024-12-27 20:26:30,020 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:26:30,020 - INFO - Training feature extraction completed in 3.43s
2024-12-27 20:26:30,020 - INFO - Creating model for classifier: KNeighbors
2024-12-27 20:26:30,020 - INFO - Using device: cuda
2024-12-27 20:26:30,020 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:26:30,020 - INFO - Training set processing completed in 0.00s
2024-12-27 20:26:30,020 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:26:30,022 - INFO - Memory usage at start_fit: CPU 3265.1 MB, GPU 47.3 MB
2024-12-27 20:26:30,022 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:26:30,101 - INFO - Fitted scaler and transformed data
2024-12-27 20:26:30,102 - INFO - Scaling time: 0.08s
2024-12-27 20:26:30,106 - INFO - Training completed in 0.08s
2024-12-27 20:26:30,107 - INFO - Final memory usage: CPU 3289.5 MB, GPU 71.8 MB
2024-12-27 20:26:30,107 - INFO - Model training completed in 0.09s
2024-12-27 20:26:30,119 - INFO - Prediction completed in 0.01s
2024-12-27 20:26:30,129 - INFO - Poison rate 0.0 completed in 0.11s
2024-12-27 20:26:30,129 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:26:30,131 - INFO - Total number of labels flipped: 50
2024-12-27 20:26:30,131 - INFO - Label flipping completed in 0.00s
2024-12-27 20:26:30,131 - INFO - Training set processing completed in 0.00s
2024-12-27 20:26:30,131 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:26:30,132 - INFO - Memory usage at start_fit: CPU 3289.5 MB, GPU 71.8 MB
2024-12-27 20:26:30,132 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:26:30,195 - INFO - Fitted scaler and transformed data
2024-12-27 20:26:30,196 - INFO - Scaling time: 0.06s
2024-12-27 20:26:30,201 - INFO - Training completed in 0.07s
2024-12-27 20:26:30,201 - INFO - Final memory usage: CPU 3289.5 MB, GPU 71.8 MB
2024-12-27 20:26:30,201 - INFO - Model training completed in 0.07s
2024-12-27 20:26:30,217 - INFO - Prediction completed in 0.02s
2024-12-27 20:26:30,225 - INFO - Poison rate 0.01 completed in 0.10s
2024-12-27 20:26:30,225 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:26:30,230 - INFO - Total number of labels flipped: 150
2024-12-27 20:26:30,230 - INFO - Label flipping completed in 0.00s
2024-12-27 20:26:30,230 - INFO - Training set processing completed in 0.00s
2024-12-27 20:26:30,230 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:26:30,231 - INFO - Memory usage at start_fit: CPU 3289.5 MB, GPU 71.8 MB
2024-12-27 20:26:30,231 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:26:30,290 - INFO - Fitted scaler and transformed data
2024-12-27 20:26:30,291 - INFO - Scaling time: 0.06s
2024-12-27 20:26:30,297 - INFO - Training completed in 0.07s
2024-12-27 20:26:30,298 - INFO - Final memory usage: CPU 3289.5 MB, GPU 71.8 MB
2024-12-27 20:26:30,299 - INFO - Model training completed in 0.07s
2024-12-27 20:26:30,313 - INFO - Prediction completed in 0.01s
2024-12-27 20:26:30,321 - INFO - Poison rate 0.03 completed in 0.10s
2024-12-27 20:26:30,322 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:26:30,329 - INFO - Total number of labels flipped: 250
2024-12-27 20:26:30,329 - INFO - Label flipping completed in 0.01s
2024-12-27 20:26:30,329 - INFO - Training set processing completed in 0.00s
2024-12-27 20:26:30,329 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:26:30,330 - INFO - Memory usage at start_fit: CPU 3289.5 MB, GPU 71.8 MB
2024-12-27 20:26:30,330 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:26:30,389 - INFO - Fitted scaler and transformed data
2024-12-27 20:26:30,389 - INFO - Scaling time: 0.06s
2024-12-27 20:26:30,394 - INFO - Training completed in 0.06s
2024-12-27 20:26:30,395 - INFO - Final memory usage: CPU 3289.5 MB, GPU 71.8 MB
2024-12-27 20:26:30,395 - INFO - Model training completed in 0.07s
2024-12-27 20:26:30,410 - INFO - Prediction completed in 0.01s
2024-12-27 20:26:30,418 - INFO - Poison rate 0.05 completed in 0.10s
2024-12-27 20:26:30,419 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:26:30,429 - INFO - Total number of labels flipped: 350
2024-12-27 20:26:30,429 - INFO - Label flipping completed in 0.01s
2024-12-27 20:26:30,429 - INFO - Training set processing completed in 0.00s
2024-12-27 20:26:30,429 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:26:30,430 - INFO - Memory usage at start_fit: CPU 3289.5 MB, GPU 71.8 MB
2024-12-27 20:26:30,430 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:26:30,491 - INFO - Fitted scaler and transformed data
2024-12-27 20:26:30,491 - INFO - Scaling time: 0.06s
2024-12-27 20:26:30,496 - INFO - Training completed in 0.07s
2024-12-27 20:26:30,496 - INFO - Final memory usage: CPU 3289.5 MB, GPU 71.8 MB
2024-12-27 20:26:30,497 - INFO - Model training completed in 0.07s
2024-12-27 20:26:30,511 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:26:30,520 - INFO - Poison rate 0.07 completed in 0.10s
2024-12-27 20:26:30,520 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:26:30,534 - INFO - Total number of labels flipped: 500
2024-12-27 20:26:30,535 - INFO - Label flipping completed in 0.01s
2024-12-27 20:26:30,535 - INFO - Training set processing completed in 0.00s
2024-12-27 20:26:30,535 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:26:30,536 - INFO - Memory usage at start_fit: CPU 3289.5 MB, GPU 71.8 MB
2024-12-27 20:26:30,536 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:26:30,602 - INFO - Fitted scaler and transformed data
2024-12-27 20:26:30,602 - INFO - Scaling time: 0.07s
2024-12-27 20:26:30,608 - INFO - Training completed in 0.07s
2024-12-27 20:26:30,608 - INFO - Final memory usage: CPU 3289.5 MB, GPU 71.8 MB
2024-12-27 20:26:30,609 - INFO - Model training completed in 0.07s
2024-12-27 20:26:30,627 - INFO - Prediction completed in 0.02s
2024-12-27 20:26:30,640 - INFO - Poison rate 0.1 completed in 0.12s
2024-12-27 20:26:30,640 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:26:30,669 - INFO - Total number of labels flipped: 1000
2024-12-27 20:26:30,669 - INFO - Label flipping completed in 0.03s
2024-12-27 20:26:30,669 - INFO - Training set processing completed in 0.00s
2024-12-27 20:26:30,669 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:26:30,670 - INFO - Memory usage at start_fit: CPU 3289.5 MB, GPU 71.8 MB
2024-12-27 20:26:30,670 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:26:30,731 - INFO - Fitted scaler and transformed data
2024-12-27 20:26:30,731 - INFO - Scaling time: 0.06s
2024-12-27 20:26:30,736 - INFO - Training completed in 0.07s
2024-12-27 20:26:30,736 - INFO - Final memory usage: CPU 3289.5 MB, GPU 71.8 MB
2024-12-27 20:26:30,737 - INFO - Model training completed in 0.07s
2024-12-27 20:26:30,750 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:26:30,759 - INFO - Poison rate 0.2 completed in 0.12s
2024-12-27 20:26:30,761 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:26:30,761 - INFO - Total evaluation time: 6.62s
2024-12-27 20:26:30,763 - INFO - 
Progress: 66.7% - Evaluating CIFAR100 with KNeighbors (dynadetect mode, iteration 1/1)
2024-12-27 20:26:30,824 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:26:30,898 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:26:30,953 - INFO - Initialized DatasetHandler for CIFAR100
2024-12-27 20:26:30,954 - INFO - Dataset type: image
2024-12-27 20:26:30,954 - INFO - Sample size: 5000
2024-12-27 20:26:30,954 - INFO - Using device: cuda
2024-12-27 20:26:30,955 - INFO - Loading datasets...
2024-12-27 20:26:32,242 - INFO - Dataset loading completed in 1.29s
2024-12-27 20:26:32,242 - INFO - Extracting validation features...
2024-12-27 20:26:32,242 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Files already downloaded and verified
Files already downloaded and verified
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:08,  3.82it/s]Extracting features:  12%|█▎        | 4/32 [00:00<00:02, 12.83it/s]Extracting features:  25%|██▌       | 8/32 [00:00<00:01, 21.10it/s]Extracting features:  41%|████      | 13/32 [00:00<00:00, 29.46it/s]Extracting features:  56%|█████▋    | 18/32 [00:00<00:00, 35.63it/s]Extracting features:  75%|███████▌  | 24/32 [00:00<00:00, 41.24it/s]Extracting features:  91%|█████████ | 29/32 [00:00<00:00, 42.65it/s]Extracting features: 100%|██████████| 32/32 [00:00<00:00, 32.12it/s]
2024-12-27 20:26:33,242 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:26:33,242 - INFO - Validation feature extraction completed in 1.00s
2024-12-27 20:26:33,242 - INFO - Extracting training features...
2024-12-27 20:26:33,242 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:46,  3.36it/s]Extracting features:   4%|▍         | 6/157 [00:00<00:08, 17.52it/s]Extracting features:   8%|▊         | 12/157 [00:00<00:04, 29.33it/s]Extracting features:  11%|█         | 17/157 [00:00<00:04, 33.81it/s]Extracting features:  15%|█▍        | 23/157 [00:00<00:03, 40.03it/s]Extracting features:  18%|█▊        | 28/157 [00:00<00:03, 42.32it/s]Extracting features:  22%|██▏       | 34/157 [00:00<00:02, 46.71it/s]Extracting features:  25%|██▌       | 40/157 [00:01<00:02, 50.21it/s]Extracting features:  29%|██▉       | 46/157 [00:01<00:02, 52.32it/s]Extracting features:  33%|███▎      | 52/157 [00:01<00:01, 53.03it/s]Extracting features:  37%|███▋      | 58/157 [00:01<00:01, 52.94it/s]Extracting features:  41%|████      | 64/157 [00:01<00:01, 53.22it/s]Extracting features:  45%|████▍     | 70/157 [00:01<00:01, 49.30it/s]Extracting features:  48%|████▊     | 76/157 [00:01<00:01, 51.59it/s]Extracting features:  52%|█████▏    | 82/157 [00:01<00:01, 51.04it/s]Extracting features:  56%|█████▌    | 88/157 [00:01<00:01, 52.29it/s]Extracting features:  60%|█████▉    | 94/157 [00:02<00:01, 51.75it/s]Extracting features:  64%|██████▎   | 100/157 [00:02<00:01, 52.23it/s]Extracting features:  68%|██████▊   | 106/157 [00:02<00:00, 52.85it/s]Extracting features:  71%|███████▏  | 112/157 [00:02<00:00, 51.36it/s]Extracting features:  75%|███████▌  | 118/157 [00:02<00:00, 53.20it/s]Extracting features:  79%|███████▉  | 124/157 [00:02<00:00, 54.32it/s]Extracting features:  83%|████████▎ | 130/157 [00:02<00:00, 53.31it/s]Extracting features:  87%|████████▋ | 136/157 [00:02<00:00, 53.87it/s]Extracting features:  90%|█████████ | 142/157 [00:02<00:00, 53.60it/s]Extracting features:  94%|█████████▍| 148/157 [00:03<00:00, 52.41it/s]Extracting features:  99%|█████████▊| 155/157 [00:03<00:00, 55.96it/s]Extracting features: 100%|██████████| 157/157 [00:03<00:00, 47.31it/s]
2024-12-27 20:26:36,572 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:26:36,572 - INFO - Training feature extraction completed in 3.33s
2024-12-27 20:26:36,572 - INFO - Creating model for classifier: KNeighbors
2024-12-27 20:26:36,573 - INFO - Using device: cuda
2024-12-27 20:26:36,573 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:26:36,573 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:26:36,573 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:26:37,150 - INFO - Feature scaling completed in 0.58s
2024-12-27 20:26:37,150 - INFO - Starting feature selection (k=50)
2024-12-27 20:26:37,156 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:26:37,156 - INFO - Starting anomaly detection
2024-12-27 20:26:38,276 - INFO - Anomaly detection completed in 1.12s
2024-12-27 20:26:38,276 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:26:38,276 - INFO - Total fit_transform time: 1.70s
2024-12-27 20:26:38,276 - INFO - Training set processing completed in 1.70s
2024-12-27 20:26:38,276 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:26:38,278 - INFO - Memory usage at start_fit: CPU 3292.8 MB, GPU 47.3 MB
2024-12-27 20:26:38,278 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:26:38,351 - INFO - Fitted scaler and transformed data
2024-12-27 20:26:38,351 - INFO - Scaling time: 0.07s
2024-12-27 20:26:38,356 - INFO - Training completed in 0.08s
2024-12-27 20:26:38,357 - INFO - Final memory usage: CPU 3292.8 MB, GPU 71.8 MB
2024-12-27 20:26:38,357 - INFO - Model training completed in 0.08s
2024-12-27 20:26:38,371 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:26:38,381 - INFO - Poison rate 0.0 completed in 1.81s
2024-12-27 20:26:38,381 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:26:38,383 - INFO - Total number of labels flipped: 50
2024-12-27 20:26:38,383 - INFO - Label flipping completed in 0.00s
2024-12-27 20:26:38,383 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:26:38,383 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:26:38,935 - INFO - Feature scaling completed in 0.55s
2024-12-27 20:26:38,935 - INFO - Starting feature selection (k=50)
2024-12-27 20:26:38,941 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:26:38,941 - INFO - Starting anomaly detection
2024-12-27 20:26:40,960 - INFO - Anomaly detection completed in 2.02s
2024-12-27 20:26:40,960 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:26:40,960 - INFO - Total fit_transform time: 2.58s
2024-12-27 20:26:40,960 - INFO - Training set processing completed in 2.58s
2024-12-27 20:26:40,960 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:26:40,962 - INFO - Memory usage at start_fit: CPU 3292.8 MB, GPU 71.8 MB
2024-12-27 20:26:40,962 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:26:41,038 - INFO - Fitted scaler and transformed data
2024-12-27 20:26:41,038 - INFO - Scaling time: 0.08s
2024-12-27 20:26:41,043 - INFO - Training completed in 0.08s
2024-12-27 20:26:41,044 - INFO - Final memory usage: CPU 3292.8 MB, GPU 71.8 MB
2024-12-27 20:26:41,044 - INFO - Model training completed in 0.08s
2024-12-27 20:26:41,058 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:26:41,067 - INFO - Poison rate 0.01 completed in 2.69s
2024-12-27 20:26:41,068 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:26:41,072 - INFO - Total number of labels flipped: 150
2024-12-27 20:26:41,073 - INFO - Label flipping completed in 0.00s
2024-12-27 20:26:41,073 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:26:41,073 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:26:41,609 - INFO - Feature scaling completed in 0.54s
2024-12-27 20:26:41,609 - INFO - Starting feature selection (k=50)
2024-12-27 20:26:41,617 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:26:41,618 - INFO - Starting anomaly detection
2024-12-27 20:26:43,874 - INFO - Anomaly detection completed in 2.26s
2024-12-27 20:26:43,874 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:26:43,874 - INFO - Total fit_transform time: 2.80s
2024-12-27 20:26:43,874 - INFO - Training set processing completed in 2.80s
2024-12-27 20:26:43,874 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:26:43,875 - INFO - Memory usage at start_fit: CPU 3292.8 MB, GPU 71.8 MB
2024-12-27 20:26:43,875 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:26:43,953 - INFO - Fitted scaler and transformed data
2024-12-27 20:26:43,953 - INFO - Scaling time: 0.08s
2024-12-27 20:26:43,962 - INFO - Training completed in 0.09s
2024-12-27 20:26:43,962 - INFO - Final memory usage: CPU 3292.8 MB, GPU 71.8 MB
2024-12-27 20:26:43,962 - INFO - Model training completed in 0.09s
2024-12-27 20:26:43,989 - INFO - Prediction completed in 0.03s
2024-12-27 20:26:43,997 - INFO - Poison rate 0.03 completed in 2.93s
2024-12-27 20:26:43,997 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:26:44,016 - INFO - Total number of labels flipped: 250
2024-12-27 20:26:44,016 - INFO - Label flipping completed in 0.02s
2024-12-27 20:26:44,016 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:26:44,016 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:26:44,556 - INFO - Feature scaling completed in 0.54s
2024-12-27 20:26:44,556 - INFO - Starting feature selection (k=50)
2024-12-27 20:26:44,564 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:26:44,564 - INFO - Starting anomaly detection
2024-12-27 20:26:46,906 - INFO - Anomaly detection completed in 2.34s
2024-12-27 20:26:46,906 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:26:46,907 - INFO - Total fit_transform time: 2.89s
2024-12-27 20:26:46,907 - INFO - Training set processing completed in 2.89s
2024-12-27 20:26:46,907 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:26:46,908 - INFO - Memory usage at start_fit: CPU 3292.8 MB, GPU 71.8 MB
2024-12-27 20:26:46,908 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:26:46,993 - INFO - Fitted scaler and transformed data
2024-12-27 20:26:46,993 - INFO - Scaling time: 0.08s
2024-12-27 20:26:47,000 - INFO - Training completed in 0.09s
2024-12-27 20:26:47,001 - INFO - Final memory usage: CPU 3292.8 MB, GPU 71.8 MB
2024-12-27 20:26:47,001 - INFO - Model training completed in 0.09s
2024-12-27 20:26:47,025 - INFO - Prediction completed in 0.02s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:26:47,034 - INFO - Poison rate 0.05 completed in 3.04s
2024-12-27 20:26:47,034 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:26:47,045 - INFO - Total number of labels flipped: 350
2024-12-27 20:26:47,045 - INFO - Label flipping completed in 0.01s
2024-12-27 20:26:47,045 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:26:47,045 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:26:47,657 - INFO - Feature scaling completed in 0.61s
2024-12-27 20:26:47,658 - INFO - Starting feature selection (k=50)
2024-12-27 20:26:47,667 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:26:47,668 - INFO - Starting anomaly detection
2024-12-27 20:26:49,703 - INFO - Anomaly detection completed in 2.04s
2024-12-27 20:26:49,703 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:26:49,703 - INFO - Total fit_transform time: 2.66s
2024-12-27 20:26:49,703 - INFO - Training set processing completed in 2.66s
2024-12-27 20:26:49,703 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:26:49,704 - INFO - Memory usage at start_fit: CPU 3292.8 MB, GPU 71.8 MB
2024-12-27 20:26:49,704 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:26:49,773 - INFO - Fitted scaler and transformed data
2024-12-27 20:26:49,773 - INFO - Scaling time: 0.07s
2024-12-27 20:26:49,779 - INFO - Training completed in 0.08s
2024-12-27 20:26:49,780 - INFO - Final memory usage: CPU 3292.8 MB, GPU 71.8 MB
2024-12-27 20:26:49,780 - INFO - Model training completed in 0.08s
2024-12-27 20:26:49,806 - INFO - Prediction completed in 0.03s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:26:49,815 - INFO - Poison rate 0.07 completed in 2.78s
2024-12-27 20:26:49,815 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:26:49,829 - INFO - Total number of labels flipped: 500
2024-12-27 20:26:49,830 - INFO - Label flipping completed in 0.01s
2024-12-27 20:26:49,830 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:26:49,830 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:26:50,432 - INFO - Feature scaling completed in 0.60s
2024-12-27 20:26:50,432 - INFO - Starting feature selection (k=50)
2024-12-27 20:26:50,440 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:26:50,440 - INFO - Starting anomaly detection
2024-12-27 20:26:52,257 - INFO - Anomaly detection completed in 1.82s
2024-12-27 20:26:52,257 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:26:52,257 - INFO - Total fit_transform time: 2.43s
2024-12-27 20:26:52,257 - INFO - Training set processing completed in 2.43s
2024-12-27 20:26:52,257 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:26:52,258 - INFO - Memory usage at start_fit: CPU 3292.8 MB, GPU 71.8 MB
2024-12-27 20:26:52,259 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:26:52,334 - INFO - Fitted scaler and transformed data
2024-12-27 20:26:52,334 - INFO - Scaling time: 0.07s
2024-12-27 20:26:52,342 - INFO - Training completed in 0.08s
2024-12-27 20:26:52,343 - INFO - Final memory usage: CPU 3292.8 MB, GPU 71.8 MB
2024-12-27 20:26:52,343 - INFO - Model training completed in 0.09s
2024-12-27 20:26:52,375 - INFO - Prediction completed in 0.03s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:26:52,385 - INFO - Poison rate 0.1 completed in 2.57s
2024-12-27 20:26:52,386 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:26:52,417 - INFO - Total number of labels flipped: 1000
2024-12-27 20:26:52,417 - INFO - Label flipping completed in 0.03s
2024-12-27 20:26:52,417 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:26:52,417 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:26:52,997 - INFO - Feature scaling completed in 0.58s
2024-12-27 20:26:52,997 - INFO - Starting feature selection (k=50)
2024-12-27 20:26:53,010 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:26:53,010 - INFO - Starting anomaly detection
2024-12-27 20:26:55,037 - INFO - Anomaly detection completed in 2.03s
2024-12-27 20:26:55,037 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:26:55,038 - INFO - Total fit_transform time: 2.62s
2024-12-27 20:26:55,038 - INFO - Training set processing completed in 2.62s
2024-12-27 20:26:55,038 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:26:55,039 - INFO - Memory usage at start_fit: CPU 3292.8 MB, GPU 71.8 MB
2024-12-27 20:26:55,040 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:26:55,124 - INFO - Fitted scaler and transformed data
2024-12-27 20:26:55,124 - INFO - Scaling time: 0.08s
2024-12-27 20:26:55,135 - INFO - Training completed in 0.10s
2024-12-27 20:26:55,136 - INFO - Final memory usage: CPU 3292.8 MB, GPU 71.8 MB
2024-12-27 20:26:55,136 - INFO - Model training completed in 0.10s
2024-12-27 20:26:55,163 - INFO - Prediction completed in 0.03s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:26:55,172 - INFO - Poison rate 0.2 completed in 2.79s
2024-12-27 20:26:55,174 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:26:55,174 - INFO - Total evaluation time: 24.22s
2024-12-27 20:26:55,175 - INFO - Completed evaluation for CIFAR100
2024-12-27 20:26:55,176 - INFO - 
Processing dataset: ImageNette
2024-12-27 20:26:55,252 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:26:55,327 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:26:55,407 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 20:26:55,407 - INFO - Dataset type: image
2024-12-27 20:26:55,407 - INFO - Sample size: 5000
2024-12-27 20:26:55,407 - INFO - Using device: cuda
2024-12-27 20:26:55,409 - INFO - 
Progress: 67.7% - Evaluating ImageNette with SVM (standard mode, iteration 1/1)
2024-12-27 20:26:55,467 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:26:55,539 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:26:55,646 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 20:26:55,646 - INFO - Dataset type: image
2024-12-27 20:26:55,646 - INFO - Sample size: 5000
2024-12-27 20:26:55,646 - INFO - Using device: cuda
2024-12-27 20:26:55,651 - INFO - Loading datasets...
2024-12-27 20:26:55,681 - INFO - Dataset loading completed in 0.03s
2024-12-27 20:26:55,681 - INFO - Extracting validation features...
2024-12-27 20:26:55,681 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:19,  1.56it/s]Extracting features:  19%|█▉        | 6/32 [00:00<00:02,  9.59it/s]Extracting features:  28%|██▊       | 9/32 [00:00<00:01, 12.12it/s]Extracting features:  34%|███▍      | 11/32 [00:01<00:01, 10.56it/s]Extracting features:  44%|████▍     | 14/32 [00:01<00:01, 11.09it/s]Extracting features:  56%|█████▋    | 18/32 [00:01<00:01, 11.99it/s]Extracting features:  62%|██████▎   | 20/32 [00:01<00:01, 10.91it/s]Extracting features:  75%|███████▌  | 24/32 [00:02<00:00, 11.43it/s]Extracting features:  88%|████████▊ | 28/32 [00:02<00:00, 13.03it/s]Extracting features:  94%|█████████▍| 30/32 [00:02<00:00, 13.10it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 11.43it/s]
2024-12-27 20:26:58,485 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:26:58,485 - INFO - Validation feature extraction completed in 2.80s
2024-12-27 20:26:58,486 - INFO - Extracting training features...
2024-12-27 20:26:58,486 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:07,  2.31it/s]Extracting features:   3%|▎         | 4/157 [00:00<00:19,  7.89it/s]Extracting features:   4%|▍         | 6/157 [00:00<00:15,  9.94it/s]Extracting features:   5%|▌         | 8/157 [00:00<00:16,  8.99it/s]Extracting features:   8%|▊         | 12/157 [00:01<00:13, 10.83it/s]Extracting features:   9%|▉         | 14/157 [00:01<00:12, 11.78it/s]Extracting features:  10%|█         | 16/157 [00:01<00:12, 11.28it/s]Extracting features:  13%|█▎        | 20/157 [00:01<00:10, 12.95it/s]Extracting features:  14%|█▍        | 22/157 [00:01<00:09, 14.01it/s]Extracting features:  15%|█▌        | 24/157 [00:02<00:09, 13.38it/s]Extracting features:  17%|█▋        | 27/157 [00:02<00:08, 15.90it/s]Extracting features:  18%|█▊        | 29/157 [00:02<00:09, 13.27it/s]Extracting features:  20%|██        | 32/157 [00:02<00:08, 14.50it/s]Extracting features:  23%|██▎       | 36/157 [00:02<00:07, 16.33it/s]Extracting features:  25%|██▌       | 40/157 [00:03<00:07, 15.80it/s]Extracting features:  28%|██▊       | 44/157 [00:03<00:07, 15.70it/s]Extracting features:  31%|███       | 48/157 [00:03<00:06, 16.51it/s]Extracting features:  33%|███▎      | 52/157 [00:03<00:06, 17.26it/s]Extracting features:  36%|███▌      | 56/157 [00:04<00:06, 16.03it/s]Extracting features:  38%|███▊      | 60/157 [00:04<00:05, 16.90it/s]Extracting features:  41%|████      | 64/157 [00:04<00:05, 16.18it/s]Extracting features:  43%|████▎     | 68/157 [00:04<00:05, 15.95it/s]Extracting features:  46%|████▌     | 72/157 [00:05<00:06, 14.15it/s]Extracting features:  48%|████▊     | 75/157 [00:05<00:05, 15.80it/s]Extracting features:  49%|████▉     | 77/157 [00:05<00:06, 12.02it/s]Extracting features:  51%|█████     | 80/157 [00:05<00:06, 11.81it/s]Extracting features:  54%|█████▎    | 84/157 [00:06<00:05, 12.48it/s]Extracting features:  56%|█████▌    | 88/157 [00:06<00:05, 12.49it/s]Extracting features:  59%|█████▊    | 92/157 [00:06<00:05, 12.84it/s]Extracting features:  61%|██████    | 96/157 [00:07<00:04, 12.89it/s]Extracting features:  64%|██████▎   | 100/157 [00:07<00:04, 13.32it/s]Extracting features:  66%|██████▌   | 104/157 [00:07<00:04, 13.21it/s]Extracting features:  69%|██████▉   | 108/157 [00:08<00:03, 13.24it/s]Extracting features:  71%|███████▏  | 112/157 [00:08<00:03, 12.78it/s]Extracting features:  74%|███████▍  | 116/157 [00:08<00:03, 12.89it/s]Extracting features:  76%|███████▋  | 120/157 [00:08<00:02, 13.25it/s]Extracting features:  79%|███████▉  | 124/157 [00:09<00:02, 13.84it/s]Extracting features:  82%|████████▏ | 128/157 [00:09<00:01, 15.18it/s]Extracting features:  84%|████████▍ | 132/157 [00:09<00:01, 15.51it/s]Extracting features:  87%|████████▋ | 136/157 [00:09<00:01, 16.97it/s]Extracting features:  89%|████████▉ | 140/157 [00:10<00:01, 16.78it/s]Extracting features:  91%|█████████ | 143/157 [00:10<00:00, 15.44it/s]Extracting features:  94%|█████████▎| 147/157 [00:10<00:00, 17.04it/s]Extracting features:  96%|█████████▌| 151/157 [00:10<00:00, 16.57it/s]Extracting features:  99%|█████████▊| 155/157 [00:10<00:00, 17.93it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 14.18it/s]
2024-12-27 20:27:09,572 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:27:09,572 - INFO - Training feature extraction completed in 11.09s
2024-12-27 20:27:09,573 - INFO - Creating model for classifier: SVM
2024-12-27 20:27:09,573 - INFO - Using device: cuda
2024-12-27 20:27:09,573 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-27 20:27:09,573 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:27:09,573 - INFO - Training set processing completed in 0.00s
2024-12-27 20:27:09,573 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:27:09,575 - INFO - Memory usage at start_fit: CPU 3090.9 MB, GPU 47.3 MB
2024-12-27 20:27:09,575 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:27:09,576 - INFO - Number of unique classes: 10
2024-12-27 20:27:09,668 - INFO - Fitted scaler and transformed data
2024-12-27 20:27:09,668 - INFO - Scaling time: 0.09s
2024-12-27 20:27:09,871 - INFO - Epoch 1/25, Train Loss: 0.4252, Val Loss: 0.0240
2024-12-27 20:27:10,062 - INFO - Epoch 2/25, Train Loss: 0.0113, Val Loss: 0.0354
2024-12-27 20:27:10,220 - INFO - Epoch 3/25, Train Loss: 0.0016, Val Loss: 0.0302
2024-12-27 20:27:10,220 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:27:10,220 - INFO - Training completed in 0.65s
2024-12-27 20:27:10,220 - INFO - Final memory usage: CPU 3117.6 MB, GPU 48.1 MB
2024-12-27 20:27:10,221 - INFO - Model training completed in 0.65s
2024-12-27 20:27:10,229 - INFO - Prediction completed in 0.01s
2024-12-27 20:27:10,237 - INFO - Poison rate 0.0 completed in 0.66s
2024-12-27 20:27:10,237 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:27:10,238 - INFO - Total number of labels flipped: 50
2024-12-27 20:27:10,238 - INFO - Label flipping completed in 0.00s
2024-12-27 20:27:10,238 - INFO - Training set processing completed in 0.00s
2024-12-27 20:27:10,239 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:27:10,239 - INFO - Memory usage at start_fit: CPU 3117.6 MB, GPU 47.5 MB
2024-12-27 20:27:10,239 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:27:10,240 - INFO - Number of unique classes: 10
2024-12-27 20:27:10,344 - INFO - Fitted scaler and transformed data
2024-12-27 20:27:10,345 - INFO - Scaling time: 0.10s
2024-12-27 20:27:10,531 - INFO - Epoch 1/25, Train Loss: 0.8118, Val Loss: 0.2702
2024-12-27 20:27:10,693 - INFO - Epoch 2/25, Train Loss: 0.2200, Val Loss: 0.3499
2024-12-27 20:27:10,873 - INFO - Epoch 3/25, Train Loss: 0.1238, Val Loss: 0.3638
2024-12-27 20:27:10,873 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:27:10,873 - INFO - Training completed in 0.63s
2024-12-27 20:27:10,874 - INFO - Final memory usage: CPU 3117.6 MB, GPU 48.1 MB
2024-12-27 20:27:10,874 - INFO - Model training completed in 0.64s
2024-12-27 20:27:10,886 - INFO - Prediction completed in 0.01s
2024-12-27 20:27:10,898 - INFO - Poison rate 0.01 completed in 0.66s
2024-12-27 20:27:10,898 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:27:10,900 - INFO - Total number of labels flipped: 150
2024-12-27 20:27:10,901 - INFO - Label flipping completed in 0.00s
2024-12-27 20:27:10,901 - INFO - Training set processing completed in 0.00s
2024-12-27 20:27:10,901 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:27:10,901 - INFO - Memory usage at start_fit: CPU 3117.6 MB, GPU 47.5 MB
2024-12-27 20:27:10,902 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:27:10,902 - INFO - Number of unique classes: 10
2024-12-27 20:27:10,979 - INFO - Fitted scaler and transformed data
2024-12-27 20:27:10,980 - INFO - Scaling time: 0.08s
2024-12-27 20:27:11,168 - INFO - Epoch 1/25, Train Loss: 1.6251, Val Loss: 1.2060
2024-12-27 20:27:11,345 - INFO - Epoch 2/25, Train Loss: 0.5885, Val Loss: 1.4922
2024-12-27 20:27:11,520 - INFO - Epoch 3/25, Train Loss: 0.2736, Val Loss: 1.4241
2024-12-27 20:27:11,520 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:27:11,520 - INFO - Training completed in 0.62s
2024-12-27 20:27:11,520 - INFO - Final memory usage: CPU 3117.6 MB, GPU 48.1 MB
2024-12-27 20:27:11,520 - INFO - Model training completed in 0.62s
2024-12-27 20:27:11,527 - INFO - Prediction completed in 0.01s
2024-12-27 20:27:11,535 - INFO - Poison rate 0.03 completed in 0.64s
2024-12-27 20:27:11,535 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:27:11,538 - INFO - Total number of labels flipped: 250
2024-12-27 20:27:11,538 - INFO - Label flipping completed in 0.00s
2024-12-27 20:27:11,538 - INFO - Training set processing completed in 0.00s
2024-12-27 20:27:11,538 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:27:11,539 - INFO - Memory usage at start_fit: CPU 3117.6 MB, GPU 47.5 MB
2024-12-27 20:27:11,539 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:27:11,540 - INFO - Number of unique classes: 10
2024-12-27 20:27:11,635 - INFO - Fitted scaler and transformed data
2024-12-27 20:27:11,635 - INFO - Scaling time: 0.09s
2024-12-27 20:27:11,814 - INFO - Epoch 1/25, Train Loss: 2.2279, Val Loss: 2.5378
2024-12-27 20:27:11,979 - INFO - Epoch 2/25, Train Loss: 0.8375, Val Loss: 2.1779
2024-12-27 20:27:12,148 - INFO - Epoch 3/25, Train Loss: 0.3968, Val Loss: 2.1570
2024-12-27 20:27:12,312 - INFO - Epoch 4/25, Train Loss: 0.1993, Val Loss: 2.0527
2024-12-27 20:27:12,500 - INFO - Epoch 5/25, Train Loss: 0.1208, Val Loss: 2.2913
2024-12-27 20:27:12,664 - INFO - Epoch 6/25, Train Loss: 0.0681, Val Loss: 2.0896
2024-12-27 20:27:12,664 - INFO - Early stopping triggered at epoch 6
2024-12-27 20:27:12,664 - INFO - Training completed in 1.13s
2024-12-27 20:27:12,664 - INFO - Final memory usage: CPU 3117.6 MB, GPU 48.1 MB
2024-12-27 20:27:12,664 - INFO - Model training completed in 1.13s
2024-12-27 20:27:12,672 - INFO - Prediction completed in 0.01s
2024-12-27 20:27:12,683 - INFO - Poison rate 0.05 completed in 1.15s
2024-12-27 20:27:12,683 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:27:12,690 - INFO - Total number of labels flipped: 350
2024-12-27 20:27:12,690 - INFO - Label flipping completed in 0.01s
2024-12-27 20:27:12,690 - INFO - Training set processing completed in 0.00s
2024-12-27 20:27:12,690 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:27:12,691 - INFO - Memory usage at start_fit: CPU 3117.6 MB, GPU 47.5 MB
2024-12-27 20:27:12,691 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:27:12,692 - INFO - Number of unique classes: 10
2024-12-27 20:27:12,793 - INFO - Fitted scaler and transformed data
2024-12-27 20:27:12,794 - INFO - Scaling time: 0.10s
2024-12-27 20:27:13,004 - INFO - Epoch 1/25, Train Loss: 2.7843, Val Loss: 3.4051
2024-12-27 20:27:13,184 - INFO - Epoch 2/25, Train Loss: 1.0569, Val Loss: 3.5155
2024-12-27 20:27:13,359 - INFO - Epoch 3/25, Train Loss: 0.4533, Val Loss: 3.0670
2024-12-27 20:27:13,551 - INFO - Epoch 4/25, Train Loss: 0.2770, Val Loss: 2.8076
2024-12-27 20:27:13,714 - INFO - Epoch 5/25, Train Loss: 0.2106, Val Loss: 2.8425
2024-12-27 20:27:13,886 - INFO - Epoch 6/25, Train Loss: 0.1234, Val Loss: 2.7652
2024-12-27 20:27:14,074 - INFO - Epoch 7/25, Train Loss: 0.1081, Val Loss: 2.6990
2024-12-27 20:27:14,265 - INFO - Epoch 8/25, Train Loss: 0.0867, Val Loss: 2.8609
2024-12-27 20:27:14,438 - INFO - Epoch 9/25, Train Loss: 0.0740, Val Loss: 2.8283
2024-12-27 20:27:14,438 - INFO - Early stopping triggered at epoch 9
2024-12-27 20:27:14,438 - INFO - Training completed in 1.75s
2024-12-27 20:27:14,438 - INFO - Final memory usage: CPU 3117.6 MB, GPU 48.1 MB
2024-12-27 20:27:14,439 - INFO - Model training completed in 1.75s
2024-12-27 20:27:14,445 - INFO - Prediction completed in 0.01s
2024-12-27 20:27:14,453 - INFO - Poison rate 0.07 completed in 1.77s
2024-12-27 20:27:14,453 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:27:14,459 - INFO - Total number of labels flipped: 500
2024-12-27 20:27:14,459 - INFO - Label flipping completed in 0.01s
2024-12-27 20:27:14,459 - INFO - Training set processing completed in 0.00s
2024-12-27 20:27:14,459 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:27:14,460 - INFO - Memory usage at start_fit: CPU 3117.6 MB, GPU 47.5 MB
2024-12-27 20:27:14,460 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:27:14,461 - INFO - Number of unique classes: 10
2024-12-27 20:27:14,545 - INFO - Fitted scaler and transformed data
2024-12-27 20:27:14,545 - INFO - Scaling time: 0.08s
2024-12-27 20:27:14,737 - INFO - Epoch 1/25, Train Loss: 3.7415, Val Loss: 4.0671
2024-12-27 20:27:14,915 - INFO - Epoch 2/25, Train Loss: 1.4678, Val Loss: 3.4015
2024-12-27 20:27:15,094 - INFO - Epoch 3/25, Train Loss: 0.6982, Val Loss: 3.4392
2024-12-27 20:27:15,266 - INFO - Epoch 4/25, Train Loss: 0.3950, Val Loss: 3.2612
2024-12-27 20:27:15,437 - INFO - Epoch 5/25, Train Loss: 0.2593, Val Loss: 3.2625
2024-12-27 20:27:15,613 - INFO - Epoch 6/25, Train Loss: 0.1766, Val Loss: 2.9317
2024-12-27 20:27:15,796 - INFO - Epoch 7/25, Train Loss: 0.1580, Val Loss: 3.0688
2024-12-27 20:27:16,003 - INFO - Epoch 8/25, Train Loss: 0.1255, Val Loss: 3.4263
2024-12-27 20:27:16,003 - INFO - Early stopping triggered at epoch 8
2024-12-27 20:27:16,003 - INFO - Training completed in 1.54s
2024-12-27 20:27:16,004 - INFO - Final memory usage: CPU 3117.6 MB, GPU 48.1 MB
2024-12-27 20:27:16,004 - INFO - Model training completed in 1.54s
2024-12-27 20:27:16,019 - INFO - Prediction completed in 0.01s
2024-12-27 20:27:16,033 - INFO - Poison rate 0.1 completed in 1.58s
2024-12-27 20:27:16,033 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:27:16,046 - INFO - Total number of labels flipped: 1000
2024-12-27 20:27:16,046 - INFO - Label flipping completed in 0.01s
2024-12-27 20:27:16,046 - INFO - Training set processing completed in 0.00s
2024-12-27 20:27:16,046 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:27:16,047 - INFO - Memory usage at start_fit: CPU 3117.6 MB, GPU 47.5 MB
2024-12-27 20:27:16,047 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:27:16,048 - INFO - Number of unique classes: 10
2024-12-27 20:27:16,167 - INFO - Fitted scaler and transformed data
2024-12-27 20:27:16,168 - INFO - Scaling time: 0.12s
2024-12-27 20:27:16,355 - INFO - Epoch 1/25, Train Loss: 6.4371, Val Loss: 4.8158
2024-12-27 20:27:16,531 - INFO - Epoch 2/25, Train Loss: 2.5228, Val Loss: 4.5701
2024-12-27 20:27:16,716 - INFO - Epoch 3/25, Train Loss: 1.4495, Val Loss: 4.3314
2024-12-27 20:27:16,901 - INFO - Epoch 4/25, Train Loss: 0.9172, Val Loss: 4.6577
2024-12-27 20:27:17,093 - INFO - Epoch 5/25, Train Loss: 0.7743, Val Loss: 4.5477
2024-12-27 20:27:17,093 - INFO - Early stopping triggered at epoch 5
2024-12-27 20:27:17,093 - INFO - Training completed in 1.05s
2024-12-27 20:27:17,093 - INFO - Final memory usage: CPU 3117.6 MB, GPU 48.1 MB
2024-12-27 20:27:17,093 - INFO - Model training completed in 1.05s
2024-12-27 20:27:17,108 - INFO - Prediction completed in 0.01s
2024-12-27 20:27:17,122 - INFO - Poison rate 0.2 completed in 1.09s
2024-12-27 20:27:17,123 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:27:17,123 - INFO - Total evaluation time: 21.47s
2024-12-27 20:27:17,125 - INFO - 
Progress: 68.8% - Evaluating ImageNette with SVM (dynadetect mode, iteration 1/1)
2024-12-27 20:27:17,185 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:27:17,256 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:27:17,342 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 20:27:17,343 - INFO - Dataset type: image
2024-12-27 20:27:17,343 - INFO - Sample size: 5000
2024-12-27 20:27:17,343 - INFO - Using device: cuda
2024-12-27 20:27:17,345 - INFO - Loading datasets...
2024-12-27 20:27:17,370 - INFO - Dataset loading completed in 0.02s
2024-12-27 20:27:17,370 - INFO - Extracting validation features...
2024-12-27 20:27:17,371 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:22,  1.36it/s]Extracting features:  12%|█▎        | 4/32 [00:00<00:04,  5.92it/s]Extracting features:  19%|█▉        | 6/32 [00:01<00:04,  6.46it/s]Extracting features:  31%|███▏      | 10/32 [00:01<00:01, 11.02it/s]Extracting features:  44%|████▍     | 14/32 [00:01<00:01, 12.40it/s]Extracting features:  53%|█████▎    | 17/32 [00:01<00:00, 15.02it/s]Extracting features:  62%|██████▎   | 20/32 [00:01<00:00, 14.63it/s]Extracting features:  69%|██████▉   | 22/32 [00:02<00:00, 11.02it/s]Extracting features:  81%|████████▏ | 26/32 [00:02<00:00, 12.69it/s]Extracting features:  94%|█████████▍| 30/32 [00:02<00:00, 15.12it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 11.75it/s]
2024-12-27 20:27:20,101 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:27:20,102 - INFO - Validation feature extraction completed in 2.73s
2024-12-27 20:27:20,102 - INFO - Extracting training features...
2024-12-27 20:27:20,102 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:24,  1.85it/s]Extracting features:   2%|▏         | 3/157 [00:00<00:29,  5.25it/s]Extracting features:   4%|▍         | 6/157 [00:00<00:14, 10.45it/s]Extracting features:   5%|▌         | 8/157 [00:01<00:15,  9.88it/s]Extracting features:   7%|▋         | 11/157 [00:01<00:16,  8.94it/s]Extracting features:   9%|▉         | 14/157 [00:01<00:12, 11.72it/s]Extracting features:  10%|█         | 16/157 [00:01<00:11, 11.96it/s]Extracting features:  11%|█▏        | 18/157 [00:01<00:11, 11.65it/s]Extracting features:  13%|█▎        | 21/157 [00:01<00:09, 14.69it/s]Extracting features:  15%|█▍        | 23/157 [00:02<00:11, 11.98it/s]Extracting features:  17%|█▋        | 27/157 [00:02<00:09, 14.09it/s]Extracting features:  19%|█▉        | 30/157 [00:02<00:07, 16.87it/s]Extracting features:  20%|██        | 32/157 [00:02<00:08, 13.92it/s]Extracting features:  22%|██▏       | 35/157 [00:02<00:08, 15.23it/s]Extracting features:  25%|██▍       | 39/157 [00:03<00:06, 16.94it/s]Extracting features:  27%|██▋       | 43/157 [00:03<00:06, 17.90it/s]Extracting features:  30%|██▉       | 47/157 [00:03<00:05, 18.60it/s]Extracting features:  32%|███▏      | 50/157 [00:03<00:05, 20.38it/s]Extracting features:  34%|███▍      | 53/157 [00:03<00:05, 18.48it/s]Extracting features:  35%|███▌      | 55/157 [00:03<00:06, 16.57it/s]Extracting features:  38%|███▊      | 59/157 [00:04<00:05, 16.99it/s]Extracting features:  40%|████      | 63/157 [00:04<00:05, 17.57it/s]Extracting features:  43%|████▎     | 67/157 [00:04<00:05, 15.51it/s]Extracting features:  45%|████▌     | 71/157 [00:05<00:05, 14.46it/s]Extracting features:  48%|████▊     | 75/157 [00:05<00:05, 14.01it/s]Extracting features:  50%|█████     | 79/157 [00:05<00:05, 14.12it/s]Extracting features:  53%|█████▎    | 83/157 [00:05<00:05, 13.50it/s]Extracting features:  55%|█████▌    | 87/157 [00:06<00:05, 13.48it/s]Extracting features:  58%|█████▊    | 91/157 [00:06<00:05, 11.47it/s]Extracting features:  61%|██████    | 95/157 [00:07<00:05, 11.89it/s]Extracting features:  63%|██████▎   | 99/157 [00:07<00:04, 13.19it/s]Extracting features:  66%|██████▌   | 103/157 [00:07<00:04, 12.95it/s]Extracting features:  68%|██████▊   | 107/157 [00:07<00:03, 12.94it/s]Extracting features:  71%|███████   | 111/157 [00:08<00:03, 12.82it/s]Extracting features:  73%|███████▎  | 115/157 [00:08<00:03, 12.83it/s]Extracting features:  76%|███████▌  | 119/157 [00:08<00:03, 12.17it/s]Extracting features:  78%|███████▊  | 123/157 [00:09<00:02, 13.08it/s]Extracting features:  81%|████████  | 127/157 [00:09<00:02, 14.29it/s]Extracting features:  83%|████████▎ | 131/157 [00:09<00:01, 15.87it/s]Extracting features:  86%|████████▌ | 135/157 [00:09<00:01, 16.67it/s]Extracting features:  89%|████████▊ | 139/157 [00:09<00:00, 18.66it/s]Extracting features:  90%|████████▉ | 141/157 [00:10<00:00, 18.34it/s]Extracting features:  91%|█████████ | 143/157 [00:10<00:00, 14.95it/s]Extracting features:  94%|█████████▎| 147/157 [00:10<00:00, 16.44it/s]Extracting features:  96%|█████████▌| 151/157 [00:10<00:00, 17.66it/s]Extracting features:  97%|█████████▋| 153/157 [00:10<00:00, 14.77it/s]Extracting features:  99%|█████████▉| 156/157 [00:11<00:00, 15.48it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 14.07it/s]
2024-12-27 20:27:31,270 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:27:31,270 - INFO - Training feature extraction completed in 11.17s
2024-12-27 20:27:31,270 - INFO - Creating model for classifier: SVM
2024-12-27 20:27:31,271 - INFO - Using device: cuda
2024-12-27 20:27:31,271 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-27 20:27:31,271 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:27:31,271 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:27:31,271 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:27:31,816 - INFO - Feature scaling completed in 0.54s
2024-12-27 20:27:31,816 - INFO - Starting feature selection (k=50)
2024-12-27 20:27:31,822 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:27:31,822 - INFO - Starting anomaly detection
2024-12-27 20:27:33,772 - INFO - Anomaly detection completed in 1.95s
2024-12-27 20:27:33,772 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:27:33,773 - INFO - Total fit_transform time: 2.50s
2024-12-27 20:27:33,773 - INFO - Training set processing completed in 2.50s
2024-12-27 20:27:33,773 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:27:33,774 - INFO - Memory usage at start_fit: CPU 3114.8 MB, GPU 47.3 MB
2024-12-27 20:27:33,775 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:27:33,775 - INFO - Number of unique classes: 10
2024-12-27 20:27:33,872 - INFO - Fitted scaler and transformed data
2024-12-27 20:27:33,872 - INFO - Scaling time: 0.09s
2024-12-27 20:27:34,080 - INFO - Epoch 1/25, Train Loss: 0.3449, Val Loss: 0.0832
2024-12-27 20:27:34,260 - INFO - Epoch 2/25, Train Loss: 0.0070, Val Loss: 0.0843
2024-12-27 20:27:34,495 - INFO - Epoch 3/25, Train Loss: 0.0004, Val Loss: 0.0808
2024-12-27 20:27:34,495 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:27:34,495 - INFO - Training completed in 0.72s
2024-12-27 20:27:34,496 - INFO - Final memory usage: CPU 3114.9 MB, GPU 48.1 MB
2024-12-27 20:27:34,496 - INFO - Model training completed in 0.72s
2024-12-27 20:27:34,509 - INFO - Prediction completed in 0.01s
2024-12-27 20:27:34,519 - INFO - Poison rate 0.0 completed in 3.25s
2024-12-27 20:27:34,520 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:27:34,521 - INFO - Total number of labels flipped: 50
2024-12-27 20:27:34,521 - INFO - Label flipping completed in 0.00s
2024-12-27 20:27:34,521 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:27:34,521 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:27:35,086 - INFO - Feature scaling completed in 0.57s
2024-12-27 20:27:35,086 - INFO - Starting feature selection (k=50)
2024-12-27 20:27:35,095 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:27:35,096 - INFO - Starting anomaly detection
2024-12-27 20:27:36,326 - INFO - Anomaly detection completed in 1.23s
2024-12-27 20:27:36,327 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:27:36,327 - INFO - Total fit_transform time: 1.81s
2024-12-27 20:27:36,327 - INFO - Training set processing completed in 1.81s
2024-12-27 20:27:36,327 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:27:36,328 - INFO - Memory usage at start_fit: CPU 3114.9 MB, GPU 47.5 MB
2024-12-27 20:27:36,329 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:27:36,329 - INFO - Number of unique classes: 10
2024-12-27 20:27:36,429 - INFO - Fitted scaler and transformed data
2024-12-27 20:27:36,429 - INFO - Scaling time: 0.10s
2024-12-27 20:27:36,628 - INFO - Epoch 1/25, Train Loss: 0.7595, Val Loss: 0.5620
2024-12-27 20:27:36,807 - INFO - Epoch 2/25, Train Loss: 0.1763, Val Loss: 0.5643
2024-12-27 20:27:36,974 - INFO - Epoch 3/25, Train Loss: 0.1057, Val Loss: 0.6368
2024-12-27 20:27:36,974 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:27:36,974 - INFO - Training completed in 0.65s
2024-12-27 20:27:36,975 - INFO - Final memory usage: CPU 3114.9 MB, GPU 48.1 MB
2024-12-27 20:27:36,975 - INFO - Model training completed in 0.65s
2024-12-27 20:27:36,983 - INFO - Prediction completed in 0.01s
2024-12-27 20:27:36,992 - INFO - Poison rate 0.01 completed in 2.47s
2024-12-27 20:27:36,993 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:27:36,995 - INFO - Total number of labels flipped: 150
2024-12-27 20:27:36,995 - INFO - Label flipping completed in 0.00s
2024-12-27 20:27:36,995 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:27:36,995 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:27:37,560 - INFO - Feature scaling completed in 0.56s
2024-12-27 20:27:37,560 - INFO - Starting feature selection (k=50)
2024-12-27 20:27:37,570 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:27:37,570 - INFO - Starting anomaly detection
2024-12-27 20:27:39,339 - INFO - Anomaly detection completed in 1.77s
2024-12-27 20:27:39,339 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:27:39,340 - INFO - Total fit_transform time: 2.34s
2024-12-27 20:27:39,340 - INFO - Training set processing completed in 2.34s
2024-12-27 20:27:39,340 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:27:39,342 - INFO - Memory usage at start_fit: CPU 3114.9 MB, GPU 47.5 MB
2024-12-27 20:27:39,342 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:27:39,343 - INFO - Number of unique classes: 10
2024-12-27 20:27:39,437 - INFO - Fitted scaler and transformed data
2024-12-27 20:27:39,438 - INFO - Scaling time: 0.09s
2024-12-27 20:27:39,680 - INFO - Epoch 1/25, Train Loss: 1.3979, Val Loss: 1.1615
2024-12-27 20:27:39,857 - INFO - Epoch 2/25, Train Loss: 0.5186, Val Loss: 1.2083
2024-12-27 20:27:40,028 - INFO - Epoch 3/25, Train Loss: 0.2472, Val Loss: 1.1612
2024-12-27 20:27:40,028 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:27:40,029 - INFO - Training completed in 0.69s
2024-12-27 20:27:40,029 - INFO - Final memory usage: CPU 3114.9 MB, GPU 48.1 MB
2024-12-27 20:27:40,029 - INFO - Model training completed in 0.69s
2024-12-27 20:27:40,036 - INFO - Prediction completed in 0.01s
2024-12-27 20:27:40,044 - INFO - Poison rate 0.03 completed in 3.05s
2024-12-27 20:27:40,044 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:27:40,047 - INFO - Total number of labels flipped: 250
2024-12-27 20:27:40,047 - INFO - Label flipping completed in 0.00s
2024-12-27 20:27:40,048 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:27:40,048 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:27:40,619 - INFO - Feature scaling completed in 0.57s
2024-12-27 20:27:40,620 - INFO - Starting feature selection (k=50)
2024-12-27 20:27:40,627 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:27:40,628 - INFO - Starting anomaly detection
2024-12-27 20:27:42,230 - INFO - Anomaly detection completed in 1.60s
2024-12-27 20:27:42,230 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:27:42,230 - INFO - Total fit_transform time: 2.18s
2024-12-27 20:27:42,230 - INFO - Training set processing completed in 2.18s
2024-12-27 20:27:42,230 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:27:42,231 - INFO - Memory usage at start_fit: CPU 3114.9 MB, GPU 47.5 MB
2024-12-27 20:27:42,231 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:27:42,232 - INFO - Number of unique classes: 10
2024-12-27 20:27:42,323 - INFO - Fitted scaler and transformed data
2024-12-27 20:27:42,324 - INFO - Scaling time: 0.09s
2024-12-27 20:27:42,516 - INFO - Epoch 1/25, Train Loss: 2.3662, Val Loss: 1.7415
2024-12-27 20:27:42,694 - INFO - Epoch 2/25, Train Loss: 0.8272, Val Loss: 1.7096
2024-12-27 20:27:42,859 - INFO - Epoch 3/25, Train Loss: 0.3777, Val Loss: 1.5116
2024-12-27 20:27:43,031 - INFO - Epoch 4/25, Train Loss: 0.2035, Val Loss: 1.5248
2024-12-27 20:27:43,197 - INFO - Epoch 5/25, Train Loss: 0.1306, Val Loss: 1.4807
2024-12-27 20:27:43,387 - INFO - Epoch 6/25, Train Loss: 0.0844, Val Loss: 1.4858
2024-12-27 20:27:43,563 - INFO - Epoch 7/25, Train Loss: 0.0649, Val Loss: 1.4884
2024-12-27 20:27:43,563 - INFO - Early stopping triggered at epoch 7
2024-12-27 20:27:43,563 - INFO - Training completed in 1.33s
2024-12-27 20:27:43,563 - INFO - Final memory usage: CPU 3114.9 MB, GPU 48.1 MB
2024-12-27 20:27:43,564 - INFO - Model training completed in 1.33s
2024-12-27 20:27:43,572 - INFO - Prediction completed in 0.01s
2024-12-27 20:27:43,588 - INFO - Poison rate 0.05 completed in 3.54s
2024-12-27 20:27:43,588 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:27:43,595 - INFO - Total number of labels flipped: 350
2024-12-27 20:27:43,595 - INFO - Label flipping completed in 0.01s
2024-12-27 20:27:43,595 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:27:43,595 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:27:44,218 - INFO - Feature scaling completed in 0.62s
2024-12-27 20:27:44,218 - INFO - Starting feature selection (k=50)
2024-12-27 20:27:44,230 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:27:44,231 - INFO - Starting anomaly detection
2024-12-27 20:27:45,507 - INFO - Anomaly detection completed in 1.28s
2024-12-27 20:27:45,507 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:27:45,507 - INFO - Total fit_transform time: 1.91s
2024-12-27 20:27:45,507 - INFO - Training set processing completed in 1.91s
2024-12-27 20:27:45,507 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:27:45,508 - INFO - Memory usage at start_fit: CPU 3114.9 MB, GPU 47.5 MB
2024-12-27 20:27:45,509 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:27:45,509 - INFO - Number of unique classes: 10
2024-12-27 20:27:45,601 - INFO - Fitted scaler and transformed data
2024-12-27 20:27:45,602 - INFO - Scaling time: 0.09s
2024-12-27 20:27:45,781 - INFO - Epoch 1/25, Train Loss: 2.7347, Val Loss: 3.7168
2024-12-27 20:27:45,938 - INFO - Epoch 2/25, Train Loss: 1.0028, Val Loss: 3.2828
2024-12-27 20:27:46,099 - INFO - Epoch 3/25, Train Loss: 0.4258, Val Loss: 3.1186
2024-12-27 20:27:46,263 - INFO - Epoch 4/25, Train Loss: 0.2271, Val Loss: 3.0580
2024-12-27 20:27:46,420 - INFO - Epoch 5/25, Train Loss: 0.1473, Val Loss: 2.9600
2024-12-27 20:27:46,576 - INFO - Epoch 6/25, Train Loss: 0.1312, Val Loss: 2.9289
2024-12-27 20:27:46,746 - INFO - Epoch 7/25, Train Loss: 0.1385, Val Loss: 3.0922
2024-12-27 20:27:46,930 - INFO - Epoch 8/25, Train Loss: 0.0923, Val Loss: 3.1049
2024-12-27 20:27:46,931 - INFO - Early stopping triggered at epoch 8
2024-12-27 20:27:46,931 - INFO - Training completed in 1.42s
2024-12-27 20:27:46,931 - INFO - Final memory usage: CPU 3114.9 MB, GPU 48.1 MB
2024-12-27 20:27:46,931 - INFO - Model training completed in 1.42s
2024-12-27 20:27:46,939 - INFO - Prediction completed in 0.01s
2024-12-27 20:27:46,954 - INFO - Poison rate 0.07 completed in 3.37s
2024-12-27 20:27:46,955 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:27:46,963 - INFO - Total number of labels flipped: 500
2024-12-27 20:27:46,963 - INFO - Label flipping completed in 0.01s
2024-12-27 20:27:46,963 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:27:46,963 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:27:47,544 - INFO - Feature scaling completed in 0.58s
2024-12-27 20:27:47,544 - INFO - Starting feature selection (k=50)
2024-12-27 20:27:47,554 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:27:47,554 - INFO - Starting anomaly detection
2024-12-27 20:27:49,256 - INFO - Anomaly detection completed in 1.70s
2024-12-27 20:27:49,256 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:27:49,257 - INFO - Total fit_transform time: 2.29s
2024-12-27 20:27:49,257 - INFO - Training set processing completed in 2.29s
2024-12-27 20:27:49,257 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:27:49,257 - INFO - Memory usage at start_fit: CPU 3114.9 MB, GPU 47.5 MB
2024-12-27 20:27:49,258 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:27:49,258 - INFO - Number of unique classes: 10
2024-12-27 20:27:49,349 - INFO - Fitted scaler and transformed data
2024-12-27 20:27:49,349 - INFO - Scaling time: 0.09s
2024-12-27 20:27:49,536 - INFO - Epoch 1/25, Train Loss: 3.5132, Val Loss: 3.5293
2024-12-27 20:27:49,708 - INFO - Epoch 2/25, Train Loss: 1.3386, Val Loss: 2.9740
2024-12-27 20:27:49,876 - INFO - Epoch 3/25, Train Loss: 0.6438, Val Loss: 2.8723
2024-12-27 20:27:50,045 - INFO - Epoch 4/25, Train Loss: 0.3967, Val Loss: 2.7870
2024-12-27 20:27:50,215 - INFO - Epoch 5/25, Train Loss: 0.2851, Val Loss: 2.7547
2024-12-27 20:27:50,388 - INFO - Epoch 6/25, Train Loss: 0.2928, Val Loss: 2.8677
2024-12-27 20:27:50,554 - INFO - Epoch 7/25, Train Loss: 0.2650, Val Loss: 2.9596
2024-12-27 20:27:50,555 - INFO - Early stopping triggered at epoch 7
2024-12-27 20:27:50,555 - INFO - Training completed in 1.30s
2024-12-27 20:27:50,555 - INFO - Final memory usage: CPU 3114.9 MB, GPU 48.1 MB
2024-12-27 20:27:50,555 - INFO - Model training completed in 1.30s
2024-12-27 20:27:50,570 - INFO - Prediction completed in 0.01s
2024-12-27 20:27:50,586 - INFO - Poison rate 0.1 completed in 3.63s
2024-12-27 20:27:50,587 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:27:50,601 - INFO - Total number of labels flipped: 1000
2024-12-27 20:27:50,601 - INFO - Label flipping completed in 0.01s
2024-12-27 20:27:50,601 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:27:50,601 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:27:51,168 - INFO - Feature scaling completed in 0.57s
2024-12-27 20:27:51,168 - INFO - Starting feature selection (k=50)
2024-12-27 20:27:51,184 - INFO - Feature selection completed in 0.02s. Output shape: (5000, 50)
2024-12-27 20:27:51,185 - INFO - Starting anomaly detection
2024-12-27 20:27:52,628 - INFO - Anomaly detection completed in 1.44s
2024-12-27 20:27:52,631 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:27:52,631 - INFO - Total fit_transform time: 2.03s
2024-12-27 20:27:52,631 - INFO - Training set processing completed in 2.03s
2024-12-27 20:27:52,631 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:27:52,632 - INFO - Memory usage at start_fit: CPU 3114.9 MB, GPU 47.5 MB
2024-12-27 20:27:52,633 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:27:52,633 - INFO - Number of unique classes: 10
2024-12-27 20:27:52,726 - INFO - Fitted scaler and transformed data
2024-12-27 20:27:52,726 - INFO - Scaling time: 0.09s
2024-12-27 20:27:52,900 - INFO - Epoch 1/25, Train Loss: 5.8745, Val Loss: 6.3248
2024-12-27 20:27:53,074 - INFO - Epoch 2/25, Train Loss: 2.2530, Val Loss: 6.0473
2024-12-27 20:27:53,265 - INFO - Epoch 3/25, Train Loss: 1.3177, Val Loss: 5.8445
2024-12-27 20:27:53,445 - INFO - Epoch 4/25, Train Loss: 0.9787, Val Loss: 5.9832
2024-12-27 20:27:53,621 - INFO - Epoch 5/25, Train Loss: 0.7576, Val Loss: 6.0848
2024-12-27 20:27:53,622 - INFO - Early stopping triggered at epoch 5
2024-12-27 20:27:53,622 - INFO - Training completed in 0.99s
2024-12-27 20:27:53,622 - INFO - Final memory usage: CPU 3114.9 MB, GPU 48.1 MB
2024-12-27 20:27:53,622 - INFO - Model training completed in 0.99s
2024-12-27 20:27:53,632 - INFO - Prediction completed in 0.01s
2024-12-27 20:27:53,644 - INFO - Poison rate 0.2 completed in 3.06s
2024-12-27 20:27:53,645 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:27:53,645 - INFO - Total evaluation time: 36.30s
2024-12-27 20:27:53,647 - INFO - 
Progress: 69.8% - Evaluating ImageNette with LogisticRegression (standard mode, iteration 1/1)
2024-12-27 20:27:53,708 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:27:53,784 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:27:54,028 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 20:27:54,028 - INFO - Dataset type: image
2024-12-27 20:27:54,028 - INFO - Sample size: 5000
2024-12-27 20:27:54,028 - INFO - Using device: cuda
2024-12-27 20:27:54,030 - INFO - Loading datasets...
2024-12-27 20:27:54,054 - INFO - Dataset loading completed in 0.02s
2024-12-27 20:27:54,054 - INFO - Extracting validation features...
2024-12-27 20:27:54,054 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:21,  1.41it/s]Extracting features:   6%|▋         | 2/32 [00:00<00:10,  2.74it/s]Extracting features:  19%|█▉        | 6/32 [00:00<00:02,  9.34it/s]Extracting features:  31%|███▏      | 10/32 [00:01<00:01, 15.15it/s]Extracting features:  41%|████      | 13/32 [00:01<00:01, 14.45it/s]Extracting features:  50%|█████     | 16/32 [00:01<00:01, 12.87it/s]Extracting features:  56%|█████▋    | 18/32 [00:01<00:01, 13.98it/s]Extracting features:  62%|██████▎   | 20/32 [00:01<00:01, 11.58it/s]Extracting features:  72%|███████▏  | 23/32 [00:02<00:00, 11.60it/s]Extracting features:  84%|████████▍ | 27/32 [00:02<00:00, 13.48it/s]Extracting features:  91%|█████████ | 29/32 [00:02<00:00, 12.71it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 11.72it/s]
2024-12-27 20:27:56,791 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:27:56,792 - INFO - Validation feature extraction completed in 2.74s
2024-12-27 20:27:56,792 - INFO - Extracting training features...
2024-12-27 20:27:56,792 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:08,  2.28it/s]Extracting features:   3%|▎         | 5/157 [00:00<00:18,  8.27it/s]Extracting features:   4%|▍         | 7/157 [00:00<00:17,  8.70it/s]Extracting features:   7%|▋         | 11/157 [00:01<00:12, 11.35it/s]Extracting features:  10%|▉         | 15/157 [00:01<00:11, 12.66it/s]Extracting features:  11%|█         | 17/157 [00:01<00:10, 12.88it/s]Extracting features:  12%|█▏        | 19/157 [00:01<00:10, 13.42it/s]Extracting features:  13%|█▎        | 21/157 [00:01<00:10, 13.19it/s]Extracting features:  15%|█▍        | 23/157 [00:01<00:09, 14.46it/s]Extracting features:  16%|█▌        | 25/157 [00:02<00:08, 14.94it/s]Extracting features:  17%|█▋        | 27/157 [00:02<00:09, 13.69it/s]Extracting features:  18%|█▊        | 29/157 [00:02<00:08, 14.69it/s]Extracting features:  20%|█▉        | 31/157 [00:02<00:08, 14.78it/s]Extracting features:  21%|██        | 33/157 [00:02<00:09, 13.46it/s]Extracting features:  23%|██▎       | 36/157 [00:02<00:08, 14.91it/s]Extracting features:  25%|██▌       | 40/157 [00:03<00:06, 17.25it/s]Extracting features:  28%|██▊       | 44/157 [00:03<00:06, 16.73it/s]Extracting features:  31%|███       | 48/157 [00:03<00:06, 17.34it/s]Extracting features:  33%|███▎      | 52/157 [00:03<00:06, 16.91it/s]Extracting features:  36%|███▌      | 56/157 [00:04<00:06, 15.69it/s]Extracting features:  38%|███▊      | 60/157 [00:04<00:06, 15.29it/s]Extracting features:  41%|████      | 64/157 [00:04<00:06, 15.30it/s]Extracting features:  43%|████▎     | 68/157 [00:04<00:06, 14.56it/s]Extracting features:  46%|████▌     | 72/157 [00:05<00:05, 15.00it/s]Extracting features:  48%|████▊     | 75/157 [00:05<00:04, 16.96it/s]Extracting features:  49%|████▉     | 77/157 [00:05<00:05, 14.78it/s]Extracting features:  50%|█████     | 79/157 [00:05<00:05, 15.54it/s]Extracting features:  52%|█████▏    | 81/157 [00:05<00:05, 14.82it/s]Extracting features:  53%|█████▎    | 83/157 [00:05<00:05, 13.68it/s]Extracting features:  55%|█████▍    | 86/157 [00:05<00:04, 16.80it/s]Extracting features:  56%|█████▌    | 88/157 [00:06<00:04, 14.32it/s]Extracting features:  58%|█████▊    | 91/157 [00:06<00:04, 13.90it/s]Extracting features:  59%|█████▉    | 93/157 [00:06<00:04, 14.30it/s]Extracting features:  61%|██████    | 95/157 [00:06<00:04, 14.00it/s]Extracting features:  62%|██████▏   | 97/157 [00:06<00:04, 12.85it/s]Extracting features:  64%|██████▎   | 100/157 [00:07<00:04, 12.46it/s]Extracting features:  66%|██████▌   | 103/157 [00:07<00:03, 13.62it/s]Extracting features:  67%|██████▋   | 105/157 [00:07<00:03, 13.32it/s]Extracting features:  69%|██████▉   | 108/157 [00:07<00:04, 12.01it/s]Extracting features:  71%|███████   | 111/157 [00:07<00:03, 13.16it/s]Extracting features:  72%|███████▏  | 113/157 [00:08<00:04, 10.96it/s]Extracting features:  74%|███████▍  | 116/157 [00:08<00:03, 11.08it/s]Extracting features:  76%|███████▋  | 120/157 [00:08<00:03, 11.53it/s]Extracting features:  78%|███████▊  | 122/157 [00:09<00:03, 11.31it/s]Extracting features:  79%|███████▉  | 124/157 [00:09<00:02, 12.35it/s]Extracting features:  80%|████████  | 126/157 [00:09<00:02, 12.12it/s]Extracting features:  82%|████████▏ | 129/157 [00:09<00:01, 15.29it/s]Extracting features:  83%|████████▎ | 131/157 [00:09<00:01, 15.15it/s]Extracting features:  85%|████████▍ | 133/157 [00:09<00:01, 13.99it/s]Extracting features:  87%|████████▋ | 136/157 [00:09<00:01, 14.75it/s]Extracting features:  89%|████████▉ | 140/157 [00:10<00:01, 16.25it/s]Extracting features:  92%|█████████▏| 144/157 [00:10<00:00, 16.22it/s]Extracting features:  94%|█████████▍| 148/157 [00:10<00:00, 16.78it/s]Extracting features:  97%|█████████▋| 152/157 [00:10<00:00, 17.73it/s]Extracting features:  98%|█████████▊| 154/157 [00:10<00:00, 16.54it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 18.80it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 14.12it/s]
2024-12-27 20:28:07,918 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:28:07,918 - INFO - Training feature extraction completed in 11.13s
2024-12-27 20:28:07,919 - INFO - Creating model for classifier: LogisticRegression
2024-12-27 20:28:07,919 - INFO - Using device: cuda
2024-12-27 20:28:07,919 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:28:07,919 - INFO - Training set processing completed in 0.00s
2024-12-27 20:28:07,919 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:28:07,920 - INFO - Memory usage at start_fit: CPU 3112.3 MB, GPU 47.3 MB
2024-12-27 20:28:07,920 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:28:07,921 - INFO - Number of unique classes: 10
2024-12-27 20:28:08,006 - INFO - Fitted scaler and transformed data
2024-12-27 20:28:08,006 - INFO - Scaling time: 0.08s
2024-12-27 20:28:08,147 - INFO - Epoch 1/200, Train Loss: 0.1212, Val Loss: 0.0404
2024-12-27 20:28:08,274 - INFO - Epoch 2/200, Train Loss: 0.0074, Val Loss: 0.0495
2024-12-27 20:28:08,428 - INFO - Epoch 3/200, Train Loss: 0.0019, Val Loss: 0.0276
2024-12-27 20:28:08,551 - INFO - Epoch 4/200, Train Loss: 0.0007, Val Loss: 0.0307
2024-12-27 20:28:08,672 - INFO - Epoch 5/200, Train Loss: 0.0000, Val Loss: 0.0220
2024-12-27 20:28:08,672 - INFO - Early stopping triggered at epoch 5
2024-12-27 20:28:08,672 - INFO - Training completed in 0.75s
2024-12-27 20:28:08,672 - INFO - Final memory usage: CPU 3116.2 MB, GPU 48.1 MB
2024-12-27 20:28:08,673 - INFO - Model training completed in 0.75s
2024-12-27 20:28:08,680 - INFO - Prediction completed in 0.01s
2024-12-27 20:28:08,702 - INFO - Poison rate 0.0 completed in 0.78s
2024-12-27 20:28:08,702 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:28:08,705 - INFO - Total number of labels flipped: 50
2024-12-27 20:28:08,706 - INFO - Label flipping completed in 0.00s
2024-12-27 20:28:08,706 - INFO - Training set processing completed in 0.00s
2024-12-27 20:28:08,706 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:28:08,707 - INFO - Memory usage at start_fit: CPU 3116.2 MB, GPU 47.5 MB
2024-12-27 20:28:08,708 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:28:08,708 - INFO - Number of unique classes: 10
2024-12-27 20:28:08,793 - INFO - Fitted scaler and transformed data
2024-12-27 20:28:08,794 - INFO - Scaling time: 0.08s
2024-12-27 20:28:08,922 - INFO - Epoch 1/200, Train Loss: 0.2817, Val Loss: 0.4075
2024-12-27 20:28:09,040 - INFO - Epoch 2/200, Train Loss: 0.0901, Val Loss: 0.3633
2024-12-27 20:28:09,172 - INFO - Epoch 3/200, Train Loss: 0.0323, Val Loss: 0.3466
2024-12-27 20:28:09,294 - INFO - Epoch 4/200, Train Loss: 0.0116, Val Loss: 0.3687
2024-12-27 20:28:09,418 - INFO - Epoch 5/200, Train Loss: 0.0030, Val Loss: 0.3571
2024-12-27 20:28:09,419 - INFO - Early stopping triggered at epoch 5
2024-12-27 20:28:09,419 - INFO - Training completed in 0.71s
2024-12-27 20:28:09,419 - INFO - Final memory usage: CPU 3116.2 MB, GPU 48.1 MB
2024-12-27 20:28:09,419 - INFO - Model training completed in 0.71s
2024-12-27 20:28:09,426 - INFO - Prediction completed in 0.01s
2024-12-27 20:28:09,434 - INFO - Poison rate 0.01 completed in 0.73s
2024-12-27 20:28:09,434 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:28:09,436 - INFO - Total number of labels flipped: 150
2024-12-27 20:28:09,436 - INFO - Label flipping completed in 0.00s
2024-12-27 20:28:09,436 - INFO - Training set processing completed in 0.00s
2024-12-27 20:28:09,436 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:28:09,437 - INFO - Memory usage at start_fit: CPU 3116.2 MB, GPU 47.5 MB
2024-12-27 20:28:09,437 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:28:09,438 - INFO - Number of unique classes: 10
2024-12-27 20:28:09,521 - INFO - Fitted scaler and transformed data
2024-12-27 20:28:09,521 - INFO - Scaling time: 0.08s
2024-12-27 20:28:09,720 - INFO - Epoch 1/200, Train Loss: 0.6510, Val Loss: 0.2996
2024-12-27 20:28:09,919 - INFO - Epoch 2/200, Train Loss: 0.2062, Val Loss: 0.2952
2024-12-27 20:28:10,088 - INFO - Epoch 3/200, Train Loss: 0.1210, Val Loss: 0.3719
2024-12-27 20:28:10,088 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:28:10,089 - INFO - Training completed in 0.65s
2024-12-27 20:28:10,089 - INFO - Final memory usage: CPU 3116.2 MB, GPU 48.1 MB
2024-12-27 20:28:10,090 - INFO - Model training completed in 0.65s
2024-12-27 20:28:10,104 - INFO - Prediction completed in 0.01s
2024-12-27 20:28:10,118 - INFO - Poison rate 0.03 completed in 0.68s
2024-12-27 20:28:10,118 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:28:10,123 - INFO - Total number of labels flipped: 250
2024-12-27 20:28:10,123 - INFO - Label flipping completed in 0.00s
2024-12-27 20:28:10,123 - INFO - Training set processing completed in 0.00s
2024-12-27 20:28:10,123 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:28:10,124 - INFO - Memory usage at start_fit: CPU 3116.2 MB, GPU 47.5 MB
2024-12-27 20:28:10,124 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:28:10,125 - INFO - Number of unique classes: 10
2024-12-27 20:28:10,214 - INFO - Fitted scaler and transformed data
2024-12-27 20:28:10,214 - INFO - Scaling time: 0.09s
2024-12-27 20:28:10,346 - INFO - Epoch 1/200, Train Loss: 0.8095, Val Loss: 0.6942
2024-12-27 20:28:10,491 - INFO - Epoch 2/200, Train Loss: 0.3011, Val Loss: 0.6957
2024-12-27 20:28:10,668 - INFO - Epoch 3/200, Train Loss: 0.1653, Val Loss: 0.7425
2024-12-27 20:28:10,669 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:28:10,669 - INFO - Training completed in 0.54s
2024-12-27 20:28:10,669 - INFO - Final memory usage: CPU 3116.2 MB, GPU 48.1 MB
2024-12-27 20:28:10,669 - INFO - Model training completed in 0.55s
2024-12-27 20:28:10,683 - INFO - Prediction completed in 0.01s
2024-12-27 20:28:10,700 - INFO - Poison rate 0.05 completed in 0.58s
2024-12-27 20:28:10,701 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:28:10,707 - INFO - Total number of labels flipped: 350
2024-12-27 20:28:10,707 - INFO - Label flipping completed in 0.01s
2024-12-27 20:28:10,707 - INFO - Training set processing completed in 0.00s
2024-12-27 20:28:10,707 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:28:10,708 - INFO - Memory usage at start_fit: CPU 3116.2 MB, GPU 47.5 MB
2024-12-27 20:28:10,709 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:28:10,709 - INFO - Number of unique classes: 10
2024-12-27 20:28:10,812 - INFO - Fitted scaler and transformed data
2024-12-27 20:28:10,813 - INFO - Scaling time: 0.10s
2024-12-27 20:28:10,954 - INFO - Epoch 1/200, Train Loss: 0.9990, Val Loss: 0.8859
2024-12-27 20:28:11,067 - INFO - Epoch 2/200, Train Loss: 0.4624, Val Loss: 0.8466
2024-12-27 20:28:11,213 - INFO - Epoch 3/200, Train Loss: 0.2920, Val Loss: 0.9117
2024-12-27 20:28:11,326 - INFO - Epoch 4/200, Train Loss: 0.1748, Val Loss: 1.0004
2024-12-27 20:28:11,326 - INFO - Early stopping triggered at epoch 4
2024-12-27 20:28:11,326 - INFO - Training completed in 0.62s
2024-12-27 20:28:11,326 - INFO - Final memory usage: CPU 3116.2 MB, GPU 48.1 MB
2024-12-27 20:28:11,327 - INFO - Model training completed in 0.62s
2024-12-27 20:28:11,340 - INFO - Prediction completed in 0.01s
2024-12-27 20:28:11,361 - INFO - Poison rate 0.07 completed in 0.66s
2024-12-27 20:28:11,361 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:28:11,376 - INFO - Total number of labels flipped: 500
2024-12-27 20:28:11,377 - INFO - Label flipping completed in 0.02s
2024-12-27 20:28:11,377 - INFO - Training set processing completed in 0.00s
2024-12-27 20:28:11,377 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:28:11,378 - INFO - Memory usage at start_fit: CPU 3116.2 MB, GPU 47.5 MB
2024-12-27 20:28:11,379 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:28:11,379 - INFO - Number of unique classes: 10
2024-12-27 20:28:11,471 - INFO - Fitted scaler and transformed data
2024-12-27 20:28:11,471 - INFO - Scaling time: 0.09s
2024-12-27 20:28:11,614 - INFO - Epoch 1/200, Train Loss: 1.1904, Val Loss: 1.1349
2024-12-27 20:28:11,750 - INFO - Epoch 2/200, Train Loss: 0.5719, Val Loss: 1.1283
2024-12-27 20:28:11,898 - INFO - Epoch 3/200, Train Loss: 0.3428, Val Loss: 1.2413
2024-12-27 20:28:11,898 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:28:11,898 - INFO - Training completed in 0.52s
2024-12-27 20:28:11,899 - INFO - Final memory usage: CPU 3116.2 MB, GPU 48.1 MB
2024-12-27 20:28:11,899 - INFO - Model training completed in 0.52s
2024-12-27 20:28:11,909 - INFO - Prediction completed in 0.01s
2024-12-27 20:28:11,917 - INFO - Poison rate 0.1 completed in 0.56s
2024-12-27 20:28:11,917 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:28:11,929 - INFO - Total number of labels flipped: 1000
2024-12-27 20:28:11,929 - INFO - Label flipping completed in 0.01s
2024-12-27 20:28:11,930 - INFO - Training set processing completed in 0.00s
2024-12-27 20:28:11,930 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:28:11,931 - INFO - Memory usage at start_fit: CPU 3116.2 MB, GPU 47.5 MB
2024-12-27 20:28:11,931 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:28:11,932 - INFO - Number of unique classes: 10
2024-12-27 20:28:12,029 - INFO - Fitted scaler and transformed data
2024-12-27 20:28:12,029 - INFO - Scaling time: 0.10s
2024-12-27 20:28:12,182 - INFO - Epoch 1/200, Train Loss: 1.7192, Val Loss: 1.3492
2024-12-27 20:28:12,307 - INFO - Epoch 2/200, Train Loss: 0.9520, Val Loss: 1.4565
2024-12-27 20:28:12,449 - INFO - Epoch 3/200, Train Loss: 0.7859, Val Loss: 1.7338
2024-12-27 20:28:12,450 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:28:12,450 - INFO - Training completed in 0.52s
2024-12-27 20:28:12,452 - INFO - Final memory usage: CPU 3116.2 MB, GPU 48.1 MB
2024-12-27 20:28:12,453 - INFO - Model training completed in 0.52s
2024-12-27 20:28:12,470 - INFO - Prediction completed in 0.02s
2024-12-27 20:28:12,482 - INFO - Poison rate 0.2 completed in 0.56s
2024-12-27 20:28:12,483 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:28:12,483 - INFO - Total evaluation time: 18.45s
2024-12-27 20:28:12,485 - INFO - 
Progress: 70.8% - Evaluating ImageNette with LogisticRegression (dynadetect mode, iteration 1/1)
2024-12-27 20:28:12,548 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:28:12,622 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:28:12,717 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 20:28:12,718 - INFO - Dataset type: image
2024-12-27 20:28:12,718 - INFO - Sample size: 5000
2024-12-27 20:28:12,718 - INFO - Using device: cuda
2024-12-27 20:28:12,720 - INFO - Loading datasets...
2024-12-27 20:28:12,748 - INFO - Dataset loading completed in 0.03s
2024-12-27 20:28:12,748 - INFO - Extracting validation features...
2024-12-27 20:28:12,748 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:21,  1.45it/s]Extracting features:  16%|█▌        | 5/32 [00:00<00:03,  7.68it/s]Extracting features:  28%|██▊       | 9/32 [00:01<00:02, 10.77it/s]Extracting features:  41%|████      | 13/32 [00:01<00:01, 13.09it/s]Extracting features:  50%|█████     | 16/32 [00:01<00:01, 14.97it/s]Extracting features:  56%|█████▋    | 18/32 [00:01<00:01, 12.91it/s]Extracting features:  62%|██████▎   | 20/32 [00:01<00:00, 13.87it/s]Extracting features:  69%|██████▉   | 22/32 [00:01<00:00, 13.28it/s]Extracting features:  75%|███████▌  | 24/32 [00:02<00:00, 12.69it/s]Extracting features:  84%|████████▍ | 27/32 [00:02<00:00, 15.83it/s]Extracting features:  91%|█████████ | 29/32 [00:02<00:00, 15.22it/s]Extracting features:  97%|█████████▋| 31/32 [00:02<00:00, 15.87it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 12.29it/s]
2024-12-27 20:28:15,357 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:28:15,358 - INFO - Validation feature extraction completed in 2.61s
2024-12-27 20:28:15,358 - INFO - Extracting training features...
2024-12-27 20:28:15,359 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:36,  1.62it/s]Extracting features:   3%|▎         | 5/157 [00:00<00:22,  6.73it/s]Extracting features:   4%|▍         | 7/157 [00:01<00:22,  6.55it/s]Extracting features:   7%|▋         | 11/157 [00:01<00:14,  9.87it/s]Extracting features:  10%|▉         | 15/157 [00:01<00:11, 12.08it/s]Extracting features:  12%|█▏        | 19/157 [00:01<00:10, 13.71it/s]Extracting features:  15%|█▍        | 23/157 [00:02<00:09, 14.65it/s]Extracting features:  16%|█▌        | 25/157 [00:02<00:09, 14.55it/s]Extracting features:  17%|█▋        | 27/157 [00:02<00:08, 15.03it/s]Extracting features:  19%|█▉        | 30/157 [00:02<00:07, 17.61it/s]Extracting features:  20%|██        | 32/157 [00:02<00:08, 14.02it/s]Extracting features:  22%|██▏       | 35/157 [00:02<00:08, 14.81it/s]Extracting features:  25%|██▍       | 39/157 [00:03<00:06, 17.08it/s]Extracting features:  27%|██▋       | 43/157 [00:03<00:06, 17.80it/s]Extracting features:  30%|██▉       | 47/157 [00:03<00:06, 17.78it/s]Extracting features:  32%|███▏      | 51/157 [00:03<00:05, 18.25it/s]Extracting features:  35%|███▌      | 55/157 [00:03<00:05, 17.74it/s]Extracting features:  36%|███▋      | 57/157 [00:04<00:06, 15.63it/s]Extracting features:  39%|███▉      | 61/157 [00:04<00:05, 17.24it/s]Extracting features:  40%|████      | 63/157 [00:04<00:05, 17.66it/s]Extracting features:  41%|████▏     | 65/157 [00:04<00:06, 15.05it/s]Extracting features:  43%|████▎     | 68/157 [00:04<00:05, 16.89it/s]Extracting features:  45%|████▍     | 70/157 [00:04<00:06, 14.50it/s]Extracting features:  46%|████▋     | 73/157 [00:05<00:05, 14.03it/s]Extracting features:  48%|████▊     | 75/157 [00:05<00:05, 14.89it/s]Extracting features:  49%|████▉     | 77/157 [00:05<00:05, 13.85it/s]Extracting features:  50%|█████     | 79/157 [00:05<00:05, 15.09it/s]Extracting features:  52%|█████▏    | 81/157 [00:05<00:05, 14.77it/s]Extracting features:  54%|█████▎    | 84/157 [00:05<00:04, 15.71it/s]Extracting features:  55%|█████▍    | 86/157 [00:06<00:04, 15.15it/s]Extracting features:  56%|█████▌    | 88/157 [00:06<00:05, 13.72it/s]Extracting features:  58%|█████▊    | 91/157 [00:06<00:06,  9.64it/s]Extracting features:  61%|██████    | 95/157 [00:06<00:05, 11.34it/s]Extracting features:  63%|██████▎   | 99/157 [00:07<00:04, 11.90it/s]Extracting features:  66%|██████▌   | 103/157 [00:07<00:05, 10.33it/s]Extracting features:  68%|██████▊   | 107/157 [00:08<00:04, 10.42it/s]Extracting features:  71%|███████   | 111/157 [00:08<00:04, 11.18it/s]Extracting features:  72%|███████▏  | 113/157 [00:08<00:03, 11.28it/s]Extracting features:  74%|███████▍  | 116/157 [00:08<00:03, 11.01it/s]Extracting features:  76%|███████▋  | 120/157 [00:09<00:03, 11.16it/s]Extracting features:  79%|███████▉  | 124/157 [00:09<00:02, 11.80it/s]Extracting features:  82%|████████▏ | 128/157 [00:09<00:02, 12.52it/s]Extracting features:  84%|████████▍ | 132/157 [00:10<00:01, 14.33it/s]Extracting features:  87%|████████▋ | 136/157 [00:10<00:01, 15.05it/s]Extracting features:  89%|████████▉ | 140/157 [00:10<00:01, 15.10it/s]Extracting features:  92%|█████████▏| 144/157 [00:10<00:00, 16.27it/s]Extracting features:  93%|█████████▎| 146/157 [00:10<00:00, 15.31it/s]Extracting features:  96%|█████████▌| 150/157 [00:11<00:00, 16.25it/s]Extracting features:  97%|█████████▋| 153/157 [00:11<00:00, 18.21it/s]Extracting features:  99%|█████████▊| 155/157 [00:11<00:00, 16.72it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 13.68it/s]
2024-12-27 20:28:26,847 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:28:26,847 - INFO - Training feature extraction completed in 11.49s
2024-12-27 20:28:26,847 - INFO - Creating model for classifier: LogisticRegression
2024-12-27 20:28:26,848 - INFO - Using device: cuda
2024-12-27 20:28:26,848 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:28:26,848 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:28:26,848 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:28:27,475 - INFO - Feature scaling completed in 0.63s
2024-12-27 20:28:27,475 - INFO - Starting feature selection (k=50)
2024-12-27 20:28:27,481 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:28:27,481 - INFO - Starting anomaly detection
2024-12-27 20:28:29,319 - INFO - Anomaly detection completed in 1.84s
2024-12-27 20:28:29,319 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:28:29,319 - INFO - Total fit_transform time: 2.47s
2024-12-27 20:28:29,320 - INFO - Training set processing completed in 2.47s
2024-12-27 20:28:29,320 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:28:29,320 - INFO - Memory usage at start_fit: CPU 3109.5 MB, GPU 47.3 MB
2024-12-27 20:28:29,320 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:28:29,321 - INFO - Number of unique classes: 10
2024-12-27 20:28:29,415 - INFO - Fitted scaler and transformed data
2024-12-27 20:28:29,415 - INFO - Scaling time: 0.09s
2024-12-27 20:28:29,551 - INFO - Epoch 1/200, Train Loss: 0.1448, Val Loss: 0.0013
2024-12-27 20:28:29,692 - INFO - Epoch 2/200, Train Loss: 0.0042, Val Loss: 0.0222
2024-12-27 20:28:29,841 - INFO - Epoch 3/200, Train Loss: 0.0033, Val Loss: 0.0015
2024-12-27 20:28:29,842 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:28:29,842 - INFO - Training completed in 0.52s
2024-12-27 20:28:29,842 - INFO - Final memory usage: CPU 3113.0 MB, GPU 48.1 MB
2024-12-27 20:28:29,842 - INFO - Model training completed in 0.52s
2024-12-27 20:28:29,862 - INFO - Prediction completed in 0.02s
2024-12-27 20:28:29,881 - INFO - Poison rate 0.0 completed in 3.03s
2024-12-27 20:28:29,881 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:28:29,883 - INFO - Total number of labels flipped: 50
2024-12-27 20:28:29,883 - INFO - Label flipping completed in 0.00s
2024-12-27 20:28:29,883 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:28:29,884 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:28:30,522 - INFO - Feature scaling completed in 0.64s
2024-12-27 20:28:30,522 - INFO - Starting feature selection (k=50)
2024-12-27 20:28:30,528 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:28:30,528 - INFO - Starting anomaly detection
2024-12-27 20:28:32,540 - INFO - Anomaly detection completed in 2.01s
2024-12-27 20:28:32,540 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:28:32,540 - INFO - Total fit_transform time: 2.66s
2024-12-27 20:28:32,540 - INFO - Training set processing completed in 2.66s
2024-12-27 20:28:32,540 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:28:32,542 - INFO - Memory usage at start_fit: CPU 3113.0 MB, GPU 47.5 MB
2024-12-27 20:28:32,542 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:28:32,543 - INFO - Number of unique classes: 10
2024-12-27 20:28:32,641 - INFO - Fitted scaler and transformed data
2024-12-27 20:28:32,642 - INFO - Scaling time: 0.10s
2024-12-27 20:28:32,803 - INFO - Epoch 1/200, Train Loss: 0.3261, Val Loss: 0.1966
2024-12-27 20:28:32,934 - INFO - Epoch 2/200, Train Loss: 0.0905, Val Loss: 0.2167
2024-12-27 20:28:33,057 - INFO - Epoch 3/200, Train Loss: 0.0370, Val Loss: 0.2362
2024-12-27 20:28:33,057 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:28:33,058 - INFO - Training completed in 0.52s
2024-12-27 20:28:33,058 - INFO - Final memory usage: CPU 3113.0 MB, GPU 48.1 MB
2024-12-27 20:28:33,059 - INFO - Model training completed in 0.52s
2024-12-27 20:28:33,074 - INFO - Prediction completed in 0.01s
2024-12-27 20:28:33,096 - INFO - Poison rate 0.01 completed in 3.21s
2024-12-27 20:28:33,096 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:28:33,102 - INFO - Total number of labels flipped: 150
2024-12-27 20:28:33,102 - INFO - Label flipping completed in 0.01s
2024-12-27 20:28:33,102 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:28:33,102 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:28:33,675 - INFO - Feature scaling completed in 0.57s
2024-12-27 20:28:33,675 - INFO - Starting feature selection (k=50)
2024-12-27 20:28:33,689 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:28:33,689 - INFO - Starting anomaly detection
2024-12-27 20:28:34,810 - INFO - Anomaly detection completed in 1.12s
2024-12-27 20:28:34,811 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:28:34,811 - INFO - Total fit_transform time: 1.71s
2024-12-27 20:28:34,811 - INFO - Training set processing completed in 1.71s
2024-12-27 20:28:34,811 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:28:34,812 - INFO - Memory usage at start_fit: CPU 3113.0 MB, GPU 47.5 MB
2024-12-27 20:28:34,813 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:28:34,813 - INFO - Number of unique classes: 10
2024-12-27 20:28:34,915 - INFO - Fitted scaler and transformed data
2024-12-27 20:28:34,915 - INFO - Scaling time: 0.10s
2024-12-27 20:28:35,056 - INFO - Epoch 1/200, Train Loss: 0.6088, Val Loss: 0.5321
2024-12-27 20:28:35,220 - INFO - Epoch 2/200, Train Loss: 0.2109, Val Loss: 0.4749
2024-12-27 20:28:35,386 - INFO - Epoch 3/200, Train Loss: 0.1293, Val Loss: 0.5309
2024-12-27 20:28:35,531 - INFO - Epoch 4/200, Train Loss: 0.0573, Val Loss: 0.5607
2024-12-27 20:28:35,532 - INFO - Early stopping triggered at epoch 4
2024-12-27 20:28:35,532 - INFO - Training completed in 0.72s
2024-12-27 20:28:35,532 - INFO - Final memory usage: CPU 3113.0 MB, GPU 48.1 MB
2024-12-27 20:28:35,532 - INFO - Model training completed in 0.72s
2024-12-27 20:28:35,543 - INFO - Prediction completed in 0.01s
2024-12-27 20:28:35,550 - INFO - Poison rate 0.03 completed in 2.45s
2024-12-27 20:28:35,550 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:28:35,554 - INFO - Total number of labels flipped: 250
2024-12-27 20:28:35,554 - INFO - Label flipping completed in 0.00s
2024-12-27 20:28:35,554 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:28:35,554 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:28:36,170 - INFO - Feature scaling completed in 0.62s
2024-12-27 20:28:36,170 - INFO - Starting feature selection (k=50)
2024-12-27 20:28:36,178 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:28:36,178 - INFO - Starting anomaly detection
2024-12-27 20:28:37,395 - INFO - Anomaly detection completed in 1.22s
2024-12-27 20:28:37,395 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:28:37,395 - INFO - Total fit_transform time: 1.84s
2024-12-27 20:28:37,395 - INFO - Training set processing completed in 1.84s
2024-12-27 20:28:37,395 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:28:37,396 - INFO - Memory usage at start_fit: CPU 3113.0 MB, GPU 47.5 MB
2024-12-27 20:28:37,396 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:28:37,396 - INFO - Number of unique classes: 10
2024-12-27 20:28:37,482 - INFO - Fitted scaler and transformed data
2024-12-27 20:28:37,482 - INFO - Scaling time: 0.08s
2024-12-27 20:28:37,673 - INFO - Epoch 1/200, Train Loss: 0.8167, Val Loss: 0.5510
2024-12-27 20:28:37,899 - INFO - Epoch 2/200, Train Loss: 0.2963, Val Loss: 0.6154
2024-12-27 20:28:38,132 - INFO - Epoch 3/200, Train Loss: 0.1989, Val Loss: 0.6439
2024-12-27 20:28:38,132 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:28:38,132 - INFO - Training completed in 0.74s
2024-12-27 20:28:38,133 - INFO - Final memory usage: CPU 3113.0 MB, GPU 48.1 MB
2024-12-27 20:28:38,133 - INFO - Model training completed in 0.74s
2024-12-27 20:28:38,146 - INFO - Prediction completed in 0.01s
2024-12-27 20:28:38,157 - INFO - Poison rate 0.05 completed in 2.61s
2024-12-27 20:28:38,157 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:28:38,163 - INFO - Total number of labels flipped: 350
2024-12-27 20:28:38,163 - INFO - Label flipping completed in 0.01s
2024-12-27 20:28:38,163 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:28:38,163 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:28:38,695 - INFO - Feature scaling completed in 0.53s
2024-12-27 20:28:38,695 - INFO - Starting feature selection (k=50)
2024-12-27 20:28:38,703 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:28:38,703 - INFO - Starting anomaly detection
2024-12-27 20:28:40,688 - INFO - Anomaly detection completed in 1.98s
2024-12-27 20:28:40,688 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:28:40,688 - INFO - Total fit_transform time: 2.52s
2024-12-27 20:28:40,688 - INFO - Training set processing completed in 2.53s
2024-12-27 20:28:40,688 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:28:40,689 - INFO - Memory usage at start_fit: CPU 3113.0 MB, GPU 47.5 MB
2024-12-27 20:28:40,689 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:28:40,690 - INFO - Number of unique classes: 10
2024-12-27 20:28:40,788 - INFO - Fitted scaler and transformed data
2024-12-27 20:28:40,789 - INFO - Scaling time: 0.10s
2024-12-27 20:28:40,996 - INFO - Epoch 1/200, Train Loss: 0.9818, Val Loss: 0.8907
2024-12-27 20:28:41,229 - INFO - Epoch 2/200, Train Loss: 0.3970, Val Loss: 0.9345
2024-12-27 20:28:41,463 - INFO - Epoch 3/200, Train Loss: 0.2455, Val Loss: 0.9816
2024-12-27 20:28:41,464 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:28:41,464 - INFO - Training completed in 0.78s
2024-12-27 20:28:41,464 - INFO - Final memory usage: CPU 3113.0 MB, GPU 48.1 MB
2024-12-27 20:28:41,465 - INFO - Model training completed in 0.78s
2024-12-27 20:28:41,478 - INFO - Prediction completed in 0.01s
2024-12-27 20:28:41,487 - INFO - Poison rate 0.07 completed in 3.33s
2024-12-27 20:28:41,487 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:28:41,494 - INFO - Total number of labels flipped: 500
2024-12-27 20:28:41,494 - INFO - Label flipping completed in 0.01s
2024-12-27 20:28:41,494 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:28:41,494 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:28:42,058 - INFO - Feature scaling completed in 0.56s
2024-12-27 20:28:42,058 - INFO - Starting feature selection (k=50)
2024-12-27 20:28:42,072 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:28:42,072 - INFO - Starting anomaly detection
2024-12-27 20:28:44,018 - INFO - Anomaly detection completed in 1.95s
2024-12-27 20:28:44,019 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:28:44,019 - INFO - Total fit_transform time: 2.52s
2024-12-27 20:28:44,019 - INFO - Training set processing completed in 2.52s
2024-12-27 20:28:44,019 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:28:44,020 - INFO - Memory usage at start_fit: CPU 3113.0 MB, GPU 47.5 MB
2024-12-27 20:28:44,020 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:28:44,020 - INFO - Number of unique classes: 10
2024-12-27 20:28:44,108 - INFO - Fitted scaler and transformed data
2024-12-27 20:28:44,109 - INFO - Scaling time: 0.09s
2024-12-27 20:28:44,324 - INFO - Epoch 1/200, Train Loss: 1.1791, Val Loss: 1.1101
2024-12-27 20:28:44,553 - INFO - Epoch 2/200, Train Loss: 0.5605, Val Loss: 1.1049
2024-12-27 20:28:44,779 - INFO - Epoch 3/200, Train Loss: 0.3765, Val Loss: 1.1915
2024-12-27 20:28:44,779 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:28:44,779 - INFO - Training completed in 0.76s
2024-12-27 20:28:44,780 - INFO - Final memory usage: CPU 3113.0 MB, GPU 48.1 MB
2024-12-27 20:28:44,781 - INFO - Model training completed in 0.76s
2024-12-27 20:28:44,798 - INFO - Prediction completed in 0.02s
2024-12-27 20:28:44,812 - INFO - Poison rate 0.1 completed in 3.32s
2024-12-27 20:28:44,812 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:28:44,824 - INFO - Total number of labels flipped: 1000
2024-12-27 20:28:44,825 - INFO - Label flipping completed in 0.01s
2024-12-27 20:28:44,825 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:28:44,825 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:28:45,366 - INFO - Feature scaling completed in 0.54s
2024-12-27 20:28:45,366 - INFO - Starting feature selection (k=50)
2024-12-27 20:28:45,380 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:28:45,380 - INFO - Starting anomaly detection
2024-12-27 20:28:47,492 - INFO - Anomaly detection completed in 2.11s
2024-12-27 20:28:47,492 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:28:47,492 - INFO - Total fit_transform time: 2.67s
2024-12-27 20:28:47,492 - INFO - Training set processing completed in 2.67s
2024-12-27 20:28:47,492 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:28:47,494 - INFO - Memory usage at start_fit: CPU 3113.0 MB, GPU 47.5 MB
2024-12-27 20:28:47,494 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:28:47,495 - INFO - Number of unique classes: 10
2024-12-27 20:28:47,589 - INFO - Fitted scaler and transformed data
2024-12-27 20:28:47,589 - INFO - Scaling time: 0.09s
2024-12-27 20:28:47,799 - INFO - Epoch 1/200, Train Loss: 1.7094, Val Loss: 1.6904
2024-12-27 20:28:48,032 - INFO - Epoch 2/200, Train Loss: 0.9572, Val Loss: 1.7957
2024-12-27 20:28:48,258 - INFO - Epoch 3/200, Train Loss: 0.7454, Val Loss: 2.1078
2024-12-27 20:28:48,258 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:28:48,258 - INFO - Training completed in 0.77s
2024-12-27 20:28:48,259 - INFO - Final memory usage: CPU 3113.0 MB, GPU 48.1 MB
2024-12-27 20:28:48,259 - INFO - Model training completed in 0.77s
2024-12-27 20:28:48,271 - INFO - Prediction completed in 0.01s
2024-12-27 20:28:48,290 - INFO - Poison rate 0.2 completed in 3.48s
2024-12-27 20:28:48,291 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:28:48,292 - INFO - Total evaluation time: 35.57s
2024-12-27 20:28:48,294 - INFO - 
Progress: 71.9% - Evaluating ImageNette with RandomForest (standard mode, iteration 1/1)
2024-12-27 20:28:48,358 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:28:48,436 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:28:48,527 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 20:28:48,528 - INFO - Dataset type: image
2024-12-27 20:28:48,528 - INFO - Sample size: 5000
2024-12-27 20:28:48,528 - INFO - Using device: cuda
2024-12-27 20:28:48,530 - INFO - Loading datasets...
2024-12-27 20:28:48,556 - INFO - Dataset loading completed in 0.03s
2024-12-27 20:28:48,557 - INFO - Extracting validation features...
2024-12-27 20:28:48,557 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:29,  1.06it/s]Extracting features:  16%|█▌        | 5/32 [00:01<00:04,  6.13it/s]Extracting features:  31%|███▏      | 10/32 [00:01<00:01, 11.79it/s]Extracting features:  41%|████      | 13/32 [00:01<00:01, 13.51it/s]Extracting features:  50%|█████     | 16/32 [00:01<00:01,  9.65it/s]Extracting features:  59%|█████▉    | 19/32 [00:02<00:01,  9.24it/s]Extracting features:  72%|███████▏  | 23/32 [00:02<00:00, 10.07it/s]Extracting features:  84%|████████▍ | 27/32 [00:02<00:00, 12.11it/s]Extracting features:  97%|█████████▋| 31/32 [00:02<00:00, 13.72it/s]Extracting features: 100%|██████████| 32/32 [00:03<00:00, 10.37it/s]
2024-12-27 20:28:51,648 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:28:51,649 - INFO - Validation feature extraction completed in 3.09s
2024-12-27 20:28:51,649 - INFO - Extracting training features...
2024-12-27 20:28:51,649 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:03,  2.45it/s]Extracting features:   2%|▏         | 3/157 [00:00<00:22,  6.72it/s]Extracting features:   4%|▍         | 6/157 [00:00<00:12, 11.93it/s]Extracting features:   6%|▌         | 9/157 [00:00<00:11, 13.40it/s]Extracting features:   7%|▋         | 11/157 [00:01<00:11, 13.05it/s]Extracting features:   8%|▊         | 13/157 [00:01<00:11, 12.72it/s]Extracting features:  10%|▉         | 15/157 [00:01<00:10, 14.17it/s]Extracting features:  11%|█         | 17/157 [00:01<00:09, 14.38it/s]Extracting features:  13%|█▎        | 20/157 [00:01<00:08, 16.97it/s]Extracting features:  14%|█▍        | 22/157 [00:01<00:09, 14.09it/s]Extracting features:  16%|█▌        | 25/157 [00:01<00:08, 15.66it/s]Extracting features:  18%|█▊        | 28/157 [00:02<00:06, 18.53it/s]Extracting features:  20%|█▉        | 31/157 [00:02<00:08, 14.05it/s]Extracting features:  22%|██▏       | 34/157 [00:02<00:08, 15.13it/s]Extracting features:  24%|██▎       | 37/157 [00:02<00:07, 17.04it/s]Extracting features:  25%|██▌       | 40/157 [00:02<00:06, 18.93it/s]Extracting features:  27%|██▋       | 43/157 [00:02<00:06, 16.99it/s]Extracting features:  29%|██▉       | 46/157 [00:03<00:06, 17.51it/s]Extracting features:  31%|███       | 49/157 [00:03<00:05, 19.71it/s]Extracting features:  33%|███▎      | 52/157 [00:03<00:06, 16.07it/s]Extracting features:  36%|███▌      | 56/157 [00:03<00:06, 15.62it/s]Extracting features:  38%|███▊      | 60/157 [00:04<00:06, 15.64it/s]Extracting features:  40%|████      | 63/157 [00:04<00:05, 16.93it/s]Extracting features:  41%|████▏     | 65/157 [00:04<00:05, 15.44it/s]Extracting features:  43%|████▎     | 67/157 [00:04<00:05, 15.89it/s]Extracting features:  44%|████▍     | 69/157 [00:04<00:06, 12.90it/s]Extracting features:  46%|████▌     | 72/157 [00:04<00:06, 12.46it/s]Extracting features:  48%|████▊     | 76/157 [00:05<00:05, 13.99it/s]Extracting features:  50%|█████     | 79/157 [00:05<00:05, 15.00it/s]Extracting features:  52%|█████▏    | 81/157 [00:05<00:05, 13.95it/s]Extracting features:  54%|█████▎    | 84/157 [00:05<00:05, 13.43it/s]Extracting features:  55%|█████▍    | 86/157 [00:05<00:05, 12.83it/s]Extracting features:  56%|█████▌    | 88/157 [00:06<00:05, 13.58it/s]Extracting features:  57%|█████▋    | 90/157 [00:06<00:04, 13.60it/s]Extracting features:  59%|█████▊    | 92/157 [00:06<00:05, 10.89it/s]Extracting features:  61%|██████    | 96/157 [00:06<00:04, 12.71it/s]Extracting features:  63%|██████▎   | 99/157 [00:06<00:04, 14.48it/s]Extracting features:  64%|██████▍   | 101/157 [00:07<00:04, 11.95it/s]Extracting features:  66%|██████▌   | 104/157 [00:07<00:05, 10.32it/s]Extracting features:  69%|██████▉   | 108/157 [00:07<00:04, 11.74it/s]Extracting features:  71%|███████▏  | 112/157 [00:08<00:03, 12.26it/s]Extracting features:  73%|███████▎  | 115/157 [00:08<00:03, 11.68it/s]Extracting features:  76%|███████▌  | 119/157 [00:08<00:02, 13.15it/s]Extracting features:  78%|███████▊  | 123/157 [00:08<00:02, 13.83it/s]Extracting features:  80%|███████▉  | 125/157 [00:09<00:02, 11.58it/s]Extracting features:  82%|████████▏ | 128/157 [00:09<00:02, 12.59it/s]Extracting features:  84%|████████▍ | 132/157 [00:09<00:01, 13.67it/s]Extracting features:  87%|████████▋ | 136/157 [00:09<00:01, 15.31it/s]Extracting features:  89%|████████▊ | 139/157 [00:09<00:01, 17.60it/s]Extracting features:  90%|█████████ | 142/157 [00:10<00:00, 16.58it/s]Extracting features:  92%|█████████▏| 144/157 [00:10<00:00, 15.03it/s]Extracting features:  93%|█████████▎| 146/157 [00:10<00:00, 12.80it/s]Extracting features:  95%|█████████▍| 149/157 [00:10<00:00, 13.66it/s]Extracting features:  97%|█████████▋| 152/157 [00:10<00:00, 16.12it/s]Extracting features:  98%|█████████▊| 154/157 [00:10<00:00, 16.48it/s]Extracting features:  99%|█████████▉| 156/157 [00:11<00:00, 15.71it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 14.08it/s]
2024-12-27 20:29:02,813 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:29:02,813 - INFO - Training feature extraction completed in 11.16s
2024-12-27 20:29:02,814 - INFO - Creating model for classifier: RandomForest
2024-12-27 20:29:02,814 - INFO - Using device: cuda
2024-12-27 20:29:02,814 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:29:02,814 - INFO - Training set processing completed in 0.00s
2024-12-27 20:29:02,814 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:29:02,816 - INFO - Memory usage at start_fit: CPU 3110.5 MB, GPU 47.3 MB
2024-12-27 20:29:02,816 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:29:02,882 - INFO - Fitted scaler and transformed data
2024-12-27 20:29:02,883 - INFO - Scaling time: 0.07s
2024-12-27 20:29:02,888 - INFO - Number of unique classes: 10
2024-12-27 20:29:06,369 - INFO - Epoch 1/15, Train Loss: 2.2966, Val Loss: 2.2894
2024-12-27 20:29:10,176 - INFO - Epoch 2/15, Train Loss: 2.2805, Val Loss: 2.2739
2024-12-27 20:29:13,588 - INFO - Epoch 3/15, Train Loss: 2.2620, Val Loss: 2.2555
2024-12-27 20:29:16,175 - INFO - Epoch 4/15, Train Loss: 2.2404, Val Loss: 2.2339
2024-12-27 20:29:19,203 - INFO - Epoch 5/15, Train Loss: 2.2155, Val Loss: 2.2093
2024-12-27 20:29:22,133 - INFO - Epoch 6/15, Train Loss: 2.1880, Val Loss: 2.1827
2024-12-27 20:29:25,125 - INFO - Epoch 7/15, Train Loss: 2.1595, Val Loss: 2.1560
2024-12-27 20:29:27,925 - INFO - Epoch 8/15, Train Loss: 2.1309, Val Loss: 2.1307
2024-12-27 20:29:30,738 - INFO - Epoch 9/15, Train Loss: 2.1049, Val Loss: 2.1080
2024-12-27 20:29:34,382 - INFO - Epoch 10/15, Train Loss: 2.0814, Val Loss: 2.0883
2024-12-27 20:29:37,593 - INFO - Epoch 11/15, Train Loss: 2.0610, Val Loss: 2.0713
2024-12-27 20:29:40,483 - INFO - Epoch 12/15, Train Loss: 2.0428, Val Loss: 2.0569
2024-12-27 20:29:43,299 - INFO - Epoch 13/15, Train Loss: 2.0279, Val Loss: 2.0446
2024-12-27 20:29:45,855 - INFO - Epoch 14/15, Train Loss: 2.0150, Val Loss: 2.0341
2024-12-27 20:29:48,826 - INFO - Epoch 15/15, Train Loss: 2.0032, Val Loss: 2.0252
2024-12-27 20:29:48,826 - INFO - Training completed in 46.01s
2024-12-27 20:29:48,827 - INFO - Final memory usage: CPU 3110.5 MB, GPU 75.5 MB
2024-12-27 20:29:48,827 - INFO - Model training completed in 46.01s
2024-12-27 20:29:48,926 - INFO - Prediction completed in 0.10s
2024-12-27 20:29:48,935 - INFO - Poison rate 0.0 completed in 46.12s
2024-12-27 20:29:48,935 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:29:48,936 - INFO - Total number of labels flipped: 50
2024-12-27 20:29:48,936 - INFO - Label flipping completed in 0.00s
2024-12-27 20:29:48,936 - INFO - Training set processing completed in 0.00s
2024-12-27 20:29:48,936 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:29:48,937 - INFO - Memory usage at start_fit: CPU 3110.5 MB, GPU 49.3 MB
2024-12-27 20:29:48,937 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:29:49,001 - INFO - Fitted scaler and transformed data
2024-12-27 20:29:49,002 - INFO - Scaling time: 0.06s
2024-12-27 20:29:49,012 - INFO - Number of unique classes: 10
2024-12-27 20:29:52,229 - INFO - Epoch 1/15, Train Loss: 2.2968, Val Loss: 2.2903
2024-12-27 20:29:55,195 - INFO - Epoch 2/15, Train Loss: 2.2808, Val Loss: 2.2758
2024-12-27 20:29:58,257 - INFO - Epoch 3/15, Train Loss: 2.2627, Val Loss: 2.2588
2024-12-27 20:30:01,336 - INFO - Epoch 4/15, Train Loss: 2.2413, Val Loss: 2.2387
2024-12-27 20:30:04,085 - INFO - Epoch 5/15, Train Loss: 2.2169, Val Loss: 2.2160
2024-12-27 20:30:06,961 - INFO - Epoch 6/15, Train Loss: 2.1895, Val Loss: 2.1912
2024-12-27 20:30:09,762 - INFO - Epoch 7/15, Train Loss: 2.1610, Val Loss: 2.1661
2024-12-27 20:30:12,825 - INFO - Epoch 8/15, Train Loss: 2.1326, Val Loss: 2.1421
2024-12-27 20:30:15,547 - INFO - Epoch 9/15, Train Loss: 2.1069, Val Loss: 2.1204
2024-12-27 20:30:18,178 - INFO - Epoch 10/15, Train Loss: 2.0829, Val Loss: 2.1014
2024-12-27 20:30:21,040 - INFO - Epoch 11/15, Train Loss: 2.0629, Val Loss: 2.0849
2024-12-27 20:30:24,223 - INFO - Epoch 12/15, Train Loss: 2.0449, Val Loss: 2.0710
2024-12-27 20:30:27,288 - INFO - Epoch 13/15, Train Loss: 2.0300, Val Loss: 2.0590
2024-12-27 20:30:30,040 - INFO - Epoch 14/15, Train Loss: 2.0173, Val Loss: 2.0486
2024-12-27 20:30:33,239 - INFO - Epoch 15/15, Train Loss: 2.0060, Val Loss: 2.0399
2024-12-27 20:30:33,239 - INFO - Training completed in 44.30s
2024-12-27 20:30:33,239 - INFO - Final memory usage: CPU 3110.5 MB, GPU 75.5 MB
2024-12-27 20:30:33,240 - INFO - Model training completed in 44.30s
2024-12-27 20:30:33,342 - INFO - Prediction completed in 0.10s
2024-12-27 20:30:33,350 - INFO - Poison rate 0.01 completed in 44.42s
2024-12-27 20:30:33,350 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:30:33,353 - INFO - Total number of labels flipped: 150
2024-12-27 20:30:33,353 - INFO - Label flipping completed in 0.00s
2024-12-27 20:30:33,353 - INFO - Training set processing completed in 0.00s
2024-12-27 20:30:33,353 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:30:33,354 - INFO - Memory usage at start_fit: CPU 3110.5 MB, GPU 49.3 MB
2024-12-27 20:30:33,354 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:30:33,418 - INFO - Fitted scaler and transformed data
2024-12-27 20:30:33,418 - INFO - Scaling time: 0.06s
2024-12-27 20:30:33,429 - INFO - Number of unique classes: 10
2024-12-27 20:30:36,249 - INFO - Epoch 1/15, Train Loss: 2.2971, Val Loss: 2.2904
2024-12-27 20:30:39,138 - INFO - Epoch 2/15, Train Loss: 2.2818, Val Loss: 2.2760
2024-12-27 20:30:41,689 - INFO - Epoch 3/15, Train Loss: 2.2646, Val Loss: 2.2590
2024-12-27 20:30:44,272 - INFO - Epoch 4/15, Train Loss: 2.2445, Val Loss: 2.2392
2024-12-27 20:30:47,029 - INFO - Epoch 5/15, Train Loss: 2.2214, Val Loss: 2.2167
2024-12-27 20:30:50,692 - INFO - Epoch 6/15, Train Loss: 2.1957, Val Loss: 2.1923
2024-12-27 20:30:54,009 - INFO - Epoch 7/15, Train Loss: 2.1690, Val Loss: 2.1673
2024-12-27 20:30:56,917 - INFO - Epoch 8/15, Train Loss: 2.1427, Val Loss: 2.1433
2024-12-27 20:30:59,928 - INFO - Epoch 9/15, Train Loss: 2.1178, Val Loss: 2.1215
2024-12-27 20:31:03,603 - INFO - Epoch 10/15, Train Loss: 2.0951, Val Loss: 2.1024
2024-12-27 20:31:06,912 - INFO - Epoch 11/15, Train Loss: 2.0754, Val Loss: 2.0859
2024-12-27 20:31:10,362 - INFO - Epoch 12/15, Train Loss: 2.0587, Val Loss: 2.0718
2024-12-27 20:31:13,358 - INFO - Epoch 13/15, Train Loss: 2.0438, Val Loss: 2.0597
2024-12-27 20:31:16,947 - INFO - Epoch 14/15, Train Loss: 2.0309, Val Loss: 2.0493
2024-12-27 20:31:20,839 - INFO - Epoch 15/15, Train Loss: 2.0199, Val Loss: 2.0404
2024-12-27 20:31:20,839 - INFO - Training completed in 47.49s
2024-12-27 20:31:20,839 - INFO - Final memory usage: CPU 3110.5 MB, GPU 75.5 MB
2024-12-27 20:31:20,840 - INFO - Model training completed in 47.49s
2024-12-27 20:31:20,988 - INFO - Prediction completed in 0.15s
2024-12-27 20:31:20,996 - INFO - Poison rate 0.03 completed in 47.65s
2024-12-27 20:31:20,996 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:31:20,999 - INFO - Total number of labels flipped: 250
2024-12-27 20:31:21,000 - INFO - Label flipping completed in 0.00s
2024-12-27 20:31:21,000 - INFO - Training set processing completed in 0.00s
2024-12-27 20:31:21,000 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:31:21,001 - INFO - Memory usage at start_fit: CPU 3110.5 MB, GPU 49.3 MB
2024-12-27 20:31:21,001 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:31:21,065 - INFO - Fitted scaler and transformed data
2024-12-27 20:31:21,065 - INFO - Scaling time: 0.06s
2024-12-27 20:31:21,075 - INFO - Number of unique classes: 10
2024-12-27 20:31:24,369 - INFO - Epoch 1/15, Train Loss: 2.2971, Val Loss: 2.2910
2024-12-27 20:31:27,174 - INFO - Epoch 2/15, Train Loss: 2.2820, Val Loss: 2.2774
2024-12-27 20:31:29,842 - INFO - Epoch 3/15, Train Loss: 2.2650, Val Loss: 2.2615
2024-12-27 20:31:33,142 - INFO - Epoch 4/15, Train Loss: 2.2449, Val Loss: 2.2430
2024-12-27 20:31:35,816 - INFO - Epoch 5/15, Train Loss: 2.2223, Val Loss: 2.2219
2024-12-27 20:31:38,950 - INFO - Epoch 6/15, Train Loss: 2.1970, Val Loss: 2.1993
2024-12-27 20:31:41,521 - INFO - Epoch 7/15, Train Loss: 2.1705, Val Loss: 2.1760
2024-12-27 20:31:44,887 - INFO - Epoch 8/15, Train Loss: 2.1440, Val Loss: 2.1539
2024-12-27 20:31:47,861 - INFO - Epoch 9/15, Train Loss: 2.1202, Val Loss: 2.1335
2024-12-27 20:31:51,153 - INFO - Epoch 10/15, Train Loss: 2.0975, Val Loss: 2.1154
2024-12-27 20:31:54,651 - INFO - Epoch 11/15, Train Loss: 2.0780, Val Loss: 2.0998
2024-12-27 20:31:58,103 - INFO - Epoch 12/15, Train Loss: 2.0613, Val Loss: 2.0863
2024-12-27 20:32:01,234 - INFO - Epoch 13/15, Train Loss: 2.0475, Val Loss: 2.0748
2024-12-27 20:32:04,046 - INFO - Epoch 14/15, Train Loss: 2.0346, Val Loss: 2.0648
2024-12-27 20:32:06,817 - INFO - Epoch 15/15, Train Loss: 2.0237, Val Loss: 2.0563
2024-12-27 20:32:06,818 - INFO - Training completed in 45.82s
2024-12-27 20:32:06,818 - INFO - Final memory usage: CPU 3110.5 MB, GPU 75.5 MB
2024-12-27 20:32:06,818 - INFO - Model training completed in 45.82s
2024-12-27 20:32:06,918 - INFO - Prediction completed in 0.10s
2024-12-27 20:32:06,926 - INFO - Poison rate 0.05 completed in 45.93s
2024-12-27 20:32:06,926 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:32:06,931 - INFO - Total number of labels flipped: 350
2024-12-27 20:32:06,931 - INFO - Label flipping completed in 0.00s
2024-12-27 20:32:06,931 - INFO - Training set processing completed in 0.00s
2024-12-27 20:32:06,931 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:32:06,931 - INFO - Memory usage at start_fit: CPU 3110.5 MB, GPU 49.3 MB
2024-12-27 20:32:06,932 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:32:06,996 - INFO - Fitted scaler and transformed data
2024-12-27 20:32:06,997 - INFO - Scaling time: 0.06s
2024-12-27 20:32:07,007 - INFO - Number of unique classes: 10
2024-12-27 20:32:09,991 - INFO - Epoch 1/15, Train Loss: 2.2974, Val Loss: 2.2911
2024-12-27 20:32:12,765 - INFO - Epoch 2/15, Train Loss: 2.2829, Val Loss: 2.2778
2024-12-27 20:32:15,573 - INFO - Epoch 3/15, Train Loss: 2.2666, Val Loss: 2.2622
2024-12-27 20:32:18,954 - INFO - Epoch 4/15, Train Loss: 2.2475, Val Loss: 2.2439
2024-12-27 20:32:22,187 - INFO - Epoch 5/15, Train Loss: 2.2257, Val Loss: 2.2230
2024-12-27 20:32:25,168 - INFO - Epoch 6/15, Train Loss: 2.2014, Val Loss: 2.2004
2024-12-27 20:32:27,730 - INFO - Epoch 7/15, Train Loss: 2.1759, Val Loss: 2.1772
2024-12-27 20:32:30,561 - INFO - Epoch 8/15, Train Loss: 2.1504, Val Loss: 2.1550
2024-12-27 20:32:33,095 - INFO - Epoch 9/15, Train Loss: 2.1265, Val Loss: 2.1348
2024-12-27 20:32:36,086 - INFO - Epoch 10/15, Train Loss: 2.1047, Val Loss: 2.1170
2024-12-27 20:32:38,835 - INFO - Epoch 11/15, Train Loss: 2.0858, Val Loss: 2.1015
2024-12-27 20:32:41,962 - INFO - Epoch 12/15, Train Loss: 2.0697, Val Loss: 2.0882
2024-12-27 20:32:44,801 - INFO - Epoch 13/15, Train Loss: 2.0550, Val Loss: 2.0770
2024-12-27 20:32:48,032 - INFO - Epoch 14/15, Train Loss: 2.0425, Val Loss: 2.0673
2024-12-27 20:32:51,131 - INFO - Epoch 15/15, Train Loss: 2.0321, Val Loss: 2.0589
2024-12-27 20:32:51,131 - INFO - Training completed in 44.20s
2024-12-27 20:32:51,132 - INFO - Final memory usage: CPU 3110.5 MB, GPU 75.5 MB
2024-12-27 20:32:51,132 - INFO - Model training completed in 44.20s
2024-12-27 20:32:51,237 - INFO - Prediction completed in 0.10s
2024-12-27 20:32:51,245 - INFO - Poison rate 0.07 completed in 44.32s
2024-12-27 20:32:51,245 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:32:51,251 - INFO - Total number of labels flipped: 500
2024-12-27 20:32:51,251 - INFO - Label flipping completed in 0.01s
2024-12-27 20:32:51,251 - INFO - Training set processing completed in 0.00s
2024-12-27 20:32:51,251 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:32:51,252 - INFO - Memory usage at start_fit: CPU 3110.5 MB, GPU 49.3 MB
2024-12-27 20:32:51,252 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:32:51,320 - INFO - Fitted scaler and transformed data
2024-12-27 20:32:51,320 - INFO - Scaling time: 0.07s
2024-12-27 20:32:51,330 - INFO - Number of unique classes: 10
2024-12-27 20:32:54,544 - INFO - Epoch 1/15, Train Loss: 2.2977, Val Loss: 2.2919
2024-12-27 20:32:57,711 - INFO - Epoch 2/15, Train Loss: 2.2839, Val Loss: 2.2795
2024-12-27 20:33:00,552 - INFO - Epoch 3/15, Train Loss: 2.2685, Val Loss: 2.2650
2024-12-27 20:33:03,503 - INFO - Epoch 4/15, Train Loss: 2.2507, Val Loss: 2.2481
2024-12-27 20:33:06,919 - INFO - Epoch 5/15, Train Loss: 2.2302, Val Loss: 2.2290
2024-12-27 20:33:10,284 - INFO - Epoch 6/15, Train Loss: 2.2078, Val Loss: 2.2081
2024-12-27 20:33:13,789 - INFO - Epoch 7/15, Train Loss: 2.1840, Val Loss: 2.1867
2024-12-27 20:33:17,017 - INFO - Epoch 8/15, Train Loss: 2.1598, Val Loss: 2.1660
2024-12-27 20:33:20,419 - INFO - Epoch 9/15, Train Loss: 2.1377, Val Loss: 2.1466
2024-12-27 20:33:23,309 - INFO - Epoch 10/15, Train Loss: 2.1168, Val Loss: 2.1294
2024-12-27 20:33:25,907 - INFO - Epoch 11/15, Train Loss: 2.0989, Val Loss: 2.1144
2024-12-27 20:33:28,873 - INFO - Epoch 12/15, Train Loss: 2.0824, Val Loss: 2.1015
2024-12-27 20:33:31,786 - INFO - Epoch 13/15, Train Loss: 2.0691, Val Loss: 2.0901
2024-12-27 20:33:35,667 - INFO - Epoch 14/15, Train Loss: 2.0571, Val Loss: 2.0804
2024-12-27 20:33:38,326 - INFO - Epoch 15/15, Train Loss: 2.0463, Val Loss: 2.0721
2024-12-27 20:33:38,326 - INFO - Training completed in 47.07s
2024-12-27 20:33:38,326 - INFO - Final memory usage: CPU 3110.5 MB, GPU 75.5 MB
2024-12-27 20:33:38,327 - INFO - Model training completed in 47.08s
2024-12-27 20:33:38,432 - INFO - Prediction completed in 0.11s
2024-12-27 20:33:38,440 - INFO - Poison rate 0.1 completed in 47.19s
2024-12-27 20:33:38,440 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:33:38,452 - INFO - Total number of labels flipped: 1000
2024-12-27 20:33:38,452 - INFO - Label flipping completed in 0.01s
2024-12-27 20:33:38,452 - INFO - Training set processing completed in 0.00s
2024-12-27 20:33:38,452 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:33:38,453 - INFO - Memory usage at start_fit: CPU 3110.5 MB, GPU 49.3 MB
2024-12-27 20:33:38,453 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:33:38,524 - INFO - Fitted scaler and transformed data
2024-12-27 20:33:38,524 - INFO - Scaling time: 0.07s
2024-12-27 20:33:38,535 - INFO - Number of unique classes: 10
2024-12-27 20:33:41,208 - INFO - Epoch 1/15, Train Loss: 2.2986, Val Loss: 2.2938
2024-12-27 20:33:44,648 - INFO - Epoch 2/15, Train Loss: 2.2868, Val Loss: 2.2836
2024-12-27 20:33:47,554 - INFO - Epoch 3/15, Train Loss: 2.2737, Val Loss: 2.2716
2024-12-27 20:33:50,198 - INFO - Epoch 4/15, Train Loss: 2.2588, Val Loss: 2.2575
2024-12-27 20:33:52,949 - INFO - Epoch 5/15, Train Loss: 2.2411, Val Loss: 2.2414
2024-12-27 20:33:56,125 - INFO - Epoch 6/15, Train Loss: 2.2221, Val Loss: 2.2235
2024-12-27 20:33:59,293 - INFO - Epoch 7/15, Train Loss: 2.2015, Val Loss: 2.2048
2024-12-27 20:34:02,432 - INFO - Epoch 8/15, Train Loss: 2.1808, Val Loss: 2.1867
2024-12-27 20:34:05,035 - INFO - Epoch 9/15, Train Loss: 2.1617, Val Loss: 2.1695
2024-12-27 20:34:07,892 - INFO - Epoch 10/15, Train Loss: 2.1435, Val Loss: 2.1542
2024-12-27 20:34:10,927 - INFO - Epoch 11/15, Train Loss: 2.1270, Val Loss: 2.1407
2024-12-27 20:34:13,425 - INFO - Epoch 12/15, Train Loss: 2.1125, Val Loss: 2.1289
2024-12-27 20:34:16,057 - INFO - Epoch 13/15, Train Loss: 2.1003, Val Loss: 2.1187
2024-12-27 20:34:18,970 - INFO - Epoch 14/15, Train Loss: 2.0887, Val Loss: 2.1099
2024-12-27 20:34:22,492 - INFO - Epoch 15/15, Train Loss: 2.0796, Val Loss: 2.1021
2024-12-27 20:34:22,492 - INFO - Training completed in 44.04s
2024-12-27 20:34:22,493 - INFO - Final memory usage: CPU 3110.5 MB, GPU 75.5 MB
2024-12-27 20:34:22,493 - INFO - Model training completed in 44.04s
2024-12-27 20:34:22,675 - INFO - Prediction completed in 0.18s
2024-12-27 20:34:22,682 - INFO - Poison rate 0.2 completed in 44.24s
2024-12-27 20:34:22,683 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:34:22,683 - INFO - Total evaluation time: 334.15s
2024-12-27 20:34:22,685 - INFO - 
Progress: 72.9% - Evaluating ImageNette with RandomForest (dynadetect mode, iteration 1/1)
2024-12-27 20:34:22,753 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:34:22,937 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:34:23,051 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 20:34:23,052 - INFO - Dataset type: image
2024-12-27 20:34:23,052 - INFO - Sample size: 5000
2024-12-27 20:34:23,052 - INFO - Using device: cuda
2024-12-27 20:34:23,055 - INFO - Loading datasets...
2024-12-27 20:34:23,081 - INFO - Dataset loading completed in 0.03s
2024-12-27 20:34:23,082 - INFO - Extracting validation features...
2024-12-27 20:34:23,082 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:20,  1.48it/s]Extracting features:  19%|█▉        | 6/32 [00:00<00:02,  9.94it/s]Extracting features:  28%|██▊       | 9/32 [00:00<00:01, 13.54it/s]Extracting features:  38%|███▊      | 12/32 [00:01<00:01, 13.11it/s]Extracting features:  47%|████▋     | 15/32 [00:01<00:01, 12.27it/s]Extracting features:  56%|█████▋    | 18/32 [00:01<00:01, 12.08it/s]Extracting features:  69%|██████▉   | 22/32 [00:01<00:00, 13.63it/s]Extracting features:  81%|████████▏ | 26/32 [00:02<00:00, 14.87it/s]Extracting features:  94%|█████████▍| 30/32 [00:02<00:00, 16.26it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 13.27it/s]
2024-12-27 20:34:25,499 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:34:25,500 - INFO - Validation feature extraction completed in 2.42s
2024-12-27 20:34:25,500 - INFO - Extracting training features...
2024-12-27 20:34:25,500 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:36,  1.61it/s]Extracting features:   3%|▎         | 5/157 [00:00<00:21,  7.03it/s]Extracting features:   6%|▌         | 9/157 [00:01<00:14, 10.54it/s]Extracting features:   8%|▊         | 13/157 [00:01<00:10, 13.16it/s]Extracting features:  10%|█         | 16/157 [00:01<00:09, 15.45it/s]Extracting features:  11%|█▏        | 18/157 [00:01<00:11, 11.59it/s]Extracting features:  13%|█▎        | 21/157 [00:01<00:09, 13.99it/s]Extracting features:  15%|█▍        | 23/157 [00:01<00:09, 13.83it/s]Extracting features:  16%|█▌        | 25/157 [00:02<00:09, 14.03it/s]Extracting features:  17%|█▋        | 27/157 [00:02<00:08, 14.77it/s]Extracting features:  18%|█▊        | 29/157 [00:02<00:08, 14.36it/s]Extracting features:  20%|██        | 32/157 [00:02<00:07, 17.70it/s]Extracting features:  22%|██▏       | 34/157 [00:02<00:07, 15.79it/s]Extracting features:  24%|██▍       | 38/157 [00:02<00:07, 16.94it/s]Extracting features:  27%|██▋       | 42/157 [00:03<00:06, 17.87it/s]Extracting features:  29%|██▉       | 46/157 [00:03<00:06, 17.72it/s]Extracting features:  32%|███▏      | 50/157 [00:03<00:06, 16.86it/s]Extracting features:  34%|███▍      | 54/157 [00:03<00:06, 16.71it/s]Extracting features:  37%|███▋      | 58/157 [00:04<00:05, 17.94it/s]Extracting features:  38%|███▊      | 60/157 [00:04<00:06, 14.88it/s]Extracting features:  41%|████      | 64/157 [00:04<00:06, 14.93it/s]Extracting features:  43%|████▎     | 68/157 [00:04<00:06, 12.83it/s]Extracting features:  46%|████▌     | 72/157 [00:05<00:06, 13.54it/s]Extracting features:  48%|████▊     | 76/157 [00:05<00:05, 14.00it/s]Extracting features:  51%|█████     | 80/157 [00:05<00:05, 14.59it/s]Extracting features:  54%|█████▎    | 84/157 [00:06<00:05, 13.88it/s]Extracting features:  56%|█████▌    | 88/157 [00:06<00:04, 13.99it/s]Extracting features:  59%|█████▊    | 92/157 [00:06<00:04, 14.16it/s]Extracting features:  61%|██████    | 96/157 [00:06<00:04, 13.61it/s]Extracting features:  64%|██████▎   | 100/157 [00:07<00:04, 13.64it/s]Extracting features:  66%|██████▌   | 104/157 [00:07<00:03, 14.29it/s]Extracting features:  69%|██████▉   | 108/157 [00:07<00:03, 12.76it/s]Extracting features:  70%|███████   | 110/157 [00:08<00:04, 11.12it/s]Extracting features:  73%|███████▎  | 114/157 [00:08<00:03, 11.70it/s]Extracting features:  74%|███████▍  | 116/157 [00:08<00:03, 11.90it/s]Extracting features:  75%|███████▌  | 118/157 [00:08<00:03, 10.86it/s]Extracting features:  77%|███████▋  | 121/157 [00:08<00:02, 13.20it/s]Extracting features:  78%|███████▊  | 123/157 [00:09<00:02, 12.55it/s]Extracting features:  80%|███████▉  | 125/157 [00:09<00:02, 12.62it/s]Extracting features:  82%|████████▏ | 128/157 [00:09<00:02, 13.53it/s]Extracting features:  84%|████████▍ | 132/157 [00:09<00:01, 15.64it/s]Extracting features:  87%|████████▋ | 136/157 [00:09<00:01, 15.41it/s]Extracting features:  89%|████████▉ | 140/157 [00:10<00:01, 15.30it/s]Extracting features:  92%|█████████▏| 144/157 [00:10<00:00, 14.32it/s]Extracting features:  94%|█████████▍| 148/157 [00:10<00:00, 15.13it/s]Extracting features:  97%|█████████▋| 152/157 [00:11<00:00, 13.80it/s]Extracting features:  99%|█████████▉| 156/157 [00:11<00:00, 15.89it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 13.84it/s]
2024-12-27 20:34:36,852 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:34:36,852 - INFO - Training feature extraction completed in 11.35s
2024-12-27 20:34:36,852 - INFO - Creating model for classifier: RandomForest
2024-12-27 20:34:36,852 - INFO - Using device: cuda
2024-12-27 20:34:36,852 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:34:36,852 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:34:36,852 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:34:37,453 - INFO - Feature scaling completed in 0.60s
2024-12-27 20:34:37,453 - INFO - Starting feature selection (k=50)
2024-12-27 20:34:37,459 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:34:37,459 - INFO - Starting anomaly detection
2024-12-27 20:34:38,676 - INFO - Anomaly detection completed in 1.22s
2024-12-27 20:34:38,676 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:34:38,676 - INFO - Total fit_transform time: 1.82s
2024-12-27 20:34:38,676 - INFO - Training set processing completed in 1.82s
2024-12-27 20:34:38,676 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:34:38,678 - INFO - Memory usage at start_fit: CPU 3111.5 MB, GPU 47.3 MB
2024-12-27 20:34:38,678 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:34:38,756 - INFO - Fitted scaler and transformed data
2024-12-27 20:34:38,757 - INFO - Scaling time: 0.08s
2024-12-27 20:34:38,762 - INFO - Number of unique classes: 10
2024-12-27 20:34:41,476 - INFO - Epoch 1/15, Train Loss: 2.1824, Val Loss: 2.2901
2024-12-27 20:34:44,627 - INFO - Epoch 2/15, Train Loss: 2.1673, Val Loss: 2.2754
2024-12-27 20:34:47,240 - INFO - Epoch 3/15, Train Loss: 2.1501, Val Loss: 2.2580
2024-12-27 20:34:50,487 - INFO - Epoch 4/15, Train Loss: 2.1299, Val Loss: 2.2376
2024-12-27 20:34:54,060 - INFO - Epoch 5/15, Train Loss: 2.1066, Val Loss: 2.2143
2024-12-27 20:34:56,458 - INFO - Epoch 6/15, Train Loss: 2.0806, Val Loss: 2.1891
2024-12-27 20:34:59,363 - INFO - Epoch 7/15, Train Loss: 2.0534, Val Loss: 2.1634
2024-12-27 20:35:02,256 - INFO - Epoch 8/15, Train Loss: 2.0268, Val Loss: 2.1389
2024-12-27 20:35:05,397 - INFO - Epoch 9/15, Train Loss: 2.0023, Val Loss: 2.1169
2024-12-27 20:35:09,303 - INFO - Epoch 10/15, Train Loss: 1.9798, Val Loss: 2.0977
2024-12-27 20:35:12,706 - INFO - Epoch 11/15, Train Loss: 1.9604, Val Loss: 2.0813
2024-12-27 20:35:16,107 - INFO - Epoch 12/15, Train Loss: 1.9438, Val Loss: 2.0673
2024-12-27 20:35:19,003 - INFO - Epoch 13/15, Train Loss: 1.9298, Val Loss: 2.0554
2024-12-27 20:35:21,549 - INFO - Epoch 14/15, Train Loss: 1.9175, Val Loss: 2.0452
2024-12-27 20:35:24,794 - INFO - Epoch 15/15, Train Loss: 1.9067, Val Loss: 2.0364
2024-12-27 20:35:24,794 - INFO - Training completed in 46.12s
2024-12-27 20:35:24,794 - INFO - Final memory usage: CPU 3111.5 MB, GPU 75.5 MB
2024-12-27 20:35:24,795 - INFO - Model training completed in 46.12s
2024-12-27 20:35:24,895 - INFO - Prediction completed in 0.10s
2024-12-27 20:35:24,903 - INFO - Poison rate 0.0 completed in 48.05s
2024-12-27 20:35:24,903 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:35:24,905 - INFO - Total number of labels flipped: 50
2024-12-27 20:35:24,905 - INFO - Label flipping completed in 0.00s
2024-12-27 20:35:24,905 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:35:24,905 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:35:25,506 - INFO - Feature scaling completed in 0.60s
2024-12-27 20:35:25,506 - INFO - Starting feature selection (k=50)
2024-12-27 20:35:25,518 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:35:25,518 - INFO - Starting anomaly detection
2024-12-27 20:35:26,918 - INFO - Anomaly detection completed in 1.40s
2024-12-27 20:35:26,918 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:35:26,918 - INFO - Total fit_transform time: 2.01s
2024-12-27 20:35:26,918 - INFO - Training set processing completed in 2.01s
2024-12-27 20:35:26,919 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:35:26,920 - INFO - Memory usage at start_fit: CPU 3111.5 MB, GPU 49.3 MB
2024-12-27 20:35:26,920 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:35:26,989 - INFO - Fitted scaler and transformed data
2024-12-27 20:35:26,989 - INFO - Scaling time: 0.07s
2024-12-27 20:35:26,995 - INFO - Number of unique classes: 10
2024-12-27 20:35:30,084 - INFO - Epoch 1/15, Train Loss: 2.1812, Val Loss: 2.2897
2024-12-27 20:35:32,880 - INFO - Epoch 2/15, Train Loss: 2.1663, Val Loss: 2.2746
2024-12-27 20:35:35,716 - INFO - Epoch 3/15, Train Loss: 2.1493, Val Loss: 2.2567
2024-12-27 20:35:38,477 - INFO - Epoch 4/15, Train Loss: 2.1294, Val Loss: 2.2357
2024-12-27 20:35:41,311 - INFO - Epoch 5/15, Train Loss: 2.1067, Val Loss: 2.2119
2024-12-27 20:35:44,849 - INFO - Epoch 6/15, Train Loss: 2.0815, Val Loss: 2.1862
2024-12-27 20:35:47,974 - INFO - Epoch 7/15, Train Loss: 2.0548, Val Loss: 2.1604
2024-12-27 20:35:50,904 - INFO - Epoch 8/15, Train Loss: 2.0293, Val Loss: 2.1358
2024-12-27 20:35:53,569 - INFO - Epoch 9/15, Train Loss: 2.0049, Val Loss: 2.1137
2024-12-27 20:35:56,393 - INFO - Epoch 10/15, Train Loss: 1.9836, Val Loss: 2.0942
2024-12-27 20:35:59,293 - INFO - Epoch 11/15, Train Loss: 1.9645, Val Loss: 2.0777
2024-12-27 20:36:02,336 - INFO - Epoch 12/15, Train Loss: 1.9480, Val Loss: 2.0636
2024-12-27 20:36:05,267 - INFO - Epoch 13/15, Train Loss: 1.9335, Val Loss: 2.0516
2024-12-27 20:36:08,093 - INFO - Epoch 14/15, Train Loss: 1.9220, Val Loss: 2.0413
2024-12-27 20:36:11,438 - INFO - Epoch 15/15, Train Loss: 1.9111, Val Loss: 2.0326
2024-12-27 20:36:11,438 - INFO - Training completed in 44.52s
2024-12-27 20:36:11,438 - INFO - Final memory usage: CPU 3111.5 MB, GPU 75.5 MB
2024-12-27 20:36:11,438 - INFO - Model training completed in 44.52s
2024-12-27 20:36:11,594 - INFO - Prediction completed in 0.15s
2024-12-27 20:36:11,602 - INFO - Poison rate 0.01 completed in 46.70s
2024-12-27 20:36:11,602 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:36:11,605 - INFO - Total number of labels flipped: 150
2024-12-27 20:36:11,605 - INFO - Label flipping completed in 0.00s
2024-12-27 20:36:11,605 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:36:11,605 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:36:12,165 - INFO - Feature scaling completed in 0.56s
2024-12-27 20:36:12,165 - INFO - Starting feature selection (k=50)
2024-12-27 20:36:12,179 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:36:12,180 - INFO - Starting anomaly detection
2024-12-27 20:36:13,835 - INFO - Anomaly detection completed in 1.65s
2024-12-27 20:36:13,835 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:36:13,835 - INFO - Total fit_transform time: 2.23s
2024-12-27 20:36:13,835 - INFO - Training set processing completed in 2.23s
2024-12-27 20:36:13,835 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:36:13,837 - INFO - Memory usage at start_fit: CPU 3111.5 MB, GPU 49.3 MB
2024-12-27 20:36:13,837 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:36:13,908 - INFO - Fitted scaler and transformed data
2024-12-27 20:36:13,908 - INFO - Scaling time: 0.07s
2024-12-27 20:36:13,914 - INFO - Number of unique classes: 10
2024-12-27 20:36:17,196 - INFO - Epoch 1/15, Train Loss: 2.1792, Val Loss: 2.2903
2024-12-27 20:36:20,319 - INFO - Epoch 2/15, Train Loss: 2.1647, Val Loss: 2.2760
2024-12-27 20:36:23,102 - INFO - Epoch 3/15, Train Loss: 2.1481, Val Loss: 2.2592
2024-12-27 20:36:26,230 - INFO - Epoch 4/15, Train Loss: 2.1288, Val Loss: 2.2395
2024-12-27 20:36:28,771 - INFO - Epoch 5/15, Train Loss: 2.1067, Val Loss: 2.2173
2024-12-27 20:36:31,584 - INFO - Epoch 6/15, Train Loss: 2.0824, Val Loss: 2.1932
2024-12-27 20:36:34,842 - INFO - Epoch 7/15, Train Loss: 2.0568, Val Loss: 2.1689
2024-12-27 20:36:39,305 - INFO - Epoch 8/15, Train Loss: 2.0313, Val Loss: 2.1457
2024-12-27 20:36:42,800 - INFO - Epoch 9/15, Train Loss: 2.0078, Val Loss: 2.1245
2024-12-27 20:36:46,031 - INFO - Epoch 10/15, Train Loss: 1.9868, Val Loss: 2.1058
2024-12-27 20:36:48,798 - INFO - Epoch 11/15, Train Loss: 1.9677, Val Loss: 2.0898
2024-12-27 20:36:52,054 - INFO - Epoch 12/15, Train Loss: 1.9520, Val Loss: 2.0760
2024-12-27 20:36:55,576 - INFO - Epoch 13/15, Train Loss: 1.9379, Val Loss: 2.0641
2024-12-27 20:36:59,299 - INFO - Epoch 14/15, Train Loss: 1.9259, Val Loss: 2.0540
2024-12-27 20:37:02,348 - INFO - Epoch 15/15, Train Loss: 1.9153, Val Loss: 2.0453
2024-12-27 20:37:02,349 - INFO - Training completed in 48.51s
2024-12-27 20:37:02,349 - INFO - Final memory usage: CPU 3111.5 MB, GPU 75.5 MB
2024-12-27 20:37:02,349 - INFO - Model training completed in 48.51s
2024-12-27 20:37:02,490 - INFO - Prediction completed in 0.14s
2024-12-27 20:37:02,498 - INFO - Poison rate 0.03 completed in 50.90s
2024-12-27 20:37:02,499 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:37:02,502 - INFO - Total number of labels flipped: 250
2024-12-27 20:37:02,502 - INFO - Label flipping completed in 0.00s
2024-12-27 20:37:02,502 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:37:02,502 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:37:03,147 - INFO - Feature scaling completed in 0.65s
2024-12-27 20:37:03,148 - INFO - Starting feature selection (k=50)
2024-12-27 20:37:03,160 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:37:03,160 - INFO - Starting anomaly detection
2024-12-27 20:37:05,309 - INFO - Anomaly detection completed in 2.15s
2024-12-27 20:37:05,309 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:37:05,309 - INFO - Total fit_transform time: 2.81s
2024-12-27 20:37:05,309 - INFO - Training set processing completed in 2.81s
2024-12-27 20:37:05,309 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:37:05,311 - INFO - Memory usage at start_fit: CPU 3111.5 MB, GPU 49.3 MB
2024-12-27 20:37:05,311 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:37:05,379 - INFO - Fitted scaler and transformed data
2024-12-27 20:37:05,379 - INFO - Scaling time: 0.07s
2024-12-27 20:37:05,390 - INFO - Number of unique classes: 10
2024-12-27 20:37:09,422 - INFO - Epoch 1/15, Train Loss: 2.1797, Val Loss: 2.2912
2024-12-27 20:37:13,099 - INFO - Epoch 2/15, Train Loss: 2.1658, Val Loss: 2.2777
2024-12-27 20:37:16,686 - INFO - Epoch 3/15, Train Loss: 2.1501, Val Loss: 2.2618
2024-12-27 20:37:19,358 - INFO - Epoch 4/15, Train Loss: 2.1316, Val Loss: 2.2432
2024-12-27 20:37:22,474 - INFO - Epoch 5/15, Train Loss: 2.1105, Val Loss: 2.2220
2024-12-27 20:37:25,478 - INFO - Epoch 6/15, Train Loss: 2.0872, Val Loss: 2.1990
2024-12-27 20:37:28,295 - INFO - Epoch 7/15, Train Loss: 2.0624, Val Loss: 2.1755
2024-12-27 20:37:31,573 - INFO - Epoch 8/15, Train Loss: 2.0379, Val Loss: 2.1529
2024-12-27 20:37:35,226 - INFO - Epoch 9/15, Train Loss: 2.0149, Val Loss: 2.1322
2024-12-27 20:37:38,574 - INFO - Epoch 10/15, Train Loss: 1.9943, Val Loss: 2.1140
2024-12-27 20:37:41,915 - INFO - Epoch 11/15, Train Loss: 1.9756, Val Loss: 2.0982
2024-12-27 20:37:45,895 - INFO - Epoch 12/15, Train Loss: 1.9598, Val Loss: 2.0845
2024-12-27 20:37:49,728 - INFO - Epoch 13/15, Train Loss: 1.9461, Val Loss: 2.0727
2024-12-27 20:37:53,350 - INFO - Epoch 14/15, Train Loss: 1.9347, Val Loss: 2.0626
2024-12-27 20:37:56,529 - INFO - Epoch 15/15, Train Loss: 1.9240, Val Loss: 2.0538
2024-12-27 20:37:56,529 - INFO - Training completed in 51.22s
2024-12-27 20:37:56,530 - INFO - Final memory usage: CPU 3111.5 MB, GPU 75.5 MB
2024-12-27 20:37:56,530 - INFO - Model training completed in 51.22s
2024-12-27 20:37:56,687 - INFO - Prediction completed in 0.16s
2024-12-27 20:37:56,695 - INFO - Poison rate 0.05 completed in 54.20s
2024-12-27 20:37:56,695 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:37:56,699 - INFO - Total number of labels flipped: 350
2024-12-27 20:37:56,699 - INFO - Label flipping completed in 0.00s
2024-12-27 20:37:56,699 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:37:56,699 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:37:57,291 - INFO - Feature scaling completed in 0.59s
2024-12-27 20:37:57,291 - INFO - Starting feature selection (k=50)
2024-12-27 20:37:57,303 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:37:57,303 - INFO - Starting anomaly detection
2024-12-27 20:37:58,768 - INFO - Anomaly detection completed in 1.46s
2024-12-27 20:37:58,768 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:37:58,768 - INFO - Total fit_transform time: 2.07s
2024-12-27 20:37:58,768 - INFO - Training set processing completed in 2.07s
2024-12-27 20:37:58,768 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:37:58,770 - INFO - Memory usage at start_fit: CPU 3111.5 MB, GPU 49.3 MB
2024-12-27 20:37:58,770 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:37:58,859 - INFO - Fitted scaler and transformed data
2024-12-27 20:37:58,859 - INFO - Scaling time: 0.09s
2024-12-27 20:37:58,864 - INFO - Number of unique classes: 10
2024-12-27 20:38:02,265 - INFO - Epoch 1/15, Train Loss: 2.1794, Val Loss: 2.2916
2024-12-27 20:38:05,247 - INFO - Epoch 2/15, Train Loss: 2.1658, Val Loss: 2.2786
2024-12-27 20:38:09,254 - INFO - Epoch 3/15, Train Loss: 2.1505, Val Loss: 2.2634
2024-12-27 20:38:13,253 - INFO - Epoch 4/15, Train Loss: 2.1325, Val Loss: 2.2456
2024-12-27 20:38:16,642 - INFO - Epoch 5/15, Train Loss: 2.1121, Val Loss: 2.2254
2024-12-27 20:38:20,088 - INFO - Epoch 6/15, Train Loss: 2.0896, Val Loss: 2.2034
2024-12-27 20:38:23,512 - INFO - Epoch 7/15, Train Loss: 2.0659, Val Loss: 2.1809
2024-12-27 20:38:26,545 - INFO - Epoch 8/15, Train Loss: 2.0422, Val Loss: 2.1593
2024-12-27 20:38:29,695 - INFO - Epoch 9/15, Train Loss: 2.0202, Val Loss: 2.1395
2024-12-27 20:38:33,029 - INFO - Epoch 10/15, Train Loss: 1.9998, Val Loss: 2.1218
2024-12-27 20:38:37,147 - INFO - Epoch 11/15, Train Loss: 1.9821, Val Loss: 2.1066
2024-12-27 20:38:40,516 - INFO - Epoch 12/15, Train Loss: 1.9667, Val Loss: 2.0934
2024-12-27 20:38:43,929 - INFO - Epoch 13/15, Train Loss: 1.9535, Val Loss: 2.0820
2024-12-27 20:38:47,431 - INFO - Epoch 14/15, Train Loss: 1.9415, Val Loss: 2.0722
2024-12-27 20:38:50,008 - INFO - Epoch 15/15, Train Loss: 1.9312, Val Loss: 2.0637
2024-12-27 20:38:50,008 - INFO - Training completed in 51.24s
2024-12-27 20:38:50,008 - INFO - Final memory usage: CPU 3111.5 MB, GPU 75.5 MB
2024-12-27 20:38:50,009 - INFO - Model training completed in 51.24s
2024-12-27 20:38:50,107 - INFO - Prediction completed in 0.10s
2024-12-27 20:38:50,114 - INFO - Poison rate 0.07 completed in 53.42s
2024-12-27 20:38:50,115 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:38:50,125 - INFO - Total number of labels flipped: 500
2024-12-27 20:38:50,125 - INFO - Label flipping completed in 0.01s
2024-12-27 20:38:50,125 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:38:50,125 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:38:50,661 - INFO - Feature scaling completed in 0.54s
2024-12-27 20:38:50,661 - INFO - Starting feature selection (k=50)
2024-12-27 20:38:50,673 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:38:50,673 - INFO - Starting anomaly detection
2024-12-27 20:38:52,813 - INFO - Anomaly detection completed in 2.14s
2024-12-27 20:38:52,813 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:38:52,813 - INFO - Total fit_transform time: 2.69s
2024-12-27 20:38:52,813 - INFO - Training set processing completed in 2.69s
2024-12-27 20:38:52,813 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:38:52,814 - INFO - Memory usage at start_fit: CPU 3111.5 MB, GPU 49.3 MB
2024-12-27 20:38:52,814 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:38:52,885 - INFO - Fitted scaler and transformed data
2024-12-27 20:38:52,885 - INFO - Scaling time: 0.07s
2024-12-27 20:38:52,891 - INFO - Number of unique classes: 10
2024-12-27 20:38:56,053 - INFO - Epoch 1/15, Train Loss: 2.1825, Val Loss: 2.2922
2024-12-27 20:38:59,521 - INFO - Epoch 2/15, Train Loss: 2.1695, Val Loss: 2.2801
2024-12-27 20:39:02,774 - INFO - Epoch 3/15, Train Loss: 2.1548, Val Loss: 2.2660
2024-12-27 20:39:05,730 - INFO - Epoch 4/15, Train Loss: 2.1379, Val Loss: 2.2496
2024-12-27 20:39:08,888 - INFO - Epoch 5/15, Train Loss: 2.1188, Val Loss: 2.2309
2024-12-27 20:39:12,059 - INFO - Epoch 6/15, Train Loss: 2.0975, Val Loss: 2.2107
2024-12-27 20:39:15,186 - INFO - Epoch 7/15, Train Loss: 2.0750, Val Loss: 2.1901
2024-12-27 20:39:19,148 - INFO - Epoch 8/15, Train Loss: 2.0527, Val Loss: 2.1700
2024-12-27 20:39:22,867 - INFO - Epoch 9/15, Train Loss: 2.0312, Val Loss: 2.1517
2024-12-27 20:39:26,380 - INFO - Epoch 10/15, Train Loss: 2.0122, Val Loss: 2.1353
2024-12-27 20:39:30,638 - INFO - Epoch 11/15, Train Loss: 1.9949, Val Loss: 2.1211
2024-12-27 20:39:33,469 - INFO - Epoch 12/15, Train Loss: 1.9801, Val Loss: 2.1088
2024-12-27 20:39:36,346 - INFO - Epoch 13/15, Train Loss: 1.9665, Val Loss: 2.0984
2024-12-27 20:39:39,614 - INFO - Epoch 14/15, Train Loss: 1.9555, Val Loss: 2.0893
2024-12-27 20:39:42,277 - INFO - Epoch 15/15, Train Loss: 1.9454, Val Loss: 2.0816
2024-12-27 20:39:42,278 - INFO - Training completed in 49.46s
2024-12-27 20:39:42,278 - INFO - Final memory usage: CPU 3111.5 MB, GPU 75.5 MB
2024-12-27 20:39:42,278 - INFO - Model training completed in 49.47s
2024-12-27 20:39:42,382 - INFO - Prediction completed in 0.10s
2024-12-27 20:39:42,390 - INFO - Poison rate 0.1 completed in 52.28s
2024-12-27 20:39:42,390 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:39:42,402 - INFO - Total number of labels flipped: 1000
2024-12-27 20:39:42,402 - INFO - Label flipping completed in 0.01s
2024-12-27 20:39:42,402 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:39:42,402 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:39:42,992 - INFO - Feature scaling completed in 0.59s
2024-12-27 20:39:42,992 - INFO - Starting feature selection (k=50)
2024-12-27 20:39:43,005 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:39:43,005 - INFO - Starting anomaly detection
2024-12-27 20:39:45,267 - INFO - Anomaly detection completed in 2.26s
2024-12-27 20:39:45,267 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:39:45,267 - INFO - Total fit_transform time: 2.87s
2024-12-27 20:39:45,267 - INFO - Training set processing completed in 2.87s
2024-12-27 20:39:45,268 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:39:45,268 - INFO - Memory usage at start_fit: CPU 3111.5 MB, GPU 49.3 MB
2024-12-27 20:39:45,268 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:39:45,334 - INFO - Fitted scaler and transformed data
2024-12-27 20:39:45,334 - INFO - Scaling time: 0.07s
2024-12-27 20:39:45,344 - INFO - Number of unique classes: 10
2024-12-27 20:39:49,112 - INFO - Epoch 1/15, Train Loss: 2.1861, Val Loss: 2.2946
2024-12-27 20:39:52,963 - INFO - Epoch 2/15, Train Loss: 2.1750, Val Loss: 2.2853
2024-12-27 20:39:56,100 - INFO - Epoch 3/15, Train Loss: 2.1629, Val Loss: 2.2746
2024-12-27 20:39:58,884 - INFO - Epoch 4/15, Train Loss: 2.1490, Val Loss: 2.2621
2024-12-27 20:40:03,420 - INFO - Epoch 5/15, Train Loss: 2.1334, Val Loss: 2.2479
2024-12-27 20:40:06,737 - INFO - Epoch 6/15, Train Loss: 2.1160, Val Loss: 2.2326
2024-12-27 20:40:10,042 - INFO - Epoch 7/15, Train Loss: 2.0973, Val Loss: 2.2165
2024-12-27 20:40:13,478 - INFO - Epoch 8/15, Train Loss: 2.0790, Val Loss: 2.2005
2024-12-27 20:40:17,087 - INFO - Epoch 9/15, Train Loss: 2.0607, Val Loss: 2.1857
2024-12-27 20:40:20,478 - INFO - Epoch 10/15, Train Loss: 2.0445, Val Loss: 2.1723
2024-12-27 20:40:23,051 - INFO - Epoch 11/15, Train Loss: 2.0293, Val Loss: 2.1604
2024-12-27 20:40:26,385 - INFO - Epoch 12/15, Train Loss: 2.0157, Val Loss: 2.1500
2024-12-27 20:40:30,978 - INFO - Epoch 13/15, Train Loss: 2.0038, Val Loss: 2.1409
2024-12-27 20:40:34,749 - INFO - Epoch 14/15, Train Loss: 1.9938, Val Loss: 2.1330
2024-12-27 20:40:38,264 - INFO - Epoch 15/15, Train Loss: 1.9850, Val Loss: 2.1262
2024-12-27 20:40:38,264 - INFO - Training completed in 53.00s
2024-12-27 20:40:38,264 - INFO - Final memory usage: CPU 3111.5 MB, GPU 75.5 MB
2024-12-27 20:40:38,265 - INFO - Model training completed in 53.00s
2024-12-27 20:40:38,369 - INFO - Prediction completed in 0.10s
2024-12-27 20:40:38,376 - INFO - Poison rate 0.2 completed in 55.99s
2024-12-27 20:40:38,377 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:40:38,377 - INFO - Total evaluation time: 375.32s
2024-12-27 20:40:38,379 - INFO - 
Progress: 74.0% - Evaluating ImageNette with KNeighbors (standard mode, iteration 1/1)
2024-12-27 20:40:38,438 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:40:38,618 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:40:38,715 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 20:40:38,715 - INFO - Dataset type: image
2024-12-27 20:40:38,715 - INFO - Sample size: 5000
2024-12-27 20:40:38,715 - INFO - Using device: cuda
2024-12-27 20:40:38,718 - INFO - Loading datasets...
2024-12-27 20:40:38,745 - INFO - Dataset loading completed in 0.03s
2024-12-27 20:40:38,745 - INFO - Extracting validation features...
2024-12-27 20:40:38,745 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:22,  1.38it/s]Extracting features:  22%|██▏       | 7/32 [00:00<00:02,  8.55it/s]Extracting features:  31%|███▏      | 10/32 [00:01<00:02, 10.45it/s]Extracting features:  41%|████      | 13/32 [00:01<00:01, 13.18it/s]Extracting features:  47%|████▋     | 15/32 [00:01<00:01, 12.04it/s]Extracting features:  53%|█████▎    | 17/32 [00:01<00:01, 11.89it/s]Extracting features:  59%|█████▉    | 19/32 [00:01<00:01, 12.46it/s]Extracting features:  69%|██████▉   | 22/32 [00:01<00:00, 14.39it/s]Extracting features:  75%|███████▌  | 24/32 [00:02<00:00, 14.01it/s]Extracting features:  81%|████████▏ | 26/32 [00:02<00:00, 14.99it/s]Extracting features:  88%|████████▊ | 28/32 [00:02<00:00, 14.25it/s]Extracting features:  97%|█████████▋| 31/32 [00:02<00:00, 14.67it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 11.88it/s]
2024-12-27 20:40:41,445 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:40:41,446 - INFO - Validation feature extraction completed in 2.70s
2024-12-27 20:40:41,446 - INFO - Extracting training features...
2024-12-27 20:40:41,446 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:09,  2.25it/s]Extracting features:   3%|▎         | 5/157 [00:00<00:20,  7.37it/s]Extracting features:   6%|▌         | 9/157 [00:00<00:13, 11.20it/s]Extracting features:   7%|▋         | 11/157 [00:01<00:11, 12.60it/s]Extracting features:   8%|▊         | 13/157 [00:01<00:15,  9.50it/s]Extracting features:  11%|█         | 17/157 [00:01<00:12, 11.60it/s]Extracting features:  13%|█▎        | 21/157 [00:01<00:10, 12.48it/s]Extracting features:  16%|█▌        | 25/157 [00:02<00:09, 14.18it/s]Extracting features:  18%|█▊        | 29/157 [00:02<00:08, 14.76it/s]Extracting features:  21%|██        | 33/157 [00:02<00:07, 16.58it/s]Extracting features:  24%|██▎       | 37/157 [00:02<00:06, 18.41it/s]Extracting features:  26%|██▌       | 41/157 [00:02<00:06, 18.88it/s]Extracting features:  29%|██▊       | 45/157 [00:03<00:06, 18.52it/s]Extracting features:  31%|███       | 49/157 [00:03<00:05, 18.09it/s]Extracting features:  32%|███▏      | 51/157 [00:03<00:05, 17.75it/s]Extracting features:  34%|███▍      | 54/157 [00:03<00:05, 19.21it/s]Extracting features:  36%|███▌      | 56/157 [00:03<00:05, 18.17it/s]Extracting features:  37%|███▋      | 58/157 [00:04<00:07, 13.85it/s]Extracting features:  39%|███▉      | 61/157 [00:04<00:06, 15.61it/s]Extracting features:  40%|████      | 63/157 [00:04<00:05, 16.35it/s]Extracting features:  41%|████▏     | 65/157 [00:04<00:06, 14.05it/s]Extracting features:  43%|████▎     | 67/157 [00:04<00:06, 14.49it/s]Extracting features:  44%|████▍     | 69/157 [00:05<00:08,  9.83it/s]Extracting features:  46%|████▋     | 73/157 [00:05<00:07, 11.65it/s]Extracting features:  49%|████▉     | 77/157 [00:05<00:06, 11.68it/s]Extracting features:  52%|█████▏    | 81/157 [00:05<00:06, 12.54it/s]Extracting features:  54%|█████▍    | 85/157 [00:06<00:05, 12.85it/s]Extracting features:  57%|█████▋    | 89/157 [00:06<00:06, 11.30it/s]Extracting features:  59%|█████▉    | 93/157 [00:06<00:05, 12.69it/s]Extracting features:  62%|██████▏   | 97/157 [00:07<00:04, 12.52it/s]Extracting features:  64%|██████▍   | 101/157 [00:07<00:04, 12.44it/s]Extracting features:  67%|██████▋   | 105/157 [00:07<00:04, 11.96it/s]Extracting features:  69%|██████▉   | 109/157 [00:08<00:03, 12.43it/s]Extracting features:  72%|███████▏  | 113/157 [00:08<00:03, 11.73it/s]Extracting features:  75%|███████▍  | 117/157 [00:08<00:03, 12.19it/s]Extracting features:  77%|███████▋  | 121/157 [00:09<00:02, 12.37it/s]Extracting features:  78%|███████▊  | 123/157 [00:09<00:02, 11.35it/s]Extracting features:  80%|████████  | 126/157 [00:09<00:02, 11.83it/s]Extracting features:  83%|████████▎ | 130/157 [00:09<00:01, 13.92it/s]Extracting features:  85%|████████▌ | 134/157 [00:10<00:01, 15.61it/s]Extracting features:  88%|████████▊ | 138/157 [00:10<00:01, 15.77it/s]Extracting features:  90%|█████████ | 142/157 [00:10<00:00, 16.10it/s]Extracting features:  93%|█████████▎| 146/157 [00:10<00:00, 15.97it/s]Extracting features:  95%|█████████▍| 149/157 [00:11<00:00, 14.51it/s]Extracting features:  97%|█████████▋| 153/157 [00:11<00:00, 15.06it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 13.78it/s]
2024-12-27 20:40:52,851 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:40:52,852 - INFO - Training feature extraction completed in 11.41s
2024-12-27 20:40:52,852 - INFO - Creating model for classifier: KNeighbors
2024-12-27 20:40:52,852 - INFO - Using device: cuda
2024-12-27 20:40:52,852 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:40:52,852 - INFO - Training set processing completed in 0.00s
2024-12-27 20:40:52,852 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:40:52,853 - INFO - Memory usage at start_fit: CPU 3111.9 MB, GPU 47.3 MB
2024-12-27 20:40:52,853 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:40:52,922 - INFO - Fitted scaler and transformed data
2024-12-27 20:40:52,922 - INFO - Scaling time: 0.07s
2024-12-27 20:40:52,928 - INFO - Training completed in 0.07s
2024-12-27 20:40:52,928 - INFO - Final memory usage: CPU 3111.9 MB, GPU 71.8 MB
2024-12-27 20:40:52,928 - INFO - Model training completed in 0.08s
2024-12-27 20:40:52,959 - INFO - Prediction completed in 0.03s
2024-12-27 20:40:52,970 - INFO - Poison rate 0.0 completed in 0.12s
2024-12-27 20:40:52,970 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:40:52,971 - INFO - Total number of labels flipped: 50
2024-12-27 20:40:52,971 - INFO - Label flipping completed in 0.00s
2024-12-27 20:40:52,971 - INFO - Training set processing completed in 0.00s
2024-12-27 20:40:52,971 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:40:52,972 - INFO - Memory usage at start_fit: CPU 3111.9 MB, GPU 71.8 MB
2024-12-27 20:40:52,972 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:40:53,032 - INFO - Fitted scaler and transformed data
2024-12-27 20:40:53,032 - INFO - Scaling time: 0.06s
2024-12-27 20:40:53,037 - INFO - Training completed in 0.07s
2024-12-27 20:40:53,038 - INFO - Final memory usage: CPU 3111.9 MB, GPU 71.8 MB
2024-12-27 20:40:53,038 - INFO - Model training completed in 0.07s
2024-12-27 20:40:53,052 - INFO - Prediction completed in 0.01s
2024-12-27 20:40:53,059 - INFO - Poison rate 0.01 completed in 0.09s
2024-12-27 20:40:53,059 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:40:53,061 - INFO - Total number of labels flipped: 150
2024-12-27 20:40:53,062 - INFO - Label flipping completed in 0.00s
2024-12-27 20:40:53,062 - INFO - Training set processing completed in 0.00s
2024-12-27 20:40:53,062 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:40:53,063 - INFO - Memory usage at start_fit: CPU 3111.9 MB, GPU 71.8 MB
2024-12-27 20:40:53,063 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:40:53,139 - INFO - Fitted scaler and transformed data
2024-12-27 20:40:53,139 - INFO - Scaling time: 0.08s
2024-12-27 20:40:53,144 - INFO - Training completed in 0.08s
2024-12-27 20:40:53,144 - INFO - Final memory usage: CPU 3111.9 MB, GPU 71.8 MB
2024-12-27 20:40:53,144 - INFO - Model training completed in 0.08s
2024-12-27 20:40:53,157 - INFO - Prediction completed in 0.01s
2024-12-27 20:40:53,165 - INFO - Poison rate 0.03 completed in 0.11s
2024-12-27 20:40:53,165 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:40:53,169 - INFO - Total number of labels flipped: 250
2024-12-27 20:40:53,169 - INFO - Label flipping completed in 0.00s
2024-12-27 20:40:53,169 - INFO - Training set processing completed in 0.00s
2024-12-27 20:40:53,169 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:40:53,170 - INFO - Memory usage at start_fit: CPU 3111.9 MB, GPU 71.8 MB
2024-12-27 20:40:53,170 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:40:53,234 - INFO - Fitted scaler and transformed data
2024-12-27 20:40:53,234 - INFO - Scaling time: 0.06s
2024-12-27 20:40:53,241 - INFO - Training completed in 0.07s
2024-12-27 20:40:53,241 - INFO - Final memory usage: CPU 3111.9 MB, GPU 71.8 MB
2024-12-27 20:40:53,241 - INFO - Model training completed in 0.07s
2024-12-27 20:40:53,259 - INFO - Prediction completed in 0.02s
2024-12-27 20:40:53,267 - INFO - Poison rate 0.05 completed in 0.10s
2024-12-27 20:40:53,267 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:40:53,271 - INFO - Total number of labels flipped: 350
2024-12-27 20:40:53,271 - INFO - Label flipping completed in 0.00s
2024-12-27 20:40:53,271 - INFO - Training set processing completed in 0.00s
2024-12-27 20:40:53,271 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:40:53,272 - INFO - Memory usage at start_fit: CPU 3111.9 MB, GPU 71.8 MB
2024-12-27 20:40:53,272 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:40:53,335 - INFO - Fitted scaler and transformed data
2024-12-27 20:40:53,335 - INFO - Scaling time: 0.06s
2024-12-27 20:40:53,340 - INFO - Training completed in 0.07s
2024-12-27 20:40:53,341 - INFO - Final memory usage: CPU 3111.9 MB, GPU 71.8 MB
2024-12-27 20:40:53,341 - INFO - Model training completed in 0.07s
2024-12-27 20:40:53,355 - INFO - Prediction completed in 0.01s
2024-12-27 20:40:53,362 - INFO - Poison rate 0.07 completed in 0.10s
2024-12-27 20:40:53,363 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:40:53,369 - INFO - Total number of labels flipped: 500
2024-12-27 20:40:53,369 - INFO - Label flipping completed in 0.01s
2024-12-27 20:40:53,369 - INFO - Training set processing completed in 0.00s
2024-12-27 20:40:53,369 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:40:53,370 - INFO - Memory usage at start_fit: CPU 3111.9 MB, GPU 71.8 MB
2024-12-27 20:40:53,371 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:40:53,432 - INFO - Fitted scaler and transformed data
2024-12-27 20:40:53,432 - INFO - Scaling time: 0.06s
2024-12-27 20:40:53,437 - INFO - Training completed in 0.07s
2024-12-27 20:40:53,438 - INFO - Final memory usage: CPU 3111.9 MB, GPU 71.8 MB
2024-12-27 20:40:53,438 - INFO - Model training completed in 0.07s
2024-12-27 20:40:53,453 - INFO - Prediction completed in 0.01s
2024-12-27 20:40:53,460 - INFO - Poison rate 0.1 completed in 0.10s
2024-12-27 20:40:53,460 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:40:53,472 - INFO - Total number of labels flipped: 1000
2024-12-27 20:40:53,472 - INFO - Label flipping completed in 0.01s
2024-12-27 20:40:53,472 - INFO - Training set processing completed in 0.00s
2024-12-27 20:40:53,472 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:40:53,473 - INFO - Memory usage at start_fit: CPU 3111.9 MB, GPU 71.8 MB
2024-12-27 20:40:53,473 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:40:53,546 - INFO - Fitted scaler and transformed data
2024-12-27 20:40:53,546 - INFO - Scaling time: 0.07s
2024-12-27 20:40:53,553 - INFO - Training completed in 0.08s
2024-12-27 20:40:53,553 - INFO - Final memory usage: CPU 3111.9 MB, GPU 71.8 MB
2024-12-27 20:40:53,553 - INFO - Model training completed in 0.08s
2024-12-27 20:40:53,579 - INFO - Prediction completed in 0.02s
2024-12-27 20:40:53,590 - INFO - Poison rate 0.2 completed in 0.13s
2024-12-27 20:40:53,591 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:40:53,591 - INFO - Total evaluation time: 14.87s
2024-12-27 20:40:53,593 - INFO - 
Progress: 75.0% - Evaluating ImageNette with KNeighbors (dynadetect mode, iteration 1/1)
2024-12-27 20:40:53,654 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:40:53,736 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:40:53,815 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 20:40:53,815 - INFO - Dataset type: image
2024-12-27 20:40:53,815 - INFO - Sample size: 5000
2024-12-27 20:40:53,815 - INFO - Using device: cuda
2024-12-27 20:40:53,817 - INFO - Loading datasets...
2024-12-27 20:40:53,842 - INFO - Dataset loading completed in 0.02s
2024-12-27 20:40:53,842 - INFO - Extracting validation features...
2024-12-27 20:40:53,843 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:16,  1.93it/s]Extracting features:  16%|█▌        | 5/32 [00:00<00:03,  8.13it/s]Extracting features:  28%|██▊       | 9/32 [00:00<00:01, 12.49it/s]Extracting features:  34%|███▍      | 11/32 [00:01<00:01, 12.49it/s]Extracting features:  44%|████▍     | 14/32 [00:01<00:01, 11.91it/s]Extracting features:  56%|█████▋    | 18/32 [00:01<00:01, 11.60it/s]Extracting features:  69%|██████▉   | 22/32 [00:01<00:00, 12.53it/s]Extracting features:  78%|███████▊  | 25/32 [00:02<00:00, 14.24it/s]Extracting features:  84%|████████▍ | 27/32 [00:02<00:00, 14.05it/s]Extracting features:  94%|█████████▍| 30/32 [00:02<00:00, 14.97it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 12.56it/s]
2024-12-27 20:40:56,393 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:40:56,394 - INFO - Validation feature extraction completed in 2.55s
2024-12-27 20:40:56,394 - INFO - Extracting training features...
2024-12-27 20:40:56,394 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:42,  1.53it/s]Extracting features:   3%|▎         | 5/157 [00:00<00:23,  6.34it/s]Extracting features:   6%|▌         | 9/157 [00:01<00:14, 10.13it/s]Extracting features:   8%|▊         | 13/157 [00:01<00:12, 11.99it/s]Extracting features:  11%|█         | 17/157 [00:01<00:10, 13.25it/s]Extracting features:  13%|█▎        | 21/157 [00:01<00:09, 14.37it/s]Extracting features:  16%|█▌        | 25/157 [00:02<00:09, 14.64it/s]Extracting features:  18%|█▊        | 29/157 [00:02<00:08, 15.43it/s]Extracting features:  21%|██        | 33/157 [00:02<00:07, 16.31it/s]Extracting features:  24%|██▎       | 37/157 [00:02<00:07, 15.04it/s]Extracting features:  26%|██▌       | 41/157 [00:03<00:06, 16.79it/s]Extracting features:  29%|██▊       | 45/157 [00:03<00:06, 18.02it/s]Extracting features:  31%|███       | 49/157 [00:03<00:06, 17.97it/s]Extracting features:  34%|███▍      | 53/157 [00:03<00:06, 17.08it/s]Extracting features:  36%|███▌      | 56/157 [00:03<00:05, 18.47it/s]Extracting features:  37%|███▋      | 58/157 [00:03<00:05, 17.95it/s]Extracting features:  39%|███▉      | 61/157 [00:04<00:05, 16.45it/s]Extracting features:  41%|████      | 64/157 [00:04<00:04, 18.67it/s]Extracting features:  43%|████▎     | 67/157 [00:04<00:05, 16.06it/s]Extracting features:  44%|████▍     | 69/157 [00:04<00:06, 13.20it/s]Extracting features:  46%|████▋     | 73/157 [00:05<00:06, 12.73it/s]Extracting features:  49%|████▉     | 77/157 [00:05<00:05, 13.61it/s]Extracting features:  52%|█████▏    | 81/157 [00:05<00:05, 13.71it/s]Extracting features:  54%|█████▍    | 85/157 [00:05<00:04, 14.41it/s]Extracting features:  57%|█████▋    | 89/157 [00:06<00:04, 13.79it/s]Extracting features:  58%|█████▊    | 91/157 [00:06<00:05, 12.65it/s]Extracting features:  60%|█████▉    | 94/157 [00:06<00:05, 12.56it/s]Extracting features:  62%|██████▏   | 97/157 [00:06<00:04, 14.86it/s]Extracting features:  63%|██████▎   | 99/157 [00:07<00:04, 12.81it/s]Extracting features:  64%|██████▍   | 101/157 [00:07<00:04, 13.78it/s]Extracting features:  66%|██████▌   | 103/157 [00:07<00:04, 12.30it/s]Extracting features:  68%|██████▊   | 106/157 [00:07<00:04, 10.68it/s]Extracting features:  70%|███████   | 110/157 [00:08<00:03, 12.03it/s]Extracting features:  72%|███████▏  | 113/157 [00:08<00:03, 13.77it/s]Extracting features:  73%|███████▎  | 115/157 [00:08<00:02, 14.04it/s]Extracting features:  75%|███████▍  | 117/157 [00:08<00:02, 14.01it/s]Extracting features:  76%|███████▌  | 119/157 [00:08<00:03, 11.19it/s]Extracting features:  78%|███████▊  | 122/157 [00:08<00:03, 10.99it/s]Extracting features:  80%|███████▉  | 125/157 [00:09<00:02, 13.58it/s]Extracting features:  81%|████████  | 127/157 [00:09<00:02, 14.67it/s]Extracting features:  82%|████████▏ | 129/157 [00:09<00:01, 15.24it/s]Extracting features:  84%|████████▍ | 132/157 [00:09<00:01, 16.26it/s]Extracting features:  85%|████████▌ | 134/157 [00:09<00:01, 16.60it/s]Extracting features:  87%|████████▋ | 137/157 [00:09<00:01, 15.88it/s]Extracting features:  89%|████████▉ | 140/157 [00:09<00:00, 18.55it/s]Extracting features:  91%|█████████ | 143/157 [00:10<00:00, 17.95it/s]Extracting features:  92%|█████████▏| 145/157 [00:10<00:00, 12.69it/s]Extracting features:  95%|█████████▍| 149/157 [00:10<00:00, 14.62it/s]Extracting features:  96%|█████████▌| 151/157 [00:10<00:00, 15.54it/s]Extracting features:  97%|█████████▋| 153/157 [00:10<00:00, 14.84it/s]Extracting features:  99%|█████████▊| 155/157 [00:10<00:00, 15.81it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 15.16it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 14.03it/s]
2024-12-27 20:41:07,595 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:41:07,595 - INFO - Training feature extraction completed in 11.20s
2024-12-27 20:41:07,596 - INFO - Creating model for classifier: KNeighbors
2024-12-27 20:41:07,596 - INFO - Using device: cuda
2024-12-27 20:41:07,596 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:41:07,596 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:41:07,596 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:41:08,193 - INFO - Feature scaling completed in 0.60s
2024-12-27 20:41:08,193 - INFO - Starting feature selection (k=50)
2024-12-27 20:41:08,200 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:41:08,201 - INFO - Starting anomaly detection
2024-12-27 20:41:09,817 - INFO - Anomaly detection completed in 1.62s
2024-12-27 20:41:09,817 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:41:09,817 - INFO - Total fit_transform time: 2.22s
2024-12-27 20:41:09,817 - INFO - Training set processing completed in 2.22s
2024-12-27 20:41:09,817 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:41:09,819 - INFO - Memory usage at start_fit: CPU 3110.2 MB, GPU 47.3 MB
2024-12-27 20:41:09,819 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:41:09,891 - INFO - Fitted scaler and transformed data
2024-12-27 20:41:09,891 - INFO - Scaling time: 0.07s
2024-12-27 20:41:09,897 - INFO - Training completed in 0.08s
2024-12-27 20:41:09,898 - INFO - Final memory usage: CPU 3110.2 MB, GPU 71.8 MB
2024-12-27 20:41:09,898 - INFO - Model training completed in 0.08s
2024-12-27 20:41:09,917 - INFO - Prediction completed in 0.02s
2024-12-27 20:41:09,925 - INFO - Poison rate 0.0 completed in 2.33s
2024-12-27 20:41:09,925 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:41:09,926 - INFO - Total number of labels flipped: 50
2024-12-27 20:41:09,926 - INFO - Label flipping completed in 0.00s
2024-12-27 20:41:09,926 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:41:09,926 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:41:10,481 - INFO - Feature scaling completed in 0.55s
2024-12-27 20:41:10,481 - INFO - Starting feature selection (k=50)
2024-12-27 20:41:10,488 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:41:10,488 - INFO - Starting anomaly detection
2024-12-27 20:41:12,422 - INFO - Anomaly detection completed in 1.93s
2024-12-27 20:41:12,423 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:41:12,423 - INFO - Total fit_transform time: 2.50s
2024-12-27 20:41:12,423 - INFO - Training set processing completed in 2.50s
2024-12-27 20:41:12,423 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:41:12,424 - INFO - Memory usage at start_fit: CPU 3110.2 MB, GPU 71.8 MB
2024-12-27 20:41:12,424 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:41:12,490 - INFO - Fitted scaler and transformed data
2024-12-27 20:41:12,491 - INFO - Scaling time: 0.07s
2024-12-27 20:41:12,497 - INFO - Training completed in 0.07s
2024-12-27 20:41:12,497 - INFO - Final memory usage: CPU 3110.2 MB, GPU 71.8 MB
2024-12-27 20:41:12,498 - INFO - Model training completed in 0.07s
2024-12-27 20:41:12,523 - INFO - Prediction completed in 0.03s
2024-12-27 20:41:12,543 - INFO - Poison rate 0.01 completed in 2.62s
2024-12-27 20:41:12,543 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:41:12,547 - INFO - Total number of labels flipped: 150
2024-12-27 20:41:12,547 - INFO - Label flipping completed in 0.00s
2024-12-27 20:41:12,547 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:41:12,547 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:41:13,133 - INFO - Feature scaling completed in 0.59s
2024-12-27 20:41:13,133 - INFO - Starting feature selection (k=50)
2024-12-27 20:41:13,141 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:41:13,141 - INFO - Starting anomaly detection
2024-12-27 20:41:15,226 - INFO - Anomaly detection completed in 2.08s
2024-12-27 20:41:15,226 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:41:15,226 - INFO - Total fit_transform time: 2.68s
2024-12-27 20:41:15,226 - INFO - Training set processing completed in 2.68s
2024-12-27 20:41:15,226 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:41:15,227 - INFO - Memory usage at start_fit: CPU 3110.2 MB, GPU 71.8 MB
2024-12-27 20:41:15,228 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:41:15,293 - INFO - Fitted scaler and transformed data
2024-12-27 20:41:15,293 - INFO - Scaling time: 0.06s
2024-12-27 20:41:15,299 - INFO - Training completed in 0.07s
2024-12-27 20:41:15,300 - INFO - Final memory usage: CPU 3110.2 MB, GPU 71.8 MB
2024-12-27 20:41:15,300 - INFO - Model training completed in 0.07s
2024-12-27 20:41:15,326 - INFO - Prediction completed in 0.03s
2024-12-27 20:41:15,333 - INFO - Poison rate 0.03 completed in 2.79s
2024-12-27 20:41:15,333 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:41:15,337 - INFO - Total number of labels flipped: 250
2024-12-27 20:41:15,337 - INFO - Label flipping completed in 0.00s
2024-12-27 20:41:15,337 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:41:15,337 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:41:15,901 - INFO - Feature scaling completed in 0.56s
2024-12-27 20:41:15,901 - INFO - Starting feature selection (k=50)
2024-12-27 20:41:15,909 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:41:15,909 - INFO - Starting anomaly detection
2024-12-27 20:41:17,754 - INFO - Anomaly detection completed in 1.84s
2024-12-27 20:41:17,754 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:41:17,754 - INFO - Total fit_transform time: 2.42s
2024-12-27 20:41:17,754 - INFO - Training set processing completed in 2.42s
2024-12-27 20:41:17,754 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:41:17,755 - INFO - Memory usage at start_fit: CPU 3110.2 MB, GPU 71.8 MB
2024-12-27 20:41:17,756 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:41:17,825 - INFO - Fitted scaler and transformed data
2024-12-27 20:41:17,825 - INFO - Scaling time: 0.07s
2024-12-27 20:41:17,833 - INFO - Training completed in 0.08s
2024-12-27 20:41:17,834 - INFO - Final memory usage: CPU 3110.2 MB, GPU 71.8 MB
2024-12-27 20:41:17,834 - INFO - Model training completed in 0.08s
2024-12-27 20:41:17,869 - INFO - Prediction completed in 0.03s
2024-12-27 20:41:17,877 - INFO - Poison rate 0.05 completed in 2.54s
2024-12-27 20:41:17,877 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:41:17,882 - INFO - Total number of labels flipped: 350
2024-12-27 20:41:17,882 - INFO - Label flipping completed in 0.00s
2024-12-27 20:41:17,882 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:41:17,882 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:41:18,517 - INFO - Feature scaling completed in 0.64s
2024-12-27 20:41:18,517 - INFO - Starting feature selection (k=50)
2024-12-27 20:41:18,525 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:41:18,525 - INFO - Starting anomaly detection
2024-12-27 20:41:19,984 - INFO - Anomaly detection completed in 1.46s
2024-12-27 20:41:19,984 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:41:19,985 - INFO - Total fit_transform time: 2.10s
2024-12-27 20:41:19,985 - INFO - Training set processing completed in 2.10s
2024-12-27 20:41:19,985 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:41:19,985 - INFO - Memory usage at start_fit: CPU 3110.2 MB, GPU 71.8 MB
2024-12-27 20:41:19,985 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:41:20,068 - INFO - Fitted scaler and transformed data
2024-12-27 20:41:20,069 - INFO - Scaling time: 0.08s
2024-12-27 20:41:20,075 - INFO - Training completed in 0.09s
2024-12-27 20:41:20,076 - INFO - Final memory usage: CPU 3110.2 MB, GPU 71.8 MB
2024-12-27 20:41:20,076 - INFO - Model training completed in 0.09s
2024-12-27 20:41:20,100 - INFO - Prediction completed in 0.02s
2024-12-27 20:41:20,108 - INFO - Poison rate 0.07 completed in 2.23s
2024-12-27 20:41:20,108 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:41:20,114 - INFO - Total number of labels flipped: 500
2024-12-27 20:41:20,114 - INFO - Label flipping completed in 0.01s
2024-12-27 20:41:20,114 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:41:20,114 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:41:20,700 - INFO - Feature scaling completed in 0.59s
2024-12-27 20:41:20,700 - INFO - Starting feature selection (k=50)
2024-12-27 20:41:20,708 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:41:20,708 - INFO - Starting anomaly detection
2024-12-27 20:41:22,851 - INFO - Anomaly detection completed in 2.14s
2024-12-27 20:41:22,851 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:41:22,851 - INFO - Total fit_transform time: 2.74s
2024-12-27 20:41:22,851 - INFO - Training set processing completed in 2.74s
2024-12-27 20:41:22,852 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:41:22,852 - INFO - Memory usage at start_fit: CPU 3110.2 MB, GPU 71.8 MB
2024-12-27 20:41:22,852 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:41:22,918 - INFO - Fitted scaler and transformed data
2024-12-27 20:41:22,918 - INFO - Scaling time: 0.07s
2024-12-27 20:41:22,925 - INFO - Training completed in 0.07s
2024-12-27 20:41:22,925 - INFO - Final memory usage: CPU 3110.2 MB, GPU 71.8 MB
2024-12-27 20:41:22,925 - INFO - Model training completed in 0.07s
2024-12-27 20:41:22,952 - INFO - Prediction completed in 0.03s
2024-12-27 20:41:22,960 - INFO - Poison rate 0.1 completed in 2.85s
2024-12-27 20:41:22,960 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:41:22,972 - INFO - Total number of labels flipped: 1000
2024-12-27 20:41:22,972 - INFO - Label flipping completed in 0.01s
2024-12-27 20:41:22,972 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:41:22,972 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:41:23,634 - INFO - Feature scaling completed in 0.66s
2024-12-27 20:41:23,635 - INFO - Starting feature selection (k=50)
2024-12-27 20:41:23,645 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:41:23,645 - INFO - Starting anomaly detection
2024-12-27 20:41:24,928 - INFO - Anomaly detection completed in 1.28s
2024-12-27 20:41:24,929 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:41:24,929 - INFO - Total fit_transform time: 1.96s
2024-12-27 20:41:24,929 - INFO - Training set processing completed in 1.96s
2024-12-27 20:41:24,929 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:41:24,930 - INFO - Memory usage at start_fit: CPU 3110.2 MB, GPU 71.8 MB
2024-12-27 20:41:24,931 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:41:25,001 - INFO - Fitted scaler and transformed data
2024-12-27 20:41:25,001 - INFO - Scaling time: 0.07s
2024-12-27 20:41:25,007 - INFO - Training completed in 0.08s
2024-12-27 20:41:25,008 - INFO - Final memory usage: CPU 3110.2 MB, GPU 71.8 MB
2024-12-27 20:41:25,008 - INFO - Model training completed in 0.08s
2024-12-27 20:41:25,034 - INFO - Prediction completed in 0.03s
2024-12-27 20:41:25,054 - INFO - Poison rate 0.2 completed in 2.09s
2024-12-27 20:41:25,055 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:41:25,055 - INFO - Total evaluation time: 31.24s
2024-12-27 20:41:25,058 - INFO - Completed evaluation for ImageNette
2024-12-27 20:41:25,058 - INFO - 
Processing dataset: ImageNette
2024-12-27 20:41:25,122 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:41:25,196 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:41:25,273 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 20:41:25,273 - INFO - Dataset type: image
2024-12-27 20:41:25,273 - INFO - Sample size: 5000
2024-12-27 20:41:25,273 - INFO - Using device: cuda
2024-12-27 20:41:25,275 - INFO - 
Progress: 76.0% - Evaluating ImageNette with SVM (standard mode, iteration 1/1)
2024-12-27 20:41:25,333 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:41:25,408 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:41:25,489 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 20:41:25,489 - INFO - Dataset type: image
2024-12-27 20:41:25,490 - INFO - Sample size: 5000
2024-12-27 20:41:25,490 - INFO - Using device: cuda
2024-12-27 20:41:25,492 - INFO - Loading datasets...
2024-12-27 20:41:25,517 - INFO - Dataset loading completed in 0.03s
2024-12-27 20:41:25,518 - INFO - Extracting validation features...
2024-12-27 20:41:25,518 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:16,  1.93it/s]Extracting features:   6%|▋         | 2/32 [00:00<00:08,  3.38it/s]Extracting features:  16%|█▌        | 5/32 [00:00<00:03,  8.96it/s]Extracting features:  31%|███▏      | 10/32 [00:01<00:01, 11.57it/s]Extracting features:  44%|████▍     | 14/32 [00:01<00:01, 13.11it/s]Extracting features:  56%|█████▋    | 18/32 [00:01<00:01, 13.59it/s]Extracting features:  66%|██████▌   | 21/32 [00:01<00:00, 15.43it/s]Extracting features:  72%|███████▏  | 23/32 [00:02<00:00, 12.96it/s]Extracting features:  84%|████████▍ | 27/32 [00:02<00:00, 14.03it/s]Extracting features:  91%|█████████ | 29/32 [00:02<00:00, 13.14it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 12.39it/s]
2024-12-27 20:41:28,106 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:41:28,107 - INFO - Validation feature extraction completed in 2.59s
2024-12-27 20:41:28,107 - INFO - Extracting training features...
2024-12-27 20:41:28,107 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:09,  2.23it/s]Extracting features:   1%|▏         | 2/157 [00:00<00:47,  3.25it/s]Extracting features:   4%|▍         | 6/157 [00:01<00:21,  7.11it/s]Extracting features:   6%|▌         | 9/157 [00:01<00:14, 10.21it/s]Extracting features:   7%|▋         | 11/157 [00:01<00:13, 10.95it/s]Extracting features:   8%|▊         | 13/157 [00:01<00:12, 11.42it/s]Extracting features:  10%|█         | 16/157 [00:01<00:09, 14.80it/s]Extracting features:  11%|█▏        | 18/157 [00:01<00:10, 13.68it/s]Extracting features:  13%|█▎        | 20/157 [00:01<00:09, 13.78it/s]Extracting features:  14%|█▍        | 22/157 [00:02<00:09, 13.92it/s]Extracting features:  16%|█▌        | 25/157 [00:02<00:09, 14.17it/s]Extracting features:  18%|█▊        | 28/157 [00:02<00:07, 16.71it/s]Extracting features:  19%|█▉        | 30/157 [00:02<00:08, 15.29it/s]Extracting features:  20%|██        | 32/157 [00:02<00:07, 16.29it/s]Extracting features:  22%|██▏       | 34/157 [00:02<00:07, 16.38it/s]Extracting features:  23%|██▎       | 36/157 [00:02<00:07, 16.66it/s]Extracting features:  25%|██▍       | 39/157 [00:03<00:07, 15.48it/s]Extracting features:  27%|██▋       | 42/157 [00:03<00:06, 18.26it/s]Extracting features:  29%|██▊       | 45/157 [00:03<00:06, 18.09it/s]Extracting features:  30%|██▉       | 47/157 [00:03<00:06, 17.65it/s]Extracting features:  31%|███       | 49/157 [00:03<00:06, 15.60it/s]Extracting features:  33%|███▎      | 52/157 [00:03<00:07, 14.90it/s]Extracting features:  36%|███▌      | 56/157 [00:04<00:06, 16.33it/s]Extracting features:  38%|███▊      | 59/157 [00:04<00:05, 17.89it/s]Extracting features:  39%|███▉      | 61/157 [00:04<00:05, 17.45it/s]Extracting features:  40%|████      | 63/157 [00:04<00:05, 16.05it/s]Extracting features:  41%|████▏     | 65/157 [00:04<00:05, 16.52it/s]Extracting features:  43%|████▎     | 67/157 [00:04<00:06, 13.25it/s]Extracting features:  45%|████▌     | 71/157 [00:05<00:06, 13.55it/s]Extracting features:  48%|████▊     | 75/157 [00:05<00:05, 13.98it/s]Extracting features:  50%|█████     | 79/157 [00:05<00:05, 13.39it/s]Extracting features:  52%|█████▏    | 81/157 [00:05<00:05, 13.59it/s]Extracting features:  53%|█████▎    | 83/157 [00:06<00:05, 12.61it/s]Extracting features:  54%|█████▍    | 85/157 [00:06<00:05, 12.87it/s]Extracting features:  55%|█████▌    | 87/157 [00:06<00:05, 13.71it/s]Extracting features:  57%|█████▋    | 89/157 [00:06<00:04, 13.78it/s]Extracting features:  58%|█████▊    | 91/157 [00:06<00:04, 15.06it/s]Extracting features:  59%|█████▉    | 93/157 [00:06<00:04, 13.57it/s]Extracting features:  61%|██████    | 96/157 [00:06<00:04, 13.16it/s]Extracting features:  64%|██████▎   | 100/157 [00:07<00:04, 12.81it/s]Extracting features:  66%|██████▌   | 104/157 [00:07<00:04, 12.01it/s]Extracting features:  69%|██████▉   | 108/157 [00:07<00:04, 12.11it/s]Extracting features:  71%|███████▏  | 112/157 [00:08<00:03, 12.86it/s]Extracting features:  73%|███████▎  | 115/157 [00:08<00:03, 12.29it/s]Extracting features:  75%|███████▍  | 117/157 [00:08<00:03, 13.19it/s]Extracting features:  76%|███████▌  | 119/157 [00:08<00:03, 11.28it/s]Extracting features:  78%|███████▊  | 123/157 [00:09<00:03,  9.37it/s]Extracting features:  81%|████████  | 127/157 [00:09<00:02, 11.47it/s]Extracting features:  83%|████████▎ | 131/157 [00:09<00:02, 12.78it/s]Extracting features:  86%|████████▌ | 135/157 [00:10<00:01, 13.97it/s]Extracting features:  89%|████████▊ | 139/157 [00:10<00:01, 14.97it/s]Extracting features:  91%|█████████ | 143/157 [00:10<00:00, 15.68it/s]Extracting features:  94%|█████████▎| 147/157 [00:10<00:00, 14.80it/s]Extracting features:  96%|█████████▌| 151/157 [00:11<00:00, 15.46it/s]Extracting features:  99%|█████████▊| 155/157 [00:11<00:00, 15.47it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 13.66it/s]
2024-12-27 20:41:39,613 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:41:39,613 - INFO - Training feature extraction completed in 11.51s
2024-12-27 20:41:39,614 - INFO - Creating model for classifier: SVM
2024-12-27 20:41:39,614 - INFO - Using device: cuda
2024-12-27 20:41:39,614 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-27 20:41:39,614 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:41:39,614 - INFO - Training set processing completed in 0.00s
2024-12-27 20:41:39,614 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:41:39,616 - INFO - Memory usage at start_fit: CPU 3115.8 MB, GPU 47.3 MB
2024-12-27 20:41:39,616 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:41:39,617 - INFO - Number of unique classes: 10
2024-12-27 20:41:39,708 - INFO - Fitted scaler and transformed data
2024-12-27 20:41:39,708 - INFO - Scaling time: 0.09s
2024-12-27 20:41:39,907 - INFO - Epoch 1/25, Train Loss: 0.3861, Val Loss: 0.0363
2024-12-27 20:41:40,078 - INFO - Epoch 2/25, Train Loss: 0.0136, Val Loss: 0.0153
2024-12-27 20:41:40,245 - INFO - Epoch 3/25, Train Loss: 0.0013, Val Loss: 0.0167
2024-12-27 20:41:40,421 - INFO - Epoch 4/25, Train Loss: 0.0005, Val Loss: 0.0115
2024-12-27 20:41:40,421 - INFO - Early stopping triggered at epoch 4
2024-12-27 20:41:40,421 - INFO - Training completed in 0.81s
2024-12-27 20:41:40,422 - INFO - Final memory usage: CPU 3116.5 MB, GPU 48.1 MB
2024-12-27 20:41:40,422 - INFO - Model training completed in 0.81s
2024-12-27 20:41:40,430 - INFO - Prediction completed in 0.01s
2024-12-27 20:41:40,438 - INFO - Poison rate 0.0 completed in 0.82s
2024-12-27 20:41:40,438 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:41:40,438 - INFO - Total number of labels flipped: 47
2024-12-27 20:41:40,439 - INFO - Label flipping completed in 0.00s
2024-12-27 20:41:40,439 - INFO - Training set processing completed in 0.00s
2024-12-27 20:41:40,439 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:41:40,439 - INFO - Memory usage at start_fit: CPU 3116.5 MB, GPU 47.5 MB
2024-12-27 20:41:40,440 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:41:40,440 - INFO - Number of unique classes: 10
2024-12-27 20:41:40,535 - INFO - Fitted scaler and transformed data
2024-12-27 20:41:40,535 - INFO - Scaling time: 0.09s
2024-12-27 20:41:40,723 - INFO - Epoch 1/25, Train Loss: 0.7081, Val Loss: 0.4606
2024-12-27 20:41:40,898 - INFO - Epoch 2/25, Train Loss: 0.2211, Val Loss: 0.4288
2024-12-27 20:41:41,062 - INFO - Epoch 3/25, Train Loss: 0.1654, Val Loss: 0.3890
2024-12-27 20:41:41,225 - INFO - Epoch 4/25, Train Loss: 0.0964, Val Loss: 0.3531
2024-12-27 20:41:41,393 - INFO - Epoch 5/25, Train Loss: 0.0620, Val Loss: 0.3796
2024-12-27 20:41:41,559 - INFO - Epoch 6/25, Train Loss: 0.0454, Val Loss: 0.3517
2024-12-27 20:41:41,559 - INFO - Early stopping triggered at epoch 6
2024-12-27 20:41:41,559 - INFO - Training completed in 1.12s
2024-12-27 20:41:41,560 - INFO - Final memory usage: CPU 3116.5 MB, GPU 48.1 MB
2024-12-27 20:41:41,560 - INFO - Model training completed in 1.12s
2024-12-27 20:41:41,567 - INFO - Prediction completed in 0.01s
2024-12-27 20:41:41,578 - INFO - Poison rate 0.01 completed in 1.14s
2024-12-27 20:41:41,579 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:41:41,579 - INFO - Total number of labels flipped: 136
2024-12-27 20:41:41,580 - INFO - Label flipping completed in 0.00s
2024-12-27 20:41:41,580 - INFO - Training set processing completed in 0.00s
2024-12-27 20:41:41,580 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:41:41,580 - INFO - Memory usage at start_fit: CPU 3116.5 MB, GPU 47.5 MB
2024-12-27 20:41:41,581 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:41:41,581 - INFO - Number of unique classes: 10
2024-12-27 20:41:41,670 - INFO - Fitted scaler and transformed data
2024-12-27 20:41:41,670 - INFO - Scaling time: 0.09s
2024-12-27 20:41:41,852 - INFO - Epoch 1/25, Train Loss: 1.3485, Val Loss: 1.0694
2024-12-27 20:41:42,005 - INFO - Epoch 2/25, Train Loss: 0.5841, Val Loss: 1.0640
2024-12-27 20:41:42,157 - INFO - Epoch 3/25, Train Loss: 0.3373, Val Loss: 0.9116
2024-12-27 20:41:42,341 - INFO - Epoch 4/25, Train Loss: 0.1901, Val Loss: 0.8859
2024-12-27 20:41:42,510 - INFO - Epoch 5/25, Train Loss: 0.1135, Val Loss: 0.8732
2024-12-27 20:41:42,674 - INFO - Epoch 6/25, Train Loss: 0.0690, Val Loss: 0.8302
2024-12-27 20:41:42,837 - INFO - Epoch 7/25, Train Loss: 0.0498, Val Loss: 0.8102
2024-12-27 20:41:43,025 - INFO - Epoch 8/25, Train Loss: 0.0391, Val Loss: 0.9298
2024-12-27 20:41:43,220 - INFO - Epoch 9/25, Train Loss: 0.0330, Val Loss: 0.8778
2024-12-27 20:41:43,220 - INFO - Early stopping triggered at epoch 9
2024-12-27 20:41:43,221 - INFO - Training completed in 1.64s
2024-12-27 20:41:43,222 - INFO - Final memory usage: CPU 3116.5 MB, GPU 48.1 MB
2024-12-27 20:41:43,222 - INFO - Model training completed in 1.64s
2024-12-27 20:41:43,230 - INFO - Prediction completed in 0.01s
2024-12-27 20:41:43,238 - INFO - Poison rate 0.03 completed in 1.66s
2024-12-27 20:41:43,238 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:41:43,239 - INFO - Total number of labels flipped: 230
2024-12-27 20:41:43,239 - INFO - Label flipping completed in 0.00s
2024-12-27 20:41:43,239 - INFO - Training set processing completed in 0.00s
2024-12-27 20:41:43,239 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:41:43,240 - INFO - Memory usage at start_fit: CPU 3116.5 MB, GPU 47.5 MB
2024-12-27 20:41:43,241 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:41:43,241 - INFO - Number of unique classes: 10
2024-12-27 20:41:43,329 - INFO - Fitted scaler and transformed data
2024-12-27 20:41:43,329 - INFO - Scaling time: 0.09s
2024-12-27 20:41:43,539 - INFO - Epoch 1/25, Train Loss: 1.7780, Val Loss: 1.5945
2024-12-27 20:41:43,760 - INFO - Epoch 2/25, Train Loss: 0.8243, Val Loss: 1.4486
2024-12-27 20:41:43,970 - INFO - Epoch 3/25, Train Loss: 0.4580, Val Loss: 1.2313
2024-12-27 20:41:44,164 - INFO - Epoch 4/25, Train Loss: 0.2899, Val Loss: 1.0671
2024-12-27 20:41:44,345 - INFO - Epoch 5/25, Train Loss: 0.1868, Val Loss: 1.0718
2024-12-27 20:41:44,512 - INFO - Epoch 6/25, Train Loss: 0.1390, Val Loss: 1.0817
2024-12-27 20:41:44,513 - INFO - Early stopping triggered at epoch 6
2024-12-27 20:41:44,513 - INFO - Training completed in 1.27s
2024-12-27 20:41:44,513 - INFO - Final memory usage: CPU 3116.5 MB, GPU 48.1 MB
2024-12-27 20:41:44,513 - INFO - Model training completed in 1.27s
2024-12-27 20:41:44,520 - INFO - Prediction completed in 0.01s
2024-12-27 20:41:44,529 - INFO - Poison rate 0.05 completed in 1.29s
2024-12-27 20:41:44,530 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:41:44,530 - INFO - Total number of labels flipped: 324
2024-12-27 20:41:44,531 - INFO - Label flipping completed in 0.00s
2024-12-27 20:41:44,531 - INFO - Training set processing completed in 0.00s
2024-12-27 20:41:44,531 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:41:44,532 - INFO - Memory usage at start_fit: CPU 3116.5 MB, GPU 47.5 MB
2024-12-27 20:41:44,532 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:41:44,532 - INFO - Number of unique classes: 10
2024-12-27 20:41:44,625 - INFO - Fitted scaler and transformed data
2024-12-27 20:41:44,625 - INFO - Scaling time: 0.09s
2024-12-27 20:41:44,840 - INFO - Epoch 1/25, Train Loss: 2.2779, Val Loss: 2.0183
2024-12-27 20:41:45,038 - INFO - Epoch 2/25, Train Loss: 1.1443, Val Loss: 1.7247
2024-12-27 20:41:45,214 - INFO - Epoch 3/25, Train Loss: 0.6190, Val Loss: 1.4883
2024-12-27 20:41:45,398 - INFO - Epoch 4/25, Train Loss: 0.3858, Val Loss: 1.3959
2024-12-27 20:41:45,582 - INFO - Epoch 5/25, Train Loss: 0.2626, Val Loss: 1.4200
2024-12-27 20:41:45,768 - INFO - Epoch 6/25, Train Loss: 0.2141, Val Loss: 1.4085
2024-12-27 20:41:45,768 - INFO - Early stopping triggered at epoch 6
2024-12-27 20:41:45,768 - INFO - Training completed in 1.24s
2024-12-27 20:41:45,768 - INFO - Final memory usage: CPU 3116.5 MB, GPU 48.1 MB
2024-12-27 20:41:45,769 - INFO - Model training completed in 1.24s
2024-12-27 20:41:45,780 - INFO - Prediction completed in 0.01s
2024-12-27 20:41:45,789 - INFO - Poison rate 0.07 completed in 1.26s
2024-12-27 20:41:45,790 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:41:45,790 - INFO - Total number of labels flipped: 446
2024-12-27 20:41:45,790 - INFO - Label flipping completed in 0.00s
2024-12-27 20:41:45,791 - INFO - Training set processing completed in 0.00s
2024-12-27 20:41:45,791 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:41:45,791 - INFO - Memory usage at start_fit: CPU 3116.5 MB, GPU 47.5 MB
2024-12-27 20:41:45,792 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:41:45,792 - INFO - Number of unique classes: 10
2024-12-27 20:41:45,872 - INFO - Fitted scaler and transformed data
2024-12-27 20:41:45,873 - INFO - Scaling time: 0.08s
2024-12-27 20:41:46,056 - INFO - Epoch 1/25, Train Loss: 2.7377, Val Loss: 2.8307
2024-12-27 20:41:46,236 - INFO - Epoch 2/25, Train Loss: 1.3525, Val Loss: 2.5624
2024-12-27 20:41:46,404 - INFO - Epoch 3/25, Train Loss: 0.6926, Val Loss: 2.6484
2024-12-27 20:41:46,586 - INFO - Epoch 4/25, Train Loss: 0.5157, Val Loss: 2.0185
2024-12-27 20:41:46,776 - INFO - Epoch 5/25, Train Loss: 0.4196, Val Loss: 2.2309
2024-12-27 20:41:46,955 - INFO - Epoch 6/25, Train Loss: 0.2868, Val Loss: 2.1153
2024-12-27 20:41:46,956 - INFO - Early stopping triggered at epoch 6
2024-12-27 20:41:46,956 - INFO - Training completed in 1.16s
2024-12-27 20:41:46,956 - INFO - Final memory usage: CPU 3116.5 MB, GPU 48.1 MB
2024-12-27 20:41:46,956 - INFO - Model training completed in 1.17s
2024-12-27 20:41:46,964 - INFO - Prediction completed in 0.01s
2024-12-27 20:41:46,974 - INFO - Poison rate 0.1 completed in 1.18s
2024-12-27 20:41:46,975 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:41:46,977 - INFO - Total number of labels flipped: 904
2024-12-27 20:41:46,977 - INFO - Label flipping completed in 0.00s
2024-12-27 20:41:46,977 - INFO - Training set processing completed in 0.00s
2024-12-27 20:41:46,978 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:41:46,979 - INFO - Memory usage at start_fit: CPU 3116.5 MB, GPU 47.5 MB
2024-12-27 20:41:46,979 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:41:46,980 - INFO - Number of unique classes: 10
2024-12-27 20:41:47,074 - INFO - Fitted scaler and transformed data
2024-12-27 20:41:47,074 - INFO - Scaling time: 0.09s
2024-12-27 20:41:47,283 - INFO - Epoch 1/25, Train Loss: 4.4016, Val Loss: 3.3707
2024-12-27 20:41:47,472 - INFO - Epoch 2/25, Train Loss: 2.1722, Val Loss: 2.5738
2024-12-27 20:41:47,652 - INFO - Epoch 3/25, Train Loss: 1.2623, Val Loss: 2.8105
2024-12-27 20:41:47,857 - INFO - Epoch 4/25, Train Loss: 0.9168, Val Loss: 2.4968
2024-12-27 20:41:48,065 - INFO - Epoch 5/25, Train Loss: 0.6413, Val Loss: 2.4772
2024-12-27 20:41:48,260 - INFO - Epoch 6/25, Train Loss: 0.5984, Val Loss: 2.4938
2024-12-27 20:41:48,452 - INFO - Epoch 7/25, Train Loss: 0.4607, Val Loss: 2.5286
2024-12-27 20:41:48,452 - INFO - Early stopping triggered at epoch 7
2024-12-27 20:41:48,452 - INFO - Training completed in 1.47s
2024-12-27 20:41:48,452 - INFO - Final memory usage: CPU 3116.5 MB, GPU 48.1 MB
2024-12-27 20:41:48,453 - INFO - Model training completed in 1.48s
2024-12-27 20:41:48,464 - INFO - Prediction completed in 0.01s
2024-12-27 20:41:48,479 - INFO - Poison rate 0.2 completed in 1.50s
2024-12-27 20:41:48,480 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:41:48,480 - INFO - Total evaluation time: 22.99s
2024-12-27 20:41:48,482 - INFO - 
Progress: 77.1% - Evaluating ImageNette with SVM (dynadetect mode, iteration 1/1)
2024-12-27 20:41:48,544 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:41:48,619 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:41:48,715 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 20:41:48,715 - INFO - Dataset type: image
2024-12-27 20:41:48,715 - INFO - Sample size: 5000
2024-12-27 20:41:48,715 - INFO - Using device: cuda
2024-12-27 20:41:48,717 - INFO - Loading datasets...
2024-12-27 20:41:48,742 - INFO - Dataset loading completed in 0.02s
2024-12-27 20:41:48,742 - INFO - Extracting validation features...
2024-12-27 20:41:48,742 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:27,  1.11it/s]Extracting features:  16%|█▌        | 5/32 [00:01<00:04,  6.26it/s]Extracting features:  31%|███▏      | 10/32 [00:01<00:01, 11.95it/s]Extracting features:  41%|████      | 13/32 [00:01<00:01, 13.85it/s]Extracting features:  50%|█████     | 16/32 [00:01<00:01, 14.56it/s]Extracting features:  59%|█████▉    | 19/32 [00:01<00:00, 13.37it/s]Extracting features:  66%|██████▌   | 21/32 [00:01<00:00, 14.12it/s]Extracting features:  72%|███████▏  | 23/32 [00:02<00:00, 11.56it/s]Extracting features:  81%|████████▏ | 26/32 [00:02<00:00, 13.47it/s]Extracting features:  88%|████████▊ | 28/32 [00:02<00:00, 14.62it/s]Extracting features:  94%|█████████▍| 30/32 [00:02<00:00, 14.71it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 11.84it/s]
2024-12-27 20:41:51,448 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:41:51,448 - INFO - Validation feature extraction completed in 2.71s
2024-12-27 20:41:51,448 - INFO - Extracting training features...
2024-12-27 20:41:51,448 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:09,  2.24it/s]Extracting features:   3%|▎         | 5/157 [00:00<00:17,  8.61it/s]Extracting features:   5%|▌         | 8/157 [00:00<00:11, 12.49it/s]Extracting features:   6%|▋         | 10/157 [00:01<00:17,  8.36it/s]Extracting features:   8%|▊         | 13/157 [00:01<00:13, 11.01it/s]Extracting features:  10%|▉         | 15/157 [00:01<00:12, 11.66it/s]Extracting features:  11%|█         | 17/157 [00:01<00:11, 12.39it/s]Extracting features:  12%|█▏        | 19/157 [00:01<00:11, 12.10it/s]Extracting features:  13%|█▎        | 21/157 [00:01<00:10, 12.47it/s]Extracting features:  15%|█▌        | 24/157 [00:02<00:08, 15.48it/s]Extracting features:  17%|█▋        | 26/157 [00:02<00:10, 12.54it/s]Extracting features:  18%|█▊        | 29/157 [00:02<00:10, 12.36it/s]Extracting features:  21%|██        | 33/157 [00:02<00:08, 14.81it/s]Extracting features:  24%|██▎       | 37/157 [00:02<00:07, 15.95it/s]Extracting features:  26%|██▌       | 41/157 [00:03<00:06, 17.67it/s]Extracting features:  29%|██▊       | 45/157 [00:03<00:06, 18.28it/s]Extracting features:  31%|███       | 49/157 [00:03<00:05, 18.33it/s]Extracting features:  33%|███▎      | 52/157 [00:03<00:05, 19.89it/s]Extracting features:  35%|███▌      | 55/157 [00:03<00:05, 18.22it/s]Extracting features:  37%|███▋      | 58/157 [00:04<00:05, 18.09it/s]Extracting features:  39%|███▉      | 61/157 [00:04<00:05, 18.31it/s]Extracting features:  40%|████      | 63/157 [00:04<00:05, 18.06it/s]Extracting features:  41%|████▏     | 65/157 [00:04<00:07, 12.34it/s]Extracting features:  44%|████▍     | 69/157 [00:04<00:06, 12.81it/s]Extracting features:  46%|████▋     | 73/157 [00:05<00:06, 13.27it/s]Extracting features:  49%|████▉     | 77/157 [00:05<00:06, 13.12it/s]Extracting features:  52%|█████▏    | 81/157 [00:05<00:05, 12.81it/s]Extracting features:  53%|█████▎    | 83/157 [00:06<00:05, 13.48it/s]Extracting features:  54%|█████▍    | 85/157 [00:06<00:05, 12.89it/s]Extracting features:  55%|█████▌    | 87/157 [00:06<00:05, 13.23it/s]Extracting features:  57%|█████▋    | 89/157 [00:06<00:06, 10.64it/s]Extracting features:  59%|█████▉    | 93/157 [00:06<00:05, 11.80it/s]Extracting features:  62%|██████▏   | 97/157 [00:07<00:05, 11.57it/s]Extracting features:  64%|██████▍   | 101/157 [00:07<00:04, 12.34it/s]Extracting features:  67%|██████▋   | 105/157 [00:07<00:04, 12.07it/s]Extracting features:  69%|██████▉   | 109/157 [00:08<00:04, 11.96it/s]Extracting features:  72%|███████▏  | 113/157 [00:08<00:03, 12.63it/s]Extracting features:  75%|███████▍  | 117/157 [00:08<00:02, 13.45it/s]Extracting features:  77%|███████▋  | 121/157 [00:09<00:02, 13.32it/s]Extracting features:  80%|███████▉  | 125/157 [00:09<00:02, 12.79it/s]Extracting features:  82%|████████▏ | 129/157 [00:09<00:01, 14.00it/s]Extracting features:  85%|████████▍ | 133/157 [00:09<00:01, 15.90it/s]Extracting features:  87%|████████▋ | 137/157 [00:10<00:01, 16.15it/s]Extracting features:  90%|████████▉ | 141/157 [00:10<00:00, 16.59it/s]Extracting features:  92%|█████████▏| 145/157 [00:10<00:00, 16.75it/s]Extracting features:  95%|█████████▍| 149/157 [00:10<00:00, 15.59it/s]Extracting features:  97%|█████████▋| 153/157 [00:11<00:00, 14.96it/s]Extracting features:  99%|█████████▊| 155/157 [00:11<00:00, 15.62it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 13.89it/s]
2024-12-27 20:42:02,769 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:42:02,769 - INFO - Training feature extraction completed in 11.32s
2024-12-27 20:42:02,769 - INFO - Creating model for classifier: SVM
2024-12-27 20:42:02,769 - INFO - Using device: cuda
2024-12-27 20:42:02,769 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-27 20:42:02,769 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:42:02,769 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:42:02,769 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:42:03,393 - INFO - Feature scaling completed in 0.62s
2024-12-27 20:42:03,393 - INFO - Starting feature selection (k=50)
2024-12-27 20:42:03,402 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:42:03,402 - INFO - Starting anomaly detection
2024-12-27 20:42:04,947 - INFO - Anomaly detection completed in 1.55s
2024-12-27 20:42:04,948 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:42:04,948 - INFO - Total fit_transform time: 2.18s
2024-12-27 20:42:04,948 - INFO - Training set processing completed in 2.18s
2024-12-27 20:42:04,948 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:42:04,949 - INFO - Memory usage at start_fit: CPU 3109.7 MB, GPU 47.3 MB
2024-12-27 20:42:04,949 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:42:04,949 - INFO - Number of unique classes: 10
2024-12-27 20:42:05,047 - INFO - Fitted scaler and transformed data
2024-12-27 20:42:05,048 - INFO - Scaling time: 0.10s
2024-12-27 20:42:05,242 - INFO - Epoch 1/25, Train Loss: 0.4159, Val Loss: 0.0510
2024-12-27 20:42:05,414 - INFO - Epoch 2/25, Train Loss: 0.0132, Val Loss: 0.0352
2024-12-27 20:42:05,576 - INFO - Epoch 3/25, Train Loss: 0.0006, Val Loss: 0.0338
2024-12-27 20:42:05,763 - INFO - Epoch 4/25, Train Loss: 0.0000, Val Loss: 0.0350
2024-12-27 20:42:05,763 - INFO - Early stopping triggered at epoch 4
2024-12-27 20:42:05,764 - INFO - Training completed in 0.82s
2024-12-27 20:42:05,764 - INFO - Final memory usage: CPU 3113.5 MB, GPU 48.1 MB
2024-12-27 20:42:05,764 - INFO - Model training completed in 0.82s
2024-12-27 20:42:05,775 - INFO - Prediction completed in 0.01s
2024-12-27 20:42:05,785 - INFO - Poison rate 0.0 completed in 3.02s
2024-12-27 20:42:05,785 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:42:05,786 - INFO - Total number of labels flipped: 46
2024-12-27 20:42:05,786 - INFO - Label flipping completed in 0.00s
2024-12-27 20:42:05,786 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:42:05,786 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:42:06,338 - INFO - Feature scaling completed in 0.55s
2024-12-27 20:42:06,338 - INFO - Starting feature selection (k=50)
2024-12-27 20:42:06,344 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:42:06,344 - INFO - Starting anomaly detection
2024-12-27 20:42:08,023 - INFO - Anomaly detection completed in 1.68s
2024-12-27 20:42:08,024 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:42:08,024 - INFO - Total fit_transform time: 2.24s
2024-12-27 20:42:08,024 - INFO - Training set processing completed in 2.24s
2024-12-27 20:42:08,024 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:42:08,025 - INFO - Memory usage at start_fit: CPU 3113.5 MB, GPU 47.5 MB
2024-12-27 20:42:08,026 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:42:08,026 - INFO - Number of unique classes: 10
2024-12-27 20:42:08,123 - INFO - Fitted scaler and transformed data
2024-12-27 20:42:08,123 - INFO - Scaling time: 0.09s
2024-12-27 20:42:08,329 - INFO - Epoch 1/25, Train Loss: 0.7094, Val Loss: 0.1306
2024-12-27 20:42:08,502 - INFO - Epoch 2/25, Train Loss: 0.1949, Val Loss: 0.1375
2024-12-27 20:42:08,677 - INFO - Epoch 3/25, Train Loss: 0.1129, Val Loss: 0.1521
2024-12-27 20:42:08,677 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:42:08,677 - INFO - Training completed in 0.65s
2024-12-27 20:42:08,677 - INFO - Final memory usage: CPU 3113.5 MB, GPU 48.1 MB
2024-12-27 20:42:08,677 - INFO - Model training completed in 0.65s
2024-12-27 20:42:08,687 - INFO - Prediction completed in 0.01s
2024-12-27 20:42:08,700 - INFO - Poison rate 0.01 completed in 2.92s
2024-12-27 20:42:08,700 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:42:08,701 - INFO - Total number of labels flipped: 138
2024-12-27 20:42:08,701 - INFO - Label flipping completed in 0.00s
2024-12-27 20:42:08,701 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:42:08,701 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:42:09,317 - INFO - Feature scaling completed in 0.62s
2024-12-27 20:42:09,318 - INFO - Starting feature selection (k=50)
2024-12-27 20:42:09,331 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:42:09,331 - INFO - Starting anomaly detection
2024-12-27 20:42:11,434 - INFO - Anomaly detection completed in 2.10s
2024-12-27 20:42:11,435 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:42:11,435 - INFO - Total fit_transform time: 2.73s
2024-12-27 20:42:11,435 - INFO - Training set processing completed in 2.73s
2024-12-27 20:42:11,435 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:42:11,436 - INFO - Memory usage at start_fit: CPU 3113.5 MB, GPU 47.5 MB
2024-12-27 20:42:11,436 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:42:11,436 - INFO - Number of unique classes: 10
2024-12-27 20:42:11,526 - INFO - Fitted scaler and transformed data
2024-12-27 20:42:11,526 - INFO - Scaling time: 0.09s
2024-12-27 20:42:11,769 - INFO - Epoch 1/25, Train Loss: 1.1365, Val Loss: 1.3353
2024-12-27 20:42:11,950 - INFO - Epoch 2/25, Train Loss: 0.5525, Val Loss: 1.1014
2024-12-27 20:42:12,124 - INFO - Epoch 3/25, Train Loss: 0.3111, Val Loss: 1.0405
2024-12-27 20:42:12,321 - INFO - Epoch 4/25, Train Loss: 0.1596, Val Loss: 1.1092
2024-12-27 20:42:12,488 - INFO - Epoch 5/25, Train Loss: 0.0953, Val Loss: 1.0004
2024-12-27 20:42:12,695 - INFO - Epoch 6/25, Train Loss: 0.0839, Val Loss: 1.0598
2024-12-27 20:42:12,917 - INFO - Epoch 7/25, Train Loss: 0.0527, Val Loss: 1.1303
2024-12-27 20:42:12,917 - INFO - Early stopping triggered at epoch 7
2024-12-27 20:42:12,918 - INFO - Training completed in 1.48s
2024-12-27 20:42:12,918 - INFO - Final memory usage: CPU 3113.5 MB, GPU 48.1 MB
2024-12-27 20:42:12,919 - INFO - Model training completed in 1.48s
2024-12-27 20:42:12,934 - INFO - Prediction completed in 0.01s
2024-12-27 20:42:12,944 - INFO - Poison rate 0.03 completed in 4.24s
2024-12-27 20:42:12,945 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:42:12,945 - INFO - Total number of labels flipped: 215
2024-12-27 20:42:12,946 - INFO - Label flipping completed in 0.00s
2024-12-27 20:42:12,946 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:42:12,946 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:42:13,562 - INFO - Feature scaling completed in 0.62s
2024-12-27 20:42:13,562 - INFO - Starting feature selection (k=50)
2024-12-27 20:42:13,578 - INFO - Feature selection completed in 0.02s. Output shape: (5000, 50)
2024-12-27 20:42:13,578 - INFO - Starting anomaly detection
2024-12-27 20:42:15,352 - INFO - Anomaly detection completed in 1.77s
2024-12-27 20:42:15,352 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:42:15,352 - INFO - Total fit_transform time: 2.41s
2024-12-27 20:42:15,352 - INFO - Training set processing completed in 2.41s
2024-12-27 20:42:15,352 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:42:15,353 - INFO - Memory usage at start_fit: CPU 3113.5 MB, GPU 47.5 MB
2024-12-27 20:42:15,354 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:42:15,354 - INFO - Number of unique classes: 10
2024-12-27 20:42:15,447 - INFO - Fitted scaler and transformed data
2024-12-27 20:42:15,447 - INFO - Scaling time: 0.09s
2024-12-27 20:42:15,643 - INFO - Epoch 1/25, Train Loss: 1.5853, Val Loss: 1.9242
2024-12-27 20:42:15,830 - INFO - Epoch 2/25, Train Loss: 0.8187, Val Loss: 1.4113
2024-12-27 20:42:16,008 - INFO - Epoch 3/25, Train Loss: 0.4756, Val Loss: 1.7760
2024-12-27 20:42:16,180 - INFO - Epoch 4/25, Train Loss: 0.2536, Val Loss: 1.5835
2024-12-27 20:42:16,180 - INFO - Early stopping triggered at epoch 4
2024-12-27 20:42:16,180 - INFO - Training completed in 0.83s
2024-12-27 20:42:16,181 - INFO - Final memory usage: CPU 3113.5 MB, GPU 48.1 MB
2024-12-27 20:42:16,181 - INFO - Model training completed in 0.83s
2024-12-27 20:42:16,190 - INFO - Prediction completed in 0.01s
2024-12-27 20:42:16,199 - INFO - Poison rate 0.05 completed in 3.25s
2024-12-27 20:42:16,200 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:42:16,200 - INFO - Total number of labels flipped: 328
2024-12-27 20:42:16,201 - INFO - Label flipping completed in 0.00s
2024-12-27 20:42:16,201 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:42:16,201 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:42:16,741 - INFO - Feature scaling completed in 0.54s
2024-12-27 20:42:16,741 - INFO - Starting feature selection (k=50)
2024-12-27 20:42:16,749 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:42:16,749 - INFO - Starting anomaly detection
2024-12-27 20:42:18,715 - INFO - Anomaly detection completed in 1.97s
2024-12-27 20:42:18,716 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:42:18,716 - INFO - Total fit_transform time: 2.52s
2024-12-27 20:42:18,716 - INFO - Training set processing completed in 2.52s
2024-12-27 20:42:18,716 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:42:18,717 - INFO - Memory usage at start_fit: CPU 3113.5 MB, GPU 47.5 MB
2024-12-27 20:42:18,717 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:42:18,718 - INFO - Number of unique classes: 10
2024-12-27 20:42:18,816 - INFO - Fitted scaler and transformed data
2024-12-27 20:42:18,817 - INFO - Scaling time: 0.10s
2024-12-27 20:42:19,012 - INFO - Epoch 1/25, Train Loss: 2.3776, Val Loss: 2.0323
2024-12-27 20:42:19,187 - INFO - Epoch 2/25, Train Loss: 1.0824, Val Loss: 1.6422
2024-12-27 20:42:19,350 - INFO - Epoch 3/25, Train Loss: 0.5497, Val Loss: 1.6336
2024-12-27 20:42:19,513 - INFO - Epoch 4/25, Train Loss: 0.3797, Val Loss: 1.8403
2024-12-27 20:42:19,513 - INFO - Early stopping triggered at epoch 4
2024-12-27 20:42:19,513 - INFO - Training completed in 0.80s
2024-12-27 20:42:19,513 - INFO - Final memory usage: CPU 3113.5 MB, GPU 48.1 MB
2024-12-27 20:42:19,514 - INFO - Model training completed in 0.80s
2024-12-27 20:42:19,523 - INFO - Prediction completed in 0.01s
2024-12-27 20:42:19,534 - INFO - Poison rate 0.07 completed in 3.33s
2024-12-27 20:42:19,534 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:42:19,535 - INFO - Total number of labels flipped: 451
2024-12-27 20:42:19,535 - INFO - Label flipping completed in 0.00s
2024-12-27 20:42:19,535 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:42:19,535 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:42:20,154 - INFO - Feature scaling completed in 0.62s
2024-12-27 20:42:20,154 - INFO - Starting feature selection (k=50)
2024-12-27 20:42:20,168 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:42:20,168 - INFO - Starting anomaly detection
2024-12-27 20:42:21,951 - INFO - Anomaly detection completed in 1.78s
2024-12-27 20:42:21,952 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:42:21,952 - INFO - Total fit_transform time: 2.42s
2024-12-27 20:42:21,952 - INFO - Training set processing completed in 2.42s
2024-12-27 20:42:21,952 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:42:21,953 - INFO - Memory usage at start_fit: CPU 3113.5 MB, GPU 47.5 MB
2024-12-27 20:42:21,953 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:42:21,954 - INFO - Number of unique classes: 10
2024-12-27 20:42:22,045 - INFO - Fitted scaler and transformed data
2024-12-27 20:42:22,045 - INFO - Scaling time: 0.09s
2024-12-27 20:42:22,274 - INFO - Epoch 1/25, Train Loss: 2.7939, Val Loss: 2.7816
2024-12-27 20:42:22,467 - INFO - Epoch 2/25, Train Loss: 1.5058, Val Loss: 2.4040
2024-12-27 20:42:22,647 - INFO - Epoch 3/25, Train Loss: 0.8156, Val Loss: 2.3655
2024-12-27 20:42:22,823 - INFO - Epoch 4/25, Train Loss: 0.5043, Val Loss: 2.5488
2024-12-27 20:42:23,007 - INFO - Epoch 5/25, Train Loss: 0.4030, Val Loss: 2.4551
2024-12-27 20:42:23,008 - INFO - Early stopping triggered at epoch 5
2024-12-27 20:42:23,008 - INFO - Training completed in 1.05s
2024-12-27 20:42:23,008 - INFO - Final memory usage: CPU 3113.5 MB, GPU 48.1 MB
2024-12-27 20:42:23,008 - INFO - Model training completed in 1.06s
2024-12-27 20:42:23,017 - INFO - Prediction completed in 0.01s
2024-12-27 20:42:23,026 - INFO - Poison rate 0.1 completed in 3.49s
2024-12-27 20:42:23,026 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:42:23,027 - INFO - Total number of labels flipped: 902
2024-12-27 20:42:23,027 - INFO - Label flipping completed in 0.00s
2024-12-27 20:42:23,027 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:42:23,027 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:42:23,624 - INFO - Feature scaling completed in 0.60s
2024-12-27 20:42:23,625 - INFO - Starting feature selection (k=50)
2024-12-27 20:42:23,647 - INFO - Feature selection completed in 0.02s. Output shape: (5000, 50)
2024-12-27 20:42:23,648 - INFO - Starting anomaly detection
2024-12-27 20:42:25,506 - INFO - Anomaly detection completed in 1.86s
2024-12-27 20:42:25,506 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:42:25,506 - INFO - Total fit_transform time: 2.48s
2024-12-27 20:42:25,507 - INFO - Training set processing completed in 2.48s
2024-12-27 20:42:25,507 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:42:25,508 - INFO - Memory usage at start_fit: CPU 3113.5 MB, GPU 47.5 MB
2024-12-27 20:42:25,508 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:42:25,508 - INFO - Number of unique classes: 10
2024-12-27 20:42:25,615 - INFO - Fitted scaler and transformed data
2024-12-27 20:42:25,615 - INFO - Scaling time: 0.11s
2024-12-27 20:42:25,809 - INFO - Epoch 1/25, Train Loss: 4.2474, Val Loss: 3.2618
2024-12-27 20:42:25,995 - INFO - Epoch 2/25, Train Loss: 1.9825, Val Loss: 2.6497
2024-12-27 20:42:26,169 - INFO - Epoch 3/25, Train Loss: 1.3050, Val Loss: 2.7402
2024-12-27 20:42:26,336 - INFO - Epoch 4/25, Train Loss: 0.9360, Val Loss: 2.5947
2024-12-27 20:42:26,503 - INFO - Epoch 5/25, Train Loss: 0.6434, Val Loss: 2.2990
2024-12-27 20:42:26,681 - INFO - Epoch 6/25, Train Loss: 0.5480, Val Loss: 2.3599
2024-12-27 20:42:26,859 - INFO - Epoch 7/25, Train Loss: 0.5132, Val Loss: 2.3124
2024-12-27 20:42:26,859 - INFO - Early stopping triggered at epoch 7
2024-12-27 20:42:26,859 - INFO - Training completed in 1.35s
2024-12-27 20:42:26,859 - INFO - Final memory usage: CPU 3113.5 MB, GPU 48.1 MB
2024-12-27 20:42:26,859 - INFO - Model training completed in 1.35s
2024-12-27 20:42:26,867 - INFO - Prediction completed in 0.01s
2024-12-27 20:42:26,875 - INFO - Poison rate 0.2 completed in 3.85s
2024-12-27 20:42:26,875 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:42:26,875 - INFO - Total evaluation time: 38.16s
2024-12-27 20:42:26,877 - INFO - 
Progress: 78.1% - Evaluating ImageNette with LogisticRegression (standard mode, iteration 1/1)
2024-12-27 20:42:26,942 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:42:27,113 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:42:27,217 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 20:42:27,217 - INFO - Dataset type: image
2024-12-27 20:42:27,217 - INFO - Sample size: 5000
2024-12-27 20:42:27,217 - INFO - Using device: cuda
2024-12-27 20:42:27,219 - INFO - Loading datasets...
2024-12-27 20:42:27,244 - INFO - Dataset loading completed in 0.02s
2024-12-27 20:42:27,244 - INFO - Extracting validation features...
2024-12-27 20:42:27,244 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:18,  1.69it/s]Extracting features:  19%|█▉        | 6/32 [00:00<00:02, 10.81it/s]Extracting features:  28%|██▊       | 9/32 [00:00<00:01, 14.35it/s]Extracting features:  38%|███▊      | 12/32 [00:01<00:01, 14.37it/s]Extracting features:  47%|████▋     | 15/32 [00:01<00:01, 12.99it/s]Extracting features:  53%|█████▎    | 17/32 [00:01<00:01, 12.52it/s]Extracting features:  59%|█████▉    | 19/32 [00:01<00:01, 12.89it/s]Extracting features:  66%|██████▌   | 21/32 [00:01<00:00, 12.01it/s]Extracting features:  72%|███████▏  | 23/32 [00:01<00:00, 12.28it/s]Extracting features:  78%|███████▊  | 25/32 [00:02<00:00, 13.44it/s]Extracting features:  84%|████████▍ | 27/32 [00:02<00:00, 14.62it/s]Extracting features:  94%|█████████▍| 30/32 [00:02<00:00, 18.04it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 13.21it/s]
2024-12-27 20:42:29,673 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:42:29,674 - INFO - Validation feature extraction completed in 2.43s
2024-12-27 20:42:29,674 - INFO - Extracting training features...
2024-12-27 20:42:29,674 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:13,  2.13it/s]Extracting features:   1%|▏         | 2/157 [00:00<00:41,  3.74it/s]Extracting features:   3%|▎         | 5/157 [00:00<00:15,  9.97it/s]Extracting features:   4%|▍         | 7/157 [00:00<00:16,  9.22it/s]Extracting features:   6%|▋         | 10/157 [00:01<00:16,  9.12it/s]Extracting features:   9%|▉         | 14/157 [00:01<00:12, 11.86it/s]Extracting features:  11%|█         | 17/157 [00:01<00:09, 14.17it/s]Extracting features:  12%|█▏        | 19/157 [00:01<00:10, 13.58it/s]Extracting features:  14%|█▍        | 22/157 [00:02<00:09, 13.65it/s]Extracting features:  16%|█▌        | 25/157 [00:02<00:07, 16.57it/s]Extracting features:  17%|█▋        | 27/157 [00:02<00:08, 15.14it/s]Extracting features:  18%|█▊        | 29/157 [00:02<00:08, 15.13it/s]Extracting features:  20%|█▉        | 31/157 [00:02<00:07, 15.87it/s]Extracting features:  22%|██▏       | 34/157 [00:02<00:08, 14.47it/s]Extracting features:  24%|██▍       | 38/157 [00:02<00:07, 15.99it/s]Extracting features:  27%|██▋       | 42/157 [00:03<00:06, 17.39it/s]Extracting features:  29%|██▉       | 46/157 [00:03<00:06, 17.09it/s]Extracting features:  32%|███▏      | 50/157 [00:03<00:06, 17.80it/s]Extracting features:  34%|███▍      | 54/157 [00:03<00:06, 16.49it/s]Extracting features:  37%|███▋      | 58/157 [00:04<00:05, 17.70it/s]Extracting features:  39%|███▉      | 62/157 [00:04<00:05, 17.65it/s]Extracting features:  42%|████▏     | 66/157 [00:04<00:05, 17.07it/s]Extracting features:  45%|████▍     | 70/157 [00:04<00:05, 16.89it/s]Extracting features:  46%|████▌     | 72/157 [00:04<00:05, 16.95it/s]Extracting features:  47%|████▋     | 74/157 [00:05<00:05, 15.93it/s]Extracting features:  49%|████▉     | 77/157 [00:05<00:04, 17.13it/s]Extracting features:  50%|█████     | 79/157 [00:05<00:05, 15.22it/s]Extracting features:  52%|█████▏    | 81/157 [00:05<00:05, 14.59it/s]Extracting features:  53%|█████▎    | 83/157 [00:05<00:05, 14.57it/s]Extracting features:  54%|█████▍    | 85/157 [00:05<00:04, 15.11it/s]Extracting features:  55%|█████▌    | 87/157 [00:06<00:06, 10.85it/s]Extracting features:  57%|█████▋    | 90/157 [00:06<00:07,  9.47it/s]Extracting features:  60%|█████▉    | 94/157 [00:06<00:05, 11.18it/s]Extracting features:  62%|██████▏   | 98/157 [00:07<00:04, 13.07it/s]Extracting features:  64%|██████▍   | 101/157 [00:07<00:03, 15.06it/s]Extracting features:  66%|██████▌   | 103/157 [00:07<00:03, 14.09it/s]Extracting features:  67%|██████▋   | 105/157 [00:07<00:04, 12.78it/s]Extracting features:  68%|██████▊   | 107/157 [00:07<00:03, 13.96it/s]Extracting features:  69%|██████▉   | 109/157 [00:07<00:04, 11.67it/s]Extracting features:  72%|███████▏  | 113/157 [00:08<00:04, 10.14it/s]Extracting features:  75%|███████▍  | 117/157 [00:08<00:03, 10.42it/s]Extracting features:  77%|███████▋  | 121/157 [00:09<00:03, 10.53it/s]Extracting features:  80%|███████▉  | 125/157 [00:09<00:02, 11.39it/s]Extracting features:  82%|████████▏ | 129/157 [00:09<00:02, 13.39it/s]Extracting features:  85%|████████▍ | 133/157 [00:09<00:01, 14.24it/s]Extracting features:  87%|████████▋ | 137/157 [00:09<00:01, 15.71it/s]Extracting features:  90%|████████▉ | 141/157 [00:10<00:00, 16.65it/s]Extracting features:  91%|█████████ | 143/157 [00:10<00:00, 15.15it/s]Extracting features:  93%|█████████▎| 146/157 [00:10<00:00, 15.61it/s]Extracting features:  95%|█████████▍| 149/157 [00:10<00:00, 17.24it/s]Extracting features:  96%|█████████▌| 151/157 [00:10<00:00, 16.89it/s]Extracting features:  97%|█████████▋| 153/157 [00:11<00:00, 14.44it/s]Extracting features:  99%|█████████▉| 156/157 [00:11<00:00, 16.85it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 13.97it/s]
2024-12-27 20:42:40,929 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:42:40,930 - INFO - Training feature extraction completed in 11.26s
2024-12-27 20:42:40,930 - INFO - Creating model for classifier: LogisticRegression
2024-12-27 20:42:40,930 - INFO - Using device: cuda
2024-12-27 20:42:40,930 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:42:40,930 - INFO - Training set processing completed in 0.00s
2024-12-27 20:42:40,930 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:42:40,931 - INFO - Memory usage at start_fit: CPU 3110.8 MB, GPU 47.3 MB
2024-12-27 20:42:40,932 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:42:40,932 - INFO - Number of unique classes: 10
2024-12-27 20:42:41,035 - INFO - Fitted scaler and transformed data
2024-12-27 20:42:41,035 - INFO - Scaling time: 0.10s
2024-12-27 20:42:41,179 - INFO - Epoch 1/200, Train Loss: 0.1206, Val Loss: 0.0206
2024-12-27 20:42:41,328 - INFO - Epoch 2/200, Train Loss: 0.0038, Val Loss: 0.0340
2024-12-27 20:42:41,519 - INFO - Epoch 3/200, Train Loss: 0.0003, Val Loss: 0.0239
2024-12-27 20:42:41,519 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:42:41,519 - INFO - Training completed in 0.59s
2024-12-27 20:42:41,520 - INFO - Final memory usage: CPU 3118.6 MB, GPU 48.1 MB
2024-12-27 20:42:41,520 - INFO - Model training completed in 0.59s
2024-12-27 20:42:41,539 - INFO - Prediction completed in 0.02s
2024-12-27 20:42:41,553 - INFO - Poison rate 0.0 completed in 0.62s
2024-12-27 20:42:41,554 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:42:41,554 - INFO - Total number of labels flipped: 47
2024-12-27 20:42:41,555 - INFO - Label flipping completed in 0.00s
2024-12-27 20:42:41,555 - INFO - Training set processing completed in 0.00s
2024-12-27 20:42:41,555 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:42:41,556 - INFO - Memory usage at start_fit: CPU 3118.6 MB, GPU 47.5 MB
2024-12-27 20:42:41,556 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:42:41,557 - INFO - Number of unique classes: 10
2024-12-27 20:42:41,649 - INFO - Fitted scaler and transformed data
2024-12-27 20:42:41,649 - INFO - Scaling time: 0.09s
2024-12-27 20:42:41,794 - INFO - Epoch 1/200, Train Loss: 0.3139, Val Loss: 0.0983
2024-12-27 20:42:41,909 - INFO - Epoch 2/200, Train Loss: 0.1394, Val Loss: 0.0715
2024-12-27 20:42:42,032 - INFO - Epoch 3/200, Train Loss: 0.0431, Val Loss: 0.0922
2024-12-27 20:42:42,139 - INFO - Epoch 4/200, Train Loss: 0.0168, Val Loss: 0.0953
2024-12-27 20:42:42,140 - INFO - Early stopping triggered at epoch 4
2024-12-27 20:42:42,140 - INFO - Training completed in 0.58s
2024-12-27 20:42:42,140 - INFO - Final memory usage: CPU 3118.6 MB, GPU 48.1 MB
2024-12-27 20:42:42,140 - INFO - Model training completed in 0.59s
2024-12-27 20:42:42,147 - INFO - Prediction completed in 0.01s
2024-12-27 20:42:42,159 - INFO - Poison rate 0.01 completed in 0.60s
2024-12-27 20:42:42,159 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:42:42,160 - INFO - Total number of labels flipped: 126
2024-12-27 20:42:42,160 - INFO - Label flipping completed in 0.00s
2024-12-27 20:42:42,160 - INFO - Training set processing completed in 0.00s
2024-12-27 20:42:42,160 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:42:42,161 - INFO - Memory usage at start_fit: CPU 3118.6 MB, GPU 47.5 MB
2024-12-27 20:42:42,161 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:42:42,161 - INFO - Number of unique classes: 10
2024-12-27 20:42:42,252 - INFO - Fitted scaler and transformed data
2024-12-27 20:42:42,253 - INFO - Scaling time: 0.09s
2024-12-27 20:42:42,377 - INFO - Epoch 1/200, Train Loss: 0.5825, Val Loss: 0.5061
2024-12-27 20:42:42,489 - INFO - Epoch 2/200, Train Loss: 0.2116, Val Loss: 0.3937
2024-12-27 20:42:42,604 - INFO - Epoch 3/200, Train Loss: 0.1061, Val Loss: 0.4539
2024-12-27 20:42:42,743 - INFO - Epoch 4/200, Train Loss: 0.0553, Val Loss: 0.4993
2024-12-27 20:42:42,743 - INFO - Early stopping triggered at epoch 4
2024-12-27 20:42:42,744 - INFO - Training completed in 0.58s
2024-12-27 20:42:42,744 - INFO - Final memory usage: CPU 3118.6 MB, GPU 48.1 MB
2024-12-27 20:42:42,744 - INFO - Model training completed in 0.58s
2024-12-27 20:42:42,751 - INFO - Prediction completed in 0.01s
2024-12-27 20:42:42,760 - INFO - Poison rate 0.03 completed in 0.60s
2024-12-27 20:42:42,761 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:42:42,762 - INFO - Total number of labels flipped: 227
2024-12-27 20:42:42,763 - INFO - Label flipping completed in 0.00s
2024-12-27 20:42:42,763 - INFO - Training set processing completed in 0.00s
2024-12-27 20:42:42,763 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:42:42,765 - INFO - Memory usage at start_fit: CPU 3118.6 MB, GPU 47.5 MB
2024-12-27 20:42:42,765 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:42:42,766 - INFO - Number of unique classes: 10
2024-12-27 20:42:42,852 - INFO - Fitted scaler and transformed data
2024-12-27 20:42:42,852 - INFO - Scaling time: 0.08s
2024-12-27 20:42:42,982 - INFO - Epoch 1/200, Train Loss: 0.7471, Val Loss: 0.5999
2024-12-27 20:42:43,099 - INFO - Epoch 2/200, Train Loss: 0.2919, Val Loss: 0.6472
2024-12-27 20:42:43,226 - INFO - Epoch 3/200, Train Loss: 0.1451, Val Loss: 0.5641
2024-12-27 20:42:43,346 - INFO - Epoch 4/200, Train Loss: 0.0888, Val Loss: 0.6077
2024-12-27 20:42:43,464 - INFO - Epoch 5/200, Train Loss: 0.1219, Val Loss: 0.6690
2024-12-27 20:42:43,464 - INFO - Early stopping triggered at epoch 5
2024-12-27 20:42:43,464 - INFO - Training completed in 0.70s
2024-12-27 20:42:43,465 - INFO - Final memory usage: CPU 3118.6 MB, GPU 48.1 MB
2024-12-27 20:42:43,465 - INFO - Model training completed in 0.70s
2024-12-27 20:42:43,472 - INFO - Prediction completed in 0.01s
2024-12-27 20:42:43,480 - INFO - Poison rate 0.05 completed in 0.72s
2024-12-27 20:42:43,480 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:42:43,480 - INFO - Total number of labels flipped: 319
2024-12-27 20:42:43,481 - INFO - Label flipping completed in 0.00s
2024-12-27 20:42:43,481 - INFO - Training set processing completed in 0.00s
2024-12-27 20:42:43,481 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:42:43,482 - INFO - Memory usage at start_fit: CPU 3118.6 MB, GPU 47.5 MB
2024-12-27 20:42:43,482 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:42:43,483 - INFO - Number of unique classes: 10
2024-12-27 20:42:43,586 - INFO - Fitted scaler and transformed data
2024-12-27 20:42:43,586 - INFO - Scaling time: 0.10s
2024-12-27 20:42:43,724 - INFO - Epoch 1/200, Train Loss: 0.9392, Val Loss: 0.5217
2024-12-27 20:42:43,848 - INFO - Epoch 2/200, Train Loss: 0.4029, Val Loss: 0.5749
2024-12-27 20:42:43,958 - INFO - Epoch 3/200, Train Loss: 0.2635, Val Loss: 0.5315
2024-12-27 20:42:43,958 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:42:43,958 - INFO - Training completed in 0.48s
2024-12-27 20:42:43,958 - INFO - Final memory usage: CPU 3118.6 MB, GPU 48.1 MB
2024-12-27 20:42:43,959 - INFO - Model training completed in 0.48s
2024-12-27 20:42:43,965 - INFO - Prediction completed in 0.01s
2024-12-27 20:42:43,986 - INFO - Poison rate 0.07 completed in 0.51s
2024-12-27 20:42:43,986 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:42:43,988 - INFO - Total number of labels flipped: 446
2024-12-27 20:42:43,988 - INFO - Label flipping completed in 0.00s
2024-12-27 20:42:43,989 - INFO - Training set processing completed in 0.00s
2024-12-27 20:42:43,989 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:42:43,990 - INFO - Memory usage at start_fit: CPU 3118.6 MB, GPU 47.5 MB
2024-12-27 20:42:43,991 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:42:43,992 - INFO - Number of unique classes: 10
2024-12-27 20:42:44,072 - INFO - Fitted scaler and transformed data
2024-12-27 20:42:44,072 - INFO - Scaling time: 0.08s
2024-12-27 20:42:44,200 - INFO - Epoch 1/200, Train Loss: 0.9740, Val Loss: 0.8514
2024-12-27 20:42:44,317 - INFO - Epoch 2/200, Train Loss: 0.5095, Val Loss: 0.8760
2024-12-27 20:42:44,426 - INFO - Epoch 3/200, Train Loss: 0.3563, Val Loss: 0.8686
2024-12-27 20:42:44,427 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:42:44,427 - INFO - Training completed in 0.44s
2024-12-27 20:42:44,428 - INFO - Final memory usage: CPU 3118.6 MB, GPU 48.1 MB
2024-12-27 20:42:44,428 - INFO - Model training completed in 0.44s
2024-12-27 20:42:44,443 - INFO - Prediction completed in 0.01s
2024-12-27 20:42:44,461 - INFO - Poison rate 0.1 completed in 0.47s
2024-12-27 20:42:44,461 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:42:44,463 - INFO - Total number of labels flipped: 906
2024-12-27 20:42:44,463 - INFO - Label flipping completed in 0.00s
2024-12-27 20:42:44,463 - INFO - Training set processing completed in 0.00s
2024-12-27 20:42:44,463 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:42:44,464 - INFO - Memory usage at start_fit: CPU 3118.6 MB, GPU 47.5 MB
2024-12-27 20:42:44,465 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:42:44,465 - INFO - Number of unique classes: 10
2024-12-27 20:42:44,556 - INFO - Fitted scaler and transformed data
2024-12-27 20:42:44,556 - INFO - Scaling time: 0.09s
2024-12-27 20:42:44,684 - INFO - Epoch 1/200, Train Loss: 1.4928, Val Loss: 1.3112
2024-12-27 20:42:44,805 - INFO - Epoch 2/200, Train Loss: 0.8617, Val Loss: 1.4260
2024-12-27 20:42:44,914 - INFO - Epoch 3/200, Train Loss: 0.6598, Val Loss: 1.4274
2024-12-27 20:42:44,914 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:42:44,914 - INFO - Training completed in 0.45s
2024-12-27 20:42:44,915 - INFO - Final memory usage: CPU 3118.6 MB, GPU 48.1 MB
2024-12-27 20:42:44,916 - INFO - Model training completed in 0.45s
2024-12-27 20:42:44,922 - INFO - Prediction completed in 0.01s
2024-12-27 20:42:44,941 - INFO - Poison rate 0.2 completed in 0.48s
2024-12-27 20:42:44,943 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:42:44,943 - INFO - Total evaluation time: 17.72s
2024-12-27 20:42:44,947 - INFO - 
Progress: 79.2% - Evaluating ImageNette with LogisticRegression (dynadetect mode, iteration 1/1)
2024-12-27 20:42:45,026 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:42:45,097 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:42:45,180 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 20:42:45,181 - INFO - Dataset type: image
2024-12-27 20:42:45,181 - INFO - Sample size: 5000
2024-12-27 20:42:45,181 - INFO - Using device: cuda
2024-12-27 20:42:45,183 - INFO - Loading datasets...
2024-12-27 20:42:45,209 - INFO - Dataset loading completed in 0.03s
2024-12-27 20:42:45,209 - INFO - Extracting validation features...
2024-12-27 20:42:45,209 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:28,  1.09it/s]Extracting features:   9%|▉         | 3/32 [00:01<00:08,  3.53it/s]Extracting features:  22%|██▏       | 7/32 [00:01<00:02,  9.20it/s]Extracting features:  34%|███▍      | 11/32 [00:01<00:01, 14.21it/s]Extracting features:  44%|████▍     | 14/32 [00:01<00:01, 11.68it/s]Extracting features:  53%|█████▎    | 17/32 [00:01<00:01, 14.54it/s]Extracting features:  62%|██████▎   | 20/32 [00:02<00:00, 12.68it/s]Extracting features:  69%|██████▉   | 22/32 [00:02<00:00, 12.73it/s]Extracting features:  75%|███████▌  | 24/32 [00:02<00:00, 13.71it/s]Extracting features:  81%|████████▏ | 26/32 [00:02<00:00, 11.68it/s]Extracting features:  91%|█████████ | 29/32 [00:02<00:00, 12.47it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 11.11it/s]
2024-12-27 20:42:48,096 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:42:48,097 - INFO - Validation feature extraction completed in 2.89s
2024-12-27 20:42:48,097 - INFO - Extracting training features...
2024-12-27 20:42:48,097 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:07,  2.30it/s]Extracting features:   1%|▏         | 2/157 [00:00<00:44,  3.46it/s]Extracting features:   2%|▏         | 3/157 [00:00<00:46,  3.33it/s]Extracting features:   4%|▍         | 7/157 [00:01<00:19,  7.62it/s]Extracting features:   7%|▋         | 11/157 [00:01<00:16,  9.08it/s]Extracting features:  10%|▉         | 15/157 [00:01<00:12, 11.67it/s]Extracting features:  12%|█▏        | 19/157 [00:02<00:10, 12.76it/s]Extracting features:  15%|█▍        | 23/157 [00:02<00:11, 11.24it/s]Extracting features:  17%|█▋        | 27/157 [00:02<00:10, 12.21it/s]Extracting features:  20%|█▉        | 31/157 [00:03<00:09, 12.88it/s]Extracting features:  22%|██▏       | 35/157 [00:03<00:09, 12.94it/s]Extracting features:  25%|██▍       | 39/157 [00:03<00:07, 15.00it/s]Extracting features:  27%|██▋       | 43/157 [00:03<00:07, 15.98it/s]Extracting features:  30%|██▉       | 47/157 [00:03<00:07, 15.62it/s]Extracting features:  32%|███▏      | 51/157 [00:04<00:06, 16.17it/s]Extracting features:  35%|███▌      | 55/157 [00:04<00:06, 15.86it/s]Extracting features:  38%|███▊      | 59/157 [00:04<00:05, 16.52it/s]Extracting features:  40%|████      | 63/157 [00:05<00:06, 13.57it/s]Extracting features:  43%|████▎     | 67/157 [00:05<00:06, 13.97it/s]Extracting features:  45%|████▌     | 71/157 [00:05<00:06, 13.35it/s]Extracting features:  48%|████▊     | 75/157 [00:05<00:05, 14.09it/s]Extracting features:  50%|█████     | 79/157 [00:06<00:05, 13.47it/s]Extracting features:  53%|█████▎    | 83/157 [00:06<00:05, 13.80it/s]Extracting features:  55%|█████▌    | 87/157 [00:06<00:04, 15.38it/s]Extracting features:  58%|█████▊    | 91/157 [00:07<00:04, 13.76it/s]Extracting features:  61%|██████    | 95/157 [00:07<00:04, 14.62it/s]Extracting features:  63%|██████▎   | 99/157 [00:07<00:03, 15.71it/s]Extracting features:  64%|██████▍   | 101/157 [00:07<00:03, 15.04it/s]Extracting features:  66%|██████▌   | 103/157 [00:07<00:03, 14.13it/s]Extracting features:  67%|██████▋   | 105/157 [00:08<00:03, 13.89it/s]Extracting features:  69%|██████▉   | 109/157 [00:08<00:03, 13.24it/s]Extracting features:  72%|███████▏  | 113/157 [00:08<00:03, 12.90it/s]Extracting features:  75%|███████▍  | 117/157 [00:08<00:02, 14.26it/s]Extracting features:  76%|███████▋  | 120/157 [00:09<00:02, 16.00it/s]Extracting features:  78%|███████▊  | 122/157 [00:09<00:02, 14.93it/s]Extracting features:  79%|███████▉  | 124/157 [00:09<00:02, 14.34it/s]Extracting features:  80%|████████  | 126/157 [00:09<00:02, 15.31it/s]Extracting features:  82%|████████▏ | 129/157 [00:09<00:01, 15.14it/s]Extracting features:  85%|████████▍ | 133/157 [00:09<00:01, 15.76it/s]Extracting features:  87%|████████▋ | 137/157 [00:10<00:01, 16.93it/s]Extracting features:  89%|████████▉ | 140/157 [00:10<00:01, 16.18it/s]Extracting features:  92%|█████████▏| 144/157 [00:10<00:00, 15.70it/s]Extracting features:  94%|█████████▍| 148/157 [00:10<00:00, 13.56it/s]Extracting features:  97%|█████████▋| 152/157 [00:11<00:00, 14.94it/s]Extracting features:  99%|█████████▉| 156/157 [00:11<00:00, 16.99it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 13.75it/s]
2024-12-27 20:42:59,526 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:42:59,527 - INFO - Training feature extraction completed in 11.43s
2024-12-27 20:42:59,527 - INFO - Creating model for classifier: LogisticRegression
2024-12-27 20:42:59,527 - INFO - Using device: cuda
2024-12-27 20:42:59,527 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:42:59,527 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:42:59,527 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:43:00,151 - INFO - Feature scaling completed in 0.62s
2024-12-27 20:43:00,152 - INFO - Starting feature selection (k=50)
2024-12-27 20:43:00,157 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:43:00,158 - INFO - Starting anomaly detection
2024-12-27 20:43:02,091 - INFO - Anomaly detection completed in 1.93s
2024-12-27 20:43:02,091 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:43:02,092 - INFO - Total fit_transform time: 2.56s
2024-12-27 20:43:02,092 - INFO - Training set processing completed in 2.56s
2024-12-27 20:43:02,092 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:43:02,093 - INFO - Memory usage at start_fit: CPU 3111.7 MB, GPU 47.3 MB
2024-12-27 20:43:02,094 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:43:02,095 - INFO - Number of unique classes: 10
2024-12-27 20:43:02,192 - INFO - Fitted scaler and transformed data
2024-12-27 20:43:02,192 - INFO - Scaling time: 0.09s
2024-12-27 20:43:02,330 - INFO - Epoch 1/200, Train Loss: 0.1212, Val Loss: 0.0157
2024-12-27 20:43:02,456 - INFO - Epoch 2/200, Train Loss: 0.0096, Val Loss: 0.0353
2024-12-27 20:43:02,612 - INFO - Epoch 3/200, Train Loss: 0.0038, Val Loss: 0.0106
2024-12-27 20:43:02,613 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:43:02,613 - INFO - Training completed in 0.52s
2024-12-27 20:43:02,614 - INFO - Final memory usage: CPU 3112.0 MB, GPU 48.1 MB
2024-12-27 20:43:02,614 - INFO - Model training completed in 0.52s
2024-12-27 20:43:02,622 - INFO - Prediction completed in 0.01s
2024-12-27 20:43:02,633 - INFO - Poison rate 0.0 completed in 3.11s
2024-12-27 20:43:02,633 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:43:02,633 - INFO - Total number of labels flipped: 42
2024-12-27 20:43:02,634 - INFO - Label flipping completed in 0.00s
2024-12-27 20:43:02,634 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:43:02,634 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:43:03,188 - INFO - Feature scaling completed in 0.55s
2024-12-27 20:43:03,188 - INFO - Starting feature selection (k=50)
2024-12-27 20:43:03,196 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:43:03,196 - INFO - Starting anomaly detection
2024-12-27 20:43:05,138 - INFO - Anomaly detection completed in 1.94s
2024-12-27 20:43:05,139 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:43:05,139 - INFO - Total fit_transform time: 2.51s
2024-12-27 20:43:05,139 - INFO - Training set processing completed in 2.51s
2024-12-27 20:43:05,139 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:43:05,141 - INFO - Memory usage at start_fit: CPU 3112.0 MB, GPU 47.5 MB
2024-12-27 20:43:05,141 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:43:05,141 - INFO - Number of unique classes: 10
2024-12-27 20:43:05,256 - INFO - Fitted scaler and transformed data
2024-12-27 20:43:05,256 - INFO - Scaling time: 0.11s
2024-12-27 20:43:05,431 - INFO - Epoch 1/200, Train Loss: 0.2563, Val Loss: 0.2479
2024-12-27 20:43:05,569 - INFO - Epoch 2/200, Train Loss: 0.0826, Val Loss: 0.2697
2024-12-27 20:43:05,723 - INFO - Epoch 3/200, Train Loss: 0.0387, Val Loss: 0.2603
2024-12-27 20:43:05,723 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:43:05,723 - INFO - Training completed in 0.58s
2024-12-27 20:43:05,724 - INFO - Final memory usage: CPU 3112.0 MB, GPU 48.1 MB
2024-12-27 20:43:05,724 - INFO - Model training completed in 0.58s
2024-12-27 20:43:05,733 - INFO - Prediction completed in 0.01s
2024-12-27 20:43:05,742 - INFO - Poison rate 0.01 completed in 3.11s
2024-12-27 20:43:05,742 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:43:05,743 - INFO - Total number of labels flipped: 139
2024-12-27 20:43:05,743 - INFO - Label flipping completed in 0.00s
2024-12-27 20:43:05,743 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:43:05,743 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:43:06,349 - INFO - Feature scaling completed in 0.61s
2024-12-27 20:43:06,349 - INFO - Starting feature selection (k=50)
2024-12-27 20:43:06,363 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:43:06,363 - INFO - Starting anomaly detection
2024-12-27 20:43:07,960 - INFO - Anomaly detection completed in 1.60s
2024-12-27 20:43:07,960 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:43:07,960 - INFO - Total fit_transform time: 2.22s
2024-12-27 20:43:07,960 - INFO - Training set processing completed in 2.22s
2024-12-27 20:43:07,961 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:43:07,962 - INFO - Memory usage at start_fit: CPU 3112.0 MB, GPU 47.5 MB
2024-12-27 20:43:07,962 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:43:07,962 - INFO - Number of unique classes: 10
2024-12-27 20:43:08,057 - INFO - Fitted scaler and transformed data
2024-12-27 20:43:08,057 - INFO - Scaling time: 0.09s
2024-12-27 20:43:08,278 - INFO - Epoch 1/200, Train Loss: 0.5639, Val Loss: 0.4753
2024-12-27 20:43:08,514 - INFO - Epoch 2/200, Train Loss: 0.2125, Val Loss: 0.4596
2024-12-27 20:43:08,735 - INFO - Epoch 3/200, Train Loss: 0.1227, Val Loss: 0.4352
2024-12-27 20:43:08,965 - INFO - Epoch 4/200, Train Loss: 0.0675, Val Loss: 0.4544
2024-12-27 20:43:09,172 - INFO - Epoch 5/200, Train Loss: 0.0467, Val Loss: 0.5014
2024-12-27 20:43:09,172 - INFO - Early stopping triggered at epoch 5
2024-12-27 20:43:09,172 - INFO - Training completed in 1.21s
2024-12-27 20:43:09,172 - INFO - Final memory usage: CPU 3112.0 MB, GPU 48.1 MB
2024-12-27 20:43:09,173 - INFO - Model training completed in 1.21s
2024-12-27 20:43:09,181 - INFO - Prediction completed in 0.01s
2024-12-27 20:43:09,189 - INFO - Poison rate 0.03 completed in 3.45s
2024-12-27 20:43:09,189 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:43:09,190 - INFO - Total number of labels flipped: 219
2024-12-27 20:43:09,190 - INFO - Label flipping completed in 0.00s
2024-12-27 20:43:09,190 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:43:09,190 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:43:09,790 - INFO - Feature scaling completed in 0.60s
2024-12-27 20:43:09,791 - INFO - Starting feature selection (k=50)
2024-12-27 20:43:09,807 - INFO - Feature selection completed in 0.02s. Output shape: (5000, 50)
2024-12-27 20:43:09,807 - INFO - Starting anomaly detection
2024-12-27 20:43:11,741 - INFO - Anomaly detection completed in 1.93s
2024-12-27 20:43:11,741 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:43:11,741 - INFO - Total fit_transform time: 2.55s
2024-12-27 20:43:11,742 - INFO - Training set processing completed in 2.55s
2024-12-27 20:43:11,742 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:43:11,743 - INFO - Memory usage at start_fit: CPU 3112.0 MB, GPU 47.5 MB
2024-12-27 20:43:11,743 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:43:11,744 - INFO - Number of unique classes: 10
2024-12-27 20:43:11,845 - INFO - Fitted scaler and transformed data
2024-12-27 20:43:11,845 - INFO - Scaling time: 0.10s
2024-12-27 20:43:11,992 - INFO - Epoch 1/200, Train Loss: 0.7112, Val Loss: 0.6467
2024-12-27 20:43:12,158 - INFO - Epoch 2/200, Train Loss: 0.2959, Val Loss: 0.7061
2024-12-27 20:43:12,323 - INFO - Epoch 3/200, Train Loss: 0.1716, Val Loss: 0.6588
2024-12-27 20:43:12,323 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:43:12,323 - INFO - Training completed in 0.58s
2024-12-27 20:43:12,323 - INFO - Final memory usage: CPU 3112.0 MB, GPU 48.1 MB
2024-12-27 20:43:12,324 - INFO - Model training completed in 0.58s
2024-12-27 20:43:12,331 - INFO - Prediction completed in 0.01s
2024-12-27 20:43:12,339 - INFO - Poison rate 0.05 completed in 3.15s
2024-12-27 20:43:12,339 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:43:12,340 - INFO - Total number of labels flipped: 312
2024-12-27 20:43:12,340 - INFO - Label flipping completed in 0.00s
2024-12-27 20:43:12,340 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:43:12,340 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:43:12,901 - INFO - Feature scaling completed in 0.56s
2024-12-27 20:43:12,901 - INFO - Starting feature selection (k=50)
2024-12-27 20:43:12,914 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:43:12,914 - INFO - Starting anomaly detection
2024-12-27 20:43:14,318 - INFO - Anomaly detection completed in 1.40s
2024-12-27 20:43:14,318 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:43:14,318 - INFO - Total fit_transform time: 1.98s
2024-12-27 20:43:14,318 - INFO - Training set processing completed in 1.98s
2024-12-27 20:43:14,318 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:43:14,320 - INFO - Memory usage at start_fit: CPU 3112.0 MB, GPU 47.5 MB
2024-12-27 20:43:14,320 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:43:14,321 - INFO - Number of unique classes: 10
2024-12-27 20:43:14,419 - INFO - Fitted scaler and transformed data
2024-12-27 20:43:14,420 - INFO - Scaling time: 0.10s
2024-12-27 20:43:14,562 - INFO - Epoch 1/200, Train Loss: 0.9139, Val Loss: 0.8062
2024-12-27 20:43:14,731 - INFO - Epoch 2/200, Train Loss: 0.4206, Val Loss: 0.7497
2024-12-27 20:43:14,846 - INFO - Epoch 3/200, Train Loss: 0.2614, Val Loss: 0.7848
2024-12-27 20:43:14,954 - INFO - Epoch 4/200, Train Loss: 0.1751, Val Loss: 0.8142
2024-12-27 20:43:14,954 - INFO - Early stopping triggered at epoch 4
2024-12-27 20:43:14,954 - INFO - Training completed in 0.64s
2024-12-27 20:43:14,954 - INFO - Final memory usage: CPU 3112.0 MB, GPU 48.1 MB
2024-12-27 20:43:14,954 - INFO - Model training completed in 0.64s
2024-12-27 20:43:14,961 - INFO - Prediction completed in 0.01s
2024-12-27 20:43:14,973 - INFO - Poison rate 0.07 completed in 2.63s
2024-12-27 20:43:14,974 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:43:14,976 - INFO - Total number of labels flipped: 452
2024-12-27 20:43:14,976 - INFO - Label flipping completed in 0.00s
2024-12-27 20:43:14,977 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:43:14,977 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:43:15,567 - INFO - Feature scaling completed in 0.59s
2024-12-27 20:43:15,568 - INFO - Starting feature selection (k=50)
2024-12-27 20:43:15,576 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:43:15,576 - INFO - Starting anomaly detection
2024-12-27 20:43:17,050 - INFO - Anomaly detection completed in 1.47s
2024-12-27 20:43:17,050 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:43:17,050 - INFO - Total fit_transform time: 2.07s
2024-12-27 20:43:17,050 - INFO - Training set processing completed in 2.07s
2024-12-27 20:43:17,050 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:43:17,051 - INFO - Memory usage at start_fit: CPU 3112.0 MB, GPU 47.5 MB
2024-12-27 20:43:17,051 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:43:17,052 - INFO - Number of unique classes: 10
2024-12-27 20:43:17,156 - INFO - Fitted scaler and transformed data
2024-12-27 20:43:17,156 - INFO - Scaling time: 0.10s
2024-12-27 20:43:17,299 - INFO - Epoch 1/200, Train Loss: 1.0599, Val Loss: 0.9117
2024-12-27 20:43:17,432 - INFO - Epoch 2/200, Train Loss: 0.5049, Val Loss: 0.9357
2024-12-27 20:43:17,557 - INFO - Epoch 3/200, Train Loss: 0.3649, Val Loss: 0.9060
2024-12-27 20:43:17,557 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:43:17,557 - INFO - Training completed in 0.51s
2024-12-27 20:43:17,557 - INFO - Final memory usage: CPU 3112.0 MB, GPU 48.1 MB
2024-12-27 20:43:17,558 - INFO - Model training completed in 0.51s
2024-12-27 20:43:17,572 - INFO - Prediction completed in 0.01s
2024-12-27 20:43:17,594 - INFO - Poison rate 0.1 completed in 2.62s
2024-12-27 20:43:17,594 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:43:17,596 - INFO - Total number of labels flipped: 889
2024-12-27 20:43:17,596 - INFO - Label flipping completed in 0.00s
2024-12-27 20:43:17,596 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:43:17,596 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:43:18,233 - INFO - Feature scaling completed in 0.64s
2024-12-27 20:43:18,233 - INFO - Starting feature selection (k=50)
2024-12-27 20:43:18,243 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:43:18,243 - INFO - Starting anomaly detection
2024-12-27 20:43:20,154 - INFO - Anomaly detection completed in 1.91s
2024-12-27 20:43:20,154 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:43:20,154 - INFO - Total fit_transform time: 2.56s
2024-12-27 20:43:20,154 - INFO - Training set processing completed in 2.56s
2024-12-27 20:43:20,154 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:43:20,155 - INFO - Memory usage at start_fit: CPU 3112.0 MB, GPU 47.5 MB
2024-12-27 20:43:20,156 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:43:20,157 - INFO - Number of unique classes: 10
2024-12-27 20:43:20,251 - INFO - Fitted scaler and transformed data
2024-12-27 20:43:20,251 - INFO - Scaling time: 0.09s
2024-12-27 20:43:20,399 - INFO - Epoch 1/200, Train Loss: 1.5297, Val Loss: 1.4471
2024-12-27 20:43:20,527 - INFO - Epoch 2/200, Train Loss: 0.9122, Val Loss: 1.3824
2024-12-27 20:43:20,641 - INFO - Epoch 3/200, Train Loss: 0.6830, Val Loss: 1.2987
2024-12-27 20:43:20,770 - INFO - Epoch 4/200, Train Loss: 0.5396, Val Loss: 1.4255
2024-12-27 20:43:20,904 - INFO - Epoch 5/200, Train Loss: 0.4803, Val Loss: 1.3657
2024-12-27 20:43:20,905 - INFO - Early stopping triggered at epoch 5
2024-12-27 20:43:20,905 - INFO - Training completed in 0.75s
2024-12-27 20:43:20,906 - INFO - Final memory usage: CPU 3112.0 MB, GPU 48.1 MB
2024-12-27 20:43:20,906 - INFO - Model training completed in 0.75s
2024-12-27 20:43:20,922 - INFO - Prediction completed in 0.01s
2024-12-27 20:43:20,943 - INFO - Poison rate 0.2 completed in 3.35s
2024-12-27 20:43:20,944 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:43:20,944 - INFO - Total evaluation time: 35.76s
2024-12-27 20:43:20,947 - INFO - 
Progress: 80.2% - Evaluating ImageNette with RandomForest (standard mode, iteration 1/1)
2024-12-27 20:43:21,039 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:43:21,108 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:43:21,189 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 20:43:21,189 - INFO - Dataset type: image
2024-12-27 20:43:21,189 - INFO - Sample size: 5000
2024-12-27 20:43:21,189 - INFO - Using device: cuda
2024-12-27 20:43:21,191 - INFO - Loading datasets...
2024-12-27 20:43:21,216 - INFO - Dataset loading completed in 0.02s
2024-12-27 20:43:21,216 - INFO - Extracting validation features...
2024-12-27 20:43:21,216 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:18,  1.68it/s]Extracting features:   6%|▋         | 2/32 [00:00<00:09,  3.09it/s]Extracting features:  16%|█▌        | 5/32 [00:00<00:03,  8.65it/s]Extracting features:  28%|██▊       | 9/32 [00:00<00:01, 14.58it/s]Extracting features:  38%|███▊      | 12/32 [00:01<00:01, 16.67it/s]Extracting features:  47%|████▋     | 15/32 [00:01<00:01, 15.27it/s]Extracting features:  53%|█████▎    | 17/32 [00:01<00:01, 12.65it/s]Extracting features:  66%|██████▌   | 21/32 [00:01<00:00, 12.73it/s]Extracting features:  72%|███████▏  | 23/32 [00:02<00:00, 12.85it/s]Extracting features:  78%|███████▊  | 25/32 [00:02<00:00, 13.68it/s]Extracting features:  88%|████████▊ | 28/32 [00:02<00:00, 16.34it/s]Extracting features:  94%|█████████▍| 30/32 [00:02<00:00, 13.45it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 12.35it/s]
2024-12-27 20:43:23,812 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:43:23,813 - INFO - Validation feature extraction completed in 2.60s
2024-12-27 20:43:23,813 - INFO - Extracting training features...
2024-12-27 20:43:23,813 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:38,  1.58it/s]Extracting features:   3%|▎         | 5/157 [00:00<00:22,  6.64it/s]Extracting features:   6%|▌         | 9/157 [00:01<00:14, 10.01it/s]Extracting features:   8%|▊         | 13/157 [00:01<00:12, 12.00it/s]Extracting features:  10%|█         | 16/157 [00:01<00:09, 14.75it/s]Extracting features:  11%|█▏        | 18/157 [00:01<00:10, 13.52it/s]Extracting features:  13%|█▎        | 21/157 [00:01<00:10, 13.47it/s]Extracting features:  16%|█▌        | 25/157 [00:02<00:09, 14.17it/s]Extracting features:  18%|█▊        | 29/157 [00:02<00:08, 15.43it/s]Extracting features:  20%|█▉        | 31/157 [00:02<00:08, 15.04it/s]Extracting features:  22%|██▏       | 34/157 [00:02<00:07, 17.25it/s]Extracting features:  24%|██▎       | 37/157 [00:02<00:06, 18.68it/s]Extracting features:  25%|██▌       | 40/157 [00:02<00:06, 17.43it/s]Extracting features:  27%|██▋       | 42/157 [00:03<00:06, 17.90it/s]Extracting features:  29%|██▉       | 46/157 [00:03<00:05, 20.03it/s]Extracting features:  31%|███       | 49/157 [00:03<00:05, 21.31it/s]Extracting features:  33%|███▎      | 52/157 [00:03<00:04, 21.35it/s]Extracting features:  35%|███▌      | 55/157 [00:03<00:05, 18.02it/s]Extracting features:  37%|███▋      | 58/157 [00:03<00:05, 17.08it/s]Extracting features:  38%|███▊      | 60/157 [00:04<00:06, 15.49it/s]Extracting features:  40%|████      | 63/157 [00:04<00:06, 13.82it/s]Extracting features:  43%|████▎     | 67/157 [00:04<00:07, 12.83it/s]Extracting features:  45%|████▌     | 71/157 [00:05<00:06, 12.40it/s]Extracting features:  48%|████▊     | 75/157 [00:05<00:06, 12.89it/s]Extracting features:  50%|█████     | 79/157 [00:05<00:06, 12.02it/s]Extracting features:  53%|█████▎    | 83/157 [00:06<00:06, 11.09it/s]Extracting features:  55%|█████▌    | 87/157 [00:06<00:05, 11.69it/s]Extracting features:  58%|█████▊    | 91/157 [00:06<00:05, 12.48it/s]Extracting features:  61%|██████    | 95/157 [00:07<00:05, 11.51it/s]Extracting features:  63%|██████▎   | 99/157 [00:07<00:04, 12.06it/s]Extracting features:  66%|██████▌   | 103/157 [00:07<00:04, 12.01it/s]Extracting features:  68%|██████▊   | 107/157 [00:08<00:04, 12.37it/s]Extracting features:  71%|███████   | 111/157 [00:08<00:03, 12.27it/s]Extracting features:  73%|███████▎  | 115/157 [00:08<00:03, 12.24it/s]Extracting features:  76%|███████▌  | 119/157 [00:08<00:02, 13.22it/s]Extracting features:  78%|███████▊  | 122/157 [00:09<00:02, 15.12it/s]Extracting features:  79%|███████▉  | 124/157 [00:09<00:02, 13.34it/s]Extracting features:  80%|████████  | 126/157 [00:09<00:02, 13.72it/s]Extracting features:  82%|████████▏ | 128/157 [00:09<00:02, 14.03it/s]Extracting features:  83%|████████▎ | 131/157 [00:09<00:01, 14.59it/s]Extracting features:  86%|████████▌ | 135/157 [00:09<00:01, 15.70it/s]Extracting features:  89%|████████▊ | 139/157 [00:10<00:01, 13.85it/s]Extracting features:  91%|█████████ | 143/157 [00:10<00:01, 12.41it/s]Extracting features:  94%|█████████▎| 147/157 [00:10<00:00, 13.11it/s]Extracting features:  96%|█████████▌| 151/157 [00:11<00:00, 13.99it/s]Extracting features:  99%|█████████▊| 155/157 [00:11<00:00, 13.92it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 13.53it/s]
2024-12-27 20:43:35,433 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:43:35,434 - INFO - Training feature extraction completed in 11.62s
2024-12-27 20:43:35,434 - INFO - Creating model for classifier: RandomForest
2024-12-27 20:43:35,434 - INFO - Using device: cuda
2024-12-27 20:43:35,434 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:43:35,434 - INFO - Training set processing completed in 0.00s
2024-12-27 20:43:35,434 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:43:35,436 - INFO - Memory usage at start_fit: CPU 3109.5 MB, GPU 47.3 MB
2024-12-27 20:43:35,436 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:43:35,508 - INFO - Fitted scaler and transformed data
2024-12-27 20:43:35,508 - INFO - Scaling time: 0.07s
2024-12-27 20:43:35,514 - INFO - Number of unique classes: 10
2024-12-27 20:43:38,701 - INFO - Epoch 1/15, Train Loss: 2.2967, Val Loss: 2.2901
2024-12-27 20:43:41,423 - INFO - Epoch 2/15, Train Loss: 2.2807, Val Loss: 2.2755
2024-12-27 20:43:44,004 - INFO - Epoch 3/15, Train Loss: 2.2625, Val Loss: 2.2583
2024-12-27 20:43:47,014 - INFO - Epoch 4/15, Train Loss: 2.2412, Val Loss: 2.2381
2024-12-27 20:43:49,973 - INFO - Epoch 5/15, Train Loss: 2.2168, Val Loss: 2.2152
2024-12-27 20:43:53,788 - INFO - Epoch 6/15, Train Loss: 2.1898, Val Loss: 2.1903
2024-12-27 20:43:56,723 - INFO - Epoch 7/15, Train Loss: 2.1612, Val Loss: 2.1652
2024-12-27 20:43:59,771 - INFO - Epoch 8/15, Train Loss: 2.1337, Val Loss: 2.1412
2024-12-27 20:44:02,869 - INFO - Epoch 9/15, Train Loss: 2.1075, Val Loss: 2.1195
2024-12-27 20:44:06,016 - INFO - Epoch 10/15, Train Loss: 2.0843, Val Loss: 2.1003
2024-12-27 20:44:09,216 - INFO - Epoch 11/15, Train Loss: 2.0638, Val Loss: 2.0838
2024-12-27 20:44:12,060 - INFO - Epoch 12/15, Train Loss: 2.0464, Val Loss: 2.0696
2024-12-27 20:44:15,988 - INFO - Epoch 13/15, Train Loss: 2.0310, Val Loss: 2.0575
2024-12-27 20:44:19,546 - INFO - Epoch 14/15, Train Loss: 2.0182, Val Loss: 2.0471
2024-12-27 20:44:22,895 - INFO - Epoch 15/15, Train Loss: 2.0068, Val Loss: 2.0382
2024-12-27 20:44:22,895 - INFO - Training completed in 47.46s
2024-12-27 20:44:22,895 - INFO - Final memory usage: CPU 3109.5 MB, GPU 75.5 MB
2024-12-27 20:44:22,896 - INFO - Model training completed in 47.46s
2024-12-27 20:44:22,994 - INFO - Prediction completed in 0.10s
2024-12-27 20:44:23,002 - INFO - Poison rate 0.0 completed in 47.57s
2024-12-27 20:44:23,002 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:44:23,003 - INFO - Total number of labels flipped: 45
2024-12-27 20:44:23,003 - INFO - Label flipping completed in 0.00s
2024-12-27 20:44:23,003 - INFO - Training set processing completed in 0.00s
2024-12-27 20:44:23,003 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:44:23,004 - INFO - Memory usage at start_fit: CPU 3109.5 MB, GPU 49.3 MB
2024-12-27 20:44:23,004 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:44:23,068 - INFO - Fitted scaler and transformed data
2024-12-27 20:44:23,069 - INFO - Scaling time: 0.06s
2024-12-27 20:44:23,079 - INFO - Number of unique classes: 10
2024-12-27 20:44:25,711 - INFO - Epoch 1/15, Train Loss: 2.2969, Val Loss: 2.2899
2024-12-27 20:44:29,374 - INFO - Epoch 2/15, Train Loss: 2.2814, Val Loss: 2.2750
2024-12-27 20:44:32,426 - INFO - Epoch 3/15, Train Loss: 2.2637, Val Loss: 2.2574
2024-12-27 20:44:35,523 - INFO - Epoch 4/15, Train Loss: 2.2431, Val Loss: 2.2367
2024-12-27 20:44:38,221 - INFO - Epoch 5/15, Train Loss: 2.2195, Val Loss: 2.2133
2024-12-27 20:44:41,480 - INFO - Epoch 6/15, Train Loss: 2.1934, Val Loss: 2.1877
2024-12-27 20:44:44,334 - INFO - Epoch 7/15, Train Loss: 2.1661, Val Loss: 2.1616
2024-12-27 20:44:47,093 - INFO - Epoch 8/15, Train Loss: 2.1386, Val Loss: 2.1368
2024-12-27 20:44:50,564 - INFO - Epoch 9/15, Train Loss: 2.1132, Val Loss: 2.1141
2024-12-27 20:44:53,517 - INFO - Epoch 10/15, Train Loss: 2.0904, Val Loss: 2.0943
2024-12-27 20:44:56,511 - INFO - Epoch 11/15, Train Loss: 2.0705, Val Loss: 2.0773
2024-12-27 20:45:00,684 - INFO - Epoch 12/15, Train Loss: 2.0536, Val Loss: 2.0628
2024-12-27 20:45:03,702 - INFO - Epoch 13/15, Train Loss: 2.0388, Val Loss: 2.0505
2024-12-27 20:45:07,192 - INFO - Epoch 14/15, Train Loss: 2.0253, Val Loss: 2.0401
2024-12-27 20:45:10,565 - INFO - Epoch 15/15, Train Loss: 2.0150, Val Loss: 2.0310
2024-12-27 20:45:10,565 - INFO - Training completed in 47.56s
2024-12-27 20:45:10,565 - INFO - Final memory usage: CPU 3109.5 MB, GPU 75.5 MB
2024-12-27 20:45:10,566 - INFO - Model training completed in 47.56s
2024-12-27 20:45:10,666 - INFO - Prediction completed in 0.10s
2024-12-27 20:45:10,673 - INFO - Poison rate 0.01 completed in 47.67s
2024-12-27 20:45:10,674 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:45:10,674 - INFO - Total number of labels flipped: 131
2024-12-27 20:45:10,674 - INFO - Label flipping completed in 0.00s
2024-12-27 20:45:10,674 - INFO - Training set processing completed in 0.00s
2024-12-27 20:45:10,675 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:45:10,675 - INFO - Memory usage at start_fit: CPU 3109.5 MB, GPU 49.3 MB
2024-12-27 20:45:10,675 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:45:10,741 - INFO - Fitted scaler and transformed data
2024-12-27 20:45:10,741 - INFO - Scaling time: 0.07s
2024-12-27 20:45:10,752 - INFO - Number of unique classes: 10
2024-12-27 20:45:13,629 - INFO - Epoch 1/15, Train Loss: 2.2971, Val Loss: 2.2906
2024-12-27 20:45:16,499 - INFO - Epoch 2/15, Train Loss: 2.2818, Val Loss: 2.2767
2024-12-27 20:45:19,480 - INFO - Epoch 3/15, Train Loss: 2.2646, Val Loss: 2.2601
2024-12-27 20:45:22,571 - INFO - Epoch 4/15, Train Loss: 2.2445, Val Loss: 2.2409
2024-12-27 20:45:25,429 - INFO - Epoch 5/15, Train Loss: 2.2214, Val Loss: 2.2191
2024-12-27 20:45:28,331 - INFO - Epoch 6/15, Train Loss: 2.1961, Val Loss: 2.1955
2024-12-27 20:45:31,284 - INFO - Epoch 7/15, Train Loss: 2.1697, Val Loss: 2.1716
2024-12-27 20:45:34,141 - INFO - Epoch 8/15, Train Loss: 2.1433, Val Loss: 2.1489
2024-12-27 20:45:36,919 - INFO - Epoch 9/15, Train Loss: 2.1193, Val Loss: 2.1283
2024-12-27 20:45:39,630 - INFO - Epoch 10/15, Train Loss: 2.0972, Val Loss: 2.1103
2024-12-27 20:45:42,259 - INFO - Epoch 11/15, Train Loss: 2.0778, Val Loss: 2.0946
2024-12-27 20:45:44,958 - INFO - Epoch 12/15, Train Loss: 2.0608, Val Loss: 2.0812
2024-12-27 20:45:48,319 - INFO - Epoch 13/15, Train Loss: 2.0466, Val Loss: 2.0698
2024-12-27 20:45:51,475 - INFO - Epoch 14/15, Train Loss: 2.0335, Val Loss: 2.0599
2024-12-27 20:45:54,247 - INFO - Epoch 15/15, Train Loss: 2.0230, Val Loss: 2.0514
2024-12-27 20:45:54,248 - INFO - Training completed in 43.57s
2024-12-27 20:45:54,248 - INFO - Final memory usage: CPU 3109.5 MB, GPU 75.5 MB
2024-12-27 20:45:54,248 - INFO - Model training completed in 43.57s
2024-12-27 20:45:54,359 - INFO - Prediction completed in 0.11s
2024-12-27 20:45:54,366 - INFO - Poison rate 0.03 completed in 43.69s
2024-12-27 20:45:54,367 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:45:54,367 - INFO - Total number of labels flipped: 228
2024-12-27 20:45:54,367 - INFO - Label flipping completed in 0.00s
2024-12-27 20:45:54,367 - INFO - Training set processing completed in 0.00s
2024-12-27 20:45:54,368 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:45:54,368 - INFO - Memory usage at start_fit: CPU 3109.5 MB, GPU 49.3 MB
2024-12-27 20:45:54,368 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:45:54,434 - INFO - Fitted scaler and transformed data
2024-12-27 20:45:54,434 - INFO - Scaling time: 0.07s
2024-12-27 20:45:54,446 - INFO - Number of unique classes: 10
2024-12-27 20:45:57,267 - INFO - Epoch 1/15, Train Loss: 2.2972, Val Loss: 2.2904
2024-12-27 20:45:59,868 - INFO - Epoch 2/15, Train Loss: 2.2823, Val Loss: 2.2762
2024-12-27 20:46:02,887 - INFO - Epoch 3/15, Train Loss: 2.2655, Val Loss: 2.2595
2024-12-27 20:46:05,486 - INFO - Epoch 4/15, Train Loss: 2.2461, Val Loss: 2.2399
2024-12-27 20:46:08,107 - INFO - Epoch 5/15, Train Loss: 2.2235, Val Loss: 2.2176
2024-12-27 20:46:11,032 - INFO - Epoch 6/15, Train Loss: 2.1992, Val Loss: 2.1932
2024-12-27 20:46:14,072 - INFO - Epoch 7/15, Train Loss: 2.1730, Val Loss: 2.1687
2024-12-27 20:46:16,825 - INFO - Epoch 8/15, Train Loss: 2.1474, Val Loss: 2.1451
2024-12-27 20:46:19,409 - INFO - Epoch 9/15, Train Loss: 2.1231, Val Loss: 2.1240
2024-12-27 20:46:22,129 - INFO - Epoch 10/15, Train Loss: 2.1016, Val Loss: 2.1054
2024-12-27 20:46:25,087 - INFO - Epoch 11/15, Train Loss: 2.0820, Val Loss: 2.0896
2024-12-27 20:46:28,012 - INFO - Epoch 12/15, Train Loss: 2.0649, Val Loss: 2.0760
2024-12-27 20:46:30,686 - INFO - Epoch 13/15, Train Loss: 2.0504, Val Loss: 2.0644
2024-12-27 20:46:33,515 - INFO - Epoch 14/15, Train Loss: 2.0384, Val Loss: 2.0545
2024-12-27 20:46:36,510 - INFO - Epoch 15/15, Train Loss: 2.0275, Val Loss: 2.0461
2024-12-27 20:46:36,510 - INFO - Training completed in 42.14s
2024-12-27 20:46:36,511 - INFO - Final memory usage: CPU 3109.5 MB, GPU 75.5 MB
2024-12-27 20:46:36,511 - INFO - Model training completed in 42.14s
2024-12-27 20:46:36,604 - INFO - Prediction completed in 0.09s
2024-12-27 20:46:36,611 - INFO - Poison rate 0.05 completed in 42.24s
2024-12-27 20:46:36,612 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:46:36,612 - INFO - Total number of labels flipped: 319
2024-12-27 20:46:36,612 - INFO - Label flipping completed in 0.00s
2024-12-27 20:46:36,613 - INFO - Training set processing completed in 0.00s
2024-12-27 20:46:36,613 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:46:36,613 - INFO - Memory usage at start_fit: CPU 3109.5 MB, GPU 49.3 MB
2024-12-27 20:46:36,614 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:46:36,679 - INFO - Fitted scaler and transformed data
2024-12-27 20:46:36,679 - INFO - Scaling time: 0.07s
2024-12-27 20:46:36,692 - INFO - Number of unique classes: 10
2024-12-27 20:46:39,293 - INFO - Epoch 1/15, Train Loss: 2.2973, Val Loss: 2.2911
2024-12-27 20:46:42,790 - INFO - Epoch 2/15, Train Loss: 2.2826, Val Loss: 2.2777
2024-12-27 20:46:45,246 - INFO - Epoch 3/15, Train Loss: 2.2660, Val Loss: 2.2620
2024-12-27 20:46:48,288 - INFO - Epoch 4/15, Train Loss: 2.2468, Val Loss: 2.2438
2024-12-27 20:46:51,006 - INFO - Epoch 5/15, Train Loss: 2.2247, Val Loss: 2.2230
2024-12-27 20:46:53,711 - INFO - Epoch 6/15, Train Loss: 2.2006, Val Loss: 2.2004
2024-12-27 20:46:56,319 - INFO - Epoch 7/15, Train Loss: 2.1749, Val Loss: 2.1775
2024-12-27 20:46:59,238 - INFO - Epoch 8/15, Train Loss: 2.1494, Val Loss: 2.1555
2024-12-27 20:47:02,151 - INFO - Epoch 9/15, Train Loss: 2.1256, Val Loss: 2.1354
2024-12-27 20:47:04,770 - INFO - Epoch 10/15, Train Loss: 2.1039, Val Loss: 2.1176
2024-12-27 20:47:07,580 - INFO - Epoch 11/15, Train Loss: 2.0848, Val Loss: 2.1022
2024-12-27 20:47:10,697 - INFO - Epoch 12/15, Train Loss: 2.0687, Val Loss: 2.0891
2024-12-27 20:47:13,579 - INFO - Epoch 13/15, Train Loss: 2.0545, Val Loss: 2.0778
2024-12-27 20:47:16,638 - INFO - Epoch 14/15, Train Loss: 2.0423, Val Loss: 2.0681
2024-12-27 20:47:20,544 - INFO - Epoch 15/15, Train Loss: 2.0314, Val Loss: 2.0598
2024-12-27 20:47:20,544 - INFO - Training completed in 43.93s
2024-12-27 20:47:20,545 - INFO - Final memory usage: CPU 3109.5 MB, GPU 75.5 MB
2024-12-27 20:47:20,545 - INFO - Model training completed in 43.93s
2024-12-27 20:47:20,670 - INFO - Prediction completed in 0.12s
2024-12-27 20:47:20,677 - INFO - Poison rate 0.07 completed in 44.07s
2024-12-27 20:47:20,677 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:47:20,678 - INFO - Total number of labels flipped: 453
2024-12-27 20:47:20,678 - INFO - Label flipping completed in 0.00s
2024-12-27 20:47:20,678 - INFO - Training set processing completed in 0.00s
2024-12-27 20:47:20,678 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:47:20,679 - INFO - Memory usage at start_fit: CPU 3109.5 MB, GPU 49.3 MB
2024-12-27 20:47:20,679 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:47:20,744 - INFO - Fitted scaler and transformed data
2024-12-27 20:47:20,744 - INFO - Scaling time: 0.06s
2024-12-27 20:47:20,755 - INFO - Number of unique classes: 10
2024-12-27 20:47:24,305 - INFO - Epoch 1/15, Train Loss: 2.2974, Val Loss: 2.2910
2024-12-27 20:47:27,609 - INFO - Epoch 2/15, Train Loss: 2.2827, Val Loss: 2.2776
2024-12-27 20:47:30,569 - INFO - Epoch 3/15, Train Loss: 2.2662, Val Loss: 2.2622
2024-12-27 20:47:33,794 - INFO - Epoch 4/15, Train Loss: 2.2474, Val Loss: 2.2444
2024-12-27 20:47:36,755 - INFO - Epoch 5/15, Train Loss: 2.2257, Val Loss: 2.2245
2024-12-27 20:47:40,557 - INFO - Epoch 6/15, Train Loss: 2.2022, Val Loss: 2.2030
2024-12-27 20:47:44,453 - INFO - Epoch 7/15, Train Loss: 2.1777, Val Loss: 2.1812
2024-12-27 20:47:47,990 - INFO - Epoch 8/15, Train Loss: 2.1531, Val Loss: 2.1605
2024-12-27 20:47:51,327 - INFO - Epoch 9/15, Train Loss: 2.1299, Val Loss: 2.1415
2024-12-27 20:47:54,941 - INFO - Epoch 10/15, Train Loss: 2.1092, Val Loss: 2.1244
2024-12-27 20:47:57,945 - INFO - Epoch 11/15, Train Loss: 2.0906, Val Loss: 2.1098
2024-12-27 20:48:01,730 - INFO - Epoch 12/15, Train Loss: 2.0747, Val Loss: 2.0973
2024-12-27 20:48:05,124 - INFO - Epoch 13/15, Train Loss: 2.0610, Val Loss: 2.0866
2024-12-27 20:48:09,082 - INFO - Epoch 14/15, Train Loss: 2.0491, Val Loss: 2.0774
2024-12-27 20:48:12,699 - INFO - Epoch 15/15, Train Loss: 2.0380, Val Loss: 2.0695
2024-12-27 20:48:12,699 - INFO - Training completed in 52.02s
2024-12-27 20:48:12,699 - INFO - Final memory usage: CPU 3109.5 MB, GPU 75.5 MB
2024-12-27 20:48:12,699 - INFO - Model training completed in 52.02s
2024-12-27 20:48:12,816 - INFO - Prediction completed in 0.12s
2024-12-27 20:48:12,824 - INFO - Poison rate 0.1 completed in 52.15s
2024-12-27 20:48:12,824 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:48:12,825 - INFO - Total number of labels flipped: 893
2024-12-27 20:48:12,825 - INFO - Label flipping completed in 0.00s
2024-12-27 20:48:12,825 - INFO - Training set processing completed in 0.00s
2024-12-27 20:48:12,825 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:48:12,826 - INFO - Memory usage at start_fit: CPU 3109.5 MB, GPU 49.3 MB
2024-12-27 20:48:12,826 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:48:12,891 - INFO - Fitted scaler and transformed data
2024-12-27 20:48:12,891 - INFO - Scaling time: 0.06s
2024-12-27 20:48:12,902 - INFO - Number of unique classes: 10
2024-12-27 20:48:16,031 - INFO - Epoch 1/15, Train Loss: 2.2972, Val Loss: 2.2906
2024-12-27 20:48:19,038 - INFO - Epoch 2/15, Train Loss: 2.2826, Val Loss: 2.2768
2024-12-27 20:48:22,510 - INFO - Epoch 3/15, Train Loss: 2.2664, Val Loss: 2.2612
2024-12-27 20:48:25,590 - INFO - Epoch 4/15, Train Loss: 2.2484, Val Loss: 2.2436
2024-12-27 20:48:28,435 - INFO - Epoch 5/15, Train Loss: 2.2286, Val Loss: 2.2242
2024-12-27 20:48:31,920 - INFO - Epoch 6/15, Train Loss: 2.2071, Val Loss: 2.2037
2024-12-27 20:48:36,554 - INFO - Epoch 7/15, Train Loss: 2.1850, Val Loss: 2.1829
2024-12-27 20:48:40,324 - INFO - Epoch 8/15, Train Loss: 2.1634, Val Loss: 2.1630
2024-12-27 20:48:43,524 - INFO - Epoch 9/15, Train Loss: 2.1424, Val Loss: 2.1446
2024-12-27 20:48:47,008 - INFO - Epoch 10/15, Train Loss: 2.1236, Val Loss: 2.1284
2024-12-27 20:48:49,937 - INFO - Epoch 11/15, Train Loss: 2.1067, Val Loss: 2.1141
2024-12-27 20:48:52,553 - INFO - Epoch 12/15, Train Loss: 2.0919, Val Loss: 2.1018
2024-12-27 20:48:57,101 - INFO - Epoch 13/15, Train Loss: 2.0791, Val Loss: 2.0912
2024-12-27 20:49:01,127 - INFO - Epoch 14/15, Train Loss: 2.0680, Val Loss: 2.0821
2024-12-27 20:49:04,843 - INFO - Epoch 15/15, Train Loss: 2.0576, Val Loss: 2.0743
2024-12-27 20:49:04,844 - INFO - Training completed in 52.02s
2024-12-27 20:49:04,844 - INFO - Final memory usage: CPU 3109.5 MB, GPU 75.5 MB
2024-12-27 20:49:04,844 - INFO - Model training completed in 52.02s
2024-12-27 20:49:04,985 - INFO - Prediction completed in 0.14s
2024-12-27 20:49:04,993 - INFO - Poison rate 0.2 completed in 52.17s
2024-12-27 20:49:04,993 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:49:04,993 - INFO - Total evaluation time: 343.80s
2024-12-27 20:49:04,995 - INFO - 
Progress: 81.2% - Evaluating ImageNette with RandomForest (dynadetect mode, iteration 1/1)
2024-12-27 20:49:05,056 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:49:05,226 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:49:05,324 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 20:49:05,325 - INFO - Dataset type: image
2024-12-27 20:49:05,325 - INFO - Sample size: 5000
2024-12-27 20:49:05,325 - INFO - Using device: cuda
2024-12-27 20:49:05,328 - INFO - Loading datasets...
2024-12-27 20:49:05,354 - INFO - Dataset loading completed in 0.03s
2024-12-27 20:49:05,354 - INFO - Extracting validation features...
2024-12-27 20:49:05,355 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:22,  1.39it/s]Extracting features:  12%|█▎        | 4/32 [00:00<00:04,  6.11it/s]Extracting features:  28%|██▊       | 9/32 [00:00<00:01, 14.46it/s]Extracting features:  41%|████      | 13/32 [00:01<00:01, 13.64it/s]Extracting features:  50%|█████     | 16/32 [00:01<00:01, 11.94it/s]Extracting features:  56%|█████▋    | 18/32 [00:01<00:01, 11.48it/s]Extracting features:  69%|██████▉   | 22/32 [00:02<00:00, 12.54it/s]Extracting features:  81%|████████▏ | 26/32 [00:02<00:00, 13.88it/s]Extracting features:  94%|█████████▍| 30/32 [00:02<00:00, 14.97it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 12.20it/s]
2024-12-27 20:49:07,984 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:49:07,985 - INFO - Validation feature extraction completed in 2.63s
2024-12-27 20:49:07,985 - INFO - Extracting training features...
2024-12-27 20:49:07,985 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:07,  2.32it/s]Extracting features:   1%|▏         | 2/157 [00:00<00:44,  3.52it/s]Extracting features:   3%|▎         | 5/157 [00:00<00:17,  8.61it/s]Extracting features:   4%|▍         | 7/157 [00:01<00:17,  8.46it/s]Extracting features:   6%|▋         | 10/157 [00:01<00:14, 10.33it/s]Extracting features:   9%|▉         | 14/157 [00:01<00:11, 12.50it/s]Extracting features:  11%|█▏        | 18/157 [00:01<00:10, 12.66it/s]Extracting features:  14%|█▍        | 22/157 [00:02<00:09, 13.84it/s]Extracting features:  17%|█▋        | 26/157 [00:02<00:08, 15.23it/s]Extracting features:  19%|█▉        | 30/157 [00:02<00:08, 15.49it/s]Extracting features:  22%|██▏       | 34/157 [00:02<00:07, 16.77it/s]Extracting features:  24%|██▍       | 38/157 [00:02<00:06, 18.68it/s]Extracting features:  27%|██▋       | 42/157 [00:03<00:06, 18.67it/s]Extracting features:  29%|██▉       | 46/157 [00:03<00:06, 17.76it/s]Extracting features:  32%|███▏      | 50/157 [00:03<00:06, 17.50it/s]Extracting features:  34%|███▍      | 54/157 [00:03<00:05, 17.83it/s]Extracting features:  36%|███▋      | 57/157 [00:03<00:05, 16.68it/s]Extracting features:  39%|███▉      | 61/157 [00:04<00:05, 16.73it/s]Extracting features:  41%|████▏     | 65/157 [00:04<00:05, 16.79it/s]Extracting features:  43%|████▎     | 68/157 [00:04<00:05, 16.77it/s]Extracting features:  45%|████▍     | 70/157 [00:04<00:05, 16.04it/s]Extracting features:  46%|████▌     | 72/157 [00:04<00:05, 15.29it/s]Extracting features:  47%|████▋     | 74/157 [00:05<00:05, 15.93it/s]Extracting features:  48%|████▊     | 76/157 [00:05<00:05, 13.59it/s]Extracting features:  50%|█████     | 79/157 [00:05<00:04, 16.52it/s]Extracting features:  52%|█████▏    | 81/157 [00:05<00:05, 14.76it/s]Extracting features:  53%|█████▎    | 83/157 [00:05<00:05, 12.35it/s]Extracting features:  54%|█████▍    | 85/157 [00:05<00:05, 12.42it/s]Extracting features:  55%|█████▌    | 87/157 [00:06<00:05, 13.20it/s]Extracting features:  57%|█████▋    | 89/157 [00:06<00:05, 12.60it/s]Extracting features:  58%|█████▊    | 91/157 [00:06<00:06, 10.72it/s]Extracting features:  60%|█████▉    | 94/157 [00:06<00:05, 11.28it/s]Extracting features:  62%|██████▏   | 98/157 [00:06<00:04, 12.67it/s]Extracting features:  65%|██████▍   | 102/157 [00:07<00:04, 11.54it/s]Extracting features:  68%|██████▊   | 106/157 [00:07<00:03, 13.04it/s]Extracting features:  70%|███████   | 110/157 [00:07<00:03, 12.40it/s]Extracting features:  72%|███████▏  | 113/157 [00:08<00:03, 11.86it/s]Extracting features:  73%|███████▎  | 115/157 [00:08<00:03, 11.64it/s]Extracting features:  75%|███████▍  | 117/157 [00:08<00:03, 12.34it/s]Extracting features:  76%|███████▌  | 119/157 [00:08<00:02, 12.84it/s]Extracting features:  77%|███████▋  | 121/157 [00:08<00:02, 12.68it/s]Extracting features:  78%|███████▊  | 123/157 [00:09<00:03, 10.21it/s]Extracting features:  80%|████████  | 126/157 [00:09<00:02, 12.38it/s]Extracting features:  83%|████████▎ | 130/157 [00:09<00:01, 15.41it/s]Extracting features:  85%|████████▍ | 133/157 [00:09<00:01, 17.08it/s]Extracting features:  86%|████████▌ | 135/157 [00:09<00:01, 15.58it/s]Extracting features:  88%|████████▊ | 138/157 [00:09<00:01, 16.20it/s]Extracting features:  90%|████████▉ | 141/157 [00:10<00:00, 16.89it/s]Extracting features:  92%|█████████▏| 144/157 [00:10<00:00, 18.20it/s]Extracting features:  93%|█████████▎| 146/157 [00:10<00:00, 14.98it/s]Extracting features:  95%|█████████▍| 149/157 [00:10<00:00, 17.44it/s]Extracting features:  96%|█████████▌| 151/157 [00:10<00:00, 15.29it/s]Extracting features:  97%|█████████▋| 153/157 [00:10<00:00, 13.93it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 14.13it/s]
2024-12-27 20:49:19,112 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:49:19,112 - INFO - Training feature extraction completed in 11.13s
2024-12-27 20:49:19,112 - INFO - Creating model for classifier: RandomForest
2024-12-27 20:49:19,112 - INFO - Using device: cuda
2024-12-27 20:49:19,113 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:49:19,113 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:49:19,113 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:49:19,742 - INFO - Feature scaling completed in 0.63s
2024-12-27 20:49:19,743 - INFO - Starting feature selection (k=50)
2024-12-27 20:49:19,748 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:49:19,749 - INFO - Starting anomaly detection
2024-12-27 20:49:21,745 - INFO - Anomaly detection completed in 2.00s
2024-12-27 20:49:21,746 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:49:21,746 - INFO - Total fit_transform time: 2.63s
2024-12-27 20:49:21,746 - INFO - Training set processing completed in 2.63s
2024-12-27 20:49:21,746 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:49:21,747 - INFO - Memory usage at start_fit: CPU 3113.8 MB, GPU 47.3 MB
2024-12-27 20:49:21,748 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:49:21,819 - INFO - Fitted scaler and transformed data
2024-12-27 20:49:21,819 - INFO - Scaling time: 0.07s
2024-12-27 20:49:21,825 - INFO - Number of unique classes: 10
2024-12-27 20:49:25,212 - INFO - Epoch 1/15, Train Loss: 2.1814, Val Loss: 2.2898
2024-12-27 20:49:28,652 - INFO - Epoch 2/15, Train Loss: 2.1664, Val Loss: 2.2746
2024-12-27 20:49:31,493 - INFO - Epoch 3/15, Train Loss: 2.1489, Val Loss: 2.2568
2024-12-27 20:49:34,833 - INFO - Epoch 4/15, Train Loss: 2.1286, Val Loss: 2.2359
2024-12-27 20:49:37,835 - INFO - Epoch 5/15, Train Loss: 2.1053, Val Loss: 2.2120
2024-12-27 20:49:40,911 - INFO - Epoch 6/15, Train Loss: 2.0794, Val Loss: 2.1862
2024-12-27 20:49:44,682 - INFO - Epoch 7/15, Train Loss: 2.0523, Val Loss: 2.1600
2024-12-27 20:49:48,605 - INFO - Epoch 8/15, Train Loss: 2.0258, Val Loss: 2.1351
2024-12-27 20:49:52,101 - INFO - Epoch 9/15, Train Loss: 2.0007, Val Loss: 2.1127
2024-12-27 20:49:55,721 - INFO - Epoch 10/15, Train Loss: 1.9783, Val Loss: 2.0932
2024-12-27 20:49:59,087 - INFO - Epoch 11/15, Train Loss: 1.9592, Val Loss: 2.0764
2024-12-27 20:50:02,012 - INFO - Epoch 12/15, Train Loss: 1.9420, Val Loss: 2.0622
2024-12-27 20:50:04,974 - INFO - Epoch 13/15, Train Loss: 1.9281, Val Loss: 2.0499
2024-12-27 20:50:08,823 - INFO - Epoch 14/15, Train Loss: 1.9154, Val Loss: 2.0396
2024-12-27 20:50:12,269 - INFO - Epoch 15/15, Train Loss: 1.9053, Val Loss: 2.0307
2024-12-27 20:50:12,269 - INFO - Training completed in 50.52s
2024-12-27 20:50:12,270 - INFO - Final memory usage: CPU 3113.8 MB, GPU 75.5 MB
2024-12-27 20:50:12,270 - INFO - Model training completed in 50.52s
2024-12-27 20:50:12,419 - INFO - Prediction completed in 0.15s
2024-12-27 20:50:12,427 - INFO - Poison rate 0.0 completed in 53.31s
2024-12-27 20:50:12,427 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:50:12,428 - INFO - Total number of labels flipped: 45
2024-12-27 20:50:12,428 - INFO - Label flipping completed in 0.00s
2024-12-27 20:50:12,428 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:50:12,428 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:50:13,058 - INFO - Feature scaling completed in 0.63s
2024-12-27 20:50:13,058 - INFO - Starting feature selection (k=50)
2024-12-27 20:50:13,071 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:50:13,072 - INFO - Starting anomaly detection
2024-12-27 20:50:14,976 - INFO - Anomaly detection completed in 1.90s
2024-12-27 20:50:14,977 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:50:14,977 - INFO - Total fit_transform time: 2.55s
2024-12-27 20:50:14,977 - INFO - Training set processing completed in 2.55s
2024-12-27 20:50:14,977 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:50:14,979 - INFO - Memory usage at start_fit: CPU 3113.8 MB, GPU 49.3 MB
2024-12-27 20:50:14,979 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:50:15,063 - INFO - Fitted scaler and transformed data
2024-12-27 20:50:15,064 - INFO - Scaling time: 0.08s
2024-12-27 20:50:15,070 - INFO - Number of unique classes: 10
2024-12-27 20:50:17,920 - INFO - Epoch 1/15, Train Loss: 2.1838, Val Loss: 2.2900
2024-12-27 20:50:21,218 - INFO - Epoch 2/15, Train Loss: 2.1690, Val Loss: 2.2753
2024-12-27 20:50:24,965 - INFO - Epoch 3/15, Train Loss: 2.1520, Val Loss: 2.2581
2024-12-27 20:50:27,905 - INFO - Epoch 4/15, Train Loss: 2.1324, Val Loss: 2.2379
2024-12-27 20:50:31,244 - INFO - Epoch 5/15, Train Loss: 2.1098, Val Loss: 2.2150
2024-12-27 20:50:34,659 - INFO - Epoch 6/15, Train Loss: 2.0851, Val Loss: 2.1901
2024-12-27 20:50:37,881 - INFO - Epoch 7/15, Train Loss: 2.0584, Val Loss: 2.1648
2024-12-27 20:50:41,756 - INFO - Epoch 8/15, Train Loss: 2.0330, Val Loss: 2.1404
2024-12-27 20:50:45,137 - INFO - Epoch 9/15, Train Loss: 2.0083, Val Loss: 2.1184
2024-12-27 20:50:48,702 - INFO - Epoch 10/15, Train Loss: 1.9866, Val Loss: 2.0990
2024-12-27 20:50:51,907 - INFO - Epoch 11/15, Train Loss: 1.9674, Val Loss: 2.0823
2024-12-27 20:50:54,738 - INFO - Epoch 12/15, Train Loss: 1.9507, Val Loss: 2.0680
2024-12-27 20:50:57,808 - INFO - Epoch 13/15, Train Loss: 1.9368, Val Loss: 2.0559
2024-12-27 20:51:01,155 - INFO - Epoch 14/15, Train Loss: 1.9245, Val Loss: 2.0455
2024-12-27 20:51:04,520 - INFO - Epoch 15/15, Train Loss: 1.9138, Val Loss: 2.0367
2024-12-27 20:51:04,521 - INFO - Training completed in 49.54s
2024-12-27 20:51:04,521 - INFO - Final memory usage: CPU 3113.8 MB, GPU 75.5 MB
2024-12-27 20:51:04,521 - INFO - Model training completed in 49.54s
2024-12-27 20:51:04,703 - INFO - Prediction completed in 0.18s
2024-12-27 20:51:04,710 - INFO - Poison rate 0.01 completed in 52.28s
2024-12-27 20:51:04,710 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:51:04,711 - INFO - Total number of labels flipped: 133
2024-12-27 20:51:04,711 - INFO - Label flipping completed in 0.00s
2024-12-27 20:51:04,711 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:51:04,712 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:51:05,308 - INFO - Feature scaling completed in 0.60s
2024-12-27 20:51:05,308 - INFO - Starting feature selection (k=50)
2024-12-27 20:51:05,321 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:51:05,322 - INFO - Starting anomaly detection
2024-12-27 20:51:06,949 - INFO - Anomaly detection completed in 1.63s
2024-12-27 20:51:06,949 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:51:06,949 - INFO - Total fit_transform time: 2.24s
2024-12-27 20:51:06,949 - INFO - Training set processing completed in 2.24s
2024-12-27 20:51:06,949 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:51:06,951 - INFO - Memory usage at start_fit: CPU 3113.8 MB, GPU 49.3 MB
2024-12-27 20:51:06,951 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:51:07,029 - INFO - Fitted scaler and transformed data
2024-12-27 20:51:07,029 - INFO - Scaling time: 0.08s
2024-12-27 20:51:07,035 - INFO - Number of unique classes: 10
2024-12-27 20:51:10,248 - INFO - Epoch 1/15, Train Loss: 2.1817, Val Loss: 2.2906
2024-12-27 20:51:13,806 - INFO - Epoch 2/15, Train Loss: 2.1672, Val Loss: 2.2766
2024-12-27 20:51:16,859 - INFO - Epoch 3/15, Train Loss: 2.1507, Val Loss: 2.2600
2024-12-27 20:51:19,495 - INFO - Epoch 4/15, Train Loss: 2.1316, Val Loss: 2.2408
2024-12-27 20:51:22,104 - INFO - Epoch 5/15, Train Loss: 2.1097, Val Loss: 2.2190
2024-12-27 20:51:25,662 - INFO - Epoch 6/15, Train Loss: 2.0856, Val Loss: 2.1954
2024-12-27 20:51:29,174 - INFO - Epoch 7/15, Train Loss: 2.0601, Val Loss: 2.1716
2024-12-27 20:51:32,270 - INFO - Epoch 8/15, Train Loss: 2.0349, Val Loss: 2.1488
2024-12-27 20:51:35,586 - INFO - Epoch 9/15, Train Loss: 2.0117, Val Loss: 2.1281
2024-12-27 20:51:38,926 - INFO - Epoch 10/15, Train Loss: 1.9907, Val Loss: 2.1097
2024-12-27 20:51:42,044 - INFO - Epoch 11/15, Train Loss: 1.9717, Val Loss: 2.0940
2024-12-27 20:51:45,025 - INFO - Epoch 12/15, Train Loss: 1.9554, Val Loss: 2.0804
2024-12-27 20:51:47,917 - INFO - Epoch 13/15, Train Loss: 1.9417, Val Loss: 2.0689
2024-12-27 20:51:51,632 - INFO - Epoch 14/15, Train Loss: 1.9297, Val Loss: 2.0589
2024-12-27 20:51:55,460 - INFO - Epoch 15/15, Train Loss: 1.9191, Val Loss: 2.0503
2024-12-27 20:51:55,460 - INFO - Training completed in 48.51s
2024-12-27 20:51:55,460 - INFO - Final memory usage: CPU 3113.8 MB, GPU 75.5 MB
2024-12-27 20:51:55,461 - INFO - Model training completed in 48.51s
2024-12-27 20:51:55,601 - INFO - Prediction completed in 0.14s
2024-12-27 20:51:55,609 - INFO - Poison rate 0.03 completed in 50.90s
2024-12-27 20:51:55,609 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:51:55,609 - INFO - Total number of labels flipped: 227
2024-12-27 20:51:55,609 - INFO - Label flipping completed in 0.00s
2024-12-27 20:51:55,610 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:51:55,610 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:51:56,181 - INFO - Feature scaling completed in 0.57s
2024-12-27 20:51:56,181 - INFO - Starting feature selection (k=50)
2024-12-27 20:51:56,193 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:51:56,194 - INFO - Starting anomaly detection
2024-12-27 20:51:58,460 - INFO - Anomaly detection completed in 2.27s
2024-12-27 20:51:58,461 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:51:58,461 - INFO - Total fit_transform time: 2.85s
2024-12-27 20:51:58,461 - INFO - Training set processing completed in 2.85s
2024-12-27 20:51:58,461 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:51:58,462 - INFO - Memory usage at start_fit: CPU 3113.8 MB, GPU 49.3 MB
2024-12-27 20:51:58,463 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:51:58,534 - INFO - Fitted scaler and transformed data
2024-12-27 20:51:58,534 - INFO - Scaling time: 0.07s
2024-12-27 20:51:58,539 - INFO - Number of unique classes: 10
2024-12-27 20:52:01,182 - INFO - Epoch 1/15, Train Loss: 2.1757, Val Loss: 2.2902
2024-12-27 20:52:03,771 - INFO - Epoch 2/15, Train Loss: 2.1611, Val Loss: 2.2759
2024-12-27 20:52:07,063 - INFO - Epoch 3/15, Train Loss: 2.1446, Val Loss: 2.2589
2024-12-27 20:52:10,030 - INFO - Epoch 4/15, Train Loss: 2.1253, Val Loss: 2.2391
2024-12-27 20:52:12,983 - INFO - Epoch 5/15, Train Loss: 2.1031, Val Loss: 2.2166
2024-12-27 20:52:16,952 - INFO - Epoch 6/15, Train Loss: 2.0788, Val Loss: 2.1923
2024-12-27 20:52:20,299 - INFO - Epoch 7/15, Train Loss: 2.0533, Val Loss: 2.1675
2024-12-27 20:52:23,818 - INFO - Epoch 8/15, Train Loss: 2.0277, Val Loss: 2.1438
2024-12-27 20:52:27,020 - INFO - Epoch 9/15, Train Loss: 2.0043, Val Loss: 2.1222
2024-12-27 20:52:30,215 - INFO - Epoch 10/15, Train Loss: 1.9832, Val Loss: 2.1030
2024-12-27 20:52:33,392 - INFO - Epoch 11/15, Train Loss: 1.9647, Val Loss: 2.0864
2024-12-27 20:52:35,965 - INFO - Epoch 12/15, Train Loss: 1.9482, Val Loss: 2.0723
2024-12-27 20:52:38,688 - INFO - Epoch 13/15, Train Loss: 1.9347, Val Loss: 2.0601
2024-12-27 20:52:41,942 - INFO - Epoch 14/15, Train Loss: 1.9223, Val Loss: 2.0497
2024-12-27 20:52:45,781 - INFO - Epoch 15/15, Train Loss: 1.9119, Val Loss: 2.0407
2024-12-27 20:52:45,782 - INFO - Training completed in 47.32s
2024-12-27 20:52:45,782 - INFO - Final memory usage: CPU 3113.8 MB, GPU 75.5 MB
2024-12-27 20:52:45,782 - INFO - Model training completed in 47.32s
2024-12-27 20:52:45,920 - INFO - Prediction completed in 0.14s
2024-12-27 20:52:45,928 - INFO - Poison rate 0.05 completed in 50.32s
2024-12-27 20:52:45,928 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:52:45,929 - INFO - Total number of labels flipped: 324
2024-12-27 20:52:45,929 - INFO - Label flipping completed in 0.00s
2024-12-27 20:52:45,929 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:52:45,929 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:52:46,544 - INFO - Feature scaling completed in 0.61s
2024-12-27 20:52:46,544 - INFO - Starting feature selection (k=50)
2024-12-27 20:52:46,557 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:52:46,557 - INFO - Starting anomaly detection
2024-12-27 20:52:48,782 - INFO - Anomaly detection completed in 2.22s
2024-12-27 20:52:48,782 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:52:48,782 - INFO - Total fit_transform time: 2.85s
2024-12-27 20:52:48,782 - INFO - Training set processing completed in 2.85s
2024-12-27 20:52:48,782 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:52:48,783 - INFO - Memory usage at start_fit: CPU 3113.8 MB, GPU 49.3 MB
2024-12-27 20:52:48,783 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:52:48,865 - INFO - Fitted scaler and transformed data
2024-12-27 20:52:48,866 - INFO - Scaling time: 0.08s
2024-12-27 20:52:48,874 - INFO - Number of unique classes: 10
2024-12-27 20:52:52,221 - INFO - Epoch 1/15, Train Loss: 2.1832, Val Loss: 2.2905
2024-12-27 20:52:55,335 - INFO - Epoch 2/15, Train Loss: 2.1691, Val Loss: 2.2765
2024-12-27 20:52:58,625 - INFO - Epoch 3/15, Train Loss: 2.1530, Val Loss: 2.2601
2024-12-27 20:53:02,568 - INFO - Epoch 4/15, Train Loss: 2.1347, Val Loss: 2.2406
2024-12-27 20:53:06,141 - INFO - Epoch 5/15, Train Loss: 2.1133, Val Loss: 2.2187
2024-12-27 20:53:09,724 - INFO - Epoch 6/15, Train Loss: 2.0896, Val Loss: 2.1948
2024-12-27 20:53:13,517 - INFO - Epoch 7/15, Train Loss: 2.0651, Val Loss: 2.1705
2024-12-27 20:53:17,018 - INFO - Epoch 8/15, Train Loss: 2.0400, Val Loss: 2.1472
2024-12-27 20:53:20,963 - INFO - Epoch 9/15, Train Loss: 2.0172, Val Loss: 2.1260
2024-12-27 20:53:24,491 - INFO - Epoch 10/15, Train Loss: 1.9963, Val Loss: 2.1075
2024-12-27 20:53:28,305 - INFO - Epoch 11/15, Train Loss: 1.9779, Val Loss: 2.0914
2024-12-27 20:53:31,736 - INFO - Epoch 12/15, Train Loss: 1.9619, Val Loss: 2.0776
2024-12-27 20:53:35,298 - INFO - Epoch 13/15, Train Loss: 1.9489, Val Loss: 2.0659
2024-12-27 20:53:38,865 - INFO - Epoch 14/15, Train Loss: 1.9366, Val Loss: 2.0559
2024-12-27 20:53:42,857 - INFO - Epoch 15/15, Train Loss: 1.9261, Val Loss: 2.0472
2024-12-27 20:53:42,857 - INFO - Training completed in 54.07s
2024-12-27 20:53:42,858 - INFO - Final memory usage: CPU 3113.8 MB, GPU 75.5 MB
2024-12-27 20:53:42,858 - INFO - Model training completed in 54.08s
2024-12-27 20:53:42,986 - INFO - Prediction completed in 0.13s
2024-12-27 20:53:42,994 - INFO - Poison rate 0.07 completed in 57.07s
2024-12-27 20:53:42,994 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:53:42,995 - INFO - Total number of labels flipped: 447
2024-12-27 20:53:42,995 - INFO - Label flipping completed in 0.00s
2024-12-27 20:53:42,995 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:53:42,995 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:53:43,565 - INFO - Feature scaling completed in 0.57s
2024-12-27 20:53:43,565 - INFO - Starting feature selection (k=50)
2024-12-27 20:53:43,578 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:53:43,579 - INFO - Starting anomaly detection
2024-12-27 20:53:45,822 - INFO - Anomaly detection completed in 2.24s
2024-12-27 20:53:45,822 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:53:45,822 - INFO - Total fit_transform time: 2.83s
2024-12-27 20:53:45,823 - INFO - Training set processing completed in 2.83s
2024-12-27 20:53:45,823 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:53:45,823 - INFO - Memory usage at start_fit: CPU 3113.8 MB, GPU 49.3 MB
2024-12-27 20:53:45,824 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:53:45,891 - INFO - Fitted scaler and transformed data
2024-12-27 20:53:45,891 - INFO - Scaling time: 0.07s
2024-12-27 20:53:45,896 - INFO - Number of unique classes: 10
2024-12-27 20:53:49,069 - INFO - Epoch 1/15, Train Loss: 2.1813, Val Loss: 2.2912
2024-12-27 20:53:52,854 - INFO - Epoch 2/15, Train Loss: 2.1677, Val Loss: 2.2781
2024-12-27 20:53:56,109 - INFO - Epoch 3/15, Train Loss: 2.1524, Val Loss: 2.2630
2024-12-27 20:53:59,625 - INFO - Epoch 4/15, Train Loss: 2.1348, Val Loss: 2.2456
2024-12-27 20:54:02,860 - INFO - Epoch 5/15, Train Loss: 2.1151, Val Loss: 2.2257
2024-12-27 20:54:06,110 - INFO - Epoch 6/15, Train Loss: 2.0929, Val Loss: 2.2044
2024-12-27 20:54:09,641 - INFO - Epoch 7/15, Train Loss: 2.0695, Val Loss: 2.1824
2024-12-27 20:54:12,788 - INFO - Epoch 8/15, Train Loss: 2.0466, Val Loss: 2.1613
2024-12-27 20:54:16,365 - INFO - Epoch 9/15, Train Loss: 2.0251, Val Loss: 2.1417
2024-12-27 20:54:19,044 - INFO - Epoch 10/15, Train Loss: 2.0050, Val Loss: 2.1245
2024-12-27 20:54:21,644 - INFO - Epoch 11/15, Train Loss: 1.9883, Val Loss: 2.1094
2024-12-27 20:54:25,002 - INFO - Epoch 12/15, Train Loss: 1.9726, Val Loss: 2.0965
2024-12-27 20:54:28,397 - INFO - Epoch 13/15, Train Loss: 1.9593, Val Loss: 2.0854
2024-12-27 20:54:31,668 - INFO - Epoch 14/15, Train Loss: 1.9485, Val Loss: 2.0758
2024-12-27 20:54:34,748 - INFO - Epoch 15/15, Train Loss: 1.9380, Val Loss: 2.0674
2024-12-27 20:54:34,748 - INFO - Training completed in 48.93s
2024-12-27 20:54:34,749 - INFO - Final memory usage: CPU 3113.8 MB, GPU 75.5 MB
2024-12-27 20:54:34,749 - INFO - Model training completed in 48.93s
2024-12-27 20:54:34,851 - INFO - Prediction completed in 0.10s
2024-12-27 20:54:34,859 - INFO - Poison rate 0.1 completed in 51.86s
2024-12-27 20:54:34,859 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:54:34,860 - INFO - Total number of labels flipped: 889
2024-12-27 20:54:34,860 - INFO - Label flipping completed in 0.00s
2024-12-27 20:54:34,860 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:54:34,860 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:54:35,409 - INFO - Feature scaling completed in 0.55s
2024-12-27 20:54:35,410 - INFO - Starting feature selection (k=50)
2024-12-27 20:54:35,423 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:54:35,423 - INFO - Starting anomaly detection
2024-12-27 20:54:37,451 - INFO - Anomaly detection completed in 2.03s
2024-12-27 20:54:37,452 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:54:37,452 - INFO - Total fit_transform time: 2.59s
2024-12-27 20:54:37,452 - INFO - Training set processing completed in 2.59s
2024-12-27 20:54:37,452 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:54:37,453 - INFO - Memory usage at start_fit: CPU 3113.8 MB, GPU 49.3 MB
2024-12-27 20:54:37,454 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:54:37,525 - INFO - Fitted scaler and transformed data
2024-12-27 20:54:37,525 - INFO - Scaling time: 0.07s
2024-12-27 20:54:37,534 - INFO - Number of unique classes: 10
2024-12-27 20:54:40,494 - INFO - Epoch 1/15, Train Loss: 2.1831, Val Loss: 2.2907
2024-12-27 20:54:43,273 - INFO - Epoch 2/15, Train Loss: 2.1691, Val Loss: 2.2771
2024-12-27 20:54:45,946 - INFO - Epoch 3/15, Train Loss: 2.1537, Val Loss: 2.2618
2024-12-27 20:54:48,702 - INFO - Epoch 4/15, Train Loss: 2.1364, Val Loss: 2.2446
2024-12-27 20:54:51,852 - INFO - Epoch 5/15, Train Loss: 2.1174, Val Loss: 2.2258
2024-12-27 20:54:55,295 - INFO - Epoch 6/15, Train Loss: 2.0963, Val Loss: 2.2060
2024-12-27 20:54:58,536 - INFO - Epoch 7/15, Train Loss: 2.0754, Val Loss: 2.1861
2024-12-27 20:55:01,911 - INFO - Epoch 8/15, Train Loss: 2.0537, Val Loss: 2.1673
2024-12-27 20:55:05,375 - INFO - Epoch 9/15, Train Loss: 2.0339, Val Loss: 2.1501
2024-12-27 20:55:08,469 - INFO - Epoch 10/15, Train Loss: 2.0156, Val Loss: 2.1347
2024-12-27 20:55:11,747 - INFO - Epoch 11/15, Train Loss: 1.9999, Val Loss: 2.1214
2024-12-27 20:55:15,036 - INFO - Epoch 12/15, Train Loss: 1.9852, Val Loss: 2.1101
2024-12-27 20:55:18,178 - INFO - Epoch 13/15, Train Loss: 1.9728, Val Loss: 2.1002
2024-12-27 20:55:21,630 - INFO - Epoch 14/15, Train Loss: 1.9617, Val Loss: 2.0918
2024-12-27 20:55:24,362 - INFO - Epoch 15/15, Train Loss: 1.9529, Val Loss: 2.0844
2024-12-27 20:55:24,362 - INFO - Training completed in 46.91s
2024-12-27 20:55:24,362 - INFO - Final memory usage: CPU 3113.8 MB, GPU 75.5 MB
2024-12-27 20:55:24,363 - INFO - Model training completed in 46.91s
2024-12-27 20:55:24,463 - INFO - Prediction completed in 0.10s
2024-12-27 20:55:24,471 - INFO - Poison rate 0.2 completed in 49.61s
2024-12-27 20:55:24,471 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:55:24,472 - INFO - Total evaluation time: 379.14s
2024-12-27 20:55:24,473 - INFO - 
Progress: 82.3% - Evaluating ImageNette with KNeighbors (standard mode, iteration 1/1)
2024-12-27 20:55:24,533 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:55:24,720 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:55:24,816 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 20:55:24,816 - INFO - Dataset type: image
2024-12-27 20:55:24,816 - INFO - Sample size: 5000
2024-12-27 20:55:24,816 - INFO - Using device: cuda
2024-12-27 20:55:24,819 - INFO - Loading datasets...
2024-12-27 20:55:24,845 - INFO - Dataset loading completed in 0.03s
2024-12-27 20:55:24,845 - INFO - Extracting validation features...
2024-12-27 20:55:24,845 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:22,  1.35it/s]Extracting features:  19%|█▉        | 6/32 [00:00<00:02,  9.05it/s]Extracting features:  28%|██▊       | 9/32 [00:01<00:02, 10.40it/s]Extracting features:  38%|███▊      | 12/32 [00:01<00:01, 13.78it/s]Extracting features:  47%|████▋     | 15/32 [00:01<00:01, 13.56it/s]Extracting features:  56%|█████▋    | 18/32 [00:01<00:01, 11.97it/s]Extracting features:  66%|██████▌   | 21/32 [00:02<00:00, 11.06it/s]Extracting features:  78%|███████▊  | 25/32 [00:02<00:00, 12.60it/s]Extracting features:  91%|█████████ | 29/32 [00:02<00:00, 13.63it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 11.95it/s]
2024-12-27 20:55:27,528 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:55:27,529 - INFO - Validation feature extraction completed in 2.68s
2024-12-27 20:55:27,529 - INFO - Extracting training features...
2024-12-27 20:55:27,529 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:26,  1.81it/s]Extracting features:   3%|▎         | 5/157 [00:00<00:20,  7.56it/s]Extracting features:   6%|▌         | 9/157 [00:01<00:14, 10.45it/s]Extracting features:   8%|▊         | 13/157 [00:01<00:11, 12.95it/s]Extracting features:  10%|▉         | 15/157 [00:01<00:15,  9.17it/s]Extracting features:  11%|█▏        | 18/157 [00:01<00:13, 10.49it/s]Extracting features:  14%|█▍        | 22/157 [00:02<00:10, 12.96it/s]Extracting features:  17%|█▋        | 26/157 [00:02<00:09, 13.38it/s]Extracting features:  19%|█▉        | 30/157 [00:02<00:08, 14.31it/s]Extracting features:  22%|██▏       | 34/157 [00:02<00:08, 14.25it/s]Extracting features:  24%|██▍       | 38/157 [00:03<00:07, 16.64it/s]Extracting features:  27%|██▋       | 42/157 [00:03<00:06, 17.93it/s]Extracting features:  29%|██▉       | 46/157 [00:03<00:05, 18.73it/s]Extracting features:  32%|███▏      | 50/157 [00:03<00:05, 18.76it/s]Extracting features:  34%|███▍      | 54/157 [00:03<00:05, 18.06it/s]Extracting features:  37%|███▋      | 58/157 [00:04<00:05, 18.78it/s]Extracting features:  38%|███▊      | 60/157 [00:04<00:05, 18.85it/s]Extracting features:  39%|███▉      | 62/157 [00:04<00:05, 16.96it/s]Extracting features:  41%|████      | 64/157 [00:04<00:06, 15.05it/s]Extracting features:  43%|████▎     | 68/157 [00:04<00:06, 13.64it/s]Extracting features:  46%|████▌     | 72/157 [00:05<00:06, 14.03it/s]Extracting features:  48%|████▊     | 76/157 [00:05<00:05, 13.72it/s]Extracting features:  51%|█████     | 80/157 [00:05<00:05, 13.31it/s]Extracting features:  54%|█████▎    | 84/157 [00:06<00:06, 11.43it/s]Extracting features:  56%|█████▌    | 88/157 [00:06<00:06, 11.18it/s]Extracting features:  59%|█████▊    | 92/157 [00:06<00:05, 11.75it/s]Extracting features:  61%|██████    | 96/157 [00:07<00:04, 13.05it/s]Extracting features:  64%|██████▎   | 100/157 [00:07<00:04, 14.05it/s]Extracting features:  66%|██████▌   | 104/157 [00:07<00:03, 14.68it/s]Extracting features:  69%|██████▉   | 108/157 [00:07<00:03, 13.62it/s]Extracting features:  71%|███████▏  | 112/157 [00:08<00:03, 12.86it/s]Extracting features:  74%|███████▍  | 116/157 [00:08<00:02, 13.76it/s]Extracting features:  75%|███████▌  | 118/157 [00:08<00:03, 11.14it/s]Extracting features:  77%|███████▋  | 121/157 [00:09<00:03,  9.96it/s]Extracting features:  80%|███████▉  | 125/157 [00:09<00:02, 11.01it/s]Extracting features:  82%|████████▏ | 129/157 [00:09<00:02, 12.58it/s]Extracting features:  85%|████████▍ | 133/157 [00:10<00:01, 13.80it/s]Extracting features:  87%|████████▋ | 137/157 [00:10<00:01, 13.59it/s]Extracting features:  90%|████████▉ | 141/157 [00:10<00:01, 14.62it/s]Extracting features:  92%|█████████▏| 145/157 [00:10<00:00, 12.94it/s]Extracting features:  95%|█████████▍| 149/157 [00:11<00:00, 13.94it/s]Extracting features:  97%|█████████▋| 153/157 [00:11<00:00, 14.72it/s]Extracting features:  99%|█████████▉| 156/157 [00:11<00:00, 16.41it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 13.54it/s]
2024-12-27 20:55:39,134 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:55:39,135 - INFO - Training feature extraction completed in 11.61s
2024-12-27 20:55:39,135 - INFO - Creating model for classifier: KNeighbors
2024-12-27 20:55:39,135 - INFO - Using device: cuda
2024-12-27 20:55:39,135 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:55:39,135 - INFO - Training set processing completed in 0.00s
2024-12-27 20:55:39,135 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:55:39,137 - INFO - Memory usage at start_fit: CPU 3114.7 MB, GPU 47.3 MB
2024-12-27 20:55:39,137 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:55:39,208 - INFO - Fitted scaler and transformed data
2024-12-27 20:55:39,208 - INFO - Scaling time: 0.07s
2024-12-27 20:55:39,215 - INFO - Training completed in 0.08s
2024-12-27 20:55:39,215 - INFO - Final memory usage: CPU 3114.7 MB, GPU 71.8 MB
2024-12-27 20:55:39,215 - INFO - Model training completed in 0.08s
2024-12-27 20:55:39,239 - INFO - Prediction completed in 0.02s
2024-12-27 20:55:39,248 - INFO - Poison rate 0.0 completed in 0.11s
2024-12-27 20:55:39,248 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:55:39,248 - INFO - Total number of labels flipped: 46
2024-12-27 20:55:39,248 - INFO - Label flipping completed in 0.00s
2024-12-27 20:55:39,248 - INFO - Training set processing completed in 0.00s
2024-12-27 20:55:39,249 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:55:39,249 - INFO - Memory usage at start_fit: CPU 3114.7 MB, GPU 71.8 MB
2024-12-27 20:55:39,250 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:55:39,322 - INFO - Fitted scaler and transformed data
2024-12-27 20:55:39,322 - INFO - Scaling time: 0.07s
2024-12-27 20:55:39,328 - INFO - Training completed in 0.08s
2024-12-27 20:55:39,329 - INFO - Final memory usage: CPU 3114.7 MB, GPU 71.8 MB
2024-12-27 20:55:39,329 - INFO - Model training completed in 0.08s
2024-12-27 20:55:39,349 - INFO - Prediction completed in 0.02s
2024-12-27 20:55:39,356 - INFO - Poison rate 0.01 completed in 0.11s
2024-12-27 20:55:39,357 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:55:39,357 - INFO - Total number of labels flipped: 139
2024-12-27 20:55:39,357 - INFO - Label flipping completed in 0.00s
2024-12-27 20:55:39,358 - INFO - Training set processing completed in 0.00s
2024-12-27 20:55:39,358 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:55:39,358 - INFO - Memory usage at start_fit: CPU 3114.7 MB, GPU 71.8 MB
2024-12-27 20:55:39,359 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:55:39,418 - INFO - Fitted scaler and transformed data
2024-12-27 20:55:39,418 - INFO - Scaling time: 0.06s
2024-12-27 20:55:39,424 - INFO - Training completed in 0.07s
2024-12-27 20:55:39,424 - INFO - Final memory usage: CPU 3114.7 MB, GPU 71.8 MB
2024-12-27 20:55:39,424 - INFO - Model training completed in 0.07s
2024-12-27 20:55:39,442 - INFO - Prediction completed in 0.02s
2024-12-27 20:55:39,451 - INFO - Poison rate 0.03 completed in 0.09s
2024-12-27 20:55:39,451 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:55:39,453 - INFO - Total number of labels flipped: 218
2024-12-27 20:55:39,454 - INFO - Label flipping completed in 0.00s
2024-12-27 20:55:39,454 - INFO - Training set processing completed in 0.00s
2024-12-27 20:55:39,454 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:55:39,455 - INFO - Memory usage at start_fit: CPU 3114.7 MB, GPU 71.8 MB
2024-12-27 20:55:39,456 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:55:39,526 - INFO - Fitted scaler and transformed data
2024-12-27 20:55:39,526 - INFO - Scaling time: 0.07s
2024-12-27 20:55:39,532 - INFO - Training completed in 0.08s
2024-12-27 20:55:39,532 - INFO - Final memory usage: CPU 3114.7 MB, GPU 71.8 MB
2024-12-27 20:55:39,532 - INFO - Model training completed in 0.08s
2024-12-27 20:55:39,549 - INFO - Prediction completed in 0.02s
2024-12-27 20:55:39,557 - INFO - Poison rate 0.05 completed in 0.11s
2024-12-27 20:55:39,557 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:55:39,558 - INFO - Total number of labels flipped: 323
2024-12-27 20:55:39,558 - INFO - Label flipping completed in 0.00s
2024-12-27 20:55:39,558 - INFO - Training set processing completed in 0.00s
2024-12-27 20:55:39,558 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:55:39,559 - INFO - Memory usage at start_fit: CPU 3114.7 MB, GPU 71.8 MB
2024-12-27 20:55:39,559 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:55:39,618 - INFO - Fitted scaler and transformed data
2024-12-27 20:55:39,618 - INFO - Scaling time: 0.06s
2024-12-27 20:55:39,624 - INFO - Training completed in 0.07s
2024-12-27 20:55:39,624 - INFO - Final memory usage: CPU 3114.7 MB, GPU 71.8 MB
2024-12-27 20:55:39,624 - INFO - Model training completed in 0.07s
2024-12-27 20:55:39,643 - INFO - Prediction completed in 0.02s
2024-12-27 20:55:39,651 - INFO - Poison rate 0.07 completed in 0.09s
2024-12-27 20:55:39,651 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:55:39,652 - INFO - Total number of labels flipped: 444
2024-12-27 20:55:39,652 - INFO - Label flipping completed in 0.00s
2024-12-27 20:55:39,652 - INFO - Training set processing completed in 0.00s
2024-12-27 20:55:39,652 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:55:39,653 - INFO - Memory usage at start_fit: CPU 3114.7 MB, GPU 71.8 MB
2024-12-27 20:55:39,653 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:55:39,713 - INFO - Fitted scaler and transformed data
2024-12-27 20:55:39,714 - INFO - Scaling time: 0.06s
2024-12-27 20:55:39,719 - INFO - Training completed in 0.07s
2024-12-27 20:55:39,720 - INFO - Final memory usage: CPU 3114.7 MB, GPU 71.8 MB
2024-12-27 20:55:39,720 - INFO - Model training completed in 0.07s
2024-12-27 20:55:39,737 - INFO - Prediction completed in 0.02s
2024-12-27 20:55:39,749 - INFO - Poison rate 0.1 completed in 0.10s
2024-12-27 20:55:39,749 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:55:39,752 - INFO - Total number of labels flipped: 902
2024-12-27 20:55:39,752 - INFO - Label flipping completed in 0.00s
2024-12-27 20:55:39,752 - INFO - Training set processing completed in 0.00s
2024-12-27 20:55:39,753 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:55:39,754 - INFO - Memory usage at start_fit: CPU 3114.7 MB, GPU 71.8 MB
2024-12-27 20:55:39,754 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:55:39,813 - INFO - Fitted scaler and transformed data
2024-12-27 20:55:39,813 - INFO - Scaling time: 0.06s
2024-12-27 20:55:39,819 - INFO - Training completed in 0.07s
2024-12-27 20:55:39,819 - INFO - Final memory usage: CPU 3114.7 MB, GPU 71.8 MB
2024-12-27 20:55:39,819 - INFO - Model training completed in 0.07s
2024-12-27 20:55:39,837 - INFO - Prediction completed in 0.02s
2024-12-27 20:55:39,858 - INFO - Poison rate 0.2 completed in 0.11s
2024-12-27 20:55:39,859 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:55:39,860 - INFO - Total evaluation time: 15.04s
2024-12-27 20:55:39,863 - INFO - 
Progress: 83.3% - Evaluating ImageNette with KNeighbors (dynadetect mode, iteration 1/1)
2024-12-27 20:55:39,932 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:55:40,002 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:55:40,105 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 20:55:40,105 - INFO - Dataset type: image
2024-12-27 20:55:40,105 - INFO - Sample size: 5000
2024-12-27 20:55:40,105 - INFO - Using device: cuda
2024-12-27 20:55:40,107 - INFO - Loading datasets...
2024-12-27 20:55:40,143 - INFO - Dataset loading completed in 0.04s
2024-12-27 20:55:40,143 - INFO - Extracting validation features...
2024-12-27 20:55:40,144 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:17,  1.77it/s]Extracting features:  16%|█▌        | 5/32 [00:00<00:03,  7.44it/s]Extracting features:  28%|██▊       | 9/32 [00:01<00:02,  9.41it/s]Extracting features:  41%|████      | 13/32 [00:01<00:01, 11.54it/s]Extracting features:  53%|█████▎    | 17/32 [00:01<00:01, 11.99it/s]Extracting features:  66%|██████▌   | 21/32 [00:01<00:00, 12.39it/s]Extracting features:  75%|███████▌  | 24/32 [00:02<00:00, 14.57it/s]Extracting features:  81%|████████▏ | 26/32 [00:02<00:00, 13.56it/s]Extracting features:  91%|█████████ | 29/32 [00:02<00:00, 13.99it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 12.22it/s]
2024-12-27 20:55:42,770 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:55:42,771 - INFO - Validation feature extraction completed in 2.63s
2024-12-27 20:55:42,771 - INFO - Extracting training features...
2024-12-27 20:55:42,771 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:09,  2.24it/s]Extracting features:   3%|▎         | 5/157 [00:00<00:22,  6.79it/s]Extracting features:   6%|▌         | 9/157 [00:01<00:16,  9.14it/s]Extracting features:   8%|▊         | 13/157 [00:01<00:12, 11.61it/s]Extracting features:  10%|█         | 16/157 [00:01<00:13, 10.55it/s]Extracting features:  13%|█▎        | 20/157 [00:01<00:11, 11.94it/s]Extracting features:  15%|█▌        | 24/157 [00:02<00:10, 12.52it/s]Extracting features:  18%|█▊        | 28/157 [00:02<00:08, 14.39it/s]Extracting features:  19%|█▉        | 30/157 [00:02<00:08, 14.74it/s]Extracting features:  21%|██        | 33/157 [00:02<00:07, 15.70it/s]Extracting features:  23%|██▎       | 36/157 [00:02<00:07, 15.42it/s]Extracting features:  25%|██▌       | 40/157 [00:03<00:06, 17.68it/s]Extracting features:  28%|██▊       | 44/157 [00:03<00:06, 18.00it/s]Extracting features:  31%|███       | 48/157 [00:03<00:05, 18.52it/s]Extracting features:  33%|███▎      | 52/157 [00:03<00:06, 17.06it/s]Extracting features:  36%|███▌      | 56/157 [00:04<00:05, 17.33it/s]Extracting features:  38%|███▊      | 60/157 [00:04<00:05, 16.65it/s]Extracting features:  41%|████      | 64/157 [00:04<00:06, 15.22it/s]Extracting features:  43%|████▎     | 68/157 [00:04<00:05, 15.01it/s]Extracting features:  46%|████▌     | 72/157 [00:05<00:05, 14.80it/s]Extracting features:  48%|████▊     | 76/157 [00:05<00:05, 14.81it/s]Extracting features:  51%|█████     | 80/157 [00:05<00:05, 14.75it/s]Extracting features:  54%|█████▎    | 84/157 [00:05<00:05, 14.40it/s]Extracting features:  56%|█████▌    | 88/157 [00:06<00:04, 14.38it/s]Extracting features:  58%|█████▊    | 91/157 [00:06<00:04, 15.28it/s]Extracting features:  59%|█████▉    | 93/157 [00:06<00:04, 13.65it/s]Extracting features:  61%|██████    | 96/157 [00:06<00:04, 14.61it/s]Extracting features:  62%|██████▏   | 98/157 [00:07<00:05, 11.69it/s]Extracting features:  64%|██████▍   | 101/157 [00:07<00:04, 12.42it/s]Extracting features:  67%|██████▋   | 105/157 [00:07<00:03, 13.45it/s]Extracting features:  69%|██████▉   | 109/157 [00:07<00:03, 14.26it/s]Extracting features:  71%|███████   | 111/157 [00:07<00:03, 14.92it/s]Extracting features:  72%|███████▏  | 113/157 [00:08<00:03, 13.29it/s]Extracting features:  74%|███████▍  | 116/157 [00:08<00:02, 15.55it/s]Extracting features:  75%|███████▌  | 118/157 [00:08<00:03, 10.08it/s]Extracting features:  78%|███████▊  | 122/157 [00:09<00:03, 10.57it/s]Extracting features:  80%|████████  | 126/157 [00:09<00:02, 12.18it/s]Extracting features:  83%|████████▎ | 130/157 [00:09<00:01, 14.00it/s]Extracting features:  85%|████████▌ | 134/157 [00:09<00:01, 15.82it/s]Extracting features:  88%|████████▊ | 138/157 [00:09<00:01, 18.63it/s]Extracting features:  90%|█████████ | 142/157 [00:10<00:00, 17.30it/s]Extracting features:  92%|█████████▏| 144/157 [00:10<00:00, 17.47it/s]Extracting features:  93%|█████████▎| 146/157 [00:10<00:00, 15.96it/s]Extracting features:  96%|█████████▌| 150/157 [00:10<00:00, 16.99it/s]Extracting features:  97%|█████████▋| 152/157 [00:10<00:00, 15.30it/s]Extracting features:  98%|█████████▊| 154/157 [00:10<00:00, 14.82it/s]Extracting features: 100%|██████████| 157/157 [00:10<00:00, 14.27it/s]
2024-12-27 20:55:53,783 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:55:53,784 - INFO - Training feature extraction completed in 11.01s
2024-12-27 20:55:53,784 - INFO - Creating model for classifier: KNeighbors
2024-12-27 20:55:53,784 - INFO - Using device: cuda
2024-12-27 20:55:53,784 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:55:53,784 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:55:53,784 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:55:54,334 - INFO - Feature scaling completed in 0.55s
2024-12-27 20:55:54,335 - INFO - Starting feature selection (k=50)
2024-12-27 20:55:54,340 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:55:54,341 - INFO - Starting anomaly detection
2024-12-27 20:55:56,358 - INFO - Anomaly detection completed in 2.02s
2024-12-27 20:55:56,358 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:55:56,358 - INFO - Total fit_transform time: 2.57s
2024-12-27 20:55:56,358 - INFO - Training set processing completed in 2.57s
2024-12-27 20:55:56,358 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:55:56,359 - INFO - Memory usage at start_fit: CPU 3108.3 MB, GPU 47.3 MB
2024-12-27 20:55:56,359 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:55:56,425 - INFO - Fitted scaler and transformed data
2024-12-27 20:55:56,426 - INFO - Scaling time: 0.07s
2024-12-27 20:55:56,430 - INFO - Training completed in 0.07s
2024-12-27 20:55:56,431 - INFO - Final memory usage: CPU 3108.3 MB, GPU 71.8 MB
2024-12-27 20:55:56,431 - INFO - Model training completed in 0.07s
2024-12-27 20:55:56,446 - INFO - Prediction completed in 0.01s
2024-12-27 20:55:56,454 - INFO - Poison rate 0.0 completed in 2.67s
2024-12-27 20:55:56,454 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:55:56,455 - INFO - Total number of labels flipped: 45
2024-12-27 20:55:56,455 - INFO - Label flipping completed in 0.00s
2024-12-27 20:55:56,455 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:55:56,455 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:55:57,041 - INFO - Feature scaling completed in 0.59s
2024-12-27 20:55:57,041 - INFO - Starting feature selection (k=50)
2024-12-27 20:55:57,047 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:55:57,047 - INFO - Starting anomaly detection
2024-12-27 20:55:58,784 - INFO - Anomaly detection completed in 1.74s
2024-12-27 20:55:58,784 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:55:58,784 - INFO - Total fit_transform time: 2.33s
2024-12-27 20:55:58,784 - INFO - Training set processing completed in 2.33s
2024-12-27 20:55:58,785 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:55:58,785 - INFO - Memory usage at start_fit: CPU 3108.3 MB, GPU 71.8 MB
2024-12-27 20:55:58,786 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:55:58,852 - INFO - Fitted scaler and transformed data
2024-12-27 20:55:58,853 - INFO - Scaling time: 0.07s
2024-12-27 20:55:58,859 - INFO - Training completed in 0.07s
2024-12-27 20:55:58,859 - INFO - Final memory usage: CPU 3108.3 MB, GPU 71.8 MB
2024-12-27 20:55:58,860 - INFO - Model training completed in 0.08s
2024-12-27 20:55:58,884 - INFO - Prediction completed in 0.02s
2024-12-27 20:55:58,891 - INFO - Poison rate 0.01 completed in 2.44s
2024-12-27 20:55:58,892 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:55:58,892 - INFO - Total number of labels flipped: 128
2024-12-27 20:55:58,892 - INFO - Label flipping completed in 0.00s
2024-12-27 20:55:58,892 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:55:58,892 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:55:59,490 - INFO - Feature scaling completed in 0.60s
2024-12-27 20:55:59,490 - INFO - Starting feature selection (k=50)
2024-12-27 20:55:59,498 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:55:59,498 - INFO - Starting anomaly detection
2024-12-27 20:56:01,459 - INFO - Anomaly detection completed in 1.96s
2024-12-27 20:56:01,459 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:56:01,460 - INFO - Total fit_transform time: 2.57s
2024-12-27 20:56:01,460 - INFO - Training set processing completed in 2.57s
2024-12-27 20:56:01,460 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:56:01,461 - INFO - Memory usage at start_fit: CPU 3108.3 MB, GPU 71.8 MB
2024-12-27 20:56:01,461 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:56:01,546 - INFO - Fitted scaler and transformed data
2024-12-27 20:56:01,546 - INFO - Scaling time: 0.08s
2024-12-27 20:56:01,554 - INFO - Training completed in 0.09s
2024-12-27 20:56:01,554 - INFO - Final memory usage: CPU 3108.3 MB, GPU 71.8 MB
2024-12-27 20:56:01,554 - INFO - Model training completed in 0.09s
2024-12-27 20:56:01,580 - INFO - Prediction completed in 0.03s
2024-12-27 20:56:01,601 - INFO - Poison rate 0.03 completed in 2.71s
2024-12-27 20:56:01,601 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:56:01,603 - INFO - Total number of labels flipped: 220
2024-12-27 20:56:01,603 - INFO - Label flipping completed in 0.00s
2024-12-27 20:56:01,603 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:56:01,603 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:56:02,155 - INFO - Feature scaling completed in 0.55s
2024-12-27 20:56:02,155 - INFO - Starting feature selection (k=50)
2024-12-27 20:56:02,168 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:56:02,168 - INFO - Starting anomaly detection
2024-12-27 20:56:03,549 - INFO - Anomaly detection completed in 1.38s
2024-12-27 20:56:03,549 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:56:03,549 - INFO - Total fit_transform time: 1.95s
2024-12-27 20:56:03,549 - INFO - Training set processing completed in 1.95s
2024-12-27 20:56:03,549 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:56:03,550 - INFO - Memory usage at start_fit: CPU 3108.3 MB, GPU 71.8 MB
2024-12-27 20:56:03,550 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:56:03,628 - INFO - Fitted scaler and transformed data
2024-12-27 20:56:03,628 - INFO - Scaling time: 0.08s
2024-12-27 20:56:03,635 - INFO - Training completed in 0.09s
2024-12-27 20:56:03,636 - INFO - Final memory usage: CPU 3108.3 MB, GPU 71.8 MB
2024-12-27 20:56:03,637 - INFO - Model training completed in 0.09s
2024-12-27 20:56:03,663 - INFO - Prediction completed in 0.03s
2024-12-27 20:56:03,678 - INFO - Poison rate 0.05 completed in 2.08s
2024-12-27 20:56:03,678 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:56:03,679 - INFO - Total number of labels flipped: 314
2024-12-27 20:56:03,679 - INFO - Label flipping completed in 0.00s
2024-12-27 20:56:03,679 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:56:03,679 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:56:04,271 - INFO - Feature scaling completed in 0.59s
2024-12-27 20:56:04,271 - INFO - Starting feature selection (k=50)
2024-12-27 20:56:04,279 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:56:04,279 - INFO - Starting anomaly detection
2024-12-27 20:56:06,293 - INFO - Anomaly detection completed in 2.01s
2024-12-27 20:56:06,293 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:56:06,294 - INFO - Total fit_transform time: 2.61s
2024-12-27 20:56:06,294 - INFO - Training set processing completed in 2.61s
2024-12-27 20:56:06,294 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:56:06,295 - INFO - Memory usage at start_fit: CPU 3108.3 MB, GPU 71.8 MB
2024-12-27 20:56:06,295 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:56:06,370 - INFO - Fitted scaler and transformed data
2024-12-27 20:56:06,371 - INFO - Scaling time: 0.07s
2024-12-27 20:56:06,378 - INFO - Training completed in 0.08s
2024-12-27 20:56:06,379 - INFO - Final memory usage: CPU 3108.3 MB, GPU 71.8 MB
2024-12-27 20:56:06,379 - INFO - Model training completed in 0.09s
2024-12-27 20:56:06,405 - INFO - Prediction completed in 0.03s
2024-12-27 20:56:06,412 - INFO - Poison rate 0.07 completed in 2.73s
2024-12-27 20:56:06,412 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:56:06,413 - INFO - Total number of labels flipped: 448
2024-12-27 20:56:06,413 - INFO - Label flipping completed in 0.00s
2024-12-27 20:56:06,413 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:56:06,413 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:56:07,006 - INFO - Feature scaling completed in 0.59s
2024-12-27 20:56:07,006 - INFO - Starting feature selection (k=50)
2024-12-27 20:56:07,020 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:56:07,020 - INFO - Starting anomaly detection
2024-12-27 20:56:09,424 - INFO - Anomaly detection completed in 2.40s
2024-12-27 20:56:09,424 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:56:09,424 - INFO - Total fit_transform time: 3.01s
2024-12-27 20:56:09,424 - INFO - Training set processing completed in 3.01s
2024-12-27 20:56:09,424 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:56:09,426 - INFO - Memory usage at start_fit: CPU 3108.3 MB, GPU 71.8 MB
2024-12-27 20:56:09,426 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:56:09,501 - INFO - Fitted scaler and transformed data
2024-12-27 20:56:09,502 - INFO - Scaling time: 0.08s
2024-12-27 20:56:09,510 - INFO - Training completed in 0.08s
2024-12-27 20:56:09,510 - INFO - Final memory usage: CPU 3108.3 MB, GPU 71.8 MB
2024-12-27 20:56:09,511 - INFO - Model training completed in 0.09s
2024-12-27 20:56:09,537 - INFO - Prediction completed in 0.03s
2024-12-27 20:56:09,544 - INFO - Poison rate 0.1 completed in 3.13s
2024-12-27 20:56:09,544 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:56:09,545 - INFO - Total number of labels flipped: 889
2024-12-27 20:56:09,546 - INFO - Label flipping completed in 0.00s
2024-12-27 20:56:09,546 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:56:09,546 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:56:10,116 - INFO - Feature scaling completed in 0.57s
2024-12-27 20:56:10,116 - INFO - Starting feature selection (k=50)
2024-12-27 20:56:10,124 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:56:10,124 - INFO - Starting anomaly detection
2024-12-27 20:56:11,610 - INFO - Anomaly detection completed in 1.49s
2024-12-27 20:56:11,610 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:56:11,610 - INFO - Total fit_transform time: 2.06s
2024-12-27 20:56:11,611 - INFO - Training set processing completed in 2.07s
2024-12-27 20:56:11,611 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 20:56:11,612 - INFO - Memory usage at start_fit: CPU 3108.3 MB, GPU 71.8 MB
2024-12-27 20:56:11,612 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:56:11,687 - INFO - Fitted scaler and transformed data
2024-12-27 20:56:11,687 - INFO - Scaling time: 0.07s
2024-12-27 20:56:11,694 - INFO - Training completed in 0.08s
2024-12-27 20:56:11,694 - INFO - Final memory usage: CPU 3108.3 MB, GPU 71.8 MB
2024-12-27 20:56:11,694 - INFO - Model training completed in 0.08s
2024-12-27 20:56:11,722 - INFO - Prediction completed in 0.03s
2024-12-27 20:56:11,737 - INFO - Poison rate 0.2 completed in 2.19s
2024-12-27 20:56:11,738 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:56:11,738 - INFO - Total evaluation time: 31.63s
2024-12-27 20:56:11,741 - INFO - Completed evaluation for ImageNette
2024-12-27 20:56:11,741 - INFO - 
Processing dataset: ImageNette
2024-12-27 20:56:11,812 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:56:11,888 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:56:11,978 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 20:56:11,979 - INFO - Dataset type: image
2024-12-27 20:56:11,979 - INFO - Sample size: 5000
2024-12-27 20:56:11,979 - INFO - Using device: cuda
2024-12-27 20:56:11,981 - INFO - 
Progress: 84.4% - Evaluating ImageNette with SVM (standard mode, iteration 1/1)
2024-12-27 20:56:12,039 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:56:12,116 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:56:12,198 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 20:56:12,198 - INFO - Dataset type: image
2024-12-27 20:56:12,198 - INFO - Sample size: 5000
2024-12-27 20:56:12,198 - INFO - Using device: cuda
2024-12-27 20:56:12,200 - INFO - Loading datasets...
2024-12-27 20:56:12,225 - INFO - Dataset loading completed in 0.02s
2024-12-27 20:56:12,225 - INFO - Extracting validation features...
2024-12-27 20:56:12,225 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:17,  1.81it/s]Extracting features:   6%|▋         | 2/32 [00:00<00:10,  2.93it/s]Extracting features:  22%|██▏       | 7/32 [00:00<00:02, 12.16it/s]Extracting features:  31%|███▏      | 10/32 [00:01<00:01, 12.15it/s]Extracting features:  44%|████▍     | 14/32 [00:01<00:01, 10.50it/s]Extracting features:  56%|█████▋    | 18/32 [00:01<00:01, 12.56it/s]Extracting features:  62%|██████▎   | 20/32 [00:01<00:00, 13.07it/s]Extracting features:  69%|██████▉   | 22/32 [00:02<00:00, 13.52it/s]Extracting features:  75%|███████▌  | 24/32 [00:02<00:00, 11.43it/s]Extracting features:  88%|████████▊ | 28/32 [00:02<00:00, 13.86it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 12.20it/s]
2024-12-27 20:56:14,851 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:56:14,851 - INFO - Validation feature extraction completed in 2.63s
2024-12-27 20:56:14,851 - INFO - Extracting training features...
2024-12-27 20:56:14,851 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<00:59,  2.64it/s]Extracting features:   1%|▏         | 2/157 [00:00<00:46,  3.37it/s]Extracting features:   4%|▍         | 6/157 [00:00<00:16,  9.20it/s]Extracting features:   6%|▌         | 9/157 [00:01<00:19,  7.47it/s]Extracting features:   8%|▊         | 13/157 [00:01<00:15,  9.06it/s]Extracting features:  11%|█         | 17/157 [00:01<00:13, 10.72it/s]Extracting features:  13%|█▎        | 21/157 [00:02<00:11, 12.16it/s]Extracting features:  16%|█▌        | 25/157 [00:02<00:09, 14.40it/s]Extracting features:  18%|█▊        | 29/157 [00:02<00:08, 15.23it/s]Extracting features:  20%|█▉        | 31/157 [00:02<00:08, 15.13it/s]Extracting features:  22%|██▏       | 35/157 [00:02<00:07, 15.51it/s]Extracting features:  25%|██▍       | 39/157 [00:03<00:07, 16.59it/s]Extracting features:  27%|██▋       | 43/157 [00:03<00:06, 18.80it/s]Extracting features:  30%|██▉       | 47/157 [00:03<00:05, 19.71it/s]Extracting features:  32%|███▏      | 51/157 [00:03<00:05, 18.93it/s]Extracting features:  35%|███▌      | 55/157 [00:03<00:05, 17.88it/s]Extracting features:  38%|███▊      | 59/157 [00:04<00:05, 17.43it/s]Extracting features:  40%|████      | 63/157 [00:04<00:05, 17.39it/s]Extracting features:  43%|████▎     | 67/157 [00:04<00:05, 16.23it/s]Extracting features:  45%|████▌     | 71/157 [00:05<00:05, 15.97it/s]Extracting features:  48%|████▊     | 75/157 [00:05<00:05, 15.24it/s]Extracting features:  50%|█████     | 79/157 [00:05<00:06, 12.17it/s]Extracting features:  53%|█████▎    | 83/157 [00:06<00:05, 13.13it/s]Extracting features:  55%|█████▌    | 87/157 [00:06<00:05, 13.48it/s]Extracting features:  57%|█████▋    | 90/157 [00:06<00:04, 15.48it/s]Extracting features:  59%|█████▊    | 92/157 [00:06<00:04, 14.31it/s]Extracting features:  61%|██████    | 95/157 [00:06<00:04, 13.82it/s]Extracting features:  62%|██████▏   | 97/157 [00:06<00:04, 13.98it/s]Extracting features:  63%|██████▎   | 99/157 [00:07<00:04, 13.84it/s]Extracting features:  64%|██████▍   | 101/157 [00:07<00:03, 14.00it/s]Extracting features:  66%|██████▌   | 103/157 [00:07<00:03, 14.53it/s]Extracting features:  67%|██████▋   | 105/157 [00:07<00:03, 13.98it/s]Extracting features:  68%|██████▊   | 107/157 [00:07<00:03, 13.82it/s]Extracting features:  69%|██████▉   | 109/157 [00:07<00:03, 13.33it/s]Extracting features:  71%|███████   | 111/157 [00:07<00:03, 14.56it/s]Extracting features:  72%|███████▏  | 113/157 [00:08<00:03, 13.82it/s]Extracting features:  73%|███████▎  | 115/157 [00:08<00:03, 13.31it/s]Extracting features:  75%|███████▍  | 117/157 [00:08<00:03, 11.71it/s]Extracting features:  76%|███████▋  | 120/157 [00:08<00:03, 10.58it/s]Extracting features:  78%|███████▊  | 123/157 [00:09<00:02, 11.97it/s]Extracting features:  80%|████████  | 126/157 [00:09<00:02, 14.70it/s]Extracting features:  82%|████████▏ | 128/157 [00:09<00:02, 14.20it/s]Extracting features:  83%|████████▎ | 131/157 [00:09<00:01, 14.04it/s]Extracting features:  86%|████████▌ | 135/157 [00:09<00:01, 15.18it/s]Extracting features:  88%|████████▊ | 138/157 [00:09<00:01, 17.55it/s]Extracting features:  89%|████████▉ | 140/157 [00:10<00:01, 15.17it/s]Extracting features:  91%|█████████ | 143/157 [00:10<00:00, 15.08it/s]Extracting features:  93%|█████████▎| 146/157 [00:10<00:00, 16.95it/s]Extracting features:  94%|█████████▍| 148/157 [00:10<00:00, 14.90it/s]Extracting features:  96%|█████████▌| 151/157 [00:10<00:00, 14.83it/s]Extracting features:  97%|█████████▋| 153/157 [00:10<00:00, 14.71it/s]Extracting features:  99%|█████████▉| 156/157 [00:11<00:00, 13.08it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 13.89it/s]
2024-12-27 20:56:26,167 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:56:26,167 - INFO - Training feature extraction completed in 11.32s
2024-12-27 20:56:26,167 - INFO - Creating model for classifier: SVM
2024-12-27 20:56:26,167 - INFO - Using device: cuda
2024-12-27 20:56:26,167 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-27 20:56:26,167 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:56:26,168 - INFO - Training set processing completed in 0.00s
2024-12-27 20:56:26,168 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:56:26,169 - INFO - Memory usage at start_fit: CPU 3115.0 MB, GPU 47.3 MB
2024-12-27 20:56:26,170 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:56:26,171 - INFO - Number of unique classes: 10
2024-12-27 20:56:26,268 - INFO - Fitted scaler and transformed data
2024-12-27 20:56:26,268 - INFO - Scaling time: 0.09s
2024-12-27 20:56:26,504 - INFO - Epoch 1/25, Train Loss: 0.4221, Val Loss: 0.0021
2024-12-27 20:56:26,676 - INFO - Epoch 2/25, Train Loss: 0.0077, Val Loss: 0.0168
2024-12-27 20:56:26,852 - INFO - Epoch 3/25, Train Loss: 0.0022, Val Loss: 0.0125
2024-12-27 20:56:26,852 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:56:26,852 - INFO - Training completed in 0.68s
2024-12-27 20:56:26,852 - INFO - Final memory usage: CPU 3116.5 MB, GPU 48.1 MB
2024-12-27 20:56:26,852 - INFO - Model training completed in 0.68s
2024-12-27 20:56:26,863 - INFO - Prediction completed in 0.01s
2024-12-27 20:56:26,876 - INFO - Poison rate 0.0 completed in 0.71s
2024-12-27 20:56:26,876 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:56:26,876 - INFO - Label flipping details:
2024-12-27 20:56:26,876 - INFO - - Source class: 1
2024-12-27 20:56:26,876 - INFO - - Target class: 0
2024-12-27 20:56:26,876 - INFO - - Available samples in source class: 500
2024-12-27 20:56:26,876 - INFO - - Requested samples to poison: 50
2024-12-27 20:56:26,876 - INFO - - Actual samples to flip: 50
2024-12-27 20:56:26,876 - INFO - - Samples remaining in source class: 450
2024-12-27 20:56:26,877 - INFO - Successfully flipped 50 labels from class 1 to 0
2024-12-27 20:56:26,877 - INFO - Total number of labels flipped: 50
2024-12-27 20:56:26,877 - INFO - Label flipping completed in 0.00s
2024-12-27 20:56:26,877 - INFO - Training set processing completed in 0.00s
2024-12-27 20:56:26,877 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:56:26,878 - INFO - Memory usage at start_fit: CPU 3116.5 MB, GPU 47.5 MB
2024-12-27 20:56:26,878 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:56:26,878 - INFO - Number of unique classes: 10
2024-12-27 20:56:26,959 - INFO - Fitted scaler and transformed data
2024-12-27 20:56:26,960 - INFO - Scaling time: 0.08s
2024-12-27 20:56:27,143 - INFO - Epoch 1/25, Train Loss: 0.5645, Val Loss: 0.2304
2024-12-27 20:56:27,314 - INFO - Epoch 2/25, Train Loss: 0.0586, Val Loss: 0.2207
2024-12-27 20:56:27,479 - INFO - Epoch 3/25, Train Loss: 0.0347, Val Loss: 0.1882
2024-12-27 20:56:27,647 - INFO - Epoch 4/25, Train Loss: 0.0274, Val Loss: 0.1746
2024-12-27 20:56:27,835 - INFO - Epoch 5/25, Train Loss: 0.0288, Val Loss: 0.1942
2024-12-27 20:56:28,003 - INFO - Epoch 6/25, Train Loss: 0.0142, Val Loss: 0.1918
2024-12-27 20:56:28,003 - INFO - Early stopping triggered at epoch 6
2024-12-27 20:56:28,003 - INFO - Training completed in 1.13s
2024-12-27 20:56:28,003 - INFO - Final memory usage: CPU 3116.5 MB, GPU 48.1 MB
2024-12-27 20:56:28,004 - INFO - Model training completed in 1.13s
2024-12-27 20:56:28,010 - INFO - Prediction completed in 0.01s
2024-12-27 20:56:28,021 - INFO - Poison rate 0.01 completed in 1.15s
2024-12-27 20:56:28,021 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:56:28,023 - INFO - Label flipping details:
2024-12-27 20:56:28,023 - INFO - - Source class: 1
2024-12-27 20:56:28,023 - INFO - - Target class: 0
2024-12-27 20:56:28,023 - INFO - - Available samples in source class: 500
2024-12-27 20:56:28,023 - INFO - - Requested samples to poison: 150
2024-12-27 20:56:28,023 - INFO - - Actual samples to flip: 150
2024-12-27 20:56:28,024 - INFO - - Samples remaining in source class: 350
2024-12-27 20:56:28,024 - INFO - Successfully flipped 150 labels from class 1 to 0
2024-12-27 20:56:28,024 - INFO - Total number of labels flipped: 150
2024-12-27 20:56:28,025 - INFO - Label flipping completed in 0.00s
2024-12-27 20:56:28,025 - INFO - Training set processing completed in 0.00s
2024-12-27 20:56:28,025 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:56:28,026 - INFO - Memory usage at start_fit: CPU 3116.5 MB, GPU 47.5 MB
2024-12-27 20:56:28,026 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:56:28,027 - INFO - Number of unique classes: 10
2024-12-27 20:56:28,108 - INFO - Fitted scaler and transformed data
2024-12-27 20:56:28,109 - INFO - Scaling time: 0.08s
2024-12-27 20:56:28,309 - INFO - Epoch 1/25, Train Loss: 0.5011, Val Loss: 0.2103
2024-12-27 20:56:28,477 - INFO - Epoch 2/25, Train Loss: 0.0984, Val Loss: 0.2450
2024-12-27 20:56:28,685 - INFO - Epoch 3/25, Train Loss: 0.0760, Val Loss: 0.1957
2024-12-27 20:56:28,879 - INFO - Epoch 4/25, Train Loss: 0.0567, Val Loss: 0.2368
2024-12-27 20:56:29,027 - INFO - Epoch 5/25, Train Loss: 0.0394, Val Loss: 0.2818
2024-12-27 20:56:29,028 - INFO - Early stopping triggered at epoch 5
2024-12-27 20:56:29,028 - INFO - Training completed in 1.00s
2024-12-27 20:56:29,028 - INFO - Final memory usage: CPU 3116.5 MB, GPU 48.1 MB
2024-12-27 20:56:29,029 - INFO - Model training completed in 1.00s
2024-12-27 20:56:29,037 - INFO - Prediction completed in 0.01s
2024-12-27 20:56:29,047 - INFO - Poison rate 0.03 completed in 1.03s
2024-12-27 20:56:29,047 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:56:29,048 - INFO - Label flipping details:
2024-12-27 20:56:29,048 - INFO - - Source class: 1
2024-12-27 20:56:29,048 - INFO - - Target class: 0
2024-12-27 20:56:29,048 - INFO - - Available samples in source class: 500
2024-12-27 20:56:29,048 - INFO - - Requested samples to poison: 250
2024-12-27 20:56:29,048 - INFO - - Actual samples to flip: 250
2024-12-27 20:56:29,048 - INFO - - Samples remaining in source class: 250
2024-12-27 20:56:29,048 - INFO - Successfully flipped 250 labels from class 1 to 0
2024-12-27 20:56:29,049 - INFO - Total number of labels flipped: 250
2024-12-27 20:56:29,049 - INFO - Label flipping completed in 0.00s
2024-12-27 20:56:29,049 - INFO - Training set processing completed in 0.00s
2024-12-27 20:56:29,049 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:56:29,050 - INFO - Memory usage at start_fit: CPU 3116.5 MB, GPU 47.5 MB
2024-12-27 20:56:29,050 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:56:29,050 - INFO - Number of unique classes: 10
2024-12-27 20:56:29,145 - INFO - Fitted scaler and transformed data
2024-12-27 20:56:29,145 - INFO - Scaling time: 0.09s
2024-12-27 20:56:29,340 - INFO - Epoch 1/25, Train Loss: 0.5774, Val Loss: 0.2464
2024-12-27 20:56:29,508 - INFO - Epoch 2/25, Train Loss: 0.1223, Val Loss: 0.2392
2024-12-27 20:56:29,676 - INFO - Epoch 3/25, Train Loss: 0.0802, Val Loss: 0.2095
2024-12-27 20:56:29,846 - INFO - Epoch 4/25, Train Loss: 0.0595, Val Loss: 0.2495
2024-12-27 20:56:30,023 - INFO - Epoch 5/25, Train Loss: 0.0611, Val Loss: 0.2401
2024-12-27 20:56:30,023 - INFO - Early stopping triggered at epoch 5
2024-12-27 20:56:30,023 - INFO - Training completed in 0.97s
2024-12-27 20:56:30,024 - INFO - Final memory usage: CPU 3116.5 MB, GPU 48.1 MB
2024-12-27 20:56:30,024 - INFO - Model training completed in 0.98s
2024-12-27 20:56:30,031 - INFO - Prediction completed in 0.01s
2024-12-27 20:56:30,038 - INFO - Poison rate 0.05 completed in 0.99s
2024-12-27 20:56:30,038 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:56:30,039 - INFO - Label flipping details:
2024-12-27 20:56:30,039 - INFO - - Source class: 1
2024-12-27 20:56:30,039 - INFO - - Target class: 0
2024-12-27 20:56:30,039 - INFO - - Available samples in source class: 500
2024-12-27 20:56:30,039 - INFO - - Requested samples to poison: 350
2024-12-27 20:56:30,039 - INFO - - Actual samples to flip: 350
2024-12-27 20:56:30,039 - INFO - - Samples remaining in source class: 150
2024-12-27 20:56:30,039 - INFO - Successfully flipped 350 labels from class 1 to 0
2024-12-27 20:56:30,039 - INFO - Total number of labels flipped: 350
2024-12-27 20:56:30,040 - INFO - Label flipping completed in 0.00s
2024-12-27 20:56:30,040 - INFO - Training set processing completed in 0.00s
2024-12-27 20:56:30,040 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:56:30,041 - INFO - Memory usage at start_fit: CPU 3116.5 MB, GPU 47.5 MB
2024-12-27 20:56:30,041 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:56:30,041 - INFO - Number of unique classes: 10
2024-12-27 20:56:30,124 - INFO - Fitted scaler and transformed data
2024-12-27 20:56:30,125 - INFO - Scaling time: 0.08s
2024-12-27 20:56:30,321 - INFO - Epoch 1/25, Train Loss: 0.6624, Val Loss: 0.1770
2024-12-27 20:56:30,495 - INFO - Epoch 2/25, Train Loss: 0.1221, Val Loss: 0.2626
2024-12-27 20:56:30,662 - INFO - Epoch 3/25, Train Loss: 0.0715, Val Loss: 0.2186
2024-12-27 20:56:30,663 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:56:30,663 - INFO - Training completed in 0.62s
2024-12-27 20:56:30,663 - INFO - Final memory usage: CPU 3116.5 MB, GPU 48.1 MB
2024-12-27 20:56:30,663 - INFO - Model training completed in 0.62s
2024-12-27 20:56:30,674 - INFO - Prediction completed in 0.01s
2024-12-27 20:56:30,690 - INFO - Poison rate 0.07 completed in 0.65s
2024-12-27 20:56:30,691 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:56:30,691 - INFO - Label flipping details:
2024-12-27 20:56:30,691 - INFO - - Source class: 1
2024-12-27 20:56:30,691 - INFO - - Target class: 0
2024-12-27 20:56:30,691 - INFO - - Available samples in source class: 500
2024-12-27 20:56:30,691 - INFO - - Requested samples to poison: 500
2024-12-27 20:56:30,692 - INFO - - Actual samples to flip: 499
2024-12-27 20:56:30,692 - INFO - - Samples remaining in source class: 1
2024-12-27 20:56:30,692 - INFO - Successfully flipped 499 labels from class 1 to 0
2024-12-27 20:56:30,692 - INFO - Total number of labels flipped: 499
2024-12-27 20:56:30,692 - INFO - Label flipping completed in 0.00s
2024-12-27 20:56:30,692 - INFO - Training set processing completed in 0.00s
2024-12-27 20:56:30,692 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:56:30,693 - INFO - Memory usage at start_fit: CPU 3116.5 MB, GPU 47.5 MB
2024-12-27 20:56:30,693 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:56:30,694 - INFO - Number of unique classes: 10
2024-12-27 20:56:30,772 - INFO - Fitted scaler and transformed data
2024-12-27 20:56:30,772 - INFO - Scaling time: 0.08s
2024-12-27 20:56:30,943 - INFO - Epoch 1/25, Train Loss: 0.3574, Val Loss: 0.0664
2024-12-27 20:56:31,110 - INFO - Epoch 2/25, Train Loss: 0.0076, Val Loss: 0.0321
2024-12-27 20:56:31,287 - INFO - Epoch 3/25, Train Loss: 0.0019, Val Loss: 0.0412
2024-12-27 20:56:31,455 - INFO - Epoch 4/25, Train Loss: 0.0002, Val Loss: 0.0474
2024-12-27 20:56:31,456 - INFO - Early stopping triggered at epoch 4
2024-12-27 20:56:31,456 - INFO - Training completed in 0.76s
2024-12-27 20:56:31,456 - INFO - Final memory usage: CPU 3116.5 MB, GPU 48.1 MB
2024-12-27 20:56:31,456 - INFO - Model training completed in 0.76s
2024-12-27 20:56:31,464 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:56:31,471 - INFO - Poison rate 0.1 completed in 0.78s
2024-12-27 20:56:31,472 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:56:31,472 - INFO - Label flipping details:
2024-12-27 20:56:31,472 - INFO - - Source class: 1
2024-12-27 20:56:31,472 - INFO - - Target class: 0
2024-12-27 20:56:31,472 - INFO - - Available samples in source class: 500
2024-12-27 20:56:31,472 - INFO - - Requested samples to poison: 1000
2024-12-27 20:56:31,472 - INFO - - Actual samples to flip: 499
2024-12-27 20:56:31,472 - INFO - - Samples remaining in source class: 1
2024-12-27 20:56:31,472 - INFO - Successfully flipped 499 labels from class 1 to 0
2024-12-27 20:56:31,473 - INFO - Total number of labels flipped: 499
2024-12-27 20:56:31,473 - INFO - Label flipping completed in 0.00s
2024-12-27 20:56:31,473 - INFO - Training set processing completed in 0.00s
2024-12-27 20:56:31,473 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:56:31,474 - INFO - Memory usage at start_fit: CPU 3116.5 MB, GPU 47.5 MB
2024-12-27 20:56:31,474 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:56:31,474 - INFO - Number of unique classes: 10
2024-12-27 20:56:31,573 - INFO - Fitted scaler and transformed data
2024-12-27 20:56:31,573 - INFO - Scaling time: 0.10s
2024-12-27 20:56:31,783 - INFO - Epoch 1/25, Train Loss: 0.3836, Val Loss: 0.0447
2024-12-27 20:56:31,960 - INFO - Epoch 2/25, Train Loss: 0.0136, Val Loss: 0.0310
2024-12-27 20:56:32,137 - INFO - Epoch 3/25, Train Loss: 0.0009, Val Loss: 0.0432
2024-12-27 20:56:32,311 - INFO - Epoch 4/25, Train Loss: 0.0009, Val Loss: 0.0387
2024-12-27 20:56:32,311 - INFO - Early stopping triggered at epoch 4
2024-12-27 20:56:32,311 - INFO - Training completed in 0.84s
2024-12-27 20:56:32,311 - INFO - Final memory usage: CPU 3116.5 MB, GPU 48.1 MB
2024-12-27 20:56:32,312 - INFO - Model training completed in 0.84s
2024-12-27 20:56:32,322 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:56:32,333 - INFO - Poison rate 0.2 completed in 0.86s
2024-12-27 20:56:32,334 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:56:32,334 - INFO - Total evaluation time: 20.13s
2024-12-27 20:56:32,337 - INFO - 
Progress: 85.4% - Evaluating ImageNette with SVM (dynadetect mode, iteration 1/1)
2024-12-27 20:56:32,448 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:56:32,531 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:56:32,611 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 20:56:32,611 - INFO - Dataset type: image
2024-12-27 20:56:32,611 - INFO - Sample size: 5000
2024-12-27 20:56:32,612 - INFO - Using device: cuda
2024-12-27 20:56:32,614 - INFO - Loading datasets...
2024-12-27 20:56:32,639 - INFO - Dataset loading completed in 0.02s
2024-12-27 20:56:32,639 - INFO - Extracting validation features...
2024-12-27 20:56:32,639 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:22,  1.37it/s]Extracting features:  22%|██▏       | 7/32 [00:00<00:02,  9.91it/s]Extracting features:  31%|███▏      | 10/32 [00:01<00:01, 12.77it/s]Extracting features:  41%|████      | 13/32 [00:01<00:01, 13.11it/s]Extracting features:  47%|████▋     | 15/32 [00:01<00:01, 12.59it/s]Extracting features:  56%|█████▋    | 18/32 [00:01<00:01, 13.11it/s]Extracting features:  62%|██████▎   | 20/32 [00:01<00:00, 13.88it/s]Extracting features:  69%|██████▉   | 22/32 [00:02<00:00, 11.42it/s]Extracting features:  78%|███████▊  | 25/32 [00:02<00:00, 13.92it/s]Extracting features:  84%|████████▍ | 27/32 [00:02<00:00, 14.65it/s]Extracting features:  91%|█████████ | 29/32 [00:02<00:00, 15.68it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 12.74it/s]
2024-12-27 20:56:35,156 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:56:35,157 - INFO - Validation feature extraction completed in 2.52s
2024-12-27 20:56:35,157 - INFO - Extracting training features...
2024-12-27 20:56:35,158 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:25,  1.82it/s]Extracting features:   3%|▎         | 4/157 [00:00<00:25,  5.92it/s]Extracting features:   5%|▌         | 8/157 [00:01<00:16,  9.00it/s]Extracting features:   8%|▊         | 12/157 [00:01<00:12, 11.69it/s]Extracting features:  10%|█         | 16/157 [00:01<00:11, 12.62it/s]Extracting features:  13%|█▎        | 20/157 [00:01<00:10, 13.60it/s]Extracting features:  14%|█▍        | 22/157 [00:01<00:09, 14.34it/s]Extracting features:  15%|█▌        | 24/157 [00:02<00:10, 13.08it/s]Extracting features:  18%|█▊        | 28/157 [00:02<00:09, 14.16it/s]Extracting features:  20%|██        | 32/157 [00:02<00:08, 14.28it/s]Extracting features:  23%|██▎       | 36/157 [00:02<00:07, 16.38it/s]Extracting features:  25%|██▌       | 40/157 [00:03<00:07, 15.13it/s]Extracting features:  28%|██▊       | 44/157 [00:03<00:06, 16.68it/s]Extracting features:  31%|███       | 48/157 [00:03<00:06, 16.65it/s]Extracting features:  33%|███▎      | 52/157 [00:03<00:06, 16.35it/s]Extracting features:  36%|███▌      | 56/157 [00:04<00:05, 17.33it/s]Extracting features:  38%|███▊      | 60/157 [00:04<00:05, 17.46it/s]Extracting features:  39%|███▉      | 62/157 [00:04<00:05, 17.12it/s]Extracting features:  41%|████      | 64/157 [00:04<00:05, 16.16it/s]Extracting features:  43%|████▎     | 67/157 [00:04<00:05, 17.71it/s]Extracting features:  44%|████▍     | 69/157 [00:04<00:05, 15.53it/s]Extracting features:  45%|████▌     | 71/157 [00:04<00:05, 15.83it/s]Extracting features:  46%|████▋     | 73/157 [00:05<00:05, 15.67it/s]Extracting features:  48%|████▊     | 75/157 [00:05<00:05, 16.02it/s]Extracting features:  49%|████▉     | 77/157 [00:05<00:05, 15.06it/s]Extracting features:  50%|█████     | 79/157 [00:05<00:05, 14.50it/s]Extracting features:  52%|█████▏    | 81/157 [00:05<00:05, 13.73it/s]Extracting features:  53%|█████▎    | 83/157 [00:05<00:05, 13.81it/s]Extracting features:  54%|█████▍    | 85/157 [00:05<00:05, 13.70it/s]Extracting features:  55%|█████▌    | 87/157 [00:06<00:04, 14.51it/s]Extracting features:  57%|█████▋    | 89/157 [00:06<00:05, 11.62it/s]Extracting features:  58%|█████▊    | 91/157 [00:06<00:04, 13.22it/s]Extracting features:  59%|█████▉    | 93/157 [00:06<00:04, 13.20it/s]Extracting features:  61%|██████    | 95/157 [00:06<00:04, 12.56it/s]Extracting features:  62%|██████▏   | 97/157 [00:06<00:04, 13.50it/s]Extracting features:  63%|██████▎   | 99/157 [00:07<00:04, 13.82it/s]Extracting features:  64%|██████▍   | 101/157 [00:07<00:04, 11.68it/s]Extracting features:  66%|██████▌   | 104/157 [00:07<00:04, 12.61it/s]Extracting features:  68%|██████▊   | 106/157 [00:07<00:03, 13.31it/s]Extracting features:  69%|██████▉   | 108/157 [00:07<00:03, 13.97it/s]Extracting features:  70%|███████   | 110/157 [00:08<00:05,  8.13it/s]Extracting features:  73%|███████▎  | 114/157 [00:08<00:04,  9.51it/s]Extracting features:  75%|███████▌  | 118/157 [00:08<00:03, 10.82it/s]Extracting features:  78%|███████▊  | 122/157 [00:09<00:03, 11.19it/s]Extracting features:  80%|████████  | 126/157 [00:09<00:02, 12.89it/s]Extracting features:  83%|████████▎ | 130/157 [00:09<00:01, 14.84it/s]Extracting features:  85%|████████▌ | 134/157 [00:09<00:01, 16.54it/s]Extracting features:  88%|████████▊ | 138/157 [00:10<00:01, 15.62it/s]Extracting features:  90%|█████████ | 142/157 [00:10<00:00, 15.22it/s]Extracting features:  93%|█████████▎| 146/157 [00:10<00:00, 15.26it/s]Extracting features:  96%|█████████▌| 150/157 [00:10<00:00, 15.33it/s]Extracting features:  98%|█████████▊| 154/157 [00:11<00:00, 14.57it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 13.91it/s]
2024-12-27 20:56:46,456 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:56:46,456 - INFO - Training feature extraction completed in 11.30s
2024-12-27 20:56:46,456 - INFO - Creating model for classifier: SVM
2024-12-27 20:56:46,456 - INFO - Using device: cuda
2024-12-27 20:56:46,456 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-27 20:56:46,456 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:56:46,457 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:56:46,457 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:56:47,092 - INFO - Feature scaling completed in 0.64s
2024-12-27 20:56:47,093 - INFO - Starting feature selection (k=50)
2024-12-27 20:56:47,099 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:56:47,099 - INFO - Starting anomaly detection
2024-12-27 20:56:48,845 - INFO - Anomaly detection completed in 1.75s
2024-12-27 20:56:48,846 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:56:48,846 - INFO - Total fit_transform time: 2.39s
2024-12-27 20:56:48,846 - INFO - Training set processing completed in 2.39s
2024-12-27 20:56:48,846 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:56:48,848 - INFO - Memory usage at start_fit: CPU 3110.2 MB, GPU 47.3 MB
2024-12-27 20:56:48,848 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:56:48,849 - INFO - Number of unique classes: 10
2024-12-27 20:56:48,959 - INFO - Fitted scaler and transformed data
2024-12-27 20:56:48,959 - INFO - Scaling time: 0.11s
2024-12-27 20:56:49,144 - INFO - Epoch 1/25, Train Loss: 0.4157, Val Loss: 0.2736
2024-12-27 20:56:49,306 - INFO - Epoch 2/25, Train Loss: 0.0065, Val Loss: 0.1835
2024-12-27 20:56:49,460 - INFO - Epoch 3/25, Train Loss: 0.0011, Val Loss: 0.1687
2024-12-27 20:56:49,633 - INFO - Epoch 4/25, Train Loss: 0.0000, Val Loss: 0.1561
2024-12-27 20:56:49,801 - INFO - Epoch 5/25, Train Loss: 0.0000, Val Loss: 0.1565
2024-12-27 20:56:49,961 - INFO - Epoch 6/25, Train Loss: 0.0000, Val Loss: 0.1531
2024-12-27 20:56:49,961 - INFO - Early stopping triggered at epoch 6
2024-12-27 20:56:49,962 - INFO - Training completed in 1.11s
2024-12-27 20:56:49,962 - INFO - Final memory usage: CPU 3113.0 MB, GPU 48.1 MB
2024-12-27 20:56:49,962 - INFO - Model training completed in 1.12s
2024-12-27 20:56:49,970 - INFO - Prediction completed in 0.01s
2024-12-27 20:56:49,979 - INFO - Poison rate 0.0 completed in 3.52s
2024-12-27 20:56:49,979 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:56:49,979 - INFO - Label flipping details:
2024-12-27 20:56:49,979 - INFO - - Source class: 1
2024-12-27 20:56:49,979 - INFO - - Target class: 0
2024-12-27 20:56:49,979 - INFO - - Available samples in source class: 500
2024-12-27 20:56:49,979 - INFO - - Requested samples to poison: 50
2024-12-27 20:56:49,979 - INFO - - Actual samples to flip: 50
2024-12-27 20:56:49,979 - INFO - - Samples remaining in source class: 450
2024-12-27 20:56:49,979 - INFO - Successfully flipped 50 labels from class 1 to 0
2024-12-27 20:56:49,980 - INFO - Total number of labels flipped: 50
2024-12-27 20:56:49,980 - INFO - Label flipping completed in 0.00s
2024-12-27 20:56:49,980 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:56:49,980 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:56:50,536 - INFO - Feature scaling completed in 0.56s
2024-12-27 20:56:50,536 - INFO - Starting feature selection (k=50)
2024-12-27 20:56:50,543 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:56:50,544 - INFO - Starting anomaly detection
2024-12-27 20:56:51,759 - INFO - Anomaly detection completed in 1.22s
2024-12-27 20:56:51,760 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:56:51,760 - INFO - Total fit_transform time: 1.78s
2024-12-27 20:56:51,760 - INFO - Training set processing completed in 1.78s
2024-12-27 20:56:51,760 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:56:51,761 - INFO - Memory usage at start_fit: CPU 3113.0 MB, GPU 47.5 MB
2024-12-27 20:56:51,761 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:56:51,761 - INFO - Number of unique classes: 10
2024-12-27 20:56:51,847 - INFO - Fitted scaler and transformed data
2024-12-27 20:56:51,848 - INFO - Scaling time: 0.09s
2024-12-27 20:56:52,026 - INFO - Epoch 1/25, Train Loss: 0.5171, Val Loss: 0.1158
2024-12-27 20:56:52,189 - INFO - Epoch 2/25, Train Loss: 0.0619, Val Loss: 0.0814
2024-12-27 20:56:52,352 - INFO - Epoch 3/25, Train Loss: 0.0358, Val Loss: 0.0525
2024-12-27 20:56:52,524 - INFO - Epoch 4/25, Train Loss: 0.0284, Val Loss: 0.0681
2024-12-27 20:56:52,698 - INFO - Epoch 5/25, Train Loss: 0.0157, Val Loss: 0.0592
2024-12-27 20:56:52,699 - INFO - Early stopping triggered at epoch 5
2024-12-27 20:56:52,699 - INFO - Training completed in 0.94s
2024-12-27 20:56:52,699 - INFO - Final memory usage: CPU 3113.0 MB, GPU 48.1 MB
2024-12-27 20:56:52,699 - INFO - Model training completed in 0.94s
2024-12-27 20:56:52,706 - INFO - Prediction completed in 0.01s
2024-12-27 20:56:52,714 - INFO - Poison rate 0.01 completed in 2.74s
2024-12-27 20:56:52,714 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:56:52,715 - INFO - Label flipping details:
2024-12-27 20:56:52,715 - INFO - - Source class: 1
2024-12-27 20:56:52,715 - INFO - - Target class: 0
2024-12-27 20:56:52,715 - INFO - - Available samples in source class: 500
2024-12-27 20:56:52,715 - INFO - - Requested samples to poison: 150
2024-12-27 20:56:52,715 - INFO - - Actual samples to flip: 150
2024-12-27 20:56:52,715 - INFO - - Samples remaining in source class: 350
2024-12-27 20:56:52,715 - INFO - Successfully flipped 150 labels from class 1 to 0
2024-12-27 20:56:52,715 - INFO - Total number of labels flipped: 150
2024-12-27 20:56:52,715 - INFO - Label flipping completed in 0.00s
2024-12-27 20:56:52,715 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:56:52,715 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:56:53,282 - INFO - Feature scaling completed in 0.57s
2024-12-27 20:56:53,282 - INFO - Starting feature selection (k=50)
2024-12-27 20:56:53,290 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:56:53,290 - INFO - Starting anomaly detection
2024-12-27 20:56:55,159 - INFO - Anomaly detection completed in 1.87s
2024-12-27 20:56:55,159 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:56:55,159 - INFO - Total fit_transform time: 2.44s
2024-12-27 20:56:55,159 - INFO - Training set processing completed in 2.44s
2024-12-27 20:56:55,159 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:56:55,161 - INFO - Memory usage at start_fit: CPU 3113.0 MB, GPU 47.5 MB
2024-12-27 20:56:55,161 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:56:55,162 - INFO - Number of unique classes: 10
2024-12-27 20:56:55,269 - INFO - Fitted scaler and transformed data
2024-12-27 20:56:55,269 - INFO - Scaling time: 0.11s
2024-12-27 20:56:55,501 - INFO - Epoch 1/25, Train Loss: 0.5696, Val Loss: 0.1380
2024-12-27 20:56:55,675 - INFO - Epoch 2/25, Train Loss: 0.1047, Val Loss: 0.2033
2024-12-27 20:56:55,838 - INFO - Epoch 3/25, Train Loss: 0.0770, Val Loss: 0.1278
2024-12-27 20:56:56,009 - INFO - Epoch 4/25, Train Loss: 0.0608, Val Loss: 0.1861
2024-12-27 20:56:56,176 - INFO - Epoch 5/25, Train Loss: 0.0714, Val Loss: 0.1811
2024-12-27 20:56:56,177 - INFO - Early stopping triggered at epoch 5
2024-12-27 20:56:56,177 - INFO - Training completed in 1.02s
2024-12-27 20:56:56,177 - INFO - Final memory usage: CPU 3113.0 MB, GPU 48.1 MB
2024-12-27 20:56:56,177 - INFO - Model training completed in 1.02s
2024-12-27 20:56:56,186 - INFO - Prediction completed in 0.01s
2024-12-27 20:56:56,194 - INFO - Poison rate 0.03 completed in 3.48s
2024-12-27 20:56:56,194 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:56:56,194 - INFO - Label flipping details:
2024-12-27 20:56:56,194 - INFO - - Source class: 1
2024-12-27 20:56:56,194 - INFO - - Target class: 0
2024-12-27 20:56:56,195 - INFO - - Available samples in source class: 500
2024-12-27 20:56:56,195 - INFO - - Requested samples to poison: 250
2024-12-27 20:56:56,195 - INFO - - Actual samples to flip: 250
2024-12-27 20:56:56,195 - INFO - - Samples remaining in source class: 250
2024-12-27 20:56:56,195 - INFO - Successfully flipped 250 labels from class 1 to 0
2024-12-27 20:56:56,195 - INFO - Total number of labels flipped: 250
2024-12-27 20:56:56,195 - INFO - Label flipping completed in 0.00s
2024-12-27 20:56:56,195 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:56:56,195 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:56:56,799 - INFO - Feature scaling completed in 0.60s
2024-12-27 20:56:56,799 - INFO - Starting feature selection (k=50)
2024-12-27 20:56:56,812 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:56:56,812 - INFO - Starting anomaly detection
2024-12-27 20:56:58,997 - INFO - Anomaly detection completed in 2.19s
2024-12-27 20:56:58,998 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:56:58,998 - INFO - Total fit_transform time: 2.80s
2024-12-27 20:56:58,998 - INFO - Training set processing completed in 2.80s
2024-12-27 20:56:58,998 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:56:58,999 - INFO - Memory usage at start_fit: CPU 3113.0 MB, GPU 47.5 MB
2024-12-27 20:56:59,000 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:56:59,001 - INFO - Number of unique classes: 10
2024-12-27 20:56:59,105 - INFO - Fitted scaler and transformed data
2024-12-27 20:56:59,105 - INFO - Scaling time: 0.10s
2024-12-27 20:56:59,336 - INFO - Epoch 1/25, Train Loss: 0.5380, Val Loss: 0.1829
2024-12-27 20:56:59,559 - INFO - Epoch 2/25, Train Loss: 0.1124, Val Loss: 0.2844
2024-12-27 20:56:59,772 - INFO - Epoch 3/25, Train Loss: 0.1155, Val Loss: 0.2373
2024-12-27 20:56:59,772 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:56:59,772 - INFO - Training completed in 0.77s
2024-12-27 20:56:59,773 - INFO - Final memory usage: CPU 3113.0 MB, GPU 48.1 MB
2024-12-27 20:56:59,774 - INFO - Model training completed in 0.78s
2024-12-27 20:56:59,781 - INFO - Prediction completed in 0.01s
2024-12-27 20:56:59,789 - INFO - Poison rate 0.05 completed in 3.60s
2024-12-27 20:56:59,789 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:56:59,790 - INFO - Label flipping details:
2024-12-27 20:56:59,790 - INFO - - Source class: 1
2024-12-27 20:56:59,790 - INFO - - Target class: 0
2024-12-27 20:56:59,790 - INFO - - Available samples in source class: 500
2024-12-27 20:56:59,790 - INFO - - Requested samples to poison: 350
2024-12-27 20:56:59,790 - INFO - - Actual samples to flip: 350
2024-12-27 20:56:59,790 - INFO - - Samples remaining in source class: 150
2024-12-27 20:56:59,790 - INFO - Successfully flipped 350 labels from class 1 to 0
2024-12-27 20:56:59,790 - INFO - Total number of labels flipped: 350
2024-12-27 20:56:59,790 - INFO - Label flipping completed in 0.00s
2024-12-27 20:56:59,791 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:56:59,791 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:57:00,434 - INFO - Feature scaling completed in 0.64s
2024-12-27 20:57:00,434 - INFO - Starting feature selection (k=50)
2024-12-27 20:57:00,448 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:57:00,449 - INFO - Starting anomaly detection
2024-12-27 20:57:02,326 - INFO - Anomaly detection completed in 1.88s
2024-12-27 20:57:02,327 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:57:02,327 - INFO - Total fit_transform time: 2.54s
2024-12-27 20:57:02,327 - INFO - Training set processing completed in 2.54s
2024-12-27 20:57:02,327 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:57:02,328 - INFO - Memory usage at start_fit: CPU 3113.0 MB, GPU 47.5 MB
2024-12-27 20:57:02,328 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:57:02,329 - INFO - Number of unique classes: 10
2024-12-27 20:57:02,422 - INFO - Fitted scaler and transformed data
2024-12-27 20:57:02,423 - INFO - Scaling time: 0.09s
2024-12-27 20:57:02,629 - INFO - Epoch 1/25, Train Loss: 0.5148, Val Loss: 0.0998
2024-12-27 20:57:02,791 - INFO - Epoch 2/25, Train Loss: 0.1076, Val Loss: 0.1516
2024-12-27 20:57:02,966 - INFO - Epoch 3/25, Train Loss: 0.0637, Val Loss: 0.1657
2024-12-27 20:57:02,966 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:57:02,966 - INFO - Training completed in 0.64s
2024-12-27 20:57:02,967 - INFO - Final memory usage: CPU 3113.0 MB, GPU 48.1 MB
2024-12-27 20:57:02,967 - INFO - Model training completed in 0.64s
2024-12-27 20:57:02,980 - INFO - Prediction completed in 0.01s
2024-12-27 20:57:02,990 - INFO - Poison rate 0.07 completed in 3.20s
2024-12-27 20:57:02,990 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:57:02,991 - INFO - Label flipping details:
2024-12-27 20:57:02,991 - INFO - - Source class: 1
2024-12-27 20:57:02,991 - INFO - - Target class: 0
2024-12-27 20:57:02,991 - INFO - - Available samples in source class: 500
2024-12-27 20:57:02,991 - INFO - - Requested samples to poison: 500
2024-12-27 20:57:02,991 - INFO - - Actual samples to flip: 499
2024-12-27 20:57:02,991 - INFO - - Samples remaining in source class: 1
2024-12-27 20:57:02,991 - INFO - Successfully flipped 499 labels from class 1 to 0
2024-12-27 20:57:02,991 - INFO - Total number of labels flipped: 499
2024-12-27 20:57:02,991 - INFO - Label flipping completed in 0.00s
2024-12-27 20:57:02,992 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:57:02,992 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:57:03,659 - INFO - Feature scaling completed in 0.67s
2024-12-27 20:57:03,660 - INFO - Starting feature selection (k=50)
2024-12-27 20:57:03,667 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:57:03,668 - INFO - Starting anomaly detection
2024-12-27 20:57:05,115 - INFO - Anomaly detection completed in 1.45s
2024-12-27 20:57:05,116 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:57:05,116 - INFO - Total fit_transform time: 2.12s
2024-12-27 20:57:05,116 - INFO - Training set processing completed in 2.12s
2024-12-27 20:57:05,116 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:57:05,117 - INFO - Memory usage at start_fit: CPU 3113.0 MB, GPU 47.5 MB
2024-12-27 20:57:05,117 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:57:05,117 - INFO - Number of unique classes: 10
2024-12-27 20:57:05,210 - INFO - Fitted scaler and transformed data
2024-12-27 20:57:05,210 - INFO - Scaling time: 0.09s
2024-12-27 20:57:05,415 - INFO - Epoch 1/25, Train Loss: 0.4330, Val Loss: 0.1050
2024-12-27 20:57:05,590 - INFO - Epoch 2/25, Train Loss: 0.0081, Val Loss: 0.1057
2024-12-27 20:57:05,795 - INFO - Epoch 3/25, Train Loss: 0.0024, Val Loss: 0.1101
2024-12-27 20:57:05,795 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:57:05,795 - INFO - Training completed in 0.68s
2024-12-27 20:57:05,795 - INFO - Final memory usage: CPU 3113.0 MB, GPU 48.1 MB
2024-12-27 20:57:05,796 - INFO - Model training completed in 0.68s
2024-12-27 20:57:05,802 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:57:05,811 - INFO - Poison rate 0.1 completed in 2.82s
2024-12-27 20:57:05,811 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:57:05,811 - INFO - Label flipping details:
2024-12-27 20:57:05,811 - INFO - - Source class: 1
2024-12-27 20:57:05,811 - INFO - - Target class: 0
2024-12-27 20:57:05,811 - INFO - - Available samples in source class: 500
2024-12-27 20:57:05,811 - INFO - - Requested samples to poison: 1000
2024-12-27 20:57:05,811 - INFO - - Actual samples to flip: 499
2024-12-27 20:57:05,811 - INFO - - Samples remaining in source class: 1
2024-12-27 20:57:05,812 - INFO - Successfully flipped 499 labels from class 1 to 0
2024-12-27 20:57:05,812 - INFO - Total number of labels flipped: 499
2024-12-27 20:57:05,812 - INFO - Label flipping completed in 0.00s
2024-12-27 20:57:05,812 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:57:05,812 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:57:06,385 - INFO - Feature scaling completed in 0.57s
2024-12-27 20:57:06,385 - INFO - Starting feature selection (k=50)
2024-12-27 20:57:06,393 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:57:06,393 - INFO - Starting anomaly detection
2024-12-27 20:57:08,363 - INFO - Anomaly detection completed in 1.97s
2024-12-27 20:57:08,364 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:57:08,364 - INFO - Total fit_transform time: 2.55s
2024-12-27 20:57:08,364 - INFO - Training set processing completed in 2.55s
2024-12-27 20:57:08,364 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 20:57:08,365 - INFO - Memory usage at start_fit: CPU 3113.0 MB, GPU 47.5 MB
2024-12-27 20:57:08,366 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:57:08,367 - INFO - Number of unique classes: 10
2024-12-27 20:57:08,463 - INFO - Fitted scaler and transformed data
2024-12-27 20:57:08,463 - INFO - Scaling time: 0.10s
2024-12-27 20:57:08,664 - INFO - Epoch 1/25, Train Loss: 0.3839, Val Loss: 0.0095
2024-12-27 20:57:08,829 - INFO - Epoch 2/25, Train Loss: 0.0090, Val Loss: 0.0049
2024-12-27 20:57:09,002 - INFO - Epoch 3/25, Train Loss: 0.0016, Val Loss: 0.0028
2024-12-27 20:57:09,003 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:57:09,003 - INFO - Training completed in 0.64s
2024-12-27 20:57:09,003 - INFO - Final memory usage: CPU 3113.0 MB, GPU 48.1 MB
2024-12-27 20:57:09,003 - INFO - Model training completed in 0.64s
2024-12-27 20:57:09,015 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:57:09,028 - INFO - Poison rate 0.2 completed in 3.22s
2024-12-27 20:57:09,028 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:57:09,029 - INFO - Total evaluation time: 36.41s
2024-12-27 20:57:09,031 - INFO - 
Progress: 86.5% - Evaluating ImageNette with LogisticRegression (standard mode, iteration 1/1)
2024-12-27 20:57:09,091 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:57:09,160 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:57:09,249 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 20:57:09,249 - INFO - Dataset type: image
2024-12-27 20:57:09,249 - INFO - Sample size: 5000
2024-12-27 20:57:09,249 - INFO - Using device: cuda
2024-12-27 20:57:09,251 - INFO - Loading datasets...
2024-12-27 20:57:09,276 - INFO - Dataset loading completed in 0.02s
2024-12-27 20:57:09,276 - INFO - Extracting validation features...
2024-12-27 20:57:09,276 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:20,  1.51it/s]Extracting features:  19%|█▉        | 6/32 [00:00<00:02, 10.02it/s]Extracting features:  28%|██▊       | 9/32 [00:01<00:02, 10.53it/s]Extracting features:  41%|████      | 13/32 [00:01<00:01, 12.12it/s]Extracting features:  50%|█████     | 16/32 [00:01<00:01, 14.66it/s]Extracting features:  59%|█████▉    | 19/32 [00:01<00:00, 14.28it/s]Extracting features:  66%|██████▌   | 21/32 [00:01<00:00, 12.95it/s]Extracting features:  72%|███████▏  | 23/32 [00:02<00:00, 11.65it/s]Extracting features:  78%|███████▊  | 25/32 [00:02<00:00, 12.55it/s]Extracting features:  91%|█████████ | 29/32 [00:02<00:00, 14.81it/s]Extracting features:  97%|█████████▋| 31/32 [00:02<00:00, 14.87it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 12.27it/s]
2024-12-27 20:57:11,889 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:57:11,890 - INFO - Validation feature extraction completed in 2.61s
2024-12-27 20:57:11,891 - INFO - Extracting training features...
2024-12-27 20:57:11,891 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:37,  1.60it/s]Extracting features:   3%|▎         | 5/157 [00:01<00:28,  5.25it/s]Extracting features:   6%|▌         | 9/157 [00:01<00:18,  7.93it/s]Extracting features:   8%|▊         | 13/157 [00:01<00:13, 10.71it/s]Extracting features:  11%|█         | 17/157 [00:01<00:11, 12.17it/s]Extracting features:  13%|█▎        | 21/157 [00:02<00:10, 13.57it/s]Extracting features:  16%|█▌        | 25/157 [00:02<00:09, 13.97it/s]Extracting features:  18%|█▊        | 29/157 [00:02<00:08, 15.03it/s]Extracting features:  21%|██        | 33/157 [00:02<00:07, 17.57it/s]Extracting features:  24%|██▎       | 37/157 [00:02<00:07, 17.03it/s]Extracting features:  26%|██▌       | 41/157 [00:03<00:06, 18.01it/s]Extracting features:  29%|██▊       | 45/157 [00:03<00:05, 18.85it/s]Extracting features:  31%|███       | 49/157 [00:03<00:07, 14.39it/s]Extracting features:  34%|███▍      | 53/157 [00:03<00:06, 15.58it/s]Extracting features:  36%|███▋      | 57/157 [00:04<00:05, 17.84it/s]Extracting features:  39%|███▉      | 61/157 [00:04<00:05, 17.43it/s]Extracting features:  41%|████▏     | 65/157 [00:04<00:05, 17.30it/s]Extracting features:  44%|████▍     | 69/157 [00:04<00:05, 16.68it/s]Extracting features:  45%|████▌     | 71/157 [00:04<00:05, 16.99it/s]Extracting features:  46%|████▋     | 73/157 [00:05<00:05, 16.42it/s]Extracting features:  48%|████▊     | 75/157 [00:05<00:05, 15.31it/s]Extracting features:  49%|████▉     | 77/157 [00:05<00:05, 15.60it/s]Extracting features:  50%|█████     | 79/157 [00:05<00:07, 10.95it/s]Extracting features:  52%|█████▏    | 82/157 [00:06<00:06, 10.87it/s]Extracting features:  55%|█████▍    | 86/157 [00:06<00:05, 12.04it/s]Extracting features:  57%|█████▋    | 90/157 [00:06<00:05, 12.87it/s]Extracting features:  60%|█████▉    | 94/157 [00:06<00:05, 12.44it/s]Extracting features:  62%|██████▏   | 98/157 [00:07<00:04, 12.73it/s]Extracting features:  65%|██████▍   | 102/157 [00:07<00:04, 12.93it/s]Extracting features:  68%|██████▊   | 106/157 [00:07<00:04, 12.64it/s]Extracting features:  70%|███████   | 110/157 [00:08<00:04, 11.55it/s]Extracting features:  73%|███████▎  | 114/157 [00:08<00:03, 12.04it/s]Extracting features:  75%|███████▌  | 118/157 [00:08<00:03, 12.19it/s]Extracting features:  76%|███████▋  | 120/157 [00:09<00:03, 11.37it/s]Extracting features:  78%|███████▊  | 123/157 [00:09<00:03, 10.91it/s]Extracting features:  81%|████████  | 127/157 [00:09<00:02, 12.67it/s]Extracting features:  83%|████████▎ | 131/157 [00:09<00:01, 13.99it/s]Extracting features:  86%|████████▌ | 135/157 [00:10<00:01, 14.87it/s]Extracting features:  89%|████████▊ | 139/157 [00:10<00:01, 15.86it/s]Extracting features:  90%|█████████ | 142/157 [00:10<00:00, 16.53it/s]Extracting features:  92%|█████████▏| 144/157 [00:10<00:00, 14.15it/s]Extracting features:  94%|█████████▎| 147/157 [00:10<00:00, 13.66it/s]Extracting features:  96%|█████████▌| 151/157 [00:11<00:00, 15.01it/s]Extracting features:  99%|█████████▊| 155/157 [00:11<00:00, 17.10it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 13.73it/s]
2024-12-27 20:57:23,331 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:57:23,332 - INFO - Training feature extraction completed in 11.44s
2024-12-27 20:57:23,332 - INFO - Creating model for classifier: LogisticRegression
2024-12-27 20:57:23,332 - INFO - Using device: cuda
2024-12-27 20:57:23,332 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:57:23,332 - INFO - Training set processing completed in 0.00s
2024-12-27 20:57:23,332 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:57:23,334 - INFO - Memory usage at start_fit: CPU 3110.2 MB, GPU 47.3 MB
2024-12-27 20:57:23,334 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:57:23,335 - INFO - Number of unique classes: 10
2024-12-27 20:57:23,440 - INFO - Fitted scaler and transformed data
2024-12-27 20:57:23,441 - INFO - Scaling time: 0.10s
2024-12-27 20:57:23,639 - INFO - Epoch 1/200, Train Loss: 0.1314, Val Loss: 0.0282
2024-12-27 20:57:23,847 - INFO - Epoch 2/200, Train Loss: 0.0073, Val Loss: 0.0142
2024-12-27 20:57:24,071 - INFO - Epoch 3/200, Train Loss: 0.0118, Val Loss: 0.0229
2024-12-27 20:57:24,299 - INFO - Epoch 4/200, Train Loss: 0.0043, Val Loss: 0.0158
2024-12-27 20:57:24,300 - INFO - Early stopping triggered at epoch 4
2024-12-27 20:57:24,300 - INFO - Training completed in 0.97s
2024-12-27 20:57:24,301 - INFO - Final memory usage: CPU 3114.4 MB, GPU 48.1 MB
2024-12-27 20:57:24,301 - INFO - Model training completed in 0.97s
2024-12-27 20:57:24,321 - INFO - Prediction completed in 0.02s
2024-12-27 20:57:24,333 - INFO - Poison rate 0.0 completed in 1.00s
2024-12-27 20:57:24,333 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:57:24,334 - INFO - Label flipping details:
2024-12-27 20:57:24,334 - INFO - - Source class: 1
2024-12-27 20:57:24,334 - INFO - - Target class: 0
2024-12-27 20:57:24,334 - INFO - - Available samples in source class: 500
2024-12-27 20:57:24,334 - INFO - - Requested samples to poison: 50
2024-12-27 20:57:24,334 - INFO - - Actual samples to flip: 50
2024-12-27 20:57:24,334 - INFO - - Samples remaining in source class: 450
2024-12-27 20:57:24,334 - INFO - Successfully flipped 50 labels from class 1 to 0
2024-12-27 20:57:24,334 - INFO - Total number of labels flipped: 50
2024-12-27 20:57:24,335 - INFO - Label flipping completed in 0.00s
2024-12-27 20:57:24,335 - INFO - Training set processing completed in 0.00s
2024-12-27 20:57:24,335 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:57:24,336 - INFO - Memory usage at start_fit: CPU 3114.4 MB, GPU 47.5 MB
2024-12-27 20:57:24,336 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:57:24,336 - INFO - Number of unique classes: 10
2024-12-27 20:57:24,439 - INFO - Fitted scaler and transformed data
2024-12-27 20:57:24,439 - INFO - Scaling time: 0.10s
2024-12-27 20:57:24,645 - INFO - Epoch 1/200, Train Loss: 0.2094, Val Loss: 0.1182
2024-12-27 20:57:24,871 - INFO - Epoch 2/200, Train Loss: 0.0498, Val Loss: 0.1251
2024-12-27 20:57:25,107 - INFO - Epoch 3/200, Train Loss: 0.0287, Val Loss: 0.1496
2024-12-27 20:57:25,108 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:57:25,108 - INFO - Training completed in 0.77s
2024-12-27 20:57:25,109 - INFO - Final memory usage: CPU 3114.4 MB, GPU 48.1 MB
2024-12-27 20:57:25,110 - INFO - Model training completed in 0.78s
2024-12-27 20:57:25,125 - INFO - Prediction completed in 0.01s
2024-12-27 20:57:25,142 - INFO - Poison rate 0.01 completed in 0.81s
2024-12-27 20:57:25,142 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:57:25,143 - INFO - Label flipping details:
2024-12-27 20:57:25,143 - INFO - - Source class: 1
2024-12-27 20:57:25,143 - INFO - - Target class: 0
2024-12-27 20:57:25,143 - INFO - - Available samples in source class: 500
2024-12-27 20:57:25,143 - INFO - - Requested samples to poison: 150
2024-12-27 20:57:25,143 - INFO - - Actual samples to flip: 150
2024-12-27 20:57:25,143 - INFO - - Samples remaining in source class: 350
2024-12-27 20:57:25,144 - INFO - Successfully flipped 150 labels from class 1 to 0
2024-12-27 20:57:25,144 - INFO - Total number of labels flipped: 150
2024-12-27 20:57:25,144 - INFO - Label flipping completed in 0.00s
2024-12-27 20:57:25,144 - INFO - Training set processing completed in 0.00s
2024-12-27 20:57:25,144 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:57:25,146 - INFO - Memory usage at start_fit: CPU 3114.4 MB, GPU 47.5 MB
2024-12-27 20:57:25,146 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:57:25,146 - INFO - Number of unique classes: 10
2024-12-27 20:57:25,246 - INFO - Fitted scaler and transformed data
2024-12-27 20:57:25,247 - INFO - Scaling time: 0.10s
2024-12-27 20:57:25,456 - INFO - Epoch 1/200, Train Loss: 0.2565, Val Loss: 0.2707
2024-12-27 20:57:25,646 - INFO - Epoch 2/200, Train Loss: 0.1095, Val Loss: 0.2121
2024-12-27 20:57:25,865 - INFO - Epoch 3/200, Train Loss: 0.0555, Val Loss: 0.2898
2024-12-27 20:57:26,116 - INFO - Epoch 4/200, Train Loss: 0.0442, Val Loss: 0.2736
2024-12-27 20:57:26,116 - INFO - Early stopping triggered at epoch 4
2024-12-27 20:57:26,116 - INFO - Training completed in 0.97s
2024-12-27 20:57:26,117 - INFO - Final memory usage: CPU 3114.4 MB, GPU 48.1 MB
2024-12-27 20:57:26,117 - INFO - Model training completed in 0.97s
2024-12-27 20:57:26,127 - INFO - Prediction completed in 0.01s
2024-12-27 20:57:26,136 - INFO - Poison rate 0.03 completed in 0.99s
2024-12-27 20:57:26,137 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:57:26,137 - INFO - Label flipping details:
2024-12-27 20:57:26,137 - INFO - - Source class: 1
2024-12-27 20:57:26,137 - INFO - - Target class: 0
2024-12-27 20:57:26,137 - INFO - - Available samples in source class: 500
2024-12-27 20:57:26,137 - INFO - - Requested samples to poison: 250
2024-12-27 20:57:26,137 - INFO - - Actual samples to flip: 250
2024-12-27 20:57:26,137 - INFO - - Samples remaining in source class: 250
2024-12-27 20:57:26,137 - INFO - Successfully flipped 250 labels from class 1 to 0
2024-12-27 20:57:26,137 - INFO - Total number of labels flipped: 250
2024-12-27 20:57:26,138 - INFO - Label flipping completed in 0.00s
2024-12-27 20:57:26,138 - INFO - Training set processing completed in 0.00s
2024-12-27 20:57:26,138 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:57:26,139 - INFO - Memory usage at start_fit: CPU 3114.4 MB, GPU 47.5 MB
2024-12-27 20:57:26,139 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:57:26,139 - INFO - Number of unique classes: 10
2024-12-27 20:57:26,249 - INFO - Fitted scaler and transformed data
2024-12-27 20:57:26,249 - INFO - Scaling time: 0.11s
2024-12-27 20:57:26,391 - INFO - Epoch 1/200, Train Loss: 0.3146, Val Loss: 0.2103
2024-12-27 20:57:26,527 - INFO - Epoch 2/200, Train Loss: 0.1140, Val Loss: 0.1832
2024-12-27 20:57:26,637 - INFO - Epoch 3/200, Train Loss: 0.0939, Val Loss: 0.2451
2024-12-27 20:57:26,760 - INFO - Epoch 4/200, Train Loss: 0.0806, Val Loss: 0.1904
2024-12-27 20:57:26,760 - INFO - Early stopping triggered at epoch 4
2024-12-27 20:57:26,760 - INFO - Training completed in 0.62s
2024-12-27 20:57:26,761 - INFO - Final memory usage: CPU 3114.4 MB, GPU 48.1 MB
2024-12-27 20:57:26,761 - INFO - Model training completed in 0.62s
2024-12-27 20:57:26,768 - INFO - Prediction completed in 0.01s
2024-12-27 20:57:26,775 - INFO - Poison rate 0.05 completed in 0.64s
2024-12-27 20:57:26,776 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:57:26,776 - INFO - Label flipping details:
2024-12-27 20:57:26,776 - INFO - - Source class: 1
2024-12-27 20:57:26,776 - INFO - - Target class: 0
2024-12-27 20:57:26,776 - INFO - - Available samples in source class: 500
2024-12-27 20:57:26,776 - INFO - - Requested samples to poison: 350
2024-12-27 20:57:26,776 - INFO - - Actual samples to flip: 350
2024-12-27 20:57:26,776 - INFO - - Samples remaining in source class: 150
2024-12-27 20:57:26,776 - INFO - Successfully flipped 350 labels from class 1 to 0
2024-12-27 20:57:26,776 - INFO - Total number of labels flipped: 350
2024-12-27 20:57:26,777 - INFO - Label flipping completed in 0.00s
2024-12-27 20:57:26,777 - INFO - Training set processing completed in 0.00s
2024-12-27 20:57:26,777 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:57:26,778 - INFO - Memory usage at start_fit: CPU 3114.4 MB, GPU 47.5 MB
2024-12-27 20:57:26,778 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:57:26,779 - INFO - Number of unique classes: 10
2024-12-27 20:57:26,878 - INFO - Fitted scaler and transformed data
2024-12-27 20:57:26,878 - INFO - Scaling time: 0.10s
2024-12-27 20:57:27,021 - INFO - Epoch 1/200, Train Loss: 0.3250, Val Loss: 0.1775
2024-12-27 20:57:27,138 - INFO - Epoch 2/200, Train Loss: 0.1120, Val Loss: 0.2110
2024-12-27 20:57:27,244 - INFO - Epoch 3/200, Train Loss: 0.0544, Val Loss: 0.2271
2024-12-27 20:57:27,245 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:57:27,245 - INFO - Training completed in 0.47s
2024-12-27 20:57:27,246 - INFO - Final memory usage: CPU 3114.4 MB, GPU 48.1 MB
2024-12-27 20:57:27,246 - INFO - Model training completed in 0.47s
2024-12-27 20:57:27,261 - INFO - Prediction completed in 0.01s
2024-12-27 20:57:27,281 - INFO - Poison rate 0.07 completed in 0.51s
2024-12-27 20:57:27,282 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:57:27,283 - INFO - Label flipping details:
2024-12-27 20:57:27,283 - INFO - - Source class: 1
2024-12-27 20:57:27,283 - INFO - - Target class: 0
2024-12-27 20:57:27,283 - INFO - - Available samples in source class: 500
2024-12-27 20:57:27,284 - INFO - - Requested samples to poison: 500
2024-12-27 20:57:27,284 - INFO - - Actual samples to flip: 499
2024-12-27 20:57:27,284 - INFO - - Samples remaining in source class: 1
2024-12-27 20:57:27,284 - INFO - Successfully flipped 499 labels from class 1 to 0
2024-12-27 20:57:27,284 - INFO - Total number of labels flipped: 499
2024-12-27 20:57:27,285 - INFO - Label flipping completed in 0.00s
2024-12-27 20:57:27,285 - INFO - Training set processing completed in 0.00s
2024-12-27 20:57:27,285 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:57:27,286 - INFO - Memory usage at start_fit: CPU 3114.4 MB, GPU 47.5 MB
2024-12-27 20:57:27,286 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:57:27,287 - INFO - Number of unique classes: 10
2024-12-27 20:57:27,381 - INFO - Fitted scaler and transformed data
2024-12-27 20:57:27,381 - INFO - Scaling time: 0.09s
2024-12-27 20:57:27,520 - INFO - Epoch 1/200, Train Loss: 0.1433, Val Loss: 0.0410
2024-12-27 20:57:27,644 - INFO - Epoch 2/200, Train Loss: 0.0097, Val Loss: 0.0200
2024-12-27 20:57:27,764 - INFO - Epoch 3/200, Train Loss: 0.0014, Val Loss: 0.0231
2024-12-27 20:57:27,878 - INFO - Epoch 4/200, Train Loss: 0.0001, Val Loss: 0.0223
2024-12-27 20:57:27,879 - INFO - Early stopping triggered at epoch 4
2024-12-27 20:57:27,879 - INFO - Training completed in 0.59s
2024-12-27 20:57:27,880 - INFO - Final memory usage: CPU 3114.4 MB, GPU 48.1 MB
2024-12-27 20:57:27,880 - INFO - Model training completed in 0.60s
2024-12-27 20:57:27,887 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:57:27,900 - INFO - Poison rate 0.1 completed in 0.62s
2024-12-27 20:57:27,901 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:57:27,901 - INFO - Label flipping details:
2024-12-27 20:57:27,902 - INFO - - Source class: 1
2024-12-27 20:57:27,902 - INFO - - Target class: 0
2024-12-27 20:57:27,902 - INFO - - Available samples in source class: 500
2024-12-27 20:57:27,902 - INFO - - Requested samples to poison: 1000
2024-12-27 20:57:27,902 - INFO - - Actual samples to flip: 499
2024-12-27 20:57:27,902 - INFO - - Samples remaining in source class: 1
2024-12-27 20:57:27,902 - INFO - Successfully flipped 499 labels from class 1 to 0
2024-12-27 20:57:27,903 - INFO - Total number of labels flipped: 499
2024-12-27 20:57:27,903 - INFO - Label flipping completed in 0.00s
2024-12-27 20:57:27,903 - INFO - Training set processing completed in 0.00s
2024-12-27 20:57:27,903 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:57:27,904 - INFO - Memory usage at start_fit: CPU 3114.4 MB, GPU 47.5 MB
2024-12-27 20:57:27,904 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:57:27,905 - INFO - Number of unique classes: 10
2024-12-27 20:57:28,016 - INFO - Fitted scaler and transformed data
2024-12-27 20:57:28,016 - INFO - Scaling time: 0.11s
2024-12-27 20:57:28,164 - INFO - Epoch 1/200, Train Loss: 0.1629, Val Loss: 0.0466
2024-12-27 20:57:28,291 - INFO - Epoch 2/200, Train Loss: 0.0096, Val Loss: 0.0802
2024-12-27 20:57:28,430 - INFO - Epoch 3/200, Train Loss: 0.0007, Val Loss: 0.0683
2024-12-27 20:57:28,430 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:57:28,430 - INFO - Training completed in 0.53s
2024-12-27 20:57:28,431 - INFO - Final memory usage: CPU 3114.4 MB, GPU 48.1 MB
2024-12-27 20:57:28,431 - INFO - Model training completed in 0.53s
2024-12-27 20:57:28,446 - INFO - Prediction completed in 0.02s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:57:28,461 - INFO - Poison rate 0.2 completed in 0.56s
2024-12-27 20:57:28,462 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:57:28,462 - INFO - Total evaluation time: 19.21s
2024-12-27 20:57:28,465 - INFO - 
Progress: 87.5% - Evaluating ImageNette with LogisticRegression (dynadetect mode, iteration 1/1)
2024-12-27 20:57:28,527 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:57:28,593 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:57:28,683 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 20:57:28,683 - INFO - Dataset type: image
2024-12-27 20:57:28,683 - INFO - Sample size: 5000
2024-12-27 20:57:28,683 - INFO - Using device: cuda
2024-12-27 20:57:28,685 - INFO - Loading datasets...
2024-12-27 20:57:28,712 - INFO - Dataset loading completed in 0.03s
2024-12-27 20:57:28,712 - INFO - Extracting validation features...
2024-12-27 20:57:28,712 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:19,  1.57it/s]Extracting features:  19%|█▉        | 6/32 [00:00<00:02,  9.52it/s]Extracting features:  28%|██▊       | 9/32 [00:01<00:02, 10.77it/s]Extracting features:  41%|████      | 13/32 [00:01<00:01, 13.33it/s]Extracting features:  53%|█████▎    | 17/32 [00:01<00:01, 12.86it/s]Extracting features:  62%|██████▎   | 20/32 [00:01<00:00, 15.25it/s]Extracting features:  69%|██████▉   | 22/32 [00:01<00:00, 12.83it/s]Extracting features:  78%|███████▊  | 25/32 [00:02<00:00, 12.89it/s]Extracting features:  91%|█████████ | 29/32 [00:02<00:00, 14.73it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 13.02it/s]
2024-12-27 20:57:31,174 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:57:31,174 - INFO - Validation feature extraction completed in 2.46s
2024-12-27 20:57:31,174 - INFO - Extracting training features...
2024-12-27 20:57:31,174 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:18,  1.98it/s]Extracting features:   1%|▏         | 2/157 [00:00<00:59,  2.59it/s]Extracting features:   4%|▍         | 6/157 [00:01<00:20,  7.34it/s]Extracting features:   6%|▋         | 10/157 [00:01<00:13, 10.77it/s]Extracting features:   9%|▉         | 14/157 [00:01<00:11, 12.38it/s]Extracting features:  11%|█▏        | 18/157 [00:01<00:10, 13.57it/s]Extracting features:  14%|█▍        | 22/157 [00:02<00:09, 14.13it/s]Extracting features:  15%|█▌        | 24/157 [00:02<00:09, 14.40it/s]Extracting features:  17%|█▋        | 26/157 [00:02<00:09, 14.35it/s]Extracting features:  18%|█▊        | 29/157 [00:02<00:07, 17.03it/s]Extracting features:  20%|█▉        | 31/157 [00:02<00:09, 13.02it/s]Extracting features:  22%|██▏       | 34/157 [00:02<00:08, 14.80it/s]Extracting features:  24%|██▍       | 38/157 [00:02<00:06, 17.77it/s]Extracting features:  27%|██▋       | 42/157 [00:03<00:05, 19.22it/s]Extracting features:  29%|██▊       | 45/157 [00:03<00:05, 19.70it/s]Extracting features:  31%|███       | 48/157 [00:03<00:06, 16.86it/s]Extracting features:  33%|███▎      | 52/157 [00:03<00:06, 17.17it/s]Extracting features:  36%|███▌      | 56/157 [00:04<00:06, 16.25it/s]Extracting features:  38%|███▊      | 60/157 [00:04<00:06, 15.64it/s]Extracting features:  41%|████      | 64/157 [00:04<00:06, 15.26it/s]Extracting features:  43%|████▎     | 68/157 [00:04<00:05, 15.90it/s]Extracting features:  46%|████▌     | 72/157 [00:05<00:05, 15.25it/s]Extracting features:  48%|████▊     | 75/157 [00:05<00:04, 17.07it/s]Extracting features:  49%|████▉     | 77/157 [00:05<00:05, 13.68it/s]Extracting features:  51%|█████     | 80/157 [00:05<00:05, 13.09it/s]Extracting features:  54%|█████▎    | 84/157 [00:06<00:05, 13.45it/s]Extracting features:  55%|█████▌    | 87/157 [00:06<00:04, 15.45it/s]Extracting features:  57%|█████▋    | 89/157 [00:06<00:05, 12.58it/s]Extracting features:  59%|█████▊    | 92/157 [00:06<00:05, 11.44it/s]Extracting features:  61%|██████    | 96/157 [00:07<00:05, 11.39it/s]Extracting features:  64%|██████▎   | 100/157 [00:07<00:04, 12.66it/s]Extracting features:  66%|██████▌   | 104/157 [00:07<00:04, 12.96it/s]Extracting features:  69%|██████▉   | 108/157 [00:07<00:03, 13.82it/s]Extracting features:  71%|███████▏  | 112/157 [00:08<00:03, 13.29it/s]Extracting features:  74%|███████▍  | 116/157 [00:08<00:03, 12.50it/s]Extracting features:  76%|███████▋  | 120/157 [00:08<00:03, 12.05it/s]Extracting features:  78%|███████▊  | 122/157 [00:09<00:03, 11.63it/s]Extracting features:  79%|███████▉  | 124/157 [00:09<00:02, 11.88it/s]Extracting features:  82%|████████▏ | 128/157 [00:09<00:02, 12.61it/s]Extracting features:  84%|████████▍ | 132/157 [00:09<00:01, 14.15it/s]Extracting features:  87%|████████▋ | 136/157 [00:10<00:01, 14.96it/s]Extracting features:  89%|████████▉ | 140/157 [00:10<00:01, 16.49it/s]Extracting features:  92%|█████████▏| 144/157 [00:10<00:00, 16.53it/s]Extracting features:  94%|█████████▍| 148/157 [00:10<00:00, 17.07it/s]Extracting features:  96%|█████████▌| 151/157 [00:10<00:00, 18.23it/s]Extracting features:  97%|█████████▋| 153/157 [00:11<00:00, 15.46it/s]Extracting features:  99%|█████████▉| 156/157 [00:11<00:00, 13.92it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 13.81it/s]
2024-12-27 20:57:42,557 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:57:42,557 - INFO - Training feature extraction completed in 11.38s
2024-12-27 20:57:42,557 - INFO - Creating model for classifier: LogisticRegression
2024-12-27 20:57:42,557 - INFO - Using device: cuda
2024-12-27 20:57:42,557 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:57:42,557 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:57:42,557 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:57:43,146 - INFO - Feature scaling completed in 0.59s
2024-12-27 20:57:43,146 - INFO - Starting feature selection (k=50)
2024-12-27 20:57:43,153 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:57:43,153 - INFO - Starting anomaly detection
2024-12-27 20:57:44,388 - INFO - Anomaly detection completed in 1.23s
2024-12-27 20:57:44,388 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:57:44,388 - INFO - Total fit_transform time: 1.83s
2024-12-27 20:57:44,388 - INFO - Training set processing completed in 1.83s
2024-12-27 20:57:44,388 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:57:44,390 - INFO - Memory usage at start_fit: CPU 3115.4 MB, GPU 47.3 MB
2024-12-27 20:57:44,391 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:57:44,391 - INFO - Number of unique classes: 10
2024-12-27 20:57:44,496 - INFO - Fitted scaler and transformed data
2024-12-27 20:57:44,496 - INFO - Scaling time: 0.10s
2024-12-27 20:57:44,644 - INFO - Epoch 1/200, Train Loss: 0.1341, Val Loss: 0.0230
2024-12-27 20:57:44,766 - INFO - Epoch 2/200, Train Loss: 0.0068, Val Loss: 0.0239
2024-12-27 20:57:44,911 - INFO - Epoch 3/200, Train Loss: 0.0013, Val Loss: 0.0290
2024-12-27 20:57:44,911 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:57:44,911 - INFO - Training completed in 0.52s
2024-12-27 20:57:44,911 - INFO - Final memory usage: CPU 3115.4 MB, GPU 48.1 MB
2024-12-27 20:57:44,912 - INFO - Model training completed in 0.52s
2024-12-27 20:57:44,919 - INFO - Prediction completed in 0.01s
2024-12-27 20:57:44,935 - INFO - Poison rate 0.0 completed in 2.38s
2024-12-27 20:57:44,935 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:57:44,937 - INFO - Label flipping details:
2024-12-27 20:57:44,937 - INFO - - Source class: 1
2024-12-27 20:57:44,937 - INFO - - Target class: 0
2024-12-27 20:57:44,937 - INFO - - Available samples in source class: 500
2024-12-27 20:57:44,937 - INFO - - Requested samples to poison: 50
2024-12-27 20:57:44,937 - INFO - - Actual samples to flip: 50
2024-12-27 20:57:44,938 - INFO - - Samples remaining in source class: 450
2024-12-27 20:57:44,938 - INFO - Successfully flipped 50 labels from class 1 to 0
2024-12-27 20:57:44,938 - INFO - Total number of labels flipped: 50
2024-12-27 20:57:44,939 - INFO - Label flipping completed in 0.00s
2024-12-27 20:57:44,939 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:57:44,939 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:57:45,527 - INFO - Feature scaling completed in 0.59s
2024-12-27 20:57:45,527 - INFO - Starting feature selection (k=50)
2024-12-27 20:57:45,533 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:57:45,533 - INFO - Starting anomaly detection
2024-12-27 20:57:47,142 - INFO - Anomaly detection completed in 1.61s
2024-12-27 20:57:47,142 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:57:47,142 - INFO - Total fit_transform time: 2.20s
2024-12-27 20:57:47,142 - INFO - Training set processing completed in 2.20s
2024-12-27 20:57:47,142 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:57:47,143 - INFO - Memory usage at start_fit: CPU 3115.4 MB, GPU 47.5 MB
2024-12-27 20:57:47,144 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:57:47,144 - INFO - Number of unique classes: 10
2024-12-27 20:57:47,251 - INFO - Fitted scaler and transformed data
2024-12-27 20:57:47,252 - INFO - Scaling time: 0.11s
2024-12-27 20:57:47,403 - INFO - Epoch 1/200, Train Loss: 0.1727, Val Loss: 0.0849
2024-12-27 20:57:47,525 - INFO - Epoch 2/200, Train Loss: 0.0410, Val Loss: 0.2325
2024-12-27 20:57:47,643 - INFO - Epoch 3/200, Train Loss: 0.0326, Val Loss: 0.1184
2024-12-27 20:57:47,643 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:57:47,643 - INFO - Training completed in 0.50s
2024-12-27 20:57:47,644 - INFO - Final memory usage: CPU 3115.4 MB, GPU 48.1 MB
2024-12-27 20:57:47,644 - INFO - Model training completed in 0.50s
2024-12-27 20:57:47,660 - INFO - Prediction completed in 0.02s
2024-12-27 20:57:47,675 - INFO - Poison rate 0.01 completed in 2.74s
2024-12-27 20:57:47,676 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:57:47,676 - INFO - Label flipping details:
2024-12-27 20:57:47,676 - INFO - - Source class: 1
2024-12-27 20:57:47,676 - INFO - - Target class: 0
2024-12-27 20:57:47,676 - INFO - - Available samples in source class: 500
2024-12-27 20:57:47,676 - INFO - - Requested samples to poison: 150
2024-12-27 20:57:47,676 - INFO - - Actual samples to flip: 150
2024-12-27 20:57:47,677 - INFO - - Samples remaining in source class: 350
2024-12-27 20:57:47,677 - INFO - Successfully flipped 150 labels from class 1 to 0
2024-12-27 20:57:47,677 - INFO - Total number of labels flipped: 150
2024-12-27 20:57:47,677 - INFO - Label flipping completed in 0.00s
2024-12-27 20:57:47,677 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:57:47,677 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:57:48,279 - INFO - Feature scaling completed in 0.60s
2024-12-27 20:57:48,279 - INFO - Starting feature selection (k=50)
2024-12-27 20:57:48,287 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:57:48,287 - INFO - Starting anomaly detection
2024-12-27 20:57:49,678 - INFO - Anomaly detection completed in 1.39s
2024-12-27 20:57:49,678 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:57:49,678 - INFO - Total fit_transform time: 2.00s
2024-12-27 20:57:49,678 - INFO - Training set processing completed in 2.00s
2024-12-27 20:57:49,678 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:57:49,679 - INFO - Memory usage at start_fit: CPU 3115.4 MB, GPU 47.5 MB
2024-12-27 20:57:49,679 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:57:49,679 - INFO - Number of unique classes: 10
2024-12-27 20:57:49,773 - INFO - Fitted scaler and transformed data
2024-12-27 20:57:49,773 - INFO - Scaling time: 0.09s
2024-12-27 20:57:49,921 - INFO - Epoch 1/200, Train Loss: 0.2687, Val Loss: 0.1631
2024-12-27 20:57:50,041 - INFO - Epoch 2/200, Train Loss: 0.0985, Val Loss: 0.1733
2024-12-27 20:57:50,163 - INFO - Epoch 3/200, Train Loss: 0.0674, Val Loss: 0.2459
2024-12-27 20:57:50,164 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:57:50,164 - INFO - Training completed in 0.48s
2024-12-27 20:57:50,164 - INFO - Final memory usage: CPU 3115.4 MB, GPU 48.1 MB
2024-12-27 20:57:50,164 - INFO - Model training completed in 0.49s
2024-12-27 20:57:50,179 - INFO - Prediction completed in 0.01s
2024-12-27 20:57:50,192 - INFO - Poison rate 0.03 completed in 2.52s
2024-12-27 20:57:50,192 - INFO - 
Processing poison rate: 0.05
2024-12-27 20:57:50,193 - INFO - Label flipping details:
2024-12-27 20:57:50,193 - INFO - - Source class: 1
2024-12-27 20:57:50,193 - INFO - - Target class: 0
2024-12-27 20:57:50,193 - INFO - - Available samples in source class: 500
2024-12-27 20:57:50,193 - INFO - - Requested samples to poison: 250
2024-12-27 20:57:50,193 - INFO - - Actual samples to flip: 250
2024-12-27 20:57:50,193 - INFO - - Samples remaining in source class: 250
2024-12-27 20:57:50,193 - INFO - Successfully flipped 250 labels from class 1 to 0
2024-12-27 20:57:50,194 - INFO - Total number of labels flipped: 250
2024-12-27 20:57:50,194 - INFO - Label flipping completed in 0.00s
2024-12-27 20:57:50,194 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:57:50,194 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:57:50,760 - INFO - Feature scaling completed in 0.57s
2024-12-27 20:57:50,760 - INFO - Starting feature selection (k=50)
2024-12-27 20:57:50,767 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:57:50,768 - INFO - Starting anomaly detection
2024-12-27 20:57:52,833 - INFO - Anomaly detection completed in 2.07s
2024-12-27 20:57:52,833 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:57:52,833 - INFO - Total fit_transform time: 2.64s
2024-12-27 20:57:52,834 - INFO - Training set processing completed in 2.64s
2024-12-27 20:57:52,834 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:57:52,835 - INFO - Memory usage at start_fit: CPU 3115.4 MB, GPU 47.5 MB
2024-12-27 20:57:52,835 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:57:52,835 - INFO - Number of unique classes: 10
2024-12-27 20:57:52,930 - INFO - Fitted scaler and transformed data
2024-12-27 20:57:52,930 - INFO - Scaling time: 0.09s
2024-12-27 20:57:53,120 - INFO - Epoch 1/200, Train Loss: 0.2861, Val Loss: 0.2629
2024-12-27 20:57:53,321 - INFO - Epoch 2/200, Train Loss: 0.1499, Val Loss: 0.1917
2024-12-27 20:57:53,497 - INFO - Epoch 3/200, Train Loss: 0.0676, Val Loss: 0.2537
2024-12-27 20:57:53,622 - INFO - Epoch 4/200, Train Loss: 0.0497, Val Loss: 0.2580
2024-12-27 20:57:53,622 - INFO - Early stopping triggered at epoch 4
2024-12-27 20:57:53,622 - INFO - Training completed in 0.79s
2024-12-27 20:57:53,622 - INFO - Final memory usage: CPU 3115.4 MB, GPU 48.1 MB
2024-12-27 20:57:53,623 - INFO - Model training completed in 0.79s
2024-12-27 20:57:53,637 - INFO - Prediction completed in 0.01s
2024-12-27 20:57:53,657 - INFO - Poison rate 0.05 completed in 3.46s
2024-12-27 20:57:53,658 - INFO - 
Processing poison rate: 0.07
2024-12-27 20:57:53,659 - INFO - Label flipping details:
2024-12-27 20:57:53,659 - INFO - - Source class: 1
2024-12-27 20:57:53,659 - INFO - - Target class: 0
2024-12-27 20:57:53,659 - INFO - - Available samples in source class: 500
2024-12-27 20:57:53,659 - INFO - - Requested samples to poison: 350
2024-12-27 20:57:53,659 - INFO - - Actual samples to flip: 350
2024-12-27 20:57:53,660 - INFO - - Samples remaining in source class: 150
2024-12-27 20:57:53,660 - INFO - Successfully flipped 350 labels from class 1 to 0
2024-12-27 20:57:53,660 - INFO - Total number of labels flipped: 350
2024-12-27 20:57:53,660 - INFO - Label flipping completed in 0.00s
2024-12-27 20:57:53,661 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:57:53,661 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:57:54,246 - INFO - Feature scaling completed in 0.58s
2024-12-27 20:57:54,246 - INFO - Starting feature selection (k=50)
2024-12-27 20:57:54,259 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:57:54,259 - INFO - Starting anomaly detection
2024-12-27 20:57:56,134 - INFO - Anomaly detection completed in 1.87s
2024-12-27 20:57:56,134 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:57:56,134 - INFO - Total fit_transform time: 2.47s
2024-12-27 20:57:56,134 - INFO - Training set processing completed in 2.47s
2024-12-27 20:57:56,134 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:57:56,135 - INFO - Memory usage at start_fit: CPU 3115.4 MB, GPU 47.5 MB
2024-12-27 20:57:56,136 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:57:56,136 - INFO - Number of unique classes: 10
2024-12-27 20:57:56,253 - INFO - Fitted scaler and transformed data
2024-12-27 20:57:56,254 - INFO - Scaling time: 0.12s
2024-12-27 20:57:56,436 - INFO - Epoch 1/200, Train Loss: 0.2623, Val Loss: 0.1560
2024-12-27 20:57:56,557 - INFO - Epoch 2/200, Train Loss: 0.0891, Val Loss: 0.0681
2024-12-27 20:57:56,691 - INFO - Epoch 3/200, Train Loss: 0.0497, Val Loss: 0.0774
2024-12-27 20:57:56,821 - INFO - Epoch 4/200, Train Loss: 0.0522, Val Loss: 0.0885
2024-12-27 20:57:56,822 - INFO - Early stopping triggered at epoch 4
2024-12-27 20:57:56,822 - INFO - Training completed in 0.69s
2024-12-27 20:57:56,823 - INFO - Final memory usage: CPU 3115.4 MB, GPU 48.1 MB
2024-12-27 20:57:56,823 - INFO - Model training completed in 0.69s
2024-12-27 20:57:56,838 - INFO - Prediction completed in 0.01s
2024-12-27 20:57:56,855 - INFO - Poison rate 0.07 completed in 3.20s
2024-12-27 20:57:56,855 - INFO - 
Processing poison rate: 0.1
2024-12-27 20:57:56,857 - INFO - Label flipping details:
2024-12-27 20:57:56,857 - INFO - - Source class: 1
2024-12-27 20:57:56,857 - INFO - - Target class: 0
2024-12-27 20:57:56,857 - INFO - - Available samples in source class: 500
2024-12-27 20:57:56,857 - INFO - - Requested samples to poison: 500
2024-12-27 20:57:56,857 - INFO - - Actual samples to flip: 499
2024-12-27 20:57:56,858 - INFO - - Samples remaining in source class: 1
2024-12-27 20:57:56,858 - INFO - Successfully flipped 499 labels from class 1 to 0
2024-12-27 20:57:56,858 - INFO - Total number of labels flipped: 499
2024-12-27 20:57:56,858 - INFO - Label flipping completed in 0.00s
2024-12-27 20:57:56,859 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:57:56,859 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:57:57,423 - INFO - Feature scaling completed in 0.56s
2024-12-27 20:57:57,423 - INFO - Starting feature selection (k=50)
2024-12-27 20:57:57,437 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:57:57,437 - INFO - Starting anomaly detection
2024-12-27 20:57:59,154 - INFO - Anomaly detection completed in 1.72s
2024-12-27 20:57:59,154 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:57:59,154 - INFO - Total fit_transform time: 2.30s
2024-12-27 20:57:59,154 - INFO - Training set processing completed in 2.30s
2024-12-27 20:57:59,154 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:57:59,156 - INFO - Memory usage at start_fit: CPU 3115.4 MB, GPU 47.5 MB
2024-12-27 20:57:59,156 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:57:59,157 - INFO - Number of unique classes: 10
2024-12-27 20:57:59,261 - INFO - Fitted scaler and transformed data
2024-12-27 20:57:59,261 - INFO - Scaling time: 0.10s
2024-12-27 20:57:59,422 - INFO - Epoch 1/200, Train Loss: 0.1255, Val Loss: 0.1177
2024-12-27 20:57:59,580 - INFO - Epoch 2/200, Train Loss: 0.0047, Val Loss: 0.1038
2024-12-27 20:57:59,738 - INFO - Epoch 3/200, Train Loss: 0.0004, Val Loss: 0.0942
2024-12-27 20:57:59,928 - INFO - Epoch 4/200, Train Loss: 0.0001, Val Loss: 0.0946
2024-12-27 20:57:59,929 - INFO - Early stopping triggered at epoch 4
2024-12-27 20:57:59,929 - INFO - Training completed in 0.77s
2024-12-27 20:57:59,929 - INFO - Final memory usage: CPU 3115.4 MB, GPU 48.1 MB
2024-12-27 20:57:59,929 - INFO - Model training completed in 0.77s
2024-12-27 20:57:59,944 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:57:59,963 - INFO - Poison rate 0.1 completed in 3.11s
2024-12-27 20:57:59,963 - INFO - 
Processing poison rate: 0.2
2024-12-27 20:57:59,963 - INFO - Label flipping details:
2024-12-27 20:57:59,964 - INFO - - Source class: 1
2024-12-27 20:57:59,964 - INFO - - Target class: 0
2024-12-27 20:57:59,964 - INFO - - Available samples in source class: 500
2024-12-27 20:57:59,964 - INFO - - Requested samples to poison: 1000
2024-12-27 20:57:59,964 - INFO - - Actual samples to flip: 499
2024-12-27 20:57:59,964 - INFO - - Samples remaining in source class: 1
2024-12-27 20:57:59,964 - INFO - Successfully flipped 499 labels from class 1 to 0
2024-12-27 20:57:59,964 - INFO - Total number of labels flipped: 499
2024-12-27 20:57:59,964 - INFO - Label flipping completed in 0.00s
2024-12-27 20:57:59,964 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 20:57:59,964 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 20:58:00,534 - INFO - Feature scaling completed in 0.57s
2024-12-27 20:58:00,534 - INFO - Starting feature selection (k=50)
2024-12-27 20:58:00,542 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 20:58:00,542 - INFO - Starting anomaly detection
2024-12-27 20:58:02,469 - INFO - Anomaly detection completed in 1.93s
2024-12-27 20:58:02,472 - INFO - Found 500 outliers (10.0%)
2024-12-27 20:58:02,472 - INFO - Total fit_transform time: 2.51s
2024-12-27 20:58:02,473 - INFO - Training set processing completed in 2.51s
2024-12-27 20:58:02,473 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 20:58:02,474 - INFO - Memory usage at start_fit: CPU 3115.4 MB, GPU 47.5 MB
2024-12-27 20:58:02,474 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:58:02,475 - INFO - Number of unique classes: 10
2024-12-27 20:58:02,572 - INFO - Fitted scaler and transformed data
2024-12-27 20:58:02,572 - INFO - Scaling time: 0.10s
2024-12-27 20:58:02,733 - INFO - Epoch 1/200, Train Loss: 0.1452, Val Loss: 0.0076
2024-12-27 20:58:02,862 - INFO - Epoch 2/200, Train Loss: 0.0088, Val Loss: 0.0248
2024-12-27 20:58:03,015 - INFO - Epoch 3/200, Train Loss: 0.0007, Val Loss: 0.0234
2024-12-27 20:58:03,015 - INFO - Early stopping triggered at epoch 3
2024-12-27 20:58:03,016 - INFO - Training completed in 0.54s
2024-12-27 20:58:03,016 - INFO - Final memory usage: CPU 3115.4 MB, GPU 48.1 MB
2024-12-27 20:58:03,016 - INFO - Model training completed in 0.54s
2024-12-27 20:58:03,023 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 20:58:03,031 - INFO - Poison rate 0.2 completed in 3.07s
2024-12-27 20:58:03,031 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 20:58:03,032 - INFO - Total evaluation time: 34.35s
2024-12-27 20:58:03,033 - INFO - 
Progress: 88.5% - Evaluating ImageNette with RandomForest (standard mode, iteration 1/1)
2024-12-27 20:58:03,112 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 20:58:03,183 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 20:58:03,273 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 20:58:03,273 - INFO - Dataset type: image
2024-12-27 20:58:03,273 - INFO - Sample size: 5000
2024-12-27 20:58:03,273 - INFO - Using device: cuda
2024-12-27 20:58:03,275 - INFO - Loading datasets...
2024-12-27 20:58:03,299 - INFO - Dataset loading completed in 0.02s
2024-12-27 20:58:03,299 - INFO - Extracting validation features...
2024-12-27 20:58:03,299 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:24,  1.25it/s]Extracting features:  19%|█▉        | 6/32 [00:00<00:03,  8.48it/s]Extracting features:  31%|███▏      | 10/32 [00:01<00:01, 12.79it/s]Extracting features:  41%|████      | 13/32 [00:01<00:01, 14.82it/s]Extracting features:  50%|█████     | 16/32 [00:01<00:01, 12.94it/s]Extracting features:  56%|█████▋    | 18/32 [00:01<00:01, 11.58it/s]Extracting features:  66%|██████▌   | 21/32 [00:01<00:00, 12.25it/s]Extracting features:  72%|███████▏  | 23/32 [00:02<00:00, 12.33it/s]Extracting features:  81%|████████▏ | 26/32 [00:02<00:00, 14.86it/s]Extracting features:  91%|█████████ | 29/32 [00:02<00:00, 16.42it/s]Extracting features:  97%|█████████▋| 31/32 [00:02<00:00, 14.53it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 12.04it/s]
2024-12-27 20:58:05,962 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 20:58:05,963 - INFO - Validation feature extraction completed in 2.66s
2024-12-27 20:58:05,963 - INFO - Extracting training features...
2024-12-27 20:58:05,964 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:20,  1.94it/s]Extracting features:   3%|▎         | 5/157 [00:00<00:23,  6.45it/s]Extracting features:   6%|▌         | 9/157 [00:01<00:17,  8.54it/s]Extracting features:   8%|▊         | 12/157 [00:01<00:12, 11.38it/s]Extracting features:   9%|▉         | 14/157 [00:01<00:12, 11.16it/s]Extracting features:  11%|█         | 17/157 [00:01<00:12, 11.08it/s]Extracting features:  13%|█▎        | 21/157 [00:02<00:10, 13.00it/s]Extracting features:  15%|█▌        | 24/157 [00:02<00:09, 14.69it/s]Extracting features:  17%|█▋        | 26/157 [00:02<00:08, 15.43it/s]Extracting features:  18%|█▊        | 28/157 [00:02<00:09, 12.98it/s]Extracting features:  20%|██        | 32/157 [00:02<00:07, 15.79it/s]Extracting features:  23%|██▎       | 36/157 [00:02<00:06, 18.07it/s]Extracting features:  25%|██▍       | 39/157 [00:02<00:05, 20.35it/s]Extracting features:  27%|██▋       | 42/157 [00:03<00:05, 19.58it/s]Extracting features:  29%|██▊       | 45/157 [00:03<00:05, 19.02it/s]Extracting features:  31%|███       | 48/157 [00:03<00:06, 17.08it/s]Extracting features:  33%|███▎      | 52/157 [00:03<00:06, 16.06it/s]Extracting features:  36%|███▌      | 56/157 [00:04<00:06, 15.44it/s]Extracting features:  38%|███▊      | 60/157 [00:04<00:05, 16.61it/s]Extracting features:  41%|████      | 64/157 [00:04<00:05, 15.95it/s]Extracting features:  43%|████▎     | 68/157 [00:04<00:06, 13.98it/s]Extracting features:  46%|████▌     | 72/157 [00:05<00:06, 13.67it/s]Extracting features:  48%|████▊     | 76/157 [00:05<00:05, 14.29it/s]Extracting features:  51%|█████     | 80/157 [00:05<00:06, 12.29it/s]Extracting features:  54%|█████▎    | 84/157 [00:06<00:05, 13.14it/s]Extracting features:  56%|█████▌    | 88/157 [00:06<00:04, 13.83it/s]Extracting features:  59%|█████▊    | 92/157 [00:06<00:04, 15.09it/s]Extracting features:  61%|██████    | 95/157 [00:06<00:03, 16.74it/s]Extracting features:  62%|██████▏   | 97/157 [00:07<00:04, 13.20it/s]Extracting features:  64%|██████▎   | 100/157 [00:07<00:04, 12.47it/s]Extracting features:  66%|██████▌   | 104/157 [00:07<00:03, 13.51it/s]Extracting features:  69%|██████▉   | 108/157 [00:07<00:03, 14.41it/s]Extracting features:  71%|███████▏  | 112/157 [00:08<00:03, 14.07it/s]Extracting features:  73%|███████▎  | 115/157 [00:08<00:02, 16.13it/s]Extracting features:  75%|███████▍  | 117/157 [00:08<00:02, 13.79it/s]Extracting features:  76%|███████▌  | 119/157 [00:08<00:03, 12.35it/s]Extracting features:  77%|███████▋  | 121/157 [00:09<00:04,  8.42it/s]Extracting features:  80%|███████▉  | 125/157 [00:09<00:03, 10.65it/s]Extracting features:  82%|████████▏ | 129/157 [00:09<00:02, 12.78it/s]Extracting features:  85%|████████▍ | 133/157 [00:09<00:01, 14.91it/s]Extracting features:  87%|████████▋ | 137/157 [00:09<00:01, 16.42it/s]Extracting features:  90%|████████▉ | 141/157 [00:10<00:00, 16.65it/s]Extracting features:  92%|█████████▏| 145/157 [00:10<00:00, 16.44it/s]Extracting features:  95%|█████████▍| 149/157 [00:10<00:00, 14.42it/s]Extracting features:  97%|█████████▋| 153/157 [00:11<00:00, 13.58it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 16.83it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 13.92it/s]
2024-12-27 20:58:17,261 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 20:58:17,262 - INFO - Training feature extraction completed in 11.30s
2024-12-27 20:58:17,262 - INFO - Creating model for classifier: RandomForest
2024-12-27 20:58:17,262 - INFO - Using device: cuda
2024-12-27 20:58:17,262 - INFO - 
Processing poison rate: 0.0
2024-12-27 20:58:17,262 - INFO - Training set processing completed in 0.00s
2024-12-27 20:58:17,262 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:58:17,263 - INFO - Memory usage at start_fit: CPU 3115.7 MB, GPU 47.3 MB
2024-12-27 20:58:17,264 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:58:17,330 - INFO - Fitted scaler and transformed data
2024-12-27 20:58:17,330 - INFO - Scaling time: 0.07s
2024-12-27 20:58:17,336 - INFO - Number of unique classes: 10
2024-12-27 20:58:20,532 - INFO - Epoch 1/15, Train Loss: 2.2968, Val Loss: 2.2899
2024-12-27 20:58:24,036 - INFO - Epoch 2/15, Train Loss: 2.2811, Val Loss: 2.2752
2024-12-27 20:58:27,609 - INFO - Epoch 3/15, Train Loss: 2.2632, Val Loss: 2.2579
2024-12-27 20:58:31,049 - INFO - Epoch 4/15, Train Loss: 2.2425, Val Loss: 2.2376
2024-12-27 20:58:35,292 - INFO - Epoch 5/15, Train Loss: 2.2187, Val Loss: 2.2148
2024-12-27 20:58:39,464 - INFO - Epoch 6/15, Train Loss: 2.1926, Val Loss: 2.1901
2024-12-27 20:58:43,007 - INFO - Epoch 7/15, Train Loss: 2.1648, Val Loss: 2.1651
2024-12-27 20:58:45,763 - INFO - Epoch 8/15, Train Loss: 2.1375, Val Loss: 2.1410
2024-12-27 20:58:48,433 - INFO - Epoch 9/15, Train Loss: 2.1122, Val Loss: 2.1191
2024-12-27 20:58:51,801 - INFO - Epoch 10/15, Train Loss: 2.0893, Val Loss: 2.1000
2024-12-27 20:58:55,512 - INFO - Epoch 11/15, Train Loss: 2.0691, Val Loss: 2.0833
2024-12-27 20:58:58,894 - INFO - Epoch 12/15, Train Loss: 2.0518, Val Loss: 2.0691
2024-12-27 20:59:02,245 - INFO - Epoch 13/15, Train Loss: 2.0365, Val Loss: 2.0570
2024-12-27 20:59:05,114 - INFO - Epoch 14/15, Train Loss: 2.0237, Val Loss: 2.0466
2024-12-27 20:59:08,701 - INFO - Epoch 15/15, Train Loss: 2.0122, Val Loss: 2.0376
2024-12-27 20:59:08,701 - INFO - Training completed in 51.44s
2024-12-27 20:59:08,702 - INFO - Final memory usage: CPU 3115.7 MB, GPU 75.5 MB
2024-12-27 20:59:08,702 - INFO - Model training completed in 51.44s
2024-12-27 20:59:08,815 - INFO - Prediction completed in 0.11s
2024-12-27 20:59:08,824 - INFO - Poison rate 0.0 completed in 51.56s
2024-12-27 20:59:08,824 - INFO - 
Processing poison rate: 0.01
2024-12-27 20:59:08,824 - INFO - Label flipping details:
2024-12-27 20:59:08,825 - INFO - - Source class: 1
2024-12-27 20:59:08,825 - INFO - - Target class: 0
2024-12-27 20:59:08,825 - INFO - - Available samples in source class: 500
2024-12-27 20:59:08,825 - INFO - - Requested samples to poison: 50
2024-12-27 20:59:08,825 - INFO - - Actual samples to flip: 50
2024-12-27 20:59:08,825 - INFO - - Samples remaining in source class: 450
2024-12-27 20:59:08,825 - INFO - Successfully flipped 50 labels from class 1 to 0
2024-12-27 20:59:08,825 - INFO - Total number of labels flipped: 50
2024-12-27 20:59:08,825 - INFO - Label flipping completed in 0.00s
2024-12-27 20:59:08,825 - INFO - Training set processing completed in 0.00s
2024-12-27 20:59:08,825 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:59:08,826 - INFO - Memory usage at start_fit: CPU 3115.7 MB, GPU 49.3 MB
2024-12-27 20:59:08,826 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:59:08,907 - INFO - Fitted scaler and transformed data
2024-12-27 20:59:08,907 - INFO - Scaling time: 0.08s
2024-12-27 20:59:08,918 - INFO - Number of unique classes: 10
2024-12-27 20:59:12,413 - INFO - Epoch 1/15, Train Loss: 2.2969, Val Loss: 2.2901
2024-12-27 20:59:15,435 - INFO - Epoch 2/15, Train Loss: 2.2812, Val Loss: 2.2755
2024-12-27 20:59:18,663 - INFO - Epoch 3/15, Train Loss: 2.2633, Val Loss: 2.2583
2024-12-27 20:59:21,289 - INFO - Epoch 4/15, Train Loss: 2.2427, Val Loss: 2.2383
2024-12-27 20:59:24,205 - INFO - Epoch 5/15, Train Loss: 2.2190, Val Loss: 2.2156
2024-12-27 20:59:27,095 - INFO - Epoch 6/15, Train Loss: 2.1927, Val Loss: 2.1913
2024-12-27 20:59:29,888 - INFO - Epoch 7/15, Train Loss: 2.1655, Val Loss: 2.1666
2024-12-27 20:59:33,236 - INFO - Epoch 8/15, Train Loss: 2.1388, Val Loss: 2.1431
2024-12-27 20:59:36,850 - INFO - Epoch 9/15, Train Loss: 2.1134, Val Loss: 2.1219
2024-12-27 20:59:40,182 - INFO - Epoch 10/15, Train Loss: 2.0911, Val Loss: 2.1033
2024-12-27 20:59:43,161 - INFO - Epoch 11/15, Train Loss: 2.0710, Val Loss: 2.0872
2024-12-27 20:59:46,538 - INFO - Epoch 12/15, Train Loss: 2.0535, Val Loss: 2.0735
2024-12-27 20:59:49,434 - INFO - Epoch 13/15, Train Loss: 2.0387, Val Loss: 2.0618
2024-12-27 20:59:52,259 - INFO - Epoch 14/15, Train Loss: 2.0261, Val Loss: 2.0517
2024-12-27 20:59:54,830 - INFO - Epoch 15/15, Train Loss: 2.0150, Val Loss: 2.0432
2024-12-27 20:59:54,831 - INFO - Training completed in 46.00s
2024-12-27 20:59:54,831 - INFO - Final memory usage: CPU 3115.7 MB, GPU 75.5 MB
2024-12-27 20:59:54,831 - INFO - Model training completed in 46.01s
2024-12-27 20:59:54,932 - INFO - Prediction completed in 0.10s
2024-12-27 20:59:54,939 - INFO - Poison rate 0.01 completed in 46.12s
2024-12-27 20:59:54,940 - INFO - 
Processing poison rate: 0.03
2024-12-27 20:59:54,940 - INFO - Label flipping details:
2024-12-27 20:59:54,940 - INFO - - Source class: 1
2024-12-27 20:59:54,940 - INFO - - Target class: 0
2024-12-27 20:59:54,940 - INFO - - Available samples in source class: 500
2024-12-27 20:59:54,940 - INFO - - Requested samples to poison: 150
2024-12-27 20:59:54,940 - INFO - - Actual samples to flip: 150
2024-12-27 20:59:54,940 - INFO - - Samples remaining in source class: 350
2024-12-27 20:59:54,940 - INFO - Successfully flipped 150 labels from class 1 to 0
2024-12-27 20:59:54,941 - INFO - Total number of labels flipped: 150
2024-12-27 20:59:54,941 - INFO - Label flipping completed in 0.00s
2024-12-27 20:59:54,941 - INFO - Training set processing completed in 0.00s
2024-12-27 20:59:54,941 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 20:59:54,942 - INFO - Memory usage at start_fit: CPU 3115.7 MB, GPU 49.3 MB
2024-12-27 20:59:54,942 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 20:59:55,006 - INFO - Fitted scaler and transformed data
2024-12-27 20:59:55,006 - INFO - Scaling time: 0.06s
2024-12-27 20:59:55,018 - INFO - Number of unique classes: 10
2024-12-27 20:59:57,992 - INFO - Epoch 1/15, Train Loss: 2.2971, Val Loss: 2.2901
2024-12-27 21:00:01,473 - INFO - Epoch 2/15, Train Loss: 2.2818, Val Loss: 2.2754
2024-12-27 21:00:05,344 - INFO - Epoch 3/15, Train Loss: 2.2645, Val Loss: 2.2582
2024-12-27 21:00:08,654 - INFO - Epoch 4/15, Train Loss: 2.2444, Val Loss: 2.2381
2024-12-27 21:00:11,951 - INFO - Epoch 5/15, Train Loss: 2.2214, Val Loss: 2.2154
2024-12-27 21:00:15,193 - INFO - Epoch 6/15, Train Loss: 2.1963, Val Loss: 2.1908
2024-12-27 21:00:18,723 - INFO - Epoch 7/15, Train Loss: 2.1697, Val Loss: 2.1659
2024-12-27 21:00:21,903 - INFO - Epoch 8/15, Train Loss: 2.1437, Val Loss: 2.1421
2024-12-27 21:00:25,056 - INFO - Epoch 9/15, Train Loss: 2.1189, Val Loss: 2.1206
2024-12-27 21:00:28,752 - INFO - Epoch 10/15, Train Loss: 2.0966, Val Loss: 2.1015
2024-12-27 21:00:32,264 - INFO - Epoch 11/15, Train Loss: 2.0776, Val Loss: 2.0851
2024-12-27 21:00:35,043 - INFO - Epoch 12/15, Train Loss: 2.0606, Val Loss: 2.0711
2024-12-27 21:00:38,943 - INFO - Epoch 13/15, Train Loss: 2.0461, Val Loss: 2.0590
2024-12-27 21:00:42,373 - INFO - Epoch 14/15, Train Loss: 2.0332, Val Loss: 2.0488
2024-12-27 21:00:45,257 - INFO - Epoch 15/15, Train Loss: 2.0225, Val Loss: 2.0398
2024-12-27 21:00:45,258 - INFO - Training completed in 50.32s
2024-12-27 21:00:45,258 - INFO - Final memory usage: CPU 3115.7 MB, GPU 75.5 MB
2024-12-27 21:00:45,258 - INFO - Model training completed in 50.32s
2024-12-27 21:00:45,369 - INFO - Prediction completed in 0.11s
2024-12-27 21:00:45,377 - INFO - Poison rate 0.03 completed in 50.44s
2024-12-27 21:00:45,377 - INFO - 
Processing poison rate: 0.05
2024-12-27 21:00:45,378 - INFO - Label flipping details:
2024-12-27 21:00:45,378 - INFO - - Source class: 1
2024-12-27 21:00:45,378 - INFO - - Target class: 0
2024-12-27 21:00:45,378 - INFO - - Available samples in source class: 500
2024-12-27 21:00:45,378 - INFO - - Requested samples to poison: 250
2024-12-27 21:00:45,378 - INFO - - Actual samples to flip: 250
2024-12-27 21:00:45,378 - INFO - - Samples remaining in source class: 250
2024-12-27 21:00:45,378 - INFO - Successfully flipped 250 labels from class 1 to 0
2024-12-27 21:00:45,378 - INFO - Total number of labels flipped: 250
2024-12-27 21:00:45,378 - INFO - Label flipping completed in 0.00s
2024-12-27 21:00:45,378 - INFO - Training set processing completed in 0.00s
2024-12-27 21:00:45,378 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 21:00:45,379 - INFO - Memory usage at start_fit: CPU 3115.7 MB, GPU 49.3 MB
2024-12-27 21:00:45,379 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:00:45,443 - INFO - Fitted scaler and transformed data
2024-12-27 21:00:45,443 - INFO - Scaling time: 0.06s
2024-12-27 21:00:45,454 - INFO - Number of unique classes: 10
2024-12-27 21:00:48,305 - INFO - Epoch 1/15, Train Loss: 2.2970, Val Loss: 2.2901
2024-12-27 21:00:51,606 - INFO - Epoch 2/15, Train Loss: 2.2818, Val Loss: 2.2755
2024-12-27 21:00:54,888 - INFO - Epoch 3/15, Train Loss: 2.2645, Val Loss: 2.2585
2024-12-27 21:00:57,875 - INFO - Epoch 4/15, Train Loss: 2.2444, Val Loss: 2.2387
2024-12-27 21:01:00,828 - INFO - Epoch 5/15, Train Loss: 2.2215, Val Loss: 2.2164
2024-12-27 21:01:04,068 - INFO - Epoch 6/15, Train Loss: 2.1961, Val Loss: 2.1924
2024-12-27 21:01:06,980 - INFO - Epoch 7/15, Train Loss: 2.1697, Val Loss: 2.1680
2024-12-27 21:01:09,540 - INFO - Epoch 8/15, Train Loss: 2.1440, Val Loss: 2.1448
2024-12-27 21:01:12,258 - INFO - Epoch 9/15, Train Loss: 2.1196, Val Loss: 2.1240
2024-12-27 21:01:15,321 - INFO - Epoch 10/15, Train Loss: 2.0980, Val Loss: 2.1058
2024-12-27 21:01:18,639 - INFO - Epoch 11/15, Train Loss: 2.0791, Val Loss: 2.0900
2024-12-27 21:01:21,775 - INFO - Epoch 12/15, Train Loss: 2.0628, Val Loss: 2.0765
2024-12-27 21:01:24,762 - INFO - Epoch 13/15, Train Loss: 2.0485, Val Loss: 2.0650
2024-12-27 21:01:27,550 - INFO - Epoch 14/15, Train Loss: 2.0356, Val Loss: 2.0554
2024-12-27 21:01:30,106 - INFO - Epoch 15/15, Train Loss: 2.0249, Val Loss: 2.0468
2024-12-27 21:01:30,106 - INFO - Training completed in 44.73s
2024-12-27 21:01:30,107 - INFO - Final memory usage: CPU 3115.7 MB, GPU 75.5 MB
2024-12-27 21:01:30,107 - INFO - Model training completed in 44.73s
2024-12-27 21:01:30,217 - INFO - Prediction completed in 0.11s
2024-12-27 21:01:30,225 - INFO - Poison rate 0.05 completed in 44.85s
2024-12-27 21:01:30,225 - INFO - 
Processing poison rate: 0.07
2024-12-27 21:01:30,226 - INFO - Label flipping details:
2024-12-27 21:01:30,226 - INFO - - Source class: 1
2024-12-27 21:01:30,226 - INFO - - Target class: 0
2024-12-27 21:01:30,226 - INFO - - Available samples in source class: 500
2024-12-27 21:01:30,226 - INFO - - Requested samples to poison: 350
2024-12-27 21:01:30,226 - INFO - - Actual samples to flip: 350
2024-12-27 21:01:30,226 - INFO - - Samples remaining in source class: 150
2024-12-27 21:01:30,226 - INFO - Successfully flipped 350 labels from class 1 to 0
2024-12-27 21:01:30,226 - INFO - Total number of labels flipped: 350
2024-12-27 21:01:30,226 - INFO - Label flipping completed in 0.00s
2024-12-27 21:01:30,226 - INFO - Training set processing completed in 0.00s
2024-12-27 21:01:30,226 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 21:01:30,227 - INFO - Memory usage at start_fit: CPU 3115.7 MB, GPU 49.3 MB
2024-12-27 21:01:30,227 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:01:30,292 - INFO - Fitted scaler and transformed data
2024-12-27 21:01:30,293 - INFO - Scaling time: 0.07s
2024-12-27 21:01:30,303 - INFO - Number of unique classes: 10
2024-12-27 21:01:33,747 - INFO - Epoch 1/15, Train Loss: 2.2968, Val Loss: 2.2901
2024-12-27 21:01:36,587 - INFO - Epoch 2/15, Train Loss: 2.2810, Val Loss: 2.2756
2024-12-27 21:01:39,887 - INFO - Epoch 3/15, Train Loss: 2.2630, Val Loss: 2.2586
2024-12-27 21:01:44,416 - INFO - Epoch 4/15, Train Loss: 2.2420, Val Loss: 2.2386
2024-12-27 21:01:47,271 - INFO - Epoch 5/15, Train Loss: 2.2179, Val Loss: 2.2159
2024-12-27 21:01:50,311 - INFO - Epoch 6/15, Train Loss: 2.1911, Val Loss: 2.1917
2024-12-27 21:01:53,373 - INFO - Epoch 7/15, Train Loss: 2.1633, Val Loss: 2.1674
2024-12-27 21:01:56,749 - INFO - Epoch 8/15, Train Loss: 2.1363, Val Loss: 2.1444
2024-12-27 21:02:00,186 - INFO - Epoch 9/15, Train Loss: 2.1111, Val Loss: 2.1238
2024-12-27 21:02:03,060 - INFO - Epoch 10/15, Train Loss: 2.0885, Val Loss: 2.1058
2024-12-27 21:02:05,962 - INFO - Epoch 11/15, Train Loss: 2.0687, Val Loss: 2.0903
2024-12-27 21:02:08,932 - INFO - Epoch 12/15, Train Loss: 2.0521, Val Loss: 2.0769
2024-12-27 21:02:12,074 - INFO - Epoch 13/15, Train Loss: 2.0376, Val Loss: 2.0656
2024-12-27 21:02:15,619 - INFO - Epoch 14/15, Train Loss: 2.0251, Val Loss: 2.0557
2024-12-27 21:02:18,950 - INFO - Epoch 15/15, Train Loss: 2.0142, Val Loss: 2.0474
2024-12-27 21:02:18,951 - INFO - Training completed in 48.72s
2024-12-27 21:02:18,951 - INFO - Final memory usage: CPU 3115.7 MB, GPU 75.5 MB
2024-12-27 21:02:18,951 - INFO - Model training completed in 48.72s
2024-12-27 21:02:19,068 - INFO - Prediction completed in 0.12s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 21:02:19,077 - INFO - Poison rate 0.07 completed in 48.85s
2024-12-27 21:02:19,077 - INFO - 
Processing poison rate: 0.1
2024-12-27 21:02:19,077 - INFO - Label flipping details:
2024-12-27 21:02:19,077 - INFO - - Source class: 1
2024-12-27 21:02:19,077 - INFO - - Target class: 0
2024-12-27 21:02:19,077 - INFO - - Available samples in source class: 500
2024-12-27 21:02:19,077 - INFO - - Requested samples to poison: 500
2024-12-27 21:02:19,077 - INFO - - Actual samples to flip: 499
2024-12-27 21:02:19,077 - INFO - - Samples remaining in source class: 1
2024-12-27 21:02:19,078 - INFO - Successfully flipped 499 labels from class 1 to 0
2024-12-27 21:02:19,078 - INFO - Total number of labels flipped: 499
2024-12-27 21:02:19,078 - INFO - Label flipping completed in 0.00s
2024-12-27 21:02:19,078 - INFO - Training set processing completed in 0.00s
2024-12-27 21:02:19,078 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 21:02:19,079 - INFO - Memory usage at start_fit: CPU 3115.7 MB, GPU 49.3 MB
2024-12-27 21:02:19,079 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:02:19,164 - INFO - Fitted scaler and transformed data
2024-12-27 21:02:19,164 - INFO - Scaling time: 0.09s
2024-12-27 21:02:19,175 - INFO - Number of unique classes: 10
2024-12-27 21:02:22,155 - INFO - Epoch 1/15, Train Loss: 2.2965, Val Loss: 2.2895
2024-12-27 21:02:25,511 - INFO - Epoch 2/15, Train Loss: 2.2801, Val Loss: 2.2741
2024-12-27 21:02:28,810 - INFO - Epoch 3/15, Train Loss: 2.2613, Val Loss: 2.2561
2024-12-27 21:02:31,708 - INFO - Epoch 4/15, Train Loss: 2.2396, Val Loss: 2.2349
2024-12-27 21:02:34,623 - INFO - Epoch 5/15, Train Loss: 2.2144, Val Loss: 2.2111
2024-12-27 21:02:38,309 - INFO - Epoch 6/15, Train Loss: 2.1870, Val Loss: 2.1854
2024-12-27 21:02:41,965 - INFO - Epoch 7/15, Train Loss: 2.1577, Val Loss: 2.1594
2024-12-27 21:02:45,388 - INFO - Epoch 8/15, Train Loss: 2.1295, Val Loss: 2.1345
2024-12-27 21:02:48,470 - INFO - Epoch 9/15, Train Loss: 2.1026, Val Loss: 2.1120
2024-12-27 21:02:51,429 - INFO - Epoch 10/15, Train Loss: 2.0792, Val Loss: 2.0923
2024-12-27 21:02:54,720 - INFO - Epoch 11/15, Train Loss: 2.0581, Val Loss: 2.0754
2024-12-27 21:02:57,534 - INFO - Epoch 12/15, Train Loss: 2.0406, Val Loss: 2.0610
2024-12-27 21:03:00,254 - INFO - Epoch 13/15, Train Loss: 2.0257, Val Loss: 2.0486
2024-12-27 21:03:04,321 - INFO - Epoch 14/15, Train Loss: 2.0125, Val Loss: 2.0381
2024-12-27 21:03:07,695 - INFO - Epoch 15/15, Train Loss: 2.0007, Val Loss: 2.0291
2024-12-27 21:03:07,695 - INFO - Training completed in 48.62s
2024-12-27 21:03:07,696 - INFO - Final memory usage: CPU 3115.7 MB, GPU 75.5 MB
2024-12-27 21:03:07,696 - INFO - Model training completed in 48.62s
2024-12-27 21:03:07,802 - INFO - Prediction completed in 0.11s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 21:03:07,811 - INFO - Poison rate 0.1 completed in 48.73s
2024-12-27 21:03:07,811 - INFO - 
Processing poison rate: 0.2
2024-12-27 21:03:07,811 - INFO - Label flipping details:
2024-12-27 21:03:07,811 - INFO - - Source class: 1
2024-12-27 21:03:07,811 - INFO - - Target class: 0
2024-12-27 21:03:07,812 - INFO - - Available samples in source class: 500
2024-12-27 21:03:07,812 - INFO - - Requested samples to poison: 1000
2024-12-27 21:03:07,812 - INFO - - Actual samples to flip: 499
2024-12-27 21:03:07,812 - INFO - - Samples remaining in source class: 1
2024-12-27 21:03:07,812 - INFO - Successfully flipped 499 labels from class 1 to 0
2024-12-27 21:03:07,812 - INFO - Total number of labels flipped: 499
2024-12-27 21:03:07,812 - INFO - Label flipping completed in 0.00s
2024-12-27 21:03:07,812 - INFO - Training set processing completed in 0.00s
2024-12-27 21:03:07,812 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 21:03:07,813 - INFO - Memory usage at start_fit: CPU 3115.7 MB, GPU 49.3 MB
2024-12-27 21:03:07,813 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:03:07,878 - INFO - Fitted scaler and transformed data
2024-12-27 21:03:07,878 - INFO - Scaling time: 0.07s
2024-12-27 21:03:07,889 - INFO - Number of unique classes: 10
2024-12-27 21:03:10,647 - INFO - Epoch 1/15, Train Loss: 2.2965, Val Loss: 2.2894
2024-12-27 21:03:14,297 - INFO - Epoch 2/15, Train Loss: 2.2802, Val Loss: 2.2739
2024-12-27 21:03:17,238 - INFO - Epoch 3/15, Train Loss: 2.2617, Val Loss: 2.2558
2024-12-27 21:03:20,235 - INFO - Epoch 4/15, Train Loss: 2.2403, Val Loss: 2.2346
2024-12-27 21:03:22,823 - INFO - Epoch 5/15, Train Loss: 2.2155, Val Loss: 2.2108
2024-12-27 21:03:25,941 - INFO - Epoch 6/15, Train Loss: 2.1883, Val Loss: 2.1851
2024-12-27 21:03:29,339 - INFO - Epoch 7/15, Train Loss: 2.1600, Val Loss: 2.1590
2024-12-27 21:03:32,953 - INFO - Epoch 8/15, Train Loss: 2.1319, Val Loss: 2.1344
2024-12-27 21:03:35,970 - INFO - Epoch 9/15, Train Loss: 2.1055, Val Loss: 2.1121
2024-12-27 21:03:39,237 - INFO - Epoch 10/15, Train Loss: 2.0825, Val Loss: 2.0926
2024-12-27 21:03:42,291 - INFO - Epoch 11/15, Train Loss: 2.0616, Val Loss: 2.0757
2024-12-27 21:03:45,278 - INFO - Epoch 12/15, Train Loss: 2.0440, Val Loss: 2.0614
2024-12-27 21:03:48,604 - INFO - Epoch 13/15, Train Loss: 2.0290, Val Loss: 2.0492
2024-12-27 21:03:51,386 - INFO - Epoch 14/15, Train Loss: 2.0160, Val Loss: 2.0388
2024-12-27 21:03:54,162 - INFO - Epoch 15/15, Train Loss: 2.0045, Val Loss: 2.0299
2024-12-27 21:03:54,162 - INFO - Training completed in 46.35s
2024-12-27 21:03:54,162 - INFO - Final memory usage: CPU 3115.7 MB, GPU 75.5 MB
2024-12-27 21:03:54,163 - INFO - Model training completed in 46.35s
2024-12-27 21:03:54,270 - INFO - Prediction completed in 0.11s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 21:03:54,279 - INFO - Poison rate 0.2 completed in 46.47s
2024-12-27 21:03:54,279 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 21:03:54,279 - INFO - Total evaluation time: 351.00s
2024-12-27 21:03:54,281 - INFO - 
Progress: 89.6% - Evaluating ImageNette with RandomForest (dynadetect mode, iteration 1/1)
2024-12-27 21:03:54,342 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 21:03:54,703 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 21:03:54,808 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 21:03:54,809 - INFO - Dataset type: image
2024-12-27 21:03:54,809 - INFO - Sample size: 5000
2024-12-27 21:03:54,809 - INFO - Using device: cuda
2024-12-27 21:03:54,813 - INFO - Loading datasets...
2024-12-27 21:03:54,838 - INFO - Dataset loading completed in 0.02s
2024-12-27 21:03:54,838 - INFO - Extracting validation features...
2024-12-27 21:03:54,838 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:23,  1.34it/s]Extracting features:  19%|█▉        | 6/32 [00:00<00:02,  8.88it/s]Extracting features:  31%|███▏      | 10/32 [00:01<00:01, 12.82it/s]Extracting features:  41%|████      | 13/32 [00:01<00:01, 11.62it/s]Extracting features:  47%|████▋     | 15/32 [00:01<00:01, 12.51it/s]Extracting features:  53%|█████▎    | 17/32 [00:01<00:01, 12.43it/s]Extracting features:  59%|█████▉    | 19/32 [00:01<00:01, 12.90it/s]Extracting features:  66%|██████▌   | 21/32 [00:02<00:01, 10.23it/s]Extracting features:  72%|███████▏  | 23/32 [00:02<00:00, 11.39it/s]Extracting features:  78%|███████▊  | 25/32 [00:02<00:00, 12.14it/s]Extracting features:  91%|█████████ | 29/32 [00:02<00:00, 12.00it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 11.47it/s]
2024-12-27 21:03:57,633 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 21:03:57,633 - INFO - Validation feature extraction completed in 2.80s
2024-12-27 21:03:57,633 - INFO - Extracting training features...
2024-12-27 21:03:57,633 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:20,  1.94it/s]Extracting features:   2%|▏         | 3/157 [00:00<00:41,  3.70it/s]Extracting features:   4%|▍         | 7/157 [00:01<00:19,  7.69it/s]Extracting features:   7%|▋         | 11/157 [00:01<00:15,  9.50it/s]Extracting features:  10%|▉         | 15/157 [00:01<00:13, 10.57it/s]Extracting features:  11%|█         | 17/157 [00:01<00:12, 11.34it/s]Extracting features:  13%|█▎        | 20/157 [00:02<00:11, 12.35it/s]Extracting features:  15%|█▍        | 23/157 [00:02<00:10, 13.13it/s]Extracting features:  16%|█▌        | 25/157 [00:02<00:09, 14.26it/s]Extracting features:  17%|█▋        | 27/157 [00:02<00:08, 14.67it/s]Extracting features:  18%|█▊        | 29/157 [00:02<00:08, 14.36it/s]Extracting features:  20%|██        | 32/157 [00:02<00:08, 14.23it/s]Extracting features:  23%|██▎       | 36/157 [00:03<00:07, 16.32it/s]Extracting features:  25%|██▌       | 40/157 [00:03<00:07, 15.21it/s]Extracting features:  28%|██▊       | 44/157 [00:03<00:06, 16.51it/s]Extracting features:  31%|███       | 48/157 [00:03<00:06, 17.79it/s]Extracting features:  33%|███▎      | 52/157 [00:03<00:05, 17.78it/s]Extracting features:  36%|███▌      | 56/157 [00:04<00:05, 17.03it/s]Extracting features:  38%|███▊      | 60/157 [00:04<00:05, 17.62it/s]Extracting features:  41%|████      | 64/157 [00:04<00:05, 16.94it/s]Extracting features:  43%|████▎     | 67/157 [00:04<00:04, 18.26it/s]Extracting features:  44%|████▍     | 69/157 [00:05<00:05, 16.75it/s]Extracting features:  45%|████▌     | 71/157 [00:05<00:05, 16.63it/s]Extracting features:  46%|████▋     | 73/157 [00:05<00:05, 15.30it/s]Extracting features:  48%|████▊     | 76/157 [00:05<00:06, 12.74it/s]Extracting features:  51%|█████     | 80/157 [00:05<00:05, 13.73it/s]Extracting features:  53%|█████▎    | 83/157 [00:06<00:05, 13.09it/s]Extracting features:  55%|█████▌    | 87/157 [00:06<00:05, 13.15it/s]Extracting features:  58%|█████▊    | 91/157 [00:06<00:04, 13.80it/s]Extracting features:  61%|██████    | 95/157 [00:06<00:04, 14.25it/s]Extracting features:  63%|██████▎   | 99/157 [00:07<00:04, 14.00it/s]Extracting features:  66%|██████▌   | 103/157 [00:07<00:04, 12.38it/s]Extracting features:  68%|██████▊   | 107/157 [00:07<00:04, 12.22it/s]Extracting features:  71%|███████   | 111/157 [00:08<00:03, 12.70it/s]Extracting features:  73%|███████▎  | 115/157 [00:08<00:03, 12.97it/s]Extracting features:  75%|███████▍  | 117/157 [00:08<00:03, 12.90it/s]Extracting features:  76%|███████▌  | 119/157 [00:08<00:03, 11.57it/s]Extracting features:  78%|███████▊  | 123/157 [00:09<00:02, 12.26it/s]Extracting features:  81%|████████  | 127/157 [00:09<00:02, 13.32it/s]Extracting features:  83%|████████▎ | 131/157 [00:09<00:01, 14.10it/s]Extracting features:  86%|████████▌ | 135/157 [00:09<00:01, 15.57it/s]Extracting features:  89%|████████▊ | 139/157 [00:10<00:01, 15.85it/s]Extracting features:  91%|█████████ | 143/157 [00:10<00:00, 16.50it/s]Extracting features:  94%|█████████▎| 147/157 [00:10<00:00, 15.97it/s]Extracting features:  95%|█████████▍| 149/157 [00:10<00:00, 15.48it/s]Extracting features:  97%|█████████▋| 152/157 [00:11<00:00, 15.56it/s]Extracting features:  99%|█████████▉| 156/157 [00:11<00:00, 16.86it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 13.89it/s]
2024-12-27 21:04:08,945 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 21:04:08,946 - INFO - Training feature extraction completed in 11.31s
2024-12-27 21:04:08,946 - INFO - Creating model for classifier: RandomForest
2024-12-27 21:04:08,946 - INFO - Using device: cuda
2024-12-27 21:04:08,946 - INFO - 
Processing poison rate: 0.0
2024-12-27 21:04:08,946 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:04:08,946 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:04:09,487 - INFO - Feature scaling completed in 0.54s
2024-12-27 21:04:09,487 - INFO - Starting feature selection (k=50)
2024-12-27 21:04:09,494 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:04:09,494 - INFO - Starting anomaly detection
2024-12-27 21:04:11,542 - INFO - Anomaly detection completed in 2.05s
2024-12-27 21:04:11,542 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:04:11,542 - INFO - Total fit_transform time: 2.60s
2024-12-27 21:04:11,542 - INFO - Training set processing completed in 2.60s
2024-12-27 21:04:11,543 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 21:04:11,544 - INFO - Memory usage at start_fit: CPU 3113.0 MB, GPU 47.3 MB
2024-12-27 21:04:11,544 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:04:11,621 - INFO - Fitted scaler and transformed data
2024-12-27 21:04:11,622 - INFO - Scaling time: 0.08s
2024-12-27 21:04:11,626 - INFO - Number of unique classes: 10
2024-12-27 21:04:15,712 - INFO - Epoch 1/15, Train Loss: 2.1799, Val Loss: 2.2899
2024-12-27 21:04:18,929 - INFO - Epoch 2/15, Train Loss: 2.1647, Val Loss: 2.2750
2024-12-27 21:04:21,775 - INFO - Epoch 3/15, Train Loss: 2.1474, Val Loss: 2.2575
2024-12-27 21:04:24,495 - INFO - Epoch 4/15, Train Loss: 2.1274, Val Loss: 2.2368
2024-12-27 21:04:27,353 - INFO - Epoch 5/15, Train Loss: 2.1040, Val Loss: 2.2134
2024-12-27 21:04:30,289 - INFO - Epoch 6/15, Train Loss: 2.0784, Val Loss: 2.1881
2024-12-27 21:04:32,796 - INFO - Epoch 7/15, Train Loss: 2.0512, Val Loss: 2.1626
2024-12-27 21:04:35,575 - INFO - Epoch 8/15, Train Loss: 2.0248, Val Loss: 2.1382
2024-12-27 21:04:38,516 - INFO - Epoch 9/15, Train Loss: 2.0001, Val Loss: 2.1163
2024-12-27 21:04:41,799 - INFO - Epoch 10/15, Train Loss: 1.9780, Val Loss: 2.0972
2024-12-27 21:04:44,931 - INFO - Epoch 11/15, Train Loss: 1.9590, Val Loss: 2.0808
2024-12-27 21:04:47,963 - INFO - Epoch 12/15, Train Loss: 1.9425, Val Loss: 2.0668
2024-12-27 21:04:51,047 - INFO - Epoch 13/15, Train Loss: 1.9284, Val Loss: 2.0549
2024-12-27 21:04:54,593 - INFO - Epoch 14/15, Train Loss: 1.9162, Val Loss: 2.0447
2024-12-27 21:04:57,214 - INFO - Epoch 15/15, Train Loss: 1.9057, Val Loss: 2.0359
2024-12-27 21:04:57,214 - INFO - Training completed in 45.67s
2024-12-27 21:04:57,215 - INFO - Final memory usage: CPU 3113.0 MB, GPU 75.5 MB
2024-12-27 21:04:57,215 - INFO - Model training completed in 45.67s
2024-12-27 21:04:57,385 - INFO - Prediction completed in 0.17s
2024-12-27 21:04:57,393 - INFO - Poison rate 0.0 completed in 48.45s
2024-12-27 21:04:57,394 - INFO - 
Processing poison rate: 0.01
2024-12-27 21:04:57,394 - INFO - Label flipping details:
2024-12-27 21:04:57,394 - INFO - - Source class: 1
2024-12-27 21:04:57,394 - INFO - - Target class: 0
2024-12-27 21:04:57,394 - INFO - - Available samples in source class: 500
2024-12-27 21:04:57,394 - INFO - - Requested samples to poison: 50
2024-12-27 21:04:57,394 - INFO - - Actual samples to flip: 50
2024-12-27 21:04:57,394 - INFO - - Samples remaining in source class: 450
2024-12-27 21:04:57,394 - INFO - Successfully flipped 50 labels from class 1 to 0
2024-12-27 21:04:57,394 - INFO - Total number of labels flipped: 50
2024-12-27 21:04:57,394 - INFO - Label flipping completed in 0.00s
2024-12-27 21:04:57,395 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:04:57,395 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:04:57,994 - INFO - Feature scaling completed in 0.60s
2024-12-27 21:04:57,994 - INFO - Starting feature selection (k=50)
2024-12-27 21:04:58,007 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:04:58,007 - INFO - Starting anomaly detection
2024-12-27 21:04:59,847 - INFO - Anomaly detection completed in 1.84s
2024-12-27 21:04:59,847 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:04:59,847 - INFO - Total fit_transform time: 2.45s
2024-12-27 21:04:59,847 - INFO - Training set processing completed in 2.45s
2024-12-27 21:04:59,847 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 21:04:59,849 - INFO - Memory usage at start_fit: CPU 3113.0 MB, GPU 49.3 MB
2024-12-27 21:04:59,849 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:04:59,918 - INFO - Fitted scaler and transformed data
2024-12-27 21:04:59,918 - INFO - Scaling time: 0.07s
2024-12-27 21:04:59,924 - INFO - Number of unique classes: 10
2024-12-27 21:05:03,358 - INFO - Epoch 1/15, Train Loss: 2.1799, Val Loss: 2.2905
2024-12-27 21:05:06,857 - INFO - Epoch 2/15, Train Loss: 2.1652, Val Loss: 2.2763
2024-12-27 21:05:09,723 - INFO - Epoch 3/15, Train Loss: 2.1484, Val Loss: 2.2594
2024-12-27 21:05:13,049 - INFO - Epoch 4/15, Train Loss: 2.1287, Val Loss: 2.2398
2024-12-27 21:05:16,030 - INFO - Epoch 5/15, Train Loss: 2.1064, Val Loss: 2.2173
2024-12-27 21:05:19,152 - INFO - Epoch 6/15, Train Loss: 2.0812, Val Loss: 2.1930
2024-12-27 21:05:21,809 - INFO - Epoch 7/15, Train Loss: 2.0552, Val Loss: 2.1683
2024-12-27 21:05:25,512 - INFO - Epoch 8/15, Train Loss: 2.0289, Val Loss: 2.1448
2024-12-27 21:05:28,679 - INFO - Epoch 9/15, Train Loss: 2.0052, Val Loss: 2.1233
2024-12-27 21:05:32,394 - INFO - Epoch 10/15, Train Loss: 1.9838, Val Loss: 2.1047
2024-12-27 21:05:35,768 - INFO - Epoch 11/15, Train Loss: 1.9645, Val Loss: 2.0886
2024-12-27 21:05:38,334 - INFO - Epoch 12/15, Train Loss: 1.9479, Val Loss: 2.0749
2024-12-27 21:05:41,337 - INFO - Epoch 13/15, Train Loss: 1.9341, Val Loss: 2.0632
2024-12-27 21:05:44,522 - INFO - Epoch 14/15, Train Loss: 1.9223, Val Loss: 2.0531
2024-12-27 21:05:47,040 - INFO - Epoch 15/15, Train Loss: 1.9116, Val Loss: 2.0445
2024-12-27 21:05:47,040 - INFO - Training completed in 47.19s
2024-12-27 21:05:47,040 - INFO - Final memory usage: CPU 3113.0 MB, GPU 75.5 MB
2024-12-27 21:05:47,040 - INFO - Model training completed in 47.19s
2024-12-27 21:05:47,138 - INFO - Prediction completed in 0.10s
2024-12-27 21:05:47,146 - INFO - Poison rate 0.01 completed in 49.75s
2024-12-27 21:05:47,146 - INFO - 
Processing poison rate: 0.03
2024-12-27 21:05:47,146 - INFO - Label flipping details:
2024-12-27 21:05:47,146 - INFO - - Source class: 1
2024-12-27 21:05:47,146 - INFO - - Target class: 0
2024-12-27 21:05:47,146 - INFO - - Available samples in source class: 500
2024-12-27 21:05:47,146 - INFO - - Requested samples to poison: 150
2024-12-27 21:05:47,146 - INFO - - Actual samples to flip: 150
2024-12-27 21:05:47,146 - INFO - - Samples remaining in source class: 350
2024-12-27 21:05:47,147 - INFO - Successfully flipped 150 labels from class 1 to 0
2024-12-27 21:05:47,147 - INFO - Total number of labels flipped: 150
2024-12-27 21:05:47,147 - INFO - Label flipping completed in 0.00s
2024-12-27 21:05:47,147 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:05:47,147 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:05:47,701 - INFO - Feature scaling completed in 0.55s
2024-12-27 21:05:47,702 - INFO - Starting feature selection (k=50)
2024-12-27 21:05:47,714 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:05:47,714 - INFO - Starting anomaly detection
2024-12-27 21:05:49,054 - INFO - Anomaly detection completed in 1.34s
2024-12-27 21:05:49,055 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:05:49,055 - INFO - Total fit_transform time: 1.91s
2024-12-27 21:05:49,055 - INFO - Training set processing completed in 1.91s
2024-12-27 21:05:49,055 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 21:05:49,056 - INFO - Memory usage at start_fit: CPU 3113.0 MB, GPU 49.3 MB
2024-12-27 21:05:49,056 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:05:49,125 - INFO - Fitted scaler and transformed data
2024-12-27 21:05:49,126 - INFO - Scaling time: 0.07s
2024-12-27 21:05:49,133 - INFO - Number of unique classes: 10
2024-12-27 21:05:53,144 - INFO - Epoch 1/15, Train Loss: 2.1841, Val Loss: 2.2908
2024-12-27 21:05:55,953 - INFO - Epoch 2/15, Train Loss: 2.1696, Val Loss: 2.2770
2024-12-27 21:05:59,242 - INFO - Epoch 3/15, Train Loss: 2.1531, Val Loss: 2.2609
2024-12-27 21:06:02,403 - INFO - Epoch 4/15, Train Loss: 2.1342, Val Loss: 2.2420
2024-12-27 21:06:05,430 - INFO - Epoch 5/15, Train Loss: 2.1124, Val Loss: 2.2207
2024-12-27 21:06:08,338 - INFO - Epoch 6/15, Train Loss: 2.0886, Val Loss: 2.1978
2024-12-27 21:06:11,112 - INFO - Epoch 7/15, Train Loss: 2.0634, Val Loss: 2.1747
2024-12-27 21:06:14,255 - INFO - Epoch 8/15, Train Loss: 2.0385, Val Loss: 2.1526
2024-12-27 21:06:17,302 - INFO - Epoch 9/15, Train Loss: 2.0152, Val Loss: 2.1327
2024-12-27 21:06:20,758 - INFO - Epoch 10/15, Train Loss: 1.9949, Val Loss: 2.1152
2024-12-27 21:06:23,775 - INFO - Epoch 11/15, Train Loss: 1.9761, Val Loss: 2.1002
2024-12-27 21:06:26,793 - INFO - Epoch 12/15, Train Loss: 1.9605, Val Loss: 2.0874
2024-12-27 21:06:29,946 - INFO - Epoch 13/15, Train Loss: 1.9468, Val Loss: 2.0765
2024-12-27 21:06:32,894 - INFO - Epoch 14/15, Train Loss: 1.9348, Val Loss: 2.0671
2024-12-27 21:06:35,620 - INFO - Epoch 15/15, Train Loss: 1.9249, Val Loss: 2.0590
2024-12-27 21:06:35,620 - INFO - Training completed in 46.56s
2024-12-27 21:06:35,621 - INFO - Final memory usage: CPU 3113.0 MB, GPU 75.5 MB
2024-12-27 21:06:35,621 - INFO - Model training completed in 46.57s
2024-12-27 21:06:35,721 - INFO - Prediction completed in 0.10s
2024-12-27 21:06:35,728 - INFO - Poison rate 0.03 completed in 48.58s
2024-12-27 21:06:35,729 - INFO - 
Processing poison rate: 0.05
2024-12-27 21:06:35,729 - INFO - Label flipping details:
2024-12-27 21:06:35,729 - INFO - - Source class: 1
2024-12-27 21:06:35,729 - INFO - - Target class: 0
2024-12-27 21:06:35,729 - INFO - - Available samples in source class: 500
2024-12-27 21:06:35,729 - INFO - - Requested samples to poison: 250
2024-12-27 21:06:35,729 - INFO - - Actual samples to flip: 250
2024-12-27 21:06:35,729 - INFO - - Samples remaining in source class: 250
2024-12-27 21:06:35,729 - INFO - Successfully flipped 250 labels from class 1 to 0
2024-12-27 21:06:35,729 - INFO - Total number of labels flipped: 250
2024-12-27 21:06:35,730 - INFO - Label flipping completed in 0.00s
2024-12-27 21:06:35,730 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:06:35,730 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:06:36,334 - INFO - Feature scaling completed in 0.60s
2024-12-27 21:06:36,335 - INFO - Starting feature selection (k=50)
2024-12-27 21:06:36,346 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:06:36,346 - INFO - Starting anomaly detection
2024-12-27 21:06:38,600 - INFO - Anomaly detection completed in 2.25s
2024-12-27 21:06:38,600 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:06:38,600 - INFO - Total fit_transform time: 2.87s
2024-12-27 21:06:38,600 - INFO - Training set processing completed in 2.87s
2024-12-27 21:06:38,600 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 21:06:38,601 - INFO - Memory usage at start_fit: CPU 3113.0 MB, GPU 49.3 MB
2024-12-27 21:06:38,602 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:06:38,680 - INFO - Fitted scaler and transformed data
2024-12-27 21:06:38,680 - INFO - Scaling time: 0.08s
2024-12-27 21:06:38,689 - INFO - Number of unique classes: 10
2024-12-27 21:06:41,605 - INFO - Epoch 1/15, Train Loss: 2.1796, Val Loss: 2.2898
2024-12-27 21:06:44,742 - INFO - Epoch 2/15, Train Loss: 2.1652, Val Loss: 2.2748
2024-12-27 21:06:47,246 - INFO - Epoch 3/15, Train Loss: 2.1490, Val Loss: 2.2573
2024-12-27 21:06:49,851 - INFO - Epoch 4/15, Train Loss: 2.1302, Val Loss: 2.2370
2024-12-27 21:06:52,831 - INFO - Epoch 5/15, Train Loss: 2.1090, Val Loss: 2.2142
2024-12-27 21:06:56,156 - INFO - Epoch 6/15, Train Loss: 2.0854, Val Loss: 2.1895
2024-12-27 21:06:59,358 - INFO - Epoch 7/15, Train Loss: 2.0611, Val Loss: 2.1646
2024-12-27 21:07:02,406 - INFO - Epoch 8/15, Train Loss: 2.0370, Val Loss: 2.1409
2024-12-27 21:07:05,747 - INFO - Epoch 9/15, Train Loss: 2.0142, Val Loss: 2.1195
2024-12-27 21:07:08,786 - INFO - Epoch 10/15, Train Loss: 1.9941, Val Loss: 2.1009
2024-12-27 21:07:12,018 - INFO - Epoch 11/15, Train Loss: 1.9758, Val Loss: 2.0848
2024-12-27 21:07:14,702 - INFO - Epoch 12/15, Train Loss: 1.9603, Val Loss: 2.0711
2024-12-27 21:07:17,485 - INFO - Epoch 13/15, Train Loss: 1.9470, Val Loss: 2.0595
2024-12-27 21:07:20,250 - INFO - Epoch 14/15, Train Loss: 1.9355, Val Loss: 2.0496
2024-12-27 21:07:23,249 - INFO - Epoch 15/15, Train Loss: 1.9249, Val Loss: 2.0411
2024-12-27 21:07:23,249 - INFO - Training completed in 44.65s
2024-12-27 21:07:23,250 - INFO - Final memory usage: CPU 3113.0 MB, GPU 75.5 MB
2024-12-27 21:07:23,250 - INFO - Model training completed in 44.65s
2024-12-27 21:07:23,364 - INFO - Prediction completed in 0.11s
2024-12-27 21:07:23,372 - INFO - Poison rate 0.05 completed in 47.64s
2024-12-27 21:07:23,372 - INFO - 
Processing poison rate: 0.07
2024-12-27 21:07:23,372 - INFO - Label flipping details:
2024-12-27 21:07:23,372 - INFO - - Source class: 1
2024-12-27 21:07:23,373 - INFO - - Target class: 0
2024-12-27 21:07:23,373 - INFO - - Available samples in source class: 500
2024-12-27 21:07:23,373 - INFO - - Requested samples to poison: 350
2024-12-27 21:07:23,373 - INFO - - Actual samples to flip: 350
2024-12-27 21:07:23,373 - INFO - - Samples remaining in source class: 150
2024-12-27 21:07:23,373 - INFO - Successfully flipped 350 labels from class 1 to 0
2024-12-27 21:07:23,373 - INFO - Total number of labels flipped: 350
2024-12-27 21:07:23,373 - INFO - Label flipping completed in 0.00s
2024-12-27 21:07:23,373 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:07:23,373 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:07:23,981 - INFO - Feature scaling completed in 0.61s
2024-12-27 21:07:23,982 - INFO - Starting feature selection (k=50)
2024-12-27 21:07:23,994 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:07:23,994 - INFO - Starting anomaly detection
2024-12-27 21:07:26,141 - INFO - Anomaly detection completed in 2.15s
2024-12-27 21:07:26,141 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:07:26,141 - INFO - Total fit_transform time: 2.77s
2024-12-27 21:07:26,141 - INFO - Training set processing completed in 2.77s
2024-12-27 21:07:26,141 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 21:07:26,142 - INFO - Memory usage at start_fit: CPU 3113.0 MB, GPU 49.3 MB
2024-12-27 21:07:26,142 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:07:26,207 - INFO - Fitted scaler and transformed data
2024-12-27 21:07:26,207 - INFO - Scaling time: 0.06s
2024-12-27 21:07:26,217 - INFO - Number of unique classes: 10
2024-12-27 21:07:29,098 - INFO - Epoch 1/15, Train Loss: 2.1829, Val Loss: 2.2897
2024-12-27 21:07:32,368 - INFO - Epoch 2/15, Train Loss: 2.1681, Val Loss: 2.2746
2024-12-27 21:07:35,792 - INFO - Epoch 3/15, Train Loss: 2.1512, Val Loss: 2.2568
2024-12-27 21:07:38,762 - INFO - Epoch 4/15, Train Loss: 2.1316, Val Loss: 2.2361
2024-12-27 21:07:41,693 - INFO - Epoch 5/15, Train Loss: 2.1094, Val Loss: 2.2125
2024-12-27 21:07:44,519 - INFO - Epoch 6/15, Train Loss: 2.0846, Val Loss: 2.1871
2024-12-27 21:07:47,183 - INFO - Epoch 7/15, Train Loss: 2.0584, Val Loss: 2.1612
2024-12-27 21:07:50,523 - INFO - Epoch 8/15, Train Loss: 2.0333, Val Loss: 2.1363
2024-12-27 21:07:54,480 - INFO - Epoch 9/15, Train Loss: 2.0090, Val Loss: 2.1138
2024-12-27 21:07:57,688 - INFO - Epoch 10/15, Train Loss: 1.9880, Val Loss: 2.0939
2024-12-27 21:08:01,043 - INFO - Epoch 11/15, Train Loss: 1.9695, Val Loss: 2.0768
2024-12-27 21:08:04,151 - INFO - Epoch 12/15, Train Loss: 1.9528, Val Loss: 2.0622
2024-12-27 21:08:07,141 - INFO - Epoch 13/15, Train Loss: 1.9388, Val Loss: 2.0498
2024-12-27 21:08:10,062 - INFO - Epoch 14/15, Train Loss: 1.9266, Val Loss: 2.0391
2024-12-27 21:08:12,951 - INFO - Epoch 15/15, Train Loss: 1.9162, Val Loss: 2.0299
2024-12-27 21:08:12,951 - INFO - Training completed in 46.81s
2024-12-27 21:08:12,951 - INFO - Final memory usage: CPU 3113.0 MB, GPU 75.5 MB
2024-12-27 21:08:12,952 - INFO - Model training completed in 46.81s
2024-12-27 21:08:13,183 - INFO - Prediction completed in 0.23s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 21:08:13,193 - INFO - Poison rate 0.07 completed in 49.82s
2024-12-27 21:08:13,194 - INFO - 
Processing poison rate: 0.1
2024-12-27 21:08:13,194 - INFO - Label flipping details:
2024-12-27 21:08:13,194 - INFO - - Source class: 1
2024-12-27 21:08:13,194 - INFO - - Target class: 0
2024-12-27 21:08:13,194 - INFO - - Available samples in source class: 500
2024-12-27 21:08:13,194 - INFO - - Requested samples to poison: 500
2024-12-27 21:08:13,194 - INFO - - Actual samples to flip: 499
2024-12-27 21:08:13,194 - INFO - - Samples remaining in source class: 1
2024-12-27 21:08:13,194 - INFO - Successfully flipped 499 labels from class 1 to 0
2024-12-27 21:08:13,194 - INFO - Total number of labels flipped: 499
2024-12-27 21:08:13,195 - INFO - Label flipping completed in 0.00s
2024-12-27 21:08:13,195 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:08:13,195 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:08:13,748 - INFO - Feature scaling completed in 0.55s
2024-12-27 21:08:13,748 - INFO - Starting feature selection (k=50)
2024-12-27 21:08:13,760 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:08:13,760 - INFO - Starting anomaly detection
2024-12-27 21:08:15,994 - INFO - Anomaly detection completed in 2.23s
2024-12-27 21:08:15,995 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:08:15,995 - INFO - Total fit_transform time: 2.80s
2024-12-27 21:08:15,995 - INFO - Training set processing completed in 2.80s
2024-12-27 21:08:15,995 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 21:08:15,997 - INFO - Memory usage at start_fit: CPU 3113.0 MB, GPU 49.3 MB
2024-12-27 21:08:15,997 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:08:16,076 - INFO - Fitted scaler and transformed data
2024-12-27 21:08:16,076 - INFO - Scaling time: 0.08s
2024-12-27 21:08:16,083 - INFO - Number of unique classes: 10
2024-12-27 21:08:19,249 - INFO - Epoch 1/15, Train Loss: 2.1793, Val Loss: 2.2896
2024-12-27 21:08:22,728 - INFO - Epoch 2/15, Train Loss: 2.1636, Val Loss: 2.2744
2024-12-27 21:08:26,166 - INFO - Epoch 3/15, Train Loss: 2.1459, Val Loss: 2.2565
2024-12-27 21:08:29,627 - INFO - Epoch 4/15, Train Loss: 2.1251, Val Loss: 2.2357
2024-12-27 21:08:32,948 - INFO - Epoch 5/15, Train Loss: 2.1011, Val Loss: 2.2121
2024-12-27 21:08:36,045 - INFO - Epoch 6/15, Train Loss: 2.0748, Val Loss: 2.1866
2024-12-27 21:08:39,996 - INFO - Epoch 7/15, Train Loss: 2.0470, Val Loss: 2.1610
2024-12-27 21:08:43,601 - INFO - Epoch 8/15, Train Loss: 2.0200, Val Loss: 2.1368
2024-12-27 21:08:47,171 - INFO - Epoch 9/15, Train Loss: 1.9945, Val Loss: 2.1148
2024-12-27 21:08:51,024 - INFO - Epoch 10/15, Train Loss: 1.9722, Val Loss: 2.0957
2024-12-27 21:08:54,721 - INFO - Epoch 11/15, Train Loss: 1.9525, Val Loss: 2.0793
2024-12-27 21:08:57,643 - INFO - Epoch 12/15, Train Loss: 1.9357, Val Loss: 2.0652
2024-12-27 21:09:00,744 - INFO - Epoch 13/15, Train Loss: 1.9211, Val Loss: 2.0532
2024-12-27 21:09:03,390 - INFO - Epoch 14/15, Train Loss: 1.9083, Val Loss: 2.0430
2024-12-27 21:09:07,141 - INFO - Epoch 15/15, Train Loss: 1.8985, Val Loss: 2.0342
2024-12-27 21:09:07,142 - INFO - Training completed in 51.15s
2024-12-27 21:09:07,142 - INFO - Final memory usage: CPU 3113.0 MB, GPU 75.5 MB
2024-12-27 21:09:07,142 - INFO - Model training completed in 51.15s
2024-12-27 21:09:07,249 - INFO - Prediction completed in 0.11s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 21:09:07,258 - INFO - Poison rate 0.1 completed in 54.06s
2024-12-27 21:09:07,258 - INFO - 
Processing poison rate: 0.2
2024-12-27 21:09:07,258 - INFO - Label flipping details:
2024-12-27 21:09:07,258 - INFO - - Source class: 1
2024-12-27 21:09:07,258 - INFO - - Target class: 0
2024-12-27 21:09:07,258 - INFO - - Available samples in source class: 500
2024-12-27 21:09:07,258 - INFO - - Requested samples to poison: 1000
2024-12-27 21:09:07,258 - INFO - - Actual samples to flip: 499
2024-12-27 21:09:07,258 - INFO - - Samples remaining in source class: 1
2024-12-27 21:09:07,258 - INFO - Successfully flipped 499 labels from class 1 to 0
2024-12-27 21:09:07,259 - INFO - Total number of labels flipped: 499
2024-12-27 21:09:07,259 - INFO - Label flipping completed in 0.00s
2024-12-27 21:09:07,259 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:09:07,259 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:09:07,906 - INFO - Feature scaling completed in 0.65s
2024-12-27 21:09:07,906 - INFO - Starting feature selection (k=50)
2024-12-27 21:09:07,918 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:09:07,918 - INFO - Starting anomaly detection
2024-12-27 21:09:10,193 - INFO - Anomaly detection completed in 2.27s
2024-12-27 21:09:10,193 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:09:10,193 - INFO - Total fit_transform time: 2.93s
2024-12-27 21:09:10,193 - INFO - Training set processing completed in 2.93s
2024-12-27 21:09:10,193 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 21:09:10,194 - INFO - Memory usage at start_fit: CPU 3113.0 MB, GPU 49.3 MB
2024-12-27 21:09:10,194 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:09:10,284 - INFO - Fitted scaler and transformed data
2024-12-27 21:09:10,285 - INFO - Scaling time: 0.09s
2024-12-27 21:09:10,291 - INFO - Number of unique classes: 10
2024-12-27 21:09:12,977 - INFO - Epoch 1/15, Train Loss: 2.1799, Val Loss: 2.2894
2024-12-27 21:09:15,737 - INFO - Epoch 2/15, Train Loss: 2.1643, Val Loss: 2.2741
2024-12-27 21:09:18,664 - INFO - Epoch 3/15, Train Loss: 2.1466, Val Loss: 2.2561
2024-12-27 21:09:21,874 - INFO - Epoch 4/15, Train Loss: 2.1258, Val Loss: 2.2353
2024-12-27 21:09:24,880 - INFO - Epoch 5/15, Train Loss: 2.1021, Val Loss: 2.2116
2024-12-27 21:09:28,355 - INFO - Epoch 6/15, Train Loss: 2.0760, Val Loss: 2.1860
2024-12-27 21:09:31,440 - INFO - Epoch 7/15, Train Loss: 2.0486, Val Loss: 2.1600
2024-12-27 21:09:34,786 - INFO - Epoch 8/15, Train Loss: 2.0215, Val Loss: 2.1353
2024-12-27 21:09:37,534 - INFO - Epoch 9/15, Train Loss: 1.9960, Val Loss: 2.1127
2024-12-27 21:09:40,761 - INFO - Epoch 10/15, Train Loss: 1.9736, Val Loss: 2.0929
2024-12-27 21:09:44,608 - INFO - Epoch 11/15, Train Loss: 1.9541, Val Loss: 2.0759
2024-12-27 21:09:48,083 - INFO - Epoch 12/15, Train Loss: 1.9368, Val Loss: 2.0613
2024-12-27 21:09:51,028 - INFO - Epoch 13/15, Train Loss: 1.9220, Val Loss: 2.0489
2024-12-27 21:09:54,471 - INFO - Epoch 14/15, Train Loss: 1.9101, Val Loss: 2.0383
2024-12-27 21:09:57,842 - INFO - Epoch 15/15, Train Loss: 1.8991, Val Loss: 2.0292
2024-12-27 21:09:57,843 - INFO - Training completed in 47.65s
2024-12-27 21:09:57,843 - INFO - Final memory usage: CPU 3113.0 MB, GPU 75.5 MB
2024-12-27 21:09:57,843 - INFO - Model training completed in 47.65s
2024-12-27 21:09:57,983 - INFO - Prediction completed in 0.14s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 21:09:57,991 - INFO - Poison rate 0.2 completed in 50.73s
2024-12-27 21:09:57,991 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 21:09:57,991 - INFO - Total evaluation time: 363.18s
2024-12-27 21:09:57,993 - INFO - 
Progress: 90.6% - Evaluating ImageNette with KNeighbors (standard mode, iteration 1/1)
2024-12-27 21:09:58,052 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 21:09:58,353 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 21:09:58,442 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 21:09:58,442 - INFO - Dataset type: image
2024-12-27 21:09:58,442 - INFO - Sample size: 5000
2024-12-27 21:09:58,442 - INFO - Using device: cuda
2024-12-27 21:09:58,445 - INFO - Loading datasets...
2024-12-27 21:09:58,633 - INFO - Dataset loading completed in 0.19s
2024-12-27 21:09:58,633 - INFO - Extracting validation features...
2024-12-27 21:09:58,633 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:23,  1.29it/s]Extracting features:   6%|▋         | 2/32 [00:00<00:11,  2.56it/s]Extracting features:  19%|█▉        | 6/32 [00:01<00:02,  9.12it/s]Extracting features:  34%|███▍      | 11/32 [00:01<00:01, 14.16it/s]Extracting features:  44%|████▍     | 14/32 [00:01<00:01, 16.03it/s]Extracting features:  53%|█████▎    | 17/32 [00:01<00:01, 13.77it/s]Extracting features:  59%|█████▉    | 19/32 [00:01<00:01, 11.56it/s]Extracting features:  69%|██████▉   | 22/32 [00:01<00:00, 14.50it/s]Extracting features:  75%|███████▌  | 24/32 [00:02<00:00, 13.18it/s]Extracting features:  81%|████████▏ | 26/32 [00:02<00:00, 13.50it/s]Extracting features:  88%|████████▊ | 28/32 [00:02<00:00, 14.60it/s]Extracting features:  94%|█████████▍| 30/32 [00:02<00:00, 14.86it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 11.80it/s]
2024-12-27 21:10:01,351 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 21:10:01,352 - INFO - Validation feature extraction completed in 2.72s
2024-12-27 21:10:01,352 - INFO - Extracting training features...
2024-12-27 21:10:01,352 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:14,  2.10it/s]Extracting features:   1%|▏         | 2/157 [00:00<00:44,  3.52it/s]Extracting features:   3%|▎         | 5/157 [00:00<00:16,  9.43it/s]Extracting features:   4%|▍         | 7/157 [00:01<00:18,  7.93it/s]Extracting features:   7%|▋         | 11/157 [00:01<00:15,  9.63it/s]Extracting features:  10%|▉         | 15/157 [00:01<00:12, 11.69it/s]Extracting features:  12%|█▏        | 19/157 [00:01<00:10, 12.58it/s]Extracting features:  15%|█▍        | 23/157 [00:02<00:10, 12.91it/s]Extracting features:  17%|█▋        | 27/157 [00:02<00:09, 13.19it/s]Extracting features:  20%|█▉        | 31/157 [00:02<00:09, 13.51it/s]Extracting features:  22%|██▏       | 35/157 [00:02<00:08, 14.82it/s]Extracting features:  25%|██▍       | 39/157 [00:03<00:07, 16.36it/s]Extracting features:  27%|██▋       | 43/157 [00:03<00:06, 17.74it/s]Extracting features:  30%|██▉       | 47/157 [00:03<00:05, 19.01it/s]Extracting features:  32%|███▏      | 51/157 [00:03<00:06, 17.39it/s]Extracting features:  35%|███▌      | 55/157 [00:04<00:05, 17.70it/s]Extracting features:  36%|███▋      | 57/157 [00:04<00:05, 17.19it/s]Extracting features:  38%|███▊      | 60/157 [00:04<00:05, 19.03it/s]Extracting features:  40%|████      | 63/157 [00:04<00:05, 15.69it/s]Extracting features:  41%|████▏     | 65/157 [00:04<00:06, 14.22it/s]Extracting features:  44%|████▍     | 69/157 [00:05<00:06, 13.25it/s]Extracting features:  46%|████▋     | 73/157 [00:05<00:06, 13.82it/s]Extracting features:  49%|████▉     | 77/157 [00:05<00:05, 13.97it/s]Extracting features:  52%|█████▏    | 81/157 [00:05<00:05, 14.28it/s]Extracting features:  54%|█████▍    | 85/157 [00:06<00:04, 14.57it/s]Extracting features:  57%|█████▋    | 89/157 [00:06<00:04, 15.21it/s]Extracting features:  59%|█████▉    | 93/157 [00:06<00:04, 14.86it/s]Extracting features:  61%|██████    | 95/157 [00:06<00:03, 15.54it/s]Extracting features:  62%|██████▏   | 97/157 [00:06<00:04, 14.43it/s]Extracting features:  64%|██████▍   | 101/157 [00:07<00:03, 14.19it/s]Extracting features:  66%|██████▌   | 104/157 [00:07<00:03, 15.05it/s]Extracting features:  68%|██████▊   | 106/157 [00:07<00:04, 11.50it/s]Extracting features:  69%|██████▉   | 109/157 [00:07<00:03, 14.04it/s]Extracting features:  71%|███████   | 111/157 [00:08<00:04, 10.98it/s]Extracting features:  73%|███████▎  | 114/157 [00:08<00:03, 11.10it/s]Extracting features:  75%|███████▌  | 118/157 [00:08<00:03, 12.56it/s]Extracting features:  77%|███████▋  | 121/157 [00:08<00:02, 13.20it/s]Extracting features:  79%|███████▉  | 124/157 [00:09<00:02, 14.79it/s]Extracting features:  80%|████████  | 126/157 [00:09<00:02, 10.74it/s]Extracting features:  82%|████████▏ | 129/157 [00:09<00:02, 12.00it/s]Extracting features:  85%|████████▍ | 133/157 [00:09<00:01, 12.69it/s]Extracting features:  87%|████████▋ | 137/157 [00:10<00:01, 14.51it/s]Extracting features:  90%|████████▉ | 141/157 [00:10<00:01, 15.74it/s]Extracting features:  92%|█████████▏| 145/157 [00:10<00:00, 16.82it/s]Extracting features:  94%|█████████▎| 147/157 [00:10<00:00, 14.95it/s]Extracting features:  96%|█████████▌| 151/157 [00:11<00:00, 13.26it/s]Extracting features:  99%|█████████▊| 155/157 [00:11<00:00, 13.33it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 13.73it/s]
2024-12-27 21:10:12,804 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 21:10:12,804 - INFO - Training feature extraction completed in 11.45s
2024-12-27 21:10:12,804 - INFO - Creating model for classifier: KNeighbors
2024-12-27 21:10:12,804 - INFO - Using device: cuda
2024-12-27 21:10:12,804 - INFO - 
Processing poison rate: 0.0
2024-12-27 21:10:12,804 - INFO - Training set processing completed in 0.00s
2024-12-27 21:10:12,804 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:10:12,806 - INFO - Memory usage at start_fit: CPU 3114.1 MB, GPU 47.3 MB
2024-12-27 21:10:12,807 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:10:12,880 - INFO - Fitted scaler and transformed data
2024-12-27 21:10:12,880 - INFO - Scaling time: 0.07s
2024-12-27 21:10:12,885 - INFO - Training completed in 0.08s
2024-12-27 21:10:12,886 - INFO - Final memory usage: CPU 3114.1 MB, GPU 71.8 MB
2024-12-27 21:10:12,886 - INFO - Model training completed in 0.08s
2024-12-27 21:10:12,903 - INFO - Prediction completed in 0.02s
2024-12-27 21:10:12,911 - INFO - Poison rate 0.0 completed in 0.11s
2024-12-27 21:10:12,911 - INFO - 
Processing poison rate: 0.01
2024-12-27 21:10:12,911 - INFO - Label flipping details:
2024-12-27 21:10:12,912 - INFO - - Source class: 1
2024-12-27 21:10:12,912 - INFO - - Target class: 0
2024-12-27 21:10:12,912 - INFO - - Available samples in source class: 500
2024-12-27 21:10:12,912 - INFO - - Requested samples to poison: 50
2024-12-27 21:10:12,912 - INFO - - Actual samples to flip: 50
2024-12-27 21:10:12,912 - INFO - - Samples remaining in source class: 450
2024-12-27 21:10:12,912 - INFO - Successfully flipped 50 labels from class 1 to 0
2024-12-27 21:10:12,912 - INFO - Total number of labels flipped: 50
2024-12-27 21:10:12,912 - INFO - Label flipping completed in 0.00s
2024-12-27 21:10:12,912 - INFO - Training set processing completed in 0.00s
2024-12-27 21:10:12,912 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:10:12,914 - INFO - Memory usage at start_fit: CPU 3114.1 MB, GPU 71.8 MB
2024-12-27 21:10:12,914 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:10:12,981 - INFO - Fitted scaler and transformed data
2024-12-27 21:10:12,981 - INFO - Scaling time: 0.07s
2024-12-27 21:10:12,986 - INFO - Training completed in 0.07s
2024-12-27 21:10:12,986 - INFO - Final memory usage: CPU 3114.1 MB, GPU 71.8 MB
2024-12-27 21:10:12,987 - INFO - Model training completed in 0.07s
2024-12-27 21:10:13,001 - INFO - Prediction completed in 0.01s
2024-12-27 21:10:13,008 - INFO - Poison rate 0.01 completed in 0.10s
2024-12-27 21:10:13,009 - INFO - 
Processing poison rate: 0.03
2024-12-27 21:10:13,009 - INFO - Label flipping details:
2024-12-27 21:10:13,009 - INFO - - Source class: 1
2024-12-27 21:10:13,009 - INFO - - Target class: 0
2024-12-27 21:10:13,009 - INFO - - Available samples in source class: 500
2024-12-27 21:10:13,009 - INFO - - Requested samples to poison: 150
2024-12-27 21:10:13,009 - INFO - - Actual samples to flip: 150
2024-12-27 21:10:13,009 - INFO - - Samples remaining in source class: 350
2024-12-27 21:10:13,009 - INFO - Successfully flipped 150 labels from class 1 to 0
2024-12-27 21:10:13,009 - INFO - Total number of labels flipped: 150
2024-12-27 21:10:13,010 - INFO - Label flipping completed in 0.00s
2024-12-27 21:10:13,010 - INFO - Training set processing completed in 0.00s
2024-12-27 21:10:13,010 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:10:13,011 - INFO - Memory usage at start_fit: CPU 3114.1 MB, GPU 71.8 MB
2024-12-27 21:10:13,011 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:10:13,088 - INFO - Fitted scaler and transformed data
2024-12-27 21:10:13,088 - INFO - Scaling time: 0.08s
2024-12-27 21:10:13,094 - INFO - Training completed in 0.08s
2024-12-27 21:10:13,095 - INFO - Final memory usage: CPU 3114.1 MB, GPU 71.8 MB
2024-12-27 21:10:13,095 - INFO - Model training completed in 0.09s
2024-12-27 21:10:13,111 - INFO - Prediction completed in 0.02s
2024-12-27 21:10:13,121 - INFO - Poison rate 0.03 completed in 0.11s
2024-12-27 21:10:13,121 - INFO - 
Processing poison rate: 0.05
2024-12-27 21:10:13,122 - INFO - Label flipping details:
2024-12-27 21:10:13,122 - INFO - - Source class: 1
2024-12-27 21:10:13,122 - INFO - - Target class: 0
2024-12-27 21:10:13,122 - INFO - - Available samples in source class: 500
2024-12-27 21:10:13,122 - INFO - - Requested samples to poison: 250
2024-12-27 21:10:13,122 - INFO - - Actual samples to flip: 250
2024-12-27 21:10:13,122 - INFO - - Samples remaining in source class: 250
2024-12-27 21:10:13,122 - INFO - Successfully flipped 250 labels from class 1 to 0
2024-12-27 21:10:13,122 - INFO - Total number of labels flipped: 250
2024-12-27 21:10:13,122 - INFO - Label flipping completed in 0.00s
2024-12-27 21:10:13,123 - INFO - Training set processing completed in 0.00s
2024-12-27 21:10:13,123 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:10:13,124 - INFO - Memory usage at start_fit: CPU 3114.1 MB, GPU 71.8 MB
2024-12-27 21:10:13,124 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:10:13,185 - INFO - Fitted scaler and transformed data
2024-12-27 21:10:13,185 - INFO - Scaling time: 0.06s
2024-12-27 21:10:13,190 - INFO - Training completed in 0.07s
2024-12-27 21:10:13,191 - INFO - Final memory usage: CPU 3114.1 MB, GPU 71.8 MB
2024-12-27 21:10:13,191 - INFO - Model training completed in 0.07s
2024-12-27 21:10:13,205 - INFO - Prediction completed in 0.01s
2024-12-27 21:10:13,213 - INFO - Poison rate 0.05 completed in 0.09s
2024-12-27 21:10:13,213 - INFO - 
Processing poison rate: 0.07
2024-12-27 21:10:13,213 - INFO - Label flipping details:
2024-12-27 21:10:13,213 - INFO - - Source class: 1
2024-12-27 21:10:13,214 - INFO - - Target class: 0
2024-12-27 21:10:13,214 - INFO - - Available samples in source class: 500
2024-12-27 21:10:13,214 - INFO - - Requested samples to poison: 350
2024-12-27 21:10:13,214 - INFO - - Actual samples to flip: 350
2024-12-27 21:10:13,214 - INFO - - Samples remaining in source class: 150
2024-12-27 21:10:13,214 - INFO - Successfully flipped 350 labels from class 1 to 0
2024-12-27 21:10:13,214 - INFO - Total number of labels flipped: 350
2024-12-27 21:10:13,214 - INFO - Label flipping completed in 0.00s
2024-12-27 21:10:13,214 - INFO - Training set processing completed in 0.00s
2024-12-27 21:10:13,214 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:10:13,215 - INFO - Memory usage at start_fit: CPU 3114.1 MB, GPU 71.8 MB
2024-12-27 21:10:13,215 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:10:13,275 - INFO - Fitted scaler and transformed data
2024-12-27 21:10:13,276 - INFO - Scaling time: 0.06s
2024-12-27 21:10:13,280 - INFO - Training completed in 0.07s
2024-12-27 21:10:13,281 - INFO - Final memory usage: CPU 3114.1 MB, GPU 71.8 MB
2024-12-27 21:10:13,281 - INFO - Model training completed in 0.07s
2024-12-27 21:10:13,294 - INFO - Prediction completed in 0.01s
2024-12-27 21:10:13,302 - INFO - Poison rate 0.07 completed in 0.09s
2024-12-27 21:10:13,302 - INFO - 
Processing poison rate: 0.1
2024-12-27 21:10:13,302 - INFO - Label flipping details:
2024-12-27 21:10:13,302 - INFO - - Source class: 1
2024-12-27 21:10:13,302 - INFO - - Target class: 0
2024-12-27 21:10:13,302 - INFO - - Available samples in source class: 500
2024-12-27 21:10:13,302 - INFO - - Requested samples to poison: 500
2024-12-27 21:10:13,302 - INFO - - Actual samples to flip: 499
2024-12-27 21:10:13,302 - INFO - - Samples remaining in source class: 1
2024-12-27 21:10:13,302 - INFO - Successfully flipped 499 labels from class 1 to 0
2024-12-27 21:10:13,303 - INFO - Total number of labels flipped: 499
2024-12-27 21:10:13,303 - INFO - Label flipping completed in 0.00s
2024-12-27 21:10:13,303 - INFO - Training set processing completed in 0.00s
2024-12-27 21:10:13,303 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:10:13,304 - INFO - Memory usage at start_fit: CPU 3114.1 MB, GPU 71.8 MB
2024-12-27 21:10:13,304 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:10:13,363 - INFO - Fitted scaler and transformed data
2024-12-27 21:10:13,363 - INFO - Scaling time: 0.06s
2024-12-27 21:10:13,368 - INFO - Training completed in 0.06s
2024-12-27 21:10:13,369 - INFO - Final memory usage: CPU 3114.1 MB, GPU 71.8 MB
2024-12-27 21:10:13,369 - INFO - Model training completed in 0.07s
2024-12-27 21:10:13,383 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 21:10:13,391 - INFO - Poison rate 0.1 completed in 0.09s
2024-12-27 21:10:13,391 - INFO - 
Processing poison rate: 0.2
2024-12-27 21:10:13,391 - INFO - Label flipping details:
2024-12-27 21:10:13,391 - INFO - - Source class: 1
2024-12-27 21:10:13,391 - INFO - - Target class: 0
2024-12-27 21:10:13,391 - INFO - - Available samples in source class: 500
2024-12-27 21:10:13,392 - INFO - - Requested samples to poison: 1000
2024-12-27 21:10:13,392 - INFO - - Actual samples to flip: 499
2024-12-27 21:10:13,392 - INFO - - Samples remaining in source class: 1
2024-12-27 21:10:13,392 - INFO - Successfully flipped 499 labels from class 1 to 0
2024-12-27 21:10:13,392 - INFO - Total number of labels flipped: 499
2024-12-27 21:10:13,392 - INFO - Label flipping completed in 0.00s
2024-12-27 21:10:13,392 - INFO - Training set processing completed in 0.00s
2024-12-27 21:10:13,392 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:10:13,393 - INFO - Memory usage at start_fit: CPU 3114.1 MB, GPU 71.8 MB
2024-12-27 21:10:13,393 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:10:13,452 - INFO - Fitted scaler and transformed data
2024-12-27 21:10:13,453 - INFO - Scaling time: 0.06s
2024-12-27 21:10:13,458 - INFO - Training completed in 0.07s
2024-12-27 21:10:13,459 - INFO - Final memory usage: CPU 3114.1 MB, GPU 71.8 MB
2024-12-27 21:10:13,459 - INFO - Model training completed in 0.07s
2024-12-27 21:10:13,473 - INFO - Prediction completed in 0.01s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 21:10:13,481 - INFO - Poison rate 0.2 completed in 0.09s
2024-12-27 21:10:13,481 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 21:10:13,481 - INFO - Total evaluation time: 15.04s
2024-12-27 21:10:13,483 - INFO - 
Progress: 91.7% - Evaluating ImageNette with KNeighbors (dynadetect mode, iteration 1/1)
2024-12-27 21:10:13,544 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 21:10:13,614 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 21:10:13,719 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 21:10:13,719 - INFO - Dataset type: image
2024-12-27 21:10:13,719 - INFO - Sample size: 5000
2024-12-27 21:10:13,719 - INFO - Using device: cuda
2024-12-27 21:10:13,722 - INFO - Loading datasets...
2024-12-27 21:10:13,748 - INFO - Dataset loading completed in 0.03s
2024-12-27 21:10:13,748 - INFO - Extracting validation features...
2024-12-27 21:10:13,748 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:15,  1.96it/s]Extracting features:  16%|█▌        | 5/32 [00:00<00:03,  7.69it/s]Extracting features:  28%|██▊       | 9/32 [00:00<00:01, 12.59it/s]Extracting features:  38%|███▊      | 12/32 [00:01<00:01, 15.45it/s]Extracting features:  47%|████▋     | 15/32 [00:01<00:01, 12.49it/s]Extracting features:  56%|█████▋    | 18/32 [00:01<00:01, 12.35it/s]Extracting features:  69%|██████▉   | 22/32 [00:01<00:00, 12.55it/s]Extracting features:  75%|███████▌  | 24/32 [00:02<00:00, 13.25it/s]Extracting features:  81%|████████▏ | 26/32 [00:02<00:00, 13.84it/s]Extracting features:  91%|█████████ | 29/32 [00:02<00:00, 16.28it/s]Extracting features:  97%|█████████▋| 31/32 [00:02<00:00, 12.15it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 12.06it/s]
2024-12-27 21:10:16,405 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 21:10:16,406 - INFO - Validation feature extraction completed in 2.66s
2024-12-27 21:10:16,406 - INFO - Extracting training features...
2024-12-27 21:10:16,406 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:32,  1.69it/s]Extracting features:   1%|▏         | 2/157 [00:00<00:55,  2.77it/s]Extracting features:   4%|▍         | 6/157 [00:01<00:19,  7.64it/s]Extracting features:   6%|▋         | 10/157 [00:01<00:16,  9.14it/s]Extracting features:   9%|▉         | 14/157 [00:01<00:12, 11.74it/s]Extracting features:  11%|█▏        | 18/157 [00:01<00:10, 13.53it/s]Extracting features:  14%|█▍        | 22/157 [00:02<00:09, 13.54it/s]Extracting features:  17%|█▋        | 26/157 [00:02<00:08, 14.61it/s]Extracting features:  18%|█▊        | 29/157 [00:02<00:07, 16.43it/s]Extracting features:  20%|█▉        | 31/157 [00:02<00:08, 15.65it/s]Extracting features:  22%|██▏       | 34/157 [00:02<00:08, 14.05it/s]Extracting features:  24%|██▍       | 38/157 [00:03<00:07, 16.40it/s]Extracting features:  27%|██▋       | 42/157 [00:03<00:06, 17.78it/s]Extracting features:  29%|██▉       | 46/157 [00:03<00:05, 19.32it/s]Extracting features:  32%|███▏      | 50/157 [00:03<00:05, 18.15it/s]Extracting features:  34%|███▍      | 54/157 [00:03<00:05, 18.61it/s]Extracting features:  37%|███▋      | 58/157 [00:04<00:05, 17.38it/s]Extracting features:  38%|███▊      | 60/157 [00:04<00:05, 16.58it/s]Extracting features:  40%|████      | 63/157 [00:04<00:06, 13.89it/s]Extracting features:  43%|████▎     | 67/157 [00:04<00:06, 14.10it/s]Extracting features:  45%|████▌     | 71/157 [00:05<00:05, 14.45it/s]Extracting features:  48%|████▊     | 75/157 [00:05<00:05, 14.90it/s]Extracting features:  50%|█████     | 79/157 [00:05<00:06, 12.36it/s]Extracting features:  53%|█████▎    | 83/157 [00:06<00:05, 12.86it/s]Extracting features:  55%|█████▌    | 87/157 [00:06<00:05, 12.47it/s]Extracting features:  58%|█████▊    | 91/157 [00:06<00:05, 13.10it/s]Extracting features:  61%|██████    | 95/157 [00:06<00:04, 13.61it/s]Extracting features:  63%|██████▎   | 99/157 [00:07<00:04, 12.86it/s]Extracting features:  66%|██████▌   | 103/157 [00:07<00:04, 11.88it/s]Extracting features:  68%|██████▊   | 107/157 [00:08<00:04, 11.68it/s]Extracting features:  71%|███████   | 111/157 [00:08<00:04, 11.50it/s]Extracting features:  73%|███████▎  | 115/157 [00:08<00:03, 12.02it/s]Extracting features:  76%|███████▌  | 119/157 [00:09<00:03, 12.21it/s]Extracting features:  78%|███████▊  | 123/157 [00:09<00:02, 11.72it/s]Extracting features:  81%|████████  | 127/157 [00:09<00:02, 14.16it/s]Extracting features:  83%|████████▎ | 130/157 [00:09<00:01, 15.77it/s]Extracting features:  84%|████████▍ | 132/157 [00:09<00:01, 15.53it/s]Extracting features:  86%|████████▌ | 135/157 [00:10<00:01, 13.99it/s]Extracting features:  89%|████████▊ | 139/157 [00:10<00:01, 14.20it/s]Extracting features:  91%|█████████ | 143/157 [00:10<00:00, 15.93it/s]Extracting features:  94%|█████████▎| 147/157 [00:10<00:00, 16.23it/s]Extracting features:  95%|█████████▍| 149/157 [00:10<00:00, 14.86it/s]Extracting features:  96%|█████████▌| 151/157 [00:11<00:00, 13.91it/s]Extracting features:  99%|█████████▊| 155/157 [00:11<00:00, 15.89it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 13.65it/s]
2024-12-27 21:10:27,922 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 21:10:27,923 - INFO - Training feature extraction completed in 11.52s
2024-12-27 21:10:27,923 - INFO - Creating model for classifier: KNeighbors
2024-12-27 21:10:27,923 - INFO - Using device: cuda
2024-12-27 21:10:27,923 - INFO - 
Processing poison rate: 0.0
2024-12-27 21:10:27,923 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:10:27,923 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:10:28,525 - INFO - Feature scaling completed in 0.60s
2024-12-27 21:10:28,526 - INFO - Starting feature selection (k=50)
2024-12-27 21:10:28,533 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:10:28,533 - INFO - Starting anomaly detection
2024-12-27 21:10:30,464 - INFO - Anomaly detection completed in 1.93s
2024-12-27 21:10:30,465 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:10:30,465 - INFO - Total fit_transform time: 2.54s
2024-12-27 21:10:30,465 - INFO - Training set processing completed in 2.54s
2024-12-27 21:10:30,465 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:10:30,467 - INFO - Memory usage at start_fit: CPU 3115.4 MB, GPU 47.3 MB
2024-12-27 21:10:30,467 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:10:30,539 - INFO - Fitted scaler and transformed data
2024-12-27 21:10:30,540 - INFO - Scaling time: 0.07s
2024-12-27 21:10:30,547 - INFO - Training completed in 0.08s
2024-12-27 21:10:30,547 - INFO - Final memory usage: CPU 3115.4 MB, GPU 71.8 MB
2024-12-27 21:10:30,547 - INFO - Model training completed in 0.08s
2024-12-27 21:10:30,566 - INFO - Prediction completed in 0.02s
2024-12-27 21:10:30,574 - INFO - Poison rate 0.0 completed in 2.65s
2024-12-27 21:10:30,574 - INFO - 
Processing poison rate: 0.01
2024-12-27 21:10:30,574 - INFO - Label flipping details:
2024-12-27 21:10:30,575 - INFO - - Source class: 1
2024-12-27 21:10:30,575 - INFO - - Target class: 0
2024-12-27 21:10:30,575 - INFO - - Available samples in source class: 500
2024-12-27 21:10:30,575 - INFO - - Requested samples to poison: 50
2024-12-27 21:10:30,575 - INFO - - Actual samples to flip: 50
2024-12-27 21:10:30,575 - INFO - - Samples remaining in source class: 450
2024-12-27 21:10:30,575 - INFO - Successfully flipped 50 labels from class 1 to 0
2024-12-27 21:10:30,575 - INFO - Total number of labels flipped: 50
2024-12-27 21:10:30,575 - INFO - Label flipping completed in 0.00s
2024-12-27 21:10:30,575 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:10:30,575 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:10:31,158 - INFO - Feature scaling completed in 0.58s
2024-12-27 21:10:31,159 - INFO - Starting feature selection (k=50)
2024-12-27 21:10:31,166 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:10:31,166 - INFO - Starting anomaly detection
2024-12-27 21:10:33,136 - INFO - Anomaly detection completed in 1.97s
2024-12-27 21:10:33,136 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:10:33,136 - INFO - Total fit_transform time: 2.56s
2024-12-27 21:10:33,137 - INFO - Training set processing completed in 2.56s
2024-12-27 21:10:33,137 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:10:33,138 - INFO - Memory usage at start_fit: CPU 3115.4 MB, GPU 71.8 MB
2024-12-27 21:10:33,138 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:10:33,208 - INFO - Fitted scaler and transformed data
2024-12-27 21:10:33,208 - INFO - Scaling time: 0.07s
2024-12-27 21:10:33,215 - INFO - Training completed in 0.08s
2024-12-27 21:10:33,215 - INFO - Final memory usage: CPU 3115.4 MB, GPU 71.8 MB
2024-12-27 21:10:33,215 - INFO - Model training completed in 0.08s
2024-12-27 21:10:33,244 - INFO - Prediction completed in 0.03s
2024-12-27 21:10:33,254 - INFO - Poison rate 0.01 completed in 2.68s
2024-12-27 21:10:33,254 - INFO - 
Processing poison rate: 0.03
2024-12-27 21:10:33,254 - INFO - Label flipping details:
2024-12-27 21:10:33,255 - INFO - - Source class: 1
2024-12-27 21:10:33,255 - INFO - - Target class: 0
2024-12-27 21:10:33,255 - INFO - - Available samples in source class: 500
2024-12-27 21:10:33,255 - INFO - - Requested samples to poison: 150
2024-12-27 21:10:33,255 - INFO - - Actual samples to flip: 150
2024-12-27 21:10:33,255 - INFO - - Samples remaining in source class: 350
2024-12-27 21:10:33,255 - INFO - Successfully flipped 150 labels from class 1 to 0
2024-12-27 21:10:33,255 - INFO - Total number of labels flipped: 150
2024-12-27 21:10:33,255 - INFO - Label flipping completed in 0.00s
2024-12-27 21:10:33,255 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:10:33,255 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:10:33,875 - INFO - Feature scaling completed in 0.62s
2024-12-27 21:10:33,875 - INFO - Starting feature selection (k=50)
2024-12-27 21:10:33,887 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:10:33,888 - INFO - Starting anomaly detection
2024-12-27 21:10:35,756 - INFO - Anomaly detection completed in 1.87s
2024-12-27 21:10:35,756 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:10:35,757 - INFO - Total fit_transform time: 2.50s
2024-12-27 21:10:35,757 - INFO - Training set processing completed in 2.50s
2024-12-27 21:10:35,757 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:10:35,758 - INFO - Memory usage at start_fit: CPU 3115.4 MB, GPU 71.8 MB
2024-12-27 21:10:35,758 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:10:35,825 - INFO - Fitted scaler and transformed data
2024-12-27 21:10:35,825 - INFO - Scaling time: 0.07s
2024-12-27 21:10:35,831 - INFO - Training completed in 0.07s
2024-12-27 21:10:35,832 - INFO - Final memory usage: CPU 3115.4 MB, GPU 71.8 MB
2024-12-27 21:10:35,832 - INFO - Model training completed in 0.07s
2024-12-27 21:10:35,858 - INFO - Prediction completed in 0.03s
2024-12-27 21:10:35,866 - INFO - Poison rate 0.03 completed in 2.61s
2024-12-27 21:10:35,866 - INFO - 
Processing poison rate: 0.05
2024-12-27 21:10:35,866 - INFO - Label flipping details:
2024-12-27 21:10:35,866 - INFO - - Source class: 1
2024-12-27 21:10:35,866 - INFO - - Target class: 0
2024-12-27 21:10:35,866 - INFO - - Available samples in source class: 500
2024-12-27 21:10:35,866 - INFO - - Requested samples to poison: 250
2024-12-27 21:10:35,866 - INFO - - Actual samples to flip: 250
2024-12-27 21:10:35,866 - INFO - - Samples remaining in source class: 250
2024-12-27 21:10:35,867 - INFO - Successfully flipped 250 labels from class 1 to 0
2024-12-27 21:10:35,867 - INFO - Total number of labels flipped: 250
2024-12-27 21:10:35,867 - INFO - Label flipping completed in 0.00s
2024-12-27 21:10:35,867 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:10:35,867 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:10:36,404 - INFO - Feature scaling completed in 0.54s
2024-12-27 21:10:36,404 - INFO - Starting feature selection (k=50)
2024-12-27 21:10:36,419 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:10:36,419 - INFO - Starting anomaly detection
2024-12-27 21:10:38,379 - INFO - Anomaly detection completed in 1.96s
2024-12-27 21:10:38,380 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:10:38,380 - INFO - Total fit_transform time: 2.51s
2024-12-27 21:10:38,380 - INFO - Training set processing completed in 2.51s
2024-12-27 21:10:38,380 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:10:38,381 - INFO - Memory usage at start_fit: CPU 3115.4 MB, GPU 71.8 MB
2024-12-27 21:10:38,381 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:10:38,448 - INFO - Fitted scaler and transformed data
2024-12-27 21:10:38,449 - INFO - Scaling time: 0.07s
2024-12-27 21:10:38,455 - INFO - Training completed in 0.07s
2024-12-27 21:10:38,455 - INFO - Final memory usage: CPU 3115.4 MB, GPU 71.8 MB
2024-12-27 21:10:38,456 - INFO - Model training completed in 0.08s
2024-12-27 21:10:38,482 - INFO - Prediction completed in 0.03s
2024-12-27 21:10:38,496 - INFO - Poison rate 0.05 completed in 2.63s
2024-12-27 21:10:38,497 - INFO - 
Processing poison rate: 0.07
2024-12-27 21:10:38,497 - INFO - Label flipping details:
2024-12-27 21:10:38,497 - INFO - - Source class: 1
2024-12-27 21:10:38,497 - INFO - - Target class: 0
2024-12-27 21:10:38,497 - INFO - - Available samples in source class: 500
2024-12-27 21:10:38,497 - INFO - - Requested samples to poison: 350
2024-12-27 21:10:38,497 - INFO - - Actual samples to flip: 350
2024-12-27 21:10:38,497 - INFO - - Samples remaining in source class: 150
2024-12-27 21:10:38,497 - INFO - Successfully flipped 350 labels from class 1 to 0
2024-12-27 21:10:38,498 - INFO - Total number of labels flipped: 350
2024-12-27 21:10:38,498 - INFO - Label flipping completed in 0.00s
2024-12-27 21:10:38,498 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:10:38,498 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:10:39,089 - INFO - Feature scaling completed in 0.59s
2024-12-27 21:10:39,089 - INFO - Starting feature selection (k=50)
2024-12-27 21:10:39,103 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:10:39,103 - INFO - Starting anomaly detection
2024-12-27 21:10:40,311 - INFO - Anomaly detection completed in 1.21s
2024-12-27 21:10:40,312 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:10:40,312 - INFO - Total fit_transform time: 1.81s
2024-12-27 21:10:40,312 - INFO - Training set processing completed in 1.81s
2024-12-27 21:10:40,312 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:10:40,313 - INFO - Memory usage at start_fit: CPU 3115.4 MB, GPU 71.8 MB
2024-12-27 21:10:40,314 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:10:40,381 - INFO - Fitted scaler and transformed data
2024-12-27 21:10:40,381 - INFO - Scaling time: 0.07s
2024-12-27 21:10:40,387 - INFO - Training completed in 0.07s
2024-12-27 21:10:40,388 - INFO - Final memory usage: CPU 3115.4 MB, GPU 71.8 MB
2024-12-27 21:10:40,388 - INFO - Model training completed in 0.08s
2024-12-27 21:10:40,412 - INFO - Prediction completed in 0.02s
2024-12-27 21:10:40,420 - INFO - Poison rate 0.07 completed in 1.92s
2024-12-27 21:10:40,420 - INFO - 
Processing poison rate: 0.1
2024-12-27 21:10:40,420 - INFO - Label flipping details:
2024-12-27 21:10:40,420 - INFO - - Source class: 1
2024-12-27 21:10:40,421 - INFO - - Target class: 0
2024-12-27 21:10:40,421 - INFO - - Available samples in source class: 500
2024-12-27 21:10:40,421 - INFO - - Requested samples to poison: 500
2024-12-27 21:10:40,421 - INFO - - Actual samples to flip: 499
2024-12-27 21:10:40,421 - INFO - - Samples remaining in source class: 1
2024-12-27 21:10:40,421 - INFO - Successfully flipped 499 labels from class 1 to 0
2024-12-27 21:10:40,421 - INFO - Total number of labels flipped: 499
2024-12-27 21:10:40,421 - INFO - Label flipping completed in 0.00s
2024-12-27 21:10:40,421 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:10:40,421 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:10:41,011 - INFO - Feature scaling completed in 0.59s
2024-12-27 21:10:41,011 - INFO - Starting feature selection (k=50)
2024-12-27 21:10:41,020 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:10:41,021 - INFO - Starting anomaly detection
2024-12-27 21:10:43,092 - INFO - Anomaly detection completed in 2.07s
2024-12-27 21:10:43,092 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:10:43,092 - INFO - Total fit_transform time: 2.67s
2024-12-27 21:10:43,092 - INFO - Training set processing completed in 2.67s
2024-12-27 21:10:43,092 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:10:43,094 - INFO - Memory usage at start_fit: CPU 3115.4 MB, GPU 71.8 MB
2024-12-27 21:10:43,094 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:10:43,167 - INFO - Fitted scaler and transformed data
2024-12-27 21:10:43,167 - INFO - Scaling time: 0.07s
2024-12-27 21:10:43,175 - INFO - Training completed in 0.08s
2024-12-27 21:10:43,176 - INFO - Final memory usage: CPU 3115.4 MB, GPU 71.8 MB
2024-12-27 21:10:43,176 - INFO - Model training completed in 0.08s
2024-12-27 21:10:43,209 - INFO - Prediction completed in 0.03s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 21:10:43,219 - INFO - Poison rate 0.1 completed in 2.80s
2024-12-27 21:10:43,219 - INFO - 
Processing poison rate: 0.2
2024-12-27 21:10:43,220 - INFO - Label flipping details:
2024-12-27 21:10:43,220 - INFO - - Source class: 1
2024-12-27 21:10:43,220 - INFO - - Target class: 0
2024-12-27 21:10:43,220 - INFO - - Available samples in source class: 500
2024-12-27 21:10:43,220 - INFO - - Requested samples to poison: 1000
2024-12-27 21:10:43,220 - INFO - - Actual samples to flip: 499
2024-12-27 21:10:43,220 - INFO - - Samples remaining in source class: 1
2024-12-27 21:10:43,220 - INFO - Successfully flipped 499 labels from class 1 to 0
2024-12-27 21:10:43,220 - INFO - Total number of labels flipped: 499
2024-12-27 21:10:43,220 - INFO - Label flipping completed in 0.00s
2024-12-27 21:10:43,220 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:10:43,220 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:10:43,759 - INFO - Feature scaling completed in 0.54s
2024-12-27 21:10:43,759 - INFO - Starting feature selection (k=50)
2024-12-27 21:10:43,767 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:10:43,767 - INFO - Starting anomaly detection
2024-12-27 21:10:45,562 - INFO - Anomaly detection completed in 1.79s
2024-12-27 21:10:45,562 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:10:45,562 - INFO - Total fit_transform time: 2.34s
2024-12-27 21:10:45,562 - INFO - Training set processing completed in 2.34s
2024-12-27 21:10:45,562 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:10:45,563 - INFO - Memory usage at start_fit: CPU 3115.4 MB, GPU 71.8 MB
2024-12-27 21:10:45,563 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:10:45,647 - INFO - Fitted scaler and transformed data
2024-12-27 21:10:45,647 - INFO - Scaling time: 0.08s
2024-12-27 21:10:45,654 - INFO - Training completed in 0.09s
2024-12-27 21:10:45,654 - INFO - Final memory usage: CPU 3115.4 MB, GPU 71.8 MB
2024-12-27 21:10:45,654 - INFO - Model training completed in 0.09s
2024-12-27 21:10:45,681 - INFO - Prediction completed in 0.03s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-27 21:10:45,689 - INFO - Poison rate 0.2 completed in 2.47s
2024-12-27 21:10:45,689 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 21:10:45,689 - INFO - Total evaluation time: 31.97s
2024-12-27 21:10:45,691 - INFO - Completed evaluation for ImageNette
2024-12-27 21:10:45,691 - INFO - 
Processing dataset: ImageNette
2024-12-27 21:10:45,752 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 21:10:45,823 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 21:10:45,906 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 21:10:45,906 - INFO - Dataset type: image
2024-12-27 21:10:45,906 - INFO - Sample size: 5000
2024-12-27 21:10:45,906 - INFO - Using device: cuda
2024-12-27 21:10:45,908 - INFO - 
Progress: 92.7% - Evaluating ImageNette with SVM (standard mode, iteration 1/1)
2024-12-27 21:10:45,966 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 21:10:46,029 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 21:10:46,112 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 21:10:46,112 - INFO - Dataset type: image
2024-12-27 21:10:46,112 - INFO - Sample size: 5000
2024-12-27 21:10:46,112 - INFO - Using device: cuda
2024-12-27 21:10:46,114 - INFO - Loading datasets...
2024-12-27 21:10:46,140 - INFO - Dataset loading completed in 0.03s
2024-12-27 21:10:46,140 - INFO - Extracting validation features...
2024-12-27 21:10:46,140 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:22,  1.36it/s]Extracting features:  16%|█▌        | 5/32 [00:00<00:03,  7.63it/s]Extracting features:  28%|██▊       | 9/32 [00:01<00:02, 10.00it/s]Extracting features:  38%|███▊      | 12/32 [00:01<00:01, 12.49it/s]Extracting features:  47%|████▋     | 15/32 [00:01<00:01, 14.43it/s]Extracting features:  56%|█████▋    | 18/32 [00:01<00:01, 13.06it/s]Extracting features:  62%|██████▎   | 20/32 [00:01<00:00, 12.26it/s]Extracting features:  69%|██████▉   | 22/32 [00:02<00:00, 13.16it/s]Extracting features:  75%|███████▌  | 24/32 [00:02<00:00, 12.24it/s]Extracting features:  88%|████████▊ | 28/32 [00:02<00:00, 15.06it/s]Extracting features:  94%|█████████▍| 30/32 [00:02<00:00, 15.22it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 12.11it/s]
2024-12-27 21:10:48,788 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 21:10:48,788 - INFO - Validation feature extraction completed in 2.65s
2024-12-27 21:10:48,789 - INFO - Extracting training features...
2024-12-27 21:10:48,789 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:09,  2.25it/s]Extracting features:   1%|▏         | 2/157 [00:00<00:41,  3.77it/s]Extracting features:   4%|▍         | 6/157 [00:00<00:15,  9.81it/s]Extracting features:   6%|▌         | 9/157 [00:00<00:11, 13.40it/s]Extracting features:   7%|▋         | 11/157 [00:01<00:11, 12.29it/s]Extracting features:   9%|▉         | 14/157 [00:01<00:09, 15.28it/s]Extracting features:  10%|█         | 16/157 [00:01<00:09, 15.64it/s]Extracting features:  11%|█▏        | 18/157 [00:01<00:09, 15.29it/s]Extracting features:  13%|█▎        | 20/157 [00:01<00:09, 13.86it/s]Extracting features:  15%|█▍        | 23/157 [00:01<00:09, 13.50it/s]Extracting features:  17%|█▋        | 27/157 [00:02<00:08, 14.48it/s]Extracting features:  20%|█▉        | 31/157 [00:02<00:08, 15.06it/s]Extracting features:  22%|██▏       | 35/157 [00:02<00:06, 17.73it/s]Extracting features:  24%|██▍       | 38/157 [00:02<00:07, 16.66it/s]Extracting features:  27%|██▋       | 42/157 [00:02<00:06, 17.25it/s]Extracting features:  29%|██▉       | 46/157 [00:03<00:05, 18.77it/s]Extracting features:  31%|███       | 48/157 [00:03<00:05, 18.22it/s]Extracting features:  32%|███▏      | 51/157 [00:03<00:06, 16.33it/s]Extracting features:  35%|███▌      | 55/157 [00:03<00:05, 17.34it/s]Extracting features:  38%|███▊      | 59/157 [00:03<00:05, 18.05it/s]Extracting features:  39%|███▉      | 62/157 [00:04<00:05, 18.01it/s]Extracting features:  41%|████▏     | 65/157 [00:04<00:04, 19.07it/s]Extracting features:  43%|████▎     | 67/157 [00:04<00:05, 15.88it/s]Extracting features:  45%|████▍     | 70/157 [00:04<00:05, 14.56it/s]Extracting features:  46%|████▋     | 73/157 [00:04<00:04, 16.80it/s]Extracting features:  48%|████▊     | 75/157 [00:04<00:05, 14.72it/s]Extracting features:  49%|████▉     | 77/157 [00:05<00:05, 14.67it/s]Extracting features:  50%|█████     | 79/157 [00:05<00:05, 13.58it/s]Extracting features:  52%|█████▏    | 82/157 [00:05<00:05, 13.04it/s]Extracting features:  55%|█████▍    | 86/157 [00:05<00:05, 13.09it/s]Extracting features:  57%|█████▋    | 90/157 [00:06<00:05, 12.99it/s]Extracting features:  59%|█████▉    | 93/157 [00:06<00:04, 14.26it/s]Extracting features:  61%|██████    | 95/157 [00:06<00:04, 14.67it/s]Extracting features:  62%|██████▏   | 97/157 [00:06<00:04, 14.14it/s]Extracting features:  63%|██████▎   | 99/157 [00:06<00:04, 13.83it/s]Extracting features:  64%|██████▍   | 101/157 [00:06<00:04, 13.90it/s]Extracting features:  66%|██████▌   | 103/157 [00:07<00:04, 12.02it/s]Extracting features:  68%|██████▊   | 106/157 [00:07<00:04, 12.34it/s]Extracting features:  69%|██████▉   | 108/157 [00:07<00:04, 11.79it/s]Extracting features:  71%|███████   | 111/157 [00:07<00:04, 11.01it/s]Extracting features:  73%|███████▎  | 115/157 [00:08<00:03, 12.15it/s]Extracting features:  76%|███████▌  | 119/157 [00:08<00:03, 12.61it/s]Extracting features:  78%|███████▊  | 123/157 [00:08<00:02, 13.06it/s]Extracting features:  81%|████████  | 127/157 [00:08<00:02, 14.21it/s]Extracting features:  83%|████████▎ | 131/157 [00:09<00:01, 14.95it/s]Extracting features:  86%|████████▌ | 135/157 [00:09<00:01, 16.08it/s]Extracting features:  89%|████████▊ | 139/157 [00:09<00:01, 17.67it/s]Extracting features:  90%|████████▉ | 141/157 [00:09<00:00, 18.00it/s]Extracting features:  91%|█████████ | 143/157 [00:09<00:00, 18.28it/s]Extracting features:  92%|█████████▏| 145/157 [00:10<00:00, 13.68it/s]Extracting features:  94%|█████████▍| 148/157 [00:10<00:00, 14.11it/s]Extracting features:  96%|█████████▌| 151/157 [00:10<00:00, 16.02it/s]Extracting features:  97%|█████████▋| 153/157 [00:10<00:00, 13.50it/s]Extracting features:  99%|█████████▉| 156/157 [00:10<00:00, 14.92it/s]Extracting features: 100%|██████████| 157/157 [00:10<00:00, 14.48it/s]
2024-12-27 21:10:59,641 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 21:10:59,642 - INFO - Training feature extraction completed in 10.85s
2024-12-27 21:10:59,642 - INFO - Creating model for classifier: SVM
2024-12-27 21:10:59,642 - INFO - Using device: cuda
2024-12-27 21:10:59,642 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-27 21:10:59,642 - INFO - 
Processing poison rate: 0.0
2024-12-27 21:10:59,642 - INFO - Training set processing completed in 0.00s
2024-12-27 21:10:59,642 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 21:10:59,644 - INFO - Memory usage at start_fit: CPU 3106.5 MB, GPU 47.3 MB
2024-12-27 21:10:59,644 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:10:59,645 - INFO - Number of unique classes: 10
2024-12-27 21:10:59,749 - INFO - Fitted scaler and transformed data
2024-12-27 21:10:59,750 - INFO - Scaling time: 0.10s
2024-12-27 21:10:59,945 - INFO - Epoch 1/25, Train Loss: 0.3063, Val Loss: 0.1126
2024-12-27 21:11:00,142 - INFO - Epoch 2/25, Train Loss: 0.0091, Val Loss: 0.0911
2024-12-27 21:11:00,331 - INFO - Epoch 3/25, Train Loss: 0.0027, Val Loss: 0.0674
2024-12-27 21:11:00,525 - INFO - Epoch 4/25, Train Loss: 0.0002, Val Loss: 0.0540
2024-12-27 21:11:00,716 - INFO - Epoch 5/25, Train Loss: 0.0000, Val Loss: 0.0533
2024-12-27 21:11:00,926 - INFO - Epoch 6/25, Train Loss: 0.0000, Val Loss: 0.0528
2024-12-27 21:11:00,927 - INFO - Early stopping triggered at epoch 6
2024-12-27 21:11:00,927 - INFO - Training completed in 1.28s
2024-12-27 21:11:00,927 - INFO - Final memory usage: CPU 3108.3 MB, GPU 48.1 MB
2024-12-27 21:11:00,927 - INFO - Model training completed in 1.29s
2024-12-27 21:11:00,942 - INFO - Prediction completed in 0.01s
2024-12-27 21:11:00,956 - INFO - Poison rate 0.0 completed in 1.31s
2024-12-27 21:11:00,956 - INFO - 
Processing poison rate: 0.01
2024-12-27 21:11:00,957 - INFO - Total number of labels flipped: 50
2024-12-27 21:11:00,957 - INFO - Label flipping completed in 0.00s
2024-12-27 21:11:00,957 - INFO - Training set processing completed in 0.00s
2024-12-27 21:11:00,958 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 21:11:00,958 - INFO - Memory usage at start_fit: CPU 3108.3 MB, GPU 47.5 MB
2024-12-27 21:11:00,958 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:11:00,959 - INFO - Number of unique classes: 10
2024-12-27 21:11:01,043 - INFO - Fitted scaler and transformed data
2024-12-27 21:11:01,043 - INFO - Scaling time: 0.08s
2024-12-27 21:11:01,228 - INFO - Epoch 1/25, Train Loss: 0.7436, Val Loss: 0.7407
2024-12-27 21:11:01,405 - INFO - Epoch 2/25, Train Loss: 0.1889, Val Loss: 0.8075
2024-12-27 21:11:01,569 - INFO - Epoch 3/25, Train Loss: 0.1140, Val Loss: 0.8675
2024-12-27 21:11:01,570 - INFO - Early stopping triggered at epoch 3
2024-12-27 21:11:01,570 - INFO - Training completed in 0.61s
2024-12-27 21:11:01,571 - INFO - Final memory usage: CPU 3108.3 MB, GPU 48.1 MB
2024-12-27 21:11:01,572 - INFO - Model training completed in 0.61s
2024-12-27 21:11:01,585 - INFO - Prediction completed in 0.01s
2024-12-27 21:11:01,599 - INFO - Poison rate 0.01 completed in 0.64s
2024-12-27 21:11:01,599 - INFO - 
Processing poison rate: 0.03
2024-12-27 21:11:01,603 - INFO - Total number of labels flipped: 150
2024-12-27 21:11:01,604 - INFO - Label flipping completed in 0.00s
2024-12-27 21:11:01,604 - INFO - Training set processing completed in 0.00s
2024-12-27 21:11:01,604 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 21:11:01,605 - INFO - Memory usage at start_fit: CPU 3108.3 MB, GPU 47.5 MB
2024-12-27 21:11:01,605 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:11:01,605 - INFO - Number of unique classes: 10
2024-12-27 21:11:01,711 - INFO - Fitted scaler and transformed data
2024-12-27 21:11:01,711 - INFO - Scaling time: 0.10s
2024-12-27 21:11:01,907 - INFO - Epoch 1/25, Train Loss: 1.6456, Val Loss: 1.6466
2024-12-27 21:11:02,072 - INFO - Epoch 2/25, Train Loss: 0.5002, Val Loss: 1.7438
2024-12-27 21:11:02,249 - INFO - Epoch 3/25, Train Loss: 0.2912, Val Loss: 1.8447
2024-12-27 21:11:02,249 - INFO - Early stopping triggered at epoch 3
2024-12-27 21:11:02,249 - INFO - Training completed in 0.64s
2024-12-27 21:11:02,249 - INFO - Final memory usage: CPU 3108.3 MB, GPU 48.1 MB
2024-12-27 21:11:02,250 - INFO - Model training completed in 0.65s
2024-12-27 21:11:02,256 - INFO - Prediction completed in 0.01s
2024-12-27 21:11:02,264 - INFO - Poison rate 0.03 completed in 0.66s
2024-12-27 21:11:02,264 - INFO - 
Processing poison rate: 0.05
2024-12-27 21:11:02,267 - INFO - Total number of labels flipped: 250
2024-12-27 21:11:02,268 - INFO - Label flipping completed in 0.00s
2024-12-27 21:11:02,268 - INFO - Training set processing completed in 0.00s
2024-12-27 21:11:02,268 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 21:11:02,269 - INFO - Memory usage at start_fit: CPU 3108.3 MB, GPU 47.5 MB
2024-12-27 21:11:02,269 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:11:02,269 - INFO - Number of unique classes: 10
2024-12-27 21:11:02,347 - INFO - Fitted scaler and transformed data
2024-12-27 21:11:02,347 - INFO - Scaling time: 0.08s
2024-12-27 21:11:02,548 - INFO - Epoch 1/25, Train Loss: 2.3789, Val Loss: 2.7945
2024-12-27 21:11:02,705 - INFO - Epoch 2/25, Train Loss: 0.9221, Val Loss: 2.2223
2024-12-27 21:11:02,877 - INFO - Epoch 3/25, Train Loss: 0.4097, Val Loss: 2.0770
2024-12-27 21:11:03,043 - INFO - Epoch 4/25, Train Loss: 0.2007, Val Loss: 1.8957
2024-12-27 21:11:03,217 - INFO - Epoch 5/25, Train Loss: 0.1356, Val Loss: 1.9820
2024-12-27 21:11:03,402 - INFO - Epoch 6/25, Train Loss: 0.0856, Val Loss: 2.0524
2024-12-27 21:11:03,402 - INFO - Early stopping triggered at epoch 6
2024-12-27 21:11:03,402 - INFO - Training completed in 1.13s
2024-12-27 21:11:03,402 - INFO - Final memory usage: CPU 3108.3 MB, GPU 48.1 MB
2024-12-27 21:11:03,402 - INFO - Model training completed in 1.13s
2024-12-27 21:11:03,409 - INFO - Prediction completed in 0.01s
2024-12-27 21:11:03,417 - INFO - Poison rate 0.05 completed in 1.15s
2024-12-27 21:11:03,417 - INFO - 
Processing poison rate: 0.07
2024-12-27 21:11:03,422 - INFO - Total number of labels flipped: 350
2024-12-27 21:11:03,422 - INFO - Label flipping completed in 0.00s
2024-12-27 21:11:03,422 - INFO - Training set processing completed in 0.00s
2024-12-27 21:11:03,422 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 21:11:03,423 - INFO - Memory usage at start_fit: CPU 3108.3 MB, GPU 47.5 MB
2024-12-27 21:11:03,423 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:11:03,423 - INFO - Number of unique classes: 10
2024-12-27 21:11:03,503 - INFO - Fitted scaler and transformed data
2024-12-27 21:11:03,503 - INFO - Scaling time: 0.08s
2024-12-27 21:11:03,697 - INFO - Epoch 1/25, Train Loss: 2.7990, Val Loss: 3.1040
2024-12-27 21:11:03,898 - INFO - Epoch 2/25, Train Loss: 1.0067, Val Loss: 3.0539
2024-12-27 21:11:04,103 - INFO - Epoch 3/25, Train Loss: 0.4883, Val Loss: 2.7454
2024-12-27 21:11:04,298 - INFO - Epoch 4/25, Train Loss: 0.3016, Val Loss: 2.6211
2024-12-27 21:11:04,499 - INFO - Epoch 5/25, Train Loss: 0.1992, Val Loss: 2.6247
2024-12-27 21:11:04,673 - INFO - Epoch 6/25, Train Loss: 0.1798, Val Loss: 2.6029
2024-12-27 21:11:04,858 - INFO - Epoch 7/25, Train Loss: 0.1473, Val Loss: 2.7433
2024-12-27 21:11:05,047 - INFO - Epoch 8/25, Train Loss: 0.2039, Val Loss: 2.8702
2024-12-27 21:11:05,047 - INFO - Early stopping triggered at epoch 8
2024-12-27 21:11:05,047 - INFO - Training completed in 1.62s
2024-12-27 21:11:05,048 - INFO - Final memory usage: CPU 3108.3 MB, GPU 48.1 MB
2024-12-27 21:11:05,048 - INFO - Model training completed in 1.63s
2024-12-27 21:11:05,062 - INFO - Prediction completed in 0.01s
2024-12-27 21:11:05,075 - INFO - Poison rate 0.07 completed in 1.66s
2024-12-27 21:11:05,075 - INFO - 
Processing poison rate: 0.1
2024-12-27 21:11:05,084 - INFO - Total number of labels flipped: 500
2024-12-27 21:11:05,084 - INFO - Label flipping completed in 0.01s
2024-12-27 21:11:05,084 - INFO - Training set processing completed in 0.00s
2024-12-27 21:11:05,085 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 21:11:05,085 - INFO - Memory usage at start_fit: CPU 3108.3 MB, GPU 47.5 MB
2024-12-27 21:11:05,086 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:11:05,086 - INFO - Number of unique classes: 10
2024-12-27 21:11:05,197 - INFO - Fitted scaler and transformed data
2024-12-27 21:11:05,197 - INFO - Scaling time: 0.11s
2024-12-27 21:11:05,415 - INFO - Epoch 1/25, Train Loss: 3.5625, Val Loss: 4.0113
2024-12-27 21:11:05,619 - INFO - Epoch 2/25, Train Loss: 1.3551, Val Loss: 3.1613
2024-12-27 21:11:05,809 - INFO - Epoch 3/25, Train Loss: 0.6491, Val Loss: 2.8799
2024-12-27 21:11:06,021 - INFO - Epoch 4/25, Train Loss: 0.4447, Val Loss: 3.1074
2024-12-27 21:11:06,213 - INFO - Epoch 5/25, Train Loss: 0.3082, Val Loss: 3.3185
2024-12-27 21:11:06,214 - INFO - Early stopping triggered at epoch 5
2024-12-27 21:11:06,214 - INFO - Training completed in 1.13s
2024-12-27 21:11:06,214 - INFO - Final memory usage: CPU 3108.3 MB, GPU 48.1 MB
2024-12-27 21:11:06,215 - INFO - Model training completed in 1.13s
2024-12-27 21:11:06,226 - INFO - Prediction completed in 0.01s
2024-12-27 21:11:06,234 - INFO - Poison rate 0.1 completed in 1.16s
2024-12-27 21:11:06,234 - INFO - 
Processing poison rate: 0.2
2024-12-27 21:11:06,246 - INFO - Total number of labels flipped: 1000
2024-12-27 21:11:06,246 - INFO - Label flipping completed in 0.01s
2024-12-27 21:11:06,246 - INFO - Training set processing completed in 0.00s
2024-12-27 21:11:06,247 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 21:11:06,247 - INFO - Memory usage at start_fit: CPU 3108.3 MB, GPU 47.5 MB
2024-12-27 21:11:06,248 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:11:06,248 - INFO - Number of unique classes: 10
2024-12-27 21:11:06,328 - INFO - Fitted scaler and transformed data
2024-12-27 21:11:06,328 - INFO - Scaling time: 0.08s
2024-12-27 21:11:06,559 - INFO - Epoch 1/25, Train Loss: 6.7746, Val Loss: 6.6261
2024-12-27 21:11:06,766 - INFO - Epoch 2/25, Train Loss: 2.5021, Val Loss: 6.2329
2024-12-27 21:11:06,967 - INFO - Epoch 3/25, Train Loss: 1.3897, Val Loss: 6.0601
2024-12-27 21:11:07,172 - INFO - Epoch 4/25, Train Loss: 1.1367, Val Loss: 5.7018
2024-12-27 21:11:07,374 - INFO - Epoch 5/25, Train Loss: 0.8586, Val Loss: 5.7493
2024-12-27 21:11:07,558 - INFO - Epoch 6/25, Train Loss: 0.6378, Val Loss: 6.1879
2024-12-27 21:11:07,558 - INFO - Early stopping triggered at epoch 6
2024-12-27 21:11:07,558 - INFO - Training completed in 1.31s
2024-12-27 21:11:07,559 - INFO - Final memory usage: CPU 3108.3 MB, GPU 48.1 MB
2024-12-27 21:11:07,559 - INFO - Model training completed in 1.31s
2024-12-27 21:11:07,567 - INFO - Prediction completed in 0.01s
2024-12-27 21:11:07,575 - INFO - Poison rate 0.2 completed in 1.34s
2024-12-27 21:11:07,576 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 21:11:07,576 - INFO - Total evaluation time: 21.46s
2024-12-27 21:11:07,578 - INFO - 
Progress: 93.8% - Evaluating ImageNette with SVM (dynadetect mode, iteration 1/1)
2024-12-27 21:11:07,641 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 21:11:07,709 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 21:11:07,796 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 21:11:07,796 - INFO - Dataset type: image
2024-12-27 21:11:07,796 - INFO - Sample size: 5000
2024-12-27 21:11:07,796 - INFO - Using device: cuda
2024-12-27 21:11:07,798 - INFO - Loading datasets...
2024-12-27 21:11:07,824 - INFO - Dataset loading completed in 0.02s
2024-12-27 21:11:07,824 - INFO - Extracting validation features...
2024-12-27 21:11:07,824 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:30,  1.00it/s]Extracting features:  12%|█▎        | 4/32 [00:01<00:06,  4.52it/s]Extracting features:  28%|██▊       | 9/32 [00:01<00:02, 11.09it/s]Extracting features:  38%|███▊      | 12/32 [00:01<00:01, 11.93it/s]Extracting features:  47%|████▋     | 15/32 [00:01<00:01, 14.50it/s]Extracting features:  56%|█████▋    | 18/32 [00:01<00:01, 13.03it/s]Extracting features:  62%|██████▎   | 20/32 [00:01<00:00, 13.98it/s]Extracting features:  69%|██████▉   | 22/32 [00:02<00:00, 12.19it/s]Extracting features:  78%|███████▊  | 25/32 [00:02<00:00, 12.63it/s]Extracting features:  91%|█████████ | 29/32 [00:02<00:00, 12.71it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 11.25it/s]
2024-12-27 21:11:10,674 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 21:11:10,675 - INFO - Validation feature extraction completed in 2.85s
2024-12-27 21:11:10,675 - INFO - Extracting training features...
2024-12-27 21:11:10,676 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:30,  1.73it/s]Extracting features:   3%|▎         | 5/157 [00:00<00:19,  7.80it/s]Extracting features:   4%|▍         | 7/157 [00:00<00:17,  8.64it/s]Extracting features:   6%|▋         | 10/157 [00:01<00:11, 12.59it/s]Extracting features:   8%|▊         | 12/157 [00:01<00:12, 11.52it/s]Extracting features:  10%|▉         | 15/157 [00:01<00:17,  8.19it/s]Extracting features:  12%|█▏        | 19/157 [00:02<00:13, 10.06it/s]Extracting features:  15%|█▍        | 23/157 [00:02<00:11, 11.41it/s]Extracting features:  17%|█▋        | 27/157 [00:02<00:10, 11.90it/s]Extracting features:  20%|█▉        | 31/157 [00:02<00:09, 13.18it/s]Extracting features:  22%|██▏       | 35/157 [00:03<00:08, 15.22it/s]Extracting features:  25%|██▍       | 39/157 [00:03<00:06, 16.98it/s]Extracting features:  27%|██▋       | 43/157 [00:03<00:06, 18.61it/s]Extracting features:  29%|██▉       | 46/157 [00:03<00:05, 19.08it/s]Extracting features:  31%|███       | 49/157 [00:03<00:06, 17.84it/s]Extracting features:  32%|███▏      | 51/157 [00:03<00:06, 17.26it/s]Extracting features:  35%|███▌      | 55/157 [00:04<00:05, 17.94it/s]Extracting features:  38%|███▊      | 59/157 [00:04<00:05, 17.91it/s]Extracting features:  40%|████      | 63/157 [00:04<00:05, 16.37it/s]Extracting features:  43%|████▎     | 67/157 [00:04<00:05, 16.41it/s]Extracting features:  44%|████▍     | 69/157 [00:04<00:05, 16.83it/s]Extracting features:  45%|████▌     | 71/157 [00:05<00:05, 15.07it/s]Extracting features:  46%|████▋     | 73/157 [00:05<00:06, 12.44it/s]Extracting features:  49%|████▉     | 77/157 [00:05<00:06, 13.19it/s]Extracting features:  52%|█████▏    | 81/157 [00:05<00:05, 13.94it/s]Extracting features:  54%|█████▎    | 84/157 [00:06<00:05, 12.92it/s]Extracting features:  56%|█████▌    | 88/157 [00:06<00:05, 13.25it/s]Extracting features:  59%|█████▊    | 92/157 [00:06<00:05, 12.36it/s]Extracting features:  61%|██████    | 96/157 [00:07<00:04, 12.52it/s]Extracting features:  64%|██████▎   | 100/157 [00:07<00:04, 13.17it/s]Extracting features:  66%|██████▌   | 104/157 [00:07<00:03, 13.98it/s]Extracting features:  68%|██████▊   | 106/157 [00:07<00:03, 13.19it/s]Extracting features:  69%|██████▉   | 108/157 [00:08<00:03, 12.50it/s]Extracting features:  71%|███████   | 111/157 [00:08<00:03, 14.81it/s]Extracting features:  72%|███████▏  | 113/157 [00:08<00:04,  9.91it/s]Extracting features:  75%|███████▍  | 117/157 [00:08<00:03, 10.93it/s]Extracting features:  77%|███████▋  | 121/157 [00:09<00:03, 11.74it/s]Extracting features:  80%|███████▉  | 125/157 [00:09<00:02, 12.32it/s]Extracting features:  82%|████████▏ | 129/157 [00:09<00:01, 14.53it/s]Extracting features:  85%|████████▍ | 133/157 [00:09<00:01, 15.49it/s]Extracting features:  87%|████████▋ | 137/157 [00:10<00:01, 17.03it/s]Extracting features:  90%|████████▉ | 141/157 [00:10<00:00, 17.77it/s]Extracting features:  92%|█████████▏| 145/157 [00:10<00:00, 17.64it/s]Extracting features:  95%|█████████▍| 149/157 [00:10<00:00, 18.57it/s]Extracting features:  96%|█████████▌| 151/157 [00:10<00:00, 17.41it/s]Extracting features:  98%|█████████▊| 154/157 [00:10<00:00, 19.22it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 18.20it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 13.96it/s]
2024-12-27 21:11:21,931 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 21:11:21,931 - INFO - Training feature extraction completed in 11.26s
2024-12-27 21:11:21,931 - INFO - Creating model for classifier: SVM
2024-12-27 21:11:21,932 - INFO - Using device: cuda
2024-12-27 21:11:21,932 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-27 21:11:21,932 - INFO - 
Processing poison rate: 0.0
2024-12-27 21:11:21,932 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:11:21,932 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:11:22,606 - INFO - Feature scaling completed in 0.67s
2024-12-27 21:11:22,606 - INFO - Starting feature selection (k=50)
2024-12-27 21:11:22,612 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:11:22,612 - INFO - Starting anomaly detection
2024-12-27 21:11:24,632 - INFO - Anomaly detection completed in 2.02s
2024-12-27 21:11:24,632 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:11:24,633 - INFO - Total fit_transform time: 2.70s
2024-12-27 21:11:24,633 - INFO - Training set processing completed in 2.70s
2024-12-27 21:11:24,633 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 21:11:24,635 - INFO - Memory usage at start_fit: CPU 3108.8 MB, GPU 47.3 MB
2024-12-27 21:11:24,635 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:11:24,635 - INFO - Number of unique classes: 10
2024-12-27 21:11:24,729 - INFO - Fitted scaler and transformed data
2024-12-27 21:11:24,729 - INFO - Scaling time: 0.09s
2024-12-27 21:11:24,922 - INFO - Epoch 1/25, Train Loss: 0.4307, Val Loss: 0.0487
2024-12-27 21:11:25,103 - INFO - Epoch 2/25, Train Loss: 0.0092, Val Loss: 0.0616
2024-12-27 21:11:25,298 - INFO - Epoch 3/25, Train Loss: 0.0006, Val Loss: 0.0626
2024-12-27 21:11:25,298 - INFO - Early stopping triggered at epoch 3
2024-12-27 21:11:25,298 - INFO - Training completed in 0.66s
2024-12-27 21:11:25,299 - INFO - Final memory usage: CPU 3108.8 MB, GPU 48.1 MB
2024-12-27 21:11:25,299 - INFO - Model training completed in 0.67s
2024-12-27 21:11:25,307 - INFO - Prediction completed in 0.01s
2024-12-27 21:11:25,315 - INFO - Poison rate 0.0 completed in 3.38s
2024-12-27 21:11:25,315 - INFO - 
Processing poison rate: 0.01
2024-12-27 21:11:25,316 - INFO - Total number of labels flipped: 50
2024-12-27 21:11:25,316 - INFO - Label flipping completed in 0.00s
2024-12-27 21:11:25,316 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:11:25,316 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:11:25,951 - INFO - Feature scaling completed in 0.63s
2024-12-27 21:11:25,951 - INFO - Starting feature selection (k=50)
2024-12-27 21:11:25,959 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:11:25,959 - INFO - Starting anomaly detection
2024-12-27 21:11:28,056 - INFO - Anomaly detection completed in 2.10s
2024-12-27 21:11:28,056 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:11:28,056 - INFO - Total fit_transform time: 2.74s
2024-12-27 21:11:28,056 - INFO - Training set processing completed in 2.74s
2024-12-27 21:11:28,056 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 21:11:28,058 - INFO - Memory usage at start_fit: CPU 3108.8 MB, GPU 47.5 MB
2024-12-27 21:11:28,058 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:11:28,059 - INFO - Number of unique classes: 10
2024-12-27 21:11:28,155 - INFO - Fitted scaler and transformed data
2024-12-27 21:11:28,155 - INFO - Scaling time: 0.09s
2024-12-27 21:11:28,344 - INFO - Epoch 1/25, Train Loss: 0.7130, Val Loss: 0.6247
2024-12-27 21:11:28,526 - INFO - Epoch 2/25, Train Loss: 0.1921, Val Loss: 0.6851
2024-12-27 21:11:28,739 - INFO - Epoch 3/25, Train Loss: 0.1254, Val Loss: 0.5428
2024-12-27 21:11:28,925 - INFO - Epoch 4/25, Train Loss: 0.0819, Val Loss: 0.6344
2024-12-27 21:11:29,123 - INFO - Epoch 5/25, Train Loss: 0.0461, Val Loss: 0.6633
2024-12-27 21:11:29,123 - INFO - Early stopping triggered at epoch 5
2024-12-27 21:11:29,123 - INFO - Training completed in 1.07s
2024-12-27 21:11:29,123 - INFO - Final memory usage: CPU 3108.8 MB, GPU 48.1 MB
2024-12-27 21:11:29,123 - INFO - Model training completed in 1.07s
2024-12-27 21:11:29,131 - INFO - Prediction completed in 0.01s
2024-12-27 21:11:29,139 - INFO - Poison rate 0.01 completed in 3.82s
2024-12-27 21:11:29,139 - INFO - 
Processing poison rate: 0.03
2024-12-27 21:11:29,141 - INFO - Total number of labels flipped: 150
2024-12-27 21:11:29,141 - INFO - Label flipping completed in 0.00s
2024-12-27 21:11:29,142 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:11:29,142 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:11:29,758 - INFO - Feature scaling completed in 0.62s
2024-12-27 21:11:29,758 - INFO - Starting feature selection (k=50)
2024-12-27 21:11:29,771 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:11:29,771 - INFO - Starting anomaly detection
2024-12-27 21:11:31,925 - INFO - Anomaly detection completed in 2.15s
2024-12-27 21:11:31,925 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:11:31,925 - INFO - Total fit_transform time: 2.78s
2024-12-27 21:11:31,925 - INFO - Training set processing completed in 2.78s
2024-12-27 21:11:31,925 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 21:11:31,926 - INFO - Memory usage at start_fit: CPU 3108.8 MB, GPU 47.5 MB
2024-12-27 21:11:31,927 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:11:31,927 - INFO - Number of unique classes: 10
2024-12-27 21:11:32,030 - INFO - Fitted scaler and transformed data
2024-12-27 21:11:32,030 - INFO - Scaling time: 0.10s
2024-12-27 21:11:32,252 - INFO - Epoch 1/25, Train Loss: 1.6060, Val Loss: 1.1083
2024-12-27 21:11:32,481 - INFO - Epoch 2/25, Train Loss: 0.6173, Val Loss: 0.9918
2024-12-27 21:11:32,671 - INFO - Epoch 3/25, Train Loss: 0.2922, Val Loss: 0.9743
2024-12-27 21:11:32,864 - INFO - Epoch 4/25, Train Loss: 0.1694, Val Loss: 0.8662
2024-12-27 21:11:33,056 - INFO - Epoch 5/25, Train Loss: 0.0953, Val Loss: 0.9130
2024-12-27 21:11:33,284 - INFO - Epoch 6/25, Train Loss: 0.0518, Val Loss: 0.8603
2024-12-27 21:11:33,284 - INFO - Early stopping triggered at epoch 6
2024-12-27 21:11:33,284 - INFO - Training completed in 1.36s
2024-12-27 21:11:33,284 - INFO - Final memory usage: CPU 3108.8 MB, GPU 48.1 MB
2024-12-27 21:11:33,285 - INFO - Model training completed in 1.36s
2024-12-27 21:11:33,292 - INFO - Prediction completed in 0.01s
2024-12-27 21:11:33,300 - INFO - Poison rate 0.03 completed in 4.16s
2024-12-27 21:11:33,300 - INFO - 
Processing poison rate: 0.05
2024-12-27 21:11:33,304 - INFO - Total number of labels flipped: 250
2024-12-27 21:11:33,304 - INFO - Label flipping completed in 0.00s
2024-12-27 21:11:33,304 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:11:33,304 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:11:33,941 - INFO - Feature scaling completed in 0.64s
2024-12-27 21:11:33,941 - INFO - Starting feature selection (k=50)
2024-12-27 21:11:33,955 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:11:33,955 - INFO - Starting anomaly detection
2024-12-27 21:11:36,094 - INFO - Anomaly detection completed in 2.14s
2024-12-27 21:11:36,094 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:11:36,094 - INFO - Total fit_transform time: 2.79s
2024-12-27 21:11:36,094 - INFO - Training set processing completed in 2.79s
2024-12-27 21:11:36,094 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 21:11:36,096 - INFO - Memory usage at start_fit: CPU 3108.8 MB, GPU 47.5 MB
2024-12-27 21:11:36,096 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:11:36,097 - INFO - Number of unique classes: 10
2024-12-27 21:11:36,190 - INFO - Fitted scaler and transformed data
2024-12-27 21:11:36,190 - INFO - Scaling time: 0.09s
2024-12-27 21:11:36,397 - INFO - Epoch 1/25, Train Loss: 2.0883, Val Loss: 1.9189
2024-12-27 21:11:36,574 - INFO - Epoch 2/25, Train Loss: 0.7508, Val Loss: 1.7798
2024-12-27 21:11:36,755 - INFO - Epoch 3/25, Train Loss: 0.4063, Val Loss: 1.6190
2024-12-27 21:11:36,936 - INFO - Epoch 4/25, Train Loss: 0.2178, Val Loss: 1.6187
2024-12-27 21:11:37,145 - INFO - Epoch 5/25, Train Loss: 0.1221, Val Loss: 1.5614
2024-12-27 21:11:37,331 - INFO - Epoch 6/25, Train Loss: 0.1017, Val Loss: 1.5960
2024-12-27 21:11:37,519 - INFO - Epoch 7/25, Train Loss: 0.0571, Val Loss: 1.6684
2024-12-27 21:11:37,519 - INFO - Early stopping triggered at epoch 7
2024-12-27 21:11:37,519 - INFO - Training completed in 1.42s
2024-12-27 21:11:37,520 - INFO - Final memory usage: CPU 3108.8 MB, GPU 48.1 MB
2024-12-27 21:11:37,520 - INFO - Model training completed in 1.43s
2024-12-27 21:11:37,527 - INFO - Prediction completed in 0.01s
2024-12-27 21:11:37,534 - INFO - Poison rate 0.05 completed in 4.23s
2024-12-27 21:11:37,534 - INFO - 
Processing poison rate: 0.07
2024-12-27 21:11:37,539 - INFO - Total number of labels flipped: 350
2024-12-27 21:11:37,539 - INFO - Label flipping completed in 0.00s
2024-12-27 21:11:37,539 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:11:37,539 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:11:38,136 - INFO - Feature scaling completed in 0.60s
2024-12-27 21:11:38,136 - INFO - Starting feature selection (k=50)
2024-12-27 21:11:38,144 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:11:38,145 - INFO - Starting anomaly detection
2024-12-27 21:11:40,021 - INFO - Anomaly detection completed in 1.88s
2024-12-27 21:11:40,021 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:11:40,021 - INFO - Total fit_transform time: 2.48s
2024-12-27 21:11:40,021 - INFO - Training set processing completed in 2.48s
2024-12-27 21:11:40,021 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 21:11:40,023 - INFO - Memory usage at start_fit: CPU 3108.8 MB, GPU 47.5 MB
2024-12-27 21:11:40,023 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:11:40,024 - INFO - Number of unique classes: 10
2024-12-27 21:11:40,125 - INFO - Fitted scaler and transformed data
2024-12-27 21:11:40,126 - INFO - Scaling time: 0.10s
2024-12-27 21:11:40,323 - INFO - Epoch 1/25, Train Loss: 2.5766, Val Loss: 3.1781
2024-12-27 21:11:40,509 - INFO - Epoch 2/25, Train Loss: 1.0772, Val Loss: 2.8118
2024-12-27 21:11:40,713 - INFO - Epoch 3/25, Train Loss: 0.5207, Val Loss: 2.7047
2024-12-27 21:11:40,911 - INFO - Epoch 4/25, Train Loss: 0.2844, Val Loss: 2.6779
2024-12-27 21:11:41,096 - INFO - Epoch 5/25, Train Loss: 0.1860, Val Loss: 2.6111
2024-12-27 21:11:41,266 - INFO - Epoch 6/25, Train Loss: 0.1251, Val Loss: 2.7697
2024-12-27 21:11:41,439 - INFO - Epoch 7/25, Train Loss: 0.0913, Val Loss: 2.7660
2024-12-27 21:11:41,439 - INFO - Early stopping triggered at epoch 7
2024-12-27 21:11:41,439 - INFO - Training completed in 1.42s
2024-12-27 21:11:41,440 - INFO - Final memory usage: CPU 3108.8 MB, GPU 48.1 MB
2024-12-27 21:11:41,440 - INFO - Model training completed in 1.42s
2024-12-27 21:11:41,448 - INFO - Prediction completed in 0.01s
2024-12-27 21:11:41,455 - INFO - Poison rate 0.07 completed in 3.92s
2024-12-27 21:11:41,455 - INFO - 
Processing poison rate: 0.1
2024-12-27 21:11:41,461 - INFO - Total number of labels flipped: 500
2024-12-27 21:11:41,461 - INFO - Label flipping completed in 0.01s
2024-12-27 21:11:41,461 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:11:41,461 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:11:42,066 - INFO - Feature scaling completed in 0.60s
2024-12-27 21:11:42,066 - INFO - Starting feature selection (k=50)
2024-12-27 21:11:42,079 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:11:42,080 - INFO - Starting anomaly detection
2024-12-27 21:11:44,152 - INFO - Anomaly detection completed in 2.07s
2024-12-27 21:11:44,152 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:11:44,152 - INFO - Total fit_transform time: 2.69s
2024-12-27 21:11:44,152 - INFO - Training set processing completed in 2.69s
2024-12-27 21:11:44,152 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 21:11:44,154 - INFO - Memory usage at start_fit: CPU 3108.8 MB, GPU 47.5 MB
2024-12-27 21:11:44,154 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:11:44,155 - INFO - Number of unique classes: 10
2024-12-27 21:11:44,252 - INFO - Fitted scaler and transformed data
2024-12-27 21:11:44,252 - INFO - Scaling time: 0.10s
2024-12-27 21:11:44,436 - INFO - Epoch 1/25, Train Loss: 3.8826, Val Loss: 4.4088
2024-12-27 21:11:44,633 - INFO - Epoch 2/25, Train Loss: 1.4253, Val Loss: 3.3797
2024-12-27 21:11:44,825 - INFO - Epoch 3/25, Train Loss: 0.5952, Val Loss: 3.1745
2024-12-27 21:11:45,012 - INFO - Epoch 4/25, Train Loss: 0.3587, Val Loss: 2.9598
2024-12-27 21:11:45,196 - INFO - Epoch 5/25, Train Loss: 0.2630, Val Loss: 2.9201
2024-12-27 21:11:45,370 - INFO - Epoch 6/25, Train Loss: 0.2297, Val Loss: 3.0985
2024-12-27 21:11:45,545 - INFO - Epoch 7/25, Train Loss: 0.1901, Val Loss: 3.0634
2024-12-27 21:11:45,545 - INFO - Early stopping triggered at epoch 7
2024-12-27 21:11:45,545 - INFO - Training completed in 1.39s
2024-12-27 21:11:45,546 - INFO - Final memory usage: CPU 3108.8 MB, GPU 48.1 MB
2024-12-27 21:11:45,546 - INFO - Model training completed in 1.39s
2024-12-27 21:11:45,555 - INFO - Prediction completed in 0.01s
2024-12-27 21:11:45,562 - INFO - Poison rate 0.1 completed in 4.11s
2024-12-27 21:11:45,562 - INFO - 
Processing poison rate: 0.2
2024-12-27 21:11:45,574 - INFO - Total number of labels flipped: 1000
2024-12-27 21:11:45,575 - INFO - Label flipping completed in 0.01s
2024-12-27 21:11:45,575 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:11:45,575 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:11:46,121 - INFO - Feature scaling completed in 0.55s
2024-12-27 21:11:46,121 - INFO - Starting feature selection (k=50)
2024-12-27 21:11:46,135 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:11:46,135 - INFO - Starting anomaly detection
2024-12-27 21:11:47,721 - INFO - Anomaly detection completed in 1.59s
2024-12-27 21:11:47,721 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:11:47,722 - INFO - Total fit_transform time: 2.15s
2024-12-27 21:11:47,722 - INFO - Training set processing completed in 2.15s
2024-12-27 21:11:47,722 - INFO - Fitting SVMWrapper model with data shape: (5000, 1280)
2024-12-27 21:11:47,723 - INFO - Memory usage at start_fit: CPU 3108.8 MB, GPU 47.5 MB
2024-12-27 21:11:47,723 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:11:47,723 - INFO - Number of unique classes: 10
2024-12-27 21:11:47,814 - INFO - Fitted scaler and transformed data
2024-12-27 21:11:47,814 - INFO - Scaling time: 0.09s
2024-12-27 21:11:48,002 - INFO - Epoch 1/25, Train Loss: 5.6678, Val Loss: 5.1550
2024-12-27 21:11:48,189 - INFO - Epoch 2/25, Train Loss: 2.1566, Val Loss: 5.3806
2024-12-27 21:11:48,367 - INFO - Epoch 3/25, Train Loss: 1.3163, Val Loss: 5.2420
2024-12-27 21:11:48,367 - INFO - Early stopping triggered at epoch 3
2024-12-27 21:11:48,367 - INFO - Training completed in 0.64s
2024-12-27 21:11:48,367 - INFO - Final memory usage: CPU 3108.8 MB, GPU 48.1 MB
2024-12-27 21:11:48,368 - INFO - Model training completed in 0.65s
2024-12-27 21:11:48,375 - INFO - Prediction completed in 0.01s
2024-12-27 21:11:48,383 - INFO - Poison rate 0.2 completed in 2.82s
2024-12-27 21:11:48,383 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 21:11:48,383 - INFO - Total evaluation time: 40.58s
2024-12-27 21:11:48,385 - INFO - 
Progress: 94.8% - Evaluating ImageNette with LogisticRegression (standard mode, iteration 1/1)
2024-12-27 21:11:48,445 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 21:11:48,515 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 21:11:48,600 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 21:11:48,600 - INFO - Dataset type: image
2024-12-27 21:11:48,600 - INFO - Sample size: 5000
2024-12-27 21:11:48,600 - INFO - Using device: cuda
2024-12-27 21:11:48,602 - INFO - Loading datasets...
2024-12-27 21:11:48,627 - INFO - Dataset loading completed in 0.02s
2024-12-27 21:11:48,627 - INFO - Extracting validation features...
2024-12-27 21:11:48,627 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:19,  1.61it/s]Extracting features:  19%|█▉        | 6/32 [00:00<00:02,  9.20it/s]Extracting features:  31%|███▏      | 10/32 [00:01<00:01, 12.00it/s]Extracting features:  44%|████▍     | 14/32 [00:01<00:01, 12.19it/s]Extracting features:  56%|█████▋    | 18/32 [00:01<00:01, 12.22it/s]Extracting features:  69%|██████▉   | 22/32 [00:02<00:00, 10.71it/s]Extracting features:  81%|████████▏ | 26/32 [00:02<00:00, 12.66it/s]Extracting features:  94%|█████████▍| 30/32 [00:02<00:00, 14.26it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 11.98it/s]
2024-12-27 21:11:51,304 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 21:11:51,305 - INFO - Validation feature extraction completed in 2.68s
2024-12-27 21:11:51,305 - INFO - Extracting training features...
2024-12-27 21:11:51,306 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:02,  2.50it/s]Extracting features:   2%|▏         | 3/157 [00:00<00:23,  6.56it/s]Extracting features:   3%|▎         | 5/157 [00:00<00:20,  7.38it/s]Extracting features:   4%|▍         | 7/157 [00:00<00:18,  8.19it/s]Extracting features:   6%|▋         | 10/157 [00:01<00:12, 12.02it/s]Extracting features:   8%|▊         | 12/157 [00:01<00:12, 11.24it/s]Extracting features:  10%|▉         | 15/157 [00:01<00:11, 12.09it/s]Extracting features:  11%|█         | 17/157 [00:01<00:11, 12.64it/s]Extracting features:  12%|█▏        | 19/157 [00:01<00:10, 13.78it/s]Extracting features:  13%|█▎        | 21/157 [00:02<00:12, 10.91it/s]Extracting features:  15%|█▌        | 24/157 [00:02<00:11, 12.01it/s]Extracting features:  18%|█▊        | 28/157 [00:02<00:09, 13.28it/s]Extracting features:  20%|██        | 32/157 [00:02<00:08, 15.55it/s]Extracting features:  23%|██▎       | 36/157 [00:02<00:07, 17.27it/s]Extracting features:  25%|██▌       | 40/157 [00:03<00:06, 17.78it/s]Extracting features:  28%|██▊       | 44/157 [00:03<00:06, 17.67it/s]Extracting features:  31%|███       | 48/157 [00:03<00:06, 17.64it/s]Extracting features:  33%|███▎      | 52/157 [00:03<00:06, 16.14it/s]Extracting features:  36%|███▌      | 56/157 [00:04<00:05, 17.75it/s]Extracting features:  38%|███▊      | 60/157 [00:04<00:06, 16.13it/s]Extracting features:  41%|████      | 64/157 [00:04<00:05, 16.12it/s]Extracting features:  42%|████▏     | 66/157 [00:04<00:05, 15.39it/s]Extracting features:  43%|████▎     | 68/157 [00:04<00:05, 15.36it/s]Extracting features:  45%|████▍     | 70/157 [00:05<00:06, 14.34it/s]Extracting features:  46%|████▋     | 73/157 [00:05<00:05, 16.71it/s]Extracting features:  48%|████▊     | 75/157 [00:05<00:05, 15.33it/s]Extracting features:  49%|████▉     | 77/157 [00:05<00:05, 15.32it/s]Extracting features:  50%|█████     | 79/157 [00:05<00:05, 13.79it/s]Extracting features:  52%|█████▏    | 81/157 [00:05<00:05, 14.16it/s]Extracting features:  53%|█████▎    | 83/157 [00:05<00:05, 12.92it/s]Extracting features:  55%|█████▍    | 86/157 [00:06<00:06, 11.12it/s]Extracting features:  57%|█████▋    | 90/157 [00:06<00:05, 12.87it/s]Extracting features:  59%|█████▉    | 93/157 [00:06<00:04, 15.46it/s]Extracting features:  61%|██████    | 95/157 [00:06<00:04, 14.63it/s]Extracting features:  62%|██████▏   | 97/157 [00:06<00:03, 15.29it/s]Extracting features:  63%|██████▎   | 99/157 [00:07<00:04, 13.75it/s]Extracting features:  65%|██████▍   | 102/157 [00:07<00:04, 13.72it/s]Extracting features:  67%|██████▋   | 105/157 [00:07<00:03, 16.38it/s]Extracting features:  68%|██████▊   | 107/157 [00:07<00:03, 14.19it/s]Extracting features:  70%|███████   | 110/157 [00:07<00:04, 11.50it/s]Extracting features:  73%|███████▎  | 114/157 [00:08<00:03, 12.98it/s]Extracting features:  75%|███████▌  | 118/157 [00:08<00:02, 13.90it/s]Extracting features:  76%|███████▋  | 120/157 [00:08<00:02, 13.68it/s]Extracting features:  78%|███████▊  | 122/157 [00:08<00:02, 13.84it/s]Extracting features:  79%|███████▉  | 124/157 [00:08<00:02, 12.84it/s]Extracting features:  81%|████████  | 127/157 [00:09<00:02, 12.97it/s]Extracting features:  83%|████████▎ | 131/157 [00:09<00:01, 15.26it/s]Extracting features:  86%|████████▌ | 135/157 [00:09<00:01, 16.91it/s]Extracting features:  89%|████████▊ | 139/157 [00:09<00:01, 17.73it/s]Extracting features:  91%|█████████ | 143/157 [00:10<00:00, 17.58it/s]Extracting features:  94%|█████████▎| 147/157 [00:10<00:00, 13.91it/s]Extracting features:  96%|█████████▌| 151/157 [00:10<00:00, 13.77it/s]Extracting features:  99%|█████████▊| 155/157 [00:10<00:00, 14.49it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 14.16it/s]
2024-12-27 21:12:02,410 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 21:12:02,410 - INFO - Training feature extraction completed in 11.10s
2024-12-27 21:12:02,410 - INFO - Creating model for classifier: LogisticRegression
2024-12-27 21:12:02,410 - INFO - Using device: cuda
2024-12-27 21:12:02,410 - INFO - 
Processing poison rate: 0.0
2024-12-27 21:12:02,410 - INFO - Training set processing completed in 0.00s
2024-12-27 21:12:02,410 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 21:12:02,412 - INFO - Memory usage at start_fit: CPU 3109.7 MB, GPU 47.3 MB
2024-12-27 21:12:02,412 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:12:02,413 - INFO - Number of unique classes: 10
2024-12-27 21:12:02,508 - INFO - Fitted scaler and transformed data
2024-12-27 21:12:02,508 - INFO - Scaling time: 0.09s
2024-12-27 21:12:02,628 - INFO - Epoch 1/200, Train Loss: 0.1319, Val Loss: 0.0537
2024-12-27 21:12:02,756 - INFO - Epoch 2/200, Train Loss: 0.0080, Val Loss: 0.0397
2024-12-27 21:12:02,890 - INFO - Epoch 3/200, Train Loss: 0.0008, Val Loss: 0.0553
2024-12-27 21:12:03,010 - INFO - Epoch 4/200, Train Loss: 0.0001, Val Loss: 0.0556
2024-12-27 21:12:03,011 - INFO - Early stopping triggered at epoch 4
2024-12-27 21:12:03,011 - INFO - Training completed in 0.60s
2024-12-27 21:12:03,011 - INFO - Final memory usage: CPU 3113.9 MB, GPU 48.1 MB
2024-12-27 21:12:03,011 - INFO - Model training completed in 0.60s
2024-12-27 21:12:03,019 - INFO - Prediction completed in 0.01s
2024-12-27 21:12:03,027 - INFO - Poison rate 0.0 completed in 0.62s
2024-12-27 21:12:03,027 - INFO - 
Processing poison rate: 0.01
2024-12-27 21:12:03,031 - INFO - Total number of labels flipped: 50
2024-12-27 21:12:03,031 - INFO - Label flipping completed in 0.00s
2024-12-27 21:12:03,032 - INFO - Training set processing completed in 0.00s
2024-12-27 21:12:03,032 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 21:12:03,033 - INFO - Memory usage at start_fit: CPU 3113.9 MB, GPU 47.5 MB
2024-12-27 21:12:03,034 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:12:03,034 - INFO - Number of unique classes: 10
2024-12-27 21:12:03,149 - INFO - Fitted scaler and transformed data
2024-12-27 21:12:03,150 - INFO - Scaling time: 0.11s
2024-12-27 21:12:03,278 - INFO - Epoch 1/200, Train Loss: 0.3414, Val Loss: 0.2416
2024-12-27 21:12:03,381 - INFO - Epoch 2/200, Train Loss: 0.0981, Val Loss: 0.2252
2024-12-27 21:12:03,496 - INFO - Epoch 3/200, Train Loss: 0.0394, Val Loss: 0.1998
2024-12-27 21:12:03,613 - INFO - Epoch 4/200, Train Loss: 0.0197, Val Loss: 0.1675
2024-12-27 21:12:03,719 - INFO - Epoch 5/200, Train Loss: 0.0042, Val Loss: 0.1892
2024-12-27 21:12:03,831 - INFO - Epoch 6/200, Train Loss: 0.0022, Val Loss: 0.1920
2024-12-27 21:12:03,831 - INFO - Early stopping triggered at epoch 6
2024-12-27 21:12:03,832 - INFO - Training completed in 0.80s
2024-12-27 21:12:03,832 - INFO - Final memory usage: CPU 3113.9 MB, GPU 48.1 MB
2024-12-27 21:12:03,832 - INFO - Model training completed in 0.80s
2024-12-27 21:12:03,839 - INFO - Prediction completed in 0.01s
2024-12-27 21:12:03,846 - INFO - Poison rate 0.01 completed in 0.82s
2024-12-27 21:12:03,846 - INFO - 
Processing poison rate: 0.03
2024-12-27 21:12:03,851 - INFO - Total number of labels flipped: 150
2024-12-27 21:12:03,851 - INFO - Label flipping completed in 0.00s
2024-12-27 21:12:03,852 - INFO - Training set processing completed in 0.00s
2024-12-27 21:12:03,852 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 21:12:03,853 - INFO - Memory usage at start_fit: CPU 3113.9 MB, GPU 47.5 MB
2024-12-27 21:12:03,853 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:12:03,854 - INFO - Number of unique classes: 10
2024-12-27 21:12:03,964 - INFO - Fitted scaler and transformed data
2024-12-27 21:12:03,964 - INFO - Scaling time: 0.11s
2024-12-27 21:12:04,093 - INFO - Epoch 1/200, Train Loss: 0.6420, Val Loss: 0.5903
2024-12-27 21:12:04,225 - INFO - Epoch 2/200, Train Loss: 0.2395, Val Loss: 0.5124
2024-12-27 21:12:04,334 - INFO - Epoch 3/200, Train Loss: 0.1065, Val Loss: 0.5536
2024-12-27 21:12:04,454 - INFO - Epoch 4/200, Train Loss: 0.0456, Val Loss: 0.5886
2024-12-27 21:12:04,454 - INFO - Early stopping triggered at epoch 4
2024-12-27 21:12:04,454 - INFO - Training completed in 0.60s
2024-12-27 21:12:04,454 - INFO - Final memory usage: CPU 3113.9 MB, GPU 48.1 MB
2024-12-27 21:12:04,455 - INFO - Model training completed in 0.60s
2024-12-27 21:12:04,461 - INFO - Prediction completed in 0.01s
2024-12-27 21:12:04,473 - INFO - Poison rate 0.03 completed in 0.63s
2024-12-27 21:12:04,473 - INFO - 
Processing poison rate: 0.05
2024-12-27 21:12:04,477 - INFO - Total number of labels flipped: 250
2024-12-27 21:12:04,477 - INFO - Label flipping completed in 0.00s
2024-12-27 21:12:04,477 - INFO - Training set processing completed in 0.00s
2024-12-27 21:12:04,477 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 21:12:04,478 - INFO - Memory usage at start_fit: CPU 3113.9 MB, GPU 47.5 MB
2024-12-27 21:12:04,478 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:12:04,478 - INFO - Number of unique classes: 10
2024-12-27 21:12:04,568 - INFO - Fitted scaler and transformed data
2024-12-27 21:12:04,569 - INFO - Scaling time: 0.09s
2024-12-27 21:12:04,713 - INFO - Epoch 1/200, Train Loss: 0.8169, Val Loss: 0.7304
2024-12-27 21:12:04,831 - INFO - Epoch 2/200, Train Loss: 0.3143, Val Loss: 0.6645
2024-12-27 21:12:04,945 - INFO - Epoch 3/200, Train Loss: 0.1817, Val Loss: 0.7265
2024-12-27 21:12:05,061 - INFO - Epoch 4/200, Train Loss: 0.1108, Val Loss: 0.7476
2024-12-27 21:12:05,061 - INFO - Early stopping triggered at epoch 4
2024-12-27 21:12:05,061 - INFO - Training completed in 0.58s
2024-12-27 21:12:05,062 - INFO - Final memory usage: CPU 3113.9 MB, GPU 48.1 MB
2024-12-27 21:12:05,062 - INFO - Model training completed in 0.59s
2024-12-27 21:12:05,069 - INFO - Prediction completed in 0.01s
2024-12-27 21:12:05,076 - INFO - Poison rate 0.05 completed in 0.60s
2024-12-27 21:12:05,077 - INFO - 
Processing poison rate: 0.07
2024-12-27 21:12:05,087 - INFO - Total number of labels flipped: 350
2024-12-27 21:12:05,087 - INFO - Label flipping completed in 0.01s
2024-12-27 21:12:05,087 - INFO - Training set processing completed in 0.00s
2024-12-27 21:12:05,088 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 21:12:05,089 - INFO - Memory usage at start_fit: CPU 3113.9 MB, GPU 47.5 MB
2024-12-27 21:12:05,089 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:12:05,090 - INFO - Number of unique classes: 10
2024-12-27 21:12:05,205 - INFO - Fitted scaler and transformed data
2024-12-27 21:12:05,205 - INFO - Scaling time: 0.11s
2024-12-27 21:12:05,343 - INFO - Epoch 1/200, Train Loss: 0.9146, Val Loss: 0.8790
2024-12-27 21:12:05,464 - INFO - Epoch 2/200, Train Loss: 0.3834, Val Loss: 1.0398
2024-12-27 21:12:05,570 - INFO - Epoch 3/200, Train Loss: 0.2426, Val Loss: 1.0058
2024-12-27 21:12:05,571 - INFO - Early stopping triggered at epoch 3
2024-12-27 21:12:05,571 - INFO - Training completed in 0.48s
2024-12-27 21:12:05,571 - INFO - Final memory usage: CPU 3113.9 MB, GPU 48.1 MB
2024-12-27 21:12:05,571 - INFO - Model training completed in 0.48s
2024-12-27 21:12:05,577 - INFO - Prediction completed in 0.01s
2024-12-27 21:12:05,597 - INFO - Poison rate 0.07 completed in 0.52s
2024-12-27 21:12:05,597 - INFO - 
Processing poison rate: 0.1
2024-12-27 21:12:05,614 - INFO - Total number of labels flipped: 500
2024-12-27 21:12:05,615 - INFO - Label flipping completed in 0.02s
2024-12-27 21:12:05,615 - INFO - Training set processing completed in 0.00s
2024-12-27 21:12:05,615 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 21:12:05,616 - INFO - Memory usage at start_fit: CPU 3113.9 MB, GPU 47.5 MB
2024-12-27 21:12:05,616 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:12:05,617 - INFO - Number of unique classes: 10
2024-12-27 21:12:05,711 - INFO - Fitted scaler and transformed data
2024-12-27 21:12:05,711 - INFO - Scaling time: 0.09s
2024-12-27 21:12:05,857 - INFO - Epoch 1/200, Train Loss: 1.2242, Val Loss: 1.0828
2024-12-27 21:12:05,987 - INFO - Epoch 2/200, Train Loss: 0.5552, Val Loss: 1.1347
2024-12-27 21:12:06,090 - INFO - Epoch 3/200, Train Loss: 0.3685, Val Loss: 1.1877
2024-12-27 21:12:06,091 - INFO - Early stopping triggered at epoch 3
2024-12-27 21:12:06,091 - INFO - Training completed in 0.47s
2024-12-27 21:12:06,091 - INFO - Final memory usage: CPU 3113.9 MB, GPU 48.1 MB
2024-12-27 21:12:06,091 - INFO - Model training completed in 0.48s
2024-12-27 21:12:06,098 - INFO - Prediction completed in 0.01s
2024-12-27 21:12:06,112 - INFO - Poison rate 0.1 completed in 0.51s
2024-12-27 21:12:06,112 - INFO - 
Processing poison rate: 0.2
2024-12-27 21:12:06,125 - INFO - Total number of labels flipped: 1000
2024-12-27 21:12:06,126 - INFO - Label flipping completed in 0.01s
2024-12-27 21:12:06,126 - INFO - Training set processing completed in 0.00s
2024-12-27 21:12:06,126 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 21:12:06,127 - INFO - Memory usage at start_fit: CPU 3113.9 MB, GPU 47.5 MB
2024-12-27 21:12:06,127 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:12:06,127 - INFO - Number of unique classes: 10
2024-12-27 21:12:06,206 - INFO - Fitted scaler and transformed data
2024-12-27 21:12:06,206 - INFO - Scaling time: 0.08s
2024-12-27 21:12:06,351 - INFO - Epoch 1/200, Train Loss: 1.6586, Val Loss: 1.6106
2024-12-27 21:12:06,504 - INFO - Epoch 2/200, Train Loss: 0.9350, Val Loss: 1.7440
2024-12-27 21:12:06,629 - INFO - Epoch 3/200, Train Loss: 0.7086, Val Loss: 1.9282
2024-12-27 21:12:06,630 - INFO - Early stopping triggered at epoch 3
2024-12-27 21:12:06,630 - INFO - Training completed in 0.50s
2024-12-27 21:12:06,630 - INFO - Final memory usage: CPU 3113.9 MB, GPU 48.1 MB
2024-12-27 21:12:06,630 - INFO - Model training completed in 0.50s
2024-12-27 21:12:06,646 - INFO - Prediction completed in 0.02s
2024-12-27 21:12:06,659 - INFO - Poison rate 0.2 completed in 0.55s
2024-12-27 21:12:06,660 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 21:12:06,660 - INFO - Total evaluation time: 18.06s
2024-12-27 21:12:06,662 - INFO - 
Progress: 95.8% - Evaluating ImageNette with LogisticRegression (dynadetect mode, iteration 1/1)
2024-12-27 21:12:06,726 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 21:12:06,798 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 21:12:06,889 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 21:12:06,889 - INFO - Dataset type: image
2024-12-27 21:12:06,889 - INFO - Sample size: 5000
2024-12-27 21:12:06,889 - INFO - Using device: cuda
2024-12-27 21:12:06,891 - INFO - Loading datasets...
2024-12-27 21:12:06,916 - INFO - Dataset loading completed in 0.02s
2024-12-27 21:12:06,916 - INFO - Extracting validation features...
2024-12-27 21:12:06,916 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:18,  1.66it/s]Extracting features:   6%|▋         | 2/32 [00:00<00:09,  3.12it/s]Extracting features:  22%|██▏       | 7/32 [00:00<00:01, 12.81it/s]Extracting features:  31%|███▏      | 10/32 [00:01<00:01, 13.44it/s]Extracting features:  41%|████      | 13/32 [00:01<00:01, 12.88it/s]Extracting features:  53%|█████▎    | 17/32 [00:01<00:01, 13.90it/s]Extracting features:  66%|██████▌   | 21/32 [00:01<00:00, 13.80it/s]Extracting features:  78%|███████▊  | 25/32 [00:02<00:00, 12.94it/s]Extracting features:  91%|█████████ | 29/32 [00:02<00:00, 14.35it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 12.81it/s]
2024-12-27 21:12:09,417 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 21:12:09,417 - INFO - Validation feature extraction completed in 2.50s
2024-12-27 21:12:09,417 - INFO - Extracting training features...
2024-12-27 21:12:09,417 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:05,  2.39it/s]Extracting features:   3%|▎         | 5/157 [00:00<00:17,  8.90it/s]Extracting features:   4%|▍         | 7/157 [00:00<00:17,  8.59it/s]Extracting features:   6%|▋         | 10/157 [00:01<00:12, 11.46it/s]Extracting features:   8%|▊         | 12/157 [00:01<00:11, 13.04it/s]Extracting features:   9%|▉         | 14/157 [00:01<00:10, 13.27it/s]Extracting features:  11%|█         | 17/157 [00:01<00:09, 14.58it/s]Extracting features:  12%|█▏        | 19/157 [00:01<00:08, 15.34it/s]Extracting features:  13%|█▎        | 21/157 [00:01<00:09, 14.74it/s]Extracting features:  15%|█▍        | 23/157 [00:01<00:10, 12.61it/s]Extracting features:  17%|█▋        | 26/157 [00:02<00:09, 13.77it/s]Extracting features:  19%|█▉        | 30/157 [00:02<00:08, 14.20it/s]Extracting features:  22%|██▏       | 34/157 [00:02<00:07, 16.07it/s]Extracting features:  24%|██▍       | 38/157 [00:02<00:06, 17.79it/s]Extracting features:  27%|██▋       | 42/157 [00:02<00:06, 18.57it/s]Extracting features:  29%|██▉       | 46/157 [00:03<00:06, 18.23it/s]Extracting features:  32%|███▏      | 50/157 [00:03<00:06, 17.30it/s]Extracting features:  34%|███▍      | 54/157 [00:03<00:05, 17.56it/s]Extracting features:  37%|███▋      | 58/157 [00:04<00:07, 14.12it/s]Extracting features:  39%|███▉      | 62/157 [00:04<00:06, 15.54it/s]Extracting features:  42%|████▏     | 66/157 [00:04<00:06, 14.64it/s]Extracting features:  45%|████▍     | 70/157 [00:04<00:05, 14.66it/s]Extracting features:  47%|████▋     | 74/157 [00:05<00:05, 15.13it/s]Extracting features:  48%|████▊     | 76/157 [00:05<00:05, 15.50it/s]Extracting features:  50%|████▉     | 78/157 [00:05<00:05, 15.42it/s]Extracting features:  51%|█████     | 80/157 [00:05<00:05, 14.99it/s]Extracting features:  53%|█████▎    | 83/157 [00:05<00:05, 13.86it/s]Extracting features:  55%|█████▍    | 86/157 [00:05<00:04, 15.52it/s]Extracting features:  56%|█████▌    | 88/157 [00:06<00:05, 13.60it/s]Extracting features:  57%|█████▋    | 90/157 [00:06<00:05, 12.70it/s]Extracting features:  60%|█████▉    | 94/157 [00:06<00:05, 12.13it/s]Extracting features:  62%|██████▏   | 98/157 [00:07<00:05, 11.66it/s]Extracting features:  65%|██████▍   | 102/157 [00:07<00:05, 10.36it/s]Extracting features:  68%|██████▊   | 106/157 [00:07<00:04, 11.15it/s]Extracting features:  70%|███████   | 110/157 [00:08<00:04, 11.53it/s]Extracting features:  73%|███████▎  | 114/157 [00:08<00:03, 11.67it/s]Extracting features:  75%|███████▌  | 118/157 [00:08<00:03, 12.57it/s]Extracting features:  78%|███████▊  | 122/157 [00:09<00:02, 12.35it/s]Extracting features:  80%|████████  | 126/157 [00:09<00:02, 13.79it/s]Extracting features:  83%|████████▎ | 130/157 [00:09<00:01, 14.11it/s]Extracting features:  85%|████████▌ | 134/157 [00:09<00:01, 16.04it/s]Extracting features:  88%|████████▊ | 138/157 [00:09<00:01, 16.12it/s]Extracting features:  90%|█████████ | 142/157 [00:10<00:00, 16.36it/s]Extracting features:  93%|█████████▎| 146/157 [00:10<00:00, 17.38it/s]Extracting features:  96%|█████████▌| 150/157 [00:10<00:00, 15.72it/s]Extracting features:  98%|█████████▊| 154/157 [00:10<00:00, 16.48it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 14.25it/s]
2024-12-27 21:12:20,446 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 21:12:20,446 - INFO - Training feature extraction completed in 11.03s
2024-12-27 21:12:20,446 - INFO - Creating model for classifier: LogisticRegression
2024-12-27 21:12:20,446 - INFO - Using device: cuda
2024-12-27 21:12:20,446 - INFO - 
Processing poison rate: 0.0
2024-12-27 21:12:20,446 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:12:20,446 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:12:21,054 - INFO - Feature scaling completed in 0.61s
2024-12-27 21:12:21,055 - INFO - Starting feature selection (k=50)
2024-12-27 21:12:21,060 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:12:21,061 - INFO - Starting anomaly detection
2024-12-27 21:12:22,971 - INFO - Anomaly detection completed in 1.91s
2024-12-27 21:12:22,971 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:12:22,971 - INFO - Total fit_transform time: 2.53s
2024-12-27 21:12:22,971 - INFO - Training set processing completed in 2.53s
2024-12-27 21:12:22,972 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 21:12:22,973 - INFO - Memory usage at start_fit: CPU 3111.3 MB, GPU 47.3 MB
2024-12-27 21:12:22,973 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:12:22,974 - INFO - Number of unique classes: 10
2024-12-27 21:12:23,069 - INFO - Fitted scaler and transformed data
2024-12-27 21:12:23,069 - INFO - Scaling time: 0.09s
2024-12-27 21:12:23,253 - INFO - Epoch 1/200, Train Loss: 0.1149, Val Loss: 0.0372
2024-12-27 21:12:23,455 - INFO - Epoch 2/200, Train Loss: 0.0037, Val Loss: 0.0453
2024-12-27 21:12:23,652 - INFO - Epoch 3/200, Train Loss: 0.0002, Val Loss: 0.0510
2024-12-27 21:12:23,652 - INFO - Early stopping triggered at epoch 3
2024-12-27 21:12:23,652 - INFO - Training completed in 0.68s
2024-12-27 21:12:23,653 - INFO - Final memory usage: CPU 3117.2 MB, GPU 48.1 MB
2024-12-27 21:12:23,654 - INFO - Model training completed in 0.68s
2024-12-27 21:12:23,672 - INFO - Prediction completed in 0.02s
2024-12-27 21:12:23,693 - INFO - Poison rate 0.0 completed in 3.25s
2024-12-27 21:12:23,694 - INFO - 
Processing poison rate: 0.01
2024-12-27 21:12:23,696 - INFO - Total number of labels flipped: 50
2024-12-27 21:12:23,697 - INFO - Label flipping completed in 0.00s
2024-12-27 21:12:23,697 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:12:23,697 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:12:24,357 - INFO - Feature scaling completed in 0.66s
2024-12-27 21:12:24,357 - INFO - Starting feature selection (k=50)
2024-12-27 21:12:24,363 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:12:24,363 - INFO - Starting anomaly detection
2024-12-27 21:12:25,626 - INFO - Anomaly detection completed in 1.26s
2024-12-27 21:12:25,626 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:12:25,626 - INFO - Total fit_transform time: 1.93s
2024-12-27 21:12:25,626 - INFO - Training set processing completed in 1.93s
2024-12-27 21:12:25,626 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 21:12:25,628 - INFO - Memory usage at start_fit: CPU 3117.2 MB, GPU 47.5 MB
2024-12-27 21:12:25,628 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:12:25,629 - INFO - Number of unique classes: 10
2024-12-27 21:12:25,721 - INFO - Fitted scaler and transformed data
2024-12-27 21:12:25,721 - INFO - Scaling time: 0.09s
2024-12-27 21:12:25,862 - INFO - Epoch 1/200, Train Loss: 0.3829, Val Loss: 0.3225
2024-12-27 21:12:25,984 - INFO - Epoch 2/200, Train Loss: 0.1087, Val Loss: 0.3565
2024-12-27 21:12:26,121 - INFO - Epoch 3/200, Train Loss: 0.0388, Val Loss: 0.3319
2024-12-27 21:12:26,121 - INFO - Early stopping triggered at epoch 3
2024-12-27 21:12:26,121 - INFO - Training completed in 0.49s
2024-12-27 21:12:26,121 - INFO - Final memory usage: CPU 3117.2 MB, GPU 48.1 MB
2024-12-27 21:12:26,122 - INFO - Model training completed in 0.50s
2024-12-27 21:12:26,129 - INFO - Prediction completed in 0.01s
2024-12-27 21:12:26,149 - INFO - Poison rate 0.01 completed in 2.45s
2024-12-27 21:12:26,149 - INFO - 
Processing poison rate: 0.03
2024-12-27 21:12:26,153 - INFO - Total number of labels flipped: 150
2024-12-27 21:12:26,153 - INFO - Label flipping completed in 0.00s
2024-12-27 21:12:26,153 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:12:26,153 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:12:26,712 - INFO - Feature scaling completed in 0.56s
2024-12-27 21:12:26,712 - INFO - Starting feature selection (k=50)
2024-12-27 21:12:26,724 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:12:26,724 - INFO - Starting anomaly detection
2024-12-27 21:12:28,755 - INFO - Anomaly detection completed in 2.03s
2024-12-27 21:12:28,755 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:12:28,755 - INFO - Total fit_transform time: 2.60s
2024-12-27 21:12:28,755 - INFO - Training set processing completed in 2.60s
2024-12-27 21:12:28,755 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 21:12:28,756 - INFO - Memory usage at start_fit: CPU 3117.2 MB, GPU 47.5 MB
2024-12-27 21:12:28,757 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:12:28,757 - INFO - Number of unique classes: 10
2024-12-27 21:12:28,860 - INFO - Fitted scaler and transformed data
2024-12-27 21:12:28,861 - INFO - Scaling time: 0.10s
2024-12-27 21:12:29,012 - INFO - Epoch 1/200, Train Loss: 0.5753, Val Loss: 0.5406
2024-12-27 21:12:29,161 - INFO - Epoch 2/200, Train Loss: 0.2182, Val Loss: 0.4880
2024-12-27 21:12:29,287 - INFO - Epoch 3/200, Train Loss: 0.1274, Val Loss: 0.5132
2024-12-27 21:12:29,407 - INFO - Epoch 4/200, Train Loss: 0.0799, Val Loss: 0.5947
2024-12-27 21:12:29,407 - INFO - Early stopping triggered at epoch 4
2024-12-27 21:12:29,407 - INFO - Training completed in 0.65s
2024-12-27 21:12:29,407 - INFO - Final memory usage: CPU 3117.2 MB, GPU 48.1 MB
2024-12-27 21:12:29,408 - INFO - Model training completed in 0.65s
2024-12-27 21:12:29,415 - INFO - Prediction completed in 0.01s
2024-12-27 21:12:29,436 - INFO - Poison rate 0.03 completed in 3.29s
2024-12-27 21:12:29,437 - INFO - 
Processing poison rate: 0.05
2024-12-27 21:12:29,446 - INFO - Total number of labels flipped: 250
2024-12-27 21:12:29,447 - INFO - Label flipping completed in 0.01s
2024-12-27 21:12:29,447 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:12:29,447 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:12:30,074 - INFO - Feature scaling completed in 0.63s
2024-12-27 21:12:30,075 - INFO - Starting feature selection (k=50)
2024-12-27 21:12:30,090 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:12:30,090 - INFO - Starting anomaly detection
2024-12-27 21:12:31,685 - INFO - Anomaly detection completed in 1.59s
2024-12-27 21:12:31,685 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:12:31,685 - INFO - Total fit_transform time: 2.24s
2024-12-27 21:12:31,685 - INFO - Training set processing completed in 2.24s
2024-12-27 21:12:31,685 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 21:12:31,686 - INFO - Memory usage at start_fit: CPU 3117.2 MB, GPU 47.5 MB
2024-12-27 21:12:31,686 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:12:31,686 - INFO - Number of unique classes: 10
2024-12-27 21:12:31,789 - INFO - Fitted scaler and transformed data
2024-12-27 21:12:31,789 - INFO - Scaling time: 0.10s
2024-12-27 21:12:31,928 - INFO - Epoch 1/200, Train Loss: 0.8539, Val Loss: 0.7536
2024-12-27 21:12:32,052 - INFO - Epoch 2/200, Train Loss: 0.2998, Val Loss: 0.6625
2024-12-27 21:12:32,186 - INFO - Epoch 3/200, Train Loss: 0.1798, Val Loss: 0.6918
2024-12-27 21:12:32,328 - INFO - Epoch 4/200, Train Loss: 0.1183, Val Loss: 0.7270
2024-12-27 21:12:32,329 - INFO - Early stopping triggered at epoch 4
2024-12-27 21:12:32,329 - INFO - Training completed in 0.64s
2024-12-27 21:12:32,329 - INFO - Final memory usage: CPU 3117.2 MB, GPU 48.1 MB
2024-12-27 21:12:32,329 - INFO - Model training completed in 0.64s
2024-12-27 21:12:32,341 - INFO - Prediction completed in 0.01s
2024-12-27 21:12:32,356 - INFO - Poison rate 0.05 completed in 2.92s
2024-12-27 21:12:32,356 - INFO - 
Processing poison rate: 0.07
2024-12-27 21:12:32,363 - INFO - Total number of labels flipped: 350
2024-12-27 21:12:32,363 - INFO - Label flipping completed in 0.01s
2024-12-27 21:12:32,363 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:12:32,363 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:12:32,932 - INFO - Feature scaling completed in 0.57s
2024-12-27 21:12:32,932 - INFO - Starting feature selection (k=50)
2024-12-27 21:12:32,941 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:12:32,941 - INFO - Starting anomaly detection
2024-12-27 21:12:34,972 - INFO - Anomaly detection completed in 2.03s
2024-12-27 21:12:34,972 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:12:34,972 - INFO - Total fit_transform time: 2.61s
2024-12-27 21:12:34,973 - INFO - Training set processing completed in 2.61s
2024-12-27 21:12:34,973 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 21:12:34,974 - INFO - Memory usage at start_fit: CPU 3117.2 MB, GPU 47.5 MB
2024-12-27 21:12:34,974 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:12:34,974 - INFO - Number of unique classes: 10
2024-12-27 21:12:35,069 - INFO - Fitted scaler and transformed data
2024-12-27 21:12:35,069 - INFO - Scaling time: 0.09s
2024-12-27 21:12:35,203 - INFO - Epoch 1/200, Train Loss: 0.9814, Val Loss: 0.8020
2024-12-27 21:12:35,331 - INFO - Epoch 2/200, Train Loss: 0.3902, Val Loss: 0.7849
2024-12-27 21:12:35,461 - INFO - Epoch 3/200, Train Loss: 0.2542, Val Loss: 1.0116
2024-12-27 21:12:35,600 - INFO - Epoch 4/200, Train Loss: 0.1610, Val Loss: 0.9440
2024-12-27 21:12:35,601 - INFO - Early stopping triggered at epoch 4
2024-12-27 21:12:35,601 - INFO - Training completed in 0.63s
2024-12-27 21:12:35,601 - INFO - Final memory usage: CPU 3117.2 MB, GPU 48.1 MB
2024-12-27 21:12:35,602 - INFO - Model training completed in 0.63s
2024-12-27 21:12:35,617 - INFO - Prediction completed in 0.01s
2024-12-27 21:12:35,638 - INFO - Poison rate 0.07 completed in 3.28s
2024-12-27 21:12:35,639 - INFO - 
Processing poison rate: 0.1
2024-12-27 21:12:35,649 - INFO - Total number of labels flipped: 500
2024-12-27 21:12:35,649 - INFO - Label flipping completed in 0.01s
2024-12-27 21:12:35,649 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:12:35,649 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:12:36,241 - INFO - Feature scaling completed in 0.59s
2024-12-27 21:12:36,241 - INFO - Starting feature selection (k=50)
2024-12-27 21:12:36,255 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:12:36,255 - INFO - Starting anomaly detection
2024-12-27 21:12:38,409 - INFO - Anomaly detection completed in 2.15s
2024-12-27 21:12:38,410 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:12:38,410 - INFO - Total fit_transform time: 2.76s
2024-12-27 21:12:38,410 - INFO - Training set processing completed in 2.76s
2024-12-27 21:12:38,410 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 21:12:38,411 - INFO - Memory usage at start_fit: CPU 3117.2 MB, GPU 47.5 MB
2024-12-27 21:12:38,411 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:12:38,411 - INFO - Number of unique classes: 10
2024-12-27 21:12:38,507 - INFO - Fitted scaler and transformed data
2024-12-27 21:12:38,507 - INFO - Scaling time: 0.09s
2024-12-27 21:12:38,667 - INFO - Epoch 1/200, Train Loss: 1.1529, Val Loss: 1.2485
2024-12-27 21:12:38,802 - INFO - Epoch 2/200, Train Loss: 0.4923, Val Loss: 1.2120
2024-12-27 21:12:38,954 - INFO - Epoch 3/200, Train Loss: 0.3304, Val Loss: 1.2685
2024-12-27 21:12:39,091 - INFO - Epoch 4/200, Train Loss: 0.2850, Val Loss: 1.4826
2024-12-27 21:12:39,091 - INFO - Early stopping triggered at epoch 4
2024-12-27 21:12:39,092 - INFO - Training completed in 0.68s
2024-12-27 21:12:39,092 - INFO - Final memory usage: CPU 3117.2 MB, GPU 48.1 MB
2024-12-27 21:12:39,093 - INFO - Model training completed in 0.68s
2024-12-27 21:12:39,108 - INFO - Prediction completed in 0.01s
2024-12-27 21:12:39,123 - INFO - Poison rate 0.1 completed in 3.48s
2024-12-27 21:12:39,124 - INFO - 
Processing poison rate: 0.2
2024-12-27 21:12:39,137 - INFO - Total number of labels flipped: 1000
2024-12-27 21:12:39,137 - INFO - Label flipping completed in 0.01s
2024-12-27 21:12:39,137 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:12:39,137 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:12:39,684 - INFO - Feature scaling completed in 0.55s
2024-12-27 21:12:39,684 - INFO - Starting feature selection (k=50)
2024-12-27 21:12:39,697 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:12:39,697 - INFO - Starting anomaly detection
2024-12-27 21:12:41,154 - INFO - Anomaly detection completed in 1.46s
2024-12-27 21:12:41,154 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:12:41,154 - INFO - Total fit_transform time: 2.02s
2024-12-27 21:12:41,154 - INFO - Training set processing completed in 2.02s
2024-12-27 21:12:41,154 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 1280)
2024-12-27 21:12:41,155 - INFO - Memory usage at start_fit: CPU 3117.2 MB, GPU 47.5 MB
2024-12-27 21:12:41,156 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:12:41,157 - INFO - Number of unique classes: 10
2024-12-27 21:12:41,248 - INFO - Fitted scaler and transformed data
2024-12-27 21:12:41,248 - INFO - Scaling time: 0.09s
2024-12-27 21:12:41,381 - INFO - Epoch 1/200, Train Loss: 1.6706, Val Loss: 1.5329
2024-12-27 21:12:41,526 - INFO - Epoch 2/200, Train Loss: 0.9367, Val Loss: 1.6274
2024-12-27 21:12:41,664 - INFO - Epoch 3/200, Train Loss: 0.6993, Val Loss: 1.7740
2024-12-27 21:12:41,665 - INFO - Early stopping triggered at epoch 3
2024-12-27 21:12:41,665 - INFO - Training completed in 0.51s
2024-12-27 21:12:41,666 - INFO - Final memory usage: CPU 3117.2 MB, GPU 48.1 MB
2024-12-27 21:12:41,666 - INFO - Model training completed in 0.51s
2024-12-27 21:12:41,681 - INFO - Prediction completed in 0.01s
2024-12-27 21:12:41,701 - INFO - Poison rate 0.2 completed in 2.58s
2024-12-27 21:12:41,703 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 21:12:41,703 - INFO - Total evaluation time: 34.81s
2024-12-27 21:12:41,707 - INFO - 
Progress: 96.9% - Evaluating ImageNette with RandomForest (standard mode, iteration 1/1)
2024-12-27 21:12:41,781 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 21:12:41,849 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 21:12:41,925 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 21:12:41,925 - INFO - Dataset type: image
2024-12-27 21:12:41,925 - INFO - Sample size: 5000
2024-12-27 21:12:41,926 - INFO - Using device: cuda
2024-12-27 21:12:41,928 - INFO - Loading datasets...
2024-12-27 21:12:41,954 - INFO - Dataset loading completed in 0.03s
2024-12-27 21:12:41,954 - INFO - Extracting validation features...
2024-12-27 21:12:41,954 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:19,  1.58it/s]Extracting features:   6%|▋         | 2/32 [00:00<00:10,  2.97it/s]Extracting features:   9%|▉         | 3/32 [00:00<00:06,  4.20it/s]Extracting features:  31%|███▏      | 10/32 [00:00<00:01, 17.89it/s]Extracting features:  41%|████      | 13/32 [00:01<00:01, 13.89it/s]Extracting features:  50%|█████     | 16/32 [00:01<00:01, 14.56it/s]Extracting features:  56%|█████▋    | 18/32 [00:01<00:01, 13.79it/s]Extracting features:  62%|██████▎   | 20/32 [00:01<00:00, 14.24it/s]Extracting features:  69%|██████▉   | 22/32 [00:02<00:00, 11.81it/s]Extracting features:  75%|███████▌  | 24/32 [00:02<00:00, 12.79it/s]Extracting features:  81%|████████▏ | 26/32 [00:02<00:00, 13.57it/s]Extracting features:  91%|█████████ | 29/32 [00:02<00:00, 15.12it/s]Extracting features:  97%|█████████▋| 31/32 [00:02<00:00, 15.48it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 12.13it/s]
2024-12-27 21:12:44,596 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 21:12:44,597 - INFO - Validation feature extraction completed in 2.64s
2024-12-27 21:12:44,597 - INFO - Extracting training features...
2024-12-27 21:12:44,597 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:08,  2.26it/s]Extracting features:   3%|▎         | 5/157 [00:00<00:17,  8.79it/s]Extracting features:   5%|▌         | 8/157 [00:00<00:11, 12.76it/s]Extracting features:   6%|▋         | 10/157 [00:00<00:12, 11.72it/s]Extracting features:   8%|▊         | 12/157 [00:01<00:15,  9.35it/s]Extracting features:  10%|█         | 16/157 [00:01<00:11, 11.93it/s]Extracting features:  12%|█▏        | 19/157 [00:01<00:09, 14.08it/s]Extracting features:  13%|█▎        | 21/157 [00:01<00:10, 13.54it/s]Extracting features:  15%|█▌        | 24/157 [00:02<00:10, 13.17it/s]Extracting features:  18%|█▊        | 28/157 [00:02<00:09, 14.29it/s]Extracting features:  20%|█▉        | 31/157 [00:02<00:07, 16.27it/s]Extracting features:  21%|██        | 33/157 [00:02<00:08, 14.03it/s]Extracting features:  23%|██▎       | 36/157 [00:02<00:07, 15.62it/s]Extracting features:  25%|██▌       | 40/157 [00:03<00:07, 16.54it/s]Extracting features:  28%|██▊       | 44/157 [00:03<00:07, 15.77it/s]Extracting features:  31%|███       | 48/157 [00:03<00:07, 15.08it/s]Extracting features:  33%|███▎      | 52/157 [00:03<00:06, 16.24it/s]Extracting features:  36%|███▌      | 56/157 [00:04<00:06, 15.93it/s]Extracting features:  38%|███▊      | 60/157 [00:04<00:06, 15.78it/s]Extracting features:  41%|████      | 64/157 [00:04<00:06, 15.29it/s]Extracting features:  43%|████▎     | 68/157 [00:04<00:06, 14.79it/s]Extracting features:  46%|████▌     | 72/157 [00:05<00:05, 14.46it/s]Extracting features:  48%|████▊     | 76/157 [00:05<00:05, 15.10it/s]Extracting features:  50%|████▉     | 78/157 [00:05<00:05, 14.83it/s]Extracting features:  51%|█████     | 80/157 [00:05<00:05, 15.12it/s]Extracting features:  52%|█████▏    | 82/157 [00:05<00:05, 14.89it/s]Extracting features:  54%|█████▎    | 84/157 [00:05<00:04, 15.22it/s]Extracting features:  55%|█████▍    | 86/157 [00:06<00:05, 12.00it/s]Extracting features:  57%|█████▋    | 90/157 [00:06<00:05, 12.75it/s]Extracting features:  59%|█████▉    | 93/157 [00:06<00:05, 12.28it/s]Extracting features:  62%|██████▏   | 97/157 [00:07<00:04, 13.51it/s]Extracting features:  63%|██████▎   | 99/157 [00:07<00:04, 12.95it/s]Extracting features:  64%|██████▍   | 101/157 [00:07<00:04, 13.94it/s]Extracting features:  66%|██████▌   | 103/157 [00:07<00:04, 13.31it/s]Extracting features:  67%|██████▋   | 105/157 [00:07<00:03, 13.62it/s]Extracting features:  68%|██████▊   | 107/157 [00:07<00:03, 12.76it/s]Extracting features:  69%|██████▉   | 109/157 [00:07<00:03, 13.54it/s]Extracting features:  71%|███████   | 111/157 [00:08<00:03, 13.80it/s]Extracting features:  72%|███████▏  | 113/157 [00:08<00:03, 14.04it/s]Extracting features:  73%|███████▎  | 115/157 [00:08<00:05,  8.36it/s]Extracting features:  75%|███████▌  | 118/157 [00:08<00:04,  9.56it/s]Extracting features:  78%|███████▊  | 122/157 [00:09<00:03, 10.86it/s]Extracting features:  80%|████████  | 126/157 [00:09<00:02, 11.65it/s]Extracting features:  83%|████████▎ | 130/157 [00:09<00:02, 13.26it/s]Extracting features:  85%|████████▌ | 134/157 [00:09<00:01, 14.85it/s]Extracting features:  88%|████████▊ | 138/157 [00:10<00:01, 16.04it/s]Extracting features:  90%|█████████ | 142/157 [00:10<00:00, 16.63it/s]Extracting features:  93%|█████████▎| 146/157 [00:10<00:00, 16.10it/s]Extracting features:  95%|█████████▍| 149/157 [00:10<00:00, 17.88it/s]Extracting features:  96%|█████████▌| 151/157 [00:10<00:00, 16.56it/s]Extracting features:  97%|█████████▋| 153/157 [00:11<00:00, 15.83it/s]Extracting features:  99%|█████████▉| 156/157 [00:11<00:00, 13.56it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 13.76it/s]
2024-12-27 21:12:56,024 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 21:12:56,024 - INFO - Training feature extraction completed in 11.43s
2024-12-27 21:12:56,024 - INFO - Creating model for classifier: RandomForest
2024-12-27 21:12:56,024 - INFO - Using device: cuda
2024-12-27 21:12:56,024 - INFO - 
Processing poison rate: 0.0
2024-12-27 21:12:56,024 - INFO - Training set processing completed in 0.00s
2024-12-27 21:12:56,024 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 21:12:56,026 - INFO - Memory usage at start_fit: CPU 3110.6 MB, GPU 47.3 MB
2024-12-27 21:12:56,026 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:12:56,089 - INFO - Fitted scaler and transformed data
2024-12-27 21:12:56,090 - INFO - Scaling time: 0.06s
2024-12-27 21:12:56,095 - INFO - Number of unique classes: 10
2024-12-27 21:12:59,282 - INFO - Epoch 1/15, Train Loss: 2.2968, Val Loss: 2.2895
2024-12-27 21:13:02,379 - INFO - Epoch 2/15, Train Loss: 2.2809, Val Loss: 2.2743
2024-12-27 21:13:05,611 - INFO - Epoch 3/15, Train Loss: 2.2628, Val Loss: 2.2563
2024-12-27 21:13:08,664 - INFO - Epoch 4/15, Train Loss: 2.2418, Val Loss: 2.2354
2024-12-27 21:13:11,388 - INFO - Epoch 5/15, Train Loss: 2.2179, Val Loss: 2.2117
2024-12-27 21:13:13,998 - INFO - Epoch 6/15, Train Loss: 2.1914, Val Loss: 2.1862
2024-12-27 21:13:17,153 - INFO - Epoch 7/15, Train Loss: 2.1635, Val Loss: 2.1606
2024-12-27 21:13:20,539 - INFO - Epoch 8/15, Train Loss: 2.1366, Val Loss: 2.1359
2024-12-27 21:13:23,337 - INFO - Epoch 9/15, Train Loss: 2.1107, Val Loss: 2.1137
2024-12-27 21:13:25,865 - INFO - Epoch 10/15, Train Loss: 2.0880, Val Loss: 2.0942
2024-12-27 21:13:28,694 - INFO - Epoch 11/15, Train Loss: 2.0680, Val Loss: 2.0775
2024-12-27 21:13:31,247 - INFO - Epoch 12/15, Train Loss: 2.0506, Val Loss: 2.0632
2024-12-27 21:13:34,847 - INFO - Epoch 13/15, Train Loss: 2.0355, Val Loss: 2.0510
2024-12-27 21:13:37,684 - INFO - Epoch 14/15, Train Loss: 2.0227, Val Loss: 2.0405
2024-12-27 21:13:40,596 - INFO - Epoch 15/15, Train Loss: 2.0114, Val Loss: 2.0316
2024-12-27 21:13:40,597 - INFO - Training completed in 44.57s
2024-12-27 21:13:40,597 - INFO - Final memory usage: CPU 3110.6 MB, GPU 75.5 MB
2024-12-27 21:13:40,597 - INFO - Model training completed in 44.57s
2024-12-27 21:13:40,697 - INFO - Prediction completed in 0.10s
2024-12-27 21:13:40,705 - INFO - Poison rate 0.0 completed in 44.68s
2024-12-27 21:13:40,706 - INFO - 
Processing poison rate: 0.01
2024-12-27 21:13:40,707 - INFO - Total number of labels flipped: 50
2024-12-27 21:13:40,707 - INFO - Label flipping completed in 0.00s
2024-12-27 21:13:40,707 - INFO - Training set processing completed in 0.00s
2024-12-27 21:13:40,707 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 21:13:40,708 - INFO - Memory usage at start_fit: CPU 3110.6 MB, GPU 49.3 MB
2024-12-27 21:13:40,708 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:13:40,774 - INFO - Fitted scaler and transformed data
2024-12-27 21:13:40,774 - INFO - Scaling time: 0.07s
2024-12-27 21:13:40,785 - INFO - Number of unique classes: 10
2024-12-27 21:13:43,910 - INFO - Epoch 1/15, Train Loss: 2.2969, Val Loss: 2.2899
2024-12-27 21:13:47,391 - INFO - Epoch 2/15, Train Loss: 2.2814, Val Loss: 2.2749
2024-12-27 21:13:50,511 - INFO - Epoch 3/15, Train Loss: 2.2636, Val Loss: 2.2573
2024-12-27 21:13:53,624 - INFO - Epoch 4/15, Train Loss: 2.2431, Val Loss: 2.2367
2024-12-27 21:13:57,064 - INFO - Epoch 5/15, Train Loss: 2.2194, Val Loss: 2.2133
2024-12-27 21:14:00,283 - INFO - Epoch 6/15, Train Loss: 2.1934, Val Loss: 2.1880
2024-12-27 21:14:04,305 - INFO - Epoch 7/15, Train Loss: 2.1660, Val Loss: 2.1624
2024-12-27 21:14:07,108 - INFO - Epoch 8/15, Train Loss: 2.1391, Val Loss: 2.1380
2024-12-27 21:14:10,656 - INFO - Epoch 9/15, Train Loss: 2.1138, Val Loss: 2.1161
2024-12-27 21:14:14,368 - INFO - Epoch 10/15, Train Loss: 2.0909, Val Loss: 2.0969
2024-12-27 21:14:17,138 - INFO - Epoch 11/15, Train Loss: 2.0711, Val Loss: 2.0804
2024-12-27 21:14:20,183 - INFO - Epoch 12/15, Train Loss: 2.0541, Val Loss: 2.0662
2024-12-27 21:14:23,398 - INFO - Epoch 13/15, Train Loss: 2.0393, Val Loss: 2.0542
2024-12-27 21:14:26,553 - INFO - Epoch 14/15, Train Loss: 2.0263, Val Loss: 2.0438
2024-12-27 21:14:29,325 - INFO - Epoch 15/15, Train Loss: 2.0152, Val Loss: 2.0350
2024-12-27 21:14:29,325 - INFO - Training completed in 48.62s
2024-12-27 21:14:29,325 - INFO - Final memory usage: CPU 3110.6 MB, GPU 75.5 MB
2024-12-27 21:14:29,326 - INFO - Model training completed in 48.62s
2024-12-27 21:14:29,424 - INFO - Prediction completed in 0.10s
2024-12-27 21:14:29,432 - INFO - Poison rate 0.01 completed in 48.73s
2024-12-27 21:14:29,432 - INFO - 
Processing poison rate: 0.03
2024-12-27 21:14:29,434 - INFO - Total number of labels flipped: 150
2024-12-27 21:14:29,434 - INFO - Label flipping completed in 0.00s
2024-12-27 21:14:29,434 - INFO - Training set processing completed in 0.00s
2024-12-27 21:14:29,434 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 21:14:29,435 - INFO - Memory usage at start_fit: CPU 3110.6 MB, GPU 49.3 MB
2024-12-27 21:14:29,435 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:14:29,500 - INFO - Fitted scaler and transformed data
2024-12-27 21:14:29,501 - INFO - Scaling time: 0.07s
2024-12-27 21:14:29,511 - INFO - Number of unique classes: 10
2024-12-27 21:14:32,286 - INFO - Epoch 1/15, Train Loss: 2.2970, Val Loss: 2.2906
2024-12-27 21:14:35,194 - INFO - Epoch 2/15, Train Loss: 2.2818, Val Loss: 2.2767
2024-12-27 21:14:38,142 - INFO - Epoch 3/15, Train Loss: 2.2645, Val Loss: 2.2602
2024-12-27 21:14:40,708 - INFO - Epoch 4/15, Train Loss: 2.2445, Val Loss: 2.2407
2024-12-27 21:14:43,648 - INFO - Epoch 5/15, Train Loss: 2.2214, Val Loss: 2.2186
2024-12-27 21:14:46,389 - INFO - Epoch 6/15, Train Loss: 2.1959, Val Loss: 2.1946
2024-12-27 21:14:49,312 - INFO - Epoch 7/15, Train Loss: 2.1693, Val Loss: 2.1702
2024-12-27 21:14:52,223 - INFO - Epoch 8/15, Train Loss: 2.1429, Val Loss: 2.1467
2024-12-27 21:14:55,412 - INFO - Epoch 9/15, Train Loss: 2.1180, Val Loss: 2.1255
2024-12-27 21:14:58,239 - INFO - Epoch 10/15, Train Loss: 2.0951, Val Loss: 2.1069
2024-12-27 21:15:01,380 - INFO - Epoch 11/15, Train Loss: 2.0761, Val Loss: 2.0908
2024-12-27 21:15:04,439 - INFO - Epoch 12/15, Train Loss: 2.0587, Val Loss: 2.0772
2024-12-27 21:15:07,364 - INFO - Epoch 13/15, Train Loss: 2.0441, Val Loss: 2.0655
2024-12-27 21:15:10,593 - INFO - Epoch 14/15, Train Loss: 2.0309, Val Loss: 2.0556
2024-12-27 21:15:13,725 - INFO - Epoch 15/15, Train Loss: 2.0196, Val Loss: 2.0470
2024-12-27 21:15:13,726 - INFO - Training completed in 44.29s
2024-12-27 21:15:13,726 - INFO - Final memory usage: CPU 3110.6 MB, GPU 75.5 MB
2024-12-27 21:15:13,726 - INFO - Model training completed in 44.29s
2024-12-27 21:15:13,823 - INFO - Prediction completed in 0.10s
2024-12-27 21:15:13,831 - INFO - Poison rate 0.03 completed in 44.40s
2024-12-27 21:15:13,831 - INFO - 
Processing poison rate: 0.05
2024-12-27 21:15:13,834 - INFO - Total number of labels flipped: 250
2024-12-27 21:15:13,835 - INFO - Label flipping completed in 0.00s
2024-12-27 21:15:13,835 - INFO - Training set processing completed in 0.00s
2024-12-27 21:15:13,835 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 21:15:13,836 - INFO - Memory usage at start_fit: CPU 3110.6 MB, GPU 49.3 MB
2024-12-27 21:15:13,836 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:15:13,915 - INFO - Fitted scaler and transformed data
2024-12-27 21:15:13,915 - INFO - Scaling time: 0.08s
2024-12-27 21:15:13,926 - INFO - Number of unique classes: 10
2024-12-27 21:15:16,870 - INFO - Epoch 1/15, Train Loss: 2.2974, Val Loss: 2.2909
2024-12-27 21:15:20,557 - INFO - Epoch 2/15, Train Loss: 2.2826, Val Loss: 2.2773
2024-12-27 21:15:23,647 - INFO - Epoch 3/15, Train Loss: 2.2660, Val Loss: 2.2612
2024-12-27 21:15:27,216 - INFO - Epoch 4/15, Train Loss: 2.2465, Val Loss: 2.2423
2024-12-27 21:15:30,656 - INFO - Epoch 5/15, Train Loss: 2.2243, Val Loss: 2.2209
2024-12-27 21:15:33,530 - INFO - Epoch 6/15, Train Loss: 2.1996, Val Loss: 2.1976
2024-12-27 21:15:36,850 - INFO - Epoch 7/15, Train Loss: 2.1734, Val Loss: 2.1742
2024-12-27 21:15:40,990 - INFO - Epoch 8/15, Train Loss: 2.1482, Val Loss: 2.1515
2024-12-27 21:15:44,047 - INFO - Epoch 9/15, Train Loss: 2.1244, Val Loss: 2.1312
2024-12-27 21:15:47,092 - INFO - Epoch 10/15, Train Loss: 2.1026, Val Loss: 2.1133
2024-12-27 21:15:50,565 - INFO - Epoch 11/15, Train Loss: 2.0838, Val Loss: 2.0977
2024-12-27 21:15:55,220 - INFO - Epoch 12/15, Train Loss: 2.0672, Val Loss: 2.0844
2024-12-27 21:15:58,010 - INFO - Epoch 13/15, Train Loss: 2.0529, Val Loss: 2.0730
2024-12-27 21:16:01,535 - INFO - Epoch 14/15, Train Loss: 2.0412, Val Loss: 2.0631
2024-12-27 21:16:04,911 - INFO - Epoch 15/15, Train Loss: 2.0301, Val Loss: 2.0545
2024-12-27 21:16:04,912 - INFO - Training completed in 51.08s
2024-12-27 21:16:04,912 - INFO - Final memory usage: CPU 3110.6 MB, GPU 75.5 MB
2024-12-27 21:16:04,912 - INFO - Model training completed in 51.08s
2024-12-27 21:16:05,064 - INFO - Prediction completed in 0.15s
2024-12-27 21:16:05,072 - INFO - Poison rate 0.05 completed in 51.24s
2024-12-27 21:16:05,073 - INFO - 
Processing poison rate: 0.07
2024-12-27 21:16:05,077 - INFO - Total number of labels flipped: 350
2024-12-27 21:16:05,077 - INFO - Label flipping completed in 0.00s
2024-12-27 21:16:05,077 - INFO - Training set processing completed in 0.00s
2024-12-27 21:16:05,077 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 21:16:05,079 - INFO - Memory usage at start_fit: CPU 3110.6 MB, GPU 49.3 MB
2024-12-27 21:16:05,079 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:16:05,148 - INFO - Fitted scaler and transformed data
2024-12-27 21:16:05,148 - INFO - Scaling time: 0.07s
2024-12-27 21:16:05,158 - INFO - Number of unique classes: 10
2024-12-27 21:16:08,117 - INFO - Epoch 1/15, Train Loss: 2.2975, Val Loss: 2.2915
2024-12-27 21:16:12,095 - INFO - Epoch 2/15, Train Loss: 2.2832, Val Loss: 2.2785
2024-12-27 21:16:15,863 - INFO - Epoch 3/15, Train Loss: 2.2671, Val Loss: 2.2633
2024-12-27 21:16:19,527 - INFO - Epoch 4/15, Train Loss: 2.2482, Val Loss: 2.2455
2024-12-27 21:16:23,312 - INFO - Epoch 5/15, Train Loss: 2.2268, Val Loss: 2.2253
2024-12-27 21:16:26,313 - INFO - Epoch 6/15, Train Loss: 2.2028, Val Loss: 2.2033
2024-12-27 21:16:30,171 - INFO - Epoch 7/15, Train Loss: 2.1778, Val Loss: 2.1807
2024-12-27 21:16:33,745 - INFO - Epoch 8/15, Train Loss: 2.1528, Val Loss: 2.1587
2024-12-27 21:16:36,788 - INFO - Epoch 9/15, Train Loss: 2.1289, Val Loss: 2.1385
2024-12-27 21:16:40,031 - INFO - Epoch 10/15, Train Loss: 2.1071, Val Loss: 2.1206
2024-12-27 21:16:44,127 - INFO - Epoch 11/15, Train Loss: 2.0881, Val Loss: 2.1050
2024-12-27 21:16:47,748 - INFO - Epoch 12/15, Train Loss: 2.0716, Val Loss: 2.0916
2024-12-27 21:16:51,745 - INFO - Epoch 13/15, Train Loss: 2.0574, Val Loss: 2.0800
2024-12-27 21:16:55,123 - INFO - Epoch 14/15, Train Loss: 2.0452, Val Loss: 2.0701
2024-12-27 21:16:58,757 - INFO - Epoch 15/15, Train Loss: 2.0342, Val Loss: 2.0615
2024-12-27 21:16:58,758 - INFO - Training completed in 53.68s
2024-12-27 21:16:58,758 - INFO - Final memory usage: CPU 3110.6 MB, GPU 75.5 MB
2024-12-27 21:16:58,758 - INFO - Model training completed in 53.68s
2024-12-27 21:16:58,881 - INFO - Prediction completed in 0.12s
2024-12-27 21:16:58,889 - INFO - Poison rate 0.07 completed in 53.82s
2024-12-27 21:16:58,889 - INFO - 
Processing poison rate: 0.1
2024-12-27 21:16:58,895 - INFO - Total number of labels flipped: 500
2024-12-27 21:16:58,896 - INFO - Label flipping completed in 0.01s
2024-12-27 21:16:58,896 - INFO - Training set processing completed in 0.00s
2024-12-27 21:16:58,896 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 21:16:58,897 - INFO - Memory usage at start_fit: CPU 3110.6 MB, GPU 49.3 MB
2024-12-27 21:16:58,897 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:16:58,962 - INFO - Fitted scaler and transformed data
2024-12-27 21:16:58,962 - INFO - Scaling time: 0.07s
2024-12-27 21:16:58,973 - INFO - Number of unique classes: 10
2024-12-27 21:17:02,459 - INFO - Epoch 1/15, Train Loss: 2.2978, Val Loss: 2.2924
2024-12-27 21:17:06,341 - INFO - Epoch 2/15, Train Loss: 2.2841, Val Loss: 2.2807
2024-12-27 21:17:09,902 - INFO - Epoch 3/15, Train Loss: 2.2687, Val Loss: 2.2668
2024-12-27 21:17:13,569 - INFO - Epoch 4/15, Train Loss: 2.2509, Val Loss: 2.2507
2024-12-27 21:17:16,896 - INFO - Epoch 5/15, Train Loss: 2.2306, Val Loss: 2.2323
2024-12-27 21:17:20,093 - INFO - Epoch 6/15, Train Loss: 2.2082, Val Loss: 2.2124
2024-12-27 21:17:23,614 - INFO - Epoch 7/15, Train Loss: 2.1843, Val Loss: 2.1920
2024-12-27 21:17:26,672 - INFO - Epoch 8/15, Train Loss: 2.1608, Val Loss: 2.1722
2024-12-27 21:17:30,454 - INFO - Epoch 9/15, Train Loss: 2.1384, Val Loss: 2.1541
2024-12-27 21:17:33,852 - INFO - Epoch 10/15, Train Loss: 2.1180, Val Loss: 2.1381
2024-12-27 21:17:37,349 - INFO - Epoch 11/15, Train Loss: 2.1000, Val Loss: 2.1241
2024-12-27 21:17:41,085 - INFO - Epoch 12/15, Train Loss: 2.0846, Val Loss: 2.1121
2024-12-27 21:17:44,570 - INFO - Epoch 13/15, Train Loss: 2.0698, Val Loss: 2.1017
2024-12-27 21:17:48,127 - INFO - Epoch 14/15, Train Loss: 2.0587, Val Loss: 2.0927
2024-12-27 21:17:51,742 - INFO - Epoch 15/15, Train Loss: 2.0481, Val Loss: 2.0850
2024-12-27 21:17:51,742 - INFO - Training completed in 52.85s
2024-12-27 21:17:51,743 - INFO - Final memory usage: CPU 3110.6 MB, GPU 75.5 MB
2024-12-27 21:17:51,743 - INFO - Model training completed in 52.85s
2024-12-27 21:17:52,006 - INFO - Prediction completed in 0.26s
2024-12-27 21:17:52,013 - INFO - Poison rate 0.1 completed in 53.12s
2024-12-27 21:17:52,014 - INFO - 
Processing poison rate: 0.2
2024-12-27 21:17:52,025 - INFO - Total number of labels flipped: 1000
2024-12-27 21:17:52,026 - INFO - Label flipping completed in 0.01s
2024-12-27 21:17:52,026 - INFO - Training set processing completed in 0.00s
2024-12-27 21:17:52,026 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 21:17:52,027 - INFO - Memory usage at start_fit: CPU 3110.6 MB, GPU 49.3 MB
2024-12-27 21:17:52,027 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:17:52,105 - INFO - Fitted scaler and transformed data
2024-12-27 21:17:52,105 - INFO - Scaling time: 0.08s
2024-12-27 21:17:52,117 - INFO - Number of unique classes: 10
2024-12-27 21:17:55,776 - INFO - Epoch 1/15, Train Loss: 2.2987, Val Loss: 2.2937
2024-12-27 21:17:59,336 - INFO - Epoch 2/15, Train Loss: 2.2871, Val Loss: 2.2835
2024-12-27 21:18:03,239 - INFO - Epoch 3/15, Train Loss: 2.2743, Val Loss: 2.2717
2024-12-27 21:18:06,465 - INFO - Epoch 4/15, Train Loss: 2.2598, Val Loss: 2.2578
2024-12-27 21:18:09,685 - INFO - Epoch 5/15, Train Loss: 2.2433, Val Loss: 2.2421
2024-12-27 21:18:12,613 - INFO - Epoch 6/15, Train Loss: 2.2249, Val Loss: 2.2247
2024-12-27 21:18:15,636 - INFO - Epoch 7/15, Train Loss: 2.2053, Val Loss: 2.2066
2024-12-27 21:18:18,612 - INFO - Epoch 8/15, Train Loss: 2.1860, Val Loss: 2.1887
2024-12-27 21:18:21,726 - INFO - Epoch 9/15, Train Loss: 2.1664, Val Loss: 2.1721
2024-12-27 21:18:25,149 - INFO - Epoch 10/15, Train Loss: 2.1491, Val Loss: 2.1572
2024-12-27 21:18:28,717 - INFO - Epoch 11/15, Train Loss: 2.1335, Val Loss: 2.1439
2024-12-27 21:18:31,571 - INFO - Epoch 12/15, Train Loss: 2.1192, Val Loss: 2.1326
2024-12-27 21:18:35,069 - INFO - Epoch 13/15, Train Loss: 2.1066, Val Loss: 2.1226
2024-12-27 21:18:37,813 - INFO - Epoch 14/15, Train Loss: 2.0964, Val Loss: 2.1140
2024-12-27 21:18:41,010 - INFO - Epoch 15/15, Train Loss: 2.0861, Val Loss: 2.1066
2024-12-27 21:18:41,010 - INFO - Training completed in 48.98s
2024-12-27 21:18:41,010 - INFO - Final memory usage: CPU 3110.6 MB, GPU 75.5 MB
2024-12-27 21:18:41,010 - INFO - Model training completed in 48.98s
2024-12-27 21:18:41,209 - INFO - Prediction completed in 0.20s
2024-12-27 21:18:41,217 - INFO - Poison rate 0.2 completed in 49.20s
2024-12-27 21:18:41,217 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 21:18:41,217 - INFO - Total evaluation time: 359.29s
2024-12-27 21:18:41,219 - INFO - 
Progress: 97.9% - Evaluating ImageNette with RandomForest (dynadetect mode, iteration 1/1)
2024-12-27 21:18:41,286 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 21:18:41,465 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 21:18:41,555 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 21:18:41,555 - INFO - Dataset type: image
2024-12-27 21:18:41,555 - INFO - Sample size: 5000
2024-12-27 21:18:41,555 - INFO - Using device: cuda
2024-12-27 21:18:41,558 - INFO - Loading datasets...
2024-12-27 21:18:41,585 - INFO - Dataset loading completed in 0.03s
2024-12-27 21:18:41,585 - INFO - Extracting validation features...
2024-12-27 21:18:41,585 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:22,  1.39it/s]Extracting features:  19%|█▉        | 6/32 [00:00<00:02,  9.26it/s]Extracting features:  28%|██▊       | 9/32 [00:01<00:01, 11.61it/s]Extracting features:  38%|███▊      | 12/32 [00:01<00:01, 14.80it/s]Extracting features:  47%|████▋     | 15/32 [00:01<00:01, 14.87it/s]Extracting features:  56%|█████▋    | 18/32 [00:01<00:01, 13.44it/s]Extracting features:  62%|██████▎   | 20/32 [00:01<00:00, 13.95it/s]Extracting features:  69%|██████▉   | 22/32 [00:01<00:00, 13.51it/s]Extracting features:  75%|███████▌  | 24/32 [00:02<00:00, 13.13it/s]Extracting features:  81%|████████▏ | 26/32 [00:02<00:00, 10.47it/s]Extracting features:  91%|█████████ | 29/32 [00:02<00:00, 12.16it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 12.29it/s]
2024-12-27 21:18:44,196 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 21:18:44,197 - INFO - Validation feature extraction completed in 2.61s
2024-12-27 21:18:44,197 - INFO - Extracting training features...
2024-12-27 21:18:44,197 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:16,  2.04it/s]Extracting features:   3%|▎         | 5/157 [00:00<00:20,  7.48it/s]Extracting features:   5%|▌         | 8/157 [00:00<00:13, 11.19it/s]Extracting features:   6%|▋         | 10/157 [00:01<00:13, 10.80it/s]Extracting features:   8%|▊         | 13/157 [00:01<00:16,  8.63it/s]Extracting features:  11%|█         | 17/157 [00:01<00:14,  9.94it/s]Extracting features:  13%|█▎        | 21/157 [00:02<00:11, 11.72it/s]Extracting features:  16%|█▌        | 25/157 [00:02<00:10, 12.37it/s]Extracting features:  18%|█▊        | 29/157 [00:02<00:09, 13.09it/s]Extracting features:  21%|██        | 33/157 [00:02<00:08, 14.56it/s]Extracting features:  24%|██▎       | 37/157 [00:03<00:07, 15.71it/s]Extracting features:  26%|██▌       | 41/157 [00:03<00:06, 17.60it/s]Extracting features:  29%|██▊       | 45/157 [00:03<00:06, 17.55it/s]Extracting features:  31%|███       | 49/157 [00:03<00:05, 18.34it/s]Extracting features:  34%|███▍      | 53/157 [00:04<00:07, 14.84it/s]Extracting features:  36%|███▋      | 57/157 [00:04<00:06, 15.87it/s]Extracting features:  39%|███▉      | 61/157 [00:04<00:05, 16.96it/s]Extracting features:  41%|████▏     | 65/157 [00:04<00:05, 16.46it/s]Extracting features:  44%|████▍     | 69/157 [00:05<00:05, 15.20it/s]Extracting features:  46%|████▋     | 73/157 [00:05<00:05, 15.16it/s]Extracting features:  49%|████▉     | 77/157 [00:05<00:05, 14.94it/s]Extracting features:  52%|█████▏    | 81/157 [00:05<00:05, 14.14it/s]Extracting features:  54%|█████▍    | 85/157 [00:06<00:05, 12.51it/s]Extracting features:  57%|█████▋    | 89/157 [00:06<00:05, 13.12it/s]Extracting features:  59%|█████▉    | 93/157 [00:06<00:04, 14.85it/s]Extracting features:  62%|██████▏   | 97/157 [00:07<00:03, 15.01it/s]Extracting features:  64%|██████▎   | 100/157 [00:07<00:03, 16.13it/s]Extracting features:  65%|██████▍   | 102/157 [00:07<00:03, 14.68it/s]Extracting features:  66%|██████▌   | 104/157 [00:07<00:03, 15.25it/s]Extracting features:  68%|██████▊   | 106/157 [00:07<00:03, 14.19it/s]Extracting features:  69%|██████▉   | 108/157 [00:07<00:03, 13.21it/s]Extracting features:  70%|███████   | 110/157 [00:07<00:03, 13.14it/s]Extracting features:  71%|███████▏  | 112/157 [00:08<00:03, 13.77it/s]Extracting features:  73%|███████▎  | 114/157 [00:08<00:03, 13.19it/s]Extracting features:  74%|███████▍  | 116/157 [00:08<00:03, 11.40it/s]Extracting features:  75%|███████▌  | 118/157 [00:08<00:03, 12.01it/s]Extracting features:  77%|███████▋  | 121/157 [00:08<00:03, 11.24it/s]Extracting features:  80%|███████▉  | 125/157 [00:09<00:02, 11.61it/s]Extracting features:  82%|████████▏ | 129/157 [00:09<00:02, 12.85it/s]Extracting features:  85%|████████▍ | 133/157 [00:09<00:01, 15.39it/s]Extracting features:  87%|████████▋ | 137/157 [00:09<00:01, 16.49it/s]Extracting features:  90%|████████▉ | 141/157 [00:10<00:00, 16.67it/s]Extracting features:  92%|█████████▏| 145/157 [00:10<00:00, 17.27it/s]Extracting features:  94%|█████████▍| 148/157 [00:10<00:00, 14.60it/s]Extracting features:  97%|█████████▋| 152/157 [00:10<00:00, 14.80it/s]Extracting features:  99%|█████████▉| 156/157 [00:11<00:00, 16.45it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 14.03it/s]
2024-12-27 21:18:55,402 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 21:18:55,402 - INFO - Training feature extraction completed in 11.20s
2024-12-27 21:18:55,402 - INFO - Creating model for classifier: RandomForest
2024-12-27 21:18:55,402 - INFO - Using device: cuda
2024-12-27 21:18:55,403 - INFO - 
Processing poison rate: 0.0
2024-12-27 21:18:55,403 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:18:55,403 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:18:55,973 - INFO - Feature scaling completed in 0.57s
2024-12-27 21:18:55,973 - INFO - Starting feature selection (k=50)
2024-12-27 21:18:55,979 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:18:55,979 - INFO - Starting anomaly detection
2024-12-27 21:18:57,980 - INFO - Anomaly detection completed in 2.00s
2024-12-27 21:18:57,980 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:18:57,980 - INFO - Total fit_transform time: 2.58s
2024-12-27 21:18:57,980 - INFO - Training set processing completed in 2.58s
2024-12-27 21:18:57,980 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 21:18:57,982 - INFO - Memory usage at start_fit: CPU 3115.5 MB, GPU 47.3 MB
2024-12-27 21:18:57,982 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:18:58,060 - INFO - Fitted scaler and transformed data
2024-12-27 21:18:58,060 - INFO - Scaling time: 0.08s
2024-12-27 21:18:58,065 - INFO - Number of unique classes: 10
2024-12-27 21:19:00,798 - INFO - Epoch 1/15, Train Loss: 2.1813, Val Loss: 2.2904
2024-12-27 21:19:03,533 - INFO - Epoch 2/15, Train Loss: 2.1662, Val Loss: 2.2761
2024-12-27 21:19:06,918 - INFO - Epoch 3/15, Train Loss: 2.1489, Val Loss: 2.2593
2024-12-27 21:19:10,451 - INFO - Epoch 4/15, Train Loss: 2.1288, Val Loss: 2.2395
2024-12-27 21:19:13,563 - INFO - Epoch 5/15, Train Loss: 2.1055, Val Loss: 2.2171
2024-12-27 21:19:16,499 - INFO - Epoch 6/15, Train Loss: 2.0799, Val Loss: 2.1930
2024-12-27 21:19:19,904 - INFO - Epoch 7/15, Train Loss: 2.0533, Val Loss: 2.1684
2024-12-27 21:19:23,446 - INFO - Epoch 8/15, Train Loss: 2.0267, Val Loss: 2.1452
2024-12-27 21:19:26,342 - INFO - Epoch 9/15, Train Loss: 2.0023, Val Loss: 2.1239
2024-12-27 21:19:29,121 - INFO - Epoch 10/15, Train Loss: 1.9801, Val Loss: 2.1054
2024-12-27 21:19:31,968 - INFO - Epoch 11/15, Train Loss: 1.9614, Val Loss: 2.0893
2024-12-27 21:19:34,939 - INFO - Epoch 12/15, Train Loss: 1.9448, Val Loss: 2.0755
2024-12-27 21:19:37,784 - INFO - Epoch 13/15, Train Loss: 1.9302, Val Loss: 2.0637
2024-12-27 21:19:41,124 - INFO - Epoch 14/15, Train Loss: 1.9186, Val Loss: 2.0536
2024-12-27 21:19:44,210 - INFO - Epoch 15/15, Train Loss: 1.9072, Val Loss: 2.0450
2024-12-27 21:19:44,210 - INFO - Training completed in 46.23s
2024-12-27 21:19:44,211 - INFO - Final memory usage: CPU 3115.5 MB, GPU 75.5 MB
2024-12-27 21:19:44,211 - INFO - Model training completed in 46.23s
2024-12-27 21:19:44,329 - INFO - Prediction completed in 0.12s
2024-12-27 21:19:44,337 - INFO - Poison rate 0.0 completed in 48.93s
2024-12-27 21:19:44,337 - INFO - 
Processing poison rate: 0.01
2024-12-27 21:19:44,338 - INFO - Total number of labels flipped: 50
2024-12-27 21:19:44,338 - INFO - Label flipping completed in 0.00s
2024-12-27 21:19:44,339 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:19:44,339 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:19:44,875 - INFO - Feature scaling completed in 0.54s
2024-12-27 21:19:44,875 - INFO - Starting feature selection (k=50)
2024-12-27 21:19:44,887 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:19:44,887 - INFO - Starting anomaly detection
2024-12-27 21:19:47,083 - INFO - Anomaly detection completed in 2.20s
2024-12-27 21:19:47,083 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:19:47,083 - INFO - Total fit_transform time: 2.74s
2024-12-27 21:19:47,083 - INFO - Training set processing completed in 2.74s
2024-12-27 21:19:47,083 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 21:19:47,084 - INFO - Memory usage at start_fit: CPU 3115.5 MB, GPU 49.3 MB
2024-12-27 21:19:47,085 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:19:47,152 - INFO - Fitted scaler and transformed data
2024-12-27 21:19:47,152 - INFO - Scaling time: 0.07s
2024-12-27 21:19:47,158 - INFO - Number of unique classes: 10
2024-12-27 21:19:50,155 - INFO - Epoch 1/15, Train Loss: 2.1818, Val Loss: 2.2901
2024-12-27 21:19:52,834 - INFO - Epoch 2/15, Train Loss: 2.1671, Val Loss: 2.2755
2024-12-27 21:19:55,934 - INFO - Epoch 3/15, Train Loss: 2.1505, Val Loss: 2.2584
2024-12-27 21:19:58,923 - INFO - Epoch 4/15, Train Loss: 2.1312, Val Loss: 2.2385
2024-12-27 21:20:03,005 - INFO - Epoch 5/15, Train Loss: 2.1093, Val Loss: 2.2160
2024-12-27 21:20:06,265 - INFO - Epoch 6/15, Train Loss: 2.0849, Val Loss: 2.1919
2024-12-27 21:20:09,569 - INFO - Epoch 7/15, Train Loss: 2.0597, Val Loss: 2.1673
2024-12-27 21:20:13,073 - INFO - Epoch 8/15, Train Loss: 2.0350, Val Loss: 2.1440
2024-12-27 21:20:16,056 - INFO - Epoch 9/15, Train Loss: 2.0113, Val Loss: 2.1228
2024-12-27 21:20:18,849 - INFO - Epoch 10/15, Train Loss: 1.9904, Val Loss: 2.1040
2024-12-27 21:20:21,735 - INFO - Epoch 11/15, Train Loss: 1.9711, Val Loss: 2.0879
2024-12-27 21:20:24,547 - INFO - Epoch 12/15, Train Loss: 1.9553, Val Loss: 2.0741
2024-12-27 21:20:28,393 - INFO - Epoch 13/15, Train Loss: 1.9415, Val Loss: 2.0623
2024-12-27 21:20:31,540 - INFO - Epoch 14/15, Train Loss: 1.9292, Val Loss: 2.0522
2024-12-27 21:20:34,904 - INFO - Epoch 15/15, Train Loss: 1.9190, Val Loss: 2.0435
2024-12-27 21:20:34,904 - INFO - Training completed in 47.82s
2024-12-27 21:20:34,905 - INFO - Final memory usage: CPU 3115.5 MB, GPU 75.5 MB
2024-12-27 21:20:34,905 - INFO - Model training completed in 47.82s
2024-12-27 21:20:35,119 - INFO - Prediction completed in 0.21s
2024-12-27 21:20:35,126 - INFO - Poison rate 0.01 completed in 50.79s
2024-12-27 21:20:35,127 - INFO - 
Processing poison rate: 0.03
2024-12-27 21:20:35,132 - INFO - Total number of labels flipped: 150
2024-12-27 21:20:35,132 - INFO - Label flipping completed in 0.01s
2024-12-27 21:20:35,133 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:20:35,133 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:20:35,715 - INFO - Feature scaling completed in 0.58s
2024-12-27 21:20:35,715 - INFO - Starting feature selection (k=50)
2024-12-27 21:20:35,728 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:20:35,729 - INFO - Starting anomaly detection
2024-12-27 21:20:37,156 - INFO - Anomaly detection completed in 1.43s
2024-12-27 21:20:37,157 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:20:37,157 - INFO - Total fit_transform time: 2.02s
2024-12-27 21:20:37,157 - INFO - Training set processing completed in 2.02s
2024-12-27 21:20:37,157 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 21:20:37,158 - INFO - Memory usage at start_fit: CPU 3115.5 MB, GPU 49.3 MB
2024-12-27 21:20:37,159 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:20:37,231 - INFO - Fitted scaler and transformed data
2024-12-27 21:20:37,231 - INFO - Scaling time: 0.07s
2024-12-27 21:20:37,237 - INFO - Number of unique classes: 10
2024-12-27 21:20:40,256 - INFO - Epoch 1/15, Train Loss: 2.1828, Val Loss: 2.2911
2024-12-27 21:20:43,246 - INFO - Epoch 2/15, Train Loss: 2.1683, Val Loss: 2.2776
2024-12-27 21:20:46,202 - INFO - Epoch 3/15, Train Loss: 2.1517, Val Loss: 2.2617
2024-12-27 21:20:48,972 - INFO - Epoch 4/15, Train Loss: 2.1324, Val Loss: 2.2430
2024-12-27 21:20:53,319 - INFO - Epoch 5/15, Train Loss: 2.1102, Val Loss: 2.2218
2024-12-27 21:20:56,653 - INFO - Epoch 6/15, Train Loss: 2.0854, Val Loss: 2.1990
2024-12-27 21:20:59,782 - INFO - Epoch 7/15, Train Loss: 2.0595, Val Loss: 2.1758
2024-12-27 21:21:02,755 - INFO - Epoch 8/15, Train Loss: 2.0341, Val Loss: 2.1535
2024-12-27 21:21:05,906 - INFO - Epoch 9/15, Train Loss: 2.0103, Val Loss: 2.1330
2024-12-27 21:21:09,023 - INFO - Epoch 10/15, Train Loss: 1.9892, Val Loss: 2.1149
2024-12-27 21:21:11,812 - INFO - Epoch 11/15, Train Loss: 1.9703, Val Loss: 2.0992
2024-12-27 21:21:15,433 - INFO - Epoch 12/15, Train Loss: 1.9542, Val Loss: 2.0855
2024-12-27 21:21:18,708 - INFO - Epoch 13/15, Train Loss: 1.9395, Val Loss: 2.0739
2024-12-27 21:21:22,204 - INFO - Epoch 14/15, Train Loss: 1.9277, Val Loss: 2.0639
2024-12-27 21:21:25,609 - INFO - Epoch 15/15, Train Loss: 1.9174, Val Loss: 2.0551
2024-12-27 21:21:25,609 - INFO - Training completed in 48.45s
2024-12-27 21:21:25,610 - INFO - Final memory usage: CPU 3115.5 MB, GPU 75.5 MB
2024-12-27 21:21:25,610 - INFO - Model training completed in 48.45s
2024-12-27 21:21:25,761 - INFO - Prediction completed in 0.15s
2024-12-27 21:21:25,769 - INFO - Poison rate 0.03 completed in 50.64s
2024-12-27 21:21:25,769 - INFO - 
Processing poison rate: 0.05
2024-12-27 21:21:25,773 - INFO - Total number of labels flipped: 250
2024-12-27 21:21:25,773 - INFO - Label flipping completed in 0.00s
2024-12-27 21:21:25,773 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:21:25,773 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:21:26,389 - INFO - Feature scaling completed in 0.62s
2024-12-27 21:21:26,389 - INFO - Starting feature selection (k=50)
2024-12-27 21:21:26,402 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:21:26,402 - INFO - Starting anomaly detection
2024-12-27 21:21:28,472 - INFO - Anomaly detection completed in 2.07s
2024-12-27 21:21:28,473 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:21:28,475 - INFO - Total fit_transform time: 2.70s
2024-12-27 21:21:28,475 - INFO - Training set processing completed in 2.70s
2024-12-27 21:21:28,476 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 21:21:28,477 - INFO - Memory usage at start_fit: CPU 3115.5 MB, GPU 49.3 MB
2024-12-27 21:21:28,477 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:21:28,543 - INFO - Fitted scaler and transformed data
2024-12-27 21:21:28,543 - INFO - Scaling time: 0.07s
2024-12-27 21:21:28,549 - INFO - Number of unique classes: 10
2024-12-27 21:21:31,576 - INFO - Epoch 1/15, Train Loss: 2.1810, Val Loss: 2.2911
2024-12-27 21:21:34,494 - INFO - Epoch 2/15, Train Loss: 2.1672, Val Loss: 2.2777
2024-12-27 21:21:38,014 - INFO - Epoch 3/15, Train Loss: 2.1516, Val Loss: 2.2620
2024-12-27 21:21:41,157 - INFO - Epoch 4/15, Train Loss: 2.1336, Val Loss: 2.2436
2024-12-27 21:21:44,090 - INFO - Epoch 5/15, Train Loss: 2.1128, Val Loss: 2.2227
2024-12-27 21:21:46,950 - INFO - Epoch 6/15, Train Loss: 2.0900, Val Loss: 2.2002
2024-12-27 21:21:50,169 - INFO - Epoch 7/15, Train Loss: 2.0658, Val Loss: 2.1772
2024-12-27 21:21:52,813 - INFO - Epoch 8/15, Train Loss: 2.0419, Val Loss: 2.1549
2024-12-27 21:21:56,176 - INFO - Epoch 9/15, Train Loss: 2.0191, Val Loss: 2.1348
2024-12-27 21:22:00,145 - INFO - Epoch 10/15, Train Loss: 1.9987, Val Loss: 2.1168
2024-12-27 21:22:03,415 - INFO - Epoch 11/15, Train Loss: 1.9804, Val Loss: 2.1012
2024-12-27 21:22:06,357 - INFO - Epoch 12/15, Train Loss: 1.9644, Val Loss: 2.0878
2024-12-27 21:22:09,456 - INFO - Epoch 13/15, Train Loss: 1.9507, Val Loss: 2.0763
2024-12-27 21:22:12,693 - INFO - Epoch 14/15, Train Loss: 1.9386, Val Loss: 2.0664
2024-12-27 21:22:15,497 - INFO - Epoch 15/15, Train Loss: 1.9286, Val Loss: 2.0579
2024-12-27 21:22:15,497 - INFO - Training completed in 47.02s
2024-12-27 21:22:15,497 - INFO - Final memory usage: CPU 3115.5 MB, GPU 75.5 MB
2024-12-27 21:22:15,498 - INFO - Model training completed in 47.02s
2024-12-27 21:22:15,620 - INFO - Prediction completed in 0.12s
2024-12-27 21:22:15,627 - INFO - Poison rate 0.05 completed in 49.86s
2024-12-27 21:22:15,628 - INFO - 
Processing poison rate: 0.07
2024-12-27 21:22:15,632 - INFO - Total number of labels flipped: 350
2024-12-27 21:22:15,632 - INFO - Label flipping completed in 0.00s
2024-12-27 21:22:15,632 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:22:15,632 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:22:16,220 - INFO - Feature scaling completed in 0.59s
2024-12-27 21:22:16,220 - INFO - Starting feature selection (k=50)
2024-12-27 21:22:16,233 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:22:16,233 - INFO - Starting anomaly detection
2024-12-27 21:22:18,524 - INFO - Anomaly detection completed in 2.29s
2024-12-27 21:22:18,524 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:22:18,524 - INFO - Total fit_transform time: 2.89s
2024-12-27 21:22:18,525 - INFO - Training set processing completed in 2.89s
2024-12-27 21:22:18,525 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 21:22:18,526 - INFO - Memory usage at start_fit: CPU 3115.5 MB, GPU 49.3 MB
2024-12-27 21:22:18,526 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:22:18,592 - INFO - Fitted scaler and transformed data
2024-12-27 21:22:18,592 - INFO - Scaling time: 0.07s
2024-12-27 21:22:18,599 - INFO - Number of unique classes: 10
2024-12-27 21:22:21,753 - INFO - Epoch 1/15, Train Loss: 2.1824, Val Loss: 2.2912
2024-12-27 21:22:25,929 - INFO - Epoch 2/15, Train Loss: 2.1686, Val Loss: 2.2780
2024-12-27 21:22:28,960 - INFO - Epoch 3/15, Train Loss: 2.1530, Val Loss: 2.2623
2024-12-27 21:22:31,963 - INFO - Epoch 4/15, Train Loss: 2.1348, Val Loss: 2.2441
2024-12-27 21:22:34,983 - INFO - Epoch 5/15, Train Loss: 2.1142, Val Loss: 2.2230
2024-12-27 21:22:37,901 - INFO - Epoch 6/15, Train Loss: 2.0910, Val Loss: 2.2004
2024-12-27 21:22:40,845 - INFO - Epoch 7/15, Train Loss: 2.0665, Val Loss: 2.1772
2024-12-27 21:22:43,632 - INFO - Epoch 8/15, Train Loss: 2.0425, Val Loss: 2.1549
2024-12-27 21:22:46,635 - INFO - Epoch 9/15, Train Loss: 2.0199, Val Loss: 2.1346
2024-12-27 21:22:49,993 - INFO - Epoch 10/15, Train Loss: 1.9994, Val Loss: 2.1168
2024-12-27 21:22:53,734 - INFO - Epoch 11/15, Train Loss: 1.9813, Val Loss: 2.1013
2024-12-27 21:22:56,354 - INFO - Epoch 12/15, Train Loss: 1.9651, Val Loss: 2.0879
2024-12-27 21:22:59,894 - INFO - Epoch 13/15, Train Loss: 1.9523, Val Loss: 2.0765
2024-12-27 21:23:02,800 - INFO - Epoch 14/15, Train Loss: 1.9404, Val Loss: 2.0667
2024-12-27 21:23:06,250 - INFO - Epoch 15/15, Train Loss: 1.9302, Val Loss: 2.0583
2024-12-27 21:23:06,250 - INFO - Training completed in 47.72s
2024-12-27 21:23:06,250 - INFO - Final memory usage: CPU 3115.5 MB, GPU 75.5 MB
2024-12-27 21:23:06,251 - INFO - Model training completed in 47.73s
2024-12-27 21:23:06,368 - INFO - Prediction completed in 0.12s
2024-12-27 21:23:06,376 - INFO - Poison rate 0.07 completed in 50.75s
2024-12-27 21:23:06,377 - INFO - 
Processing poison rate: 0.1
2024-12-27 21:23:06,383 - INFO - Total number of labels flipped: 500
2024-12-27 21:23:06,383 - INFO - Label flipping completed in 0.01s
2024-12-27 21:23:06,383 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:23:06,383 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:23:06,957 - INFO - Feature scaling completed in 0.57s
2024-12-27 21:23:06,957 - INFO - Starting feature selection (k=50)
2024-12-27 21:23:06,969 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:23:06,969 - INFO - Starting anomaly detection
2024-12-27 21:23:09,231 - INFO - Anomaly detection completed in 2.26s
2024-12-27 21:23:09,231 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:23:09,231 - INFO - Total fit_transform time: 2.85s
2024-12-27 21:23:09,232 - INFO - Training set processing completed in 2.85s
2024-12-27 21:23:09,232 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 21:23:09,233 - INFO - Memory usage at start_fit: CPU 3115.5 MB, GPU 49.3 MB
2024-12-27 21:23:09,234 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:23:09,305 - INFO - Fitted scaler and transformed data
2024-12-27 21:23:09,305 - INFO - Scaling time: 0.07s
2024-12-27 21:23:09,314 - INFO - Number of unique classes: 10
2024-12-27 21:23:12,633 - INFO - Epoch 1/15, Train Loss: 2.1823, Val Loss: 2.2920
2024-12-27 21:23:15,702 - INFO - Epoch 2/15, Train Loss: 2.1693, Val Loss: 2.2796
2024-12-27 21:23:18,578 - INFO - Epoch 3/15, Train Loss: 2.1546, Val Loss: 2.2650
2024-12-27 21:23:21,340 - INFO - Epoch 4/15, Train Loss: 2.1375, Val Loss: 2.2480
2024-12-27 21:23:24,766 - INFO - Epoch 5/15, Train Loss: 2.1178, Val Loss: 2.2286
2024-12-27 21:23:28,140 - INFO - Epoch 6/15, Train Loss: 2.0960, Val Loss: 2.2072
2024-12-27 21:23:30,565 - INFO - Epoch 7/15, Train Loss: 2.0731, Val Loss: 2.1854
2024-12-27 21:23:33,203 - INFO - Epoch 8/15, Train Loss: 2.0503, Val Loss: 2.1643
2024-12-27 21:23:36,804 - INFO - Epoch 9/15, Train Loss: 2.0287, Val Loss: 2.1449
2024-12-27 21:23:40,631 - INFO - Epoch 10/15, Train Loss: 2.0091, Val Loss: 2.1277
2024-12-27 21:23:43,576 - INFO - Epoch 11/15, Train Loss: 1.9916, Val Loss: 2.1129
2024-12-27 21:23:46,829 - INFO - Epoch 12/15, Train Loss: 1.9770, Val Loss: 2.1000
2024-12-27 21:23:49,928 - INFO - Epoch 13/15, Train Loss: 1.9637, Val Loss: 2.0889
2024-12-27 21:23:53,134 - INFO - Epoch 14/15, Train Loss: 1.9519, Val Loss: 2.0795
2024-12-27 21:23:55,942 - INFO - Epoch 15/15, Train Loss: 1.9425, Val Loss: 2.0713
2024-12-27 21:23:55,942 - INFO - Training completed in 46.71s
2024-12-27 21:23:55,943 - INFO - Final memory usage: CPU 3115.6 MB, GPU 75.5 MB
2024-12-27 21:23:55,943 - INFO - Model training completed in 46.71s
2024-12-27 21:23:56,045 - INFO - Prediction completed in 0.10s
2024-12-27 21:23:56,053 - INFO - Poison rate 0.1 completed in 49.68s
2024-12-27 21:23:56,053 - INFO - 
Processing poison rate: 0.2
2024-12-27 21:23:56,064 - INFO - Total number of labels flipped: 1000
2024-12-27 21:23:56,064 - INFO - Label flipping completed in 0.01s
2024-12-27 21:23:56,064 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:23:56,064 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:23:56,638 - INFO - Feature scaling completed in 0.57s
2024-12-27 21:23:56,638 - INFO - Starting feature selection (k=50)
2024-12-27 21:23:56,651 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:23:56,651 - INFO - Starting anomaly detection
2024-12-27 21:23:58,752 - INFO - Anomaly detection completed in 2.10s
2024-12-27 21:23:58,752 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:23:58,753 - INFO - Total fit_transform time: 2.69s
2024-12-27 21:23:58,753 - INFO - Training set processing completed in 2.69s
2024-12-27 21:23:58,753 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 1280)
2024-12-27 21:23:58,754 - INFO - Memory usage at start_fit: CPU 3115.6 MB, GPU 49.3 MB
2024-12-27 21:23:58,754 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:23:58,835 - INFO - Fitted scaler and transformed data
2024-12-27 21:23:58,835 - INFO - Scaling time: 0.08s
2024-12-27 21:23:58,845 - INFO - Number of unique classes: 10
2024-12-27 21:24:02,098 - INFO - Epoch 1/15, Train Loss: 2.1857, Val Loss: 2.2936
2024-12-27 21:24:05,448 - INFO - Epoch 2/15, Train Loss: 2.1745, Val Loss: 2.2832
2024-12-27 21:24:08,608 - INFO - Epoch 3/15, Train Loss: 2.1621, Val Loss: 2.2709
2024-12-27 21:24:11,544 - INFO - Epoch 4/15, Train Loss: 2.1478, Val Loss: 2.2565
2024-12-27 21:24:14,150 - INFO - Epoch 5/15, Train Loss: 2.1316, Val Loss: 2.2401
2024-12-27 21:24:17,433 - INFO - Epoch 6/15, Train Loss: 2.1134, Val Loss: 2.2220
2024-12-27 21:24:20,301 - INFO - Epoch 7/15, Train Loss: 2.0939, Val Loss: 2.2031
2024-12-27 21:24:23,002 - INFO - Epoch 8/15, Train Loss: 2.0746, Val Loss: 2.1846
2024-12-27 21:24:25,861 - INFO - Epoch 9/15, Train Loss: 2.0561, Val Loss: 2.1676
2024-12-27 21:24:29,429 - INFO - Epoch 10/15, Train Loss: 2.0385, Val Loss: 2.1522
2024-12-27 21:24:33,179 - INFO - Epoch 11/15, Train Loss: 2.0239, Val Loss: 2.1386
2024-12-27 21:24:36,456 - INFO - Epoch 12/15, Train Loss: 2.0095, Val Loss: 2.1269
2024-12-27 21:24:39,827 - INFO - Epoch 13/15, Train Loss: 1.9982, Val Loss: 2.1166
2024-12-27 21:24:43,085 - INFO - Epoch 14/15, Train Loss: 1.9882, Val Loss: 2.1078
2024-12-27 21:24:46,210 - INFO - Epoch 15/15, Train Loss: 1.9784, Val Loss: 2.1001
2024-12-27 21:24:46,210 - INFO - Training completed in 47.46s
2024-12-27 21:24:46,211 - INFO - Final memory usage: CPU 3115.7 MB, GPU 75.5 MB
2024-12-27 21:24:46,211 - INFO - Model training completed in 47.46s
2024-12-27 21:24:46,396 - INFO - Prediction completed in 0.19s
2024-12-27 21:24:46,404 - INFO - Poison rate 0.2 completed in 50.35s
2024-12-27 21:24:46,405 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 21:24:46,405 - INFO - Total evaluation time: 364.85s
2024-12-27 21:24:46,407 - INFO - 
Progress: 99.0% - Evaluating ImageNette with KNeighbors (standard mode, iteration 1/1)
2024-12-27 21:24:46,467 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 21:24:46,722 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 21:24:46,798 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 21:24:46,799 - INFO - Dataset type: image
2024-12-27 21:24:46,799 - INFO - Sample size: 5000
2024-12-27 21:24:46,799 - INFO - Using device: cuda
2024-12-27 21:24:46,802 - INFO - Loading datasets...
2024-12-27 21:24:46,828 - INFO - Dataset loading completed in 0.03s
2024-12-27 21:24:46,828 - INFO - Extracting validation features...
2024-12-27 21:24:46,829 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:23,  1.31it/s]Extracting features:  22%|██▏       | 7/32 [00:00<00:02, 10.13it/s]Extracting features:  31%|███▏      | 10/32 [00:01<00:01, 12.26it/s]Extracting features:  41%|████      | 13/32 [00:01<00:01, 13.25it/s]Extracting features:  50%|█████     | 16/32 [00:01<00:01, 15.70it/s]Extracting features:  59%|█████▉    | 19/32 [00:01<00:00, 13.87it/s]Extracting features:  66%|██████▌   | 21/32 [00:01<00:01, 10.57it/s]Extracting features:  78%|███████▊  | 25/32 [00:02<00:00, 11.75it/s]Extracting features:  91%|█████████ | 29/32 [00:02<00:00, 14.01it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 12.54it/s]
2024-12-27 21:24:49,386 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 21:24:49,387 - INFO - Validation feature extraction completed in 2.56s
2024-12-27 21:24:49,388 - INFO - Extracting training features...
2024-12-27 21:24:49,388 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:09,  2.25it/s]Extracting features:   3%|▎         | 5/157 [00:00<00:14, 10.25it/s]Extracting features:   4%|▍         | 7/157 [00:00<00:20,  7.31it/s]Extracting features:   7%|▋         | 11/157 [00:01<00:14,  9.77it/s]Extracting features:  10%|▉         | 15/157 [00:01<00:11, 12.15it/s]Extracting features:  11%|█         | 17/157 [00:01<00:12, 11.64it/s]Extracting features:  13%|█▎        | 20/157 [00:01<00:11, 11.68it/s]Extracting features:  15%|█▍        | 23/157 [00:02<00:09, 13.80it/s]Extracting features:  16%|█▌        | 25/157 [00:02<00:09, 14.20it/s]Extracting features:  17%|█▋        | 27/157 [00:02<00:09, 13.84it/s]Extracting features:  19%|█▉        | 30/157 [00:02<00:07, 16.46it/s]Extracting features:  20%|██        | 32/157 [00:02<00:08, 14.19it/s]Extracting features:  22%|██▏       | 35/157 [00:02<00:07, 16.85it/s]Extracting features:  24%|██▎       | 37/157 [00:02<00:07, 16.60it/s]Extracting features:  25%|██▍       | 39/157 [00:03<00:06, 16.95it/s]Extracting features:  26%|██▌       | 41/157 [00:03<00:06, 16.77it/s]Extracting features:  27%|██▋       | 43/157 [00:03<00:06, 16.70it/s]Extracting features:  30%|██▉       | 47/157 [00:03<00:05, 18.78it/s]Extracting features:  31%|███       | 49/157 [00:03<00:06, 16.32it/s]Extracting features:  32%|███▏      | 51/157 [00:03<00:06, 17.11it/s]Extracting features:  35%|███▌      | 55/157 [00:03<00:05, 17.58it/s]Extracting features:  37%|███▋      | 58/157 [00:04<00:05, 19.53it/s]Extracting features:  39%|███▉      | 61/157 [00:04<00:04, 19.21it/s]Extracting features:  40%|████      | 63/157 [00:04<00:05, 15.86it/s]Extracting features:  41%|████▏     | 65/157 [00:04<00:05, 16.16it/s]Extracting features:  43%|████▎     | 67/157 [00:04<00:06, 14.76it/s]Extracting features:  45%|████▌     | 71/157 [00:04<00:05, 14.67it/s]Extracting features:  46%|████▋     | 73/157 [00:05<00:05, 14.50it/s]Extracting features:  48%|████▊     | 75/157 [00:05<00:05, 13.75it/s]Extracting features:  50%|█████     | 79/157 [00:05<00:05, 14.21it/s]Extracting features:  52%|█████▏    | 82/157 [00:05<00:04, 16.51it/s]Extracting features:  54%|█████▎    | 84/157 [00:06<00:06, 12.03it/s]Extracting features:  55%|█████▌    | 87/157 [00:06<00:05, 13.57it/s]Extracting features:  57%|█████▋    | 89/157 [00:06<00:05, 11.79it/s]Extracting features:  59%|█████▊    | 92/157 [00:06<00:05, 11.73it/s]Extracting features:  61%|██████    | 96/157 [00:06<00:04, 12.67it/s]Extracting features:  63%|██████▎   | 99/157 [00:07<00:03, 14.54it/s]Extracting features:  64%|██████▍   | 101/157 [00:07<00:03, 14.26it/s]Extracting features:  66%|██████▌   | 103/157 [00:07<00:03, 14.81it/s]Extracting features:  67%|██████▋   | 105/157 [00:07<00:03, 13.53it/s]Extracting features:  68%|██████▊   | 107/157 [00:07<00:03, 14.76it/s]Extracting features:  69%|██████▉   | 109/157 [00:07<00:04, 11.45it/s]Extracting features:  71%|███████▏  | 112/157 [00:08<00:03, 12.78it/s]Extracting features:  73%|███████▎  | 114/157 [00:08<00:03, 11.84it/s]Extracting features:  75%|███████▍  | 117/157 [00:08<00:03, 11.77it/s]Extracting features:  76%|███████▋  | 120/157 [00:08<00:02, 13.41it/s]Extracting features:  78%|███████▊  | 122/157 [00:08<00:02, 14.42it/s]Extracting features:  79%|███████▉  | 124/157 [00:09<00:02, 12.72it/s]Extracting features:  80%|████████  | 126/157 [00:09<00:02, 12.97it/s]Extracting features:  82%|████████▏ | 129/157 [00:09<00:01, 14.06it/s]Extracting features:  84%|████████▍ | 132/157 [00:09<00:01, 16.68it/s]Extracting features:  85%|████████▌ | 134/157 [00:09<00:01, 15.13it/s]Extracting features:  87%|████████▋ | 137/157 [00:09<00:01, 14.03it/s]Extracting features:  90%|████████▉ | 141/157 [00:10<00:00, 16.40it/s]Extracting features:  92%|█████████▏| 144/157 [00:10<00:00, 15.27it/s]Extracting features:  94%|█████████▍| 148/157 [00:10<00:00, 15.77it/s]Extracting features:  97%|█████████▋| 152/157 [00:10<00:00, 16.46it/s]Extracting features:  99%|█████████▉| 156/157 [00:10<00:00, 17.86it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 14.23it/s]
2024-12-27 21:25:00,435 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 21:25:00,435 - INFO - Training feature extraction completed in 11.05s
2024-12-27 21:25:00,435 - INFO - Creating model for classifier: KNeighbors
2024-12-27 21:25:00,436 - INFO - Using device: cuda
2024-12-27 21:25:00,436 - INFO - 
Processing poison rate: 0.0
2024-12-27 21:25:00,436 - INFO - Training set processing completed in 0.00s
2024-12-27 21:25:00,436 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:25:00,438 - INFO - Memory usage at start_fit: CPU 3113.3 MB, GPU 47.3 MB
2024-12-27 21:25:00,438 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:25:00,521 - INFO - Fitted scaler and transformed data
2024-12-27 21:25:00,521 - INFO - Scaling time: 0.08s
2024-12-27 21:25:00,526 - INFO - Training completed in 0.09s
2024-12-27 21:25:00,527 - INFO - Final memory usage: CPU 3113.3 MB, GPU 71.8 MB
2024-12-27 21:25:00,527 - INFO - Model training completed in 0.09s
2024-12-27 21:25:00,544 - INFO - Prediction completed in 0.02s
2024-12-27 21:25:00,552 - INFO - Poison rate 0.0 completed in 0.12s
2024-12-27 21:25:00,553 - INFO - 
Processing poison rate: 0.01
2024-12-27 21:25:00,554 - INFO - Total number of labels flipped: 50
2024-12-27 21:25:00,554 - INFO - Label flipping completed in 0.00s
2024-12-27 21:25:00,554 - INFO - Training set processing completed in 0.00s
2024-12-27 21:25:00,554 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:25:00,555 - INFO - Memory usage at start_fit: CPU 3113.3 MB, GPU 71.8 MB
2024-12-27 21:25:00,555 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:25:00,614 - INFO - Fitted scaler and transformed data
2024-12-27 21:25:00,615 - INFO - Scaling time: 0.06s
2024-12-27 21:25:00,620 - INFO - Training completed in 0.06s
2024-12-27 21:25:00,620 - INFO - Final memory usage: CPU 3113.3 MB, GPU 71.8 MB
2024-12-27 21:25:00,620 - INFO - Model training completed in 0.07s
2024-12-27 21:25:00,634 - INFO - Prediction completed in 0.01s
2024-12-27 21:25:00,642 - INFO - Poison rate 0.01 completed in 0.09s
2024-12-27 21:25:00,642 - INFO - 
Processing poison rate: 0.03
2024-12-27 21:25:00,644 - INFO - Total number of labels flipped: 150
2024-12-27 21:25:00,645 - INFO - Label flipping completed in 0.00s
2024-12-27 21:25:00,645 - INFO - Training set processing completed in 0.00s
2024-12-27 21:25:00,645 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:25:00,646 - INFO - Memory usage at start_fit: CPU 3113.3 MB, GPU 71.8 MB
2024-12-27 21:25:00,646 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:25:00,705 - INFO - Fitted scaler and transformed data
2024-12-27 21:25:00,705 - INFO - Scaling time: 0.06s
2024-12-27 21:25:00,710 - INFO - Training completed in 0.06s
2024-12-27 21:25:00,711 - INFO - Final memory usage: CPU 3113.3 MB, GPU 71.8 MB
2024-12-27 21:25:00,711 - INFO - Model training completed in 0.07s
2024-12-27 21:25:00,725 - INFO - Prediction completed in 0.01s
2024-12-27 21:25:00,733 - INFO - Poison rate 0.03 completed in 0.09s
2024-12-27 21:25:00,733 - INFO - 
Processing poison rate: 0.05
2024-12-27 21:25:00,736 - INFO - Total number of labels flipped: 250
2024-12-27 21:25:00,736 - INFO - Label flipping completed in 0.00s
2024-12-27 21:25:00,737 - INFO - Training set processing completed in 0.00s
2024-12-27 21:25:00,737 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:25:00,738 - INFO - Memory usage at start_fit: CPU 3113.3 MB, GPU 71.8 MB
2024-12-27 21:25:00,738 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:25:00,799 - INFO - Fitted scaler and transformed data
2024-12-27 21:25:00,799 - INFO - Scaling time: 0.06s
2024-12-27 21:25:00,804 - INFO - Training completed in 0.07s
2024-12-27 21:25:00,804 - INFO - Final memory usage: CPU 3113.3 MB, GPU 71.8 MB
2024-12-27 21:25:00,804 - INFO - Model training completed in 0.07s
2024-12-27 21:25:00,819 - INFO - Prediction completed in 0.01s
2024-12-27 21:25:00,827 - INFO - Poison rate 0.05 completed in 0.09s
2024-12-27 21:25:00,827 - INFO - 
Processing poison rate: 0.07
2024-12-27 21:25:00,831 - INFO - Total number of labels flipped: 350
2024-12-27 21:25:00,831 - INFO - Label flipping completed in 0.00s
2024-12-27 21:25:00,831 - INFO - Training set processing completed in 0.00s
2024-12-27 21:25:00,831 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:25:00,832 - INFO - Memory usage at start_fit: CPU 3113.3 MB, GPU 71.8 MB
2024-12-27 21:25:00,832 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:25:00,892 - INFO - Fitted scaler and transformed data
2024-12-27 21:25:00,892 - INFO - Scaling time: 0.06s
2024-12-27 21:25:00,897 - INFO - Training completed in 0.06s
2024-12-27 21:25:00,897 - INFO - Final memory usage: CPU 3113.3 MB, GPU 71.8 MB
2024-12-27 21:25:00,897 - INFO - Model training completed in 0.07s
2024-12-27 21:25:00,912 - INFO - Prediction completed in 0.01s
2024-12-27 21:25:00,919 - INFO - Poison rate 0.07 completed in 0.09s
2024-12-27 21:25:00,919 - INFO - 
Processing poison rate: 0.1
2024-12-27 21:25:00,925 - INFO - Total number of labels flipped: 500
2024-12-27 21:25:00,925 - INFO - Label flipping completed in 0.01s
2024-12-27 21:25:00,925 - INFO - Training set processing completed in 0.00s
2024-12-27 21:25:00,925 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:25:00,926 - INFO - Memory usage at start_fit: CPU 3113.3 MB, GPU 71.8 MB
2024-12-27 21:25:00,926 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:25:01,000 - INFO - Fitted scaler and transformed data
2024-12-27 21:25:01,000 - INFO - Scaling time: 0.07s
2024-12-27 21:25:01,005 - INFO - Training completed in 0.08s
2024-12-27 21:25:01,006 - INFO - Final memory usage: CPU 3113.3 MB, GPU 71.8 MB
2024-12-27 21:25:01,006 - INFO - Model training completed in 0.08s
2024-12-27 21:25:01,024 - INFO - Prediction completed in 0.02s
2024-12-27 21:25:01,031 - INFO - Poison rate 0.1 completed in 0.11s
2024-12-27 21:25:01,032 - INFO - 
Processing poison rate: 0.2
2024-12-27 21:25:01,043 - INFO - Total number of labels flipped: 1000
2024-12-27 21:25:01,043 - INFO - Label flipping completed in 0.01s
2024-12-27 21:25:01,043 - INFO - Training set processing completed in 0.00s
2024-12-27 21:25:01,043 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:25:01,044 - INFO - Memory usage at start_fit: CPU 3113.3 MB, GPU 71.8 MB
2024-12-27 21:25:01,044 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:25:01,111 - INFO - Fitted scaler and transformed data
2024-12-27 21:25:01,111 - INFO - Scaling time: 0.07s
2024-12-27 21:25:01,118 - INFO - Training completed in 0.07s
2024-12-27 21:25:01,119 - INFO - Final memory usage: CPU 3113.3 MB, GPU 71.8 MB
2024-12-27 21:25:01,119 - INFO - Model training completed in 0.08s
2024-12-27 21:25:01,132 - INFO - Prediction completed in 0.01s
2024-12-27 21:25:01,139 - INFO - Poison rate 0.2 completed in 0.11s
2024-12-27 21:25:01,140 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 21:25:01,140 - INFO - Total evaluation time: 14.34s
2024-12-27 21:25:01,142 - INFO - 
Progress: 100.0% - Evaluating ImageNette with KNeighbors (dynadetect mode, iteration 1/1)
2024-12-27 21:25:01,226 - INFO - Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
2024-12-27 21:25:01,306 - INFO - [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-12-27 21:25:01,392 - INFO - Initialized DatasetHandler for ImageNette
2024-12-27 21:25:01,392 - INFO - Dataset type: image
2024-12-27 21:25:01,392 - INFO - Sample size: 5000
2024-12-27 21:25:01,392 - INFO - Using device: cuda
2024-12-27 21:25:01,394 - INFO - Loading datasets...
2024-12-27 21:25:01,419 - INFO - Dataset loading completed in 0.02s
2024-12-27 21:25:01,419 - INFO - Extracting validation features...
2024-12-27 21:25:01,419 - INFO - Extracting features from 1000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/32 [00:00<?, ?it/s]Extracting features:   3%|▎         | 1/32 [00:00<00:15,  2.01it/s]Extracting features:  16%|█▌        | 5/32 [00:00<00:03,  8.12it/s]Extracting features:  28%|██▊       | 9/32 [00:00<00:02, 11.31it/s]Extracting features:  41%|████      | 13/32 [00:01<00:01, 13.25it/s]Extracting features:  47%|████▋     | 15/32 [00:01<00:01, 14.13it/s]Extracting features:  53%|█████▎    | 17/32 [00:01<00:01, 11.94it/s]Extracting features:  66%|██████▌   | 21/32 [00:01<00:00, 13.02it/s]Extracting features:  72%|███████▏  | 23/32 [00:02<00:00, 11.30it/s]Extracting features:  81%|████████▏ | 26/32 [00:02<00:00, 12.52it/s]Extracting features:  91%|█████████ | 29/32 [00:02<00:00, 14.32it/s]Extracting features: 100%|██████████| 32/32 [00:02<00:00, 12.49it/s]
2024-12-27 21:25:03,987 - INFO - Feature extraction completed. Final feature shape: (1000, 1280)
2024-12-27 21:25:03,988 - INFO - Validation feature extraction completed in 2.57s
2024-12-27 21:25:03,988 - INFO - Extracting training features...
2024-12-27 21:25:03,989 - INFO - Extracting features from 5000 samples using EfficientNetB0...
Extracting features:   0%|          | 0/157 [00:00<?, ?it/s]Extracting features:   1%|          | 1/157 [00:00<01:14,  2.10it/s]Extracting features:   3%|▎         | 5/157 [00:00<00:16,  9.11it/s]Extracting features:   4%|▍         | 7/157 [00:00<00:19,  7.77it/s]Extracting features:   7%|▋         | 11/157 [00:01<00:15,  9.41it/s]Extracting features:   9%|▉         | 14/157 [00:01<00:12, 11.16it/s]Extracting features:  10%|█         | 16/157 [00:01<00:13, 10.56it/s]Extracting features:  12%|█▏        | 19/157 [00:01<00:11, 11.55it/s]Extracting features:  14%|█▍        | 22/157 [00:02<00:10, 13.02it/s]Extracting features:  16%|█▌        | 25/157 [00:02<00:08, 15.82it/s]Extracting features:  17%|█▋        | 27/157 [00:02<00:08, 14.79it/s]Extracting features:  19%|█▉        | 30/157 [00:02<00:08, 14.71it/s]Extracting features:  22%|██▏       | 34/157 [00:02<00:07, 16.63it/s]Extracting features:  24%|██▍       | 38/157 [00:02<00:06, 18.43it/s]Extracting features:  27%|██▋       | 42/157 [00:03<00:05, 20.12it/s]Extracting features:  29%|██▊       | 45/157 [00:03<00:05, 19.54it/s]Extracting features:  31%|███       | 48/157 [00:03<00:05, 19.64it/s]Extracting features:  32%|███▏      | 51/157 [00:03<00:06, 15.94it/s]Extracting features:  35%|███▌      | 55/157 [00:03<00:06, 15.99it/s]Extracting features:  37%|███▋      | 58/157 [00:04<00:06, 15.18it/s]Extracting features:  39%|███▉      | 62/157 [00:04<00:05, 16.09it/s]Extracting features:  41%|████      | 64/157 [00:04<00:05, 16.07it/s]Extracting features:  42%|████▏     | 66/157 [00:04<00:05, 16.29it/s]Extracting features:  43%|████▎     | 68/157 [00:04<00:06, 13.13it/s]Extracting features:  45%|████▌     | 71/157 [00:05<00:06, 13.08it/s]Extracting features:  48%|████▊     | 75/157 [00:05<00:06, 13.41it/s]Extracting features:  50%|█████     | 79/157 [00:05<00:06, 12.80it/s]Extracting features:  53%|█████▎    | 83/157 [00:06<00:05, 12.82it/s]Extracting features:  55%|█████▌    | 87/157 [00:06<00:05, 13.87it/s]Extracting features:  58%|█████▊    | 91/157 [00:06<00:04, 13.63it/s]Extracting features:  61%|██████    | 95/157 [00:06<00:04, 13.54it/s]Extracting features:  63%|██████▎   | 99/157 [00:07<00:04, 13.25it/s]Extracting features:  64%|██████▍   | 101/157 [00:07<00:04, 13.38it/s]Extracting features:  66%|██████▌   | 104/157 [00:07<00:04, 11.21it/s]Extracting features:  69%|██████▉   | 108/157 [00:08<00:04, 11.56it/s]Extracting features:  71%|███████   | 111/157 [00:08<00:03, 13.50it/s]Extracting features:  72%|███████▏  | 113/157 [00:08<00:03, 13.84it/s]Extracting features:  73%|███████▎  | 115/157 [00:08<00:03, 10.81it/s]Extracting features:  76%|███████▌  | 119/157 [00:08<00:03, 12.00it/s]Extracting features:  78%|███████▊  | 123/157 [00:09<00:02, 12.84it/s]Extracting features:  81%|████████  | 127/157 [00:09<00:02, 14.17it/s]Extracting features:  83%|████████▎ | 130/157 [00:09<00:01, 15.91it/s]Extracting features:  84%|████████▍ | 132/157 [00:09<00:01, 15.95it/s]Extracting features:  86%|████████▌ | 135/157 [00:09<00:01, 15.18it/s]Extracting features:  89%|████████▊ | 139/157 [00:10<00:01, 15.96it/s]Extracting features:  91%|█████████ | 143/157 [00:10<00:00, 15.65it/s]Extracting features:  93%|█████████▎| 146/157 [00:10<00:00, 14.92it/s]Extracting features:  96%|█████████▌| 150/157 [00:10<00:00, 15.26it/s]Extracting features:  98%|█████████▊| 154/157 [00:11<00:00, 16.26it/s]Extracting features: 100%|██████████| 157/157 [00:11<00:00, 14.06it/s]
2024-12-27 21:25:15,166 - INFO - Feature extraction completed. Final feature shape: (5000, 1280)
2024-12-27 21:25:15,166 - INFO - Training feature extraction completed in 11.18s
2024-12-27 21:25:15,166 - INFO - Creating model for classifier: KNeighbors
2024-12-27 21:25:15,166 - INFO - Using device: cuda
2024-12-27 21:25:15,166 - INFO - 
Processing poison rate: 0.0
2024-12-27 21:25:15,166 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:25:15,167 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:25:15,743 - INFO - Feature scaling completed in 0.58s
2024-12-27 21:25:15,743 - INFO - Starting feature selection (k=50)
2024-12-27 21:25:15,751 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:25:15,752 - INFO - Starting anomaly detection
2024-12-27 21:25:17,490 - INFO - Anomaly detection completed in 1.74s
2024-12-27 21:25:17,490 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:25:17,490 - INFO - Total fit_transform time: 2.32s
2024-12-27 21:25:17,491 - INFO - Training set processing completed in 2.32s
2024-12-27 21:25:17,491 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:25:17,492 - INFO - Memory usage at start_fit: CPU 3110.8 MB, GPU 47.3 MB
2024-12-27 21:25:17,492 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:25:17,566 - INFO - Fitted scaler and transformed data
2024-12-27 21:25:17,566 - INFO - Scaling time: 0.07s
2024-12-27 21:25:17,572 - INFO - Training completed in 0.08s
2024-12-27 21:25:17,573 - INFO - Final memory usage: CPU 3110.8 MB, GPU 71.8 MB
2024-12-27 21:25:17,573 - INFO - Model training completed in 0.08s
2024-12-27 21:25:17,596 - INFO - Prediction completed in 0.02s
2024-12-27 21:25:17,604 - INFO - Poison rate 0.0 completed in 2.44s
2024-12-27 21:25:17,604 - INFO - 
Processing poison rate: 0.01
2024-12-27 21:25:17,605 - INFO - Total number of labels flipped: 50
2024-12-27 21:25:17,605 - INFO - Label flipping completed in 0.00s
2024-12-27 21:25:17,605 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:25:17,605 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:25:18,208 - INFO - Feature scaling completed in 0.60s
2024-12-27 21:25:18,208 - INFO - Starting feature selection (k=50)
2024-12-27 21:25:18,214 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:25:18,214 - INFO - Starting anomaly detection
2024-12-27 21:25:20,262 - INFO - Anomaly detection completed in 2.05s
2024-12-27 21:25:20,262 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:25:20,262 - INFO - Total fit_transform time: 2.66s
2024-12-27 21:25:20,262 - INFO - Training set processing completed in 2.66s
2024-12-27 21:25:20,262 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:25:20,263 - INFO - Memory usage at start_fit: CPU 3110.8 MB, GPU 71.8 MB
2024-12-27 21:25:20,264 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:25:20,328 - INFO - Fitted scaler and transformed data
2024-12-27 21:25:20,329 - INFO - Scaling time: 0.07s
2024-12-27 21:25:20,335 - INFO - Training completed in 0.07s
2024-12-27 21:25:20,336 - INFO - Final memory usage: CPU 3110.8 MB, GPU 71.8 MB
2024-12-27 21:25:20,336 - INFO - Model training completed in 0.07s
2024-12-27 21:25:20,361 - INFO - Prediction completed in 0.03s
2024-12-27 21:25:20,368 - INFO - Poison rate 0.01 completed in 2.76s
2024-12-27 21:25:20,369 - INFO - 
Processing poison rate: 0.03
2024-12-27 21:25:20,371 - INFO - Total number of labels flipped: 150
2024-12-27 21:25:20,371 - INFO - Label flipping completed in 0.00s
2024-12-27 21:25:20,371 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:25:20,371 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:25:20,971 - INFO - Feature scaling completed in 0.60s
2024-12-27 21:25:20,971 - INFO - Starting feature selection (k=50)
2024-12-27 21:25:20,982 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:25:20,982 - INFO - Starting anomaly detection
2024-12-27 21:25:23,003 - INFO - Anomaly detection completed in 2.02s
2024-12-27 21:25:23,003 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:25:23,003 - INFO - Total fit_transform time: 2.63s
2024-12-27 21:25:23,004 - INFO - Training set processing completed in 2.63s
2024-12-27 21:25:23,004 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:25:23,005 - INFO - Memory usage at start_fit: CPU 3110.8 MB, GPU 71.8 MB
2024-12-27 21:25:23,005 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:25:23,072 - INFO - Fitted scaler and transformed data
2024-12-27 21:25:23,072 - INFO - Scaling time: 0.07s
2024-12-27 21:25:23,079 - INFO - Training completed in 0.07s
2024-12-27 21:25:23,080 - INFO - Final memory usage: CPU 3110.8 MB, GPU 71.8 MB
2024-12-27 21:25:23,080 - INFO - Model training completed in 0.08s
2024-12-27 21:25:23,105 - INFO - Prediction completed in 0.02s
2024-12-27 21:25:23,113 - INFO - Poison rate 0.03 completed in 2.74s
2024-12-27 21:25:23,113 - INFO - 
Processing poison rate: 0.05
2024-12-27 21:25:23,116 - INFO - Total number of labels flipped: 250
2024-12-27 21:25:23,116 - INFO - Label flipping completed in 0.00s
2024-12-27 21:25:23,116 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:25:23,116 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:25:23,718 - INFO - Feature scaling completed in 0.60s
2024-12-27 21:25:23,718 - INFO - Starting feature selection (k=50)
2024-12-27 21:25:23,732 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:25:23,732 - INFO - Starting anomaly detection
2024-12-27 21:25:25,654 - INFO - Anomaly detection completed in 1.92s
2024-12-27 21:25:25,654 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:25:25,655 - INFO - Total fit_transform time: 2.54s
2024-12-27 21:25:25,655 - INFO - Training set processing completed in 2.54s
2024-12-27 21:25:25,655 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:25:25,656 - INFO - Memory usage at start_fit: CPU 3110.8 MB, GPU 71.8 MB
2024-12-27 21:25:25,656 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:25:25,727 - INFO - Fitted scaler and transformed data
2024-12-27 21:25:25,727 - INFO - Scaling time: 0.07s
2024-12-27 21:25:25,734 - INFO - Training completed in 0.08s
2024-12-27 21:25:25,734 - INFO - Final memory usage: CPU 3110.8 MB, GPU 71.8 MB
2024-12-27 21:25:25,734 - INFO - Model training completed in 0.08s
2024-12-27 21:25:25,762 - INFO - Prediction completed in 0.03s
2024-12-27 21:25:25,769 - INFO - Poison rate 0.05 completed in 2.66s
2024-12-27 21:25:25,769 - INFO - 
Processing poison rate: 0.07
2024-12-27 21:25:25,774 - INFO - Total number of labels flipped: 350
2024-12-27 21:25:25,774 - INFO - Label flipping completed in 0.00s
2024-12-27 21:25:25,774 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:25:25,774 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:25:26,339 - INFO - Feature scaling completed in 0.56s
2024-12-27 21:25:26,339 - INFO - Starting feature selection (k=50)
2024-12-27 21:25:26,353 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:25:26,353 - INFO - Starting anomaly detection
2024-12-27 21:25:28,291 - INFO - Anomaly detection completed in 1.94s
2024-12-27 21:25:28,291 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:25:28,291 - INFO - Total fit_transform time: 2.52s
2024-12-27 21:25:28,291 - INFO - Training set processing completed in 2.52s
2024-12-27 21:25:28,291 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:25:28,292 - INFO - Memory usage at start_fit: CPU 3110.8 MB, GPU 71.8 MB
2024-12-27 21:25:28,292 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:25:28,359 - INFO - Fitted scaler and transformed data
2024-12-27 21:25:28,359 - INFO - Scaling time: 0.07s
2024-12-27 21:25:28,366 - INFO - Training completed in 0.07s
2024-12-27 21:25:28,366 - INFO - Final memory usage: CPU 3110.8 MB, GPU 71.8 MB
2024-12-27 21:25:28,366 - INFO - Model training completed in 0.07s
2024-12-27 21:25:28,392 - INFO - Prediction completed in 0.03s
2024-12-27 21:25:28,399 - INFO - Poison rate 0.07 completed in 2.63s
2024-12-27 21:25:28,399 - INFO - 
Processing poison rate: 0.1
2024-12-27 21:25:28,405 - INFO - Total number of labels flipped: 500
2024-12-27 21:25:28,406 - INFO - Label flipping completed in 0.01s
2024-12-27 21:25:28,406 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:25:28,406 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:25:28,938 - INFO - Feature scaling completed in 0.53s
2024-12-27 21:25:28,938 - INFO - Starting feature selection (k=50)
2024-12-27 21:25:28,952 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:25:28,952 - INFO - Starting anomaly detection
2024-12-27 21:25:30,987 - INFO - Anomaly detection completed in 2.03s
2024-12-27 21:25:30,987 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:25:30,987 - INFO - Total fit_transform time: 2.58s
2024-12-27 21:25:30,987 - INFO - Training set processing completed in 2.58s
2024-12-27 21:25:30,987 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:25:30,988 - INFO - Memory usage at start_fit: CPU 3110.8 MB, GPU 71.8 MB
2024-12-27 21:25:30,988 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:25:31,056 - INFO - Fitted scaler and transformed data
2024-12-27 21:25:31,057 - INFO - Scaling time: 0.07s
2024-12-27 21:25:31,064 - INFO - Training completed in 0.08s
2024-12-27 21:25:31,065 - INFO - Final memory usage: CPU 3110.8 MB, GPU 71.8 MB
2024-12-27 21:25:31,065 - INFO - Model training completed in 0.08s
2024-12-27 21:25:31,097 - INFO - Prediction completed in 0.03s
2024-12-27 21:25:31,105 - INFO - Poison rate 0.1 completed in 2.71s
2024-12-27 21:25:31,105 - INFO - 
Processing poison rate: 0.2
2024-12-27 21:25:31,116 - INFO - Total number of labels flipped: 1000
2024-12-27 21:25:31,116 - INFO - Label flipping completed in 0.01s
2024-12-27 21:25:31,116 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 21:25:31,116 - INFO - Starting feature scaling on shape (5000, 1280)
2024-12-27 21:25:31,664 - INFO - Feature scaling completed in 0.55s
2024-12-27 21:25:31,665 - INFO - Starting feature selection (k=50)
2024-12-27 21:25:31,677 - INFO - Feature selection completed in 0.01s. Output shape: (5000, 50)
2024-12-27 21:25:31,677 - INFO - Starting anomaly detection
2024-12-27 21:25:32,977 - INFO - Anomaly detection completed in 1.30s
2024-12-27 21:25:32,977 - INFO - Found 500 outliers (10.0%)
2024-12-27 21:25:32,977 - INFO - Total fit_transform time: 1.86s
2024-12-27 21:25:32,977 - INFO - Training set processing completed in 1.86s
2024-12-27 21:25:32,977 - INFO - Fitting KNeighborsWrapper model with data shape: (5000, 1280)
2024-12-27 21:25:32,979 - INFO - Memory usage at start_fit: CPU 3110.8 MB, GPU 71.8 MB
2024-12-27 21:25:32,979 - INFO - Input data shape: (5000, 1280), labels shape: (5000,)
2024-12-27 21:25:33,051 - INFO - Fitted scaler and transformed data
2024-12-27 21:25:33,051 - INFO - Scaling time: 0.07s
2024-12-27 21:25:33,060 - INFO - Training completed in 0.08s
2024-12-27 21:25:33,061 - INFO - Final memory usage: CPU 3110.8 MB, GPU 71.8 MB
2024-12-27 21:25:33,061 - INFO - Model training completed in 0.08s
2024-12-27 21:25:33,089 - INFO - Prediction completed in 0.03s
2024-12-27 21:25:33,096 - INFO - Poison rate 0.2 completed in 1.99s
2024-12-27 21:25:33,097 - INFO - Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
2024-12-27 21:25:33,097 - INFO - Total evaluation time: 31.70s
2024-12-27 21:25:33,098 - INFO - Completed evaluation for ImageNette
2024-12-27 21:25:33,099 - INFO - 
Experiment run completed

Experiment completed successfully
Results saved to: /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_171305.csv
