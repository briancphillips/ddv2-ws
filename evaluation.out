nohup: ignoring input
2024-12-29 12:46:57,026 - INFO - Logging setup completed successfully
2024-12-29 12:46:57,027 - INFO - Log file created at: /home/brian/Notebooks/ddv2-ws/logs/experiment_20241229_124656.log
2024-12-29 12:46:57,027 - INFO - Starting experiment run
2024-12-29 12:46:57,028 - INFO - Test mode: False
2024-12-29 12:46:57,028 - INFO - 
Processing dataset: GTSRB
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 12:46:57,513 - INFO - 
Progress: 1.0% - Evaluating GTSRB with SVM (standard mode, iteration 1/1)
2024-12-29 12:46:57,708 - INFO - Loading datasets...
2024-12-29 12:46:57,729 - INFO - Dataset loading completed in 0.02s
2024-12-29 12:46:57,729 - INFO - Extracting validation features...
2024-12-29 12:46:57,729 - INFO - Extracting features from 3925 samples...

Archiving previous files...
Archiving results from: /home/brian/Notebooks/ddv2-ws/results
Results archived
Archiving logs from: /home/brian/Notebooks/ddv2-ws/logs
Logs archived
Cleanup completed
Archiving finished - starting evaluation

Logging to: /home/brian/Notebooks/ddv2-ws/logs/experiment_20241229_124656.log
Initializing configuration manager...
Getting configurations...

Evaluation Plan:
- Datasets: ['GTSRB', 'GTSRB', 'GTSRB', 'GTSRB', 'ImageNette', 'ImageNette', 'ImageNette', 'ImageNette', 'CIFAR100', 'CIFAR100', 'CIFAR100', 'CIFAR100']
- Classifiers: ['SVM', 'LogisticRegression', 'RandomForest', 'KNeighbors']
- Sample sizes: Full
- Modes: ['standard', 'dynadetect']
- Iterations: 1

Starting evaluation...
2024-12-29 12:47:07,192 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 12:47:07,197 - INFO - Validation feature extraction completed in 9.47s
2024-12-29 12:47:07,197 - INFO - Extracting training features...
2024-12-29 12:47:07,197 - INFO - Extracting features from 9469 samples...
2024-12-29 12:47:28,607 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 12:47:28,617 - INFO - Training feature extraction completed in 21.42s
2024-12-29 12:47:28,617 - INFO - Creating model for classifier: SVM
2024-12-29 12:47:28,618 - INFO - Using device: cuda
2024-12-29 12:47:28,618 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-29 12:47:28,618 - INFO - 
Processing poison rate: 0.0
2024-12-29 12:47:28,619 - INFO - Training set processing completed in 0.00s
2024-12-29 12:47:28,619 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 12:47:28,621 - INFO - Memory usage at start_fit: CPU 1684.3 MB, GPU 87.1 MB
2024-12-29 12:47:28,621 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:47:28,626 - INFO - Number of unique classes: 10
2024-12-29 12:47:28,697 - INFO - Fitted scaler and transformed data
2024-12-29 12:47:28,697 - INFO - Scaling time: 0.07s
2024-12-29 12:47:29,325 - INFO - Epoch 1/500, Train Loss: 0.7841, Val Loss: 0.1599
2024-12-29 12:47:29,629 - INFO - Epoch 2/500, Train Loss: 0.0886, Val Loss: 0.1259
2024-12-29 12:47:29,966 - INFO - Epoch 3/500, Train Loss: 0.0584, Val Loss: 0.1128
2024-12-29 12:47:30,319 - INFO - Epoch 4/500, Train Loss: 0.0421, Val Loss: 0.1075
2024-12-29 12:47:30,601 - INFO - Epoch 5/500, Train Loss: 0.0326, Val Loss: 0.1009
2024-12-29 12:47:30,909 - INFO - Epoch 6/500, Train Loss: 0.0259, Val Loss: 0.0974
2024-12-29 12:47:31,213 - INFO - Epoch 7/500, Train Loss: 0.0209, Val Loss: 0.0956
2024-12-29 12:47:31,518 - INFO - Epoch 8/500, Train Loss: 0.0172, Val Loss: 0.0914
2024-12-29 12:47:31,819 - INFO - Epoch 9/500, Train Loss: 0.0140, Val Loss: 0.0936
2024-12-29 12:47:32,121 - INFO - Epoch 10/500, Train Loss: 0.0120, Val Loss: 0.0938
2024-12-29 12:47:32,438 - INFO - Epoch 11/500, Train Loss: 0.0103, Val Loss: 0.0918
2024-12-29 12:47:32,756 - INFO - Epoch 12/500, Train Loss: 0.0088, Val Loss: 0.0933
2024-12-29 12:47:33,064 - INFO - Epoch 13/500, Train Loss: 0.0079, Val Loss: 0.0908
2024-12-29 12:47:33,064 - INFO - Early stopping triggered at epoch 13
2024-12-29 12:47:33,064 - INFO - Training completed in 4.44s
2024-12-29 12:47:33,065 - INFO - Final memory usage: CPU 2013.2 MB, GPU 103.6 MB
2024-12-29 12:47:33,065 - INFO - Model training completed in 4.45s
2024-12-29 12:47:33,115 - INFO - Prediction completed in 0.05s
2024-12-29 12:47:33,125 - INFO - Poison rate 0.0 completed in 4.51s
2024-12-29 12:47:33,125 - INFO - 
Processing poison rate: 0.01
2024-12-29 12:47:33,127 - INFO - Total number of labels flipped: 94
2024-12-29 12:47:33,127 - INFO - Label flipping completed in 0.00s
2024-12-29 12:47:33,127 - INFO - Training set processing completed in 0.00s
2024-12-29 12:47:33,127 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 12:47:33,128 - INFO - Memory usage at start_fit: CPU 2007.3 MB, GPU 103.5 MB
2024-12-29 12:47:33,128 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:47:33,133 - INFO - Number of unique classes: 10
2024-12-29 12:47:33,200 - INFO - Fitted scaler and transformed data
2024-12-29 12:47:33,201 - INFO - Scaling time: 0.07s
2024-12-29 12:47:33,538 - INFO - Epoch 1/500, Train Loss: 0.9975, Val Loss: 0.3222
2024-12-29 12:47:33,868 - INFO - Epoch 2/500, Train Loss: 0.2178, Val Loss: 0.2834
2024-12-29 12:47:34,209 - INFO - Epoch 3/500, Train Loss: 0.1712, Val Loss: 0.2726
2024-12-29 12:47:34,530 - INFO - Epoch 4/500, Train Loss: 0.1412, Val Loss: 0.2626
2024-12-29 12:47:34,872 - INFO - Epoch 5/500, Train Loss: 0.1183, Val Loss: 0.2624
2024-12-29 12:47:35,266 - INFO - Epoch 6/500, Train Loss: 0.1003, Val Loss: 0.2680
2024-12-29 12:47:35,565 - INFO - Epoch 7/500, Train Loss: 0.0880, Val Loss: 0.2586
2024-12-29 12:47:35,918 - INFO - Epoch 8/500, Train Loss: 0.0796, Val Loss: 0.2660
2024-12-29 12:47:36,228 - INFO - Epoch 9/500, Train Loss: 0.0716, Val Loss: 0.2602
2024-12-29 12:47:36,573 - INFO - Epoch 10/500, Train Loss: 0.0658, Val Loss: 0.2631
2024-12-29 12:47:36,921 - INFO - Epoch 11/500, Train Loss: 0.0608, Val Loss: 0.2634
2024-12-29 12:47:37,273 - INFO - Epoch 12/500, Train Loss: 0.0570, Val Loss: 0.2637
2024-12-29 12:47:37,274 - INFO - Early stopping triggered at epoch 12
2024-12-29 12:47:37,274 - INFO - Training completed in 4.15s
2024-12-29 12:47:37,275 - INFO - Final memory usage: CPU 2040.0 MB, GPU 103.6 MB
2024-12-29 12:47:37,276 - INFO - Model training completed in 4.15s
2024-12-29 12:47:37,353 - INFO - Prediction completed in 0.08s
2024-12-29 12:47:37,362 - INFO - Poison rate 0.01 completed in 4.24s
2024-12-29 12:47:37,362 - INFO - 
Processing poison rate: 0.03
2024-12-29 12:47:37,366 - INFO - Total number of labels flipped: 284
2024-12-29 12:47:37,366 - INFO - Label flipping completed in 0.00s
2024-12-29 12:47:37,366 - INFO - Training set processing completed in 0.00s
2024-12-29 12:47:37,366 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 12:47:37,367 - INFO - Memory usage at start_fit: CPU 2040.0 MB, GPU 103.5 MB
2024-12-29 12:47:37,368 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:47:37,371 - INFO - Number of unique classes: 10
2024-12-29 12:47:37,450 - INFO - Fitted scaler and transformed data
2024-12-29 12:47:37,450 - INFO - Scaling time: 0.08s
2024-12-29 12:47:37,805 - INFO - Epoch 1/500, Train Loss: 1.2510, Val Loss: 0.5940
2024-12-29 12:47:38,181 - INFO - Epoch 2/500, Train Loss: 0.4502, Val Loss: 0.5939
2024-12-29 12:47:38,529 - INFO - Epoch 3/500, Train Loss: 0.3771, Val Loss: 0.5898
2024-12-29 12:47:38,874 - INFO - Epoch 4/500, Train Loss: 0.3258, Val Loss: 0.5909
2024-12-29 12:47:39,204 - INFO - Epoch 5/500, Train Loss: 0.2891, Val Loss: 0.6035
2024-12-29 12:47:39,530 - INFO - Epoch 6/500, Train Loss: 0.2592, Val Loss: 0.6185
2024-12-29 12:47:39,862 - INFO - Epoch 7/500, Train Loss: 0.2386, Val Loss: 0.6118
2024-12-29 12:47:40,179 - INFO - Epoch 8/500, Train Loss: 0.2163, Val Loss: 0.6081
2024-12-29 12:47:40,179 - INFO - Early stopping triggered at epoch 8
2024-12-29 12:47:40,179 - INFO - Training completed in 2.81s
2024-12-29 12:47:40,180 - INFO - Final memory usage: CPU 2058.3 MB, GPU 103.6 MB
2024-12-29 12:47:40,180 - INFO - Model training completed in 2.81s
2024-12-29 12:47:40,230 - INFO - Prediction completed in 0.05s
2024-12-29 12:47:40,239 - INFO - Poison rate 0.03 completed in 2.88s
2024-12-29 12:47:40,239 - INFO - 
Processing poison rate: 0.05
2024-12-29 12:47:40,245 - INFO - Total number of labels flipped: 473
2024-12-29 12:47:40,245 - INFO - Label flipping completed in 0.01s
2024-12-29 12:47:40,246 - INFO - Training set processing completed in 0.00s
2024-12-29 12:47:40,246 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 12:47:40,246 - INFO - Memory usage at start_fit: CPU 2021.4 MB, GPU 103.5 MB
2024-12-29 12:47:40,247 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:47:40,251 - INFO - Number of unique classes: 10
2024-12-29 12:47:40,319 - INFO - Fitted scaler and transformed data
2024-12-29 12:47:40,320 - INFO - Scaling time: 0.07s
2024-12-29 12:47:40,632 - INFO - Epoch 1/500, Train Loss: 1.3681, Val Loss: 0.8344
2024-12-29 12:47:41,014 - INFO - Epoch 2/500, Train Loss: 0.6827, Val Loss: 0.8387
2024-12-29 12:47:41,387 - INFO - Epoch 3/500, Train Loss: 0.5817, Val Loss: 0.8437
2024-12-29 12:47:41,707 - INFO - Epoch 4/500, Train Loss: 0.5094, Val Loss: 0.8449
2024-12-29 12:47:42,033 - INFO - Epoch 5/500, Train Loss: 0.4616, Val Loss: 0.8355
2024-12-29 12:47:42,388 - INFO - Epoch 6/500, Train Loss: 0.4246, Val Loss: 0.8297
2024-12-29 12:47:42,732 - INFO - Epoch 7/500, Train Loss: 0.3939, Val Loss: 0.8269
2024-12-29 12:47:43,032 - INFO - Epoch 8/500, Train Loss: 0.3667, Val Loss: 0.8422
2024-12-29 12:47:43,345 - INFO - Epoch 9/500, Train Loss: 0.3460, Val Loss: 0.8234
2024-12-29 12:47:43,682 - INFO - Epoch 10/500, Train Loss: 0.3343, Val Loss: 0.8286
2024-12-29 12:47:44,058 - INFO - Epoch 11/500, Train Loss: 0.3198, Val Loss: 0.8356
2024-12-29 12:47:44,387 - INFO - Epoch 12/500, Train Loss: 0.3079, Val Loss: 0.8237
2024-12-29 12:47:44,755 - INFO - Epoch 13/500, Train Loss: 0.2944, Val Loss: 0.8226
2024-12-29 12:47:45,102 - INFO - Epoch 14/500, Train Loss: 0.2882, Val Loss: 0.8364
2024-12-29 12:47:45,102 - INFO - Early stopping triggered at epoch 14
2024-12-29 12:47:45,102 - INFO - Training completed in 4.86s
2024-12-29 12:47:45,103 - INFO - Final memory usage: CPU 2058.6 MB, GPU 103.6 MB
2024-12-29 12:47:45,103 - INFO - Model training completed in 4.86s
2024-12-29 12:47:45,166 - INFO - Prediction completed in 0.06s
2024-12-29 12:47:45,174 - INFO - Poison rate 0.05 completed in 4.93s
2024-12-29 12:47:45,174 - INFO - 
Processing poison rate: 0.07
2024-12-29 12:47:45,182 - INFO - Total number of labels flipped: 662
2024-12-29 12:47:45,183 - INFO - Label flipping completed in 0.01s
2024-12-29 12:47:45,183 - INFO - Training set processing completed in 0.00s
2024-12-29 12:47:45,183 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 12:47:45,184 - INFO - Memory usage at start_fit: CPU 2021.8 MB, GPU 103.5 MB
2024-12-29 12:47:45,184 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:47:45,189 - INFO - Number of unique classes: 10
2024-12-29 12:47:45,259 - INFO - Fitted scaler and transformed data
2024-12-29 12:47:45,260 - INFO - Scaling time: 0.07s
2024-12-29 12:47:45,646 - INFO - Epoch 1/500, Train Loss: 1.8022, Val Loss: 1.0105
2024-12-29 12:47:45,959 - INFO - Epoch 2/500, Train Loss: 0.9301, Val Loss: 1.0132
2024-12-29 12:47:46,284 - INFO - Epoch 3/500, Train Loss: 0.7977, Val Loss: 1.0375
2024-12-29 12:47:46,674 - INFO - Epoch 4/500, Train Loss: 0.7135, Val Loss: 1.0511
2024-12-29 12:47:47,016 - INFO - Epoch 5/500, Train Loss: 0.6516, Val Loss: 1.0650
2024-12-29 12:47:47,388 - INFO - Epoch 6/500, Train Loss: 0.6038, Val Loss: 1.0630
2024-12-29 12:47:47,388 - INFO - Early stopping triggered at epoch 6
2024-12-29 12:47:47,388 - INFO - Training completed in 2.20s
2024-12-29 12:47:47,388 - INFO - Final memory usage: CPU 2058.4 MB, GPU 103.6 MB
2024-12-29 12:47:47,389 - INFO - Model training completed in 2.21s
2024-12-29 12:47:47,450 - INFO - Prediction completed in 0.06s
2024-12-29 12:47:47,458 - INFO - Poison rate 0.07 completed in 2.28s
2024-12-29 12:47:47,458 - INFO - 
Processing poison rate: 0.1
2024-12-29 12:47:47,470 - INFO - Total number of labels flipped: 946
2024-12-29 12:47:47,470 - INFO - Label flipping completed in 0.01s
2024-12-29 12:47:47,470 - INFO - Training set processing completed in 0.00s
2024-12-29 12:47:47,470 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 12:47:47,471 - INFO - Memory usage at start_fit: CPU 2021.6 MB, GPU 103.5 MB
2024-12-29 12:47:47,471 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:47:47,475 - INFO - Number of unique classes: 10
2024-12-29 12:47:47,553 - INFO - Fitted scaler and transformed data
2024-12-29 12:47:47,554 - INFO - Scaling time: 0.08s
2024-12-29 12:47:47,904 - INFO - Epoch 1/500, Train Loss: 1.8608, Val Loss: 1.4682
2024-12-29 12:47:48,250 - INFO - Epoch 2/500, Train Loss: 1.2377, Val Loss: 1.4487
2024-12-29 12:47:48,581 - INFO - Epoch 3/500, Train Loss: 1.0997, Val Loss: 1.4612
2024-12-29 12:47:48,925 - INFO - Epoch 4/500, Train Loss: 1.0052, Val Loss: 1.4769
2024-12-29 12:47:49,247 - INFO - Epoch 5/500, Train Loss: 0.9352, Val Loss: 1.4901
2024-12-29 12:47:49,586 - INFO - Epoch 6/500, Train Loss: 0.8787, Val Loss: 1.4851
2024-12-29 12:47:49,960 - INFO - Epoch 7/500, Train Loss: 0.8405, Val Loss: 1.4927
2024-12-29 12:47:49,960 - INFO - Early stopping triggered at epoch 7
2024-12-29 12:47:49,960 - INFO - Training completed in 2.49s
2024-12-29 12:47:49,961 - INFO - Final memory usage: CPU 2058.6 MB, GPU 103.6 MB
2024-12-29 12:47:49,961 - INFO - Model training completed in 2.49s
2024-12-29 12:47:50,021 - INFO - Prediction completed in 0.06s
2024-12-29 12:47:50,030 - INFO - Poison rate 0.1 completed in 2.57s
2024-12-29 12:47:50,030 - INFO - 
Processing poison rate: 0.2
2024-12-29 12:47:50,052 - INFO - Total number of labels flipped: 1893
2024-12-29 12:47:50,052 - INFO - Label flipping completed in 0.02s
2024-12-29 12:47:50,052 - INFO - Training set processing completed in 0.00s
2024-12-29 12:47:50,052 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 12:47:50,053 - INFO - Memory usage at start_fit: CPU 2021.7 MB, GPU 103.5 MB
2024-12-29 12:47:50,053 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:47:50,057 - INFO - Number of unique classes: 10
2024-12-29 12:47:50,128 - INFO - Fitted scaler and transformed data
2024-12-29 12:47:50,128 - INFO - Scaling time: 0.07s
2024-12-29 12:47:50,523 - INFO - Epoch 1/500, Train Loss: 3.1967, Val Loss: 2.6045
2024-12-29 12:47:50,854 - INFO - Epoch 2/500, Train Loss: 2.3562, Val Loss: 2.5564
2024-12-29 12:47:51,246 - INFO - Epoch 3/500, Train Loss: 2.1296, Val Loss: 2.5664
2024-12-29 12:47:51,588 - INFO - Epoch 4/500, Train Loss: 1.9916, Val Loss: 2.5542
2024-12-29 12:47:51,958 - INFO - Epoch 5/500, Train Loss: 1.9078, Val Loss: 2.5621
2024-12-29 12:47:52,306 - INFO - Epoch 6/500, Train Loss: 1.8166, Val Loss: 2.5599
2024-12-29 12:47:52,679 - INFO - Epoch 7/500, Train Loss: 1.7768, Val Loss: 2.5417
2024-12-29 12:47:53,088 - INFO - Epoch 8/500, Train Loss: 1.7186, Val Loss: 2.5975
2024-12-29 12:47:53,422 - INFO - Epoch 9/500, Train Loss: 1.6791, Val Loss: 2.5877
2024-12-29 12:47:53,791 - INFO - Epoch 10/500, Train Loss: 1.6442, Val Loss: 2.6318
2024-12-29 12:47:54,142 - INFO - Epoch 11/500, Train Loss: 1.6116, Val Loss: 2.5963
2024-12-29 12:47:54,471 - INFO - Epoch 12/500, Train Loss: 1.6056, Val Loss: 2.6599
2024-12-29 12:47:54,471 - INFO - Early stopping triggered at epoch 12
2024-12-29 12:47:54,471 - INFO - Training completed in 4.42s
2024-12-29 12:47:54,472 - INFO - Final memory usage: CPU 2058.4 MB, GPU 103.6 MB
2024-12-29 12:47:54,473 - INFO - Model training completed in 4.42s
2024-12-29 12:47:54,551 - INFO - Prediction completed in 0.08s
2024-12-29 12:47:54,560 - INFO - Poison rate 0.2 completed in 4.53s
2024-12-29 12:47:54,560 - INFO - Total results to save: 7
2024-12-29 12:47:54,561 - INFO - Saved 7 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 12:47:54,561 - INFO - Total evaluation time: 56.85s
2024-12-29 12:47:54,563 - INFO - 
Progress: 2.1% - Evaluating GTSRB with SVM (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 12:47:54,737 - INFO - Loading datasets...
2024-12-29 12:47:54,757 - INFO - Dataset loading completed in 0.02s
2024-12-29 12:47:54,758 - INFO - Extracting validation features...
2024-12-29 12:47:54,758 - INFO - Extracting features from 3925 samples...
2024-12-29 12:48:03,866 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 12:48:03,873 - INFO - Validation feature extraction completed in 9.11s
2024-12-29 12:48:03,873 - INFO - Extracting training features...
2024-12-29 12:48:03,874 - INFO - Extracting features from 9469 samples...
2024-12-29 12:48:25,029 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 12:48:25,040 - INFO - Training feature extraction completed in 21.17s
2024-12-29 12:48:25,040 - INFO - Creating model for classifier: SVM
2024-12-29 12:48:25,041 - INFO - Using device: cuda
2024-12-29 12:48:25,041 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-29 12:48:25,041 - INFO - 
Processing poison rate: 0.0
2024-12-29 12:48:25,041 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:48:25,041 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:48:25,625 - INFO - Feature scaling completed in 0.58s
2024-12-29 12:48:25,625 - INFO - Starting feature selection (k=50)
2024-12-29 12:48:25,794 - INFO - Feature selection completed in 0.17s. Output shape: (9469, 50)
2024-12-29 12:48:25,794 - INFO - Starting anomaly detection
2024-12-29 12:48:29,544 - INFO - Anomaly detection completed in 3.75s
2024-12-29 12:48:29,545 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:48:29,545 - INFO - Total fit_transform time: 4.50s
2024-12-29 12:48:29,545 - INFO - Training set processing completed in 4.50s
2024-12-29 12:48:29,545 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 12:48:29,547 - INFO - Memory usage at start_fit: CPU 2320.0 MB, GPU 103.1 MB
2024-12-29 12:48:29,547 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:48:29,553 - INFO - Number of unique classes: 10
2024-12-29 12:48:29,628 - INFO - Fitted scaler and transformed data
2024-12-29 12:48:29,629 - INFO - Scaling time: 0.07s
2024-12-29 12:48:29,974 - INFO - Epoch 1/500, Train Loss: 0.9021, Val Loss: 0.1228
2024-12-29 12:48:30,296 - INFO - Epoch 2/500, Train Loss: 0.0911, Val Loss: 0.0936
2024-12-29 12:48:30,621 - INFO - Epoch 3/500, Train Loss: 0.0590, Val Loss: 0.0789
2024-12-29 12:48:30,946 - INFO - Epoch 4/500, Train Loss: 0.0419, Val Loss: 0.0698
2024-12-29 12:48:31,275 - INFO - Epoch 5/500, Train Loss: 0.0321, Val Loss: 0.0653
2024-12-29 12:48:31,583 - INFO - Epoch 6/500, Train Loss: 0.0259, Val Loss: 0.0630
2024-12-29 12:48:31,956 - INFO - Epoch 7/500, Train Loss: 0.0209, Val Loss: 0.0634
2024-12-29 12:48:32,268 - INFO - Epoch 8/500, Train Loss: 0.0177, Val Loss: 0.0617
2024-12-29 12:48:32,592 - INFO - Epoch 9/500, Train Loss: 0.0149, Val Loss: 0.0632
2024-12-29 12:48:32,913 - INFO - Epoch 10/500, Train Loss: 0.0127, Val Loss: 0.0616
2024-12-29 12:48:33,235 - INFO - Epoch 11/500, Train Loss: 0.0113, Val Loss: 0.0604
2024-12-29 12:48:33,555 - INFO - Epoch 12/500, Train Loss: 0.0095, Val Loss: 0.0594
2024-12-29 12:48:33,898 - INFO - Epoch 13/500, Train Loss: 0.0082, Val Loss: 0.0604
2024-12-29 12:48:34,219 - INFO - Epoch 14/500, Train Loss: 0.0075, Val Loss: 0.0593
2024-12-29 12:48:34,540 - INFO - Epoch 15/500, Train Loss: 0.0066, Val Loss: 0.0592
2024-12-29 12:48:34,881 - INFO - Epoch 16/500, Train Loss: 0.0057, Val Loss: 0.0582
2024-12-29 12:48:35,210 - INFO - Epoch 17/500, Train Loss: 0.0054, Val Loss: 0.0596
2024-12-29 12:48:35,534 - INFO - Epoch 18/500, Train Loss: 0.0050, Val Loss: 0.0608
2024-12-29 12:48:35,857 - INFO - Epoch 19/500, Train Loss: 0.0050, Val Loss: 0.0607
2024-12-29 12:48:36,182 - INFO - Epoch 20/500, Train Loss: 0.0042, Val Loss: 0.0599
2024-12-29 12:48:36,556 - INFO - Epoch 21/500, Train Loss: 0.0044, Val Loss: 0.0604
2024-12-29 12:48:36,557 - INFO - Early stopping triggered at epoch 21
2024-12-29 12:48:36,557 - INFO - Training completed in 7.01s
2024-12-29 12:48:36,557 - INFO - Final memory usage: CPU 2357.0 MB, GPU 103.3 MB
2024-12-29 12:48:36,558 - INFO - Model training completed in 7.01s
2024-12-29 12:48:36,623 - INFO - Prediction completed in 0.06s
2024-12-29 12:48:36,632 - INFO - Poison rate 0.0 completed in 11.59s
2024-12-29 12:48:36,632 - INFO - 
Processing poison rate: 0.01
2024-12-29 12:48:36,634 - INFO - Total number of labels flipped: 94
2024-12-29 12:48:36,635 - INFO - Label flipping completed in 0.00s
2024-12-29 12:48:36,635 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:48:36,635 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:48:37,151 - INFO - Feature scaling completed in 0.52s
2024-12-29 12:48:37,151 - INFO - Starting feature selection (k=50)
2024-12-29 12:48:37,166 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 12:48:37,167 - INFO - Starting anomaly detection
2024-12-29 12:48:41,315 - INFO - Anomaly detection completed in 4.15s
2024-12-29 12:48:41,315 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:48:41,315 - INFO - Total fit_transform time: 4.68s
2024-12-29 12:48:41,315 - INFO - Training set processing completed in 4.68s
2024-12-29 12:48:41,315 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 12:48:41,316 - INFO - Memory usage at start_fit: CPU 2338.4 MB, GPU 103.2 MB
2024-12-29 12:48:41,316 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:48:41,321 - INFO - Number of unique classes: 10
2024-12-29 12:48:41,390 - INFO - Fitted scaler and transformed data
2024-12-29 12:48:41,390 - INFO - Scaling time: 0.07s
2024-12-29 12:48:41,726 - INFO - Epoch 1/500, Train Loss: 0.8217, Val Loss: 0.2573
2024-12-29 12:48:42,078 - INFO - Epoch 2/500, Train Loss: 0.1947, Val Loss: 0.2406
2024-12-29 12:48:42,413 - INFO - Epoch 3/500, Train Loss: 0.1516, Val Loss: 0.2439
2024-12-29 12:48:42,777 - INFO - Epoch 4/500, Train Loss: 0.1240, Val Loss: 0.2471
2024-12-29 12:48:43,116 - INFO - Epoch 5/500, Train Loss: 0.1043, Val Loss: 0.2496
2024-12-29 12:48:43,492 - INFO - Epoch 6/500, Train Loss: 0.0883, Val Loss: 0.2583
2024-12-29 12:48:43,882 - INFO - Epoch 7/500, Train Loss: 0.0782, Val Loss: 0.2577
2024-12-29 12:48:43,883 - INFO - Early stopping triggered at epoch 7
2024-12-29 12:48:43,883 - INFO - Training completed in 2.57s
2024-12-29 12:48:43,884 - INFO - Final memory usage: CPU 2358.6 MB, GPU 103.3 MB
2024-12-29 12:48:43,886 - INFO - Model training completed in 2.57s
2024-12-29 12:48:43,946 - INFO - Prediction completed in 0.06s
2024-12-29 12:48:43,955 - INFO - Poison rate 0.01 completed in 7.32s
2024-12-29 12:48:43,955 - INFO - 
Processing poison rate: 0.03
2024-12-29 12:48:43,959 - INFO - Total number of labels flipped: 284
2024-12-29 12:48:43,959 - INFO - Label flipping completed in 0.00s
2024-12-29 12:48:43,960 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:48:43,960 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:48:44,557 - INFO - Feature scaling completed in 0.60s
2024-12-29 12:48:44,557 - INFO - Starting feature selection (k=50)
2024-12-29 12:48:44,571 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 12:48:44,572 - INFO - Starting anomaly detection
2024-12-29 12:48:48,765 - INFO - Anomaly detection completed in 4.19s
2024-12-29 12:48:48,765 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:48:48,765 - INFO - Total fit_transform time: 4.81s
2024-12-29 12:48:48,765 - INFO - Training set processing completed in 4.81s
2024-12-29 12:48:48,765 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 12:48:48,766 - INFO - Memory usage at start_fit: CPU 2347.4 MB, GPU 103.2 MB
2024-12-29 12:48:48,766 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:48:48,768 - INFO - Number of unique classes: 10
2024-12-29 12:48:48,838 - INFO - Fitted scaler and transformed data
2024-12-29 12:48:48,838 - INFO - Scaling time: 0.07s
2024-12-29 12:48:49,191 - INFO - Epoch 1/500, Train Loss: 1.1575, Val Loss: 0.5900
2024-12-29 12:48:49,551 - INFO - Epoch 2/500, Train Loss: 0.4479, Val Loss: 0.5674
2024-12-29 12:48:49,953 - INFO - Epoch 3/500, Train Loss: 0.3770, Val Loss: 0.5414
2024-12-29 12:48:50,347 - INFO - Epoch 4/500, Train Loss: 0.3273, Val Loss: 0.5388
2024-12-29 12:48:50,729 - INFO - Epoch 5/500, Train Loss: 0.2881, Val Loss: 0.5180
2024-12-29 12:48:51,100 - INFO - Epoch 6/500, Train Loss: 0.2586, Val Loss: 0.5220
2024-12-29 12:48:51,449 - INFO - Epoch 7/500, Train Loss: 0.2339, Val Loss: 0.5227
2024-12-29 12:48:51,830 - INFO - Epoch 8/500, Train Loss: 0.2180, Val Loss: 0.5318
2024-12-29 12:48:52,200 - INFO - Epoch 9/500, Train Loss: 0.2042, Val Loss: 0.5219
2024-12-29 12:48:52,552 - INFO - Epoch 10/500, Train Loss: 0.1953, Val Loss: 0.5260
2024-12-29 12:48:52,552 - INFO - Early stopping triggered at epoch 10
2024-12-29 12:48:52,552 - INFO - Training completed in 3.79s
2024-12-29 12:48:52,553 - INFO - Final memory usage: CPU 2366.5 MB, GPU 103.3 MB
2024-12-29 12:48:52,554 - INFO - Model training completed in 3.79s
2024-12-29 12:48:52,602 - INFO - Prediction completed in 0.05s
2024-12-29 12:48:52,611 - INFO - Poison rate 0.03 completed in 8.66s
2024-12-29 12:48:52,611 - INFO - 
Processing poison rate: 0.05
2024-12-29 12:48:52,617 - INFO - Total number of labels flipped: 473
2024-12-29 12:48:52,617 - INFO - Label flipping completed in 0.01s
2024-12-29 12:48:52,617 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:48:52,617 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:48:53,195 - INFO - Feature scaling completed in 0.58s
2024-12-29 12:48:53,195 - INFO - Starting feature selection (k=50)
2024-12-29 12:48:53,214 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 12:48:53,214 - INFO - Starting anomaly detection
2024-12-29 12:48:57,296 - INFO - Anomaly detection completed in 4.08s
2024-12-29 12:48:57,296 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:48:57,297 - INFO - Total fit_transform time: 4.68s
2024-12-29 12:48:57,297 - INFO - Training set processing completed in 4.68s
2024-12-29 12:48:57,297 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 12:48:57,297 - INFO - Memory usage at start_fit: CPU 2348.1 MB, GPU 103.2 MB
2024-12-29 12:48:57,298 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:48:57,300 - INFO - Number of unique classes: 10
2024-12-29 12:48:57,366 - INFO - Fitted scaler and transformed data
2024-12-29 12:48:57,366 - INFO - Scaling time: 0.07s
2024-12-29 12:48:57,762 - INFO - Epoch 1/500, Train Loss: 1.3285, Val Loss: 0.8413
2024-12-29 12:48:58,084 - INFO - Epoch 2/500, Train Loss: 0.6573, Val Loss: 0.8337
2024-12-29 12:48:58,439 - INFO - Epoch 3/500, Train Loss: 0.5707, Val Loss: 0.8343
2024-12-29 12:48:58,823 - INFO - Epoch 4/500, Train Loss: 0.5062, Val Loss: 0.8319
2024-12-29 12:48:59,164 - INFO - Epoch 5/500, Train Loss: 0.4534, Val Loss: 0.8342
2024-12-29 12:48:59,546 - INFO - Epoch 6/500, Train Loss: 0.4167, Val Loss: 0.8474
2024-12-29 12:48:59,932 - INFO - Epoch 7/500, Train Loss: 0.3848, Val Loss: 0.8498
2024-12-29 12:49:00,323 - INFO - Epoch 8/500, Train Loss: 0.3591, Val Loss: 0.8687
2024-12-29 12:49:00,702 - INFO - Epoch 9/500, Train Loss: 0.3423, Val Loss: 0.8761
2024-12-29 12:49:00,703 - INFO - Early stopping triggered at epoch 9
2024-12-29 12:49:00,703 - INFO - Training completed in 3.41s
2024-12-29 12:49:00,703 - INFO - Final memory usage: CPU 2357.2 MB, GPU 103.3 MB
2024-12-29 12:49:00,705 - INFO - Model training completed in 3.41s
2024-12-29 12:49:00,753 - INFO - Prediction completed in 0.05s
2024-12-29 12:49:00,762 - INFO - Poison rate 0.05 completed in 8.15s
2024-12-29 12:49:00,762 - INFO - 
Processing poison rate: 0.07
2024-12-29 12:49:00,770 - INFO - Total number of labels flipped: 662
2024-12-29 12:49:00,770 - INFO - Label flipping completed in 0.01s
2024-12-29 12:49:00,770 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:49:00,770 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:49:01,336 - INFO - Feature scaling completed in 0.57s
2024-12-29 12:49:01,336 - INFO - Starting feature selection (k=50)
2024-12-29 12:49:01,352 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 12:49:01,352 - INFO - Starting anomaly detection
2024-12-29 12:49:05,617 - INFO - Anomaly detection completed in 4.26s
2024-12-29 12:49:05,617 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:49:05,618 - INFO - Total fit_transform time: 4.85s
2024-12-29 12:49:05,618 - INFO - Training set processing completed in 4.85s
2024-12-29 12:49:05,619 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 12:49:05,620 - INFO - Memory usage at start_fit: CPU 2347.7 MB, GPU 103.2 MB
2024-12-29 12:49:05,620 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:49:05,623 - INFO - Number of unique classes: 10
2024-12-29 12:49:05,697 - INFO - Fitted scaler and transformed data
2024-12-29 12:49:05,697 - INFO - Scaling time: 0.07s
2024-12-29 12:49:06,076 - INFO - Epoch 1/500, Train Loss: 1.6464, Val Loss: 0.9581
2024-12-29 12:49:06,435 - INFO - Epoch 2/500, Train Loss: 0.9127, Val Loss: 0.9184
2024-12-29 12:49:06,826 - INFO - Epoch 3/500, Train Loss: 0.7903, Val Loss: 0.9104
2024-12-29 12:49:07,171 - INFO - Epoch 4/500, Train Loss: 0.7008, Val Loss: 0.9000
2024-12-29 12:49:07,552 - INFO - Epoch 5/500, Train Loss: 0.6420, Val Loss: 0.9111
2024-12-29 12:49:07,873 - INFO - Epoch 6/500, Train Loss: 0.5955, Val Loss: 0.9084
2024-12-29 12:49:08,198 - INFO - Epoch 7/500, Train Loss: 0.5580, Val Loss: 0.9170
2024-12-29 12:49:08,558 - INFO - Epoch 8/500, Train Loss: 0.5319, Val Loss: 0.9180
2024-12-29 12:49:08,878 - INFO - Epoch 9/500, Train Loss: 0.5077, Val Loss: 0.9432
2024-12-29 12:49:08,878 - INFO - Early stopping triggered at epoch 9
2024-12-29 12:49:08,878 - INFO - Training completed in 3.26s
2024-12-29 12:49:08,878 - INFO - Final memory usage: CPU 2366.3 MB, GPU 103.3 MB
2024-12-29 12:49:08,879 - INFO - Model training completed in 3.26s
2024-12-29 12:49:08,922 - INFO - Prediction completed in 0.04s
2024-12-29 12:49:08,931 - INFO - Poison rate 0.07 completed in 8.17s
2024-12-29 12:49:08,931 - INFO - 
Processing poison rate: 0.1
2024-12-29 12:49:08,957 - INFO - Total number of labels flipped: 946
2024-12-29 12:49:08,957 - INFO - Label flipping completed in 0.03s
2024-12-29 12:49:08,957 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:49:08,957 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:49:09,531 - INFO - Feature scaling completed in 0.57s
2024-12-29 12:49:09,531 - INFO - Starting feature selection (k=50)
2024-12-29 12:49:09,546 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 12:49:09,547 - INFO - Starting anomaly detection
2024-12-29 12:49:13,662 - INFO - Anomaly detection completed in 4.12s
2024-12-29 12:49:13,662 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:49:13,662 - INFO - Total fit_transform time: 4.70s
2024-12-29 12:49:13,662 - INFO - Training set processing completed in 4.71s
2024-12-29 12:49:13,662 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 12:49:13,663 - INFO - Memory usage at start_fit: CPU 2347.7 MB, GPU 103.2 MB
2024-12-29 12:49:13,663 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:49:13,666 - INFO - Number of unique classes: 10
2024-12-29 12:49:13,736 - INFO - Fitted scaler and transformed data
2024-12-29 12:49:13,737 - INFO - Scaling time: 0.07s
2024-12-29 12:49:14,112 - INFO - Epoch 1/500, Train Loss: 1.8354, Val Loss: 1.3827
2024-12-29 12:49:14,492 - INFO - Epoch 2/500, Train Loss: 1.1432, Val Loss: 1.3912
2024-12-29 12:49:14,818 - INFO - Epoch 3/500, Train Loss: 1.0301, Val Loss: 1.3593
2024-12-29 12:49:15,179 - INFO - Epoch 4/500, Train Loss: 0.9463, Val Loss: 1.3946
2024-12-29 12:49:15,500 - INFO - Epoch 5/500, Train Loss: 0.8781, Val Loss: 1.3954
2024-12-29 12:49:15,815 - INFO - Epoch 6/500, Train Loss: 0.8296, Val Loss: 1.4069
2024-12-29 12:49:16,143 - INFO - Epoch 7/500, Train Loss: 0.7978, Val Loss: 1.4132
2024-12-29 12:49:16,483 - INFO - Epoch 8/500, Train Loss: 0.7652, Val Loss: 1.4415
2024-12-29 12:49:16,483 - INFO - Early stopping triggered at epoch 8
2024-12-29 12:49:16,483 - INFO - Training completed in 2.82s
2024-12-29 12:49:16,484 - INFO - Final memory usage: CPU 2357.1 MB, GPU 103.3 MB
2024-12-29 12:49:16,484 - INFO - Model training completed in 2.82s
2024-12-29 12:49:16,541 - INFO - Prediction completed in 0.06s
2024-12-29 12:49:16,550 - INFO - Poison rate 0.1 completed in 7.62s
2024-12-29 12:49:16,550 - INFO - 
Processing poison rate: 0.2
2024-12-29 12:49:16,573 - INFO - Total number of labels flipped: 1893
2024-12-29 12:49:16,573 - INFO - Label flipping completed in 0.02s
2024-12-29 12:49:16,573 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:49:16,573 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:49:17,089 - INFO - Feature scaling completed in 0.52s
2024-12-29 12:49:17,089 - INFO - Starting feature selection (k=50)
2024-12-29 12:49:17,103 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 12:49:17,104 - INFO - Starting anomaly detection
2024-12-29 12:49:21,250 - INFO - Anomaly detection completed in 4.15s
2024-12-29 12:49:21,250 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:49:21,250 - INFO - Total fit_transform time: 4.68s
2024-12-29 12:49:21,250 - INFO - Training set processing completed in 4.68s
2024-12-29 12:49:21,250 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 12:49:21,251 - INFO - Memory usage at start_fit: CPU 2348.1 MB, GPU 103.2 MB
2024-12-29 12:49:21,252 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:49:21,255 - INFO - Number of unique classes: 10
2024-12-29 12:49:21,324 - INFO - Fitted scaler and transformed data
2024-12-29 12:49:21,324 - INFO - Scaling time: 0.07s
2024-12-29 12:49:21,724 - INFO - Epoch 1/500, Train Loss: 3.0705, Val Loss: 2.3825
2024-12-29 12:49:22,097 - INFO - Epoch 2/500, Train Loss: 2.2704, Val Loss: 2.3348
2024-12-29 12:49:22,417 - INFO - Epoch 3/500, Train Loss: 2.0661, Val Loss: 2.3594
2024-12-29 12:49:22,761 - INFO - Epoch 4/500, Train Loss: 1.9394, Val Loss: 2.3517
2024-12-29 12:49:23,108 - INFO - Epoch 5/500, Train Loss: 1.8529, Val Loss: 2.3643
2024-12-29 12:49:23,453 - INFO - Epoch 6/500, Train Loss: 1.7795, Val Loss: 2.3538
2024-12-29 12:49:23,810 - INFO - Epoch 7/500, Train Loss: 1.7283, Val Loss: 2.3340
2024-12-29 12:49:23,810 - INFO - Early stopping triggered at epoch 7
2024-12-29 12:49:23,810 - INFO - Training completed in 2.56s
2024-12-29 12:49:23,810 - INFO - Final memory usage: CPU 2366.7 MB, GPU 103.3 MB
2024-12-29 12:49:23,811 - INFO - Model training completed in 2.56s
2024-12-29 12:49:23,874 - INFO - Prediction completed in 0.06s
2024-12-29 12:49:23,883 - INFO - Poison rate 0.2 completed in 7.33s
2024-12-29 12:49:23,883 - INFO - Loaded 7 existing results
2024-12-29 12:49:23,883 - INFO - Total results to save: 14
2024-12-29 12:49:23,884 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 12:49:23,885 - INFO - Saved 14 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 12:49:23,885 - INFO - Total evaluation time: 89.15s
2024-12-29 12:49:23,886 - INFO - 
Progress: 3.1% - Evaluating GTSRB with LogisticRegression (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 12:49:24,066 - INFO - Loading datasets...
2024-12-29 12:49:24,087 - INFO - Dataset loading completed in 0.02s
2024-12-29 12:49:24,087 - INFO - Extracting validation features...
2024-12-29 12:49:24,087 - INFO - Extracting features from 3925 samples...
2024-12-29 12:49:33,358 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 12:49:33,359 - INFO - Validation feature extraction completed in 9.27s
2024-12-29 12:49:33,359 - INFO - Extracting training features...
2024-12-29 12:49:33,359 - INFO - Extracting features from 9469 samples...
2024-12-29 12:49:54,954 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 12:49:54,962 - INFO - Training feature extraction completed in 21.60s
2024-12-29 12:49:54,963 - INFO - Creating model for classifier: LogisticRegression
2024-12-29 12:49:54,963 - INFO - Using device: cuda
2024-12-29 12:49:54,963 - INFO - 
Processing poison rate: 0.0
2024-12-29 12:49:54,963 - INFO - Training set processing completed in 0.00s
2024-12-29 12:49:54,964 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 12:49:54,965 - INFO - Memory usage at start_fit: CPU 2655.9 MB, GPU 103.1 MB
2024-12-29 12:49:54,965 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:49:54,970 - INFO - Number of unique classes: 10
2024-12-29 12:49:55,042 - INFO - Fitted scaler and transformed data
2024-12-29 12:49:55,043 - INFO - Scaling time: 0.07s
2024-12-29 12:49:55,272 - INFO - Epoch 1/1000, Train Loss: 0.4639, Val Loss: 0.1219
2024-12-29 12:49:55,465 - INFO - Epoch 2/1000, Train Loss: 0.0945, Val Loss: 0.0867
2024-12-29 12:49:55,676 - INFO - Epoch 3/1000, Train Loss: 0.0678, Val Loss: 0.0735
2024-12-29 12:49:55,894 - INFO - Epoch 4/1000, Train Loss: 0.0543, Val Loss: 0.0675
2024-12-29 12:49:56,084 - INFO - Epoch 5/1000, Train Loss: 0.0467, Val Loss: 0.0635
2024-12-29 12:49:56,283 - INFO - Epoch 6/1000, Train Loss: 0.0416, Val Loss: 0.0612
2024-12-29 12:49:56,486 - INFO - Epoch 7/1000, Train Loss: 0.0380, Val Loss: 0.0599
2024-12-29 12:49:56,712 - INFO - Epoch 8/1000, Train Loss: 0.0357, Val Loss: 0.0589
2024-12-29 12:49:56,924 - INFO - Epoch 9/1000, Train Loss: 0.0341, Val Loss: 0.0582
2024-12-29 12:49:57,122 - INFO - Epoch 10/1000, Train Loss: 0.0327, Val Loss: 0.0582
2024-12-29 12:49:57,335 - INFO - Epoch 11/1000, Train Loss: 0.0316, Val Loss: 0.0576
2024-12-29 12:49:57,537 - INFO - Epoch 12/1000, Train Loss: 0.0309, Val Loss: 0.0578
2024-12-29 12:49:57,761 - INFO - Epoch 13/1000, Train Loss: 0.0302, Val Loss: 0.0575
2024-12-29 12:49:57,969 - INFO - Epoch 14/1000, Train Loss: 0.0297, Val Loss: 0.0573
2024-12-29 12:49:57,969 - INFO - Early stopping triggered at epoch 14
2024-12-29 12:49:57,970 - INFO - Training completed in 3.01s
2024-12-29 12:49:57,971 - INFO - Final memory usage: CPU 2659.2 MB, GPU 103.3 MB
2024-12-29 12:49:57,971 - INFO - Model training completed in 3.01s
2024-12-29 12:49:58,037 - INFO - Prediction completed in 0.06s
2024-12-29 12:49:58,046 - INFO - Poison rate 0.0 completed in 3.08s
2024-12-29 12:49:58,047 - INFO - 
Processing poison rate: 0.01
2024-12-29 12:49:58,049 - INFO - Total number of labels flipped: 94
2024-12-29 12:49:58,049 - INFO - Label flipping completed in 0.00s
2024-12-29 12:49:58,049 - INFO - Training set processing completed in 0.00s
2024-12-29 12:49:58,049 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 12:49:58,050 - INFO - Memory usage at start_fit: CPU 2659.2 MB, GPU 103.2 MB
2024-12-29 12:49:58,050 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:49:58,052 - INFO - Number of unique classes: 10
2024-12-29 12:49:58,125 - INFO - Fitted scaler and transformed data
2024-12-29 12:49:58,125 - INFO - Scaling time: 0.07s
2024-12-29 12:49:58,326 - INFO - Epoch 1/1000, Train Loss: 0.5083, Val Loss: 0.2036
2024-12-29 12:49:58,525 - INFO - Epoch 2/1000, Train Loss: 0.1650, Val Loss: 0.1803
2024-12-29 12:49:58,711 - INFO - Epoch 3/1000, Train Loss: 0.1419, Val Loss: 0.1726
2024-12-29 12:49:58,918 - INFO - Epoch 4/1000, Train Loss: 0.1310, Val Loss: 0.1691
2024-12-29 12:49:59,139 - INFO - Epoch 5/1000, Train Loss: 0.1223, Val Loss: 0.1674
2024-12-29 12:49:59,358 - INFO - Epoch 6/1000, Train Loss: 0.1177, Val Loss: 0.1666
2024-12-29 12:49:59,549 - INFO - Epoch 7/1000, Train Loss: 0.1127, Val Loss: 0.1669
2024-12-29 12:49:59,774 - INFO - Epoch 8/1000, Train Loss: 0.1087, Val Loss: 0.1654
2024-12-29 12:50:00,002 - INFO - Epoch 9/1000, Train Loss: 0.1069, Val Loss: 0.1662
2024-12-29 12:50:00,212 - INFO - Epoch 10/1000, Train Loss: 0.1034, Val Loss: 0.1663
2024-12-29 12:50:00,434 - INFO - Epoch 11/1000, Train Loss: 0.1017, Val Loss: 0.1656
2024-12-29 12:50:00,690 - INFO - Epoch 12/1000, Train Loss: 0.0994, Val Loss: 0.1662
2024-12-29 12:50:00,934 - INFO - Epoch 13/1000, Train Loss: 0.0983, Val Loss: 0.1665
2024-12-29 12:50:00,935 - INFO - Early stopping triggered at epoch 13
2024-12-29 12:50:00,935 - INFO - Training completed in 2.89s
2024-12-29 12:50:00,936 - INFO - Final memory usage: CPU 2659.2 MB, GPU 103.3 MB
2024-12-29 12:50:00,937 - INFO - Model training completed in 2.89s
2024-12-29 12:50:01,018 - INFO - Prediction completed in 0.08s
2024-12-29 12:50:01,027 - INFO - Poison rate 0.01 completed in 2.98s
2024-12-29 12:50:01,027 - INFO - 
Processing poison rate: 0.03
2024-12-29 12:50:01,031 - INFO - Total number of labels flipped: 284
2024-12-29 12:50:01,031 - INFO - Label flipping completed in 0.00s
2024-12-29 12:50:01,032 - INFO - Training set processing completed in 0.00s
2024-12-29 12:50:01,032 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 12:50:01,033 - INFO - Memory usage at start_fit: CPU 2659.2 MB, GPU 103.2 MB
2024-12-29 12:50:01,033 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:50:01,036 - INFO - Number of unique classes: 10
2024-12-29 12:50:01,126 - INFO - Fitted scaler and transformed data
2024-12-29 12:50:01,127 - INFO - Scaling time: 0.09s
2024-12-29 12:50:01,365 - INFO - Epoch 1/1000, Train Loss: 0.5885, Val Loss: 0.2628
2024-12-29 12:50:01,569 - INFO - Epoch 2/1000, Train Loss: 0.3024, Val Loss: 0.2456
2024-12-29 12:50:01,779 - INFO - Epoch 3/1000, Train Loss: 0.2826, Val Loss: 0.2424
2024-12-29 12:50:02,069 - INFO - Epoch 4/1000, Train Loss: 0.2689, Val Loss: 0.2444
2024-12-29 12:50:02,250 - INFO - Epoch 5/1000, Train Loss: 0.2596, Val Loss: 0.2437
2024-12-29 12:50:02,460 - INFO - Epoch 6/1000, Train Loss: 0.2530, Val Loss: 0.2441
2024-12-29 12:50:02,674 - INFO - Epoch 7/1000, Train Loss: 0.2448, Val Loss: 0.2462
2024-12-29 12:50:02,888 - INFO - Epoch 8/1000, Train Loss: 0.2398, Val Loss: 0.2474
2024-12-29 12:50:02,888 - INFO - Early stopping triggered at epoch 8
2024-12-29 12:50:02,888 - INFO - Training completed in 1.86s
2024-12-29 12:50:02,888 - INFO - Final memory usage: CPU 2659.2 MB, GPU 103.3 MB
2024-12-29 12:50:02,889 - INFO - Model training completed in 1.86s
2024-12-29 12:50:02,939 - INFO - Prediction completed in 0.05s
2024-12-29 12:50:02,949 - INFO - Poison rate 0.03 completed in 1.92s
2024-12-29 12:50:02,949 - INFO - 
Processing poison rate: 0.05
2024-12-29 12:50:02,955 - INFO - Total number of labels flipped: 473
2024-12-29 12:50:02,955 - INFO - Label flipping completed in 0.01s
2024-12-29 12:50:02,956 - INFO - Training set processing completed in 0.00s
2024-12-29 12:50:02,956 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 12:50:02,956 - INFO - Memory usage at start_fit: CPU 2659.2 MB, GPU 103.2 MB
2024-12-29 12:50:02,957 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:50:02,959 - INFO - Number of unique classes: 10
2024-12-29 12:50:03,022 - INFO - Fitted scaler and transformed data
2024-12-29 12:50:03,022 - INFO - Scaling time: 0.06s
2024-12-29 12:50:03,237 - INFO - Epoch 1/1000, Train Loss: 0.7226, Val Loss: 0.4022
2024-12-29 12:50:03,452 - INFO - Epoch 2/1000, Train Loss: 0.4176, Val Loss: 0.3857
2024-12-29 12:50:03,698 - INFO - Epoch 3/1000, Train Loss: 0.3951, Val Loss: 0.3835
2024-12-29 12:50:03,888 - INFO - Epoch 4/1000, Train Loss: 0.3792, Val Loss: 0.3837
2024-12-29 12:50:04,077 - INFO - Epoch 5/1000, Train Loss: 0.3682, Val Loss: 0.3821
2024-12-29 12:50:04,268 - INFO - Epoch 6/1000, Train Loss: 0.3588, Val Loss: 0.3842
2024-12-29 12:50:04,482 - INFO - Epoch 7/1000, Train Loss: 0.3504, Val Loss: 0.3866
2024-12-29 12:50:04,698 - INFO - Epoch 8/1000, Train Loss: 0.3440, Val Loss: 0.3874
2024-12-29 12:50:04,902 - INFO - Epoch 9/1000, Train Loss: 0.3390, Val Loss: 0.3901
2024-12-29 12:50:05,095 - INFO - Epoch 10/1000, Train Loss: 0.3334, Val Loss: 0.3892
2024-12-29 12:50:05,096 - INFO - Early stopping triggered at epoch 10
2024-12-29 12:50:05,096 - INFO - Training completed in 2.14s
2024-12-29 12:50:05,097 - INFO - Final memory usage: CPU 2659.2 MB, GPU 103.3 MB
2024-12-29 12:50:05,097 - INFO - Model training completed in 2.14s
2024-12-29 12:50:05,186 - INFO - Prediction completed in 0.09s
2024-12-29 12:50:05,200 - INFO - Poison rate 0.05 completed in 2.25s
2024-12-29 12:50:05,201 - INFO - 
Processing poison rate: 0.07
2024-12-29 12:50:05,210 - INFO - Total number of labels flipped: 662
2024-12-29 12:50:05,210 - INFO - Label flipping completed in 0.01s
2024-12-29 12:50:05,210 - INFO - Training set processing completed in 0.00s
2024-12-29 12:50:05,210 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 12:50:05,211 - INFO - Memory usage at start_fit: CPU 2659.2 MB, GPU 103.2 MB
2024-12-29 12:50:05,211 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:50:05,213 - INFO - Number of unique classes: 10
2024-12-29 12:50:05,282 - INFO - Fitted scaler and transformed data
2024-12-29 12:50:05,282 - INFO - Scaling time: 0.07s
2024-12-29 12:50:05,493 - INFO - Epoch 1/1000, Train Loss: 0.7859, Val Loss: 0.5653
2024-12-29 12:50:05,691 - INFO - Epoch 2/1000, Train Loss: 0.5255, Val Loss: 0.5581
2024-12-29 12:50:05,887 - INFO - Epoch 3/1000, Train Loss: 0.4997, Val Loss: 0.5508
2024-12-29 12:50:06,110 - INFO - Epoch 4/1000, Train Loss: 0.4832, Val Loss: 0.5513
2024-12-29 12:50:06,301 - INFO - Epoch 5/1000, Train Loss: 0.4707, Val Loss: 0.5525
2024-12-29 12:50:06,508 - INFO - Epoch 6/1000, Train Loss: 0.4576, Val Loss: 0.5538
2024-12-29 12:50:06,708 - INFO - Epoch 7/1000, Train Loss: 0.4501, Val Loss: 0.5532
2024-12-29 12:50:06,902 - INFO - Epoch 8/1000, Train Loss: 0.4429, Val Loss: 0.5559
2024-12-29 12:50:06,903 - INFO - Early stopping triggered at epoch 8
2024-12-29 12:50:06,903 - INFO - Training completed in 1.69s
2024-12-29 12:50:06,904 - INFO - Final memory usage: CPU 2659.2 MB, GPU 103.3 MB
2024-12-29 12:50:06,904 - INFO - Model training completed in 1.69s
2024-12-29 12:50:06,972 - INFO - Prediction completed in 0.07s
2024-12-29 12:50:06,980 - INFO - Poison rate 0.07 completed in 1.78s
2024-12-29 12:50:06,980 - INFO - 
Processing poison rate: 0.1
2024-12-29 12:50:06,992 - INFO - Total number of labels flipped: 946
2024-12-29 12:50:06,992 - INFO - Label flipping completed in 0.01s
2024-12-29 12:50:06,992 - INFO - Training set processing completed in 0.00s
2024-12-29 12:50:06,992 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 12:50:06,994 - INFO - Memory usage at start_fit: CPU 2659.2 MB, GPU 103.2 MB
2024-12-29 12:50:06,994 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:50:06,997 - INFO - Number of unique classes: 10
2024-12-29 12:50:07,057 - INFO - Fitted scaler and transformed data
2024-12-29 12:50:07,058 - INFO - Scaling time: 0.06s
2024-12-29 12:50:07,273 - INFO - Epoch 1/1000, Train Loss: 0.9007, Val Loss: 0.6954
2024-12-29 12:50:07,504 - INFO - Epoch 2/1000, Train Loss: 0.6514, Val Loss: 0.6831
2024-12-29 12:50:07,743 - INFO - Epoch 3/1000, Train Loss: 0.6252, Val Loss: 0.6831
2024-12-29 12:50:07,943 - INFO - Epoch 4/1000, Train Loss: 0.6091, Val Loss: 0.6848
2024-12-29 12:50:08,124 - INFO - Epoch 5/1000, Train Loss: 0.5954, Val Loss: 0.6873
2024-12-29 12:50:08,307 - INFO - Epoch 6/1000, Train Loss: 0.5861, Val Loss: 0.6919
2024-12-29 12:50:08,493 - INFO - Epoch 7/1000, Train Loss: 0.5759, Val Loss: 0.6946
2024-12-29 12:50:08,493 - INFO - Early stopping triggered at epoch 7
2024-12-29 12:50:08,493 - INFO - Training completed in 1.50s
2024-12-29 12:50:08,494 - INFO - Final memory usage: CPU 2659.2 MB, GPU 103.3 MB
2024-12-29 12:50:08,494 - INFO - Model training completed in 1.50s
2024-12-29 12:50:08,564 - INFO - Prediction completed in 0.07s
2024-12-29 12:50:08,572 - INFO - Poison rate 0.1 completed in 1.59s
2024-12-29 12:50:08,573 - INFO - 
Processing poison rate: 0.2
2024-12-29 12:50:08,595 - INFO - Total number of labels flipped: 1893
2024-12-29 12:50:08,595 - INFO - Label flipping completed in 0.02s
2024-12-29 12:50:08,595 - INFO - Training set processing completed in 0.00s
2024-12-29 12:50:08,595 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 12:50:08,596 - INFO - Memory usage at start_fit: CPU 2659.2 MB, GPU 103.2 MB
2024-12-29 12:50:08,596 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:50:08,599 - INFO - Number of unique classes: 10
2024-12-29 12:50:08,687 - INFO - Fitted scaler and transformed data
2024-12-29 12:50:08,687 - INFO - Scaling time: 0.09s
2024-12-29 12:50:08,898 - INFO - Epoch 1/1000, Train Loss: 1.2449, Val Loss: 1.1291
2024-12-29 12:50:09,101 - INFO - Epoch 2/1000, Train Loss: 1.0417, Val Loss: 1.1117
2024-12-29 12:50:09,295 - INFO - Epoch 3/1000, Train Loss: 1.0128, Val Loss: 1.1088
2024-12-29 12:50:09,500 - INFO - Epoch 4/1000, Train Loss: 0.9883, Val Loss: 1.1127
2024-12-29 12:50:09,702 - INFO - Epoch 5/1000, Train Loss: 0.9742, Val Loss: 1.1202
2024-12-29 12:50:09,894 - INFO - Epoch 6/1000, Train Loss: 0.9620, Val Loss: 1.1220
2024-12-29 12:50:10,108 - INFO - Epoch 7/1000, Train Loss: 0.9512, Val Loss: 1.1236
2024-12-29 12:50:10,327 - INFO - Epoch 8/1000, Train Loss: 0.9447, Val Loss: 1.1305
2024-12-29 12:50:10,328 - INFO - Early stopping triggered at epoch 8
2024-12-29 12:50:10,328 - INFO - Training completed in 1.73s
2024-12-29 12:50:10,329 - INFO - Final memory usage: CPU 2659.2 MB, GPU 103.3 MB
2024-12-29 12:50:10,329 - INFO - Model training completed in 1.73s
2024-12-29 12:50:10,405 - INFO - Prediction completed in 0.08s
2024-12-29 12:50:10,413 - INFO - Poison rate 0.2 completed in 1.84s
2024-12-29 12:50:10,414 - INFO - Loaded 14 existing results
2024-12-29 12:50:10,414 - INFO - Total results to save: 21
2024-12-29 12:50:10,415 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 12:50:10,416 - INFO - Saved 21 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 12:50:10,416 - INFO - Total evaluation time: 46.35s
2024-12-29 12:50:10,418 - INFO - 
Progress: 4.2% - Evaluating GTSRB with LogisticRegression (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 12:50:10,590 - INFO - Loading datasets...
2024-12-29 12:50:10,610 - INFO - Dataset loading completed in 0.02s
2024-12-29 12:50:10,610 - INFO - Extracting validation features...
2024-12-29 12:50:10,610 - INFO - Extracting features from 3925 samples...
2024-12-29 12:50:20,054 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 12:50:20,057 - INFO - Validation feature extraction completed in 9.45s
2024-12-29 12:50:20,057 - INFO - Extracting training features...
2024-12-29 12:50:20,058 - INFO - Extracting features from 9469 samples...
2024-12-29 12:50:41,891 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 12:50:41,897 - INFO - Training feature extraction completed in 21.84s
2024-12-29 12:50:41,898 - INFO - Creating model for classifier: LogisticRegression
2024-12-29 12:50:41,898 - INFO - Using device: cuda
2024-12-29 12:50:41,899 - INFO - 
Processing poison rate: 0.0
2024-12-29 12:50:41,899 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:50:41,899 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:50:42,463 - INFO - Feature scaling completed in 0.56s
2024-12-29 12:50:42,464 - INFO - Starting feature selection (k=50)
2024-12-29 12:50:42,474 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 12:50:42,475 - INFO - Starting anomaly detection
2024-12-29 12:50:44,674 - INFO - Anomaly detection completed in 2.20s
2024-12-29 12:50:44,675 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:50:44,675 - INFO - Total fit_transform time: 2.78s
2024-12-29 12:50:44,676 - INFO - Training set processing completed in 2.78s
2024-12-29 12:50:44,676 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 12:50:44,677 - INFO - Memory usage at start_fit: CPU 2696.8 MB, GPU 103.1 MB
2024-12-29 12:50:44,678 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:50:44,681 - INFO - Number of unique classes: 10
2024-12-29 12:50:44,761 - INFO - Fitted scaler and transformed data
2024-12-29 12:50:44,761 - INFO - Scaling time: 0.08s
2024-12-29 12:50:45,037 - INFO - Epoch 1/1000, Train Loss: 0.5001, Val Loss: 0.1308
2024-12-29 12:50:45,290 - INFO - Epoch 2/1000, Train Loss: 0.0942, Val Loss: 0.0917
2024-12-29 12:50:45,553 - INFO - Epoch 3/1000, Train Loss: 0.0674, Val Loss: 0.0774
2024-12-29 12:50:45,825 - INFO - Epoch 4/1000, Train Loss: 0.0541, Val Loss: 0.0696
2024-12-29 12:50:46,147 - INFO - Epoch 5/1000, Train Loss: 0.0466, Val Loss: 0.0651
2024-12-29 12:50:46,459 - INFO - Epoch 6/1000, Train Loss: 0.0418, Val Loss: 0.0624
2024-12-29 12:50:46,746 - INFO - Epoch 7/1000, Train Loss: 0.0382, Val Loss: 0.0604
2024-12-29 12:50:46,937 - INFO - Epoch 8/1000, Train Loss: 0.0360, Val Loss: 0.0591
2024-12-29 12:50:47,128 - INFO - Epoch 9/1000, Train Loss: 0.0340, Val Loss: 0.0580
2024-12-29 12:50:47,334 - INFO - Epoch 10/1000, Train Loss: 0.0329, Val Loss: 0.0575
2024-12-29 12:50:47,538 - INFO - Epoch 11/1000, Train Loss: 0.0316, Val Loss: 0.0564
2024-12-29 12:50:47,734 - INFO - Epoch 12/1000, Train Loss: 0.0309, Val Loss: 0.0562
2024-12-29 12:50:47,922 - INFO - Epoch 13/1000, Train Loss: 0.0303, Val Loss: 0.0560
2024-12-29 12:50:48,112 - INFO - Epoch 14/1000, Train Loss: 0.0298, Val Loss: 0.0553
2024-12-29 12:50:48,288 - INFO - Epoch 15/1000, Train Loss: 0.0295, Val Loss: 0.0555
2024-12-29 12:50:48,484 - INFO - Epoch 16/1000, Train Loss: 0.0293, Val Loss: 0.0543
2024-12-29 12:50:48,676 - INFO - Epoch 17/1000, Train Loss: 0.0288, Val Loss: 0.0544
2024-12-29 12:50:48,876 - INFO - Epoch 18/1000, Train Loss: 0.0286, Val Loss: 0.0546
2024-12-29 12:50:49,116 - INFO - Epoch 19/1000, Train Loss: 0.0288, Val Loss: 0.0548
2024-12-29 12:50:49,316 - INFO - Epoch 20/1000, Train Loss: 0.0284, Val Loss: 0.0543
2024-12-29 12:50:49,507 - INFO - Epoch 21/1000, Train Loss: 0.0284, Val Loss: 0.0538
2024-12-29 12:50:49,507 - INFO - Early stopping triggered at epoch 21
2024-12-29 12:50:49,507 - INFO - Training completed in 4.83s
2024-12-29 12:50:49,508 - INFO - Final memory usage: CPU 2696.8 MB, GPU 103.3 MB
2024-12-29 12:50:49,509 - INFO - Model training completed in 4.83s
2024-12-29 12:50:49,573 - INFO - Prediction completed in 0.06s
2024-12-29 12:50:49,581 - INFO - Poison rate 0.0 completed in 7.68s
2024-12-29 12:50:49,581 - INFO - 
Processing poison rate: 0.01
2024-12-29 12:50:49,583 - INFO - Total number of labels flipped: 94
2024-12-29 12:50:49,583 - INFO - Label flipping completed in 0.00s
2024-12-29 12:50:49,584 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:50:49,584 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:50:50,100 - INFO - Feature scaling completed in 0.52s
2024-12-29 12:50:50,100 - INFO - Starting feature selection (k=50)
2024-12-29 12:50:50,114 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 12:50:50,114 - INFO - Starting anomaly detection
2024-12-29 12:50:52,966 - INFO - Anomaly detection completed in 2.85s
2024-12-29 12:50:52,966 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:50:52,966 - INFO - Total fit_transform time: 3.38s
2024-12-29 12:50:52,967 - INFO - Training set processing completed in 3.38s
2024-12-29 12:50:52,967 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 12:50:52,968 - INFO - Memory usage at start_fit: CPU 2696.8 MB, GPU 103.2 MB
2024-12-29 12:50:52,968 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:50:52,971 - INFO - Number of unique classes: 10
2024-12-29 12:50:53,050 - INFO - Fitted scaler and transformed data
2024-12-29 12:50:53,050 - INFO - Scaling time: 0.08s
2024-12-29 12:50:53,249 - INFO - Epoch 1/1000, Train Loss: 0.5497, Val Loss: 0.1979
2024-12-29 12:50:53,441 - INFO - Epoch 2/1000, Train Loss: 0.1660, Val Loss: 0.1716
2024-12-29 12:50:53,670 - INFO - Epoch 3/1000, Train Loss: 0.1437, Val Loss: 0.1643
2024-12-29 12:50:53,975 - INFO - Epoch 4/1000, Train Loss: 0.1309, Val Loss: 0.1624
2024-12-29 12:50:54,295 - INFO - Epoch 5/1000, Train Loss: 0.1240, Val Loss: 0.1615
2024-12-29 12:50:54,658 - INFO - Epoch 6/1000, Train Loss: 0.1180, Val Loss: 0.1612
2024-12-29 12:50:55,048 - INFO - Epoch 7/1000, Train Loss: 0.1127, Val Loss: 0.1601
2024-12-29 12:50:55,468 - INFO - Epoch 8/1000, Train Loss: 0.1089, Val Loss: 0.1608
2024-12-29 12:50:55,874 - INFO - Epoch 9/1000, Train Loss: 0.1048, Val Loss: 0.1594
2024-12-29 12:50:56,297 - INFO - Epoch 10/1000, Train Loss: 0.1021, Val Loss: 0.1612
2024-12-29 12:50:56,532 - INFO - Epoch 11/1000, Train Loss: 0.1004, Val Loss: 0.1594
2024-12-29 12:50:56,763 - INFO - Epoch 12/1000, Train Loss: 0.0983, Val Loss: 0.1599
2024-12-29 12:50:56,764 - INFO - Early stopping triggered at epoch 12
2024-12-29 12:50:56,764 - INFO - Training completed in 3.80s
2024-12-29 12:50:56,765 - INFO - Final memory usage: CPU 2696.8 MB, GPU 103.3 MB
2024-12-29 12:50:56,766 - INFO - Model training completed in 3.80s
2024-12-29 12:50:56,835 - INFO - Prediction completed in 0.07s
2024-12-29 12:50:56,843 - INFO - Poison rate 0.01 completed in 7.26s
2024-12-29 12:50:56,843 - INFO - 
Processing poison rate: 0.03
2024-12-29 12:50:56,847 - INFO - Total number of labels flipped: 284
2024-12-29 12:50:56,847 - INFO - Label flipping completed in 0.00s
2024-12-29 12:50:56,847 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:50:56,847 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:50:57,371 - INFO - Feature scaling completed in 0.52s
2024-12-29 12:50:57,371 - INFO - Starting feature selection (k=50)
2024-12-29 12:50:57,384 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 12:50:57,385 - INFO - Starting anomaly detection
2024-12-29 12:50:59,990 - INFO - Anomaly detection completed in 2.61s
2024-12-29 12:50:59,991 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:50:59,991 - INFO - Total fit_transform time: 3.14s
2024-12-29 12:50:59,991 - INFO - Training set processing completed in 3.14s
2024-12-29 12:50:59,991 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 12:50:59,991 - INFO - Memory usage at start_fit: CPU 2696.8 MB, GPU 103.2 MB
2024-12-29 12:50:59,992 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:50:59,994 - INFO - Number of unique classes: 10
2024-12-29 12:51:00,064 - INFO - Fitted scaler and transformed data
2024-12-29 12:51:00,064 - INFO - Scaling time: 0.07s
2024-12-29 12:51:00,266 - INFO - Epoch 1/1000, Train Loss: 0.6297, Val Loss: 0.2790
2024-12-29 12:51:00,457 - INFO - Epoch 2/1000, Train Loss: 0.3011, Val Loss: 0.2673
2024-12-29 12:51:00,646 - INFO - Epoch 3/1000, Train Loss: 0.2800, Val Loss: 0.2665
2024-12-29 12:51:00,846 - INFO - Epoch 4/1000, Train Loss: 0.2639, Val Loss: 0.2672
2024-12-29 12:51:01,052 - INFO - Epoch 5/1000, Train Loss: 0.2532, Val Loss: 0.2672
2024-12-29 12:51:01,259 - INFO - Epoch 6/1000, Train Loss: 0.2448, Val Loss: 0.2712
2024-12-29 12:51:01,453 - INFO - Epoch 7/1000, Train Loss: 0.2370, Val Loss: 0.2730
2024-12-29 12:51:01,453 - INFO - Early stopping triggered at epoch 7
2024-12-29 12:51:01,454 - INFO - Training completed in 1.46s
2024-12-29 12:51:01,454 - INFO - Final memory usage: CPU 2696.8 MB, GPU 103.3 MB
2024-12-29 12:51:01,455 - INFO - Model training completed in 1.46s
2024-12-29 12:51:01,521 - INFO - Prediction completed in 0.07s
2024-12-29 12:51:01,530 - INFO - Poison rate 0.03 completed in 4.69s
2024-12-29 12:51:01,530 - INFO - 
Processing poison rate: 0.05
2024-12-29 12:51:01,536 - INFO - Total number of labels flipped: 473
2024-12-29 12:51:01,536 - INFO - Label flipping completed in 0.01s
2024-12-29 12:51:01,536 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:51:01,536 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:51:02,149 - INFO - Feature scaling completed in 0.61s
2024-12-29 12:51:02,149 - INFO - Starting feature selection (k=50)
2024-12-29 12:51:02,159 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 12:51:02,159 - INFO - Starting anomaly detection
2024-12-29 12:51:05,023 - INFO - Anomaly detection completed in 2.86s
2024-12-29 12:51:05,023 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:51:05,023 - INFO - Total fit_transform time: 3.49s
2024-12-29 12:51:05,023 - INFO - Training set processing completed in 3.49s
2024-12-29 12:51:05,023 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 12:51:05,025 - INFO - Memory usage at start_fit: CPU 2696.8 MB, GPU 103.2 MB
2024-12-29 12:51:05,025 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:51:05,028 - INFO - Number of unique classes: 10
2024-12-29 12:51:05,095 - INFO - Fitted scaler and transformed data
2024-12-29 12:51:05,095 - INFO - Scaling time: 0.07s
2024-12-29 12:51:05,301 - INFO - Epoch 1/1000, Train Loss: 0.7134, Val Loss: 0.4522
2024-12-29 12:51:05,493 - INFO - Epoch 2/1000, Train Loss: 0.4101, Val Loss: 0.4397
2024-12-29 12:51:05,682 - INFO - Epoch 3/1000, Train Loss: 0.3871, Val Loss: 0.4359
2024-12-29 12:51:05,876 - INFO - Epoch 4/1000, Train Loss: 0.3722, Val Loss: 0.4374
2024-12-29 12:51:06,061 - INFO - Epoch 5/1000, Train Loss: 0.3565, Val Loss: 0.4352
2024-12-29 12:51:06,244 - INFO - Epoch 6/1000, Train Loss: 0.3480, Val Loss: 0.4418
2024-12-29 12:51:06,429 - INFO - Epoch 7/1000, Train Loss: 0.3407, Val Loss: 0.4380
2024-12-29 12:51:06,620 - INFO - Epoch 8/1000, Train Loss: 0.3337, Val Loss: 0.4426
2024-12-29 12:51:06,620 - INFO - Early stopping triggered at epoch 8
2024-12-29 12:51:06,620 - INFO - Training completed in 1.60s
2024-12-29 12:51:06,621 - INFO - Final memory usage: CPU 2696.8 MB, GPU 103.3 MB
2024-12-29 12:51:06,622 - INFO - Model training completed in 1.60s
2024-12-29 12:51:06,687 - INFO - Prediction completed in 0.07s
2024-12-29 12:51:06,696 - INFO - Poison rate 0.05 completed in 5.17s
2024-12-29 12:51:06,696 - INFO - 
Processing poison rate: 0.07
2024-12-29 12:51:06,704 - INFO - Total number of labels flipped: 662
2024-12-29 12:51:06,705 - INFO - Label flipping completed in 0.01s
2024-12-29 12:51:06,705 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:51:06,705 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:51:07,287 - INFO - Feature scaling completed in 0.58s
2024-12-29 12:51:07,287 - INFO - Starting feature selection (k=50)
2024-12-29 12:51:07,301 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 12:51:07,301 - INFO - Starting anomaly detection
2024-12-29 12:51:11,122 - INFO - Anomaly detection completed in 3.82s
2024-12-29 12:51:11,122 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:51:11,122 - INFO - Total fit_transform time: 4.42s
2024-12-29 12:51:11,122 - INFO - Training set processing completed in 4.42s
2024-12-29 12:51:11,123 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 12:51:11,124 - INFO - Memory usage at start_fit: CPU 2696.8 MB, GPU 103.2 MB
2024-12-29 12:51:11,124 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:51:11,127 - INFO - Number of unique classes: 10
2024-12-29 12:51:11,195 - INFO - Fitted scaler and transformed data
2024-12-29 12:51:11,195 - INFO - Scaling time: 0.07s
2024-12-29 12:51:11,504 - INFO - Epoch 1/1000, Train Loss: 0.7803, Val Loss: 0.5376
2024-12-29 12:51:11,827 - INFO - Epoch 2/1000, Train Loss: 0.5161, Val Loss: 0.5265
2024-12-29 12:51:12,204 - INFO - Epoch 3/1000, Train Loss: 0.4914, Val Loss: 0.5312
2024-12-29 12:51:12,569 - INFO - Epoch 4/1000, Train Loss: 0.4728, Val Loss: 0.5298
2024-12-29 12:51:13,002 - INFO - Epoch 5/1000, Train Loss: 0.4600, Val Loss: 0.5364
2024-12-29 12:51:13,406 - INFO - Epoch 6/1000, Train Loss: 0.4498, Val Loss: 0.5334
2024-12-29 12:51:13,818 - INFO - Epoch 7/1000, Train Loss: 0.4403, Val Loss: 0.5367
2024-12-29 12:51:13,819 - INFO - Early stopping triggered at epoch 7
2024-12-29 12:51:13,819 - INFO - Training completed in 2.70s
2024-12-29 12:51:13,819 - INFO - Final memory usage: CPU 2696.8 MB, GPU 103.3 MB
2024-12-29 12:51:13,820 - INFO - Model training completed in 2.70s
2024-12-29 12:51:13,867 - INFO - Prediction completed in 0.05s
2024-12-29 12:51:13,876 - INFO - Poison rate 0.07 completed in 7.18s
2024-12-29 12:51:13,876 - INFO - 
Processing poison rate: 0.1
2024-12-29 12:51:13,888 - INFO - Total number of labels flipped: 946
2024-12-29 12:51:13,889 - INFO - Label flipping completed in 0.01s
2024-12-29 12:51:13,889 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:51:13,889 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:51:14,433 - INFO - Feature scaling completed in 0.54s
2024-12-29 12:51:14,433 - INFO - Starting feature selection (k=50)
2024-12-29 12:51:14,446 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 12:51:14,447 - INFO - Starting anomaly detection
2024-12-29 12:51:17,138 - INFO - Anomaly detection completed in 2.69s
2024-12-29 12:51:17,139 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:51:17,139 - INFO - Total fit_transform time: 3.25s
2024-12-29 12:51:17,139 - INFO - Training set processing completed in 3.25s
2024-12-29 12:51:17,139 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 12:51:17,140 - INFO - Memory usage at start_fit: CPU 2696.8 MB, GPU 103.2 MB
2024-12-29 12:51:17,140 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:51:17,143 - INFO - Number of unique classes: 10
2024-12-29 12:51:17,216 - INFO - Fitted scaler and transformed data
2024-12-29 12:51:17,216 - INFO - Scaling time: 0.07s
2024-12-29 12:51:17,565 - INFO - Epoch 1/1000, Train Loss: 0.9281, Val Loss: 0.6472
2024-12-29 12:51:17,861 - INFO - Epoch 2/1000, Train Loss: 0.6658, Val Loss: 0.6382
2024-12-29 12:51:18,254 - INFO - Epoch 3/1000, Train Loss: 0.6370, Val Loss: 0.6369
2024-12-29 12:51:18,646 - INFO - Epoch 4/1000, Train Loss: 0.6199, Val Loss: 0.6343
2024-12-29 12:51:19,004 - INFO - Epoch 5/1000, Train Loss: 0.6023, Val Loss: 0.6337
2024-12-29 12:51:19,389 - INFO - Epoch 6/1000, Train Loss: 0.5912, Val Loss: 0.6429
2024-12-29 12:51:19,779 - INFO - Epoch 7/1000, Train Loss: 0.5834, Val Loss: 0.6416
2024-12-29 12:51:20,195 - INFO - Epoch 8/1000, Train Loss: 0.5771, Val Loss: 0.6398
2024-12-29 12:51:20,604 - INFO - Epoch 9/1000, Train Loss: 0.5688, Val Loss: 0.6450
2024-12-29 12:51:20,604 - INFO - Early stopping triggered at epoch 9
2024-12-29 12:51:20,604 - INFO - Training completed in 3.46s
2024-12-29 12:51:20,604 - INFO - Final memory usage: CPU 2696.8 MB, GPU 103.3 MB
2024-12-29 12:51:20,605 - INFO - Model training completed in 3.47s
2024-12-29 12:51:20,650 - INFO - Prediction completed in 0.04s
2024-12-29 12:51:20,659 - INFO - Poison rate 0.1 completed in 6.78s
2024-12-29 12:51:20,659 - INFO - 
Processing poison rate: 0.2
2024-12-29 12:51:20,698 - INFO - Total number of labels flipped: 1893
2024-12-29 12:51:20,699 - INFO - Label flipping completed in 0.04s
2024-12-29 12:51:20,699 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:51:20,699 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:51:21,253 - INFO - Feature scaling completed in 0.55s
2024-12-29 12:51:21,253 - INFO - Starting feature selection (k=50)
2024-12-29 12:51:21,267 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 12:51:21,267 - INFO - Starting anomaly detection
2024-12-29 12:51:25,357 - INFO - Anomaly detection completed in 4.09s
2024-12-29 12:51:25,357 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:51:25,357 - INFO - Total fit_transform time: 4.66s
2024-12-29 12:51:25,358 - INFO - Training set processing completed in 4.66s
2024-12-29 12:51:25,358 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 12:51:25,359 - INFO - Memory usage at start_fit: CPU 2696.8 MB, GPU 103.2 MB
2024-12-29 12:51:25,360 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:51:25,363 - INFO - Number of unique classes: 10
2024-12-29 12:51:25,440 - INFO - Fitted scaler and transformed data
2024-12-29 12:51:25,440 - INFO - Scaling time: 0.08s
2024-12-29 12:51:25,707 - INFO - Epoch 1/1000, Train Loss: 1.2599, Val Loss: 1.0723
2024-12-29 12:51:26,056 - INFO - Epoch 2/1000, Train Loss: 1.0516, Val Loss: 1.0702
2024-12-29 12:51:26,323 - INFO - Epoch 3/1000, Train Loss: 1.0186, Val Loss: 1.0779
2024-12-29 12:51:26,601 - INFO - Epoch 4/1000, Train Loss: 0.9974, Val Loss: 1.0751
2024-12-29 12:51:26,904 - INFO - Epoch 5/1000, Train Loss: 0.9814, Val Loss: 1.0888
2024-12-29 12:51:27,240 - INFO - Epoch 6/1000, Train Loss: 0.9726, Val Loss: 1.0851
2024-12-29 12:51:27,533 - INFO - Epoch 7/1000, Train Loss: 0.9601, Val Loss: 1.0898
2024-12-29 12:51:27,533 - INFO - Early stopping triggered at epoch 7
2024-12-29 12:51:27,533 - INFO - Training completed in 2.17s
2024-12-29 12:51:27,533 - INFO - Final memory usage: CPU 2696.8 MB, GPU 103.3 MB
2024-12-29 12:51:27,534 - INFO - Model training completed in 2.18s
2024-12-29 12:51:27,587 - INFO - Prediction completed in 0.05s
2024-12-29 12:51:27,595 - INFO - Poison rate 0.2 completed in 6.94s
2024-12-29 12:51:27,596 - INFO - Loaded 21 existing results
2024-12-29 12:51:27,596 - INFO - Total results to save: 28
2024-12-29 12:51:27,597 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 12:51:27,598 - INFO - Saved 28 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 12:51:27,598 - INFO - Total evaluation time: 77.01s
2024-12-29 12:51:27,600 - INFO - 
Progress: 5.2% - Evaluating GTSRB with RandomForest (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 12:51:27,794 - INFO - Loading datasets...
2024-12-29 12:51:27,815 - INFO - Dataset loading completed in 0.02s
2024-12-29 12:51:27,815 - INFO - Extracting validation features...
2024-12-29 12:51:27,815 - INFO - Extracting features from 3925 samples...
2024-12-29 12:51:36,975 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 12:51:36,978 - INFO - Validation feature extraction completed in 9.16s
2024-12-29 12:51:36,978 - INFO - Extracting training features...
2024-12-29 12:51:36,978 - INFO - Extracting features from 9469 samples...
2024-12-29 12:51:58,493 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 12:51:58,500 - INFO - Training feature extraction completed in 21.52s
2024-12-29 12:51:58,501 - INFO - Creating model for classifier: RandomForest
2024-12-29 12:51:58,501 - INFO - Using device: cuda
2024-12-29 12:51:58,501 - INFO - 
Processing poison rate: 0.0
2024-12-29 12:51:58,501 - INFO - Training set processing completed in 0.00s
2024-12-29 12:51:58,501 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 12:51:58,503 - INFO - Memory usage at start_fit: CPU 2698.6 MB, GPU 103.4 MB
2024-12-29 12:51:58,503 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:51:58,686 - INFO - Fitted scaler and transformed data
2024-12-29 12:51:58,686 - INFO - Scaling time: 0.18s
2024-12-29 12:51:58,698 - INFO - Number of unique classes: 10
2024-12-29 12:52:01,527 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3013
2024-12-29 12:52:04,121 - INFO - Epoch 2/10, Train Loss: 2.3005, Val Loss: 2.3000
2024-12-29 12:52:07,026 - INFO - Epoch 3/10, Train Loss: 2.2991, Val Loss: 2.2987
2024-12-29 12:52:09,867 - INFO - Epoch 4/10, Train Loss: 2.2977, Val Loss: 2.2973
2024-12-29 12:52:09,867 - INFO - Early stopping triggered at epoch 4
2024-12-29 12:52:09,867 - INFO - Training completed in 11.37s
2024-12-29 12:52:09,868 - INFO - Final memory usage: CPU 2670.8 MB, GPU 125.3 MB
2024-12-29 12:52:09,868 - INFO - Model training completed in 11.37s
2024-12-29 12:52:10,166 - INFO - Prediction completed in 0.30s
2024-12-29 12:52:10,175 - INFO - Poison rate 0.0 completed in 11.67s
2024-12-29 12:52:10,175 - INFO - 
Processing poison rate: 0.01
2024-12-29 12:52:10,177 - INFO - Total number of labels flipped: 94
2024-12-29 12:52:10,177 - INFO - Label flipping completed in 0.00s
2024-12-29 12:52:10,177 - INFO - Training set processing completed in 0.00s
2024-12-29 12:52:10,177 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 12:52:10,178 - INFO - Memory usage at start_fit: CPU 2682.0 MB, GPU 105.4 MB
2024-12-29 12:52:10,178 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:52:10,378 - INFO - Fitted scaler and transformed data
2024-12-29 12:52:10,378 - INFO - Scaling time: 0.20s
2024-12-29 12:52:10,392 - INFO - Number of unique classes: 10
2024-12-29 12:52:13,037 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3013
2024-12-29 12:52:16,020 - INFO - Epoch 2/10, Train Loss: 2.3006, Val Loss: 2.3000
2024-12-29 12:52:18,901 - INFO - Epoch 3/10, Train Loss: 2.2992, Val Loss: 2.2987
2024-12-29 12:52:21,905 - INFO - Epoch 4/10, Train Loss: 2.2978, Val Loss: 2.2974
2024-12-29 12:52:21,905 - INFO - Early stopping triggered at epoch 4
2024-12-29 12:52:21,905 - INFO - Training completed in 11.73s
2024-12-29 12:52:21,906 - INFO - Final memory usage: CPU 2698.7 MB, GPU 125.3 MB
2024-12-29 12:52:21,907 - INFO - Model training completed in 11.73s
2024-12-29 12:52:22,066 - INFO - Prediction completed in 0.16s
2024-12-29 12:52:22,074 - INFO - Poison rate 0.01 completed in 11.90s
2024-12-29 12:52:22,074 - INFO - 
Processing poison rate: 0.03
2024-12-29 12:52:22,078 - INFO - Total number of labels flipped: 284
2024-12-29 12:52:22,078 - INFO - Label flipping completed in 0.00s
2024-12-29 12:52:22,078 - INFO - Training set processing completed in 0.00s
2024-12-29 12:52:22,079 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 12:52:22,079 - INFO - Memory usage at start_fit: CPU 2698.7 MB, GPU 105.4 MB
2024-12-29 12:52:22,079 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:52:22,255 - INFO - Fitted scaler and transformed data
2024-12-29 12:52:22,256 - INFO - Scaling time: 0.18s
2024-12-29 12:52:22,266 - INFO - Number of unique classes: 10
2024-12-29 12:52:24,632 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3014
2024-12-29 12:52:27,615 - INFO - Epoch 2/10, Train Loss: 2.3007, Val Loss: 2.3002
2024-12-29 12:52:30,586 - INFO - Epoch 3/10, Train Loss: 2.2993, Val Loss: 2.2990
2024-12-29 12:52:33,298 - INFO - Epoch 4/10, Train Loss: 2.2980, Val Loss: 2.2978
2024-12-29 12:52:33,298 - INFO - Early stopping triggered at epoch 4
2024-12-29 12:52:33,298 - INFO - Training completed in 11.22s
2024-12-29 12:52:33,298 - INFO - Final memory usage: CPU 2698.9 MB, GPU 125.3 MB
2024-12-29 12:52:33,299 - INFO - Model training completed in 11.22s
2024-12-29 12:52:33,446 - INFO - Prediction completed in 0.15s
2024-12-29 12:52:33,455 - INFO - Poison rate 0.03 completed in 11.38s
2024-12-29 12:52:33,455 - INFO - 
Processing poison rate: 0.05
2024-12-29 12:52:33,461 - INFO - Total number of labels flipped: 473
2024-12-29 12:52:33,461 - INFO - Label flipping completed in 0.01s
2024-12-29 12:52:33,461 - INFO - Training set processing completed in 0.00s
2024-12-29 12:52:33,461 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 12:52:33,462 - INFO - Memory usage at start_fit: CPU 2698.9 MB, GPU 105.4 MB
2024-12-29 12:52:33,462 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:52:33,647 - INFO - Fitted scaler and transformed data
2024-12-29 12:52:33,647 - INFO - Scaling time: 0.18s
2024-12-29 12:52:33,657 - INFO - Number of unique classes: 10
2024-12-29 12:52:36,799 - INFO - Epoch 1/10, Train Loss: 2.3021, Val Loss: 2.3014
2024-12-29 12:52:39,788 - INFO - Epoch 2/10, Train Loss: 2.3007, Val Loss: 2.3003
2024-12-29 12:52:42,664 - INFO - Epoch 3/10, Train Loss: 2.2994, Val Loss: 2.2991
2024-12-29 12:52:46,031 - INFO - Epoch 4/10, Train Loss: 2.2981, Val Loss: 2.2978
2024-12-29 12:52:46,031 - INFO - Early stopping triggered at epoch 4
2024-12-29 12:52:46,031 - INFO - Training completed in 12.57s
2024-12-29 12:52:46,032 - INFO - Final memory usage: CPU 2699.2 MB, GPU 125.3 MB
2024-12-29 12:52:46,032 - INFO - Model training completed in 12.57s
2024-12-29 12:52:46,203 - INFO - Prediction completed in 0.17s
2024-12-29 12:52:46,212 - INFO - Poison rate 0.05 completed in 12.76s
2024-12-29 12:52:46,212 - INFO - 
Processing poison rate: 0.07
2024-12-29 12:52:46,220 - INFO - Total number of labels flipped: 662
2024-12-29 12:52:46,220 - INFO - Label flipping completed in 0.01s
2024-12-29 12:52:46,220 - INFO - Training set processing completed in 0.00s
2024-12-29 12:52:46,220 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 12:52:46,221 - INFO - Memory usage at start_fit: CPU 2699.2 MB, GPU 105.4 MB
2024-12-29 12:52:46,221 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:52:46,394 - INFO - Fitted scaler and transformed data
2024-12-29 12:52:46,394 - INFO - Scaling time: 0.17s
2024-12-29 12:52:46,405 - INFO - Number of unique classes: 10
2024-12-29 12:52:49,856 - INFO - Epoch 1/10, Train Loss: 2.3021, Val Loss: 2.3015
2024-12-29 12:52:53,837 - INFO - Epoch 2/10, Train Loss: 2.3008, Val Loss: 2.3003
2024-12-29 12:52:56,584 - INFO - Epoch 3/10, Train Loss: 2.2995, Val Loss: 2.2992
2024-12-29 12:52:59,604 - INFO - Epoch 4/10, Train Loss: 2.2982, Val Loss: 2.2980
2024-12-29 12:52:59,605 - INFO - Early stopping triggered at epoch 4
2024-12-29 12:52:59,605 - INFO - Training completed in 13.38s
2024-12-29 12:52:59,605 - INFO - Final memory usage: CPU 2699.2 MB, GPU 125.3 MB
2024-12-29 12:52:59,605 - INFO - Model training completed in 13.39s
2024-12-29 12:52:59,794 - INFO - Prediction completed in 0.19s
2024-12-29 12:52:59,803 - INFO - Poison rate 0.07 completed in 13.59s
2024-12-29 12:52:59,803 - INFO - 
Processing poison rate: 0.1
2024-12-29 12:52:59,815 - INFO - Total number of labels flipped: 946
2024-12-29 12:52:59,815 - INFO - Label flipping completed in 0.01s
2024-12-29 12:52:59,815 - INFO - Training set processing completed in 0.00s
2024-12-29 12:52:59,815 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 12:52:59,816 - INFO - Memory usage at start_fit: CPU 2699.2 MB, GPU 105.4 MB
2024-12-29 12:52:59,816 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:53:00,000 - INFO - Fitted scaler and transformed data
2024-12-29 12:53:00,000 - INFO - Scaling time: 0.18s
2024-12-29 12:53:00,011 - INFO - Number of unique classes: 10
2024-12-29 12:53:03,703 - INFO - Epoch 1/10, Train Loss: 2.3021, Val Loss: 2.3015
2024-12-29 12:53:06,839 - INFO - Epoch 2/10, Train Loss: 2.3009, Val Loss: 2.3004
2024-12-29 12:53:10,147 - INFO - Epoch 3/10, Train Loss: 2.2996, Val Loss: 2.2993
2024-12-29 12:53:13,276 - INFO - Epoch 4/10, Train Loss: 2.2984, Val Loss: 2.2982
2024-12-29 12:53:13,276 - INFO - Early stopping triggered at epoch 4
2024-12-29 12:53:13,276 - INFO - Training completed in 13.46s
2024-12-29 12:53:13,277 - INFO - Final memory usage: CPU 2699.2 MB, GPU 125.3 MB
2024-12-29 12:53:13,277 - INFO - Model training completed in 13.46s
2024-12-29 12:53:13,429 - INFO - Prediction completed in 0.15s
2024-12-29 12:53:13,437 - INFO - Poison rate 0.1 completed in 13.63s
2024-12-29 12:53:13,438 - INFO - 
Processing poison rate: 0.2
2024-12-29 12:53:13,460 - INFO - Total number of labels flipped: 1893
2024-12-29 12:53:13,460 - INFO - Label flipping completed in 0.02s
2024-12-29 12:53:13,460 - INFO - Training set processing completed in 0.00s
2024-12-29 12:53:13,460 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 12:53:13,461 - INFO - Memory usage at start_fit: CPU 2699.2 MB, GPU 105.4 MB
2024-12-29 12:53:13,461 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:53:13,652 - INFO - Fitted scaler and transformed data
2024-12-29 12:53:13,652 - INFO - Scaling time: 0.19s
2024-12-29 12:53:13,665 - INFO - Number of unique classes: 10
2024-12-29 12:53:16,246 - INFO - Epoch 1/10, Train Loss: 2.3022, Val Loss: 2.3017
2024-12-29 12:53:18,915 - INFO - Epoch 2/10, Train Loss: 2.3012, Val Loss: 2.3009
2024-12-29 12:53:21,549 - INFO - Epoch 3/10, Train Loss: 2.3002, Val Loss: 2.3000
2024-12-29 12:53:24,590 - INFO - Epoch 4/10, Train Loss: 2.2992, Val Loss: 2.2991
2024-12-29 12:53:24,591 - INFO - Early stopping triggered at epoch 4
2024-12-29 12:53:24,591 - INFO - Training completed in 11.13s
2024-12-29 12:53:24,591 - INFO - Final memory usage: CPU 2703.1 MB, GPU 125.3 MB
2024-12-29 12:53:24,591 - INFO - Model training completed in 11.13s
2024-12-29 12:53:24,758 - INFO - Prediction completed in 0.17s
2024-12-29 12:53:24,767 - INFO - Poison rate 0.2 completed in 11.33s
2024-12-29 12:53:24,768 - INFO - Loaded 28 existing results
2024-12-29 12:53:24,768 - INFO - Total results to save: 35
2024-12-29 12:53:24,769 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 12:53:24,770 - INFO - Saved 35 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 12:53:24,771 - INFO - Total evaluation time: 116.98s
2024-12-29 12:53:24,772 - INFO - 
Progress: 6.2% - Evaluating GTSRB with RandomForest (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 12:53:24,949 - INFO - Loading datasets...
2024-12-29 12:53:24,970 - INFO - Dataset loading completed in 0.02s
2024-12-29 12:53:24,970 - INFO - Extracting validation features...
2024-12-29 12:53:24,970 - INFO - Extracting features from 3925 samples...
2024-12-29 12:53:33,985 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 12:53:33,991 - INFO - Validation feature extraction completed in 9.02s
2024-12-29 12:53:33,991 - INFO - Extracting training features...
2024-12-29 12:53:33,991 - INFO - Extracting features from 9469 samples...
2024-12-29 12:53:54,932 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 12:53:54,938 - INFO - Training feature extraction completed in 20.95s
2024-12-29 12:53:54,939 - INFO - Creating model for classifier: RandomForest
2024-12-29 12:53:54,939 - INFO - Using device: cuda
2024-12-29 12:53:54,939 - INFO - 
Processing poison rate: 0.0
2024-12-29 12:53:54,940 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:53:54,940 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:53:55,500 - INFO - Feature scaling completed in 0.56s
2024-12-29 12:53:55,500 - INFO - Starting feature selection (k=50)
2024-12-29 12:53:55,509 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 12:53:55,509 - INFO - Starting anomaly detection
2024-12-29 12:53:59,348 - INFO - Anomaly detection completed in 3.84s
2024-12-29 12:53:59,348 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:53:59,348 - INFO - Total fit_transform time: 4.41s
2024-12-29 12:53:59,349 - INFO - Training set processing completed in 4.41s
2024-12-29 12:53:59,349 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 12:53:59,350 - INFO - Memory usage at start_fit: CPU 2760.4 MB, GPU 103.7 MB
2024-12-29 12:53:59,350 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:53:59,530 - INFO - Fitted scaler and transformed data
2024-12-29 12:53:59,531 - INFO - Scaling time: 0.18s
2024-12-29 12:53:59,538 - INFO - Number of unique classes: 10
2024-12-29 12:54:03,081 - INFO - Epoch 1/10, Train Loss: 2.1877, Val Loss: 2.3013
2024-12-29 12:54:06,479 - INFO - Epoch 2/10, Train Loss: 2.1863, Val Loss: 2.3000
2024-12-29 12:54:09,832 - INFO - Epoch 3/10, Train Loss: 2.1850, Val Loss: 2.2987
2024-12-29 12:54:13,752 - INFO - Epoch 4/10, Train Loss: 2.1836, Val Loss: 2.2974
2024-12-29 12:54:13,752 - INFO - Early stopping triggered at epoch 4
2024-12-29 12:54:13,752 - INFO - Training completed in 14.40s
2024-12-29 12:54:13,752 - INFO - Final memory usage: CPU 2760.5 MB, GPU 125.7 MB
2024-12-29 12:54:13,753 - INFO - Model training completed in 14.40s
2024-12-29 12:54:13,986 - INFO - Prediction completed in 0.23s
2024-12-29 12:54:13,995 - INFO - Poison rate 0.0 completed in 19.06s
2024-12-29 12:54:13,995 - INFO - 
Processing poison rate: 0.01
2024-12-29 12:54:13,997 - INFO - Total number of labels flipped: 94
2024-12-29 12:54:13,997 - INFO - Label flipping completed in 0.00s
2024-12-29 12:54:13,997 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:54:13,997 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:54:14,596 - INFO - Feature scaling completed in 0.60s
2024-12-29 12:54:14,596 - INFO - Starting feature selection (k=50)
2024-12-29 12:54:14,611 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 12:54:14,611 - INFO - Starting anomaly detection
2024-12-29 12:54:18,100 - INFO - Anomaly detection completed in 3.49s
2024-12-29 12:54:18,100 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:54:18,100 - INFO - Total fit_transform time: 4.10s
2024-12-29 12:54:18,100 - INFO - Training set processing completed in 4.10s
2024-12-29 12:54:18,100 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 12:54:18,101 - INFO - Memory usage at start_fit: CPU 2760.5 MB, GPU 105.8 MB
2024-12-29 12:54:18,101 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:54:18,310 - INFO - Fitted scaler and transformed data
2024-12-29 12:54:18,310 - INFO - Scaling time: 0.21s
2024-12-29 12:54:18,316 - INFO - Number of unique classes: 10
2024-12-29 12:54:21,642 - INFO - Epoch 1/10, Train Loss: 2.1874, Val Loss: 2.3013
2024-12-29 12:54:24,520 - INFO - Epoch 2/10, Train Loss: 2.1861, Val Loss: 2.3001
2024-12-29 12:54:27,747 - INFO - Epoch 3/10, Train Loss: 2.1847, Val Loss: 2.2988
2024-12-29 12:54:30,389 - INFO - Epoch 4/10, Train Loss: 2.1834, Val Loss: 2.2974
2024-12-29 12:54:30,389 - INFO - Early stopping triggered at epoch 4
2024-12-29 12:54:30,390 - INFO - Training completed in 12.29s
2024-12-29 12:54:30,390 - INFO - Final memory usage: CPU 2760.5 MB, GPU 125.7 MB
2024-12-29 12:54:30,390 - INFO - Model training completed in 12.29s
2024-12-29 12:54:30,533 - INFO - Prediction completed in 0.14s
2024-12-29 12:54:30,541 - INFO - Poison rate 0.01 completed in 16.55s
2024-12-29 12:54:30,542 - INFO - 
Processing poison rate: 0.03
2024-12-29 12:54:30,546 - INFO - Total number of labels flipped: 284
2024-12-29 12:54:30,546 - INFO - Label flipping completed in 0.00s
2024-12-29 12:54:30,546 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:54:30,546 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:54:31,098 - INFO - Feature scaling completed in 0.55s
2024-12-29 12:54:31,098 - INFO - Starting feature selection (k=50)
2024-12-29 12:54:31,111 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 12:54:31,111 - INFO - Starting anomaly detection
2024-12-29 12:54:34,973 - INFO - Anomaly detection completed in 3.86s
2024-12-29 12:54:34,974 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:54:34,974 - INFO - Total fit_transform time: 4.43s
2024-12-29 12:54:34,974 - INFO - Training set processing completed in 4.43s
2024-12-29 12:54:34,974 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 12:54:34,975 - INFO - Memory usage at start_fit: CPU 2760.6 MB, GPU 105.8 MB
2024-12-29 12:54:34,976 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:54:35,179 - INFO - Fitted scaler and transformed data
2024-12-29 12:54:35,179 - INFO - Scaling time: 0.20s
2024-12-29 12:54:35,187 - INFO - Number of unique classes: 10
2024-12-29 12:54:38,649 - INFO - Epoch 1/10, Train Loss: 2.1875, Val Loss: 2.3014
2024-12-29 12:54:41,769 - INFO - Epoch 2/10, Train Loss: 2.1862, Val Loss: 2.3002
2024-12-29 12:54:45,568 - INFO - Epoch 3/10, Train Loss: 2.1849, Val Loss: 2.2989
2024-12-29 12:54:48,971 - INFO - Epoch 4/10, Train Loss: 2.1836, Val Loss: 2.2976
2024-12-29 12:54:48,971 - INFO - Early stopping triggered at epoch 4
2024-12-29 12:54:48,971 - INFO - Training completed in 14.00s
2024-12-29 12:54:48,971 - INFO - Final memory usage: CPU 2760.6 MB, GPU 125.7 MB
2024-12-29 12:54:48,971 - INFO - Model training completed in 14.00s
2024-12-29 12:54:49,135 - INFO - Prediction completed in 0.16s
2024-12-29 12:54:49,143 - INFO - Poison rate 0.03 completed in 18.60s
2024-12-29 12:54:49,143 - INFO - 
Processing poison rate: 0.05
2024-12-29 12:54:49,149 - INFO - Total number of labels flipped: 473
2024-12-29 12:54:49,149 - INFO - Label flipping completed in 0.01s
2024-12-29 12:54:49,149 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:54:49,150 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:54:49,682 - INFO - Feature scaling completed in 0.53s
2024-12-29 12:54:49,682 - INFO - Starting feature selection (k=50)
2024-12-29 12:54:49,694 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 12:54:49,695 - INFO - Starting anomaly detection
2024-12-29 12:54:51,952 - INFO - Anomaly detection completed in 2.26s
2024-12-29 12:54:51,952 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:54:51,952 - INFO - Total fit_transform time: 2.80s
2024-12-29 12:54:51,952 - INFO - Training set processing completed in 2.80s
2024-12-29 12:54:51,952 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 12:54:51,953 - INFO - Memory usage at start_fit: CPU 2760.6 MB, GPU 105.8 MB
2024-12-29 12:54:51,953 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:54:52,123 - INFO - Fitted scaler and transformed data
2024-12-29 12:54:52,123 - INFO - Scaling time: 0.17s
2024-12-29 12:54:52,130 - INFO - Number of unique classes: 10
2024-12-29 12:54:55,767 - INFO - Epoch 1/10, Train Loss: 2.1859, Val Loss: 2.3014
2024-12-29 12:54:58,998 - INFO - Epoch 2/10, Train Loss: 2.1846, Val Loss: 2.3003
2024-12-29 12:55:01,669 - INFO - Epoch 3/10, Train Loss: 2.1834, Val Loss: 2.2991
2024-12-29 12:55:04,501 - INFO - Epoch 4/10, Train Loss: 2.1821, Val Loss: 2.2979
2024-12-29 12:55:04,501 - INFO - Early stopping triggered at epoch 4
2024-12-29 12:55:04,501 - INFO - Training completed in 12.55s
2024-12-29 12:55:04,501 - INFO - Final memory usage: CPU 2760.6 MB, GPU 125.7 MB
2024-12-29 12:55:04,502 - INFO - Model training completed in 12.55s
2024-12-29 12:55:04,668 - INFO - Prediction completed in 0.17s
2024-12-29 12:55:04,677 - INFO - Poison rate 0.05 completed in 15.53s
2024-12-29 12:55:04,677 - INFO - 
Processing poison rate: 0.07
2024-12-29 12:55:04,685 - INFO - Total number of labels flipped: 662
2024-12-29 12:55:04,685 - INFO - Label flipping completed in 0.01s
2024-12-29 12:55:04,686 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:55:04,686 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:55:05,203 - INFO - Feature scaling completed in 0.52s
2024-12-29 12:55:05,203 - INFO - Starting feature selection (k=50)
2024-12-29 12:55:05,217 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 12:55:05,217 - INFO - Starting anomaly detection
2024-12-29 12:55:07,956 - INFO - Anomaly detection completed in 2.74s
2024-12-29 12:55:07,956 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:55:07,956 - INFO - Total fit_transform time: 3.27s
2024-12-29 12:55:07,956 - INFO - Training set processing completed in 3.27s
2024-12-29 12:55:07,957 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 12:55:07,957 - INFO - Memory usage at start_fit: CPU 2760.6 MB, GPU 105.8 MB
2024-12-29 12:55:07,958 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:55:08,149 - INFO - Fitted scaler and transformed data
2024-12-29 12:55:08,149 - INFO - Scaling time: 0.19s
2024-12-29 12:55:08,158 - INFO - Number of unique classes: 10
2024-12-29 12:55:11,792 - INFO - Epoch 1/10, Train Loss: 2.1869, Val Loss: 2.3014
2024-12-29 12:55:14,996 - INFO - Epoch 2/10, Train Loss: 2.1857, Val Loss: 2.3003
2024-12-29 12:55:17,855 - INFO - Epoch 3/10, Train Loss: 2.1845, Val Loss: 2.2991
2024-12-29 12:55:20,806 - INFO - Epoch 4/10, Train Loss: 2.1832, Val Loss: 2.2980
2024-12-29 12:55:20,807 - INFO - Early stopping triggered at epoch 4
2024-12-29 12:55:20,807 - INFO - Training completed in 12.85s
2024-12-29 12:55:20,807 - INFO - Final memory usage: CPU 2760.6 MB, GPU 125.7 MB
2024-12-29 12:55:20,807 - INFO - Model training completed in 12.85s
2024-12-29 12:55:20,952 - INFO - Prediction completed in 0.14s
2024-12-29 12:55:20,961 - INFO - Poison rate 0.07 completed in 16.28s
2024-12-29 12:55:20,961 - INFO - 
Processing poison rate: 0.1
2024-12-29 12:55:20,973 - INFO - Total number of labels flipped: 946
2024-12-29 12:55:20,973 - INFO - Label flipping completed in 0.01s
2024-12-29 12:55:20,973 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:55:20,973 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:55:21,490 - INFO - Feature scaling completed in 0.52s
2024-12-29 12:55:21,490 - INFO - Starting feature selection (k=50)
2024-12-29 12:55:21,503 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 12:55:21,503 - INFO - Starting anomaly detection
2024-12-29 12:55:25,651 - INFO - Anomaly detection completed in 4.15s
2024-12-29 12:55:25,652 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:55:25,652 - INFO - Total fit_transform time: 4.68s
2024-12-29 12:55:25,652 - INFO - Training set processing completed in 4.68s
2024-12-29 12:55:25,652 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 12:55:25,653 - INFO - Memory usage at start_fit: CPU 2760.6 MB, GPU 105.8 MB
2024-12-29 12:55:25,653 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:55:25,842 - INFO - Fitted scaler and transformed data
2024-12-29 12:55:25,843 - INFO - Scaling time: 0.19s
2024-12-29 12:55:25,850 - INFO - Number of unique classes: 10
2024-12-29 12:55:28,505 - INFO - Epoch 1/10, Train Loss: 2.1868, Val Loss: 2.3015
2024-12-29 12:55:31,585 - INFO - Epoch 2/10, Train Loss: 2.1856, Val Loss: 2.3005
2024-12-29 12:55:34,277 - INFO - Epoch 3/10, Train Loss: 2.1845, Val Loss: 2.2994
2024-12-29 12:55:37,279 - INFO - Epoch 4/10, Train Loss: 2.1833, Val Loss: 2.2983
2024-12-29 12:55:37,279 - INFO - Early stopping triggered at epoch 4
2024-12-29 12:55:37,279 - INFO - Training completed in 11.63s
2024-12-29 12:55:37,280 - INFO - Final memory usage: CPU 2760.6 MB, GPU 125.7 MB
2024-12-29 12:55:37,281 - INFO - Model training completed in 11.63s
2024-12-29 12:55:37,509 - INFO - Prediction completed in 0.23s
2024-12-29 12:55:37,518 - INFO - Poison rate 0.1 completed in 16.56s
2024-12-29 12:55:37,518 - INFO - 
Processing poison rate: 0.2
2024-12-29 12:55:37,539 - INFO - Total number of labels flipped: 1893
2024-12-29 12:55:37,540 - INFO - Label flipping completed in 0.02s
2024-12-29 12:55:37,540 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:55:37,540 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:55:38,099 - INFO - Feature scaling completed in 0.56s
2024-12-29 12:55:38,099 - INFO - Starting feature selection (k=50)
2024-12-29 12:55:38,112 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 12:55:38,113 - INFO - Starting anomaly detection
2024-12-29 12:55:41,330 - INFO - Anomaly detection completed in 3.22s
2024-12-29 12:55:41,331 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:55:41,331 - INFO - Total fit_transform time: 3.79s
2024-12-29 12:55:41,331 - INFO - Training set processing completed in 3.79s
2024-12-29 12:55:41,331 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 12:55:41,332 - INFO - Memory usage at start_fit: CPU 2760.6 MB, GPU 105.8 MB
2024-12-29 12:55:41,332 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:55:41,510 - INFO - Fitted scaler and transformed data
2024-12-29 12:55:41,510 - INFO - Scaling time: 0.18s
2024-12-29 12:55:41,516 - INFO - Number of unique classes: 10
2024-12-29 12:55:44,463 - INFO - Epoch 1/10, Train Loss: 2.1864, Val Loss: 2.3017
2024-12-29 12:55:47,203 - INFO - Epoch 2/10, Train Loss: 2.1854, Val Loss: 2.3008
2024-12-29 12:55:51,411 - INFO - Epoch 3/10, Train Loss: 2.1844, Val Loss: 2.2999
2024-12-29 12:55:54,842 - INFO - Epoch 4/10, Train Loss: 2.1835, Val Loss: 2.2990
2024-12-29 12:55:54,843 - INFO - Early stopping triggered at epoch 4
2024-12-29 12:55:54,843 - INFO - Training completed in 13.51s
2024-12-29 12:55:54,843 - INFO - Final memory usage: CPU 2760.6 MB, GPU 125.7 MB
2024-12-29 12:55:54,843 - INFO - Model training completed in 13.51s
2024-12-29 12:55:54,989 - INFO - Prediction completed in 0.15s
2024-12-29 12:55:54,998 - INFO - Poison rate 0.2 completed in 17.48s
2024-12-29 12:55:54,999 - INFO - Loaded 35 existing results
2024-12-29 12:55:54,999 - INFO - Total results to save: 42
2024-12-29 12:55:54,999 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 12:55:55,002 - INFO - Saved 42 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 12:55:55,002 - INFO - Total evaluation time: 150.05s
2024-12-29 12:55:55,003 - INFO - 
Progress: 7.3% - Evaluating GTSRB with KNeighbors (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 12:55:55,207 - INFO - Loading datasets...
2024-12-29 12:55:55,231 - INFO - Dataset loading completed in 0.02s
2024-12-29 12:55:55,231 - INFO - Extracting validation features...
2024-12-29 12:55:55,231 - INFO - Extracting features from 3925 samples...
2024-12-29 12:56:04,302 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 12:56:04,306 - INFO - Validation feature extraction completed in 9.07s
2024-12-29 12:56:04,307 - INFO - Extracting training features...
2024-12-29 12:56:04,307 - INFO - Extracting features from 9469 samples...
2024-12-29 12:56:25,712 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 12:56:25,720 - INFO - Training feature extraction completed in 21.41s
2024-12-29 12:56:25,721 - INFO - Creating model for classifier: KNeighbors
2024-12-29 12:56:25,721 - INFO - Using device: cuda
2024-12-29 12:56:25,722 - INFO - 
Processing poison rate: 0.0
2024-12-29 12:56:25,722 - INFO - Training set processing completed in 0.00s
2024-12-29 12:56:25,723 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 12:56:25,725 - INFO - Memory usage at start_fit: CPU 2762.6 MB, GPU 102.5 MB
2024-12-29 12:56:25,725 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:56:25,902 - INFO - Fitted scaler and transformed data
2024-12-29 12:56:25,902 - INFO - Scaling time: 0.18s
2024-12-29 12:56:25,910 - INFO - Training completed in 0.19s
2024-12-29 12:56:25,911 - INFO - Final memory usage: CPU 2708.3 MB, GPU 121.1 MB
2024-12-29 12:56:25,911 - INFO - Model training completed in 0.19s
2024-12-29 12:56:26,006 - INFO - Prediction completed in 0.10s
2024-12-29 12:56:26,016 - INFO - Poison rate 0.0 completed in 0.29s
2024-12-29 12:56:26,016 - INFO - 
Processing poison rate: 0.01
2024-12-29 12:56:26,019 - INFO - Total number of labels flipped: 94
2024-12-29 12:56:26,019 - INFO - Label flipping completed in 0.00s
2024-12-29 12:56:26,019 - INFO - Training set processing completed in 0.00s
2024-12-29 12:56:26,020 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 12:56:26,020 - INFO - Memory usage at start_fit: CPU 2708.4 MB, GPU 121.1 MB
2024-12-29 12:56:26,020 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:56:26,196 - INFO - Fitted scaler and transformed data
2024-12-29 12:56:26,196 - INFO - Scaling time: 0.18s
2024-12-29 12:56:26,202 - INFO - Training completed in 0.18s
2024-12-29 12:56:26,203 - INFO - Final memory usage: CPU 2708.4 MB, GPU 121.1 MB
2024-12-29 12:56:26,203 - INFO - Model training completed in 0.18s
2024-12-29 12:56:26,282 - INFO - Prediction completed in 0.08s
2024-12-29 12:56:26,292 - INFO - Poison rate 0.01 completed in 0.28s
2024-12-29 12:56:26,292 - INFO - 
Processing poison rate: 0.03
2024-12-29 12:56:26,297 - INFO - Total number of labels flipped: 284
2024-12-29 12:56:26,297 - INFO - Label flipping completed in 0.00s
2024-12-29 12:56:26,297 - INFO - Training set processing completed in 0.00s
2024-12-29 12:56:26,297 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 12:56:26,298 - INFO - Memory usage at start_fit: CPU 2708.4 MB, GPU 121.1 MB
2024-12-29 12:56:26,298 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:56:26,466 - INFO - Fitted scaler and transformed data
2024-12-29 12:56:26,466 - INFO - Scaling time: 0.17s
2024-12-29 12:56:26,472 - INFO - Training completed in 0.17s
2024-12-29 12:56:26,473 - INFO - Final memory usage: CPU 2708.4 MB, GPU 121.1 MB
2024-12-29 12:56:26,473 - INFO - Model training completed in 0.18s
2024-12-29 12:56:26,553 - INFO - Prediction completed in 0.08s
2024-12-29 12:56:26,561 - INFO - Poison rate 0.03 completed in 0.27s
2024-12-29 12:56:26,562 - INFO - 
Processing poison rate: 0.05
2024-12-29 12:56:26,568 - INFO - Total number of labels flipped: 473
2024-12-29 12:56:26,568 - INFO - Label flipping completed in 0.01s
2024-12-29 12:56:26,568 - INFO - Training set processing completed in 0.00s
2024-12-29 12:56:26,568 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 12:56:26,569 - INFO - Memory usage at start_fit: CPU 2708.4 MB, GPU 121.1 MB
2024-12-29 12:56:26,569 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:56:26,783 - INFO - Fitted scaler and transformed data
2024-12-29 12:56:26,783 - INFO - Scaling time: 0.21s
2024-12-29 12:56:26,789 - INFO - Training completed in 0.22s
2024-12-29 12:56:26,789 - INFO - Final memory usage: CPU 2708.4 MB, GPU 121.1 MB
2024-12-29 12:56:26,789 - INFO - Model training completed in 0.22s
2024-12-29 12:56:26,870 - INFO - Prediction completed in 0.08s
2024-12-29 12:56:26,878 - INFO - Poison rate 0.05 completed in 0.32s
2024-12-29 12:56:26,879 - INFO - 
Processing poison rate: 0.07
2024-12-29 12:56:26,887 - INFO - Total number of labels flipped: 662
2024-12-29 12:56:26,887 - INFO - Label flipping completed in 0.01s
2024-12-29 12:56:26,887 - INFO - Training set processing completed in 0.00s
2024-12-29 12:56:26,887 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 12:56:26,888 - INFO - Memory usage at start_fit: CPU 2708.4 MB, GPU 121.1 MB
2024-12-29 12:56:26,888 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:56:27,091 - INFO - Fitted scaler and transformed data
2024-12-29 12:56:27,091 - INFO - Scaling time: 0.20s
2024-12-29 12:56:27,097 - INFO - Training completed in 0.21s
2024-12-29 12:56:27,097 - INFO - Final memory usage: CPU 2708.4 MB, GPU 121.1 MB
2024-12-29 12:56:27,097 - INFO - Model training completed in 0.21s
2024-12-29 12:56:27,178 - INFO - Prediction completed in 0.08s
2024-12-29 12:56:27,186 - INFO - Poison rate 0.07 completed in 0.31s
2024-12-29 12:56:27,186 - INFO - 
Processing poison rate: 0.1
2024-12-29 12:56:27,198 - INFO - Total number of labels flipped: 946
2024-12-29 12:56:27,198 - INFO - Label flipping completed in 0.01s
2024-12-29 12:56:27,198 - INFO - Training set processing completed in 0.00s
2024-12-29 12:56:27,198 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 12:56:27,199 - INFO - Memory usage at start_fit: CPU 2708.4 MB, GPU 121.1 MB
2024-12-29 12:56:27,199 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:56:27,366 - INFO - Fitted scaler and transformed data
2024-12-29 12:56:27,366 - INFO - Scaling time: 0.17s
2024-12-29 12:56:27,374 - INFO - Training completed in 0.18s
2024-12-29 12:56:27,374 - INFO - Final memory usage: CPU 2708.4 MB, GPU 121.1 MB
2024-12-29 12:56:27,374 - INFO - Model training completed in 0.18s
2024-12-29 12:56:27,459 - INFO - Prediction completed in 0.08s
2024-12-29 12:56:27,469 - INFO - Poison rate 0.1 completed in 0.28s
2024-12-29 12:56:27,470 - INFO - 
Processing poison rate: 0.2
2024-12-29 12:56:27,491 - INFO - Total number of labels flipped: 1893
2024-12-29 12:56:27,492 - INFO - Label flipping completed in 0.02s
2024-12-29 12:56:27,492 - INFO - Training set processing completed in 0.00s
2024-12-29 12:56:27,492 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 12:56:27,492 - INFO - Memory usage at start_fit: CPU 2708.4 MB, GPU 121.1 MB
2024-12-29 12:56:27,492 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:56:27,664 - INFO - Fitted scaler and transformed data
2024-12-29 12:56:27,664 - INFO - Scaling time: 0.17s
2024-12-29 12:56:27,674 - INFO - Training completed in 0.18s
2024-12-29 12:56:27,675 - INFO - Final memory usage: CPU 2717.6 MB, GPU 121.1 MB
2024-12-29 12:56:27,675 - INFO - Model training completed in 0.18s
2024-12-29 12:56:27,786 - INFO - Prediction completed in 0.11s
2024-12-29 12:56:27,794 - INFO - Poison rate 0.2 completed in 0.32s
2024-12-29 12:56:27,796 - INFO - Loaded 42 existing results
2024-12-29 12:56:27,796 - INFO - Total results to save: 49
2024-12-29 12:56:27,796 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 12:56:27,799 - INFO - Saved 49 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 12:56:27,799 - INFO - Total evaluation time: 32.59s
2024-12-29 12:56:27,800 - INFO - 
Progress: 8.3% - Evaluating GTSRB with KNeighbors (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 12:56:27,992 - INFO - Loading datasets...
2024-12-29 12:56:28,012 - INFO - Dataset loading completed in 0.02s
2024-12-29 12:56:28,013 - INFO - Extracting validation features...
2024-12-29 12:56:28,013 - INFO - Extracting features from 3925 samples...
2024-12-29 12:56:37,242 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 12:56:37,245 - INFO - Validation feature extraction completed in 9.23s
2024-12-29 12:56:37,245 - INFO - Extracting training features...
2024-12-29 12:56:37,245 - INFO - Extracting features from 9469 samples...
2024-12-29 12:56:58,609 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 12:56:58,617 - INFO - Training feature extraction completed in 21.37s
2024-12-29 12:56:58,617 - INFO - Creating model for classifier: KNeighbors
2024-12-29 12:56:58,618 - INFO - Using device: cuda
2024-12-29 12:56:58,618 - INFO - 
Processing poison rate: 0.0
2024-12-29 12:56:58,618 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:56:58,618 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:56:59,244 - INFO - Feature scaling completed in 0.63s
2024-12-29 12:56:59,244 - INFO - Starting feature selection (k=50)
2024-12-29 12:56:59,259 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 12:56:59,260 - INFO - Starting anomaly detection
2024-12-29 12:57:02,969 - INFO - Anomaly detection completed in 3.71s
2024-12-29 12:57:02,970 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:57:02,970 - INFO - Total fit_transform time: 4.35s
2024-12-29 12:57:02,970 - INFO - Training set processing completed in 4.35s
2024-12-29 12:57:02,970 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 12:57:02,971 - INFO - Memory usage at start_fit: CPU 2761.9 MB, GPU 104.0 MB
2024-12-29 12:57:02,971 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:57:03,156 - INFO - Fitted scaler and transformed data
2024-12-29 12:57:03,156 - INFO - Scaling time: 0.19s
2024-12-29 12:57:03,164 - INFO - Training completed in 0.19s
2024-12-29 12:57:03,165 - INFO - Final memory usage: CPU 2761.9 MB, GPU 122.6 MB
2024-12-29 12:57:03,165 - INFO - Model training completed in 0.20s
2024-12-29 12:57:03,291 - INFO - Prediction completed in 0.13s
2024-12-29 12:57:03,300 - INFO - Poison rate 0.0 completed in 4.68s
2024-12-29 12:57:03,301 - INFO - 
Processing poison rate: 0.01
2024-12-29 12:57:03,303 - INFO - Total number of labels flipped: 94
2024-12-29 12:57:03,303 - INFO - Label flipping completed in 0.00s
2024-12-29 12:57:03,303 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:57:03,303 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:57:03,828 - INFO - Feature scaling completed in 0.53s
2024-12-29 12:57:03,829 - INFO - Starting feature selection (k=50)
2024-12-29 12:57:03,842 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 12:57:03,842 - INFO - Starting anomaly detection
2024-12-29 12:57:06,874 - INFO - Anomaly detection completed in 3.03s
2024-12-29 12:57:06,874 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:57:06,875 - INFO - Total fit_transform time: 3.57s
2024-12-29 12:57:06,875 - INFO - Training set processing completed in 3.57s
2024-12-29 12:57:06,875 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 12:57:06,876 - INFO - Memory usage at start_fit: CPU 2761.9 MB, GPU 122.6 MB
2024-12-29 12:57:06,876 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:57:07,065 - INFO - Fitted scaler and transformed data
2024-12-29 12:57:07,066 - INFO - Scaling time: 0.19s
2024-12-29 12:57:07,073 - INFO - Training completed in 0.20s
2024-12-29 12:57:07,073 - INFO - Final memory usage: CPU 2761.9 MB, GPU 122.6 MB
2024-12-29 12:57:07,074 - INFO - Model training completed in 0.20s
2024-12-29 12:57:07,177 - INFO - Prediction completed in 0.10s
2024-12-29 12:57:07,185 - INFO - Poison rate 0.01 completed in 3.88s
2024-12-29 12:57:07,185 - INFO - 
Processing poison rate: 0.03
2024-12-29 12:57:07,189 - INFO - Total number of labels flipped: 284
2024-12-29 12:57:07,189 - INFO - Label flipping completed in 0.00s
2024-12-29 12:57:07,189 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:57:07,189 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:57:07,779 - INFO - Feature scaling completed in 0.59s
2024-12-29 12:57:07,779 - INFO - Starting feature selection (k=50)
2024-12-29 12:57:07,788 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 12:57:07,788 - INFO - Starting anomaly detection
2024-12-29 12:57:11,379 - INFO - Anomaly detection completed in 3.59s
2024-12-29 12:57:11,379 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:57:11,379 - INFO - Total fit_transform time: 4.19s
2024-12-29 12:57:11,379 - INFO - Training set processing completed in 4.19s
2024-12-29 12:57:11,379 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 12:57:11,380 - INFO - Memory usage at start_fit: CPU 2761.9 MB, GPU 122.6 MB
2024-12-29 12:57:11,380 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:57:11,574 - INFO - Fitted scaler and transformed data
2024-12-29 12:57:11,574 - INFO - Scaling time: 0.19s
2024-12-29 12:57:11,581 - INFO - Training completed in 0.20s
2024-12-29 12:57:11,582 - INFO - Final memory usage: CPU 2761.9 MB, GPU 122.6 MB
2024-12-29 12:57:11,582 - INFO - Model training completed in 0.20s
2024-12-29 12:57:11,703 - INFO - Prediction completed in 0.12s
2024-12-29 12:57:11,711 - INFO - Poison rate 0.03 completed in 4.53s
2024-12-29 12:57:11,712 - INFO - 
Processing poison rate: 0.05
2024-12-29 12:57:11,717 - INFO - Total number of labels flipped: 473
2024-12-29 12:57:11,718 - INFO - Label flipping completed in 0.01s
2024-12-29 12:57:11,718 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:57:11,718 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:57:12,236 - INFO - Feature scaling completed in 0.52s
2024-12-29 12:57:12,236 - INFO - Starting feature selection (k=50)
2024-12-29 12:57:12,248 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 12:57:12,248 - INFO - Starting anomaly detection
2024-12-29 12:57:15,903 - INFO - Anomaly detection completed in 3.65s
2024-12-29 12:57:15,903 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:57:15,903 - INFO - Total fit_transform time: 4.19s
2024-12-29 12:57:15,904 - INFO - Training set processing completed in 4.19s
2024-12-29 12:57:15,904 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 12:57:15,906 - INFO - Memory usage at start_fit: CPU 2761.9 MB, GPU 122.6 MB
2024-12-29 12:57:15,906 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:57:16,101 - INFO - Fitted scaler and transformed data
2024-12-29 12:57:16,102 - INFO - Scaling time: 0.20s
2024-12-29 12:57:16,109 - INFO - Training completed in 0.20s
2024-12-29 12:57:16,109 - INFO - Final memory usage: CPU 2761.9 MB, GPU 122.6 MB
2024-12-29 12:57:16,110 - INFO - Model training completed in 0.21s
2024-12-29 12:57:16,209 - INFO - Prediction completed in 0.10s
2024-12-29 12:57:16,217 - INFO - Poison rate 0.05 completed in 4.51s
2024-12-29 12:57:16,218 - INFO - 
Processing poison rate: 0.07
2024-12-29 12:57:16,226 - INFO - Total number of labels flipped: 662
2024-12-29 12:57:16,226 - INFO - Label flipping completed in 0.01s
2024-12-29 12:57:16,226 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:57:16,226 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:57:16,768 - INFO - Feature scaling completed in 0.54s
2024-12-29 12:57:16,768 - INFO - Starting feature selection (k=50)
2024-12-29 12:57:16,777 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 12:57:16,778 - INFO - Starting anomaly detection
2024-12-29 12:57:20,396 - INFO - Anomaly detection completed in 3.62s
2024-12-29 12:57:20,396 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:57:20,396 - INFO - Total fit_transform time: 4.17s
2024-12-29 12:57:20,396 - INFO - Training set processing completed in 4.17s
2024-12-29 12:57:20,397 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 12:57:20,398 - INFO - Memory usage at start_fit: CPU 2761.9 MB, GPU 122.6 MB
2024-12-29 12:57:20,398 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:57:20,591 - INFO - Fitted scaler and transformed data
2024-12-29 12:57:20,591 - INFO - Scaling time: 0.19s
2024-12-29 12:57:20,598 - INFO - Training completed in 0.20s
2024-12-29 12:57:20,598 - INFO - Final memory usage: CPU 2761.9 MB, GPU 122.6 MB
2024-12-29 12:57:20,599 - INFO - Model training completed in 0.20s
2024-12-29 12:57:20,704 - INFO - Prediction completed in 0.10s
2024-12-29 12:57:20,712 - INFO - Poison rate 0.07 completed in 4.49s
2024-12-29 12:57:20,713 - INFO - 
Processing poison rate: 0.1
2024-12-29 12:57:20,724 - INFO - Total number of labels flipped: 946
2024-12-29 12:57:20,724 - INFO - Label flipping completed in 0.01s
2024-12-29 12:57:20,724 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:57:20,724 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:57:21,291 - INFO - Feature scaling completed in 0.57s
2024-12-29 12:57:21,291 - INFO - Starting feature selection (k=50)
2024-12-29 12:57:21,300 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 12:57:21,301 - INFO - Starting anomaly detection
2024-12-29 12:57:24,106 - INFO - Anomaly detection completed in 2.81s
2024-12-29 12:57:24,106 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:57:24,106 - INFO - Total fit_transform time: 3.38s
2024-12-29 12:57:24,107 - INFO - Training set processing completed in 3.38s
2024-12-29 12:57:24,107 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 12:57:24,107 - INFO - Memory usage at start_fit: CPU 2761.9 MB, GPU 122.6 MB
2024-12-29 12:57:24,108 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:57:24,276 - INFO - Fitted scaler and transformed data
2024-12-29 12:57:24,276 - INFO - Scaling time: 0.17s
2024-12-29 12:57:24,284 - INFO - Training completed in 0.18s
2024-12-29 12:57:24,284 - INFO - Final memory usage: CPU 2761.9 MB, GPU 122.6 MB
2024-12-29 12:57:24,285 - INFO - Model training completed in 0.18s
2024-12-29 12:57:24,379 - INFO - Prediction completed in 0.09s
2024-12-29 12:57:24,387 - INFO - Poison rate 0.1 completed in 3.67s
2024-12-29 12:57:24,387 - INFO - 
Processing poison rate: 0.2
2024-12-29 12:57:24,409 - INFO - Total number of labels flipped: 1893
2024-12-29 12:57:24,409 - INFO - Label flipping completed in 0.02s
2024-12-29 12:57:24,409 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:57:24,410 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:57:24,980 - INFO - Feature scaling completed in 0.57s
2024-12-29 12:57:24,980 - INFO - Starting feature selection (k=50)
2024-12-29 12:57:24,990 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 12:57:24,991 - INFO - Starting anomaly detection
2024-12-29 12:57:28,497 - INFO - Anomaly detection completed in 3.51s
2024-12-29 12:57:28,497 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:57:28,497 - INFO - Total fit_transform time: 4.09s
2024-12-29 12:57:28,497 - INFO - Training set processing completed in 4.09s
2024-12-29 12:57:28,497 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 12:57:28,498 - INFO - Memory usage at start_fit: CPU 2761.9 MB, GPU 122.6 MB
2024-12-29 12:57:28,498 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:57:28,676 - INFO - Fitted scaler and transformed data
2024-12-29 12:57:28,677 - INFO - Scaling time: 0.18s
2024-12-29 12:57:28,683 - INFO - Training completed in 0.19s
2024-12-29 12:57:28,684 - INFO - Final memory usage: CPU 2761.9 MB, GPU 122.6 MB
2024-12-29 12:57:28,684 - INFO - Model training completed in 0.19s
2024-12-29 12:57:28,800 - INFO - Prediction completed in 0.12s
2024-12-29 12:57:28,818 - INFO - Poison rate 0.2 completed in 4.43s
2024-12-29 12:57:28,820 - INFO - Loaded 49 existing results
2024-12-29 12:57:28,820 - INFO - Total results to save: 56
2024-12-29 12:57:28,821 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 12:57:28,824 - INFO - Saved 56 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 12:57:28,824 - INFO - Total evaluation time: 60.83s
2024-12-29 12:57:28,826 - INFO - Completed evaluation for GTSRB
2024-12-29 12:57:28,826 - INFO - 
Processing dataset: GTSRB
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 12:57:29,021 - INFO - 
Progress: 9.4% - Evaluating GTSRB with SVM (standard mode, iteration 1/1)
2024-12-29 12:57:29,213 - INFO - Loading datasets...
2024-12-29 12:57:29,234 - INFO - Dataset loading completed in 0.02s
2024-12-29 12:57:29,234 - INFO - Extracting validation features...
2024-12-29 12:57:29,234 - INFO - Extracting features from 3925 samples...
2024-12-29 12:57:38,400 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 12:57:38,406 - INFO - Validation feature extraction completed in 9.17s
2024-12-29 12:57:38,406 - INFO - Extracting training features...
2024-12-29 12:57:38,406 - INFO - Extracting features from 9469 samples...
2024-12-29 12:57:59,834 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 12:57:59,838 - INFO - Training feature extraction completed in 21.43s
2024-12-29 12:57:59,838 - INFO - Creating model for classifier: SVM
2024-12-29 12:57:59,838 - INFO - Using device: cuda
2024-12-29 12:57:59,838 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-29 12:57:59,838 - INFO - 
Processing poison rate: 0.0
2024-12-29 12:57:59,838 - INFO - Training set processing completed in 0.00s
2024-12-29 12:57:59,838 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 12:57:59,839 - INFO - Memory usage at start_fit: CPU 2761.9 MB, GPU 104.0 MB
2024-12-29 12:57:59,840 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:57:59,851 - INFO - Number of unique classes: 10
2024-12-29 12:57:59,916 - INFO - Fitted scaler and transformed data
2024-12-29 12:57:59,917 - INFO - Scaling time: 0.06s
2024-12-29 12:58:00,258 - INFO - Epoch 1/500, Train Loss: 1.0051, Val Loss: 0.1526
2024-12-29 12:58:00,584 - INFO - Epoch 2/500, Train Loss: 0.0988, Val Loss: 0.1244
2024-12-29 12:58:00,939 - INFO - Epoch 3/500, Train Loss: 0.0665, Val Loss: 0.1131
2024-12-29 12:58:01,283 - INFO - Epoch 4/500, Train Loss: 0.0486, Val Loss: 0.1104
2024-12-29 12:58:01,642 - INFO - Epoch 5/500, Train Loss: 0.0369, Val Loss: 0.1041
2024-12-29 12:58:01,955 - INFO - Epoch 6/500, Train Loss: 0.0294, Val Loss: 0.1024
2024-12-29 12:58:02,267 - INFO - Epoch 7/500, Train Loss: 0.0240, Val Loss: 0.0978
2024-12-29 12:58:02,578 - INFO - Epoch 8/500, Train Loss: 0.0199, Val Loss: 0.0958
2024-12-29 12:58:02,884 - INFO - Epoch 9/500, Train Loss: 0.0166, Val Loss: 0.0950
2024-12-29 12:58:03,196 - INFO - Epoch 10/500, Train Loss: 0.0143, Val Loss: 0.0918
2024-12-29 12:58:03,604 - INFO - Epoch 11/500, Train Loss: 0.0122, Val Loss: 0.0908
2024-12-29 12:58:03,951 - INFO - Epoch 12/500, Train Loss: 0.0108, Val Loss: 0.0888
2024-12-29 12:58:04,383 - INFO - Epoch 13/500, Train Loss: 0.0097, Val Loss: 0.0875
2024-12-29 12:58:04,744 - INFO - Epoch 14/500, Train Loss: 0.0084, Val Loss: 0.0893
2024-12-29 12:58:05,121 - INFO - Epoch 15/500, Train Loss: 0.0073, Val Loss: 0.0891
2024-12-29 12:58:05,473 - INFO - Epoch 16/500, Train Loss: 0.0067, Val Loss: 0.0865
2024-12-29 12:58:05,848 - INFO - Epoch 17/500, Train Loss: 0.0062, Val Loss: 0.0868
2024-12-29 12:58:06,198 - INFO - Epoch 18/500, Train Loss: 0.0056, Val Loss: 0.0894
2024-12-29 12:58:06,584 - INFO - Epoch 19/500, Train Loss: 0.0055, Val Loss: 0.0872
2024-12-29 12:58:06,910 - INFO - Epoch 20/500, Train Loss: 0.0050, Val Loss: 0.0900
2024-12-29 12:58:07,245 - INFO - Epoch 21/500, Train Loss: 0.0044, Val Loss: 0.0898
2024-12-29 12:58:07,246 - INFO - Early stopping triggered at epoch 21
2024-12-29 12:58:07,246 - INFO - Training completed in 7.41s
2024-12-29 12:58:07,247 - INFO - Final memory usage: CPU 2717.1 MB, GPU 104.2 MB
2024-12-29 12:58:07,249 - INFO - Model training completed in 7.41s
2024-12-29 12:58:07,299 - INFO - Prediction completed in 0.05s
2024-12-29 12:58:07,309 - INFO - Poison rate 0.0 completed in 7.47s
2024-12-29 12:58:07,309 - INFO - 
Processing poison rate: 0.01
2024-12-29 12:58:07,310 - INFO - Total number of labels flipped: 88
2024-12-29 12:58:07,310 - INFO - Label flipping completed in 0.00s
2024-12-29 12:58:07,310 - INFO - Training set processing completed in 0.00s
2024-12-29 12:58:07,310 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 12:58:07,311 - INFO - Memory usage at start_fit: CPU 2687.9 MB, GPU 104.1 MB
2024-12-29 12:58:07,311 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:58:07,315 - INFO - Number of unique classes: 10
2024-12-29 12:58:07,383 - INFO - Fitted scaler and transformed data
2024-12-29 12:58:07,383 - INFO - Scaling time: 0.07s
2024-12-29 12:58:07,731 - INFO - Epoch 1/500, Train Loss: 0.9083, Val Loss: 0.3411
2024-12-29 12:58:08,082 - INFO - Epoch 2/500, Train Loss: 0.1920, Val Loss: 0.3191
2024-12-29 12:58:08,428 - INFO - Epoch 3/500, Train Loss: 0.1493, Val Loss: 0.3036
2024-12-29 12:58:08,767 - INFO - Epoch 4/500, Train Loss: 0.1215, Val Loss: 0.2912
2024-12-29 12:58:09,139 - INFO - Epoch 5/500, Train Loss: 0.0997, Val Loss: 0.2758
2024-12-29 12:58:09,505 - INFO - Epoch 6/500, Train Loss: 0.0873, Val Loss: 0.2753
2024-12-29 12:58:09,875 - INFO - Epoch 7/500, Train Loss: 0.0750, Val Loss: 0.2638
2024-12-29 12:58:10,206 - INFO - Epoch 8/500, Train Loss: 0.0672, Val Loss: 0.2660
2024-12-29 12:58:10,551 - INFO - Epoch 9/500, Train Loss: 0.0605, Val Loss: 0.2597
2024-12-29 12:58:10,894 - INFO - Epoch 10/500, Train Loss: 0.0554, Val Loss: 0.2463
2024-12-29 12:58:11,261 - INFO - Epoch 11/500, Train Loss: 0.0517, Val Loss: 0.2482
2024-12-29 12:58:11,608 - INFO - Epoch 12/500, Train Loss: 0.0484, Val Loss: 0.2534
2024-12-29 12:58:11,957 - INFO - Epoch 13/500, Train Loss: 0.0454, Val Loss: 0.2457
2024-12-29 12:58:12,306 - INFO - Epoch 14/500, Train Loss: 0.0428, Val Loss: 0.2430
2024-12-29 12:58:12,637 - INFO - Epoch 15/500, Train Loss: 0.0409, Val Loss: 0.2398
2024-12-29 12:58:13,020 - INFO - Epoch 16/500, Train Loss: 0.0395, Val Loss: 0.2393
2024-12-29 12:58:13,368 - INFO - Epoch 17/500, Train Loss: 0.0376, Val Loss: 0.2421
2024-12-29 12:58:13,697 - INFO - Epoch 18/500, Train Loss: 0.0362, Val Loss: 0.2321
2024-12-29 12:58:14,031 - INFO - Epoch 19/500, Train Loss: 0.0345, Val Loss: 0.2326
2024-12-29 12:58:14,444 - INFO - Epoch 20/500, Train Loss: 0.0341, Val Loss: 0.2320
2024-12-29 12:58:14,827 - INFO - Epoch 21/500, Train Loss: 0.0332, Val Loss: 0.2258
2024-12-29 12:58:15,232 - INFO - Epoch 22/500, Train Loss: 0.0324, Val Loss: 0.2291
2024-12-29 12:58:15,572 - INFO - Epoch 23/500, Train Loss: 0.0324, Val Loss: 0.2208
2024-12-29 12:58:15,895 - INFO - Epoch 24/500, Train Loss: 0.0316, Val Loss: 0.2361
2024-12-29 12:58:16,259 - INFO - Epoch 25/500, Train Loss: 0.0302, Val Loss: 0.2245
2024-12-29 12:58:16,616 - INFO - Epoch 26/500, Train Loss: 0.0301, Val Loss: 0.2329
2024-12-29 12:58:17,011 - INFO - Epoch 27/500, Train Loss: 0.0289, Val Loss: 0.2242
2024-12-29 12:58:17,419 - INFO - Epoch 28/500, Train Loss: 0.0283, Val Loss: 0.2200
2024-12-29 12:58:17,420 - INFO - Early stopping triggered at epoch 28
2024-12-29 12:58:17,420 - INFO - Training completed in 10.11s
2024-12-29 12:58:17,421 - INFO - Final memory usage: CPU 2717.1 MB, GPU 104.2 MB
2024-12-29 12:58:17,422 - INFO - Model training completed in 10.11s
2024-12-29 12:58:17,488 - INFO - Prediction completed in 0.07s
2024-12-29 12:58:17,503 - INFO - Poison rate 0.01 completed in 10.19s
2024-12-29 12:58:17,504 - INFO - 
Processing poison rate: 0.03
2024-12-29 12:58:17,504 - INFO - Total number of labels flipped: 252
2024-12-29 12:58:17,505 - INFO - Label flipping completed in 0.00s
2024-12-29 12:58:17,505 - INFO - Training set processing completed in 0.00s
2024-12-29 12:58:17,505 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 12:58:17,505 - INFO - Memory usage at start_fit: CPU 2687.5 MB, GPU 104.1 MB
2024-12-29 12:58:17,506 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:58:17,511 - INFO - Number of unique classes: 10
2024-12-29 12:58:17,594 - INFO - Fitted scaler and transformed data
2024-12-29 12:58:17,595 - INFO - Scaling time: 0.08s
2024-12-29 12:58:17,960 - INFO - Epoch 1/500, Train Loss: 1.1633, Val Loss: 0.5986
2024-12-29 12:58:18,312 - INFO - Epoch 2/500, Train Loss: 0.3922, Val Loss: 0.5495
2024-12-29 12:58:18,753 - INFO - Epoch 3/500, Train Loss: 0.3198, Val Loss: 0.5205
2024-12-29 12:58:19,086 - INFO - Epoch 4/500, Train Loss: 0.2714, Val Loss: 0.5089
2024-12-29 12:58:19,481 - INFO - Epoch 5/500, Train Loss: 0.2349, Val Loss: 0.4848
2024-12-29 12:58:19,817 - INFO - Epoch 6/500, Train Loss: 0.2086, Val Loss: 0.4706
2024-12-29 12:58:20,215 - INFO - Epoch 7/500, Train Loss: 0.1883, Val Loss: 0.4432
2024-12-29 12:58:20,546 - INFO - Epoch 8/500, Train Loss: 0.1714, Val Loss: 0.4163
2024-12-29 12:58:20,876 - INFO - Epoch 9/500, Train Loss: 0.1619, Val Loss: 0.4133
2024-12-29 12:58:21,223 - INFO - Epoch 10/500, Train Loss: 0.1490, Val Loss: 0.3809
2024-12-29 12:58:21,546 - INFO - Epoch 11/500, Train Loss: 0.1376, Val Loss: 0.3789
2024-12-29 12:58:21,942 - INFO - Epoch 12/500, Train Loss: 0.1304, Val Loss: 0.3712
2024-12-29 12:58:22,312 - INFO - Epoch 13/500, Train Loss: 0.1236, Val Loss: 0.3615
2024-12-29 12:58:22,651 - INFO - Epoch 14/500, Train Loss: 0.1179, Val Loss: 0.3621
2024-12-29 12:58:23,013 - INFO - Epoch 15/500, Train Loss: 0.1144, Val Loss: 0.3548
2024-12-29 12:58:23,368 - INFO - Epoch 16/500, Train Loss: 0.1099, Val Loss: 0.3496
2024-12-29 12:58:23,703 - INFO - Epoch 17/500, Train Loss: 0.1065, Val Loss: 0.3508
2024-12-29 12:58:24,045 - INFO - Epoch 18/500, Train Loss: 0.1041, Val Loss: 0.3495
2024-12-29 12:58:24,424 - INFO - Epoch 19/500, Train Loss: 0.1024, Val Loss: 0.3515
2024-12-29 12:58:24,777 - INFO - Epoch 20/500, Train Loss: 0.0986, Val Loss: 0.3537
2024-12-29 12:58:25,095 - INFO - Epoch 21/500, Train Loss: 0.0970, Val Loss: 0.3460
2024-12-29 12:58:25,427 - INFO - Epoch 22/500, Train Loss: 0.0954, Val Loss: 0.3450
2024-12-29 12:58:25,779 - INFO - Epoch 23/500, Train Loss: 0.0935, Val Loss: 0.3533
2024-12-29 12:58:26,132 - INFO - Epoch 24/500, Train Loss: 0.0922, Val Loss: 0.3471
2024-12-29 12:58:26,499 - INFO - Epoch 25/500, Train Loss: 0.0920, Val Loss: 0.3472
2024-12-29 12:58:26,850 - INFO - Epoch 26/500, Train Loss: 0.0902, Val Loss: 0.3352
2024-12-29 12:58:27,221 - INFO - Epoch 27/500, Train Loss: 0.0885, Val Loss: 0.3352
2024-12-29 12:58:27,568 - INFO - Epoch 28/500, Train Loss: 0.0888, Val Loss: 0.3408
2024-12-29 12:58:27,920 - INFO - Epoch 29/500, Train Loss: 0.0883, Val Loss: 0.3241
2024-12-29 12:58:28,258 - INFO - Epoch 30/500, Train Loss: 0.0860, Val Loss: 0.3330
2024-12-29 12:58:28,666 - INFO - Epoch 31/500, Train Loss: 0.0866, Val Loss: 0.3424
2024-12-29 12:58:29,043 - INFO - Epoch 32/500, Train Loss: 0.0864, Val Loss: 0.3275
2024-12-29 12:58:29,366 - INFO - Epoch 33/500, Train Loss: 0.0854, Val Loss: 0.3370
2024-12-29 12:58:29,709 - INFO - Epoch 34/500, Train Loss: 0.0817, Val Loss: 0.3314
2024-12-29 12:58:29,709 - INFO - Early stopping triggered at epoch 34
2024-12-29 12:58:29,709 - INFO - Training completed in 12.20s
2024-12-29 12:58:29,710 - INFO - Final memory usage: CPU 2717.1 MB, GPU 104.2 MB
2024-12-29 12:58:29,711 - INFO - Model training completed in 12.21s
2024-12-29 12:58:29,756 - INFO - Prediction completed in 0.04s
2024-12-29 12:58:29,764 - INFO - Poison rate 0.03 completed in 12.26s
2024-12-29 12:58:29,764 - INFO - 
Processing poison rate: 0.05
2024-12-29 12:58:29,765 - INFO - Total number of labels flipped: 422
2024-12-29 12:58:29,765 - INFO - Label flipping completed in 0.00s
2024-12-29 12:58:29,766 - INFO - Training set processing completed in 0.00s
2024-12-29 12:58:29,766 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 12:58:29,766 - INFO - Memory usage at start_fit: CPU 2687.5 MB, GPU 104.1 MB
2024-12-29 12:58:29,766 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:58:29,772 - INFO - Number of unique classes: 10
2024-12-29 12:58:29,840 - INFO - Fitted scaler and transformed data
2024-12-29 12:58:29,840 - INFO - Scaling time: 0.07s
2024-12-29 12:58:30,206 - INFO - Epoch 1/500, Train Loss: 1.3071, Val Loss: 0.7041
2024-12-29 12:58:30,566 - INFO - Epoch 2/500, Train Loss: 0.5601, Val Loss: 0.6439
2024-12-29 12:58:30,947 - INFO - Epoch 3/500, Train Loss: 0.4629, Val Loss: 0.6133
2024-12-29 12:58:31,280 - INFO - Epoch 4/500, Train Loss: 0.3956, Val Loss: 0.5772
2024-12-29 12:58:31,621 - INFO - Epoch 5/500, Train Loss: 0.3467, Val Loss: 0.5452
2024-12-29 12:58:32,012 - INFO - Epoch 6/500, Train Loss: 0.3075, Val Loss: 0.5374
2024-12-29 12:58:32,352 - INFO - Epoch 7/500, Train Loss: 0.2784, Val Loss: 0.4977
2024-12-29 12:58:32,689 - INFO - Epoch 8/500, Train Loss: 0.2507, Val Loss: 0.4823
2024-12-29 12:58:33,091 - INFO - Epoch 9/500, Train Loss: 0.2333, Val Loss: 0.4600
2024-12-29 12:58:33,432 - INFO - Epoch 10/500, Train Loss: 0.2174, Val Loss: 0.4430
2024-12-29 12:58:33,789 - INFO - Epoch 11/500, Train Loss: 0.2027, Val Loss: 0.4308
2024-12-29 12:58:34,133 - INFO - Epoch 12/500, Train Loss: 0.1933, Val Loss: 0.4168
2024-12-29 12:58:34,471 - INFO - Epoch 13/500, Train Loss: 0.1854, Val Loss: 0.4125
2024-12-29 12:58:34,830 - INFO - Epoch 14/500, Train Loss: 0.1792, Val Loss: 0.3945
2024-12-29 12:58:35,260 - INFO - Epoch 15/500, Train Loss: 0.1708, Val Loss: 0.3907
2024-12-29 12:58:35,617 - INFO - Epoch 16/500, Train Loss: 0.1679, Val Loss: 0.3783
2024-12-29 12:58:36,002 - INFO - Epoch 17/500, Train Loss: 0.1618, Val Loss: 0.3714
2024-12-29 12:58:36,318 - INFO - Epoch 18/500, Train Loss: 0.1588, Val Loss: 0.3737
2024-12-29 12:58:36,656 - INFO - Epoch 19/500, Train Loss: 0.1541, Val Loss: 0.3703
2024-12-29 12:58:36,979 - INFO - Epoch 20/500, Train Loss: 0.1514, Val Loss: 0.3703
2024-12-29 12:58:37,309 - INFO - Epoch 21/500, Train Loss: 0.1480, Val Loss: 0.3681
2024-12-29 12:58:37,645 - INFO - Epoch 22/500, Train Loss: 0.1471, Val Loss: 0.3745
2024-12-29 12:58:37,989 - INFO - Epoch 23/500, Train Loss: 0.1429, Val Loss: 0.3632
2024-12-29 12:58:38,350 - INFO - Epoch 24/500, Train Loss: 0.1408, Val Loss: 0.3608
2024-12-29 12:58:38,711 - INFO - Epoch 25/500, Train Loss: 0.1410, Val Loss: 0.3581
2024-12-29 12:58:39,040 - INFO - Epoch 26/500, Train Loss: 0.1383, Val Loss: 0.3608
2024-12-29 12:58:39,398 - INFO - Epoch 27/500, Train Loss: 0.1376, Val Loss: 0.3616
2024-12-29 12:58:39,728 - INFO - Epoch 28/500, Train Loss: 0.1348, Val Loss: 0.3578
2024-12-29 12:58:40,080 - INFO - Epoch 29/500, Train Loss: 0.1344, Val Loss: 0.3548
2024-12-29 12:58:40,428 - INFO - Epoch 30/500, Train Loss: 0.1331, Val Loss: 0.3614
2024-12-29 12:58:40,760 - INFO - Epoch 31/500, Train Loss: 0.1321, Val Loss: 0.3537
2024-12-29 12:58:41,133 - INFO - Epoch 32/500, Train Loss: 0.1334, Val Loss: 0.3622
2024-12-29 12:58:41,471 - INFO - Epoch 33/500, Train Loss: 0.1314, Val Loss: 0.3699
2024-12-29 12:58:41,859 - INFO - Epoch 34/500, Train Loss: 0.1280, Val Loss: 0.3568
2024-12-29 12:58:42,210 - INFO - Epoch 35/500, Train Loss: 0.1300, Val Loss: 0.3701
2024-12-29 12:58:42,572 - INFO - Epoch 36/500, Train Loss: 0.1293, Val Loss: 0.3681
2024-12-29 12:58:42,572 - INFO - Early stopping triggered at epoch 36
2024-12-29 12:58:42,572 - INFO - Training completed in 12.81s
2024-12-29 12:58:42,572 - INFO - Final memory usage: CPU 2717.2 MB, GPU 104.2 MB
2024-12-29 12:58:42,573 - INFO - Model training completed in 12.81s
2024-12-29 12:58:42,619 - INFO - Prediction completed in 0.05s
2024-12-29 12:58:42,628 - INFO - Poison rate 0.05 completed in 12.86s
2024-12-29 12:58:42,628 - INFO - 
Processing poison rate: 0.07
2024-12-29 12:58:42,629 - INFO - Total number of labels flipped: 602
2024-12-29 12:58:42,629 - INFO - Label flipping completed in 0.00s
2024-12-29 12:58:42,629 - INFO - Training set processing completed in 0.00s
2024-12-29 12:58:42,629 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 12:58:42,630 - INFO - Memory usage at start_fit: CPU 2687.7 MB, GPU 104.1 MB
2024-12-29 12:58:42,630 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:58:42,634 - INFO - Number of unique classes: 10
2024-12-29 12:58:42,703 - INFO - Fitted scaler and transformed data
2024-12-29 12:58:42,703 - INFO - Scaling time: 0.07s
2024-12-29 12:58:43,061 - INFO - Epoch 1/500, Train Loss: 1.5509, Val Loss: 0.9432
2024-12-29 12:58:43,423 - INFO - Epoch 2/500, Train Loss: 0.7375, Val Loss: 0.8345
2024-12-29 12:58:43,769 - INFO - Epoch 3/500, Train Loss: 0.6068, Val Loss: 0.7677
2024-12-29 12:58:44,105 - INFO - Epoch 4/500, Train Loss: 0.5214, Val Loss: 0.7300
2024-12-29 12:58:44,455 - INFO - Epoch 5/500, Train Loss: 0.4530, Val Loss: 0.6712
2024-12-29 12:58:44,798 - INFO - Epoch 6/500, Train Loss: 0.3963, Val Loss: 0.6282
2024-12-29 12:58:45,125 - INFO - Epoch 7/500, Train Loss: 0.3563, Val Loss: 0.6068
2024-12-29 12:58:45,529 - INFO - Epoch 8/500, Train Loss: 0.3276, Val Loss: 0.5530
2024-12-29 12:58:45,898 - INFO - Epoch 9/500, Train Loss: 0.3023, Val Loss: 0.5470
2024-12-29 12:58:46,250 - INFO - Epoch 10/500, Train Loss: 0.2837, Val Loss: 0.5363
2024-12-29 12:58:46,657 - INFO - Epoch 11/500, Train Loss: 0.2709, Val Loss: 0.5109
2024-12-29 12:58:46,987 - INFO - Epoch 12/500, Train Loss: 0.2584, Val Loss: 0.5041
2024-12-29 12:58:47,335 - INFO - Epoch 13/500, Train Loss: 0.2487, Val Loss: 0.5042
2024-12-29 12:58:47,705 - INFO - Epoch 14/500, Train Loss: 0.2381, Val Loss: 0.4841
2024-12-29 12:58:48,059 - INFO - Epoch 15/500, Train Loss: 0.2322, Val Loss: 0.4769
2024-12-29 12:58:48,416 - INFO - Epoch 16/500, Train Loss: 0.2290, Val Loss: 0.4683
2024-12-29 12:58:48,795 - INFO - Epoch 17/500, Train Loss: 0.2225, Val Loss: 0.4619
2024-12-29 12:58:49,143 - INFO - Epoch 18/500, Train Loss: 0.2189, Val Loss: 0.4627
2024-12-29 12:58:49,499 - INFO - Epoch 19/500, Train Loss: 0.2158, Val Loss: 0.4583
2024-12-29 12:58:49,812 - INFO - Epoch 20/500, Train Loss: 0.2130, Val Loss: 0.4567
2024-12-29 12:58:50,146 - INFO - Epoch 21/500, Train Loss: 0.2085, Val Loss: 0.4563
2024-12-29 12:58:50,586 - INFO - Epoch 22/500, Train Loss: 0.2051, Val Loss: 0.4416
2024-12-29 12:58:50,927 - INFO - Epoch 23/500, Train Loss: 0.2026, Val Loss: 0.4580
2024-12-29 12:58:51,305 - INFO - Epoch 24/500, Train Loss: 0.2021, Val Loss: 0.4420
2024-12-29 12:58:51,678 - INFO - Epoch 25/500, Train Loss: 0.1999, Val Loss: 0.4553
2024-12-29 12:58:52,043 - INFO - Epoch 26/500, Train Loss: 0.1997, Val Loss: 0.4546
2024-12-29 12:58:52,396 - INFO - Epoch 27/500, Train Loss: 0.1968, Val Loss: 0.4494
2024-12-29 12:58:52,396 - INFO - Early stopping triggered at epoch 27
2024-12-29 12:58:52,396 - INFO - Training completed in 9.77s
2024-12-29 12:58:52,396 - INFO - Final memory usage: CPU 2717.2 MB, GPU 104.2 MB
2024-12-29 12:58:52,398 - INFO - Model training completed in 9.77s
2024-12-29 12:58:52,455 - INFO - Prediction completed in 0.06s
2024-12-29 12:58:52,463 - INFO - Poison rate 0.07 completed in 9.84s
2024-12-29 12:58:52,464 - INFO - 
Processing poison rate: 0.1
2024-12-29 12:58:52,465 - INFO - Total number of labels flipped: 843
2024-12-29 12:58:52,465 - INFO - Label flipping completed in 0.00s
2024-12-29 12:58:52,465 - INFO - Training set processing completed in 0.00s
2024-12-29 12:58:52,465 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 12:58:52,466 - INFO - Memory usage at start_fit: CPU 2687.6 MB, GPU 104.1 MB
2024-12-29 12:58:52,467 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:58:52,471 - INFO - Number of unique classes: 10
2024-12-29 12:58:52,548 - INFO - Fitted scaler and transformed data
2024-12-29 12:58:52,548 - INFO - Scaling time: 0.08s
2024-12-29 12:58:52,923 - INFO - Epoch 1/500, Train Loss: 1.7660, Val Loss: 1.2130
2024-12-29 12:58:53,259 - INFO - Epoch 2/500, Train Loss: 0.9480, Val Loss: 1.0609
2024-12-29 12:58:53,619 - INFO - Epoch 3/500, Train Loss: 0.7902, Val Loss: 0.9445
2024-12-29 12:58:54,009 - INFO - Epoch 4/500, Train Loss: 0.6702, Val Loss: 0.8675
2024-12-29 12:58:54,396 - INFO - Epoch 5/500, Train Loss: 0.5787, Val Loss: 0.7832
2024-12-29 12:58:54,761 - INFO - Epoch 6/500, Train Loss: 0.5060, Val Loss: 0.7242
2024-12-29 12:58:55,102 - INFO - Epoch 7/500, Train Loss: 0.4532, Val Loss: 0.6643
2024-12-29 12:58:55,459 - INFO - Epoch 8/500, Train Loss: 0.4130, Val Loss: 0.6555
2024-12-29 12:58:55,867 - INFO - Epoch 9/500, Train Loss: 0.3847, Val Loss: 0.6036
2024-12-29 12:58:56,242 - INFO - Epoch 10/500, Train Loss: 0.3607, Val Loss: 0.5581
2024-12-29 12:58:56,602 - INFO - Epoch 11/500, Train Loss: 0.3431, Val Loss: 0.5509
2024-12-29 12:58:56,939 - INFO - Epoch 12/500, Train Loss: 0.3318, Val Loss: 0.5377
2024-12-29 12:58:57,293 - INFO - Epoch 13/500, Train Loss: 0.3194, Val Loss: 0.5233
2024-12-29 12:58:57,665 - INFO - Epoch 14/500, Train Loss: 0.3117, Val Loss: 0.5284
2024-12-29 12:58:57,989 - INFO - Epoch 15/500, Train Loss: 0.3014, Val Loss: 0.5295
2024-12-29 12:58:58,358 - INFO - Epoch 16/500, Train Loss: 0.2963, Val Loss: 0.5065
2024-12-29 12:58:58,721 - INFO - Epoch 17/500, Train Loss: 0.2918, Val Loss: 0.5104
2024-12-29 12:58:59,119 - INFO - Epoch 18/500, Train Loss: 0.2870, Val Loss: 0.4943
2024-12-29 12:58:59,502 - INFO - Epoch 19/500, Train Loss: 0.2809, Val Loss: 0.5084
2024-12-29 12:58:59,858 - INFO - Epoch 20/500, Train Loss: 0.2784, Val Loss: 0.4987
2024-12-29 12:59:00,214 - INFO - Epoch 21/500, Train Loss: 0.2751, Val Loss: 0.5124
2024-12-29 12:59:00,559 - INFO - Epoch 22/500, Train Loss: 0.2712, Val Loss: 0.4938
2024-12-29 12:59:00,944 - INFO - Epoch 23/500, Train Loss: 0.2691, Val Loss: 0.4966
2024-12-29 12:59:00,944 - INFO - Early stopping triggered at epoch 23
2024-12-29 12:59:00,944 - INFO - Training completed in 8.48s
2024-12-29 12:59:00,944 - INFO - Final memory usage: CPU 2717.1 MB, GPU 104.2 MB
2024-12-29 12:59:00,945 - INFO - Model training completed in 8.48s
2024-12-29 12:59:00,990 - INFO - Prediction completed in 0.04s
2024-12-29 12:59:00,998 - INFO - Poison rate 0.1 completed in 8.53s
2024-12-29 12:59:00,998 - INFO - 
Processing poison rate: 0.2
2024-12-29 12:59:01,000 - INFO - Total number of labels flipped: 1684
2024-12-29 12:59:01,000 - INFO - Label flipping completed in 0.00s
2024-12-29 12:59:01,000 - INFO - Training set processing completed in 0.00s
2024-12-29 12:59:01,000 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 12:59:01,001 - INFO - Memory usage at start_fit: CPU 2687.5 MB, GPU 104.1 MB
2024-12-29 12:59:01,001 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:59:01,005 - INFO - Number of unique classes: 10
2024-12-29 12:59:01,073 - INFO - Fitted scaler and transformed data
2024-12-29 12:59:01,073 - INFO - Scaling time: 0.07s
2024-12-29 12:59:01,415 - INFO - Epoch 1/500, Train Loss: 2.6566, Val Loss: 1.9368
2024-12-29 12:59:01,787 - INFO - Epoch 2/500, Train Loss: 1.7237, Val Loss: 1.6908
2024-12-29 12:59:02,142 - INFO - Epoch 3/500, Train Loss: 1.4563, Val Loss: 1.5081
2024-12-29 12:59:02,486 - INFO - Epoch 4/500, Train Loss: 1.2347, Val Loss: 1.3207
2024-12-29 12:59:02,824 - INFO - Epoch 5/500, Train Loss: 1.0452, Val Loss: 1.1568
2024-12-29 12:59:03,194 - INFO - Epoch 6/500, Train Loss: 0.8981, Val Loss: 1.0209
2024-12-29 12:59:03,528 - INFO - Epoch 7/500, Train Loss: 0.7804, Val Loss: 0.9107
2024-12-29 12:59:03,854 - INFO - Epoch 8/500, Train Loss: 0.7087, Val Loss: 0.8306
2024-12-29 12:59:04,244 - INFO - Epoch 9/500, Train Loss: 0.6555, Val Loss: 0.7868
2024-12-29 12:59:04,606 - INFO - Epoch 10/500, Train Loss: 0.6167, Val Loss: 0.7397
2024-12-29 12:59:04,951 - INFO - Epoch 11/500, Train Loss: 0.5894, Val Loss: 0.7189
2024-12-29 12:59:05,309 - INFO - Epoch 12/500, Train Loss: 0.5670, Val Loss: 0.6981
2024-12-29 12:59:05,675 - INFO - Epoch 13/500, Train Loss: 0.5528, Val Loss: 0.6761
2024-12-29 12:59:06,048 - INFO - Epoch 14/500, Train Loss: 0.5393, Val Loss: 0.6784
2024-12-29 12:59:06,400 - INFO - Epoch 15/500, Train Loss: 0.5289, Val Loss: 0.6726
2024-12-29 12:59:06,737 - INFO - Epoch 16/500, Train Loss: 0.5219, Val Loss: 0.6625
2024-12-29 12:59:07,097 - INFO - Epoch 17/500, Train Loss: 0.5147, Val Loss: 0.6592
2024-12-29 12:59:07,433 - INFO - Epoch 18/500, Train Loss: 0.5075, Val Loss: 0.6618
2024-12-29 12:59:07,828 - INFO - Epoch 19/500, Train Loss: 0.5000, Val Loss: 0.6594
2024-12-29 12:59:08,203 - INFO - Epoch 20/500, Train Loss: 0.4924, Val Loss: 0.6618
2024-12-29 12:59:08,580 - INFO - Epoch 21/500, Train Loss: 0.4892, Val Loss: 0.6600
2024-12-29 12:59:08,949 - INFO - Epoch 22/500, Train Loss: 0.4871, Val Loss: 0.6633
2024-12-29 12:59:08,949 - INFO - Early stopping triggered at epoch 22
2024-12-29 12:59:08,949 - INFO - Training completed in 7.95s
2024-12-29 12:59:08,949 - INFO - Final memory usage: CPU 2717.1 MB, GPU 104.2 MB
2024-12-29 12:59:08,951 - INFO - Model training completed in 7.95s
2024-12-29 12:59:08,996 - INFO - Prediction completed in 0.05s
2024-12-29 12:59:09,005 - INFO - Poison rate 0.2 completed in 8.01s
2024-12-29 12:59:09,007 - INFO - Loaded 56 existing results
2024-12-29 12:59:09,007 - INFO - Total results to save: 63
2024-12-29 12:59:09,007 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 12:59:09,010 - INFO - Saved 63 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 12:59:09,010 - INFO - Total evaluation time: 99.80s
2024-12-29 12:59:09,011 - INFO - 
Progress: 10.4% - Evaluating GTSRB with SVM (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 12:59:09,216 - INFO - Loading datasets...
2024-12-29 12:59:09,236 - INFO - Dataset loading completed in 0.02s
2024-12-29 12:59:09,236 - INFO - Extracting validation features...
2024-12-29 12:59:09,236 - INFO - Extracting features from 3925 samples...
2024-12-29 12:59:18,318 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 12:59:18,321 - INFO - Validation feature extraction completed in 9.08s
2024-12-29 12:59:18,321 - INFO - Extracting training features...
2024-12-29 12:59:18,321 - INFO - Extracting features from 9469 samples...
2024-12-29 12:59:39,910 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 12:59:39,914 - INFO - Training feature extraction completed in 21.59s
2024-12-29 12:59:39,914 - INFO - Creating model for classifier: SVM
2024-12-29 12:59:39,914 - INFO - Using device: cuda
2024-12-29 12:59:39,914 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-29 12:59:39,914 - INFO - 
Processing poison rate: 0.0
2024-12-29 12:59:39,914 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:59:39,914 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:59:40,443 - INFO - Feature scaling completed in 0.53s
2024-12-29 12:59:40,443 - INFO - Starting feature selection (k=50)
2024-12-29 12:59:40,454 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 12:59:40,454 - INFO - Starting anomaly detection
2024-12-29 12:59:42,785 - INFO - Anomaly detection completed in 2.33s
2024-12-29 12:59:42,785 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:59:42,785 - INFO - Total fit_transform time: 2.87s
2024-12-29 12:59:42,786 - INFO - Training set processing completed in 2.87s
2024-12-29 12:59:42,786 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 12:59:42,787 - INFO - Memory usage at start_fit: CPU 2761.3 MB, GPU 104.9 MB
2024-12-29 12:59:42,788 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:59:42,791 - INFO - Number of unique classes: 10
2024-12-29 12:59:42,863 - INFO - Fitted scaler and transformed data
2024-12-29 12:59:42,864 - INFO - Scaling time: 0.07s
2024-12-29 12:59:43,220 - INFO - Epoch 1/500, Train Loss: 0.7400, Val Loss: 0.1297
2024-12-29 12:59:43,587 - INFO - Epoch 2/500, Train Loss: 0.0877, Val Loss: 0.0969
2024-12-29 12:59:43,929 - INFO - Epoch 3/500, Train Loss: 0.0563, Val Loss: 0.0839
2024-12-29 12:59:44,270 - INFO - Epoch 4/500, Train Loss: 0.0399, Val Loss: 0.0762
2024-12-29 12:59:44,617 - INFO - Epoch 5/500, Train Loss: 0.0303, Val Loss: 0.0728
2024-12-29 12:59:45,010 - INFO - Epoch 6/500, Train Loss: 0.0244, Val Loss: 0.0707
2024-12-29 12:59:45,316 - INFO - Epoch 7/500, Train Loss: 0.0195, Val Loss: 0.0675
2024-12-29 12:59:45,675 - INFO - Epoch 8/500, Train Loss: 0.0164, Val Loss: 0.0647
2024-12-29 12:59:46,033 - INFO - Epoch 9/500, Train Loss: 0.0135, Val Loss: 0.0651
2024-12-29 12:59:46,374 - INFO - Epoch 10/500, Train Loss: 0.0117, Val Loss: 0.0649
2024-12-29 12:59:46,767 - INFO - Epoch 11/500, Train Loss: 0.0099, Val Loss: 0.0644
2024-12-29 12:59:47,120 - INFO - Epoch 12/500, Train Loss: 0.0090, Val Loss: 0.0637
2024-12-29 12:59:47,486 - INFO - Epoch 13/500, Train Loss: 0.0078, Val Loss: 0.0629
2024-12-29 12:59:47,841 - INFO - Epoch 14/500, Train Loss: 0.0071, Val Loss: 0.0642
2024-12-29 12:59:48,213 - INFO - Epoch 15/500, Train Loss: 0.0064, Val Loss: 0.0631
2024-12-29 12:59:48,605 - INFO - Epoch 16/500, Train Loss: 0.0058, Val Loss: 0.0642
2024-12-29 12:59:48,974 - INFO - Epoch 17/500, Train Loss: 0.0053, Val Loss: 0.0643
2024-12-29 12:59:48,974 - INFO - Early stopping triggered at epoch 17
2024-12-29 12:59:48,974 - INFO - Training completed in 6.19s
2024-12-29 12:59:48,975 - INFO - Final memory usage: CPU 2761.3 MB, GPU 105.1 MB
2024-12-29 12:59:48,979 - INFO - Model training completed in 6.19s
2024-12-29 12:59:49,046 - INFO - Prediction completed in 0.07s
2024-12-29 12:59:49,055 - INFO - Poison rate 0.0 completed in 9.14s
2024-12-29 12:59:49,056 - INFO - 
Processing poison rate: 0.01
2024-12-29 12:59:49,056 - INFO - Total number of labels flipped: 84
2024-12-29 12:59:49,057 - INFO - Label flipping completed in 0.00s
2024-12-29 12:59:49,057 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 12:59:49,057 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 12:59:49,622 - INFO - Feature scaling completed in 0.57s
2024-12-29 12:59:49,623 - INFO - Starting feature selection (k=50)
2024-12-29 12:59:49,637 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 12:59:49,638 - INFO - Starting anomaly detection
2024-12-29 12:59:53,860 - INFO - Anomaly detection completed in 4.22s
2024-12-29 12:59:53,860 - INFO - Found 947 outliers (10.0%)
2024-12-29 12:59:53,861 - INFO - Total fit_transform time: 4.80s
2024-12-29 12:59:53,861 - INFO - Training set processing completed in 4.80s
2024-12-29 12:59:53,861 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 12:59:53,862 - INFO - Memory usage at start_fit: CPU 2707.9 MB, GPU 105.0 MB
2024-12-29 12:59:53,862 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 12:59:53,864 - INFO - Number of unique classes: 10
2024-12-29 12:59:53,959 - INFO - Fitted scaler and transformed data
2024-12-29 12:59:53,959 - INFO - Scaling time: 0.09s
2024-12-29 12:59:54,338 - INFO - Epoch 1/500, Train Loss: 0.8206, Val Loss: 0.2309
2024-12-29 12:59:54,652 - INFO - Epoch 2/500, Train Loss: 0.1861, Val Loss: 0.1975
2024-12-29 12:59:54,964 - INFO - Epoch 3/500, Train Loss: 0.1398, Val Loss: 0.1861
2024-12-29 12:59:55,294 - INFO - Epoch 4/500, Train Loss: 0.1119, Val Loss: 0.1749
2024-12-29 12:59:55,663 - INFO - Epoch 5/500, Train Loss: 0.0937, Val Loss: 0.1759
2024-12-29 12:59:56,009 - INFO - Epoch 6/500, Train Loss: 0.0810, Val Loss: 0.1692
2024-12-29 12:59:56,334 - INFO - Epoch 7/500, Train Loss: 0.0716, Val Loss: 0.1702
2024-12-29 12:59:56,677 - INFO - Epoch 8/500, Train Loss: 0.0640, Val Loss: 0.1699
2024-12-29 12:59:57,018 - INFO - Epoch 9/500, Train Loss: 0.0588, Val Loss: 0.1669
2024-12-29 12:59:57,330 - INFO - Epoch 10/500, Train Loss: 0.0536, Val Loss: 0.1660
2024-12-29 12:59:57,677 - INFO - Epoch 11/500, Train Loss: 0.0500, Val Loss: 0.1686
2024-12-29 12:59:58,030 - INFO - Epoch 12/500, Train Loss: 0.0473, Val Loss: 0.1638
2024-12-29 12:59:58,386 - INFO - Epoch 13/500, Train Loss: 0.0447, Val Loss: 0.1689
2024-12-29 12:59:58,708 - INFO - Epoch 14/500, Train Loss: 0.0423, Val Loss: 0.1664
2024-12-29 12:59:59,073 - INFO - Epoch 15/500, Train Loss: 0.0403, Val Loss: 0.1585
2024-12-29 12:59:59,428 - INFO - Epoch 16/500, Train Loss: 0.0386, Val Loss: 0.1584
2024-12-29 12:59:59,822 - INFO - Epoch 17/500, Train Loss: 0.0368, Val Loss: 0.1626
2024-12-29 13:00:00,157 - INFO - Epoch 18/500, Train Loss: 0.0361, Val Loss: 0.1578
2024-12-29 13:00:00,482 - INFO - Epoch 19/500, Train Loss: 0.0342, Val Loss: 0.1548
2024-12-29 13:00:00,846 - INFO - Epoch 20/500, Train Loss: 0.0342, Val Loss: 0.1606
2024-12-29 13:00:01,206 - INFO - Epoch 21/500, Train Loss: 0.0343, Val Loss: 0.1570
2024-12-29 13:00:01,546 - INFO - Epoch 22/500, Train Loss: 0.0327, Val Loss: 0.1603
2024-12-29 13:00:01,910 - INFO - Epoch 23/500, Train Loss: 0.0318, Val Loss: 0.1637
2024-12-29 13:00:02,263 - INFO - Epoch 24/500, Train Loss: 0.0307, Val Loss: 0.1552
2024-12-29 13:00:02,263 - INFO - Early stopping triggered at epoch 24
2024-12-29 13:00:02,263 - INFO - Training completed in 8.40s
2024-12-29 13:00:02,264 - INFO - Final memory usage: CPU 2726.5 MB, GPU 105.1 MB
2024-12-29 13:00:02,265 - INFO - Model training completed in 8.40s
2024-12-29 13:00:02,315 - INFO - Prediction completed in 0.05s
2024-12-29 13:00:02,324 - INFO - Poison rate 0.01 completed in 13.27s
2024-12-29 13:00:02,324 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:00:02,325 - INFO - Total number of labels flipped: 247
2024-12-29 13:00:02,325 - INFO - Label flipping completed in 0.00s
2024-12-29 13:00:02,325 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:00:02,325 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:00:02,919 - INFO - Feature scaling completed in 0.59s
2024-12-29 13:00:02,919 - INFO - Starting feature selection (k=50)
2024-12-29 13:00:02,937 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 13:00:02,937 - INFO - Starting anomaly detection
2024-12-29 13:00:05,295 - INFO - Anomaly detection completed in 2.36s
2024-12-29 13:00:05,295 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:00:05,295 - INFO - Total fit_transform time: 2.97s
2024-12-29 13:00:05,295 - INFO - Training set processing completed in 2.97s
2024-12-29 13:00:05,295 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:00:05,296 - INFO - Memory usage at start_fit: CPU 2707.9 MB, GPU 105.0 MB
2024-12-29 13:00:05,296 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:00:05,298 - INFO - Number of unique classes: 10
2024-12-29 13:00:05,368 - INFO - Fitted scaler and transformed data
2024-12-29 13:00:05,369 - INFO - Scaling time: 0.07s
2024-12-29 13:00:05,690 - INFO - Epoch 1/500, Train Loss: 1.0912, Val Loss: 0.5594
2024-12-29 13:00:06,018 - INFO - Epoch 2/500, Train Loss: 0.3585, Val Loss: 0.5062
2024-12-29 13:00:06,361 - INFO - Epoch 3/500, Train Loss: 0.2921, Val Loss: 0.4643
2024-12-29 13:00:06,681 - INFO - Epoch 4/500, Train Loss: 0.2442, Val Loss: 0.4342
2024-12-29 13:00:06,999 - INFO - Epoch 5/500, Train Loss: 0.2107, Val Loss: 0.4184
2024-12-29 13:00:07,357 - INFO - Epoch 6/500, Train Loss: 0.1860, Val Loss: 0.4112
2024-12-29 13:00:07,690 - INFO - Epoch 7/500, Train Loss: 0.1667, Val Loss: 0.3897
2024-12-29 13:00:08,038 - INFO - Epoch 8/500, Train Loss: 0.1525, Val Loss: 0.3710
2024-12-29 13:00:08,377 - INFO - Epoch 9/500, Train Loss: 0.1414, Val Loss: 0.3826
2024-12-29 13:00:08,715 - INFO - Epoch 10/500, Train Loss: 0.1317, Val Loss: 0.3543
2024-12-29 13:00:09,060 - INFO - Epoch 11/500, Train Loss: 0.1240, Val Loss: 0.3620
2024-12-29 13:00:09,377 - INFO - Epoch 12/500, Train Loss: 0.1160, Val Loss: 0.3465
2024-12-29 13:00:09,700 - INFO - Epoch 13/500, Train Loss: 0.1104, Val Loss: 0.3484
2024-12-29 13:00:10,010 - INFO - Epoch 14/500, Train Loss: 0.1062, Val Loss: 0.3350
2024-12-29 13:00:10,430 - INFO - Epoch 15/500, Train Loss: 0.1025, Val Loss: 0.3222
2024-12-29 13:00:10,785 - INFO - Epoch 16/500, Train Loss: 0.1007, Val Loss: 0.3244
2024-12-29 13:00:11,125 - INFO - Epoch 17/500, Train Loss: 0.0954, Val Loss: 0.3257
2024-12-29 13:00:11,461 - INFO - Epoch 18/500, Train Loss: 0.0938, Val Loss: 0.3187
2024-12-29 13:00:11,787 - INFO - Epoch 19/500, Train Loss: 0.0903, Val Loss: 0.3128
2024-12-29 13:00:12,118 - INFO - Epoch 20/500, Train Loss: 0.0892, Val Loss: 0.3131
2024-12-29 13:00:12,439 - INFO - Epoch 21/500, Train Loss: 0.0877, Val Loss: 0.3100
2024-12-29 13:00:12,752 - INFO - Epoch 22/500, Train Loss: 0.0846, Val Loss: 0.3106
2024-12-29 13:00:13,069 - INFO - Epoch 23/500, Train Loss: 0.0846, Val Loss: 0.3206
2024-12-29 13:00:13,383 - INFO - Epoch 24/500, Train Loss: 0.0864, Val Loss: 0.3096
2024-12-29 13:00:13,693 - INFO - Epoch 25/500, Train Loss: 0.0816, Val Loss: 0.3168
2024-12-29 13:00:14,022 - INFO - Epoch 26/500, Train Loss: 0.0808, Val Loss: 0.3099
2024-12-29 13:00:14,023 - INFO - Early stopping triggered at epoch 26
2024-12-29 13:00:14,023 - INFO - Training completed in 8.73s
2024-12-29 13:00:14,023 - INFO - Final memory usage: CPU 2716.9 MB, GPU 105.1 MB
2024-12-29 13:00:14,024 - INFO - Model training completed in 8.73s
2024-12-29 13:00:14,070 - INFO - Prediction completed in 0.05s
2024-12-29 13:00:14,078 - INFO - Poison rate 0.03 completed in 11.75s
2024-12-29 13:00:14,078 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:00:14,079 - INFO - Total number of labels flipped: 424
2024-12-29 13:00:14,080 - INFO - Label flipping completed in 0.00s
2024-12-29 13:00:14,080 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:00:14,080 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:00:14,584 - INFO - Feature scaling completed in 0.50s
2024-12-29 13:00:14,584 - INFO - Starting feature selection (k=50)
2024-12-29 13:00:14,598 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:00:14,598 - INFO - Starting anomaly detection
2024-12-29 13:00:18,685 - INFO - Anomaly detection completed in 4.09s
2024-12-29 13:00:18,685 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:00:18,685 - INFO - Total fit_transform time: 4.61s
2024-12-29 13:00:18,686 - INFO - Training set processing completed in 4.61s
2024-12-29 13:00:18,686 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:00:18,687 - INFO - Memory usage at start_fit: CPU 2707.6 MB, GPU 105.0 MB
2024-12-29 13:00:18,687 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:00:18,690 - INFO - Number of unique classes: 10
2024-12-29 13:00:18,760 - INFO - Fitted scaler and transformed data
2024-12-29 13:00:18,760 - INFO - Scaling time: 0.07s
2024-12-29 13:00:19,136 - INFO - Epoch 1/500, Train Loss: 1.3098, Val Loss: 0.5681
2024-12-29 13:00:19,488 - INFO - Epoch 2/500, Train Loss: 0.5584, Val Loss: 0.5021
2024-12-29 13:00:19,819 - INFO - Epoch 3/500, Train Loss: 0.4572, Val Loss: 0.4665
2024-12-29 13:00:20,142 - INFO - Epoch 4/500, Train Loss: 0.3848, Val Loss: 0.4287
2024-12-29 13:00:20,486 - INFO - Epoch 5/500, Train Loss: 0.3349, Val Loss: 0.4043
2024-12-29 13:00:20,833 - INFO - Epoch 6/500, Train Loss: 0.2955, Val Loss: 0.3994
2024-12-29 13:00:21,163 - INFO - Epoch 7/500, Train Loss: 0.2665, Val Loss: 0.3777
2024-12-29 13:00:21,516 - INFO - Epoch 8/500, Train Loss: 0.2411, Val Loss: 0.3681
2024-12-29 13:00:21,906 - INFO - Epoch 9/500, Train Loss: 0.2235, Val Loss: 0.3477
2024-12-29 13:00:22,262 - INFO - Epoch 10/500, Train Loss: 0.2118, Val Loss: 0.3517
2024-12-29 13:00:22,625 - INFO - Epoch 11/500, Train Loss: 0.2023, Val Loss: 0.3370
2024-12-29 13:00:22,975 - INFO - Epoch 12/500, Train Loss: 0.1898, Val Loss: 0.3201
2024-12-29 13:00:23,315 - INFO - Epoch 13/500, Train Loss: 0.1820, Val Loss: 0.3065
2024-12-29 13:00:23,651 - INFO - Epoch 14/500, Train Loss: 0.1768, Val Loss: 0.3191
2024-12-29 13:00:23,989 - INFO - Epoch 15/500, Train Loss: 0.1710, Val Loss: 0.3104
2024-12-29 13:00:24,382 - INFO - Epoch 16/500, Train Loss: 0.1634, Val Loss: 0.3161
2024-12-29 13:00:24,767 - INFO - Epoch 17/500, Train Loss: 0.1598, Val Loss: 0.3107
2024-12-29 13:00:25,158 - INFO - Epoch 18/500, Train Loss: 0.1572, Val Loss: 0.3061
2024-12-29 13:00:25,158 - INFO - Early stopping triggered at epoch 18
2024-12-29 13:00:25,158 - INFO - Training completed in 6.47s
2024-12-29 13:00:25,158 - INFO - Final memory usage: CPU 2726.1 MB, GPU 105.1 MB
2024-12-29 13:00:25,159 - INFO - Model training completed in 6.47s
2024-12-29 13:00:25,203 - INFO - Prediction completed in 0.04s
2024-12-29 13:00:25,212 - INFO - Poison rate 0.05 completed in 11.13s
2024-12-29 13:00:25,212 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:00:25,213 - INFO - Total number of labels flipped: 585
2024-12-29 13:00:25,213 - INFO - Label flipping completed in 0.00s
2024-12-29 13:00:25,213 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:00:25,213 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:00:25,791 - INFO - Feature scaling completed in 0.58s
2024-12-29 13:00:25,792 - INFO - Starting feature selection (k=50)
2024-12-29 13:00:25,806 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:00:25,806 - INFO - Starting anomaly detection
2024-12-29 13:00:29,617 - INFO - Anomaly detection completed in 3.81s
2024-12-29 13:00:29,618 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:00:29,618 - INFO - Total fit_transform time: 4.40s
2024-12-29 13:00:29,618 - INFO - Training set processing completed in 4.41s
2024-12-29 13:00:29,619 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:00:29,620 - INFO - Memory usage at start_fit: CPU 2707.5 MB, GPU 105.0 MB
2024-12-29 13:00:29,620 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:00:29,622 - INFO - Number of unique classes: 10
2024-12-29 13:00:29,694 - INFO - Fitted scaler and transformed data
2024-12-29 13:00:29,694 - INFO - Scaling time: 0.07s
2024-12-29 13:00:30,032 - INFO - Epoch 1/500, Train Loss: 1.4021, Val Loss: 0.8210
2024-12-29 13:00:30,351 - INFO - Epoch 2/500, Train Loss: 0.6679, Val Loss: 0.7164
2024-12-29 13:00:30,657 - INFO - Epoch 3/500, Train Loss: 0.5516, Val Loss: 0.6496
2024-12-29 13:00:31,018 - INFO - Epoch 4/500, Train Loss: 0.4743, Val Loss: 0.5907
2024-12-29 13:00:31,365 - INFO - Epoch 5/500, Train Loss: 0.4074, Val Loss: 0.5533
2024-12-29 13:00:31,691 - INFO - Epoch 6/500, Train Loss: 0.3603, Val Loss: 0.5223
2024-12-29 13:00:32,017 - INFO - Epoch 7/500, Train Loss: 0.3247, Val Loss: 0.4872
2024-12-29 13:00:32,396 - INFO - Epoch 8/500, Train Loss: 0.3007, Val Loss: 0.4608
2024-12-29 13:00:32,712 - INFO - Epoch 9/500, Train Loss: 0.2826, Val Loss: 0.4406
2024-12-29 13:00:33,064 - INFO - Epoch 10/500, Train Loss: 0.2629, Val Loss: 0.4259
2024-12-29 13:00:33,385 - INFO - Epoch 11/500, Train Loss: 0.2507, Val Loss: 0.4172
2024-12-29 13:00:33,707 - INFO - Epoch 12/500, Train Loss: 0.2410, Val Loss: 0.4102
2024-12-29 13:00:34,068 - INFO - Epoch 13/500, Train Loss: 0.2314, Val Loss: 0.4139
2024-12-29 13:00:34,405 - INFO - Epoch 14/500, Train Loss: 0.2238, Val Loss: 0.4052
2024-12-29 13:00:34,837 - INFO - Epoch 15/500, Train Loss: 0.2187, Val Loss: 0.3972
2024-12-29 13:00:35,208 - INFO - Epoch 16/500, Train Loss: 0.2148, Val Loss: 0.3926
2024-12-29 13:00:35,568 - INFO - Epoch 17/500, Train Loss: 0.2090, Val Loss: 0.3810
2024-12-29 13:00:35,964 - INFO - Epoch 18/500, Train Loss: 0.2069, Val Loss: 0.3850
2024-12-29 13:00:36,377 - INFO - Epoch 19/500, Train Loss: 0.2015, Val Loss: 0.3836
2024-12-29 13:00:36,721 - INFO - Epoch 20/500, Train Loss: 0.1951, Val Loss: 0.3726
2024-12-29 13:00:37,047 - INFO - Epoch 21/500, Train Loss: 0.1951, Val Loss: 0.3813
2024-12-29 13:00:37,431 - INFO - Epoch 22/500, Train Loss: 0.1943, Val Loss: 0.3752
2024-12-29 13:00:37,818 - INFO - Epoch 23/500, Train Loss: 0.1924, Val Loss: 0.3780
2024-12-29 13:00:38,177 - INFO - Epoch 24/500, Train Loss: 0.1901, Val Loss: 0.3691
2024-12-29 13:00:38,504 - INFO - Epoch 25/500, Train Loss: 0.1887, Val Loss: 0.3767
2024-12-29 13:00:38,914 - INFO - Epoch 26/500, Train Loss: 0.1839, Val Loss: 0.3667
2024-12-29 13:00:39,266 - INFO - Epoch 27/500, Train Loss: 0.1833, Val Loss: 0.3754
2024-12-29 13:00:39,640 - INFO - Epoch 28/500, Train Loss: 0.1810, Val Loss: 0.3793
2024-12-29 13:00:39,993 - INFO - Epoch 29/500, Train Loss: 0.1810, Val Loss: 0.3771
2024-12-29 13:00:40,354 - INFO - Epoch 30/500, Train Loss: 0.1794, Val Loss: 0.3739
2024-12-29 13:00:40,698 - INFO - Epoch 31/500, Train Loss: 0.1784, Val Loss: 0.3799
2024-12-29 13:00:40,698 - INFO - Early stopping triggered at epoch 31
2024-12-29 13:00:40,698 - INFO - Training completed in 11.08s
2024-12-29 13:00:40,699 - INFO - Final memory usage: CPU 2717.1 MB, GPU 105.1 MB
2024-12-29 13:00:40,700 - INFO - Model training completed in 11.08s
2024-12-29 13:00:40,744 - INFO - Prediction completed in 0.04s
2024-12-29 13:00:40,753 - INFO - Poison rate 0.07 completed in 15.54s
2024-12-29 13:00:40,753 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:00:40,755 - INFO - Total number of labels flipped: 851
2024-12-29 13:00:40,755 - INFO - Label flipping completed in 0.00s
2024-12-29 13:00:40,755 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:00:40,755 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:00:41,284 - INFO - Feature scaling completed in 0.53s
2024-12-29 13:00:41,284 - INFO - Starting feature selection (k=50)
2024-12-29 13:00:41,299 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:00:41,299 - INFO - Starting anomaly detection
2024-12-29 13:00:45,504 - INFO - Anomaly detection completed in 4.20s
2024-12-29 13:00:45,504 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:00:45,504 - INFO - Total fit_transform time: 4.75s
2024-12-29 13:00:45,504 - INFO - Training set processing completed in 4.75s
2024-12-29 13:00:45,504 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:00:45,505 - INFO - Memory usage at start_fit: CPU 2707.5 MB, GPU 105.0 MB
2024-12-29 13:00:45,506 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:00:45,509 - INFO - Number of unique classes: 10
2024-12-29 13:00:45,582 - INFO - Fitted scaler and transformed data
2024-12-29 13:00:45,582 - INFO - Scaling time: 0.07s
2024-12-29 13:00:45,994 - INFO - Epoch 1/500, Train Loss: 1.7554, Val Loss: 1.1144
2024-12-29 13:00:46,355 - INFO - Epoch 2/500, Train Loss: 0.9487, Val Loss: 1.0028
2024-12-29 13:00:46,679 - INFO - Epoch 3/500, Train Loss: 0.7953, Val Loss: 0.9063
2024-12-29 13:00:47,058 - INFO - Epoch 4/500, Train Loss: 0.6897, Val Loss: 0.8182
2024-12-29 13:00:47,413 - INFO - Epoch 5/500, Train Loss: 0.6034, Val Loss: 0.7516
2024-12-29 13:00:47,766 - INFO - Epoch 6/500, Train Loss: 0.5332, Val Loss: 0.6734
2024-12-29 13:00:48,150 - INFO - Epoch 7/500, Train Loss: 0.4776, Val Loss: 0.6371
2024-12-29 13:00:48,484 - INFO - Epoch 8/500, Train Loss: 0.4312, Val Loss: 0.5807
2024-12-29 13:00:48,810 - INFO - Epoch 9/500, Train Loss: 0.4002, Val Loss: 0.5415
2024-12-29 13:00:49,132 - INFO - Epoch 10/500, Train Loss: 0.3663, Val Loss: 0.5265
2024-12-29 13:00:49,476 - INFO - Epoch 11/500, Train Loss: 0.3484, Val Loss: 0.5019
2024-12-29 13:00:49,862 - INFO - Epoch 12/500, Train Loss: 0.3305, Val Loss: 0.4826
2024-12-29 13:00:50,232 - INFO - Epoch 13/500, Train Loss: 0.3197, Val Loss: 0.4814
2024-12-29 13:00:50,604 - INFO - Epoch 14/500, Train Loss: 0.3101, Val Loss: 0.4607
2024-12-29 13:00:50,998 - INFO - Epoch 15/500, Train Loss: 0.2997, Val Loss: 0.4588
2024-12-29 13:00:51,328 - INFO - Epoch 16/500, Train Loss: 0.2938, Val Loss: 0.4639
2024-12-29 13:00:51,703 - INFO - Epoch 17/500, Train Loss: 0.2868, Val Loss: 0.4446
2024-12-29 13:00:52,052 - INFO - Epoch 18/500, Train Loss: 0.2797, Val Loss: 0.4400
2024-12-29 13:00:52,411 - INFO - Epoch 19/500, Train Loss: 0.2767, Val Loss: 0.4460
2024-12-29 13:00:52,744 - INFO - Epoch 20/500, Train Loss: 0.2745, Val Loss: 0.4525
2024-12-29 13:00:53,078 - INFO - Epoch 21/500, Train Loss: 0.2670, Val Loss: 0.4534
2024-12-29 13:00:53,425 - INFO - Epoch 22/500, Train Loss: 0.2658, Val Loss: 0.4348
2024-12-29 13:00:53,769 - INFO - Epoch 23/500, Train Loss: 0.2630, Val Loss: 0.4365
2024-12-29 13:00:54,111 - INFO - Epoch 24/500, Train Loss: 0.2588, Val Loss: 0.4447
2024-12-29 13:00:54,424 - INFO - Epoch 25/500, Train Loss: 0.2574, Val Loss: 0.4362
2024-12-29 13:00:54,765 - INFO - Epoch 26/500, Train Loss: 0.2541, Val Loss: 0.4424
2024-12-29 13:00:55,137 - INFO - Epoch 27/500, Train Loss: 0.2534, Val Loss: 0.4347
2024-12-29 13:00:55,137 - INFO - Early stopping triggered at epoch 27
2024-12-29 13:00:55,137 - INFO - Training completed in 9.63s
2024-12-29 13:00:55,137 - INFO - Final memory usage: CPU 2726.3 MB, GPU 105.1 MB
2024-12-29 13:00:55,138 - INFO - Model training completed in 9.63s
2024-12-29 13:00:55,181 - INFO - Prediction completed in 0.04s
2024-12-29 13:00:55,190 - INFO - Poison rate 0.1 completed in 14.44s
2024-12-29 13:00:55,190 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:00:55,192 - INFO - Total number of labels flipped: 1693
2024-12-29 13:00:55,192 - INFO - Label flipping completed in 0.00s
2024-12-29 13:00:55,192 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:00:55,192 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:00:55,769 - INFO - Feature scaling completed in 0.58s
2024-12-29 13:00:55,769 - INFO - Starting feature selection (k=50)
2024-12-29 13:00:55,786 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 13:00:55,786 - INFO - Starting anomaly detection
2024-12-29 13:00:59,907 - INFO - Anomaly detection completed in 4.12s
2024-12-29 13:00:59,907 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:00:59,907 - INFO - Total fit_transform time: 4.72s
2024-12-29 13:00:59,908 - INFO - Training set processing completed in 4.72s
2024-12-29 13:00:59,908 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:00:59,908 - INFO - Memory usage at start_fit: CPU 2707.7 MB, GPU 105.0 MB
2024-12-29 13:00:59,909 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:00:59,911 - INFO - Number of unique classes: 10
2024-12-29 13:00:59,982 - INFO - Fitted scaler and transformed data
2024-12-29 13:00:59,982 - INFO - Scaling time: 0.07s
2024-12-29 13:01:00,321 - INFO - Epoch 1/500, Train Loss: 2.6260, Val Loss: 2.1167
2024-12-29 13:01:00,640 - INFO - Epoch 2/500, Train Loss: 1.6487, Val Loss: 1.8258
2024-12-29 13:01:00,944 - INFO - Epoch 3/500, Train Loss: 1.3597, Val Loss: 1.6166
2024-12-29 13:01:01,257 - INFO - Epoch 4/500, Train Loss: 1.1526, Val Loss: 1.4140
2024-12-29 13:01:01,599 - INFO - Epoch 5/500, Train Loss: 0.9802, Val Loss: 1.2788
2024-12-29 13:01:01,923 - INFO - Epoch 6/500, Train Loss: 0.8464, Val Loss: 1.1251
2024-12-29 13:01:02,246 - INFO - Epoch 7/500, Train Loss: 0.7440, Val Loss: 1.0176
2024-12-29 13:01:02,597 - INFO - Epoch 8/500, Train Loss: 0.6701, Val Loss: 0.9390
2024-12-29 13:01:02,913 - INFO - Epoch 9/500, Train Loss: 0.6249, Val Loss: 0.8808
2024-12-29 13:01:03,225 - INFO - Epoch 10/500, Train Loss: 0.5863, Val Loss: 0.8488
2024-12-29 13:01:03,543 - INFO - Epoch 11/500, Train Loss: 0.5611, Val Loss: 0.8182
2024-12-29 13:01:03,900 - INFO - Epoch 12/500, Train Loss: 0.5434, Val Loss: 0.8013
2024-12-29 13:01:04,341 - INFO - Epoch 13/500, Train Loss: 0.5284, Val Loss: 0.7971
2024-12-29 13:01:04,745 - INFO - Epoch 14/500, Train Loss: 0.5174, Val Loss: 0.7834
2024-12-29 13:01:05,118 - INFO - Epoch 15/500, Train Loss: 0.5097, Val Loss: 0.7853
2024-12-29 13:01:05,461 - INFO - Epoch 16/500, Train Loss: 0.4999, Val Loss: 0.7725
2024-12-29 13:01:05,778 - INFO - Epoch 17/500, Train Loss: 0.4929, Val Loss: 0.7566
2024-12-29 13:01:06,100 - INFO - Epoch 18/500, Train Loss: 0.4881, Val Loss: 0.7603
2024-12-29 13:01:06,398 - INFO - Epoch 19/500, Train Loss: 0.4805, Val Loss: 0.7600
2024-12-29 13:01:06,747 - INFO - Epoch 20/500, Train Loss: 0.4798, Val Loss: 0.7432
2024-12-29 13:01:07,138 - INFO - Epoch 21/500, Train Loss: 0.4758, Val Loss: 0.7447
2024-12-29 13:01:07,456 - INFO - Epoch 22/500, Train Loss: 0.4709, Val Loss: 0.7435
2024-12-29 13:01:07,892 - INFO - Epoch 23/500, Train Loss: 0.4643, Val Loss: 0.7505
2024-12-29 13:01:08,243 - INFO - Epoch 24/500, Train Loss: 0.4648, Val Loss: 0.7539
2024-12-29 13:01:08,589 - INFO - Epoch 25/500, Train Loss: 0.4583, Val Loss: 0.7461
2024-12-29 13:01:08,589 - INFO - Early stopping triggered at epoch 25
2024-12-29 13:01:08,589 - INFO - Training completed in 8.68s
2024-12-29 13:01:08,590 - INFO - Final memory usage: CPU 2717.1 MB, GPU 105.1 MB
2024-12-29 13:01:08,591 - INFO - Model training completed in 8.68s
2024-12-29 13:01:08,639 - INFO - Prediction completed in 0.05s
2024-12-29 13:01:08,660 - INFO - Poison rate 0.2 completed in 13.47s
2024-12-29 13:01:08,663 - INFO - Loaded 63 existing results
2024-12-29 13:01:08,663 - INFO - Total results to save: 70
2024-12-29 13:01:08,664 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:01:08,667 - INFO - Saved 70 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:01:08,667 - INFO - Total evaluation time: 119.45s
2024-12-29 13:01:08,669 - INFO - 
Progress: 11.5% - Evaluating GTSRB with LogisticRegression (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:01:08,847 - INFO - Loading datasets...
2024-12-29 13:01:08,868 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:01:08,868 - INFO - Extracting validation features...
2024-12-29 13:01:08,868 - INFO - Extracting features from 3925 samples...
2024-12-29 13:01:18,064 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:01:18,069 - INFO - Validation feature extraction completed in 9.20s
2024-12-29 13:01:18,069 - INFO - Extracting training features...
2024-12-29 13:01:18,070 - INFO - Extracting features from 9469 samples...
2024-12-29 13:01:39,060 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:01:39,068 - INFO - Training feature extraction completed in 21.00s
2024-12-29 13:01:39,069 - INFO - Creating model for classifier: LogisticRegression
2024-12-29 13:01:39,069 - INFO - Using device: cuda
2024-12-29 13:01:39,069 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:01:39,069 - INFO - Training set processing completed in 0.00s
2024-12-29 13:01:39,069 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:01:39,071 - INFO - Memory usage at start_fit: CPU 2760.9 MB, GPU 104.0 MB
2024-12-29 13:01:39,071 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:01:39,075 - INFO - Number of unique classes: 10
2024-12-29 13:01:39,143 - INFO - Fitted scaler and transformed data
2024-12-29 13:01:39,144 - INFO - Scaling time: 0.07s
2024-12-29 13:01:39,397 - INFO - Epoch 1/1000, Train Loss: 0.4885, Val Loss: 0.1225
2024-12-29 13:01:39,709 - INFO - Epoch 2/1000, Train Loss: 0.0940, Val Loss: 0.0865
2024-12-29 13:01:40,075 - INFO - Epoch 3/1000, Train Loss: 0.0676, Val Loss: 0.0727
2024-12-29 13:01:40,405 - INFO - Epoch 4/1000, Train Loss: 0.0548, Val Loss: 0.0654
2024-12-29 13:01:40,584 - INFO - Epoch 5/1000, Train Loss: 0.0471, Val Loss: 0.0614
2024-12-29 13:01:40,759 - INFO - Epoch 6/1000, Train Loss: 0.0423, Val Loss: 0.0590
2024-12-29 13:01:40,947 - INFO - Epoch 7/1000, Train Loss: 0.0389, Val Loss: 0.0568
2024-12-29 13:01:41,150 - INFO - Epoch 8/1000, Train Loss: 0.0362, Val Loss: 0.0559
2024-12-29 13:01:41,328 - INFO - Epoch 9/1000, Train Loss: 0.0346, Val Loss: 0.0549
2024-12-29 13:01:41,524 - INFO - Epoch 10/1000, Train Loss: 0.0330, Val Loss: 0.0543
2024-12-29 13:01:41,768 - INFO - Epoch 11/1000, Train Loss: 0.0318, Val Loss: 0.0540
2024-12-29 13:01:41,969 - INFO - Epoch 12/1000, Train Loss: 0.0312, Val Loss: 0.0535
2024-12-29 13:01:42,173 - INFO - Epoch 13/1000, Train Loss: 0.0304, Val Loss: 0.0530
2024-12-29 13:01:42,364 - INFO - Epoch 14/1000, Train Loss: 0.0300, Val Loss: 0.0532
2024-12-29 13:01:42,566 - INFO - Epoch 15/1000, Train Loss: 0.0297, Val Loss: 0.0528
2024-12-29 13:01:42,754 - INFO - Epoch 16/1000, Train Loss: 0.0293, Val Loss: 0.0532
2024-12-29 13:01:42,966 - INFO - Epoch 17/1000, Train Loss: 0.0290, Val Loss: 0.0529
2024-12-29 13:01:42,966 - INFO - Early stopping triggered at epoch 17
2024-12-29 13:01:42,966 - INFO - Training completed in 3.90s
2024-12-29 13:01:42,966 - INFO - Final memory usage: CPU 2761.3 MB, GPU 104.2 MB
2024-12-29 13:01:42,969 - INFO - Model training completed in 3.90s
2024-12-29 13:01:43,037 - INFO - Prediction completed in 0.07s
2024-12-29 13:01:43,062 - INFO - Poison rate 0.0 completed in 3.99s
2024-12-29 13:01:43,062 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:01:43,064 - INFO - Total number of labels flipped: 84
2024-12-29 13:01:43,064 - INFO - Label flipping completed in 0.00s
2024-12-29 13:01:43,064 - INFO - Training set processing completed in 0.00s
2024-12-29 13:01:43,064 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:01:43,065 - INFO - Memory usage at start_fit: CPU 2688.0 MB, GPU 104.1 MB
2024-12-29 13:01:43,065 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:01:43,069 - INFO - Number of unique classes: 10
2024-12-29 13:01:43,138 - INFO - Fitted scaler and transformed data
2024-12-29 13:01:43,138 - INFO - Scaling time: 0.07s
2024-12-29 13:01:43,353 - INFO - Epoch 1/1000, Train Loss: 0.5464, Val Loss: 0.2164
2024-12-29 13:01:43,542 - INFO - Epoch 2/1000, Train Loss: 0.1542, Val Loss: 0.1896
2024-12-29 13:01:43,740 - INFO - Epoch 3/1000, Train Loss: 0.1305, Val Loss: 0.1817
2024-12-29 13:01:43,941 - INFO - Epoch 4/1000, Train Loss: 0.1165, Val Loss: 0.1783
2024-12-29 13:01:44,145 - INFO - Epoch 5/1000, Train Loss: 0.1080, Val Loss: 0.1769
2024-12-29 13:01:44,333 - INFO - Epoch 6/1000, Train Loss: 0.1017, Val Loss: 0.1763
2024-12-29 13:01:44,530 - INFO - Epoch 7/1000, Train Loss: 0.0973, Val Loss: 0.1764
2024-12-29 13:01:44,737 - INFO - Epoch 8/1000, Train Loss: 0.0928, Val Loss: 0.1743
2024-12-29 13:01:44,944 - INFO - Epoch 9/1000, Train Loss: 0.0909, Val Loss: 0.1738
2024-12-29 13:01:45,158 - INFO - Epoch 10/1000, Train Loss: 0.0872, Val Loss: 0.1743
2024-12-29 13:01:45,363 - INFO - Epoch 11/1000, Train Loss: 0.0852, Val Loss: 0.1745
2024-12-29 13:01:45,583 - INFO - Epoch 12/1000, Train Loss: 0.0838, Val Loss: 0.1765
2024-12-29 13:01:45,805 - INFO - Epoch 13/1000, Train Loss: 0.0818, Val Loss: 0.1762
2024-12-29 13:01:45,805 - INFO - Early stopping triggered at epoch 13
2024-12-29 13:01:45,805 - INFO - Training completed in 2.74s
2024-12-29 13:01:45,805 - INFO - Final memory usage: CPU 2716.7 MB, GPU 104.2 MB
2024-12-29 13:01:45,806 - INFO - Model training completed in 2.74s
2024-12-29 13:01:45,872 - INFO - Prediction completed in 0.06s
2024-12-29 13:01:45,880 - INFO - Poison rate 0.01 completed in 2.82s
2024-12-29 13:01:45,881 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:01:45,881 - INFO - Total number of labels flipped: 251
2024-12-29 13:01:45,882 - INFO - Label flipping completed in 0.00s
2024-12-29 13:01:45,882 - INFO - Training set processing completed in 0.00s
2024-12-29 13:01:45,882 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:01:45,883 - INFO - Memory usage at start_fit: CPU 2687.4 MB, GPU 104.1 MB
2024-12-29 13:01:45,883 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:01:45,886 - INFO - Number of unique classes: 10
2024-12-29 13:01:45,975 - INFO - Fitted scaler and transformed data
2024-12-29 13:01:45,975 - INFO - Scaling time: 0.09s
2024-12-29 13:01:46,199 - INFO - Epoch 1/1000, Train Loss: 0.6194, Val Loss: 0.3444
2024-12-29 13:01:46,410 - INFO - Epoch 2/1000, Train Loss: 0.2751, Val Loss: 0.3260
2024-12-29 13:01:46,606 - INFO - Epoch 3/1000, Train Loss: 0.2535, Val Loss: 0.3189
2024-12-29 13:01:46,816 - INFO - Epoch 4/1000, Train Loss: 0.2410, Val Loss: 0.3174
2024-12-29 13:01:47,038 - INFO - Epoch 5/1000, Train Loss: 0.2295, Val Loss: 0.3143
2024-12-29 13:01:47,287 - INFO - Epoch 6/1000, Train Loss: 0.2204, Val Loss: 0.3126
2024-12-29 13:01:47,492 - INFO - Epoch 7/1000, Train Loss: 0.2138, Val Loss: 0.3104
2024-12-29 13:01:47,737 - INFO - Epoch 8/1000, Train Loss: 0.2067, Val Loss: 0.3103
2024-12-29 13:01:47,945 - INFO - Epoch 9/1000, Train Loss: 0.2009, Val Loss: 0.3073
2024-12-29 13:01:48,149 - INFO - Epoch 10/1000, Train Loss: 0.1970, Val Loss: 0.3070
2024-12-29 13:01:48,355 - INFO - Epoch 11/1000, Train Loss: 0.1936, Val Loss: 0.3053
2024-12-29 13:01:48,574 - INFO - Epoch 12/1000, Train Loss: 0.1904, Val Loss: 0.3064
2024-12-29 13:01:48,762 - INFO - Epoch 13/1000, Train Loss: 0.1882, Val Loss: 0.3096
2024-12-29 13:01:48,958 - INFO - Epoch 14/1000, Train Loss: 0.1843, Val Loss: 0.3066
2024-12-29 13:01:49,155 - INFO - Epoch 15/1000, Train Loss: 0.1817, Val Loss: 0.3042
2024-12-29 13:01:49,364 - INFO - Epoch 16/1000, Train Loss: 0.1802, Val Loss: 0.3025
2024-12-29 13:01:49,573 - INFO - Epoch 17/1000, Train Loss: 0.1791, Val Loss: 0.3020
2024-12-29 13:01:49,782 - INFO - Epoch 18/1000, Train Loss: 0.1766, Val Loss: 0.3006
2024-12-29 13:01:49,973 - INFO - Epoch 19/1000, Train Loss: 0.1743, Val Loss: 0.3032
2024-12-29 13:01:50,197 - INFO - Epoch 20/1000, Train Loss: 0.1754, Val Loss: 0.2996
2024-12-29 13:01:50,416 - INFO - Epoch 21/1000, Train Loss: 0.1724, Val Loss: 0.3009
2024-12-29 13:01:50,646 - INFO - Epoch 22/1000, Train Loss: 0.1712, Val Loss: 0.2990
2024-12-29 13:01:50,870 - INFO - Epoch 23/1000, Train Loss: 0.1710, Val Loss: 0.2992
2024-12-29 13:01:51,072 - INFO - Epoch 24/1000, Train Loss: 0.1681, Val Loss: 0.2979
2024-12-29 13:01:51,280 - INFO - Epoch 25/1000, Train Loss: 0.1689, Val Loss: 0.2967
2024-12-29 13:01:51,464 - INFO - Epoch 26/1000, Train Loss: 0.1677, Val Loss: 0.2977
2024-12-29 13:01:51,657 - INFO - Epoch 27/1000, Train Loss: 0.1671, Val Loss: 0.2966
2024-12-29 13:01:51,868 - INFO - Epoch 28/1000, Train Loss: 0.1677, Val Loss: 0.2937
2024-12-29 13:01:52,092 - INFO - Epoch 29/1000, Train Loss: 0.1667, Val Loss: 0.2971
2024-12-29 13:01:52,280 - INFO - Epoch 30/1000, Train Loss: 0.1656, Val Loss: 0.2962
2024-12-29 13:01:52,485 - INFO - Epoch 31/1000, Train Loss: 0.1640, Val Loss: 0.2937
2024-12-29 13:01:52,680 - INFO - Epoch 32/1000, Train Loss: 0.1662, Val Loss: 0.2931
2024-12-29 13:01:52,874 - INFO - Epoch 33/1000, Train Loss: 0.1646, Val Loss: 0.2942
2024-12-29 13:01:52,874 - INFO - Early stopping triggered at epoch 33
2024-12-29 13:01:52,874 - INFO - Training completed in 6.99s
2024-12-29 13:01:52,875 - INFO - Final memory usage: CPU 2717.0 MB, GPU 104.2 MB
2024-12-29 13:01:52,877 - INFO - Model training completed in 7.00s
2024-12-29 13:01:52,943 - INFO - Prediction completed in 0.06s
2024-12-29 13:01:52,951 - INFO - Poison rate 0.03 completed in 7.07s
2024-12-29 13:01:52,951 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:01:52,952 - INFO - Total number of labels flipped: 433
2024-12-29 13:01:52,953 - INFO - Label flipping completed in 0.00s
2024-12-29 13:01:52,953 - INFO - Training set processing completed in 0.00s
2024-12-29 13:01:52,953 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:01:52,953 - INFO - Memory usage at start_fit: CPU 2687.7 MB, GPU 104.1 MB
2024-12-29 13:01:52,954 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:01:52,957 - INFO - Number of unique classes: 10
2024-12-29 13:01:53,026 - INFO - Fitted scaler and transformed data
2024-12-29 13:01:53,026 - INFO - Scaling time: 0.07s
2024-12-29 13:01:53,256 - INFO - Epoch 1/1000, Train Loss: 0.6706, Val Loss: 0.3895
2024-12-29 13:01:53,463 - INFO - Epoch 2/1000, Train Loss: 0.3825, Val Loss: 0.3745
2024-12-29 13:01:53,659 - INFO - Epoch 3/1000, Train Loss: 0.3568, Val Loss: 0.3693
2024-12-29 13:01:53,857 - INFO - Epoch 4/1000, Train Loss: 0.3374, Val Loss: 0.3654
2024-12-29 13:01:54,050 - INFO - Epoch 5/1000, Train Loss: 0.3222, Val Loss: 0.3678
2024-12-29 13:01:54,243 - INFO - Epoch 6/1000, Train Loss: 0.3124, Val Loss: 0.3653
2024-12-29 13:01:54,429 - INFO - Epoch 7/1000, Train Loss: 0.3030, Val Loss: 0.3637
2024-12-29 13:01:54,613 - INFO - Epoch 8/1000, Train Loss: 0.2949, Val Loss: 0.3700
2024-12-29 13:01:54,797 - INFO - Epoch 9/1000, Train Loss: 0.2881, Val Loss: 0.3595
2024-12-29 13:01:54,980 - INFO - Epoch 10/1000, Train Loss: 0.2834, Val Loss: 0.3614
2024-12-29 13:01:55,175 - INFO - Epoch 11/1000, Train Loss: 0.2758, Val Loss: 0.3630
2024-12-29 13:01:55,386 - INFO - Epoch 12/1000, Train Loss: 0.2711, Val Loss: 0.3626
2024-12-29 13:01:55,572 - INFO - Epoch 13/1000, Train Loss: 0.2682, Val Loss: 0.3568
2024-12-29 13:01:55,763 - INFO - Epoch 14/1000, Train Loss: 0.2649, Val Loss: 0.3574
2024-12-29 13:01:55,973 - INFO - Epoch 15/1000, Train Loss: 0.2625, Val Loss: 0.3608
2024-12-29 13:01:56,188 - INFO - Epoch 16/1000, Train Loss: 0.2586, Val Loss: 0.3581
2024-12-29 13:01:56,387 - INFO - Epoch 17/1000, Train Loss: 0.2557, Val Loss: 0.3574
2024-12-29 13:01:56,587 - INFO - Epoch 18/1000, Train Loss: 0.2536, Val Loss: 0.3614
2024-12-29 13:01:56,588 - INFO - Early stopping triggered at epoch 18
2024-12-29 13:01:56,588 - INFO - Training completed in 3.64s
2024-12-29 13:01:56,589 - INFO - Final memory usage: CPU 2716.8 MB, GPU 104.2 MB
2024-12-29 13:01:56,591 - INFO - Model training completed in 3.64s
2024-12-29 13:01:56,668 - INFO - Prediction completed in 0.08s
2024-12-29 13:01:56,676 - INFO - Poison rate 0.05 completed in 3.73s
2024-12-29 13:01:56,677 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:01:56,678 - INFO - Total number of labels flipped: 587
2024-12-29 13:01:56,678 - INFO - Label flipping completed in 0.00s
2024-12-29 13:01:56,678 - INFO - Training set processing completed in 0.00s
2024-12-29 13:01:56,678 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:01:56,679 - INFO - Memory usage at start_fit: CPU 2691.2 MB, GPU 104.1 MB
2024-12-29 13:01:56,679 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:01:56,682 - INFO - Number of unique classes: 10
2024-12-29 13:01:56,780 - INFO - Fitted scaler and transformed data
2024-12-29 13:01:56,780 - INFO - Scaling time: 0.10s
2024-12-29 13:01:57,008 - INFO - Epoch 1/1000, Train Loss: 0.7581, Val Loss: 0.4836
2024-12-29 13:01:57,200 - INFO - Epoch 2/1000, Train Loss: 0.4777, Val Loss: 0.4720
2024-12-29 13:01:57,391 - INFO - Epoch 3/1000, Train Loss: 0.4452, Val Loss: 0.4634
2024-12-29 13:01:57,621 - INFO - Epoch 4/1000, Train Loss: 0.4267, Val Loss: 0.4574
2024-12-29 13:01:57,827 - INFO - Epoch 5/1000, Train Loss: 0.4071, Val Loss: 0.4519
2024-12-29 13:01:58,017 - INFO - Epoch 6/1000, Train Loss: 0.3966, Val Loss: 0.4515
2024-12-29 13:01:58,218 - INFO - Epoch 7/1000, Train Loss: 0.3833, Val Loss: 0.4453
2024-12-29 13:01:58,420 - INFO - Epoch 8/1000, Train Loss: 0.3757, Val Loss: 0.4428
2024-12-29 13:01:58,628 - INFO - Epoch 9/1000, Train Loss: 0.3662, Val Loss: 0.4428
2024-12-29 13:01:58,875 - INFO - Epoch 10/1000, Train Loss: 0.3568, Val Loss: 0.4353
2024-12-29 13:01:59,060 - INFO - Epoch 11/1000, Train Loss: 0.3537, Val Loss: 0.4355
2024-12-29 13:01:59,264 - INFO - Epoch 12/1000, Train Loss: 0.3460, Val Loss: 0.4278
2024-12-29 13:01:59,454 - INFO - Epoch 13/1000, Train Loss: 0.3396, Val Loss: 0.4343
2024-12-29 13:01:59,670 - INFO - Epoch 14/1000, Train Loss: 0.3330, Val Loss: 0.4266
2024-12-29 13:01:59,886 - INFO - Epoch 15/1000, Train Loss: 0.3286, Val Loss: 0.4298
2024-12-29 13:02:00,102 - INFO - Epoch 16/1000, Train Loss: 0.3260, Val Loss: 0.4147
2024-12-29 13:02:00,305 - INFO - Epoch 17/1000, Train Loss: 0.3208, Val Loss: 0.4231
2024-12-29 13:02:00,501 - INFO - Epoch 18/1000, Train Loss: 0.3188, Val Loss: 0.4167
2024-12-29 13:02:00,716 - INFO - Epoch 19/1000, Train Loss: 0.3153, Val Loss: 0.4146
2024-12-29 13:02:00,921 - INFO - Epoch 20/1000, Train Loss: 0.3134, Val Loss: 0.4116
2024-12-29 13:02:01,108 - INFO - Epoch 21/1000, Train Loss: 0.3106, Val Loss: 0.4125
2024-12-29 13:02:01,315 - INFO - Epoch 22/1000, Train Loss: 0.3069, Val Loss: 0.4081
2024-12-29 13:02:01,527 - INFO - Epoch 23/1000, Train Loss: 0.3059, Val Loss: 0.4140
2024-12-29 13:02:01,760 - INFO - Epoch 24/1000, Train Loss: 0.3024, Val Loss: 0.4091
2024-12-29 13:02:01,971 - INFO - Epoch 25/1000, Train Loss: 0.3008, Val Loss: 0.4083
2024-12-29 13:02:02,192 - INFO - Epoch 26/1000, Train Loss: 0.2987, Val Loss: 0.4058
2024-12-29 13:02:02,378 - INFO - Epoch 27/1000, Train Loss: 0.2967, Val Loss: 0.4027
2024-12-29 13:02:02,565 - INFO - Epoch 28/1000, Train Loss: 0.2954, Val Loss: 0.4036
2024-12-29 13:02:02,757 - INFO - Epoch 29/1000, Train Loss: 0.2943, Val Loss: 0.3991
2024-12-29 13:02:02,964 - INFO - Epoch 30/1000, Train Loss: 0.2932, Val Loss: 0.3974
2024-12-29 13:02:03,169 - INFO - Epoch 31/1000, Train Loss: 0.2909, Val Loss: 0.3969
2024-12-29 13:02:03,398 - INFO - Epoch 32/1000, Train Loss: 0.2866, Val Loss: 0.3913
2024-12-29 13:02:03,609 - INFO - Epoch 33/1000, Train Loss: 0.2872, Val Loss: 0.3951
2024-12-29 13:02:03,805 - INFO - Epoch 34/1000, Train Loss: 0.2856, Val Loss: 0.3919
2024-12-29 13:02:04,009 - INFO - Epoch 35/1000, Train Loss: 0.2851, Val Loss: 0.3975
2024-12-29 13:02:04,207 - INFO - Epoch 36/1000, Train Loss: 0.2851, Val Loss: 0.3935
2024-12-29 13:02:04,389 - INFO - Epoch 37/1000, Train Loss: 0.2820, Val Loss: 0.3892
2024-12-29 13:02:04,607 - INFO - Epoch 38/1000, Train Loss: 0.2811, Val Loss: 0.3942
2024-12-29 13:02:04,838 - INFO - Epoch 39/1000, Train Loss: 0.2819, Val Loss: 0.3869
2024-12-29 13:02:05,040 - INFO - Epoch 40/1000, Train Loss: 0.2807, Val Loss: 0.3849
2024-12-29 13:02:05,249 - INFO - Epoch 41/1000, Train Loss: 0.2785, Val Loss: 0.3868
2024-12-29 13:02:05,464 - INFO - Epoch 42/1000, Train Loss: 0.2787, Val Loss: 0.3866
2024-12-29 13:02:05,686 - INFO - Epoch 43/1000, Train Loss: 0.2777, Val Loss: 0.3877
2024-12-29 13:02:05,873 - INFO - Epoch 44/1000, Train Loss: 0.2761, Val Loss: 0.3794
2024-12-29 13:02:06,074 - INFO - Epoch 45/1000, Train Loss: 0.2770, Val Loss: 0.3908
2024-12-29 13:02:06,269 - INFO - Epoch 46/1000, Train Loss: 0.2771, Val Loss: 0.3856
2024-12-29 13:02:06,475 - INFO - Epoch 47/1000, Train Loss: 0.2751, Val Loss: 0.3832
2024-12-29 13:02:06,675 - INFO - Epoch 48/1000, Train Loss: 0.2754, Val Loss: 0.3858
2024-12-29 13:02:06,889 - INFO - Epoch 49/1000, Train Loss: 0.2749, Val Loss: 0.3783
2024-12-29 13:02:07,106 - INFO - Epoch 50/1000, Train Loss: 0.2732, Val Loss: 0.3775
2024-12-29 13:02:07,307 - INFO - Epoch 51/1000, Train Loss: 0.2740, Val Loss: 0.3799
2024-12-29 13:02:07,533 - INFO - Epoch 52/1000, Train Loss: 0.2722, Val Loss: 0.3809
2024-12-29 13:02:07,744 - INFO - Epoch 53/1000, Train Loss: 0.2725, Val Loss: 0.3813
2024-12-29 13:02:07,959 - INFO - Epoch 54/1000, Train Loss: 0.2716, Val Loss: 0.3818
2024-12-29 13:02:07,960 - INFO - Early stopping triggered at epoch 54
2024-12-29 13:02:07,960 - INFO - Training completed in 11.28s
2024-12-29 13:02:07,961 - INFO - Final memory usage: CPU 2720.6 MB, GPU 104.2 MB
2024-12-29 13:02:07,963 - INFO - Model training completed in 11.28s
2024-12-29 13:02:08,020 - INFO - Prediction completed in 0.06s
2024-12-29 13:02:08,029 - INFO - Poison rate 0.07 completed in 11.35s
2024-12-29 13:02:08,029 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:02:08,030 - INFO - Total number of labels flipped: 850
2024-12-29 13:02:08,030 - INFO - Label flipping completed in 0.00s
2024-12-29 13:02:08,030 - INFO - Training set processing completed in 0.00s
2024-12-29 13:02:08,030 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:02:08,032 - INFO - Memory usage at start_fit: CPU 2691.3 MB, GPU 104.1 MB
2024-12-29 13:02:08,032 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:02:08,037 - INFO - Number of unique classes: 10
2024-12-29 13:02:08,117 - INFO - Fitted scaler and transformed data
2024-12-29 13:02:08,118 - INFO - Scaling time: 0.08s
2024-12-29 13:02:08,339 - INFO - Epoch 1/1000, Train Loss: 0.8607, Val Loss: 0.6368
2024-12-29 13:02:08,554 - INFO - Epoch 2/1000, Train Loss: 0.6036, Val Loss: 0.6165
2024-12-29 13:02:08,744 - INFO - Epoch 3/1000, Train Loss: 0.5684, Val Loss: 0.5956
2024-12-29 13:02:08,939 - INFO - Epoch 4/1000, Train Loss: 0.5439, Val Loss: 0.5924
2024-12-29 13:02:09,172 - INFO - Epoch 5/1000, Train Loss: 0.5231, Val Loss: 0.5845
2024-12-29 13:02:09,369 - INFO - Epoch 6/1000, Train Loss: 0.5093, Val Loss: 0.5758
2024-12-29 13:02:09,600 - INFO - Epoch 7/1000, Train Loss: 0.4930, Val Loss: 0.5649
2024-12-29 13:02:09,786 - INFO - Epoch 8/1000, Train Loss: 0.4848, Val Loss: 0.5593
2024-12-29 13:02:10,003 - INFO - Epoch 9/1000, Train Loss: 0.4721, Val Loss: 0.5621
2024-12-29 13:02:10,234 - INFO - Epoch 10/1000, Train Loss: 0.4599, Val Loss: 0.5599
2024-12-29 13:02:10,426 - INFO - Epoch 11/1000, Train Loss: 0.4535, Val Loss: 0.5504
2024-12-29 13:02:10,634 - INFO - Epoch 12/1000, Train Loss: 0.4449, Val Loss: 0.5470
2024-12-29 13:02:10,842 - INFO - Epoch 13/1000, Train Loss: 0.4384, Val Loss: 0.5398
2024-12-29 13:02:11,039 - INFO - Epoch 14/1000, Train Loss: 0.4322, Val Loss: 0.5360
2024-12-29 13:02:11,254 - INFO - Epoch 15/1000, Train Loss: 0.4233, Val Loss: 0.5361
2024-12-29 13:02:11,507 - INFO - Epoch 16/1000, Train Loss: 0.4213, Val Loss: 0.5318
2024-12-29 13:02:11,728 - INFO - Epoch 17/1000, Train Loss: 0.4147, Val Loss: 0.5233
2024-12-29 13:02:11,943 - INFO - Epoch 18/1000, Train Loss: 0.4081, Val Loss: 0.5188
2024-12-29 13:02:12,127 - INFO - Epoch 19/1000, Train Loss: 0.4037, Val Loss: 0.5202
2024-12-29 13:02:12,324 - INFO - Epoch 20/1000, Train Loss: 0.4030, Val Loss: 0.5115
2024-12-29 13:02:12,537 - INFO - Epoch 21/1000, Train Loss: 0.3969, Val Loss: 0.5113
2024-12-29 13:02:12,786 - INFO - Epoch 22/1000, Train Loss: 0.3930, Val Loss: 0.5073
2024-12-29 13:02:12,995 - INFO - Epoch 23/1000, Train Loss: 0.3914, Val Loss: 0.5058
2024-12-29 13:02:13,220 - INFO - Epoch 24/1000, Train Loss: 0.3863, Val Loss: 0.5047
2024-12-29 13:02:13,425 - INFO - Epoch 25/1000, Train Loss: 0.3846, Val Loss: 0.4996
2024-12-29 13:02:13,642 - INFO - Epoch 26/1000, Train Loss: 0.3801, Val Loss: 0.4992
2024-12-29 13:02:13,844 - INFO - Epoch 27/1000, Train Loss: 0.3790, Val Loss: 0.4959
2024-12-29 13:02:14,045 - INFO - Epoch 28/1000, Train Loss: 0.3779, Val Loss: 0.4974
2024-12-29 13:02:14,241 - INFO - Epoch 29/1000, Train Loss: 0.3750, Val Loss: 0.5027
2024-12-29 13:02:14,450 - INFO - Epoch 30/1000, Train Loss: 0.3720, Val Loss: 0.4892
2024-12-29 13:02:14,663 - INFO - Epoch 31/1000, Train Loss: 0.3700, Val Loss: 0.4930
2024-12-29 13:02:14,916 - INFO - Epoch 32/1000, Train Loss: 0.3671, Val Loss: 0.4925
2024-12-29 13:02:15,141 - INFO - Epoch 33/1000, Train Loss: 0.3660, Val Loss: 0.4883
2024-12-29 13:02:15,361 - INFO - Epoch 34/1000, Train Loss: 0.3631, Val Loss: 0.4816
2024-12-29 13:02:15,562 - INFO - Epoch 35/1000, Train Loss: 0.3637, Val Loss: 0.4831
2024-12-29 13:02:15,763 - INFO - Epoch 36/1000, Train Loss: 0.3621, Val Loss: 0.4837
2024-12-29 13:02:15,983 - INFO - Epoch 37/1000, Train Loss: 0.3596, Val Loss: 0.4864
2024-12-29 13:02:16,194 - INFO - Epoch 38/1000, Train Loss: 0.3590, Val Loss: 0.4805
2024-12-29 13:02:16,380 - INFO - Epoch 39/1000, Train Loss: 0.3573, Val Loss: 0.4874
2024-12-29 13:02:16,596 - INFO - Epoch 40/1000, Train Loss: 0.3564, Val Loss: 0.4820
2024-12-29 13:02:16,794 - INFO - Epoch 41/1000, Train Loss: 0.3548, Val Loss: 0.4745
2024-12-29 13:02:17,009 - INFO - Epoch 42/1000, Train Loss: 0.3528, Val Loss: 0.4786
2024-12-29 13:02:17,205 - INFO - Epoch 43/1000, Train Loss: 0.3525, Val Loss: 0.4723
2024-12-29 13:02:17,410 - INFO - Epoch 44/1000, Train Loss: 0.3510, Val Loss: 0.4730
2024-12-29 13:02:17,636 - INFO - Epoch 45/1000, Train Loss: 0.3484, Val Loss: 0.4716
2024-12-29 13:02:17,864 - INFO - Epoch 46/1000, Train Loss: 0.3499, Val Loss: 0.4740
2024-12-29 13:02:18,088 - INFO - Epoch 47/1000, Train Loss: 0.3491, Val Loss: 0.4735
2024-12-29 13:02:18,300 - INFO - Epoch 48/1000, Train Loss: 0.3466, Val Loss: 0.4684
2024-12-29 13:02:18,495 - INFO - Epoch 49/1000, Train Loss: 0.3465, Val Loss: 0.4727
2024-12-29 13:02:18,702 - INFO - Epoch 50/1000, Train Loss: 0.3454, Val Loss: 0.4735
2024-12-29 13:02:18,892 - INFO - Epoch 51/1000, Train Loss: 0.3448, Val Loss: 0.4745
2024-12-29 13:02:19,085 - INFO - Epoch 52/1000, Train Loss: 0.3450, Val Loss: 0.4742
2024-12-29 13:02:19,316 - INFO - Epoch 53/1000, Train Loss: 0.3446, Val Loss: 0.4661
2024-12-29 13:02:19,531 - INFO - Epoch 54/1000, Train Loss: 0.3437, Val Loss: 0.4691
2024-12-29 13:02:19,739 - INFO - Epoch 55/1000, Train Loss: 0.3437, Val Loss: 0.4740
2024-12-29 13:02:19,946 - INFO - Epoch 56/1000, Train Loss: 0.3425, Val Loss: 0.4824
2024-12-29 13:02:20,158 - INFO - Epoch 57/1000, Train Loss: 0.3420, Val Loss: 0.4646
2024-12-29 13:02:20,363 - INFO - Epoch 58/1000, Train Loss: 0.3407, Val Loss: 0.4637
2024-12-29 13:02:20,564 - INFO - Epoch 59/1000, Train Loss: 0.3402, Val Loss: 0.4676
2024-12-29 13:02:20,756 - INFO - Epoch 60/1000, Train Loss: 0.3428, Val Loss: 0.4682
2024-12-29 13:02:20,961 - INFO - Epoch 61/1000, Train Loss: 0.3417, Val Loss: 0.4676
2024-12-29 13:02:21,161 - INFO - Epoch 62/1000, Train Loss: 0.3397, Val Loss: 0.4621
2024-12-29 13:02:21,374 - INFO - Epoch 63/1000, Train Loss: 0.3392, Val Loss: 0.4632
2024-12-29 13:02:21,567 - INFO - Epoch 64/1000, Train Loss: 0.3386, Val Loss: 0.4684
2024-12-29 13:02:21,769 - INFO - Epoch 65/1000, Train Loss: 0.3397, Val Loss: 0.4599
2024-12-29 13:02:21,972 - INFO - Epoch 66/1000, Train Loss: 0.3380, Val Loss: 0.4646
2024-12-29 13:02:22,167 - INFO - Epoch 67/1000, Train Loss: 0.3399, Val Loss: 0.4654
2024-12-29 13:02:22,367 - INFO - Epoch 68/1000, Train Loss: 0.3391, Val Loss: 0.4637
2024-12-29 13:02:22,559 - INFO - Epoch 69/1000, Train Loss: 0.3383, Val Loss: 0.4652
2024-12-29 13:02:22,775 - INFO - Epoch 70/1000, Train Loss: 0.3372, Val Loss: 0.4617
2024-12-29 13:02:22,776 - INFO - Early stopping triggered at epoch 70
2024-12-29 13:02:22,776 - INFO - Training completed in 14.74s
2024-12-29 13:02:22,776 - INFO - Final memory usage: CPU 2720.6 MB, GPU 104.2 MB
2024-12-29 13:02:22,777 - INFO - Model training completed in 14.75s
2024-12-29 13:02:22,821 - INFO - Prediction completed in 0.04s
2024-12-29 13:02:22,829 - INFO - Poison rate 0.1 completed in 14.80s
2024-12-29 13:02:22,830 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:02:22,831 - INFO - Total number of labels flipped: 1719
2024-12-29 13:02:22,831 - INFO - Label flipping completed in 0.00s
2024-12-29 13:02:22,831 - INFO - Training set processing completed in 0.00s
2024-12-29 13:02:22,832 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:02:22,832 - INFO - Memory usage at start_fit: CPU 2691.3 MB, GPU 104.1 MB
2024-12-29 13:02:22,832 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:02:22,836 - INFO - Number of unique classes: 10
2024-12-29 13:02:22,908 - INFO - Fitted scaler and transformed data
2024-12-29 13:02:22,908 - INFO - Scaling time: 0.07s
2024-12-29 13:02:23,128 - INFO - Epoch 1/1000, Train Loss: 1.1767, Val Loss: 0.9816
2024-12-29 13:02:23,331 - INFO - Epoch 2/1000, Train Loss: 0.9580, Val Loss: 0.9418
2024-12-29 13:02:23,560 - INFO - Epoch 3/1000, Train Loss: 0.9141, Val Loss: 0.9285
2024-12-29 13:02:23,765 - INFO - Epoch 4/1000, Train Loss: 0.8798, Val Loss: 0.8987
2024-12-29 13:02:23,969 - INFO - Epoch 5/1000, Train Loss: 0.8471, Val Loss: 0.8852
2024-12-29 13:02:24,153 - INFO - Epoch 6/1000, Train Loss: 0.8164, Val Loss: 0.8742
2024-12-29 13:02:24,359 - INFO - Epoch 7/1000, Train Loss: 0.7974, Val Loss: 0.8646
2024-12-29 13:02:24,570 - INFO - Epoch 8/1000, Train Loss: 0.7755, Val Loss: 0.8457
2024-12-29 13:02:24,787 - INFO - Epoch 9/1000, Train Loss: 0.7523, Val Loss: 0.8344
2024-12-29 13:02:24,992 - INFO - Epoch 10/1000, Train Loss: 0.7373, Val Loss: 0.8211
2024-12-29 13:02:25,191 - INFO - Epoch 11/1000, Train Loss: 0.7190, Val Loss: 0.8149
2024-12-29 13:02:25,387 - INFO - Epoch 12/1000, Train Loss: 0.7067, Val Loss: 0.7996
2024-12-29 13:02:25,573 - INFO - Epoch 13/1000, Train Loss: 0.6923, Val Loss: 0.7953
2024-12-29 13:02:25,762 - INFO - Epoch 14/1000, Train Loss: 0.6791, Val Loss: 0.7814
2024-12-29 13:02:25,974 - INFO - Epoch 15/1000, Train Loss: 0.6646, Val Loss: 0.7730
2024-12-29 13:02:26,199 - INFO - Epoch 16/1000, Train Loss: 0.6541, Val Loss: 0.7655
2024-12-29 13:02:26,388 - INFO - Epoch 17/1000, Train Loss: 0.6438, Val Loss: 0.7565
2024-12-29 13:02:26,578 - INFO - Epoch 18/1000, Train Loss: 0.6355, Val Loss: 0.7508
2024-12-29 13:02:26,777 - INFO - Epoch 19/1000, Train Loss: 0.6257, Val Loss: 0.7429
2024-12-29 13:02:26,975 - INFO - Epoch 20/1000, Train Loss: 0.6158, Val Loss: 0.7316
2024-12-29 13:02:27,179 - INFO - Epoch 21/1000, Train Loss: 0.6098, Val Loss: 0.7261
2024-12-29 13:02:27,397 - INFO - Epoch 22/1000, Train Loss: 0.6023, Val Loss: 0.7174
2024-12-29 13:02:27,592 - INFO - Epoch 23/1000, Train Loss: 0.5958, Val Loss: 0.7126
2024-12-29 13:02:27,796 - INFO - Epoch 24/1000, Train Loss: 0.5894, Val Loss: 0.7184
2024-12-29 13:02:27,983 - INFO - Epoch 25/1000, Train Loss: 0.5837, Val Loss: 0.7180
2024-12-29 13:02:28,203 - INFO - Epoch 26/1000, Train Loss: 0.5793, Val Loss: 0.6980
2024-12-29 13:02:28,416 - INFO - Epoch 27/1000, Train Loss: 0.5724, Val Loss: 0.7003
2024-12-29 13:02:28,634 - INFO - Epoch 28/1000, Train Loss: 0.5683, Val Loss: 0.6926
2024-12-29 13:02:28,848 - INFO - Epoch 29/1000, Train Loss: 0.5654, Val Loss: 0.6901
2024-12-29 13:02:29,053 - INFO - Epoch 30/1000, Train Loss: 0.5605, Val Loss: 0.6831
2024-12-29 13:02:29,251 - INFO - Epoch 31/1000, Train Loss: 0.5576, Val Loss: 0.6927
2024-12-29 13:02:29,472 - INFO - Epoch 32/1000, Train Loss: 0.5541, Val Loss: 0.6864
2024-12-29 13:02:29,707 - INFO - Epoch 33/1000, Train Loss: 0.5513, Val Loss: 0.6808
2024-12-29 13:02:29,892 - INFO - Epoch 34/1000, Train Loss: 0.5484, Val Loss: 0.6738
2024-12-29 13:02:30,102 - INFO - Epoch 35/1000, Train Loss: 0.5422, Val Loss: 0.6795
2024-12-29 13:02:30,313 - INFO - Epoch 36/1000, Train Loss: 0.5424, Val Loss: 0.6658
2024-12-29 13:02:30,508 - INFO - Epoch 37/1000, Train Loss: 0.5394, Val Loss: 0.6701
2024-12-29 13:02:30,708 - INFO - Epoch 38/1000, Train Loss: 0.5364, Val Loss: 0.6723
2024-12-29 13:02:30,902 - INFO - Epoch 39/1000, Train Loss: 0.5355, Val Loss: 0.6670
2024-12-29 13:02:31,099 - INFO - Epoch 40/1000, Train Loss: 0.5328, Val Loss: 0.6643
2024-12-29 13:02:31,306 - INFO - Epoch 41/1000, Train Loss: 0.5307, Val Loss: 0.6632
2024-12-29 13:02:31,508 - INFO - Epoch 42/1000, Train Loss: 0.5279, Val Loss: 0.6690
2024-12-29 13:02:31,711 - INFO - Epoch 43/1000, Train Loss: 0.5261, Val Loss: 0.6590
2024-12-29 13:02:31,922 - INFO - Epoch 44/1000, Train Loss: 0.5245, Val Loss: 0.6603
2024-12-29 13:02:32,133 - INFO - Epoch 45/1000, Train Loss: 0.5218, Val Loss: 0.6571
2024-12-29 13:02:32,346 - INFO - Epoch 46/1000, Train Loss: 0.5190, Val Loss: 0.6641
2024-12-29 13:02:32,549 - INFO - Epoch 47/1000, Train Loss: 0.5196, Val Loss: 0.6598
2024-12-29 13:02:32,751 - INFO - Epoch 48/1000, Train Loss: 0.5177, Val Loss: 0.6583
2024-12-29 13:02:32,964 - INFO - Epoch 49/1000, Train Loss: 0.5160, Val Loss: 0.6505
2024-12-29 13:02:33,155 - INFO - Epoch 50/1000, Train Loss: 0.5137, Val Loss: 0.6502
2024-12-29 13:02:33,367 - INFO - Epoch 51/1000, Train Loss: 0.5156, Val Loss: 0.6570
2024-12-29 13:02:33,552 - INFO - Epoch 52/1000, Train Loss: 0.5135, Val Loss: 0.6502
2024-12-29 13:02:33,750 - INFO - Epoch 53/1000, Train Loss: 0.5110, Val Loss: 0.6478
2024-12-29 13:02:33,953 - INFO - Epoch 54/1000, Train Loss: 0.5120, Val Loss: 0.6470
2024-12-29 13:02:34,148 - INFO - Epoch 55/1000, Train Loss: 0.5090, Val Loss: 0.6444
2024-12-29 13:02:34,358 - INFO - Epoch 56/1000, Train Loss: 0.5080, Val Loss: 0.6428
2024-12-29 13:02:34,587 - INFO - Epoch 57/1000, Train Loss: 0.5061, Val Loss: 0.6404
2024-12-29 13:02:34,781 - INFO - Epoch 58/1000, Train Loss: 0.5074, Val Loss: 0.6450
2024-12-29 13:02:34,995 - INFO - Epoch 59/1000, Train Loss: 0.5061, Val Loss: 0.6464
2024-12-29 13:02:35,225 - INFO - Epoch 60/1000, Train Loss: 0.5033, Val Loss: 0.6403
2024-12-29 13:02:35,410 - INFO - Epoch 61/1000, Train Loss: 0.5031, Val Loss: 0.6444
2024-12-29 13:02:35,601 - INFO - Epoch 62/1000, Train Loss: 0.5016, Val Loss: 0.6456
2024-12-29 13:02:35,601 - INFO - Early stopping triggered at epoch 62
2024-12-29 13:02:35,601 - INFO - Training completed in 12.77s
2024-12-29 13:02:35,602 - INFO - Final memory usage: CPU 2720.9 MB, GPU 104.2 MB
2024-12-29 13:02:35,602 - INFO - Model training completed in 12.77s
2024-12-29 13:02:35,695 - INFO - Prediction completed in 0.09s
2024-12-29 13:02:35,707 - INFO - Poison rate 0.2 completed in 12.88s
2024-12-29 13:02:35,709 - INFO - Loaded 70 existing results
2024-12-29 13:02:35,709 - INFO - Total results to save: 77
2024-12-29 13:02:35,710 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:02:35,713 - INFO - Saved 77 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:02:35,713 - INFO - Total evaluation time: 86.87s
2024-12-29 13:02:35,715 - INFO - 
Progress: 12.5% - Evaluating GTSRB with LogisticRegression (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:02:35,946 - INFO - Loading datasets...
2024-12-29 13:02:35,975 - INFO - Dataset loading completed in 0.03s
2024-12-29 13:02:35,976 - INFO - Extracting validation features...
2024-12-29 13:02:35,976 - INFO - Extracting features from 3925 samples...
2024-12-29 13:02:45,601 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:02:45,609 - INFO - Validation feature extraction completed in 9.63s
2024-12-29 13:02:45,610 - INFO - Extracting training features...
2024-12-29 13:02:45,610 - INFO - Extracting features from 9469 samples...
2024-12-29 13:03:07,314 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:03:07,318 - INFO - Training feature extraction completed in 21.71s
2024-12-29 13:03:07,319 - INFO - Creating model for classifier: LogisticRegression
2024-12-29 13:03:07,319 - INFO - Using device: cuda
2024-12-29 13:03:07,319 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:03:07,319 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:03:07,319 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:03:07,903 - INFO - Feature scaling completed in 0.58s
2024-12-29 13:03:07,903 - INFO - Starting feature selection (k=50)
2024-12-29 13:03:07,911 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:03:07,911 - INFO - Starting anomaly detection
2024-12-29 13:03:09,955 - INFO - Anomaly detection completed in 2.04s
2024-12-29 13:03:09,955 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:03:09,955 - INFO - Total fit_transform time: 2.64s
2024-12-29 13:03:09,956 - INFO - Training set processing completed in 2.64s
2024-12-29 13:03:09,956 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:03:09,957 - INFO - Memory usage at start_fit: CPU 2707.7 MB, GPU 104.9 MB
2024-12-29 13:03:09,957 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:03:09,959 - INFO - Number of unique classes: 10
2024-12-29 13:03:10,028 - INFO - Fitted scaler and transformed data
2024-12-29 13:03:10,028 - INFO - Scaling time: 0.07s
2024-12-29 13:03:10,253 - INFO - Epoch 1/1000, Train Loss: 0.4761, Val Loss: 0.1190
2024-12-29 13:03:10,461 - INFO - Epoch 2/1000, Train Loss: 0.0946, Val Loss: 0.0837
2024-12-29 13:03:10,673 - INFO - Epoch 3/1000, Train Loss: 0.0675, Val Loss: 0.0715
2024-12-29 13:03:10,874 - INFO - Epoch 4/1000, Train Loss: 0.0547, Val Loss: 0.0656
2024-12-29 13:03:11,102 - INFO - Epoch 5/1000, Train Loss: 0.0469, Val Loss: 0.0625
2024-12-29 13:03:11,308 - INFO - Epoch 6/1000, Train Loss: 0.0418, Val Loss: 0.0608
2024-12-29 13:03:11,504 - INFO - Epoch 7/1000, Train Loss: 0.0383, Val Loss: 0.0591
2024-12-29 13:03:11,703 - INFO - Epoch 8/1000, Train Loss: 0.0359, Val Loss: 0.0589
2024-12-29 13:03:11,918 - INFO - Epoch 9/1000, Train Loss: 0.0342, Val Loss: 0.0584
2024-12-29 13:03:12,157 - INFO - Epoch 10/1000, Train Loss: 0.0328, Val Loss: 0.0582
2024-12-29 13:03:12,410 - INFO - Epoch 11/1000, Train Loss: 0.0317, Val Loss: 0.0580
2024-12-29 13:03:12,594 - INFO - Epoch 12/1000, Train Loss: 0.0309, Val Loss: 0.0578
2024-12-29 13:03:12,806 - INFO - Epoch 13/1000, Train Loss: 0.0302, Val Loss: 0.0582
2024-12-29 13:03:13,040 - INFO - Epoch 14/1000, Train Loss: 0.0298, Val Loss: 0.0577
2024-12-29 13:03:13,273 - INFO - Epoch 15/1000, Train Loss: 0.0294, Val Loss: 0.0573
2024-12-29 13:03:13,493 - INFO - Epoch 16/1000, Train Loss: 0.0290, Val Loss: 0.0576
2024-12-29 13:03:13,493 - INFO - Early stopping triggered at epoch 16
2024-12-29 13:03:13,494 - INFO - Training completed in 3.54s
2024-12-29 13:03:13,494 - INFO - Final memory usage: CPU 2717.0 MB, GPU 105.1 MB
2024-12-29 13:03:13,497 - INFO - Model training completed in 3.54s
2024-12-29 13:03:13,555 - INFO - Prediction completed in 0.06s
2024-12-29 13:03:13,564 - INFO - Poison rate 0.0 completed in 6.25s
2024-12-29 13:03:13,564 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:03:13,565 - INFO - Total number of labels flipped: 86
2024-12-29 13:03:13,566 - INFO - Label flipping completed in 0.00s
2024-12-29 13:03:13,566 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:03:13,566 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:03:14,083 - INFO - Feature scaling completed in 0.52s
2024-12-29 13:03:14,083 - INFO - Starting feature selection (k=50)
2024-12-29 13:03:14,100 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 13:03:14,100 - INFO - Starting anomaly detection
2024-12-29 13:03:18,179 - INFO - Anomaly detection completed in 4.08s
2024-12-29 13:03:18,179 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:03:18,179 - INFO - Total fit_transform time: 4.61s
2024-12-29 13:03:18,179 - INFO - Training set processing completed in 4.61s
2024-12-29 13:03:18,179 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:03:18,181 - INFO - Memory usage at start_fit: CPU 2707.8 MB, GPU 105.0 MB
2024-12-29 13:03:18,181 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:03:18,184 - INFO - Number of unique classes: 10
2024-12-29 13:03:18,252 - INFO - Fitted scaler and transformed data
2024-12-29 13:03:18,252 - INFO - Scaling time: 0.07s
2024-12-29 13:03:18,515 - INFO - Epoch 1/1000, Train Loss: 0.5183, Val Loss: 0.1912
2024-12-29 13:03:18,723 - INFO - Epoch 2/1000, Train Loss: 0.1572, Val Loss: 0.1645
2024-12-29 13:03:18,959 - INFO - Epoch 3/1000, Train Loss: 0.1349, Val Loss: 0.1553
2024-12-29 13:03:19,173 - INFO - Epoch 4/1000, Train Loss: 0.1238, Val Loss: 0.1517
2024-12-29 13:03:19,341 - INFO - Epoch 5/1000, Train Loss: 0.1157, Val Loss: 0.1501
2024-12-29 13:03:19,547 - INFO - Epoch 6/1000, Train Loss: 0.1101, Val Loss: 0.1479
2024-12-29 13:03:19,749 - INFO - Epoch 7/1000, Train Loss: 0.1058, Val Loss: 0.1479
2024-12-29 13:03:19,947 - INFO - Epoch 8/1000, Train Loss: 0.1022, Val Loss: 0.1475
2024-12-29 13:03:20,157 - INFO - Epoch 9/1000, Train Loss: 0.0991, Val Loss: 0.1467
2024-12-29 13:03:20,365 - INFO - Epoch 10/1000, Train Loss: 0.0962, Val Loss: 0.1458
2024-12-29 13:03:20,601 - INFO - Epoch 11/1000, Train Loss: 0.0940, Val Loss: 0.1461
2024-12-29 13:03:20,816 - INFO - Epoch 12/1000, Train Loss: 0.0932, Val Loss: 0.1480
2024-12-29 13:03:21,051 - INFO - Epoch 13/1000, Train Loss: 0.0919, Val Loss: 0.1450
2024-12-29 13:03:21,251 - INFO - Epoch 14/1000, Train Loss: 0.0901, Val Loss: 0.1465
2024-12-29 13:03:21,453 - INFO - Epoch 15/1000, Train Loss: 0.0885, Val Loss: 0.1460
2024-12-29 13:03:21,648 - INFO - Epoch 16/1000, Train Loss: 0.0876, Val Loss: 0.1460
2024-12-29 13:03:21,865 - INFO - Epoch 17/1000, Train Loss: 0.0869, Val Loss: 0.1445
2024-12-29 13:03:22,067 - INFO - Epoch 18/1000, Train Loss: 0.0869, Val Loss: 0.1459
2024-12-29 13:03:22,067 - INFO - Early stopping triggered at epoch 18
2024-12-29 13:03:22,068 - INFO - Training completed in 3.89s
2024-12-29 13:03:22,069 - INFO - Final memory usage: CPU 2726.2 MB, GPU 105.1 MB
2024-12-29 13:03:22,070 - INFO - Model training completed in 3.89s
2024-12-29 13:03:22,141 - INFO - Prediction completed in 0.07s
2024-12-29 13:03:22,149 - INFO - Poison rate 0.01 completed in 8.58s
2024-12-29 13:03:22,149 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:03:22,150 - INFO - Total number of labels flipped: 257
2024-12-29 13:03:22,150 - INFO - Label flipping completed in 0.00s
2024-12-29 13:03:22,150 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:03:22,150 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:03:22,776 - INFO - Feature scaling completed in 0.63s
2024-12-29 13:03:22,776 - INFO - Starting feature selection (k=50)
2024-12-29 13:03:22,796 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 13:03:22,796 - INFO - Starting anomaly detection
2024-12-29 13:03:27,002 - INFO - Anomaly detection completed in 4.21s
2024-12-29 13:03:27,002 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:03:27,002 - INFO - Total fit_transform time: 4.85s
2024-12-29 13:03:27,002 - INFO - Training set processing completed in 4.85s
2024-12-29 13:03:27,003 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:03:27,004 - INFO - Memory usage at start_fit: CPU 2707.6 MB, GPU 105.0 MB
2024-12-29 13:03:27,004 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:03:27,007 - INFO - Number of unique classes: 10
2024-12-29 13:03:27,085 - INFO - Fitted scaler and transformed data
2024-12-29 13:03:27,086 - INFO - Scaling time: 0.08s
2024-12-29 13:03:27,312 - INFO - Epoch 1/1000, Train Loss: 0.6417, Val Loss: 0.2950
2024-12-29 13:03:27,518 - INFO - Epoch 2/1000, Train Loss: 0.2866, Val Loss: 0.2777
2024-12-29 13:03:27,703 - INFO - Epoch 3/1000, Train Loss: 0.2629, Val Loss: 0.2732
2024-12-29 13:03:27,913 - INFO - Epoch 4/1000, Train Loss: 0.2481, Val Loss: 0.2700
2024-12-29 13:03:28,134 - INFO - Epoch 5/1000, Train Loss: 0.2351, Val Loss: 0.2665
2024-12-29 13:03:28,350 - INFO - Epoch 6/1000, Train Loss: 0.2255, Val Loss: 0.2654
2024-12-29 13:03:28,573 - INFO - Epoch 7/1000, Train Loss: 0.2192, Val Loss: 0.2640
2024-12-29 13:03:28,791 - INFO - Epoch 8/1000, Train Loss: 0.2121, Val Loss: 0.2609
2024-12-29 13:03:29,001 - INFO - Epoch 9/1000, Train Loss: 0.2061, Val Loss: 0.2607
2024-12-29 13:03:29,234 - INFO - Epoch 10/1000, Train Loss: 0.2028, Val Loss: 0.2615
2024-12-29 13:03:29,436 - INFO - Epoch 11/1000, Train Loss: 0.1981, Val Loss: 0.2569
2024-12-29 13:03:29,653 - INFO - Epoch 12/1000, Train Loss: 0.1936, Val Loss: 0.2575
2024-12-29 13:03:29,883 - INFO - Epoch 13/1000, Train Loss: 0.1894, Val Loss: 0.2529
2024-12-29 13:03:30,086 - INFO - Epoch 14/1000, Train Loss: 0.1874, Val Loss: 0.2548
2024-12-29 13:03:30,310 - INFO - Epoch 15/1000, Train Loss: 0.1840, Val Loss: 0.2545
2024-12-29 13:03:30,522 - INFO - Epoch 16/1000, Train Loss: 0.1818, Val Loss: 0.2535
2024-12-29 13:03:30,706 - INFO - Epoch 17/1000, Train Loss: 0.1799, Val Loss: 0.2506
2024-12-29 13:03:30,944 - INFO - Epoch 18/1000, Train Loss: 0.1778, Val Loss: 0.2483
2024-12-29 13:03:31,173 - INFO - Epoch 19/1000, Train Loss: 0.1774, Val Loss: 0.2480
2024-12-29 13:03:31,410 - INFO - Epoch 20/1000, Train Loss: 0.1753, Val Loss: 0.2480
2024-12-29 13:03:31,642 - INFO - Epoch 21/1000, Train Loss: 0.1748, Val Loss: 0.2483
2024-12-29 13:03:31,838 - INFO - Epoch 22/1000, Train Loss: 0.1726, Val Loss: 0.2423
2024-12-29 13:03:32,063 - INFO - Epoch 23/1000, Train Loss: 0.1714, Val Loss: 0.2410
2024-12-29 13:03:32,259 - INFO - Epoch 24/1000, Train Loss: 0.1706, Val Loss: 0.2440
2024-12-29 13:03:32,483 - INFO - Epoch 25/1000, Train Loss: 0.1695, Val Loss: 0.2395
2024-12-29 13:03:32,743 - INFO - Epoch 26/1000, Train Loss: 0.1698, Val Loss: 0.2469
2024-12-29 13:03:32,956 - INFO - Epoch 27/1000, Train Loss: 0.1688, Val Loss: 0.2436
2024-12-29 13:03:33,210 - INFO - Epoch 28/1000, Train Loss: 0.1675, Val Loss: 0.2412
2024-12-29 13:03:33,437 - INFO - Epoch 29/1000, Train Loss: 0.1668, Val Loss: 0.2443
2024-12-29 13:03:33,644 - INFO - Epoch 30/1000, Train Loss: 0.1668, Val Loss: 0.2380
2024-12-29 13:03:33,869 - INFO - Epoch 31/1000, Train Loss: 0.1660, Val Loss: 0.2410
2024-12-29 13:03:34,062 - INFO - Epoch 32/1000, Train Loss: 0.1651, Val Loss: 0.2427
2024-12-29 13:03:34,292 - INFO - Epoch 33/1000, Train Loss: 0.1661, Val Loss: 0.2391
2024-12-29 13:03:34,557 - INFO - Epoch 34/1000, Train Loss: 0.1648, Val Loss: 0.2382
2024-12-29 13:03:34,745 - INFO - Epoch 35/1000, Train Loss: 0.1631, Val Loss: 0.2363
2024-12-29 13:03:34,993 - INFO - Epoch 36/1000, Train Loss: 0.1624, Val Loss: 0.2388
2024-12-29 13:03:35,186 - INFO - Epoch 37/1000, Train Loss: 0.1624, Val Loss: 0.2372
2024-12-29 13:03:35,382 - INFO - Epoch 38/1000, Train Loss: 0.1636, Val Loss: 0.2391
2024-12-29 13:03:35,600 - INFO - Epoch 39/1000, Train Loss: 0.1637, Val Loss: 0.2372
2024-12-29 13:03:35,827 - INFO - Epoch 40/1000, Train Loss: 0.1628, Val Loss: 0.2350
2024-12-29 13:03:36,047 - INFO - Epoch 41/1000, Train Loss: 0.1612, Val Loss: 0.2367
2024-12-29 13:03:36,281 - INFO - Epoch 42/1000, Train Loss: 0.1614, Val Loss: 0.2363
2024-12-29 13:03:36,497 - INFO - Epoch 43/1000, Train Loss: 0.1612, Val Loss: 0.2360
2024-12-29 13:03:36,702 - INFO - Epoch 44/1000, Train Loss: 0.1614, Val Loss: 0.2340
2024-12-29 13:03:36,920 - INFO - Epoch 45/1000, Train Loss: 0.1614, Val Loss: 0.2352
2024-12-29 13:03:36,920 - INFO - Early stopping triggered at epoch 45
2024-12-29 13:03:36,920 - INFO - Training completed in 9.92s
2024-12-29 13:03:36,921 - INFO - Final memory usage: CPU 2717.0 MB, GPU 105.1 MB
2024-12-29 13:03:36,924 - INFO - Model training completed in 9.92s
2024-12-29 13:03:36,988 - INFO - Prediction completed in 0.06s
2024-12-29 13:03:36,996 - INFO - Poison rate 0.03 completed in 14.85s
2024-12-29 13:03:36,996 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:03:36,998 - INFO - Total number of labels flipped: 420
2024-12-29 13:03:36,998 - INFO - Label flipping completed in 0.00s
2024-12-29 13:03:36,998 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:03:36,998 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:03:37,592 - INFO - Feature scaling completed in 0.59s
2024-12-29 13:03:37,592 - INFO - Starting feature selection (k=50)
2024-12-29 13:03:37,611 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 13:03:37,611 - INFO - Starting anomaly detection
2024-12-29 13:03:40,086 - INFO - Anomaly detection completed in 2.47s
2024-12-29 13:03:40,087 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:03:40,087 - INFO - Total fit_transform time: 3.09s
2024-12-29 13:03:40,087 - INFO - Training set processing completed in 3.09s
2024-12-29 13:03:40,087 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:03:40,088 - INFO - Memory usage at start_fit: CPU 2707.5 MB, GPU 105.0 MB
2024-12-29 13:03:40,088 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:03:40,091 - INFO - Number of unique classes: 10
2024-12-29 13:03:40,160 - INFO - Fitted scaler and transformed data
2024-12-29 13:03:40,160 - INFO - Scaling time: 0.07s
2024-12-29 13:03:40,385 - INFO - Epoch 1/1000, Train Loss: 0.6835, Val Loss: 0.3652
2024-12-29 13:03:40,619 - INFO - Epoch 2/1000, Train Loss: 0.3691, Val Loss: 0.3499
2024-12-29 13:03:40,869 - INFO - Epoch 3/1000, Train Loss: 0.3439, Val Loss: 0.3438
2024-12-29 13:03:41,118 - INFO - Epoch 4/1000, Train Loss: 0.3254, Val Loss: 0.3398
2024-12-29 13:03:41,345 - INFO - Epoch 5/1000, Train Loss: 0.3139, Val Loss: 0.3382
2024-12-29 13:03:41,561 - INFO - Epoch 6/1000, Train Loss: 0.3040, Val Loss: 0.3340
2024-12-29 13:03:41,749 - INFO - Epoch 7/1000, Train Loss: 0.2943, Val Loss: 0.3309
2024-12-29 13:03:41,966 - INFO - Epoch 8/1000, Train Loss: 0.2875, Val Loss: 0.3318
2024-12-29 13:03:42,274 - INFO - Epoch 9/1000, Train Loss: 0.2832, Val Loss: 0.3263
2024-12-29 13:03:42,535 - INFO - Epoch 10/1000, Train Loss: 0.2757, Val Loss: 0.3247
2024-12-29 13:03:42,779 - INFO - Epoch 11/1000, Train Loss: 0.2705, Val Loss: 0.3231
2024-12-29 13:03:43,112 - INFO - Epoch 12/1000, Train Loss: 0.2668, Val Loss: 0.3218
2024-12-29 13:03:43,409 - INFO - Epoch 13/1000, Train Loss: 0.2630, Val Loss: 0.3227
2024-12-29 13:03:43,696 - INFO - Epoch 14/1000, Train Loss: 0.2595, Val Loss: 0.3197
2024-12-29 13:03:43,961 - INFO - Epoch 15/1000, Train Loss: 0.2555, Val Loss: 0.3226
2024-12-29 13:03:44,279 - INFO - Epoch 16/1000, Train Loss: 0.2530, Val Loss: 0.3155
2024-12-29 13:03:44,607 - INFO - Epoch 17/1000, Train Loss: 0.2501, Val Loss: 0.3137
2024-12-29 13:03:44,934 - INFO - Epoch 18/1000, Train Loss: 0.2479, Val Loss: 0.3183
2024-12-29 13:03:45,137 - INFO - Epoch 19/1000, Train Loss: 0.2458, Val Loss: 0.3119
2024-12-29 13:03:45,389 - INFO - Epoch 20/1000, Train Loss: 0.2440, Val Loss: 0.3119
2024-12-29 13:03:45,608 - INFO - Epoch 21/1000, Train Loss: 0.2415, Val Loss: 0.3129
2024-12-29 13:03:45,835 - INFO - Epoch 22/1000, Train Loss: 0.2402, Val Loss: 0.3109
2024-12-29 13:03:46,111 - INFO - Epoch 23/1000, Train Loss: 0.2386, Val Loss: 0.3090
2024-12-29 13:03:46,445 - INFO - Epoch 24/1000, Train Loss: 0.2378, Val Loss: 0.3107
2024-12-29 13:03:46,739 - INFO - Epoch 25/1000, Train Loss: 0.2369, Val Loss: 0.3102
2024-12-29 13:03:46,979 - INFO - Epoch 26/1000, Train Loss: 0.2357, Val Loss: 0.3082
2024-12-29 13:03:47,260 - INFO - Epoch 27/1000, Train Loss: 0.2330, Val Loss: 0.3050
2024-12-29 13:03:47,503 - INFO - Epoch 28/1000, Train Loss: 0.2322, Val Loss: 0.3090
2024-12-29 13:03:47,765 - INFO - Epoch 29/1000, Train Loss: 0.2321, Val Loss: 0.3015
2024-12-29 13:03:48,044 - INFO - Epoch 30/1000, Train Loss: 0.2305, Val Loss: 0.3060
2024-12-29 13:03:48,412 - INFO - Epoch 31/1000, Train Loss: 0.2294, Val Loss: 0.3080
2024-12-29 13:03:48,721 - INFO - Epoch 32/1000, Train Loss: 0.2282, Val Loss: 0.3000
2024-12-29 13:03:49,004 - INFO - Epoch 33/1000, Train Loss: 0.2291, Val Loss: 0.3068
2024-12-29 13:03:49,342 - INFO - Epoch 34/1000, Train Loss: 0.2276, Val Loss: 0.3034
2024-12-29 13:03:49,681 - INFO - Epoch 35/1000, Train Loss: 0.2267, Val Loss: 0.3028
2024-12-29 13:03:49,888 - INFO - Epoch 36/1000, Train Loss: 0.2280, Val Loss: 0.3058
2024-12-29 13:03:50,183 - INFO - Epoch 37/1000, Train Loss: 0.2261, Val Loss: 0.3027
2024-12-29 13:03:50,183 - INFO - Early stopping triggered at epoch 37
2024-12-29 13:03:50,184 - INFO - Training completed in 10.10s
2024-12-29 13:03:50,184 - INFO - Final memory usage: CPU 2726.2 MB, GPU 105.1 MB
2024-12-29 13:03:50,186 - INFO - Model training completed in 10.10s
2024-12-29 13:03:50,256 - INFO - Prediction completed in 0.07s
2024-12-29 13:03:50,265 - INFO - Poison rate 0.05 completed in 13.27s
2024-12-29 13:03:50,265 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:03:50,266 - INFO - Total number of labels flipped: 589
2024-12-29 13:03:50,266 - INFO - Label flipping completed in 0.00s
2024-12-29 13:03:50,266 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:03:50,266 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:03:50,818 - INFO - Feature scaling completed in 0.55s
2024-12-29 13:03:50,818 - INFO - Starting feature selection (k=50)
2024-12-29 13:03:50,833 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 13:03:50,834 - INFO - Starting anomaly detection
2024-12-29 13:03:55,096 - INFO - Anomaly detection completed in 4.26s
2024-12-29 13:03:55,096 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:03:55,096 - INFO - Total fit_transform time: 4.83s
2024-12-29 13:03:55,096 - INFO - Training set processing completed in 4.83s
2024-12-29 13:03:55,096 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:03:55,097 - INFO - Memory usage at start_fit: CPU 2707.8 MB, GPU 105.0 MB
2024-12-29 13:03:55,097 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:03:55,100 - INFO - Number of unique classes: 10
2024-12-29 13:03:55,172 - INFO - Fitted scaler and transformed data
2024-12-29 13:03:55,173 - INFO - Scaling time: 0.07s
2024-12-29 13:03:55,352 - INFO - Epoch 1/1000, Train Loss: 0.7507, Val Loss: 0.5101
2024-12-29 13:03:55,556 - INFO - Epoch 2/1000, Train Loss: 0.4671, Val Loss: 0.4944
2024-12-29 13:03:55,740 - INFO - Epoch 3/1000, Train Loss: 0.4372, Val Loss: 0.4836
2024-12-29 13:03:55,936 - INFO - Epoch 4/1000, Train Loss: 0.4171, Val Loss: 0.4792
2024-12-29 13:03:56,127 - INFO - Epoch 5/1000, Train Loss: 0.4009, Val Loss: 0.4725
2024-12-29 13:03:56,327 - INFO - Epoch 6/1000, Train Loss: 0.3884, Val Loss: 0.4668
2024-12-29 13:03:56,525 - INFO - Epoch 7/1000, Train Loss: 0.3761, Val Loss: 0.4669
2024-12-29 13:03:56,768 - INFO - Epoch 8/1000, Train Loss: 0.3675, Val Loss: 0.4631
2024-12-29 13:03:57,040 - INFO - Epoch 9/1000, Train Loss: 0.3615, Val Loss: 0.4566
2024-12-29 13:03:57,394 - INFO - Epoch 10/1000, Train Loss: 0.3523, Val Loss: 0.4535
2024-12-29 13:03:57,776 - INFO - Epoch 11/1000, Train Loss: 0.3468, Val Loss: 0.4510
2024-12-29 13:03:58,099 - INFO - Epoch 12/1000, Train Loss: 0.3406, Val Loss: 0.4485
2024-12-29 13:03:58,370 - INFO - Epoch 13/1000, Train Loss: 0.3339, Val Loss: 0.4467
2024-12-29 13:03:58,612 - INFO - Epoch 14/1000, Train Loss: 0.3310, Val Loss: 0.4462
2024-12-29 13:03:58,848 - INFO - Epoch 15/1000, Train Loss: 0.3258, Val Loss: 0.4459
2024-12-29 13:03:59,103 - INFO - Epoch 16/1000, Train Loss: 0.3226, Val Loss: 0.4398
2024-12-29 13:03:59,314 - INFO - Epoch 17/1000, Train Loss: 0.3168, Val Loss: 0.4346
2024-12-29 13:03:59,549 - INFO - Epoch 18/1000, Train Loss: 0.3162, Val Loss: 0.4350
2024-12-29 13:03:59,785 - INFO - Epoch 19/1000, Train Loss: 0.3130, Val Loss: 0.4335
2024-12-29 13:04:00,011 - INFO - Epoch 20/1000, Train Loss: 0.3099, Val Loss: 0.4288
2024-12-29 13:04:00,213 - INFO - Epoch 21/1000, Train Loss: 0.3079, Val Loss: 0.4272
2024-12-29 13:04:00,437 - INFO - Epoch 22/1000, Train Loss: 0.3049, Val Loss: 0.4314
2024-12-29 13:04:00,704 - INFO - Epoch 23/1000, Train Loss: 0.3012, Val Loss: 0.4237
2024-12-29 13:04:00,974 - INFO - Epoch 24/1000, Train Loss: 0.3007, Val Loss: 0.4309
2024-12-29 13:04:01,205 - INFO - Epoch 25/1000, Train Loss: 0.2985, Val Loss: 0.4255
2024-12-29 13:04:01,421 - INFO - Epoch 26/1000, Train Loss: 0.2971, Val Loss: 0.4193
2024-12-29 13:04:01,631 - INFO - Epoch 27/1000, Train Loss: 0.2960, Val Loss: 0.4170
2024-12-29 13:04:01,836 - INFO - Epoch 28/1000, Train Loss: 0.2933, Val Loss: 0.4120
2024-12-29 13:04:02,046 - INFO - Epoch 29/1000, Train Loss: 0.2920, Val Loss: 0.4164
2024-12-29 13:04:02,263 - INFO - Epoch 30/1000, Train Loss: 0.2903, Val Loss: 0.4170
2024-12-29 13:04:02,507 - INFO - Epoch 31/1000, Train Loss: 0.2899, Val Loss: 0.4152
2024-12-29 13:04:02,714 - INFO - Epoch 32/1000, Train Loss: 0.2879, Val Loss: 0.4096
2024-12-29 13:04:02,914 - INFO - Epoch 33/1000, Train Loss: 0.2861, Val Loss: 0.4084
2024-12-29 13:04:03,119 - INFO - Epoch 34/1000, Train Loss: 0.2851, Val Loss: 0.4079
2024-12-29 13:04:03,315 - INFO - Epoch 35/1000, Train Loss: 0.2857, Val Loss: 0.4128
2024-12-29 13:04:03,539 - INFO - Epoch 36/1000, Train Loss: 0.2831, Val Loss: 0.4052
2024-12-29 13:04:03,750 - INFO - Epoch 37/1000, Train Loss: 0.2830, Val Loss: 0.4065
2024-12-29 13:04:03,967 - INFO - Epoch 38/1000, Train Loss: 0.2825, Val Loss: 0.4052
2024-12-29 13:04:04,204 - INFO - Epoch 39/1000, Train Loss: 0.2805, Val Loss: 0.4017
2024-12-29 13:04:04,408 - INFO - Epoch 40/1000, Train Loss: 0.2804, Val Loss: 0.4056
2024-12-29 13:04:04,624 - INFO - Epoch 41/1000, Train Loss: 0.2780, Val Loss: 0.4045
2024-12-29 13:04:04,844 - INFO - Epoch 42/1000, Train Loss: 0.2775, Val Loss: 0.4078
2024-12-29 13:04:05,061 - INFO - Epoch 43/1000, Train Loss: 0.2768, Val Loss: 0.3982
2024-12-29 13:04:05,273 - INFO - Epoch 44/1000, Train Loss: 0.2798, Val Loss: 0.4099
2024-12-29 13:04:05,539 - INFO - Epoch 45/1000, Train Loss: 0.2777, Val Loss: 0.3971
2024-12-29 13:04:05,765 - INFO - Epoch 46/1000, Train Loss: 0.2768, Val Loss: 0.3993
2024-12-29 13:04:06,018 - INFO - Epoch 47/1000, Train Loss: 0.2760, Val Loss: 0.3969
2024-12-29 13:04:06,276 - INFO - Epoch 48/1000, Train Loss: 0.2742, Val Loss: 0.4003
2024-12-29 13:04:06,572 - INFO - Epoch 49/1000, Train Loss: 0.2733, Val Loss: 0.4065
2024-12-29 13:04:06,826 - INFO - Epoch 50/1000, Train Loss: 0.2739, Val Loss: 0.3934
2024-12-29 13:04:07,070 - INFO - Epoch 51/1000, Train Loss: 0.2742, Val Loss: 0.3974
2024-12-29 13:04:07,322 - INFO - Epoch 52/1000, Train Loss: 0.2736, Val Loss: 0.3974
2024-12-29 13:04:07,633 - INFO - Epoch 53/1000, Train Loss: 0.2720, Val Loss: 0.3945
2024-12-29 13:04:07,942 - INFO - Epoch 54/1000, Train Loss: 0.2720, Val Loss: 0.3970
2024-12-29 13:04:08,226 - INFO - Epoch 55/1000, Train Loss: 0.2722, Val Loss: 0.3995
2024-12-29 13:04:08,226 - INFO - Early stopping triggered at epoch 55
2024-12-29 13:04:08,226 - INFO - Training completed in 13.13s
2024-12-29 13:04:08,226 - INFO - Final memory usage: CPU 2717.3 MB, GPU 105.1 MB
2024-12-29 13:04:08,227 - INFO - Model training completed in 13.13s
2024-12-29 13:04:08,272 - INFO - Prediction completed in 0.05s
2024-12-29 13:04:08,281 - INFO - Poison rate 0.07 completed in 18.02s
2024-12-29 13:04:08,281 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:04:08,282 - INFO - Total number of labels flipped: 838
2024-12-29 13:04:08,283 - INFO - Label flipping completed in 0.00s
2024-12-29 13:04:08,283 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:04:08,283 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:04:08,877 - INFO - Feature scaling completed in 0.59s
2024-12-29 13:04:08,877 - INFO - Starting feature selection (k=50)
2024-12-29 13:04:08,891 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:04:08,891 - INFO - Starting anomaly detection
2024-12-29 13:04:13,123 - INFO - Anomaly detection completed in 4.23s
2024-12-29 13:04:13,123 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:04:13,124 - INFO - Total fit_transform time: 4.84s
2024-12-29 13:04:13,124 - INFO - Training set processing completed in 4.84s
2024-12-29 13:04:13,124 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:04:13,125 - INFO - Memory usage at start_fit: CPU 2707.7 MB, GPU 105.0 MB
2024-12-29 13:04:13,125 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:04:13,127 - INFO - Number of unique classes: 10
2024-12-29 13:04:13,194 - INFO - Fitted scaler and transformed data
2024-12-29 13:04:13,194 - INFO - Scaling time: 0.07s
2024-12-29 13:04:13,395 - INFO - Epoch 1/1000, Train Loss: 0.8707, Val Loss: 0.6751
2024-12-29 13:04:13,617 - INFO - Epoch 2/1000, Train Loss: 0.5912, Val Loss: 0.6451
2024-12-29 13:04:13,856 - INFO - Epoch 3/1000, Train Loss: 0.5554, Val Loss: 0.6277
2024-12-29 13:04:14,066 - INFO - Epoch 4/1000, Train Loss: 0.5286, Val Loss: 0.6217
2024-12-29 13:04:14,286 - INFO - Epoch 5/1000, Train Loss: 0.5100, Val Loss: 0.6126
2024-12-29 13:04:14,523 - INFO - Epoch 6/1000, Train Loss: 0.4932, Val Loss: 0.6023
2024-12-29 13:04:14,748 - INFO - Epoch 7/1000, Train Loss: 0.4792, Val Loss: 0.5940
2024-12-29 13:04:14,984 - INFO - Epoch 8/1000, Train Loss: 0.4671, Val Loss: 0.5890
2024-12-29 13:04:15,172 - INFO - Epoch 9/1000, Train Loss: 0.4567, Val Loss: 0.5873
2024-12-29 13:04:15,384 - INFO - Epoch 10/1000, Train Loss: 0.4474, Val Loss: 0.5841
2024-12-29 13:04:15,596 - INFO - Epoch 11/1000, Train Loss: 0.4395, Val Loss: 0.5815
2024-12-29 13:04:15,842 - INFO - Epoch 12/1000, Train Loss: 0.4303, Val Loss: 0.5703
2024-12-29 13:04:16,062 - INFO - Epoch 13/1000, Train Loss: 0.4268, Val Loss: 0.5638
2024-12-29 13:04:16,266 - INFO - Epoch 14/1000, Train Loss: 0.4180, Val Loss: 0.5532
2024-12-29 13:04:16,477 - INFO - Epoch 15/1000, Train Loss: 0.4120, Val Loss: 0.5526
2024-12-29 13:04:16,705 - INFO - Epoch 16/1000, Train Loss: 0.4060, Val Loss: 0.5445
2024-12-29 13:04:16,963 - INFO - Epoch 17/1000, Train Loss: 0.4026, Val Loss: 0.5488
2024-12-29 13:04:17,167 - INFO - Epoch 18/1000, Train Loss: 0.3992, Val Loss: 0.5422
2024-12-29 13:04:17,375 - INFO - Epoch 19/1000, Train Loss: 0.3926, Val Loss: 0.5365
2024-12-29 13:04:17,588 - INFO - Epoch 20/1000, Train Loss: 0.3873, Val Loss: 0.5370
2024-12-29 13:04:17,827 - INFO - Epoch 21/1000, Train Loss: 0.3830, Val Loss: 0.5441
2024-12-29 13:04:18,056 - INFO - Epoch 22/1000, Train Loss: 0.3808, Val Loss: 0.5393
2024-12-29 13:04:18,285 - INFO - Epoch 23/1000, Train Loss: 0.3777, Val Loss: 0.5221
2024-12-29 13:04:18,493 - INFO - Epoch 24/1000, Train Loss: 0.3740, Val Loss: 0.5242
2024-12-29 13:04:18,741 - INFO - Epoch 25/1000, Train Loss: 0.3723, Val Loss: 0.5323
2024-12-29 13:04:18,984 - INFO - Epoch 26/1000, Train Loss: 0.3700, Val Loss: 0.5210
2024-12-29 13:04:19,258 - INFO - Epoch 27/1000, Train Loss: 0.3647, Val Loss: 0.5240
2024-12-29 13:04:19,509 - INFO - Epoch 28/1000, Train Loss: 0.3626, Val Loss: 0.5225
2024-12-29 13:04:19,722 - INFO - Epoch 29/1000, Train Loss: 0.3633, Val Loss: 0.5141
2024-12-29 13:04:19,973 - INFO - Epoch 30/1000, Train Loss: 0.3609, Val Loss: 0.5048
2024-12-29 13:04:20,178 - INFO - Epoch 31/1000, Train Loss: 0.3578, Val Loss: 0.5095
2024-12-29 13:04:20,452 - INFO - Epoch 32/1000, Train Loss: 0.3565, Val Loss: 0.5074
2024-12-29 13:04:20,725 - INFO - Epoch 33/1000, Train Loss: 0.3549, Val Loss: 0.5117
2024-12-29 13:04:21,049 - INFO - Epoch 34/1000, Train Loss: 0.3530, Val Loss: 0.4967
2024-12-29 13:04:21,298 - INFO - Epoch 35/1000, Train Loss: 0.3503, Val Loss: 0.5012
2024-12-29 13:04:21,605 - INFO - Epoch 36/1000, Train Loss: 0.3494, Val Loss: 0.4931
2024-12-29 13:04:21,853 - INFO - Epoch 37/1000, Train Loss: 0.3481, Val Loss: 0.5008
2024-12-29 13:04:22,061 - INFO - Epoch 38/1000, Train Loss: 0.3480, Val Loss: 0.4994
2024-12-29 13:04:22,338 - INFO - Epoch 39/1000, Train Loss: 0.3448, Val Loss: 0.5000
2024-12-29 13:04:22,628 - INFO - Epoch 40/1000, Train Loss: 0.3445, Val Loss: 0.4922
2024-12-29 13:04:22,874 - INFO - Epoch 41/1000, Train Loss: 0.3431, Val Loss: 0.4838
2024-12-29 13:04:23,142 - INFO - Epoch 42/1000, Train Loss: 0.3417, Val Loss: 0.4925
2024-12-29 13:04:23,425 - INFO - Epoch 43/1000, Train Loss: 0.3404, Val Loss: 0.4862
2024-12-29 13:04:23,675 - INFO - Epoch 44/1000, Train Loss: 0.3401, Val Loss: 0.4857
2024-12-29 13:04:23,942 - INFO - Epoch 45/1000, Train Loss: 0.3392, Val Loss: 0.4903
2024-12-29 13:04:24,215 - INFO - Epoch 46/1000, Train Loss: 0.3386, Val Loss: 0.4860
2024-12-29 13:04:24,215 - INFO - Early stopping triggered at epoch 46
2024-12-29 13:04:24,215 - INFO - Training completed in 11.09s
2024-12-29 13:04:24,216 - INFO - Final memory usage: CPU 2726.5 MB, GPU 105.1 MB
2024-12-29 13:04:24,217 - INFO - Model training completed in 11.09s
2024-12-29 13:04:24,285 - INFO - Prediction completed in 0.07s
2024-12-29 13:04:24,296 - INFO - Poison rate 0.1 completed in 16.01s
2024-12-29 13:04:24,296 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:04:24,297 - INFO - Total number of labels flipped: 1700
2024-12-29 13:04:24,297 - INFO - Label flipping completed in 0.00s
2024-12-29 13:04:24,298 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:04:24,298 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:04:24,882 - INFO - Feature scaling completed in 0.58s
2024-12-29 13:04:24,882 - INFO - Starting feature selection (k=50)
2024-12-29 13:04:24,897 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:04:24,897 - INFO - Starting anomaly detection
2024-12-29 13:04:29,232 - INFO - Anomaly detection completed in 4.33s
2024-12-29 13:04:29,232 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:04:29,232 - INFO - Total fit_transform time: 4.93s
2024-12-29 13:04:29,232 - INFO - Training set processing completed in 4.93s
2024-12-29 13:04:29,232 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:04:29,233 - INFO - Memory usage at start_fit: CPU 2707.9 MB, GPU 105.0 MB
2024-12-29 13:04:29,233 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:04:29,236 - INFO - Number of unique classes: 10
2024-12-29 13:04:29,306 - INFO - Fitted scaler and transformed data
2024-12-29 13:04:29,306 - INFO - Scaling time: 0.07s
2024-12-29 13:04:29,546 - INFO - Epoch 1/1000, Train Loss: 1.1806, Val Loss: 0.9935
2024-12-29 13:04:29,772 - INFO - Epoch 2/1000, Train Loss: 0.9522, Val Loss: 0.9521
2024-12-29 13:04:30,031 - INFO - Epoch 3/1000, Train Loss: 0.9039, Val Loss: 0.9270
2024-12-29 13:04:30,238 - INFO - Epoch 4/1000, Train Loss: 0.8677, Val Loss: 0.9145
2024-12-29 13:04:30,471 - INFO - Epoch 5/1000, Train Loss: 0.8372, Val Loss: 0.8973
2024-12-29 13:04:30,684 - INFO - Epoch 6/1000, Train Loss: 0.8094, Val Loss: 0.8750
2024-12-29 13:04:30,955 - INFO - Epoch 7/1000, Train Loss: 0.7888, Val Loss: 0.8689
2024-12-29 13:04:31,204 - INFO - Epoch 8/1000, Train Loss: 0.7667, Val Loss: 0.8563
2024-12-29 13:04:31,417 - INFO - Epoch 9/1000, Train Loss: 0.7472, Val Loss: 0.8460
2024-12-29 13:04:31,711 - INFO - Epoch 10/1000, Train Loss: 0.7294, Val Loss: 0.8461
2024-12-29 13:04:31,940 - INFO - Epoch 11/1000, Train Loss: 0.7134, Val Loss: 0.8351
2024-12-29 13:04:32,163 - INFO - Epoch 12/1000, Train Loss: 0.6992, Val Loss: 0.8167
2024-12-29 13:04:32,385 - INFO - Epoch 13/1000, Train Loss: 0.6828, Val Loss: 0.8108
2024-12-29 13:04:32,597 - INFO - Epoch 14/1000, Train Loss: 0.6726, Val Loss: 0.7858
2024-12-29 13:04:32,805 - INFO - Epoch 15/1000, Train Loss: 0.6591, Val Loss: 0.7824
2024-12-29 13:04:33,067 - INFO - Epoch 16/1000, Train Loss: 0.6450, Val Loss: 0.7825
2024-12-29 13:04:33,305 - INFO - Epoch 17/1000, Train Loss: 0.6405, Val Loss: 0.7558
2024-12-29 13:04:33,572 - INFO - Epoch 18/1000, Train Loss: 0.6297, Val Loss: 0.7582
2024-12-29 13:04:33,772 - INFO - Epoch 19/1000, Train Loss: 0.6219, Val Loss: 0.7677
2024-12-29 13:04:34,019 - INFO - Epoch 20/1000, Train Loss: 0.6160, Val Loss: 0.7432
2024-12-29 13:04:34,243 - INFO - Epoch 21/1000, Train Loss: 0.6059, Val Loss: 0.7394
2024-12-29 13:04:34,517 - INFO - Epoch 22/1000, Train Loss: 0.5978, Val Loss: 0.7347
2024-12-29 13:04:34,777 - INFO - Epoch 23/1000, Train Loss: 0.5894, Val Loss: 0.7185
2024-12-29 13:04:34,988 - INFO - Epoch 24/1000, Train Loss: 0.5856, Val Loss: 0.7311
2024-12-29 13:04:35,208 - INFO - Epoch 25/1000, Train Loss: 0.5808, Val Loss: 0.7220
2024-12-29 13:04:35,440 - INFO - Epoch 26/1000, Train Loss: 0.5749, Val Loss: 0.7152
2024-12-29 13:04:35,653 - INFO - Epoch 27/1000, Train Loss: 0.5710, Val Loss: 0.7198
2024-12-29 13:04:35,906 - INFO - Epoch 28/1000, Train Loss: 0.5683, Val Loss: 0.7095
2024-12-29 13:04:36,132 - INFO - Epoch 29/1000, Train Loss: 0.5632, Val Loss: 0.7098
2024-12-29 13:04:36,393 - INFO - Epoch 30/1000, Train Loss: 0.5610, Val Loss: 0.7074
2024-12-29 13:04:36,644 - INFO - Epoch 31/1000, Train Loss: 0.5563, Val Loss: 0.6962
2024-12-29 13:04:36,930 - INFO - Epoch 32/1000, Train Loss: 0.5528, Val Loss: 0.7020
2024-12-29 13:04:37,175 - INFO - Epoch 33/1000, Train Loss: 0.5511, Val Loss: 0.6956
2024-12-29 13:04:37,493 - INFO - Epoch 34/1000, Train Loss: 0.5477, Val Loss: 0.6872
2024-12-29 13:04:37,745 - INFO - Epoch 35/1000, Train Loss: 0.5433, Val Loss: 0.6794
2024-12-29 13:04:37,951 - INFO - Epoch 36/1000, Train Loss: 0.5406, Val Loss: 0.6991
2024-12-29 13:04:38,151 - INFO - Epoch 37/1000, Train Loss: 0.5393, Val Loss: 0.6793
2024-12-29 13:04:38,341 - INFO - Epoch 38/1000, Train Loss: 0.5353, Val Loss: 0.6730
2024-12-29 13:04:38,551 - INFO - Epoch 39/1000, Train Loss: 0.5331, Val Loss: 0.6965
2024-12-29 13:04:38,807 - INFO - Epoch 40/1000, Train Loss: 0.5325, Val Loss: 0.6773
2024-12-29 13:04:39,055 - INFO - Epoch 41/1000, Train Loss: 0.5285, Val Loss: 0.6839
2024-12-29 13:04:39,313 - INFO - Epoch 42/1000, Train Loss: 0.5297, Val Loss: 0.6730
2024-12-29 13:04:39,545 - INFO - Epoch 43/1000, Train Loss: 0.5279, Val Loss: 0.6704
2024-12-29 13:04:39,773 - INFO - Epoch 44/1000, Train Loss: 0.5243, Val Loss: 0.6723
2024-12-29 13:04:40,031 - INFO - Epoch 45/1000, Train Loss: 0.5245, Val Loss: 0.6801
2024-12-29 13:04:40,273 - INFO - Epoch 46/1000, Train Loss: 0.5188, Val Loss: 0.6729
2024-12-29 13:04:40,485 - INFO - Epoch 47/1000, Train Loss: 0.5203, Val Loss: 0.6640
2024-12-29 13:04:40,742 - INFO - Epoch 48/1000, Train Loss: 0.5187, Val Loss: 0.6663
2024-12-29 13:04:41,037 - INFO - Epoch 49/1000, Train Loss: 0.5166, Val Loss: 0.6594
2024-12-29 13:04:41,298 - INFO - Epoch 50/1000, Train Loss: 0.5172, Val Loss: 0.6713
2024-12-29 13:04:41,546 - INFO - Epoch 51/1000, Train Loss: 0.5153, Val Loss: 0.6597
2024-12-29 13:04:41,836 - INFO - Epoch 52/1000, Train Loss: 0.5118, Val Loss: 0.6795
2024-12-29 13:04:42,113 - INFO - Epoch 53/1000, Train Loss: 0.5152, Val Loss: 0.6633
2024-12-29 13:04:42,305 - INFO - Epoch 54/1000, Train Loss: 0.5124, Val Loss: 0.6518
2024-12-29 13:04:42,560 - INFO - Epoch 55/1000, Train Loss: 0.5086, Val Loss: 0.6668
2024-12-29 13:04:42,777 - INFO - Epoch 56/1000, Train Loss: 0.5084, Val Loss: 0.6593
2024-12-29 13:04:42,998 - INFO - Epoch 57/1000, Train Loss: 0.5088, Val Loss: 0.6589
2024-12-29 13:04:43,216 - INFO - Epoch 58/1000, Train Loss: 0.5099, Val Loss: 0.6622
2024-12-29 13:04:43,432 - INFO - Epoch 59/1000, Train Loss: 0.5073, Val Loss: 0.6535
2024-12-29 13:04:43,432 - INFO - Early stopping triggered at epoch 59
2024-12-29 13:04:43,432 - INFO - Training completed in 14.20s
2024-12-29 13:04:43,433 - INFO - Final memory usage: CPU 2717.1 MB, GPU 105.1 MB
2024-12-29 13:04:43,436 - INFO - Model training completed in 14.20s
2024-12-29 13:04:43,501 - INFO - Prediction completed in 0.07s
2024-12-29 13:04:43,510 - INFO - Poison rate 0.2 completed in 19.21s
2024-12-29 13:04:43,512 - INFO - Loaded 77 existing results
2024-12-29 13:04:43,512 - INFO - Total results to save: 84
2024-12-29 13:04:43,513 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:04:43,516 - INFO - Saved 84 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:04:43,516 - INFO - Total evaluation time: 127.57s
2024-12-29 13:04:43,518 - INFO - 
Progress: 13.5% - Evaluating GTSRB with RandomForest (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:04:43,712 - INFO - Loading datasets...
2024-12-29 13:04:43,734 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:04:43,734 - INFO - Extracting validation features...
2024-12-29 13:04:43,734 - INFO - Extracting features from 3925 samples...
2024-12-29 13:04:52,975 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:04:52,981 - INFO - Validation feature extraction completed in 9.25s
2024-12-29 13:04:52,981 - INFO - Extracting training features...
2024-12-29 13:04:52,981 - INFO - Extracting features from 9469 samples...
2024-12-29 13:05:14,634 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:05:14,642 - INFO - Training feature extraction completed in 21.66s
2024-12-29 13:05:14,643 - INFO - Creating model for classifier: RandomForest
2024-12-29 13:05:14,643 - INFO - Using device: cuda
2024-12-29 13:05:14,643 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:05:14,643 - INFO - Training set processing completed in 0.00s
2024-12-29 13:05:14,644 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:05:14,645 - INFO - Memory usage at start_fit: CPU 2689.5 MB, GPU 104.0 MB
2024-12-29 13:05:14,645 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:05:14,853 - INFO - Fitted scaler and transformed data
2024-12-29 13:05:14,853 - INFO - Scaling time: 0.21s
2024-12-29 13:05:14,861 - INFO - Number of unique classes: 10
2024-12-29 13:05:17,987 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3013
2024-12-29 13:05:21,470 - INFO - Epoch 2/10, Train Loss: 2.3005, Val Loss: 2.3000
2024-12-29 13:05:25,163 - INFO - Epoch 3/10, Train Loss: 2.2991, Val Loss: 2.2987
2024-12-29 13:05:29,114 - INFO - Epoch 4/10, Train Loss: 2.2977, Val Loss: 2.2974
2024-12-29 13:05:29,115 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:05:29,115 - INFO - Training completed in 14.47s
2024-12-29 13:05:29,115 - INFO - Final memory usage: CPU 2708.0 MB, GPU 125.9 MB
2024-12-29 13:05:29,115 - INFO - Model training completed in 14.47s
2024-12-29 13:05:29,280 - INFO - Prediction completed in 0.16s
2024-12-29 13:05:29,289 - INFO - Poison rate 0.0 completed in 14.65s
2024-12-29 13:05:29,289 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:05:29,290 - INFO - Total number of labels flipped: 86
2024-12-29 13:05:29,290 - INFO - Label flipping completed in 0.00s
2024-12-29 13:05:29,290 - INFO - Training set processing completed in 0.00s
2024-12-29 13:05:29,290 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:05:29,291 - INFO - Memory usage at start_fit: CPU 2708.0 MB, GPU 106.0 MB
2024-12-29 13:05:29,291 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:05:29,511 - INFO - Fitted scaler and transformed data
2024-12-29 13:05:29,511 - INFO - Scaling time: 0.22s
2024-12-29 13:05:29,522 - INFO - Number of unique classes: 10
2024-12-29 13:05:33,617 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3013
2024-12-29 13:05:37,642 - INFO - Epoch 2/10, Train Loss: 2.3006, Val Loss: 2.3000
2024-12-29 13:05:41,531 - INFO - Epoch 3/10, Train Loss: 2.2992, Val Loss: 2.2987
2024-12-29 13:05:45,476 - INFO - Epoch 4/10, Train Loss: 2.2978, Val Loss: 2.2974
2024-12-29 13:05:45,476 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:05:45,476 - INFO - Training completed in 16.19s
2024-12-29 13:05:45,477 - INFO - Final memory usage: CPU 2708.1 MB, GPU 125.9 MB
2024-12-29 13:05:45,477 - INFO - Model training completed in 16.19s
2024-12-29 13:05:45,743 - INFO - Prediction completed in 0.27s
2024-12-29 13:05:45,751 - INFO - Poison rate 0.01 completed in 16.46s
2024-12-29 13:05:45,751 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:05:45,752 - INFO - Total number of labels flipped: 253
2024-12-29 13:05:45,752 - INFO - Label flipping completed in 0.00s
2024-12-29 13:05:45,753 - INFO - Training set processing completed in 0.00s
2024-12-29 13:05:45,753 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:05:45,754 - INFO - Memory usage at start_fit: CPU 2708.1 MB, GPU 106.0 MB
2024-12-29 13:05:45,754 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:05:45,967 - INFO - Fitted scaler and transformed data
2024-12-29 13:05:45,968 - INFO - Scaling time: 0.21s
2024-12-29 13:05:45,978 - INFO - Number of unique classes: 10
2024-12-29 13:05:49,688 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3014
2024-12-29 13:05:52,958 - INFO - Epoch 2/10, Train Loss: 2.3006, Val Loss: 2.3001
2024-12-29 13:05:56,283 - INFO - Epoch 3/10, Train Loss: 2.2993, Val Loss: 2.2988
2024-12-29 13:05:59,415 - INFO - Epoch 4/10, Train Loss: 2.2979, Val Loss: 2.2976
2024-12-29 13:05:59,416 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:05:59,416 - INFO - Training completed in 13.66s
2024-12-29 13:05:59,416 - INFO - Final memory usage: CPU 2708.1 MB, GPU 125.9 MB
2024-12-29 13:05:59,416 - INFO - Model training completed in 13.66s
2024-12-29 13:05:59,602 - INFO - Prediction completed in 0.19s
2024-12-29 13:05:59,611 - INFO - Poison rate 0.03 completed in 13.86s
2024-12-29 13:05:59,611 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:05:59,613 - INFO - Total number of labels flipped: 417
2024-12-29 13:05:59,613 - INFO - Label flipping completed in 0.00s
2024-12-29 13:05:59,613 - INFO - Training set processing completed in 0.00s
2024-12-29 13:05:59,613 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:05:59,614 - INFO - Memory usage at start_fit: CPU 2708.1 MB, GPU 106.0 MB
2024-12-29 13:05:59,614 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:05:59,820 - INFO - Fitted scaler and transformed data
2024-12-29 13:05:59,820 - INFO - Scaling time: 0.21s
2024-12-29 13:05:59,831 - INFO - Number of unique classes: 10
2024-12-29 13:06:02,863 - INFO - Epoch 1/10, Train Loss: 2.3021, Val Loss: 2.3015
2024-12-29 13:06:05,567 - INFO - Epoch 2/10, Train Loss: 2.3007, Val Loss: 2.3003
2024-12-29 13:06:08,704 - INFO - Epoch 3/10, Train Loss: 2.2994, Val Loss: 2.2991
2024-12-29 13:06:11,471 - INFO - Epoch 4/10, Train Loss: 2.2981, Val Loss: 2.2979
2024-12-29 13:06:11,472 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:06:11,472 - INFO - Training completed in 11.86s
2024-12-29 13:06:11,472 - INFO - Final memory usage: CPU 2708.1 MB, GPU 125.9 MB
2024-12-29 13:06:11,472 - INFO - Model training completed in 11.86s
2024-12-29 13:06:11,635 - INFO - Prediction completed in 0.16s
2024-12-29 13:06:11,644 - INFO - Poison rate 0.05 completed in 12.03s
2024-12-29 13:06:11,644 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:06:11,645 - INFO - Total number of labels flipped: 599
2024-12-29 13:06:11,645 - INFO - Label flipping completed in 0.00s
2024-12-29 13:06:11,646 - INFO - Training set processing completed in 0.00s
2024-12-29 13:06:11,646 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:06:11,646 - INFO - Memory usage at start_fit: CPU 2708.1 MB, GPU 106.0 MB
2024-12-29 13:06:11,647 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:06:11,821 - INFO - Fitted scaler and transformed data
2024-12-29 13:06:11,821 - INFO - Scaling time: 0.17s
2024-12-29 13:06:11,831 - INFO - Number of unique classes: 10
2024-12-29 13:06:14,717 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3014
2024-12-29 13:06:17,242 - INFO - Epoch 2/10, Train Loss: 2.3007, Val Loss: 2.3002
2024-12-29 13:06:20,097 - INFO - Epoch 3/10, Train Loss: 2.2994, Val Loss: 2.2990
2024-12-29 13:06:23,049 - INFO - Epoch 4/10, Train Loss: 2.2981, Val Loss: 2.2978
2024-12-29 13:06:23,049 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:06:23,049 - INFO - Training completed in 11.40s
2024-12-29 13:06:23,049 - INFO - Final memory usage: CPU 2708.1 MB, GPU 125.9 MB
2024-12-29 13:06:23,050 - INFO - Model training completed in 11.40s
2024-12-29 13:06:23,207 - INFO - Prediction completed in 0.16s
2024-12-29 13:06:23,216 - INFO - Poison rate 0.07 completed in 11.57s
2024-12-29 13:06:23,216 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:06:23,217 - INFO - Total number of labels flipped: 847
2024-12-29 13:06:23,217 - INFO - Label flipping completed in 0.00s
2024-12-29 13:06:23,218 - INFO - Training set processing completed in 0.00s
2024-12-29 13:06:23,218 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:06:23,218 - INFO - Memory usage at start_fit: CPU 2708.1 MB, GPU 106.0 MB
2024-12-29 13:06:23,218 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:06:23,419 - INFO - Fitted scaler and transformed data
2024-12-29 13:06:23,419 - INFO - Scaling time: 0.20s
2024-12-29 13:06:23,429 - INFO - Number of unique classes: 10
2024-12-29 13:06:26,443 - INFO - Epoch 1/10, Train Loss: 2.3021, Val Loss: 2.3014
2024-12-29 13:06:29,012 - INFO - Epoch 2/10, Train Loss: 2.3007, Val Loss: 2.3003
2024-12-29 13:06:32,055 - INFO - Epoch 3/10, Train Loss: 2.2995, Val Loss: 2.2991
2024-12-29 13:06:35,055 - INFO - Epoch 4/10, Train Loss: 2.2981, Val Loss: 2.2980
2024-12-29 13:06:35,055 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:06:35,055 - INFO - Training completed in 11.84s
2024-12-29 13:06:35,055 - INFO - Final memory usage: CPU 2708.1 MB, GPU 125.9 MB
2024-12-29 13:06:35,056 - INFO - Model training completed in 11.84s
2024-12-29 13:06:35,292 - INFO - Prediction completed in 0.24s
2024-12-29 13:06:35,301 - INFO - Poison rate 0.1 completed in 12.08s
2024-12-29 13:06:35,301 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:06:35,302 - INFO - Total number of labels flipped: 1691
2024-12-29 13:06:35,303 - INFO - Label flipping completed in 0.00s
2024-12-29 13:06:35,303 - INFO - Training set processing completed in 0.00s
2024-12-29 13:06:35,303 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:06:35,303 - INFO - Memory usage at start_fit: CPU 2708.1 MB, GPU 106.0 MB
2024-12-29 13:06:35,303 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:06:35,503 - INFO - Fitted scaler and transformed data
2024-12-29 13:06:35,503 - INFO - Scaling time: 0.20s
2024-12-29 13:06:35,513 - INFO - Number of unique classes: 10
2024-12-29 13:06:38,310 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3014
2024-12-29 13:06:42,719 - INFO - Epoch 2/10, Train Loss: 2.3007, Val Loss: 2.3003
2024-12-29 13:06:46,401 - INFO - Epoch 3/10, Train Loss: 2.2994, Val Loss: 2.2991
2024-12-29 13:06:50,345 - INFO - Epoch 4/10, Train Loss: 2.2981, Val Loss: 2.2979
2024-12-29 13:06:50,345 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:06:50,345 - INFO - Training completed in 15.04s
2024-12-29 13:06:50,345 - INFO - Final memory usage: CPU 2708.1 MB, GPU 125.9 MB
2024-12-29 13:06:50,346 - INFO - Model training completed in 15.04s
2024-12-29 13:06:50,560 - INFO - Prediction completed in 0.21s
2024-12-29 13:06:50,572 - INFO - Poison rate 0.2 completed in 15.27s
2024-12-29 13:06:50,574 - INFO - Loaded 84 existing results
2024-12-29 13:06:50,574 - INFO - Total results to save: 91
2024-12-29 13:06:50,575 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:06:50,578 - INFO - Saved 91 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:06:50,578 - INFO - Total evaluation time: 126.87s
2024-12-29 13:06:50,580 - INFO - 
Progress: 14.6% - Evaluating GTSRB with RandomForest (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:06:50,786 - INFO - Loading datasets...
2024-12-29 13:06:50,808 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:06:50,808 - INFO - Extracting validation features...
2024-12-29 13:06:50,808 - INFO - Extracting features from 3925 samples...
2024-12-29 13:06:59,882 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:06:59,888 - INFO - Validation feature extraction completed in 9.08s
2024-12-29 13:06:59,888 - INFO - Extracting training features...
2024-12-29 13:06:59,888 - INFO - Extracting features from 9469 samples...
2024-12-29 13:07:20,950 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:07:20,958 - INFO - Training feature extraction completed in 21.07s
2024-12-29 13:07:20,959 - INFO - Creating model for classifier: RandomForest
2024-12-29 13:07:20,959 - INFO - Using device: cuda
2024-12-29 13:07:20,959 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:07:20,959 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:07:20,959 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:07:21,519 - INFO - Feature scaling completed in 0.56s
2024-12-29 13:07:21,519 - INFO - Starting feature selection (k=50)
2024-12-29 13:07:21,537 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 13:07:21,537 - INFO - Starting anomaly detection
2024-12-29 13:07:24,782 - INFO - Anomaly detection completed in 3.24s
2024-12-29 13:07:24,783 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:07:24,783 - INFO - Total fit_transform time: 3.82s
2024-12-29 13:07:24,783 - INFO - Training set processing completed in 3.82s
2024-12-29 13:07:24,784 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:07:24,785 - INFO - Memory usage at start_fit: CPU 2707.8 MB, GPU 104.0 MB
2024-12-29 13:07:24,785 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:07:24,986 - INFO - Fitted scaler and transformed data
2024-12-29 13:07:24,987 - INFO - Scaling time: 0.20s
2024-12-29 13:07:24,994 - INFO - Number of unique classes: 10
2024-12-29 13:07:27,724 - INFO - Epoch 1/10, Train Loss: 2.1870, Val Loss: 2.3013
2024-12-29 13:07:30,946 - INFO - Epoch 2/10, Train Loss: 2.1857, Val Loss: 2.3000
2024-12-29 13:07:34,125 - INFO - Epoch 3/10, Train Loss: 2.1843, Val Loss: 2.2986
2024-12-29 13:07:36,882 - INFO - Epoch 4/10, Train Loss: 2.1830, Val Loss: 2.2973
2024-12-29 13:07:36,882 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:07:36,882 - INFO - Training completed in 12.10s
2024-12-29 13:07:36,883 - INFO - Final memory usage: CPU 2707.9 MB, GPU 125.9 MB
2024-12-29 13:07:36,883 - INFO - Model training completed in 12.10s
2024-12-29 13:07:37,100 - INFO - Prediction completed in 0.22s
2024-12-29 13:07:37,109 - INFO - Poison rate 0.0 completed in 16.15s
2024-12-29 13:07:37,109 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:07:37,110 - INFO - Total number of labels flipped: 79
2024-12-29 13:07:37,110 - INFO - Label flipping completed in 0.00s
2024-12-29 13:07:37,110 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:07:37,111 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:07:37,659 - INFO - Feature scaling completed in 0.55s
2024-12-29 13:07:37,659 - INFO - Starting feature selection (k=50)
2024-12-29 13:07:37,673 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:07:37,673 - INFO - Starting anomaly detection
2024-12-29 13:07:41,922 - INFO - Anomaly detection completed in 4.25s
2024-12-29 13:07:41,922 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:07:41,922 - INFO - Total fit_transform time: 4.81s
2024-12-29 13:07:41,922 - INFO - Training set processing completed in 4.81s
2024-12-29 13:07:41,922 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:07:41,924 - INFO - Memory usage at start_fit: CPU 2707.9 MB, GPU 106.0 MB
2024-12-29 13:07:41,924 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:07:42,104 - INFO - Fitted scaler and transformed data
2024-12-29 13:07:42,104 - INFO - Scaling time: 0.18s
2024-12-29 13:07:42,111 - INFO - Number of unique classes: 10
2024-12-29 13:07:46,443 - INFO - Epoch 1/10, Train Loss: 2.1861, Val Loss: 2.3014
2024-12-29 13:07:49,638 - INFO - Epoch 2/10, Train Loss: 2.1847, Val Loss: 2.3001
2024-12-29 13:07:53,062 - INFO - Epoch 3/10, Train Loss: 2.1834, Val Loss: 2.2989
2024-12-29 13:07:56,313 - INFO - Epoch 4/10, Train Loss: 2.1821, Val Loss: 2.2977
2024-12-29 13:07:56,313 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:07:56,313 - INFO - Training completed in 14.39s
2024-12-29 13:07:56,314 - INFO - Final memory usage: CPU 2707.9 MB, GPU 125.9 MB
2024-12-29 13:07:56,314 - INFO - Model training completed in 14.39s
2024-12-29 13:07:56,459 - INFO - Prediction completed in 0.14s
2024-12-29 13:07:56,468 - INFO - Poison rate 0.01 completed in 19.36s
2024-12-29 13:07:56,468 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:07:56,469 - INFO - Total number of labels flipped: 252
2024-12-29 13:07:56,469 - INFO - Label flipping completed in 0.00s
2024-12-29 13:07:56,469 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:07:56,469 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:07:56,993 - INFO - Feature scaling completed in 0.52s
2024-12-29 13:07:56,994 - INFO - Starting feature selection (k=50)
2024-12-29 13:07:57,007 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:07:57,007 - INFO - Starting anomaly detection
2024-12-29 13:08:01,306 - INFO - Anomaly detection completed in 4.30s
2024-12-29 13:08:01,306 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:08:01,306 - INFO - Total fit_transform time: 4.84s
2024-12-29 13:08:01,306 - INFO - Training set processing completed in 4.84s
2024-12-29 13:08:01,306 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:08:01,307 - INFO - Memory usage at start_fit: CPU 2707.9 MB, GPU 106.0 MB
2024-12-29 13:08:01,307 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:08:01,481 - INFO - Fitted scaler and transformed data
2024-12-29 13:08:01,481 - INFO - Scaling time: 0.17s
2024-12-29 13:08:01,490 - INFO - Number of unique classes: 10
2024-12-29 13:08:04,406 - INFO - Epoch 1/10, Train Loss: 2.1893, Val Loss: 2.3013
2024-12-29 13:08:07,346 - INFO - Epoch 2/10, Train Loss: 2.1880, Val Loss: 2.3001
2024-12-29 13:08:10,488 - INFO - Epoch 3/10, Train Loss: 2.1868, Val Loss: 2.2988
2024-12-29 13:08:14,045 - INFO - Epoch 4/10, Train Loss: 2.1855, Val Loss: 2.2976
2024-12-29 13:08:14,046 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:08:14,046 - INFO - Training completed in 12.74s
2024-12-29 13:08:14,046 - INFO - Final memory usage: CPU 2707.9 MB, GPU 125.9 MB
2024-12-29 13:08:14,046 - INFO - Model training completed in 12.74s
2024-12-29 13:08:14,254 - INFO - Prediction completed in 0.21s
2024-12-29 13:08:14,263 - INFO - Poison rate 0.03 completed in 17.80s
2024-12-29 13:08:14,264 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:08:14,265 - INFO - Total number of labels flipped: 432
2024-12-29 13:08:14,265 - INFO - Label flipping completed in 0.00s
2024-12-29 13:08:14,265 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:08:14,265 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:08:14,874 - INFO - Feature scaling completed in 0.61s
2024-12-29 13:08:14,874 - INFO - Starting feature selection (k=50)
2024-12-29 13:08:14,887 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:08:14,888 - INFO - Starting anomaly detection
2024-12-29 13:08:18,000 - INFO - Anomaly detection completed in 3.11s
2024-12-29 13:08:18,000 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:08:18,001 - INFO - Total fit_transform time: 3.74s
2024-12-29 13:08:18,001 - INFO - Training set processing completed in 3.74s
2024-12-29 13:08:18,001 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:08:18,001 - INFO - Memory usage at start_fit: CPU 2707.9 MB, GPU 106.0 MB
2024-12-29 13:08:18,002 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:08:18,197 - INFO - Fitted scaler and transformed data
2024-12-29 13:08:18,198 - INFO - Scaling time: 0.20s
2024-12-29 13:08:18,204 - INFO - Number of unique classes: 10
2024-12-29 13:08:21,059 - INFO - Epoch 1/10, Train Loss: 2.1881, Val Loss: 2.3014
2024-12-29 13:08:24,038 - INFO - Epoch 2/10, Train Loss: 2.1868, Val Loss: 2.3003
2024-12-29 13:08:27,582 - INFO - Epoch 3/10, Train Loss: 2.1855, Val Loss: 2.2990
2024-12-29 13:08:31,305 - INFO - Epoch 4/10, Train Loss: 2.1843, Val Loss: 2.2978
2024-12-29 13:08:31,305 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:08:31,305 - INFO - Training completed in 13.30s
2024-12-29 13:08:31,306 - INFO - Final memory usage: CPU 2707.9 MB, GPU 125.9 MB
2024-12-29 13:08:31,306 - INFO - Model training completed in 13.31s
2024-12-29 13:08:31,541 - INFO - Prediction completed in 0.23s
2024-12-29 13:08:31,549 - INFO - Poison rate 0.05 completed in 17.29s
2024-12-29 13:08:31,550 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:08:31,551 - INFO - Total number of labels flipped: 599
2024-12-29 13:08:31,551 - INFO - Label flipping completed in 0.00s
2024-12-29 13:08:31,551 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:08:31,551 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:08:32,107 - INFO - Feature scaling completed in 0.56s
2024-12-29 13:08:32,107 - INFO - Starting feature selection (k=50)
2024-12-29 13:08:32,120 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:08:32,120 - INFO - Starting anomaly detection
2024-12-29 13:08:35,491 - INFO - Anomaly detection completed in 3.37s
2024-12-29 13:08:35,492 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:08:35,492 - INFO - Total fit_transform time: 3.94s
2024-12-29 13:08:35,492 - INFO - Training set processing completed in 3.94s
2024-12-29 13:08:35,492 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:08:35,493 - INFO - Memory usage at start_fit: CPU 2707.9 MB, GPU 106.0 MB
2024-12-29 13:08:35,494 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:08:35,714 - INFO - Fitted scaler and transformed data
2024-12-29 13:08:35,715 - INFO - Scaling time: 0.22s
2024-12-29 13:08:35,722 - INFO - Number of unique classes: 10
2024-12-29 13:08:38,675 - INFO - Epoch 1/10, Train Loss: 2.1892, Val Loss: 2.3014
2024-12-29 13:08:42,401 - INFO - Epoch 2/10, Train Loss: 2.1880, Val Loss: 2.3002
2024-12-29 13:08:45,540 - INFO - Epoch 3/10, Train Loss: 2.1867, Val Loss: 2.2990
2024-12-29 13:08:49,156 - INFO - Epoch 4/10, Train Loss: 2.1855, Val Loss: 2.2978
2024-12-29 13:08:49,157 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:08:49,157 - INFO - Training completed in 13.66s
2024-12-29 13:08:49,157 - INFO - Final memory usage: CPU 2707.9 MB, GPU 125.9 MB
2024-12-29 13:08:49,158 - INFO - Model training completed in 13.67s
2024-12-29 13:08:49,352 - INFO - Prediction completed in 0.19s
2024-12-29 13:08:49,361 - INFO - Poison rate 0.07 completed in 17.81s
2024-12-29 13:08:49,361 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:08:49,362 - INFO - Total number of labels flipped: 830
2024-12-29 13:08:49,363 - INFO - Label flipping completed in 0.00s
2024-12-29 13:08:49,363 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:08:49,363 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:08:49,928 - INFO - Feature scaling completed in 0.56s
2024-12-29 13:08:49,928 - INFO - Starting feature selection (k=50)
2024-12-29 13:08:49,941 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:08:49,941 - INFO - Starting anomaly detection
2024-12-29 13:08:52,789 - INFO - Anomaly detection completed in 2.85s
2024-12-29 13:08:52,789 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:08:52,789 - INFO - Total fit_transform time: 3.43s
2024-12-29 13:08:52,790 - INFO - Training set processing completed in 3.43s
2024-12-29 13:08:52,790 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:08:52,791 - INFO - Memory usage at start_fit: CPU 2707.9 MB, GPU 106.0 MB
2024-12-29 13:08:52,791 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:08:53,000 - INFO - Fitted scaler and transformed data
2024-12-29 13:08:53,000 - INFO - Scaling time: 0.21s
2024-12-29 13:08:53,007 - INFO - Number of unique classes: 10
2024-12-29 13:08:55,946 - INFO - Epoch 1/10, Train Loss: 2.1869, Val Loss: 2.3014
2024-12-29 13:08:59,424 - INFO - Epoch 2/10, Train Loss: 2.1857, Val Loss: 2.3002
2024-12-29 13:09:02,948 - INFO - Epoch 3/10, Train Loss: 2.1845, Val Loss: 2.2990
2024-12-29 13:09:06,083 - INFO - Epoch 4/10, Train Loss: 2.1832, Val Loss: 2.2978
2024-12-29 13:09:06,083 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:09:06,083 - INFO - Training completed in 13.29s
2024-12-29 13:09:06,083 - INFO - Final memory usage: CPU 2707.9 MB, GPU 125.9 MB
2024-12-29 13:09:06,084 - INFO - Model training completed in 13.29s
2024-12-29 13:09:06,263 - INFO - Prediction completed in 0.18s
2024-12-29 13:09:06,272 - INFO - Poison rate 0.1 completed in 16.91s
2024-12-29 13:09:06,273 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:09:06,274 - INFO - Total number of labels flipped: 1700
2024-12-29 13:09:06,274 - INFO - Label flipping completed in 0.00s
2024-12-29 13:09:06,274 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:09:06,275 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:09:06,844 - INFO - Feature scaling completed in 0.57s
2024-12-29 13:09:06,844 - INFO - Starting feature selection (k=50)
2024-12-29 13:09:06,857 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:09:06,857 - INFO - Starting anomaly detection
2024-12-29 13:09:10,544 - INFO - Anomaly detection completed in 3.69s
2024-12-29 13:09:10,545 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:09:10,545 - INFO - Total fit_transform time: 4.27s
2024-12-29 13:09:10,545 - INFO - Training set processing completed in 4.27s
2024-12-29 13:09:10,545 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:09:10,547 - INFO - Memory usage at start_fit: CPU 2707.9 MB, GPU 106.0 MB
2024-12-29 13:09:10,547 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:09:10,750 - INFO - Fitted scaler and transformed data
2024-12-29 13:09:10,750 - INFO - Scaling time: 0.20s
2024-12-29 13:09:10,757 - INFO - Number of unique classes: 10
2024-12-29 13:09:14,191 - INFO - Epoch 1/10, Train Loss: 2.1865, Val Loss: 2.3013
2024-12-29 13:09:17,094 - INFO - Epoch 2/10, Train Loss: 2.1852, Val Loss: 2.3001
2024-12-29 13:09:19,898 - INFO - Epoch 3/10, Train Loss: 2.1840, Val Loss: 2.2989
2024-12-29 13:09:23,451 - INFO - Epoch 4/10, Train Loss: 2.1827, Val Loss: 2.2976
2024-12-29 13:09:23,451 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:09:23,451 - INFO - Training completed in 12.91s
2024-12-29 13:09:23,451 - INFO - Final memory usage: CPU 2707.9 MB, GPU 125.9 MB
2024-12-29 13:09:23,452 - INFO - Model training completed in 12.91s
2024-12-29 13:09:23,612 - INFO - Prediction completed in 0.16s
2024-12-29 13:09:23,623 - INFO - Poison rate 0.2 completed in 17.35s
2024-12-29 13:09:23,625 - INFO - Loaded 91 existing results
2024-12-29 13:09:23,625 - INFO - Total results to save: 98
2024-12-29 13:09:23,626 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:09:23,630 - INFO - Saved 98 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:09:23,630 - INFO - Total evaluation time: 152.84s
2024-12-29 13:09:23,631 - INFO - 
Progress: 15.6% - Evaluating GTSRB with KNeighbors (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:09:23,811 - INFO - Loading datasets...
2024-12-29 13:09:23,833 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:09:23,833 - INFO - Extracting validation features...
2024-12-29 13:09:23,833 - INFO - Extracting features from 3925 samples...
2024-12-29 13:09:32,909 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:09:32,916 - INFO - Validation feature extraction completed in 9.08s
2024-12-29 13:09:32,916 - INFO - Extracting training features...
2024-12-29 13:09:32,916 - INFO - Extracting features from 9469 samples...
2024-12-29 13:09:54,462 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:09:54,468 - INFO - Training feature extraction completed in 21.55s
2024-12-29 13:09:54,469 - INFO - Creating model for classifier: KNeighbors
2024-12-29 13:09:54,469 - INFO - Using device: cuda
2024-12-29 13:09:54,469 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:09:54,469 - INFO - Training set processing completed in 0.00s
2024-12-29 13:09:54,469 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:09:54,471 - INFO - Memory usage at start_fit: CPU 2718.6 MB, GPU 104.0 MB
2024-12-29 13:09:54,471 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:09:54,651 - INFO - Fitted scaler and transformed data
2024-12-29 13:09:54,651 - INFO - Scaling time: 0.18s
2024-12-29 13:09:54,657 - INFO - Training completed in 0.19s
2024-12-29 13:09:54,658 - INFO - Final memory usage: CPU 2708.3 MB, GPU 122.6 MB
2024-12-29 13:09:54,658 - INFO - Model training completed in 0.19s
2024-12-29 13:09:54,730 - INFO - Prediction completed in 0.07s
2024-12-29 13:09:54,740 - INFO - Poison rate 0.0 completed in 0.27s
2024-12-29 13:09:54,740 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:09:54,741 - INFO - Total number of labels flipped: 83
2024-12-29 13:09:54,741 - INFO - Label flipping completed in 0.00s
2024-12-29 13:09:54,742 - INFO - Training set processing completed in 0.00s
2024-12-29 13:09:54,742 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:09:54,742 - INFO - Memory usage at start_fit: CPU 2708.3 MB, GPU 122.6 MB
2024-12-29 13:09:54,742 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:09:54,914 - INFO - Fitted scaler and transformed data
2024-12-29 13:09:54,914 - INFO - Scaling time: 0.17s
2024-12-29 13:09:54,923 - INFO - Training completed in 0.18s
2024-12-29 13:09:54,923 - INFO - Final memory usage: CPU 2717.3 MB, GPU 122.6 MB
2024-12-29 13:09:54,923 - INFO - Model training completed in 0.18s
2024-12-29 13:09:54,995 - INFO - Prediction completed in 0.07s
2024-12-29 13:09:55,004 - INFO - Poison rate 0.01 completed in 0.26s
2024-12-29 13:09:55,004 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:09:55,005 - INFO - Total number of labels flipped: 250
2024-12-29 13:09:55,005 - INFO - Label flipping completed in 0.00s
2024-12-29 13:09:55,005 - INFO - Training set processing completed in 0.00s
2024-12-29 13:09:55,005 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:09:55,006 - INFO - Memory usage at start_fit: CPU 2717.3 MB, GPU 122.6 MB
2024-12-29 13:09:55,006 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:09:55,226 - INFO - Fitted scaler and transformed data
2024-12-29 13:09:55,226 - INFO - Scaling time: 0.22s
2024-12-29 13:09:55,232 - INFO - Training completed in 0.23s
2024-12-29 13:09:55,233 - INFO - Final memory usage: CPU 2717.3 MB, GPU 122.6 MB
2024-12-29 13:09:55,233 - INFO - Model training completed in 0.23s
2024-12-29 13:09:55,321 - INFO - Prediction completed in 0.09s
2024-12-29 13:09:55,330 - INFO - Poison rate 0.03 completed in 0.33s
2024-12-29 13:09:55,330 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:09:55,331 - INFO - Total number of labels flipped: 431
2024-12-29 13:09:55,331 - INFO - Label flipping completed in 0.00s
2024-12-29 13:09:55,331 - INFO - Training set processing completed in 0.00s
2024-12-29 13:09:55,332 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:09:55,332 - INFO - Memory usage at start_fit: CPU 2680.5 MB, GPU 122.6 MB
2024-12-29 13:09:55,332 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:09:55,528 - INFO - Fitted scaler and transformed data
2024-12-29 13:09:55,528 - INFO - Scaling time: 0.20s
2024-12-29 13:09:55,536 - INFO - Training completed in 0.20s
2024-12-29 13:09:55,537 - INFO - Final memory usage: CPU 2708.1 MB, GPU 122.6 MB
2024-12-29 13:09:55,537 - INFO - Model training completed in 0.21s
2024-12-29 13:09:55,609 - INFO - Prediction completed in 0.07s
2024-12-29 13:09:55,618 - INFO - Poison rate 0.05 completed in 0.29s
2024-12-29 13:09:55,618 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:09:55,619 - INFO - Total number of labels flipped: 599
2024-12-29 13:09:55,619 - INFO - Label flipping completed in 0.00s
2024-12-29 13:09:55,620 - INFO - Training set processing completed in 0.00s
2024-12-29 13:09:55,620 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:09:55,621 - INFO - Memory usage at start_fit: CPU 2708.1 MB, GPU 122.6 MB
2024-12-29 13:09:55,621 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:09:55,791 - INFO - Fitted scaler and transformed data
2024-12-29 13:09:55,791 - INFO - Scaling time: 0.17s
2024-12-29 13:09:55,800 - INFO - Training completed in 0.18s
2024-12-29 13:09:55,800 - INFO - Final memory usage: CPU 2717.5 MB, GPU 122.6 MB
2024-12-29 13:09:55,800 - INFO - Model training completed in 0.18s
2024-12-29 13:09:55,875 - INFO - Prediction completed in 0.07s
2024-12-29 13:09:55,884 - INFO - Poison rate 0.07 completed in 0.27s
2024-12-29 13:09:55,884 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:09:55,885 - INFO - Total number of labels flipped: 850
2024-12-29 13:09:55,886 - INFO - Label flipping completed in 0.00s
2024-12-29 13:09:55,886 - INFO - Training set processing completed in 0.00s
2024-12-29 13:09:55,886 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:09:55,887 - INFO - Memory usage at start_fit: CPU 2680.6 MB, GPU 122.6 MB
2024-12-29 13:09:55,887 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:09:56,059 - INFO - Fitted scaler and transformed data
2024-12-29 13:09:56,059 - INFO - Scaling time: 0.17s
2024-12-29 13:09:56,065 - INFO - Training completed in 0.18s
2024-12-29 13:09:56,066 - INFO - Final memory usage: CPU 2708.2 MB, GPU 122.6 MB
2024-12-29 13:09:56,066 - INFO - Model training completed in 0.18s
2024-12-29 13:09:56,150 - INFO - Prediction completed in 0.08s
2024-12-29 13:09:56,159 - INFO - Poison rate 0.1 completed in 0.27s
2024-12-29 13:09:56,159 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:09:56,161 - INFO - Total number of labels flipped: 1684
2024-12-29 13:09:56,161 - INFO - Label flipping completed in 0.00s
2024-12-29 13:09:56,161 - INFO - Training set processing completed in 0.00s
2024-12-29 13:09:56,161 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:09:56,162 - INFO - Memory usage at start_fit: CPU 2708.2 MB, GPU 122.6 MB
2024-12-29 13:09:56,162 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:09:56,360 - INFO - Fitted scaler and transformed data
2024-12-29 13:09:56,360 - INFO - Scaling time: 0.20s
2024-12-29 13:09:56,373 - INFO - Training completed in 0.21s
2024-12-29 13:09:56,373 - INFO - Final memory usage: CPU 2717.4 MB, GPU 122.6 MB
2024-12-29 13:09:56,374 - INFO - Model training completed in 0.21s
2024-12-29 13:09:56,464 - INFO - Prediction completed in 0.09s
2024-12-29 13:09:56,480 - INFO - Poison rate 0.2 completed in 0.32s
2024-12-29 13:09:56,487 - INFO - Loaded 98 existing results
2024-12-29 13:09:56,487 - INFO - Total results to save: 105
2024-12-29 13:09:56,488 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:09:56,492 - INFO - Saved 105 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:09:56,492 - INFO - Total evaluation time: 32.68s
2024-12-29 13:09:56,494 - INFO - 
Progress: 16.7% - Evaluating GTSRB with KNeighbors (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:09:56,676 - INFO - Loading datasets...
2024-12-29 13:09:56,698 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:09:56,698 - INFO - Extracting validation features...
2024-12-29 13:09:56,698 - INFO - Extracting features from 3925 samples...
2024-12-29 13:10:06,084 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:10:06,090 - INFO - Validation feature extraction completed in 9.39s
2024-12-29 13:10:06,091 - INFO - Extracting training features...
2024-12-29 13:10:06,091 - INFO - Extracting features from 9469 samples...
2024-12-29 13:10:27,834 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:10:27,842 - INFO - Training feature extraction completed in 21.75s
2024-12-29 13:10:27,842 - INFO - Creating model for classifier: KNeighbors
2024-12-29 13:10:27,842 - INFO - Using device: cuda
2024-12-29 13:10:27,842 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:10:27,842 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:10:27,842 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:10:28,376 - INFO - Feature scaling completed in 0.53s
2024-12-29 13:10:28,376 - INFO - Starting feature selection (k=50)
2024-12-29 13:10:28,387 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:10:28,387 - INFO - Starting anomaly detection
2024-12-29 13:10:31,660 - INFO - Anomaly detection completed in 3.27s
2024-12-29 13:10:31,660 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:10:31,660 - INFO - Total fit_transform time: 3.82s
2024-12-29 13:10:31,660 - INFO - Training set processing completed in 3.82s
2024-12-29 13:10:31,660 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:10:31,661 - INFO - Memory usage at start_fit: CPU 2708.2 MB, GPU 104.0 MB
2024-12-29 13:10:31,661 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:10:31,865 - INFO - Fitted scaler and transformed data
2024-12-29 13:10:31,865 - INFO - Scaling time: 0.20s
2024-12-29 13:10:31,874 - INFO - Training completed in 0.21s
2024-12-29 13:10:31,874 - INFO - Final memory usage: CPU 2708.2 MB, GPU 122.6 MB
2024-12-29 13:10:31,875 - INFO - Model training completed in 0.21s
2024-12-29 13:10:31,971 - INFO - Prediction completed in 0.10s
2024-12-29 13:10:31,981 - INFO - Poison rate 0.0 completed in 4.14s
2024-12-29 13:10:31,981 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:10:31,982 - INFO - Total number of labels flipped: 87
2024-12-29 13:10:31,982 - INFO - Label flipping completed in 0.00s
2024-12-29 13:10:31,982 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:10:31,982 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:10:32,558 - INFO - Feature scaling completed in 0.58s
2024-12-29 13:10:32,559 - INFO - Starting feature selection (k=50)
2024-12-29 13:10:32,570 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:10:32,570 - INFO - Starting anomaly detection
2024-12-29 13:10:35,507 - INFO - Anomaly detection completed in 2.94s
2024-12-29 13:10:35,507 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:10:35,507 - INFO - Total fit_transform time: 3.52s
2024-12-29 13:10:35,507 - INFO - Training set processing completed in 3.52s
2024-12-29 13:10:35,507 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:10:35,508 - INFO - Memory usage at start_fit: CPU 2717.5 MB, GPU 122.6 MB
2024-12-29 13:10:35,509 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:10:35,689 - INFO - Fitted scaler and transformed data
2024-12-29 13:10:35,689 - INFO - Scaling time: 0.18s
2024-12-29 13:10:35,696 - INFO - Training completed in 0.19s
2024-12-29 13:10:35,697 - INFO - Final memory usage: CPU 2717.5 MB, GPU 122.6 MB
2024-12-29 13:10:35,697 - INFO - Model training completed in 0.19s
2024-12-29 13:10:35,809 - INFO - Prediction completed in 0.11s
2024-12-29 13:10:35,818 - INFO - Poison rate 0.01 completed in 3.84s
2024-12-29 13:10:35,818 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:10:35,819 - INFO - Total number of labels flipped: 265
2024-12-29 13:10:35,819 - INFO - Label flipping completed in 0.00s
2024-12-29 13:10:35,819 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:10:35,819 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:10:36,344 - INFO - Feature scaling completed in 0.52s
2024-12-29 13:10:36,345 - INFO - Starting feature selection (k=50)
2024-12-29 13:10:36,358 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:10:36,359 - INFO - Starting anomaly detection
2024-12-29 13:10:39,812 - INFO - Anomaly detection completed in 3.45s
2024-12-29 13:10:39,813 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:10:39,813 - INFO - Total fit_transform time: 3.99s
2024-12-29 13:10:39,814 - INFO - Training set processing completed in 3.99s
2024-12-29 13:10:39,814 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:10:39,815 - INFO - Memory usage at start_fit: CPU 2708.2 MB, GPU 122.6 MB
2024-12-29 13:10:39,815 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:10:40,029 - INFO - Fitted scaler and transformed data
2024-12-29 13:10:40,029 - INFO - Scaling time: 0.21s
2024-12-29 13:10:40,036 - INFO - Training completed in 0.22s
2024-12-29 13:10:40,036 - INFO - Final memory usage: CPU 2708.3 MB, GPU 122.6 MB
2024-12-29 13:10:40,037 - INFO - Model training completed in 0.22s
2024-12-29 13:10:40,156 - INFO - Prediction completed in 0.12s
2024-12-29 13:10:40,165 - INFO - Poison rate 0.03 completed in 4.35s
2024-12-29 13:10:40,166 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:10:40,167 - INFO - Total number of labels flipped: 430
2024-12-29 13:10:40,167 - INFO - Label flipping completed in 0.00s
2024-12-29 13:10:40,167 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:10:40,167 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:10:40,718 - INFO - Feature scaling completed in 0.55s
2024-12-29 13:10:40,719 - INFO - Starting feature selection (k=50)
2024-12-29 13:10:40,732 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:10:40,732 - INFO - Starting anomaly detection
2024-12-29 13:10:44,374 - INFO - Anomaly detection completed in 3.64s
2024-12-29 13:10:44,374 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:10:44,375 - INFO - Total fit_transform time: 4.21s
2024-12-29 13:10:44,375 - INFO - Training set processing completed in 4.21s
2024-12-29 13:10:44,375 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:10:44,376 - INFO - Memory usage at start_fit: CPU 2717.4 MB, GPU 122.6 MB
2024-12-29 13:10:44,376 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:10:44,555 - INFO - Fitted scaler and transformed data
2024-12-29 13:10:44,557 - INFO - Scaling time: 0.18s
2024-12-29 13:10:44,564 - INFO - Training completed in 0.19s
2024-12-29 13:10:44,564 - INFO - Final memory usage: CPU 2717.4 MB, GPU 122.6 MB
2024-12-29 13:10:44,565 - INFO - Model training completed in 0.19s
2024-12-29 13:10:44,666 - INFO - Prediction completed in 0.10s
2024-12-29 13:10:44,675 - INFO - Poison rate 0.05 completed in 4.51s
2024-12-29 13:10:44,675 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:10:44,677 - INFO - Total number of labels flipped: 582
2024-12-29 13:10:44,677 - INFO - Label flipping completed in 0.00s
2024-12-29 13:10:44,677 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:10:44,677 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:10:45,224 - INFO - Feature scaling completed in 0.55s
2024-12-29 13:10:45,224 - INFO - Starting feature selection (k=50)
2024-12-29 13:10:45,237 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:10:45,238 - INFO - Starting anomaly detection
2024-12-29 13:10:49,375 - INFO - Anomaly detection completed in 4.14s
2024-12-29 13:10:49,376 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:10:49,376 - INFO - Total fit_transform time: 4.70s
2024-12-29 13:10:49,376 - INFO - Training set processing completed in 4.70s
2024-12-29 13:10:49,376 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:10:49,377 - INFO - Memory usage at start_fit: CPU 2708.0 MB, GPU 122.6 MB
2024-12-29 13:10:49,377 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:10:49,558 - INFO - Fitted scaler and transformed data
2024-12-29 13:10:49,558 - INFO - Scaling time: 0.18s
2024-12-29 13:10:49,565 - INFO - Training completed in 0.19s
2024-12-29 13:10:49,566 - INFO - Final memory usage: CPU 2708.2 MB, GPU 122.6 MB
2024-12-29 13:10:49,566 - INFO - Model training completed in 0.19s
2024-12-29 13:10:49,667 - INFO - Prediction completed in 0.10s
2024-12-29 13:10:49,675 - INFO - Poison rate 0.07 completed in 5.00s
2024-12-29 13:10:49,676 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:10:49,677 - INFO - Total number of labels flipped: 849
2024-12-29 13:10:49,677 - INFO - Label flipping completed in 0.00s
2024-12-29 13:10:49,677 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:10:49,677 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:10:50,219 - INFO - Feature scaling completed in 0.54s
2024-12-29 13:10:50,220 - INFO - Starting feature selection (k=50)
2024-12-29 13:10:50,228 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:10:50,228 - INFO - Starting anomaly detection
2024-12-29 13:10:52,636 - INFO - Anomaly detection completed in 2.41s
2024-12-29 13:10:52,636 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:10:52,636 - INFO - Total fit_transform time: 2.96s
2024-12-29 13:10:52,636 - INFO - Training set processing completed in 2.96s
2024-12-29 13:10:52,636 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:10:52,637 - INFO - Memory usage at start_fit: CPU 2708.2 MB, GPU 122.6 MB
2024-12-29 13:10:52,638 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:10:52,823 - INFO - Fitted scaler and transformed data
2024-12-29 13:10:52,823 - INFO - Scaling time: 0.18s
2024-12-29 13:10:52,830 - INFO - Training completed in 0.19s
2024-12-29 13:10:52,830 - INFO - Final memory usage: CPU 2708.2 MB, GPU 122.6 MB
2024-12-29 13:10:52,830 - INFO - Model training completed in 0.19s
2024-12-29 13:10:52,905 - INFO - Prediction completed in 0.07s
2024-12-29 13:10:52,914 - INFO - Poison rate 0.1 completed in 3.24s
2024-12-29 13:10:52,914 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:10:52,915 - INFO - Total number of labels flipped: 1715
2024-12-29 13:10:52,916 - INFO - Label flipping completed in 0.00s
2024-12-29 13:10:52,916 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:10:52,916 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:10:53,449 - INFO - Feature scaling completed in 0.53s
2024-12-29 13:10:53,449 - INFO - Starting feature selection (k=50)
2024-12-29 13:10:53,456 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:10:53,457 - INFO - Starting anomaly detection
2024-12-29 13:10:56,930 - INFO - Anomaly detection completed in 3.47s
2024-12-29 13:10:56,930 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:10:56,930 - INFO - Total fit_transform time: 4.01s
2024-12-29 13:10:56,930 - INFO - Training set processing completed in 4.01s
2024-12-29 13:10:56,931 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:10:56,932 - INFO - Memory usage at start_fit: CPU 2708.2 MB, GPU 122.6 MB
2024-12-29 13:10:56,932 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:10:57,115 - INFO - Fitted scaler and transformed data
2024-12-29 13:10:57,115 - INFO - Scaling time: 0.18s
2024-12-29 13:10:57,122 - INFO - Training completed in 0.19s
2024-12-29 13:10:57,123 - INFO - Final memory usage: CPU 2708.2 MB, GPU 122.6 MB
2024-12-29 13:10:57,123 - INFO - Model training completed in 0.19s
2024-12-29 13:10:57,228 - INFO - Prediction completed in 0.10s
2024-12-29 13:10:57,237 - INFO - Poison rate 0.2 completed in 4.32s
2024-12-29 13:10:57,240 - INFO - Loaded 105 existing results
2024-12-29 13:10:57,240 - INFO - Total results to save: 112
2024-12-29 13:10:57,241 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:10:57,245 - INFO - Saved 112 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:10:57,245 - INFO - Total evaluation time: 60.57s
2024-12-29 13:10:57,246 - INFO - Completed evaluation for GTSRB
2024-12-29 13:10:57,247 - INFO - 
Processing dataset: GTSRB
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:10:57,441 - INFO - 
Progress: 17.7% - Evaluating GTSRB with SVM (standard mode, iteration 1/1)
2024-12-29 13:10:57,606 - INFO - Loading datasets...
2024-12-29 13:10:57,627 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:10:57,628 - INFO - Extracting validation features...
2024-12-29 13:10:57,628 - INFO - Extracting features from 3925 samples...
2024-12-29 13:11:06,661 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:11:06,666 - INFO - Validation feature extraction completed in 9.04s
2024-12-29 13:11:06,666 - INFO - Extracting training features...
2024-12-29 13:11:06,666 - INFO - Extracting features from 9469 samples...
2024-12-29 13:11:28,220 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:11:28,228 - INFO - Training feature extraction completed in 21.56s
2024-12-29 13:11:28,229 - INFO - Creating model for classifier: SVM
2024-12-29 13:11:28,229 - INFO - Using device: cuda
2024-12-29 13:11:28,230 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-29 13:11:28,230 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:11:28,230 - INFO - Training set processing completed in 0.00s
2024-12-29 13:11:28,230 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:11:28,231 - INFO - Memory usage at start_fit: CPU 2763.6 MB, GPU 104.0 MB
2024-12-29 13:11:28,231 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:11:28,234 - INFO - Number of unique classes: 10
2024-12-29 13:11:28,303 - INFO - Fitted scaler and transformed data
2024-12-29 13:11:28,303 - INFO - Scaling time: 0.07s
2024-12-29 13:11:28,710 - INFO - Epoch 1/500, Train Loss: 0.7890, Val Loss: 0.0894
2024-12-29 13:11:29,073 - INFO - Epoch 2/500, Train Loss: 0.0926, Val Loss: 0.0680
2024-12-29 13:11:29,407 - INFO - Epoch 3/500, Train Loss: 0.0610, Val Loss: 0.0566
2024-12-29 13:11:29,729 - INFO - Epoch 4/500, Train Loss: 0.0437, Val Loss: 0.0501
2024-12-29 13:11:30,043 - INFO - Epoch 5/500, Train Loss: 0.0334, Val Loss: 0.0487
2024-12-29 13:11:30,352 - INFO - Epoch 6/500, Train Loss: 0.0267, Val Loss: 0.0458
2024-12-29 13:11:30,689 - INFO - Epoch 7/500, Train Loss: 0.0216, Val Loss: 0.0445
2024-12-29 13:11:31,080 - INFO - Epoch 8/500, Train Loss: 0.0178, Val Loss: 0.0439
2024-12-29 13:11:31,429 - INFO - Epoch 9/500, Train Loss: 0.0152, Val Loss: 0.0437
2024-12-29 13:11:31,742 - INFO - Epoch 10/500, Train Loss: 0.0130, Val Loss: 0.0441
2024-12-29 13:11:32,071 - INFO - Epoch 11/500, Train Loss: 0.0110, Val Loss: 0.0431
2024-12-29 13:11:32,428 - INFO - Epoch 12/500, Train Loss: 0.0096, Val Loss: 0.0452
2024-12-29 13:11:32,757 - INFO - Epoch 13/500, Train Loss: 0.0086, Val Loss: 0.0440
2024-12-29 13:11:33,122 - INFO - Epoch 14/500, Train Loss: 0.0079, Val Loss: 0.0464
2024-12-29 13:11:33,470 - INFO - Epoch 15/500, Train Loss: 0.0069, Val Loss: 0.0462
2024-12-29 13:11:33,819 - INFO - Epoch 16/500, Train Loss: 0.0061, Val Loss: 0.0473
2024-12-29 13:11:33,819 - INFO - Early stopping triggered at epoch 16
2024-12-29 13:11:33,819 - INFO - Training completed in 5.59s
2024-12-29 13:11:33,819 - INFO - Final memory usage: CPU 2763.6 MB, GPU 104.2 MB
2024-12-29 13:11:33,822 - INFO - Model training completed in 5.59s
2024-12-29 13:11:33,890 - INFO - Prediction completed in 0.07s
2024-12-29 13:11:33,899 - INFO - Poison rate 0.0 completed in 5.67s
2024-12-29 13:11:33,900 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:11:33,900 - INFO - Label flipping details:
2024-12-29 13:11:33,900 - INFO - - Source class: 1
2024-12-29 13:11:33,900 - INFO - - Target class: 0
2024-12-29 13:11:33,901 - INFO - - Available samples in source class: 955
2024-12-29 13:11:33,901 - INFO - - Requested samples to poison: 94
2024-12-29 13:11:33,901 - INFO - - Actual samples to flip: 94
2024-12-29 13:11:33,901 - INFO - - Samples remaining in source class: 861
2024-12-29 13:11:33,901 - INFO - Successfully flipped 94 labels from class 1 to 0
2024-12-29 13:11:33,901 - INFO - Total number of labels flipped: 94
2024-12-29 13:11:33,901 - INFO - Label flipping completed in 0.00s
2024-12-29 13:11:33,901 - INFO - Training set processing completed in 0.00s
2024-12-29 13:11:33,901 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:11:33,902 - INFO - Memory usage at start_fit: CPU 2688.1 MB, GPU 104.1 MB
2024-12-29 13:11:33,902 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:11:33,905 - INFO - Number of unique classes: 10
2024-12-29 13:11:33,980 - INFO - Fitted scaler and transformed data
2024-12-29 13:11:33,980 - INFO - Scaling time: 0.07s
2024-12-29 13:11:34,371 - INFO - Epoch 1/500, Train Loss: 0.7924, Val Loss: 0.1333
2024-12-29 13:11:34,739 - INFO - Epoch 2/500, Train Loss: 0.1266, Val Loss: 0.1033
2024-12-29 13:11:35,094 - INFO - Epoch 3/500, Train Loss: 0.0926, Val Loss: 0.0899
2024-12-29 13:11:35,468 - INFO - Epoch 4/500, Train Loss: 0.0739, Val Loss: 0.0796
2024-12-29 13:11:35,814 - INFO - Epoch 5/500, Train Loss: 0.0609, Val Loss: 0.0780
2024-12-29 13:11:36,169 - INFO - Epoch 6/500, Train Loss: 0.0529, Val Loss: 0.0706
2024-12-29 13:11:36,529 - INFO - Epoch 7/500, Train Loss: 0.0471, Val Loss: 0.0709
2024-12-29 13:11:36,963 - INFO - Epoch 8/500, Train Loss: 0.0432, Val Loss: 0.0702
2024-12-29 13:11:37,385 - INFO - Epoch 9/500, Train Loss: 0.0393, Val Loss: 0.0695
2024-12-29 13:11:37,766 - INFO - Epoch 10/500, Train Loss: 0.0372, Val Loss: 0.0687
2024-12-29 13:11:38,208 - INFO - Epoch 11/500, Train Loss: 0.0347, Val Loss: 0.0707
2024-12-29 13:11:38,576 - INFO - Epoch 12/500, Train Loss: 0.0331, Val Loss: 0.0691
2024-12-29 13:11:38,937 - INFO - Epoch 13/500, Train Loss: 0.0319, Val Loss: 0.0676
2024-12-29 13:11:39,276 - INFO - Epoch 14/500, Train Loss: 0.0310, Val Loss: 0.0680
2024-12-29 13:11:39,613 - INFO - Epoch 15/500, Train Loss: 0.0296, Val Loss: 0.0732
2024-12-29 13:11:39,950 - INFO - Epoch 16/500, Train Loss: 0.0284, Val Loss: 0.0688
2024-12-29 13:11:40,297 - INFO - Epoch 17/500, Train Loss: 0.0280, Val Loss: 0.0697
2024-12-29 13:11:40,695 - INFO - Epoch 18/500, Train Loss: 0.0287, Val Loss: 0.0706
2024-12-29 13:11:40,695 - INFO - Early stopping triggered at epoch 18
2024-12-29 13:11:40,695 - INFO - Training completed in 6.79s
2024-12-29 13:11:40,695 - INFO - Final memory usage: CPU 2717.0 MB, GPU 104.2 MB
2024-12-29 13:11:40,696 - INFO - Model training completed in 6.80s
2024-12-29 13:11:40,740 - INFO - Prediction completed in 0.04s
2024-12-29 13:11:40,749 - INFO - Poison rate 0.01 completed in 6.85s
2024-12-29 13:11:40,749 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:11:40,750 - INFO - Label flipping details:
2024-12-29 13:11:40,750 - INFO - - Source class: 1
2024-12-29 13:11:40,750 - INFO - - Target class: 0
2024-12-29 13:11:40,750 - INFO - - Available samples in source class: 955
2024-12-29 13:11:40,750 - INFO - - Requested samples to poison: 284
2024-12-29 13:11:40,750 - INFO - - Actual samples to flip: 284
2024-12-29 13:11:40,750 - INFO - - Samples remaining in source class: 671
2024-12-29 13:11:40,750 - INFO - Successfully flipped 284 labels from class 1 to 0
2024-12-29 13:11:40,750 - INFO - Total number of labels flipped: 284
2024-12-29 13:11:40,750 - INFO - Label flipping completed in 0.00s
2024-12-29 13:11:40,750 - INFO - Training set processing completed in 0.00s
2024-12-29 13:11:40,750 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:11:40,751 - INFO - Memory usage at start_fit: CPU 2687.7 MB, GPU 104.1 MB
2024-12-29 13:11:40,751 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:11:40,755 - INFO - Number of unique classes: 10
2024-12-29 13:11:40,833 - INFO - Fitted scaler and transformed data
2024-12-29 13:11:40,833 - INFO - Scaling time: 0.08s
2024-12-29 13:11:41,219 - INFO - Epoch 1/500, Train Loss: 0.9890, Val Loss: 0.1583
2024-12-29 13:11:41,556 - INFO - Epoch 2/500, Train Loss: 0.1725, Val Loss: 0.1248
2024-12-29 13:11:41,930 - INFO - Epoch 3/500, Train Loss: 0.1361, Val Loss: 0.1110
2024-12-29 13:11:42,327 - INFO - Epoch 4/500, Train Loss: 0.1174, Val Loss: 0.1046
2024-12-29 13:11:42,659 - INFO - Epoch 5/500, Train Loss: 0.1059, Val Loss: 0.1021
2024-12-29 13:11:42,994 - INFO - Epoch 6/500, Train Loss: 0.0956, Val Loss: 0.1030
2024-12-29 13:11:43,361 - INFO - Epoch 7/500, Train Loss: 0.0894, Val Loss: 0.1014
2024-12-29 13:11:43,788 - INFO - Epoch 8/500, Train Loss: 0.0851, Val Loss: 0.1013
2024-12-29 13:11:44,138 - INFO - Epoch 9/500, Train Loss: 0.0808, Val Loss: 0.1027
2024-12-29 13:11:44,472 - INFO - Epoch 10/500, Train Loss: 0.0771, Val Loss: 0.1052
2024-12-29 13:11:44,473 - INFO - Early stopping triggered at epoch 10
2024-12-29 13:11:44,473 - INFO - Training completed in 3.72s
2024-12-29 13:11:44,473 - INFO - Final memory usage: CPU 2717.2 MB, GPU 104.2 MB
2024-12-29 13:11:44,474 - INFO - Model training completed in 3.72s
2024-12-29 13:11:44,518 - INFO - Prediction completed in 0.04s
2024-12-29 13:11:44,537 - INFO - Poison rate 0.03 completed in 3.79s
2024-12-29 13:11:44,538 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:11:44,538 - INFO - Label flipping details:
2024-12-29 13:11:44,538 - INFO - - Source class: 1
2024-12-29 13:11:44,538 - INFO - - Target class: 0
2024-12-29 13:11:44,538 - INFO - - Available samples in source class: 955
2024-12-29 13:11:44,539 - INFO - - Requested samples to poison: 473
2024-12-29 13:11:44,539 - INFO - - Actual samples to flip: 473
2024-12-29 13:11:44,539 - INFO - - Samples remaining in source class: 482
2024-12-29 13:11:44,539 - INFO - Successfully flipped 473 labels from class 1 to 0
2024-12-29 13:11:44,539 - INFO - Total number of labels flipped: 473
2024-12-29 13:11:44,539 - INFO - Label flipping completed in 0.00s
2024-12-29 13:11:44,539 - INFO - Training set processing completed in 0.00s
2024-12-29 13:11:44,539 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:11:44,540 - INFO - Memory usage at start_fit: CPU 2687.9 MB, GPU 104.1 MB
2024-12-29 13:11:44,540 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:11:44,544 - INFO - Number of unique classes: 10
2024-12-29 13:11:44,614 - INFO - Fitted scaler and transformed data
2024-12-29 13:11:44,615 - INFO - Scaling time: 0.07s
2024-12-29 13:11:45,027 - INFO - Epoch 1/500, Train Loss: 1.0014, Val Loss: 0.2435
2024-12-29 13:11:45,414 - INFO - Epoch 2/500, Train Loss: 0.2003, Val Loss: 0.1990
2024-12-29 13:11:45,784 - INFO - Epoch 3/500, Train Loss: 0.1641, Val Loss: 0.1839
2024-12-29 13:11:46,191 - INFO - Epoch 4/500, Train Loss: 0.1430, Val Loss: 0.1757
2024-12-29 13:11:46,591 - INFO - Epoch 5/500, Train Loss: 0.1276, Val Loss: 0.1732
2024-12-29 13:11:46,993 - INFO - Epoch 6/500, Train Loss: 0.1178, Val Loss: 0.1667
2024-12-29 13:11:47,413 - INFO - Epoch 7/500, Train Loss: 0.1098, Val Loss: 0.1645
2024-12-29 13:11:47,747 - INFO - Epoch 8/500, Train Loss: 0.1046, Val Loss: 0.1623
2024-12-29 13:11:48,105 - INFO - Epoch 9/500, Train Loss: 0.0975, Val Loss: 0.1665
2024-12-29 13:11:48,457 - INFO - Epoch 10/500, Train Loss: 0.0971, Val Loss: 0.1647
2024-12-29 13:11:48,883 - INFO - Epoch 11/500, Train Loss: 0.0922, Val Loss: 0.1685
2024-12-29 13:11:49,223 - INFO - Epoch 12/500, Train Loss: 0.0902, Val Loss: 0.1665
2024-12-29 13:11:49,585 - INFO - Epoch 13/500, Train Loss: 0.0881, Val Loss: 0.1666
2024-12-29 13:11:49,586 - INFO - Early stopping triggered at epoch 13
2024-12-29 13:11:49,586 - INFO - Training completed in 5.05s
2024-12-29 13:11:49,586 - INFO - Final memory usage: CPU 2717.1 MB, GPU 104.2 MB
2024-12-29 13:11:49,587 - INFO - Model training completed in 5.05s
2024-12-29 13:11:49,655 - INFO - Prediction completed in 0.07s
2024-12-29 13:11:49,670 - INFO - Poison rate 0.05 completed in 5.13s
2024-12-29 13:11:49,670 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:11:49,671 - INFO - Label flipping details:
2024-12-29 13:11:49,671 - INFO - - Source class: 1
2024-12-29 13:11:49,671 - INFO - - Target class: 0
2024-12-29 13:11:49,671 - INFO - - Available samples in source class: 955
2024-12-29 13:11:49,671 - INFO - - Requested samples to poison: 662
2024-12-29 13:11:49,671 - INFO - - Actual samples to flip: 662
2024-12-29 13:11:49,671 - INFO - - Samples remaining in source class: 293
2024-12-29 13:11:49,671 - INFO - Successfully flipped 662 labels from class 1 to 0
2024-12-29 13:11:49,672 - INFO - Total number of labels flipped: 662
2024-12-29 13:11:49,672 - INFO - Label flipping completed in 0.00s
2024-12-29 13:11:49,672 - INFO - Training set processing completed in 0.00s
2024-12-29 13:11:49,672 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:11:49,673 - INFO - Memory usage at start_fit: CPU 2687.8 MB, GPU 104.1 MB
2024-12-29 13:11:49,673 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:11:49,677 - INFO - Number of unique classes: 10
2024-12-29 13:11:49,748 - INFO - Fitted scaler and transformed data
2024-12-29 13:11:49,748 - INFO - Scaling time: 0.07s
2024-12-29 13:11:50,145 - INFO - Epoch 1/500, Train Loss: 0.8087, Val Loss: 0.1962
2024-12-29 13:11:50,555 - INFO - Epoch 2/500, Train Loss: 0.1667, Val Loss: 0.1750
2024-12-29 13:11:50,898 - INFO - Epoch 3/500, Train Loss: 0.1308, Val Loss: 0.1641
2024-12-29 13:11:51,267 - INFO - Epoch 4/500, Train Loss: 0.1111, Val Loss: 0.1569
2024-12-29 13:11:51,626 - INFO - Epoch 5/500, Train Loss: 0.0988, Val Loss: 0.1538
2024-12-29 13:11:51,969 - INFO - Epoch 6/500, Train Loss: 0.0905, Val Loss: 0.1570
2024-12-29 13:11:52,327 - INFO - Epoch 7/500, Train Loss: 0.0861, Val Loss: 0.1582
2024-12-29 13:11:52,719 - INFO - Epoch 8/500, Train Loss: 0.0829, Val Loss: 0.1553
2024-12-29 13:11:53,040 - INFO - Epoch 9/500, Train Loss: 0.0778, Val Loss: 0.1519
2024-12-29 13:11:53,385 - INFO - Epoch 10/500, Train Loss: 0.0752, Val Loss: 0.1503
2024-12-29 13:11:53,736 - INFO - Epoch 11/500, Train Loss: 0.0743, Val Loss: 0.1481
2024-12-29 13:11:54,068 - INFO - Epoch 12/500, Train Loss: 0.0699, Val Loss: 0.1478
2024-12-29 13:11:54,406 - INFO - Epoch 13/500, Train Loss: 0.0684, Val Loss: 0.1478
2024-12-29 13:11:54,804 - INFO - Epoch 14/500, Train Loss: 0.0682, Val Loss: 0.1454
2024-12-29 13:11:55,143 - INFO - Epoch 15/500, Train Loss: 0.0668, Val Loss: 0.1459
2024-12-29 13:11:55,487 - INFO - Epoch 16/500, Train Loss: 0.0648, Val Loss: 0.1501
2024-12-29 13:11:55,818 - INFO - Epoch 17/500, Train Loss: 0.0639, Val Loss: 0.1495
2024-12-29 13:11:56,158 - INFO - Epoch 18/500, Train Loss: 0.0634, Val Loss: 0.1458
2024-12-29 13:11:56,498 - INFO - Epoch 19/500, Train Loss: 0.0627, Val Loss: 0.1465
2024-12-29 13:11:56,498 - INFO - Early stopping triggered at epoch 19
2024-12-29 13:11:56,498 - INFO - Training completed in 6.83s
2024-12-29 13:11:56,498 - INFO - Final memory usage: CPU 2717.1 MB, GPU 104.2 MB
2024-12-29 13:11:56,499 - INFO - Model training completed in 6.83s
2024-12-29 13:11:56,544 - INFO - Prediction completed in 0.04s
2024-12-29 13:11:56,554 - INFO - Poison rate 0.07 completed in 6.88s
2024-12-29 13:11:56,554 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:11:56,555 - INFO - Label flipping details:
2024-12-29 13:11:56,555 - INFO - - Source class: 1
2024-12-29 13:11:56,555 - INFO - - Target class: 0
2024-12-29 13:11:56,555 - INFO - - Available samples in source class: 955
2024-12-29 13:11:56,555 - INFO - - Requested samples to poison: 946
2024-12-29 13:11:56,555 - INFO - - Actual samples to flip: 946
2024-12-29 13:11:56,555 - INFO - - Samples remaining in source class: 9
2024-12-29 13:11:56,555 - INFO - Successfully flipped 946 labels from class 1 to 0
2024-12-29 13:11:56,555 - INFO - Total number of labels flipped: 946
2024-12-29 13:11:56,555 - INFO - Label flipping completed in 0.00s
2024-12-29 13:11:56,556 - INFO - Training set processing completed in 0.00s
2024-12-29 13:11:56,556 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:11:56,557 - INFO - Memory usage at start_fit: CPU 2687.7 MB, GPU 104.1 MB
2024-12-29 13:11:56,557 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:11:56,561 - INFO - Number of unique classes: 10
2024-12-29 13:11:56,638 - INFO - Fitted scaler and transformed data
2024-12-29 13:11:56,638 - INFO - Scaling time: 0.08s
2024-12-29 13:11:57,027 - INFO - Epoch 1/500, Train Loss: 0.7391, Val Loss: 0.1136
2024-12-29 13:11:57,382 - INFO - Epoch 2/500, Train Loss: 0.1036, Val Loss: 0.0838
2024-12-29 13:11:57,726 - INFO - Epoch 3/500, Train Loss: 0.0704, Val Loss: 0.0726
2024-12-29 13:11:58,070 - INFO - Epoch 4/500, Train Loss: 0.0523, Val Loss: 0.0645
2024-12-29 13:11:58,402 - INFO - Epoch 5/500, Train Loss: 0.0421, Val Loss: 0.0587
2024-12-29 13:11:58,721 - INFO - Epoch 6/500, Train Loss: 0.0339, Val Loss: 0.0558
2024-12-29 13:11:59,047 - INFO - Epoch 7/500, Train Loss: 0.0276, Val Loss: 0.0530
2024-12-29 13:11:59,397 - INFO - Epoch 8/500, Train Loss: 0.0235, Val Loss: 0.0529
2024-12-29 13:11:59,796 - INFO - Epoch 9/500, Train Loss: 0.0196, Val Loss: 0.0511
2024-12-29 13:12:00,122 - INFO - Epoch 10/500, Train Loss: 0.0172, Val Loss: 0.0517
2024-12-29 13:12:00,473 - INFO - Epoch 11/500, Train Loss: 0.0156, Val Loss: 0.0505
2024-12-29 13:12:00,812 - INFO - Epoch 12/500, Train Loss: 0.0135, Val Loss: 0.0507
2024-12-29 13:12:01,199 - INFO - Epoch 13/500, Train Loss: 0.0111, Val Loss: 0.0503
2024-12-29 13:12:01,553 - INFO - Epoch 14/500, Train Loss: 0.0101, Val Loss: 0.0500
2024-12-29 13:12:01,890 - INFO - Epoch 15/500, Train Loss: 0.0090, Val Loss: 0.0488
2024-12-29 13:12:02,233 - INFO - Epoch 16/500, Train Loss: 0.0082, Val Loss: 0.0495
2024-12-29 13:12:02,606 - INFO - Epoch 17/500, Train Loss: 0.0076, Val Loss: 0.0491
2024-12-29 13:12:02,937 - INFO - Epoch 18/500, Train Loss: 0.0073, Val Loss: 0.0506
2024-12-29 13:12:03,261 - INFO - Epoch 19/500, Train Loss: 0.0066, Val Loss: 0.0505
2024-12-29 13:12:03,585 - INFO - Epoch 20/500, Train Loss: 0.0065, Val Loss: 0.0510
2024-12-29 13:12:03,585 - INFO - Early stopping triggered at epoch 20
2024-12-29 13:12:03,585 - INFO - Training completed in 7.03s
2024-12-29 13:12:03,586 - INFO - Final memory usage: CPU 2717.0 MB, GPU 104.2 MB
2024-12-29 13:12:03,586 - INFO - Model training completed in 7.03s
2024-12-29 13:12:03,650 - INFO - Prediction completed in 0.06s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 13:12:03,661 - INFO - Poison rate 0.1 completed in 7.11s
2024-12-29 13:12:03,662 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:12:03,662 - INFO - Label flipping details:
2024-12-29 13:12:03,662 - INFO - - Source class: 1
2024-12-29 13:12:03,662 - INFO - - Target class: 0
2024-12-29 13:12:03,662 - INFO - - Available samples in source class: 955
2024-12-29 13:12:03,662 - INFO - - Requested samples to poison: 1893
2024-12-29 13:12:03,663 - INFO - - Actual samples to flip: 954
2024-12-29 13:12:03,663 - INFO - - Samples remaining in source class: 1
2024-12-29 13:12:03,663 - INFO - Successfully flipped 954 labels from class 1 to 0
2024-12-29 13:12:03,663 - INFO - Total number of labels flipped: 954
2024-12-29 13:12:03,663 - INFO - Label flipping completed in 0.00s
2024-12-29 13:12:03,663 - INFO - Training set processing completed in 0.00s
2024-12-29 13:12:03,663 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:12:03,664 - INFO - Memory usage at start_fit: CPU 2687.8 MB, GPU 104.1 MB
2024-12-29 13:12:03,664 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:12:03,668 - INFO - Number of unique classes: 10
2024-12-29 13:12:03,743 - INFO - Fitted scaler and transformed data
2024-12-29 13:12:03,743 - INFO - Scaling time: 0.07s
2024-12-29 13:12:04,093 - INFO - Epoch 1/500, Train Loss: 0.8718, Val Loss: 0.1249
2024-12-29 13:12:04,538 - INFO - Epoch 2/500, Train Loss: 0.1033, Val Loss: 0.0957
2024-12-29 13:12:04,871 - INFO - Epoch 3/500, Train Loss: 0.0678, Val Loss: 0.0835
2024-12-29 13:12:05,196 - INFO - Epoch 4/500, Train Loss: 0.0485, Val Loss: 0.0754
2024-12-29 13:12:05,515 - INFO - Epoch 5/500, Train Loss: 0.0372, Val Loss: 0.0725
2024-12-29 13:12:05,875 - INFO - Epoch 6/500, Train Loss: 0.0302, Val Loss: 0.0675
2024-12-29 13:12:06,218 - INFO - Epoch 7/500, Train Loss: 0.0252, Val Loss: 0.0655
2024-12-29 13:12:06,561 - INFO - Epoch 8/500, Train Loss: 0.0204, Val Loss: 0.0628
2024-12-29 13:12:06,921 - INFO - Epoch 9/500, Train Loss: 0.0172, Val Loss: 0.0616
2024-12-29 13:12:07,297 - INFO - Epoch 10/500, Train Loss: 0.0146, Val Loss: 0.0602
2024-12-29 13:12:07,628 - INFO - Epoch 11/500, Train Loss: 0.0124, Val Loss: 0.0613
2024-12-29 13:12:07,965 - INFO - Epoch 12/500, Train Loss: 0.0108, Val Loss: 0.0598
2024-12-29 13:12:08,291 - INFO - Epoch 13/500, Train Loss: 0.0094, Val Loss: 0.0578
2024-12-29 13:12:08,657 - INFO - Epoch 14/500, Train Loss: 0.0084, Val Loss: 0.0581
2024-12-29 13:12:08,991 - INFO - Epoch 15/500, Train Loss: 0.0071, Val Loss: 0.0567
2024-12-29 13:12:09,359 - INFO - Epoch 16/500, Train Loss: 0.0064, Val Loss: 0.0570
2024-12-29 13:12:09,736 - INFO - Epoch 17/500, Train Loss: 0.0060, Val Loss: 0.0556
2024-12-29 13:12:10,085 - INFO - Epoch 18/500, Train Loss: 0.0054, Val Loss: 0.0571
2024-12-29 13:12:10,511 - INFO - Epoch 19/500, Train Loss: 0.0051, Val Loss: 0.0535
2024-12-29 13:12:10,888 - INFO - Epoch 20/500, Train Loss: 0.0048, Val Loss: 0.0565
2024-12-29 13:12:11,262 - INFO - Epoch 21/500, Train Loss: 0.0045, Val Loss: 0.0563
2024-12-29 13:12:11,598 - INFO - Epoch 22/500, Train Loss: 0.0036, Val Loss: 0.0559
2024-12-29 13:12:11,941 - INFO - Epoch 23/500, Train Loss: 0.0039, Val Loss: 0.0569
2024-12-29 13:12:12,256 - INFO - Epoch 24/500, Train Loss: 0.0038, Val Loss: 0.0568
2024-12-29 13:12:12,257 - INFO - Early stopping triggered at epoch 24
2024-12-29 13:12:12,257 - INFO - Training completed in 8.59s
2024-12-29 13:12:12,257 - INFO - Final memory usage: CPU 2717.0 MB, GPU 104.2 MB
2024-12-29 13:12:12,258 - INFO - Model training completed in 8.59s
2024-12-29 13:12:12,302 - INFO - Prediction completed in 0.04s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 13:12:12,330 - INFO - Poison rate 0.2 completed in 8.67s
2024-12-29 13:12:12,335 - INFO - Loaded 112 existing results
2024-12-29 13:12:12,335 - INFO - Total results to save: 119
2024-12-29 13:12:12,336 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:12:12,342 - INFO - Saved 119 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:12:12,342 - INFO - Total evaluation time: 74.74s
2024-12-29 13:12:12,344 - INFO - 
Progress: 18.8% - Evaluating GTSRB with SVM (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:12:12,552 - INFO - Loading datasets...
2024-12-29 13:12:12,573 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:12:12,573 - INFO - Extracting validation features...
2024-12-29 13:12:12,574 - INFO - Extracting features from 3925 samples...
2024-12-29 13:12:21,899 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:12:21,905 - INFO - Validation feature extraction completed in 9.33s
2024-12-29 13:12:21,905 - INFO - Extracting training features...
2024-12-29 13:12:21,905 - INFO - Extracting features from 9469 samples...
2024-12-29 13:12:43,350 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:12:43,356 - INFO - Training feature extraction completed in 21.45s
2024-12-29 13:12:43,356 - INFO - Creating model for classifier: SVM
2024-12-29 13:12:43,356 - INFO - Using device: cuda
2024-12-29 13:12:43,356 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-29 13:12:43,356 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:12:43,356 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:12:43,357 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:12:43,953 - INFO - Feature scaling completed in 0.60s
2024-12-29 13:12:43,953 - INFO - Starting feature selection (k=50)
2024-12-29 13:12:43,964 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:12:43,964 - INFO - Starting anomaly detection
2024-12-29 13:12:47,668 - INFO - Anomaly detection completed in 3.70s
2024-12-29 13:12:47,668 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:12:47,668 - INFO - Total fit_transform time: 4.31s
2024-12-29 13:12:47,668 - INFO - Training set processing completed in 4.31s
2024-12-29 13:12:47,668 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:12:47,670 - INFO - Memory usage at start_fit: CPU 2761.5 MB, GPU 104.6 MB
2024-12-29 13:12:47,670 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:12:47,673 - INFO - Number of unique classes: 10
2024-12-29 13:12:47,742 - INFO - Fitted scaler and transformed data
2024-12-29 13:12:47,743 - INFO - Scaling time: 0.07s
2024-12-29 13:12:48,110 - INFO - Epoch 1/500, Train Loss: 0.9068, Val Loss: 0.1133
2024-12-29 13:12:48,505 - INFO - Epoch 2/500, Train Loss: 0.0932, Val Loss: 0.0943
2024-12-29 13:12:48,830 - INFO - Epoch 3/500, Train Loss: 0.0611, Val Loss: 0.0912
2024-12-29 13:12:49,142 - INFO - Epoch 4/500, Train Loss: 0.0423, Val Loss: 0.0911
2024-12-29 13:12:49,502 - INFO - Epoch 5/500, Train Loss: 0.0324, Val Loss: 0.0894
2024-12-29 13:12:49,843 - INFO - Epoch 6/500, Train Loss: 0.0263, Val Loss: 0.0900
2024-12-29 13:12:50,160 - INFO - Epoch 7/500, Train Loss: 0.0213, Val Loss: 0.0937
2024-12-29 13:12:50,501 - INFO - Epoch 8/500, Train Loss: 0.0175, Val Loss: 0.0927
2024-12-29 13:12:50,886 - INFO - Epoch 9/500, Train Loss: 0.0148, Val Loss: 0.0954
2024-12-29 13:12:51,219 - INFO - Epoch 10/500, Train Loss: 0.0125, Val Loss: 0.0932
2024-12-29 13:12:51,219 - INFO - Early stopping triggered at epoch 10
2024-12-29 13:12:51,219 - INFO - Training completed in 3.55s
2024-12-29 13:12:51,219 - INFO - Final memory usage: CPU 2761.5 MB, GPU 104.8 MB
2024-12-29 13:12:51,220 - INFO - Model training completed in 3.55s
2024-12-29 13:12:51,266 - INFO - Prediction completed in 0.05s
2024-12-29 13:12:51,274 - INFO - Poison rate 0.0 completed in 7.92s
2024-12-29 13:12:51,275 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:12:51,275 - INFO - Label flipping details:
2024-12-29 13:12:51,275 - INFO - - Source class: 1
2024-12-29 13:12:51,275 - INFO - - Target class: 0
2024-12-29 13:12:51,275 - INFO - - Available samples in source class: 955
2024-12-29 13:12:51,276 - INFO - - Requested samples to poison: 94
2024-12-29 13:12:51,276 - INFO - - Actual samples to flip: 94
2024-12-29 13:12:51,276 - INFO - - Samples remaining in source class: 861
2024-12-29 13:12:51,276 - INFO - Successfully flipped 94 labels from class 1 to 0
2024-12-29 13:12:51,276 - INFO - Total number of labels flipped: 94
2024-12-29 13:12:51,276 - INFO - Label flipping completed in 0.00s
2024-12-29 13:12:51,276 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:12:51,276 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:12:51,823 - INFO - Feature scaling completed in 0.55s
2024-12-29 13:12:51,823 - INFO - Starting feature selection (k=50)
2024-12-29 13:12:51,837 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:12:51,837 - INFO - Starting anomaly detection
2024-12-29 13:12:56,028 - INFO - Anomaly detection completed in 4.19s
2024-12-29 13:12:56,028 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:12:56,028 - INFO - Total fit_transform time: 4.75s
2024-12-29 13:12:56,028 - INFO - Training set processing completed in 4.75s
2024-12-29 13:12:56,028 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:12:56,030 - INFO - Memory usage at start_fit: CPU 2761.5 MB, GPU 104.7 MB
2024-12-29 13:12:56,030 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:12:56,033 - INFO - Number of unique classes: 10
2024-12-29 13:12:56,099 - INFO - Fitted scaler and transformed data
2024-12-29 13:12:56,099 - INFO - Scaling time: 0.06s
2024-12-29 13:12:56,509 - INFO - Epoch 1/500, Train Loss: 0.9199, Val Loss: 0.2413
2024-12-29 13:12:56,882 - INFO - Epoch 2/500, Train Loss: 0.1193, Val Loss: 0.2008
2024-12-29 13:12:57,236 - INFO - Epoch 3/500, Train Loss: 0.0865, Val Loss: 0.1856
2024-12-29 13:12:57,587 - INFO - Epoch 4/500, Train Loss: 0.0678, Val Loss: 0.1793
2024-12-29 13:12:57,961 - INFO - Epoch 5/500, Train Loss: 0.0573, Val Loss: 0.1717
2024-12-29 13:12:58,283 - INFO - Epoch 6/500, Train Loss: 0.0496, Val Loss: 0.1685
2024-12-29 13:12:58,597 - INFO - Epoch 7/500, Train Loss: 0.0442, Val Loss: 0.1678
2024-12-29 13:12:58,941 - INFO - Epoch 8/500, Train Loss: 0.0403, Val Loss: 0.1645
2024-12-29 13:12:59,256 - INFO - Epoch 9/500, Train Loss: 0.0375, Val Loss: 0.1648
2024-12-29 13:12:59,622 - INFO - Epoch 10/500, Train Loss: 0.0354, Val Loss: 0.1637
2024-12-29 13:13:00,017 - INFO - Epoch 11/500, Train Loss: 0.0331, Val Loss: 0.1626
2024-12-29 13:13:00,375 - INFO - Epoch 12/500, Train Loss: 0.0319, Val Loss: 0.1614
2024-12-29 13:13:00,758 - INFO - Epoch 13/500, Train Loss: 0.0306, Val Loss: 0.1615
2024-12-29 13:13:01,159 - INFO - Epoch 14/500, Train Loss: 0.0290, Val Loss: 0.1597
2024-12-29 13:13:01,536 - INFO - Epoch 15/500, Train Loss: 0.0279, Val Loss: 0.1598
2024-12-29 13:13:01,963 - INFO - Epoch 16/500, Train Loss: 0.0272, Val Loss: 0.1604
2024-12-29 13:13:02,300 - INFO - Epoch 17/500, Train Loss: 0.0268, Val Loss: 0.1533
2024-12-29 13:13:02,671 - INFO - Epoch 18/500, Train Loss: 0.0257, Val Loss: 0.1573
2024-12-29 13:13:03,087 - INFO - Epoch 19/500, Train Loss: 0.0250, Val Loss: 0.1562
2024-12-29 13:13:03,478 - INFO - Epoch 20/500, Train Loss: 0.0241, Val Loss: 0.1536
2024-12-29 13:13:03,819 - INFO - Epoch 21/500, Train Loss: 0.0244, Val Loss: 0.1570
2024-12-29 13:13:04,224 - INFO - Epoch 22/500, Train Loss: 0.0239, Val Loss: 0.1566
2024-12-29 13:13:04,224 - INFO - Early stopping triggered at epoch 22
2024-12-29 13:13:04,224 - INFO - Training completed in 8.20s
2024-12-29 13:13:04,224 - INFO - Final memory usage: CPU 2761.5 MB, GPU 104.8 MB
2024-12-29 13:13:04,225 - INFO - Model training completed in 8.20s
2024-12-29 13:13:04,288 - INFO - Prediction completed in 0.06s
2024-12-29 13:13:04,297 - INFO - Poison rate 0.01 completed in 13.02s
2024-12-29 13:13:04,297 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:13:04,298 - INFO - Label flipping details:
2024-12-29 13:13:04,298 - INFO - - Source class: 1
2024-12-29 13:13:04,298 - INFO - - Target class: 0
2024-12-29 13:13:04,298 - INFO - - Available samples in source class: 955
2024-12-29 13:13:04,298 - INFO - - Requested samples to poison: 284
2024-12-29 13:13:04,298 - INFO - - Actual samples to flip: 284
2024-12-29 13:13:04,298 - INFO - - Samples remaining in source class: 671
2024-12-29 13:13:04,298 - INFO - Successfully flipped 284 labels from class 1 to 0
2024-12-29 13:13:04,298 - INFO - Total number of labels flipped: 284
2024-12-29 13:13:04,299 - INFO - Label flipping completed in 0.00s
2024-12-29 13:13:04,299 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:13:04,299 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:13:04,927 - INFO - Feature scaling completed in 0.63s
2024-12-29 13:13:04,927 - INFO - Starting feature selection (k=50)
2024-12-29 13:13:04,941 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:13:04,941 - INFO - Starting anomaly detection
2024-12-29 13:13:08,865 - INFO - Anomaly detection completed in 3.92s
2024-12-29 13:13:08,865 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:13:08,866 - INFO - Total fit_transform time: 4.57s
2024-12-29 13:13:08,866 - INFO - Training set processing completed in 4.57s
2024-12-29 13:13:08,866 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:13:08,867 - INFO - Memory usage at start_fit: CPU 2761.5 MB, GPU 104.7 MB
2024-12-29 13:13:08,867 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:13:08,869 - INFO - Number of unique classes: 10
2024-12-29 13:13:08,937 - INFO - Fitted scaler and transformed data
2024-12-29 13:13:08,937 - INFO - Scaling time: 0.07s
2024-12-29 13:13:09,271 - INFO - Epoch 1/500, Train Loss: 0.8929, Val Loss: 0.2554
2024-12-29 13:13:09,639 - INFO - Epoch 2/500, Train Loss: 0.1638, Val Loss: 0.2152
2024-12-29 13:13:10,014 - INFO - Epoch 3/500, Train Loss: 0.1291, Val Loss: 0.1971
2024-12-29 13:13:10,409 - INFO - Epoch 4/500, Train Loss: 0.1101, Val Loss: 0.1907
2024-12-29 13:13:10,809 - INFO - Epoch 5/500, Train Loss: 0.0984, Val Loss: 0.1867
2024-12-29 13:13:11,233 - INFO - Epoch 6/500, Train Loss: 0.0891, Val Loss: 0.1862
2024-12-29 13:13:11,592 - INFO - Epoch 7/500, Train Loss: 0.0830, Val Loss: 0.1867
2024-12-29 13:13:11,992 - INFO - Epoch 8/500, Train Loss: 0.0790, Val Loss: 0.1885
2024-12-29 13:13:12,381 - INFO - Epoch 9/500, Train Loss: 0.0737, Val Loss: 0.1817
2024-12-29 13:13:12,778 - INFO - Epoch 10/500, Train Loss: 0.0711, Val Loss: 0.1829
2024-12-29 13:13:13,133 - INFO - Epoch 11/500, Train Loss: 0.0671, Val Loss: 0.1835
2024-12-29 13:13:13,501 - INFO - Epoch 12/500, Train Loss: 0.0655, Val Loss: 0.1805
2024-12-29 13:13:13,894 - INFO - Epoch 13/500, Train Loss: 0.0631, Val Loss: 0.1809
2024-12-29 13:13:14,249 - INFO - Epoch 14/500, Train Loss: 0.0614, Val Loss: 0.1799
2024-12-29 13:13:14,588 - INFO - Epoch 15/500, Train Loss: 0.0606, Val Loss: 0.1841
2024-12-29 13:13:14,962 - INFO - Epoch 16/500, Train Loss: 0.0596, Val Loss: 0.1900
2024-12-29 13:13:15,362 - INFO - Epoch 17/500, Train Loss: 0.0591, Val Loss: 0.1850
2024-12-29 13:13:15,362 - INFO - Early stopping triggered at epoch 17
2024-12-29 13:13:15,362 - INFO - Training completed in 6.50s
2024-12-29 13:13:15,363 - INFO - Final memory usage: CPU 2761.5 MB, GPU 104.8 MB
2024-12-29 13:13:15,364 - INFO - Model training completed in 6.50s
2024-12-29 13:13:15,421 - INFO - Prediction completed in 0.06s
2024-12-29 13:13:15,430 - INFO - Poison rate 0.03 completed in 11.13s
2024-12-29 13:13:15,430 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:13:15,431 - INFO - Label flipping details:
2024-12-29 13:13:15,431 - INFO - - Source class: 1
2024-12-29 13:13:15,431 - INFO - - Target class: 0
2024-12-29 13:13:15,431 - INFO - - Available samples in source class: 955
2024-12-29 13:13:15,431 - INFO - - Requested samples to poison: 473
2024-12-29 13:13:15,431 - INFO - - Actual samples to flip: 473
2024-12-29 13:13:15,431 - INFO - - Samples remaining in source class: 482
2024-12-29 13:13:15,431 - INFO - Successfully flipped 473 labels from class 1 to 0
2024-12-29 13:13:15,431 - INFO - Total number of labels flipped: 473
2024-12-29 13:13:15,431 - INFO - Label flipping completed in 0.00s
2024-12-29 13:13:15,432 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:13:15,432 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:13:16,000 - INFO - Feature scaling completed in 0.57s
2024-12-29 13:13:16,000 - INFO - Starting feature selection (k=50)
2024-12-29 13:13:16,013 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:13:16,014 - INFO - Starting anomaly detection
2024-12-29 13:13:20,201 - INFO - Anomaly detection completed in 4.19s
2024-12-29 13:13:20,202 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:13:20,202 - INFO - Total fit_transform time: 4.77s
2024-12-29 13:13:20,202 - INFO - Training set processing completed in 4.77s
2024-12-29 13:13:20,202 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:13:20,203 - INFO - Memory usage at start_fit: CPU 2761.5 MB, GPU 104.7 MB
2024-12-29 13:13:20,203 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:13:20,205 - INFO - Number of unique classes: 10
2024-12-29 13:13:20,269 - INFO - Fitted scaler and transformed data
2024-12-29 13:13:20,269 - INFO - Scaling time: 0.06s
2024-12-29 13:13:20,611 - INFO - Epoch 1/500, Train Loss: 0.9468, Val Loss: 0.2244
2024-12-29 13:13:20,944 - INFO - Epoch 2/500, Train Loss: 0.1863, Val Loss: 0.2033
2024-12-29 13:13:21,272 - INFO - Epoch 3/500, Train Loss: 0.1528, Val Loss: 0.1891
2024-12-29 13:13:21,615 - INFO - Epoch 4/500, Train Loss: 0.1327, Val Loss: 0.1819
2024-12-29 13:13:21,933 - INFO - Epoch 5/500, Train Loss: 0.1188, Val Loss: 0.1805
2024-12-29 13:13:22,246 - INFO - Epoch 6/500, Train Loss: 0.1108, Val Loss: 0.1753
2024-12-29 13:13:22,558 - INFO - Epoch 7/500, Train Loss: 0.1027, Val Loss: 0.1747
2024-12-29 13:13:22,913 - INFO - Epoch 8/500, Train Loss: 0.0986, Val Loss: 0.1761
2024-12-29 13:13:23,259 - INFO - Epoch 9/500, Train Loss: 0.0920, Val Loss: 0.1775
2024-12-29 13:13:23,628 - INFO - Epoch 10/500, Train Loss: 0.0910, Val Loss: 0.1738
2024-12-29 13:13:23,994 - INFO - Epoch 11/500, Train Loss: 0.0877, Val Loss: 0.1703
2024-12-29 13:13:24,360 - INFO - Epoch 12/500, Train Loss: 0.0843, Val Loss: 0.1783
2024-12-29 13:13:24,715 - INFO - Epoch 13/500, Train Loss: 0.0823, Val Loss: 0.1765
2024-12-29 13:13:25,038 - INFO - Epoch 14/500, Train Loss: 0.0816, Val Loss: 0.1747
2024-12-29 13:13:25,426 - INFO - Epoch 15/500, Train Loss: 0.0768, Val Loss: 0.1757
2024-12-29 13:13:25,756 - INFO - Epoch 16/500, Train Loss: 0.0765, Val Loss: 0.1784
2024-12-29 13:13:25,757 - INFO - Early stopping triggered at epoch 16
2024-12-29 13:13:25,757 - INFO - Training completed in 5.55s
2024-12-29 13:13:25,757 - INFO - Final memory usage: CPU 2761.5 MB, GPU 104.8 MB
2024-12-29 13:13:25,757 - INFO - Model training completed in 5.56s
2024-12-29 13:13:25,810 - INFO - Prediction completed in 0.05s
2024-12-29 13:13:25,819 - INFO - Poison rate 0.05 completed in 10.39s
2024-12-29 13:13:25,819 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:13:25,820 - INFO - Label flipping details:
2024-12-29 13:13:25,820 - INFO - - Source class: 1
2024-12-29 13:13:25,820 - INFO - - Target class: 0
2024-12-29 13:13:25,820 - INFO - - Available samples in source class: 955
2024-12-29 13:13:25,820 - INFO - - Requested samples to poison: 662
2024-12-29 13:13:25,820 - INFO - - Actual samples to flip: 662
2024-12-29 13:13:25,820 - INFO - - Samples remaining in source class: 293
2024-12-29 13:13:25,820 - INFO - Successfully flipped 662 labels from class 1 to 0
2024-12-29 13:13:25,820 - INFO - Total number of labels flipped: 662
2024-12-29 13:13:25,820 - INFO - Label flipping completed in 0.00s
2024-12-29 13:13:25,820 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:13:25,821 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:13:26,413 - INFO - Feature scaling completed in 0.59s
2024-12-29 13:13:26,413 - INFO - Starting feature selection (k=50)
2024-12-29 13:13:26,427 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:13:26,427 - INFO - Starting anomaly detection
2024-12-29 13:13:29,521 - INFO - Anomaly detection completed in 3.09s
2024-12-29 13:13:29,522 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:13:29,522 - INFO - Total fit_transform time: 3.70s
2024-12-29 13:13:29,522 - INFO - Training set processing completed in 3.70s
2024-12-29 13:13:29,522 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:13:29,523 - INFO - Memory usage at start_fit: CPU 2761.5 MB, GPU 104.7 MB
2024-12-29 13:13:29,524 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:13:29,526 - INFO - Number of unique classes: 10
2024-12-29 13:13:29,591 - INFO - Fitted scaler and transformed data
2024-12-29 13:13:29,592 - INFO - Scaling time: 0.06s
2024-12-29 13:13:29,965 - INFO - Epoch 1/500, Train Loss: 1.0351, Val Loss: 0.2281
2024-12-29 13:13:30,316 - INFO - Epoch 2/500, Train Loss: 0.1622, Val Loss: 0.1903
2024-12-29 13:13:30,703 - INFO - Epoch 3/500, Train Loss: 0.1274, Val Loss: 0.1741
2024-12-29 13:13:31,036 - INFO - Epoch 4/500, Train Loss: 0.1084, Val Loss: 0.1621
2024-12-29 13:13:31,377 - INFO - Epoch 5/500, Train Loss: 0.0970, Val Loss: 0.1519
2024-12-29 13:13:31,723 - INFO - Epoch 6/500, Train Loss: 0.0888, Val Loss: 0.1486
2024-12-29 13:13:32,097 - INFO - Epoch 7/500, Train Loss: 0.0835, Val Loss: 0.1443
2024-12-29 13:13:32,430 - INFO - Epoch 8/500, Train Loss: 0.0788, Val Loss: 0.1426
2024-12-29 13:13:32,763 - INFO - Epoch 9/500, Train Loss: 0.0749, Val Loss: 0.1430
2024-12-29 13:13:33,086 - INFO - Epoch 10/500, Train Loss: 0.0705, Val Loss: 0.1422
2024-12-29 13:13:33,455 - INFO - Epoch 11/500, Train Loss: 0.0692, Val Loss: 0.1464
2024-12-29 13:13:33,786 - INFO - Epoch 12/500, Train Loss: 0.0671, Val Loss: 0.1429
2024-12-29 13:13:34,114 - INFO - Epoch 13/500, Train Loss: 0.0663, Val Loss: 0.1412
2024-12-29 13:13:34,452 - INFO - Epoch 14/500, Train Loss: 0.0640, Val Loss: 0.1426
2024-12-29 13:13:34,815 - INFO - Epoch 15/500, Train Loss: 0.0627, Val Loss: 0.1459
2024-12-29 13:13:35,141 - INFO - Epoch 16/500, Train Loss: 0.0616, Val Loss: 0.1435
2024-12-29 13:13:35,481 - INFO - Epoch 17/500, Train Loss: 0.0606, Val Loss: 0.1454
2024-12-29 13:13:35,839 - INFO - Epoch 18/500, Train Loss: 0.0596, Val Loss: 0.1457
2024-12-29 13:13:35,840 - INFO - Early stopping triggered at epoch 18
2024-12-29 13:13:35,840 - INFO - Training completed in 6.32s
2024-12-29 13:13:35,840 - INFO - Final memory usage: CPU 2761.5 MB, GPU 104.8 MB
2024-12-29 13:13:35,840 - INFO - Model training completed in 6.32s
2024-12-29 13:13:35,891 - INFO - Prediction completed in 0.05s
2024-12-29 13:13:35,900 - INFO - Poison rate 0.07 completed in 10.08s
2024-12-29 13:13:35,900 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:13:35,901 - INFO - Label flipping details:
2024-12-29 13:13:35,901 - INFO - - Source class: 1
2024-12-29 13:13:35,901 - INFO - - Target class: 0
2024-12-29 13:13:35,901 - INFO - - Available samples in source class: 955
2024-12-29 13:13:35,902 - INFO - - Requested samples to poison: 946
2024-12-29 13:13:35,902 - INFO - - Actual samples to flip: 946
2024-12-29 13:13:35,902 - INFO - - Samples remaining in source class: 9
2024-12-29 13:13:35,902 - INFO - Successfully flipped 946 labels from class 1 to 0
2024-12-29 13:13:35,902 - INFO - Total number of labels flipped: 946
2024-12-29 13:13:35,902 - INFO - Label flipping completed in 0.00s
2024-12-29 13:13:35,902 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:13:35,902 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:13:36,458 - INFO - Feature scaling completed in 0.56s
2024-12-29 13:13:36,458 - INFO - Starting feature selection (k=50)
2024-12-29 13:13:36,472 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:13:36,472 - INFO - Starting anomaly detection
2024-12-29 13:13:40,412 - INFO - Anomaly detection completed in 3.94s
2024-12-29 13:13:40,412 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:13:40,412 - INFO - Total fit_transform time: 4.51s
2024-12-29 13:13:40,413 - INFO - Training set processing completed in 4.51s
2024-12-29 13:13:40,413 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:13:40,414 - INFO - Memory usage at start_fit: CPU 2761.5 MB, GPU 104.7 MB
2024-12-29 13:13:40,414 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:13:40,416 - INFO - Number of unique classes: 10
2024-12-29 13:13:40,488 - INFO - Fitted scaler and transformed data
2024-12-29 13:13:40,488 - INFO - Scaling time: 0.07s
2024-12-29 13:13:40,818 - INFO - Epoch 1/500, Train Loss: 0.8587, Val Loss: 0.1109
2024-12-29 13:13:41,131 - INFO - Epoch 2/500, Train Loss: 0.0918, Val Loss: 0.0886
2024-12-29 13:13:41,462 - INFO - Epoch 3/500, Train Loss: 0.0622, Val Loss: 0.0757
2024-12-29 13:13:41,791 - INFO - Epoch 4/500, Train Loss: 0.0469, Val Loss: 0.0709
2024-12-29 13:13:42,094 - INFO - Epoch 5/500, Train Loss: 0.0365, Val Loss: 0.0669
2024-12-29 13:13:42,414 - INFO - Epoch 6/500, Train Loss: 0.0297, Val Loss: 0.0635
2024-12-29 13:13:42,763 - INFO - Epoch 7/500, Train Loss: 0.0251, Val Loss: 0.0608
2024-12-29 13:13:43,104 - INFO - Epoch 8/500, Train Loss: 0.0214, Val Loss: 0.0595
2024-12-29 13:13:43,468 - INFO - Epoch 9/500, Train Loss: 0.0189, Val Loss: 0.0587
2024-12-29 13:13:43,810 - INFO - Epoch 10/500, Train Loss: 0.0163, Val Loss: 0.0587
2024-12-29 13:13:44,185 - INFO - Epoch 11/500, Train Loss: 0.0142, Val Loss: 0.0592
2024-12-29 13:13:44,508 - INFO - Epoch 12/500, Train Loss: 0.0128, Val Loss: 0.0570
2024-12-29 13:13:44,888 - INFO - Epoch 13/500, Train Loss: 0.0112, Val Loss: 0.0586
2024-12-29 13:13:45,251 - INFO - Epoch 14/500, Train Loss: 0.0101, Val Loss: 0.0594
2024-12-29 13:13:45,582 - INFO - Epoch 15/500, Train Loss: 0.0094, Val Loss: 0.0576
2024-12-29 13:13:45,993 - INFO - Epoch 16/500, Train Loss: 0.0081, Val Loss: 0.0574
2024-12-29 13:13:46,357 - INFO - Epoch 17/500, Train Loss: 0.0075, Val Loss: 0.0600
2024-12-29 13:13:46,358 - INFO - Early stopping triggered at epoch 17
2024-12-29 13:13:46,358 - INFO - Training completed in 5.94s
2024-12-29 13:13:46,359 - INFO - Final memory usage: CPU 2761.5 MB, GPU 104.8 MB
2024-12-29 13:13:46,359 - INFO - Model training completed in 5.95s
2024-12-29 13:13:46,411 - INFO - Prediction completed in 0.05s
2024-12-29 13:13:46,421 - INFO - Poison rate 0.1 completed in 10.52s
2024-12-29 13:13:46,421 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:13:46,421 - INFO - Label flipping details:
2024-12-29 13:13:46,422 - INFO - - Source class: 1
2024-12-29 13:13:46,422 - INFO - - Target class: 0
2024-12-29 13:13:46,422 - INFO - - Available samples in source class: 955
2024-12-29 13:13:46,422 - INFO - - Requested samples to poison: 1893
2024-12-29 13:13:46,422 - INFO - - Actual samples to flip: 954
2024-12-29 13:13:46,422 - INFO - - Samples remaining in source class: 1
2024-12-29 13:13:46,422 - INFO - Successfully flipped 954 labels from class 1 to 0
2024-12-29 13:13:46,422 - INFO - Total number of labels flipped: 954
2024-12-29 13:13:46,422 - INFO - Label flipping completed in 0.00s
2024-12-29 13:13:46,422 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:13:46,422 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:13:47,027 - INFO - Feature scaling completed in 0.60s
2024-12-29 13:13:47,027 - INFO - Starting feature selection (k=50)
2024-12-29 13:13:47,041 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:13:47,041 - INFO - Starting anomaly detection
2024-12-29 13:13:49,777 - INFO - Anomaly detection completed in 2.74s
2024-12-29 13:13:49,777 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:13:49,778 - INFO - Total fit_transform time: 3.36s
2024-12-29 13:13:49,778 - INFO - Training set processing completed in 3.36s
2024-12-29 13:13:49,778 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:13:49,779 - INFO - Memory usage at start_fit: CPU 2761.5 MB, GPU 104.7 MB
2024-12-29 13:13:49,779 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:13:49,782 - INFO - Number of unique classes: 10
2024-12-29 13:13:49,850 - INFO - Fitted scaler and transformed data
2024-12-29 13:13:49,850 - INFO - Scaling time: 0.07s
2024-12-29 13:13:50,180 - INFO - Epoch 1/500, Train Loss: 0.9497, Val Loss: 0.1151
2024-12-29 13:13:50,500 - INFO - Epoch 2/500, Train Loss: 0.0993, Val Loss: 0.0924
2024-12-29 13:13:50,827 - INFO - Epoch 3/500, Train Loss: 0.0668, Val Loss: 0.0802
2024-12-29 13:13:51,141 - INFO - Epoch 4/500, Train Loss: 0.0493, Val Loss: 0.0755
2024-12-29 13:13:51,509 - INFO - Epoch 5/500, Train Loss: 0.0382, Val Loss: 0.0718
2024-12-29 13:13:51,880 - INFO - Epoch 6/500, Train Loss: 0.0303, Val Loss: 0.0710
2024-12-29 13:13:52,229 - INFO - Epoch 7/500, Train Loss: 0.0253, Val Loss: 0.0689
2024-12-29 13:13:52,543 - INFO - Epoch 8/500, Train Loss: 0.0208, Val Loss: 0.0701
2024-12-29 13:13:52,860 - INFO - Epoch 9/500, Train Loss: 0.0178, Val Loss: 0.0702
2024-12-29 13:13:53,201 - INFO - Epoch 10/500, Train Loss: 0.0153, Val Loss: 0.0695
2024-12-29 13:13:53,525 - INFO - Epoch 11/500, Train Loss: 0.0131, Val Loss: 0.0687
2024-12-29 13:13:53,841 - INFO - Epoch 12/500, Train Loss: 0.0116, Val Loss: 0.0680
2024-12-29 13:13:53,841 - INFO - Early stopping triggered at epoch 12
2024-12-29 13:13:53,841 - INFO - Training completed in 4.06s
2024-12-29 13:13:53,842 - INFO - Final memory usage: CPU 2761.5 MB, GPU 104.8 MB
2024-12-29 13:13:53,842 - INFO - Model training completed in 4.06s
2024-12-29 13:13:53,889 - INFO - Prediction completed in 0.05s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 13:13:53,899 - INFO - Poison rate 0.2 completed in 7.48s
2024-12-29 13:13:53,902 - INFO - Loaded 119 existing results
2024-12-29 13:13:53,902 - INFO - Total results to save: 126
2024-12-29 13:13:53,903 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:13:53,907 - INFO - Saved 126 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:13:53,908 - INFO - Total evaluation time: 101.36s
2024-12-29 13:13:53,910 - INFO - 
Progress: 19.8% - Evaluating GTSRB with LogisticRegression (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:13:54,085 - INFO - Loading datasets...
2024-12-29 13:13:54,112 - INFO - Dataset loading completed in 0.03s
2024-12-29 13:13:54,112 - INFO - Extracting validation features...
2024-12-29 13:13:54,112 - INFO - Extracting features from 3925 samples...
2024-12-29 13:14:03,436 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:14:03,441 - INFO - Validation feature extraction completed in 9.33s
2024-12-29 13:14:03,441 - INFO - Extracting training features...
2024-12-29 13:14:03,441 - INFO - Extracting features from 9469 samples...
2024-12-29 13:14:24,989 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:14:24,997 - INFO - Training feature extraction completed in 21.56s
2024-12-29 13:14:24,998 - INFO - Creating model for classifier: LogisticRegression
2024-12-29 13:14:24,998 - INFO - Using device: cuda
2024-12-29 13:14:24,998 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:14:24,998 - INFO - Training set processing completed in 0.00s
2024-12-29 13:14:24,998 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:14:25,000 - INFO - Memory usage at start_fit: CPU 2768.7 MB, GPU 104.0 MB
2024-12-29 13:14:25,000 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:14:25,007 - INFO - Number of unique classes: 10
2024-12-29 13:14:25,071 - INFO - Fitted scaler and transformed data
2024-12-29 13:14:25,071 - INFO - Scaling time: 0.06s
2024-12-29 13:14:25,459 - INFO - Epoch 1/1000, Train Loss: 0.4719, Val Loss: 0.1238
2024-12-29 13:14:25,869 - INFO - Epoch 2/1000, Train Loss: 0.0929, Val Loss: 0.0855
2024-12-29 13:14:26,261 - INFO - Epoch 3/1000, Train Loss: 0.0667, Val Loss: 0.0713
2024-12-29 13:14:26,608 - INFO - Epoch 4/1000, Train Loss: 0.0540, Val Loss: 0.0643
2024-12-29 13:14:26,984 - INFO - Epoch 5/1000, Train Loss: 0.0466, Val Loss: 0.0602
2024-12-29 13:14:27,383 - INFO - Epoch 6/1000, Train Loss: 0.0417, Val Loss: 0.0585
2024-12-29 13:14:27,763 - INFO - Epoch 7/1000, Train Loss: 0.0382, Val Loss: 0.0563
2024-12-29 13:14:27,978 - INFO - Epoch 8/1000, Train Loss: 0.0358, Val Loss: 0.0548
2024-12-29 13:14:28,159 - INFO - Epoch 9/1000, Train Loss: 0.0339, Val Loss: 0.0546
2024-12-29 13:14:28,355 - INFO - Epoch 10/1000, Train Loss: 0.0328, Val Loss: 0.0545
2024-12-29 13:14:28,541 - INFO - Epoch 11/1000, Train Loss: 0.0317, Val Loss: 0.0538
2024-12-29 13:14:28,731 - INFO - Epoch 12/1000, Train Loss: 0.0308, Val Loss: 0.0533
2024-12-29 13:14:28,949 - INFO - Epoch 13/1000, Train Loss: 0.0305, Val Loss: 0.0531
2024-12-29 13:14:29,152 - INFO - Epoch 14/1000, Train Loss: 0.0299, Val Loss: 0.0532
2024-12-29 13:14:29,359 - INFO - Epoch 15/1000, Train Loss: 0.0295, Val Loss: 0.0526
2024-12-29 13:14:29,563 - INFO - Epoch 16/1000, Train Loss: 0.0292, Val Loss: 0.0534
2024-12-29 13:14:29,781 - INFO - Epoch 17/1000, Train Loss: 0.0286, Val Loss: 0.0528
2024-12-29 13:14:30,015 - INFO - Epoch 18/1000, Train Loss: 0.0287, Val Loss: 0.0523
2024-12-29 13:14:30,223 - INFO - Epoch 19/1000, Train Loss: 0.0285, Val Loss: 0.0523
2024-12-29 13:14:30,430 - INFO - Epoch 20/1000, Train Loss: 0.0281, Val Loss: 0.0523
2024-12-29 13:14:30,430 - INFO - Early stopping triggered at epoch 20
2024-12-29 13:14:30,431 - INFO - Training completed in 5.43s
2024-12-29 13:14:30,431 - INFO - Final memory usage: CPU 2717.5 MB, GPU 104.2 MB
2024-12-29 13:14:30,434 - INFO - Model training completed in 5.44s
2024-12-29 13:14:30,505 - INFO - Prediction completed in 0.07s
2024-12-29 13:14:30,514 - INFO - Poison rate 0.0 completed in 5.52s
2024-12-29 13:14:30,514 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:14:30,515 - INFO - Label flipping details:
2024-12-29 13:14:30,515 - INFO - - Source class: 1
2024-12-29 13:14:30,515 - INFO - - Target class: 0
2024-12-29 13:14:30,515 - INFO - - Available samples in source class: 955
2024-12-29 13:14:30,515 - INFO - - Requested samples to poison: 94
2024-12-29 13:14:30,515 - INFO - - Actual samples to flip: 94
2024-12-29 13:14:30,515 - INFO - - Samples remaining in source class: 861
2024-12-29 13:14:30,515 - INFO - Successfully flipped 94 labels from class 1 to 0
2024-12-29 13:14:30,515 - INFO - Total number of labels flipped: 94
2024-12-29 13:14:30,516 - INFO - Label flipping completed in 0.00s
2024-12-29 13:14:30,516 - INFO - Training set processing completed in 0.00s
2024-12-29 13:14:30,516 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:14:30,517 - INFO - Memory usage at start_fit: CPU 2692.0 MB, GPU 104.1 MB
2024-12-29 13:14:30,517 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:14:30,520 - INFO - Number of unique classes: 10
2024-12-29 13:14:30,592 - INFO - Fitted scaler and transformed data
2024-12-29 13:14:30,593 - INFO - Scaling time: 0.07s
2024-12-29 13:14:30,804 - INFO - Epoch 1/1000, Train Loss: 0.5340, Val Loss: 0.1608
2024-12-29 13:14:31,004 - INFO - Epoch 2/1000, Train Loss: 0.1347, Val Loss: 0.1210
2024-12-29 13:14:31,215 - INFO - Epoch 3/1000, Train Loss: 0.1046, Val Loss: 0.1054
2024-12-29 13:14:31,418 - INFO - Epoch 4/1000, Train Loss: 0.0895, Val Loss: 0.0974
2024-12-29 13:14:31,620 - INFO - Epoch 5/1000, Train Loss: 0.0808, Val Loss: 0.0930
2024-12-29 13:14:31,833 - INFO - Epoch 6/1000, Train Loss: 0.0746, Val Loss: 0.0932
2024-12-29 13:14:32,078 - INFO - Epoch 7/1000, Train Loss: 0.0706, Val Loss: 0.0887
2024-12-29 13:14:32,318 - INFO - Epoch 8/1000, Train Loss: 0.0682, Val Loss: 0.0871
2024-12-29 13:14:32,526 - INFO - Epoch 9/1000, Train Loss: 0.0651, Val Loss: 0.0862
2024-12-29 13:14:32,756 - INFO - Epoch 10/1000, Train Loss: 0.0628, Val Loss: 0.0873
2024-12-29 13:14:32,975 - INFO - Epoch 11/1000, Train Loss: 0.0613, Val Loss: 0.0871
2024-12-29 13:14:33,203 - INFO - Epoch 12/1000, Train Loss: 0.0601, Val Loss: 0.0847
2024-12-29 13:14:33,420 - INFO - Epoch 13/1000, Train Loss: 0.0595, Val Loss: 0.0849
2024-12-29 13:14:33,630 - INFO - Epoch 14/1000, Train Loss: 0.0585, Val Loss: 0.0841
2024-12-29 13:14:33,867 - INFO - Epoch 15/1000, Train Loss: 0.0579, Val Loss: 0.0839
2024-12-29 13:14:34,067 - INFO - Epoch 16/1000, Train Loss: 0.0578, Val Loss: 0.0842
2024-12-29 13:14:34,261 - INFO - Epoch 17/1000, Train Loss: 0.0563, Val Loss: 0.0833
2024-12-29 13:14:34,495 - INFO - Epoch 18/1000, Train Loss: 0.0565, Val Loss: 0.0844
2024-12-29 13:14:34,712 - INFO - Epoch 19/1000, Train Loss: 0.0558, Val Loss: 0.0847
2024-12-29 13:14:34,909 - INFO - Epoch 20/1000, Train Loss: 0.0556, Val Loss: 0.0836
2024-12-29 13:14:35,114 - INFO - Epoch 21/1000, Train Loss: 0.0552, Val Loss: 0.0839
2024-12-29 13:14:35,315 - INFO - Epoch 22/1000, Train Loss: 0.0546, Val Loss: 0.0833
2024-12-29 13:14:35,315 - INFO - Early stopping triggered at epoch 22
2024-12-29 13:14:35,315 - INFO - Training completed in 4.80s
2024-12-29 13:14:35,315 - INFO - Final memory usage: CPU 2717.2 MB, GPU 104.2 MB
2024-12-29 13:14:35,316 - INFO - Model training completed in 4.80s
2024-12-29 13:14:35,410 - INFO - Prediction completed in 0.09s
2024-12-29 13:14:35,418 - INFO - Poison rate 0.01 completed in 4.90s
2024-12-29 13:14:35,418 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:14:35,419 - INFO - Label flipping details:
2024-12-29 13:14:35,419 - INFO - - Source class: 1
2024-12-29 13:14:35,419 - INFO - - Target class: 0
2024-12-29 13:14:35,419 - INFO - - Available samples in source class: 955
2024-12-29 13:14:35,419 - INFO - - Requested samples to poison: 284
2024-12-29 13:14:35,419 - INFO - - Actual samples to flip: 284
2024-12-29 13:14:35,419 - INFO - - Samples remaining in source class: 671
2024-12-29 13:14:35,419 - INFO - Successfully flipped 284 labels from class 1 to 0
2024-12-29 13:14:35,419 - INFO - Total number of labels flipped: 284
2024-12-29 13:14:35,420 - INFO - Label flipping completed in 0.00s
2024-12-29 13:14:35,420 - INFO - Training set processing completed in 0.00s
2024-12-29 13:14:35,420 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:14:35,420 - INFO - Memory usage at start_fit: CPU 2691.9 MB, GPU 104.1 MB
2024-12-29 13:14:35,421 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:14:35,423 - INFO - Number of unique classes: 10
2024-12-29 13:14:35,492 - INFO - Fitted scaler and transformed data
2024-12-29 13:14:35,492 - INFO - Scaling time: 0.07s
2024-12-29 13:14:35,724 - INFO - Epoch 1/1000, Train Loss: 0.5303, Val Loss: 0.1907
2024-12-29 13:14:35,923 - INFO - Epoch 2/1000, Train Loss: 0.1600, Val Loss: 0.1622
2024-12-29 13:14:36,139 - INFO - Epoch 3/1000, Train Loss: 0.1308, Val Loss: 0.1413
2024-12-29 13:14:36,368 - INFO - Epoch 4/1000, Train Loss: 0.1158, Val Loss: 0.1351
2024-12-29 13:14:36,573 - INFO - Epoch 5/1000, Train Loss: 0.1068, Val Loss: 0.1364
2024-12-29 13:14:36,770 - INFO - Epoch 6/1000, Train Loss: 0.1003, Val Loss: 0.1324
2024-12-29 13:14:36,974 - INFO - Epoch 7/1000, Train Loss: 0.0953, Val Loss: 0.1298
2024-12-29 13:14:37,191 - INFO - Epoch 8/1000, Train Loss: 0.0919, Val Loss: 0.1304
2024-12-29 13:14:37,408 - INFO - Epoch 9/1000, Train Loss: 0.0897, Val Loss: 0.1289
2024-12-29 13:14:37,593 - INFO - Epoch 10/1000, Train Loss: 0.0870, Val Loss: 0.1298
2024-12-29 13:14:37,785 - INFO - Epoch 11/1000, Train Loss: 0.0864, Val Loss: 0.1323
2024-12-29 13:14:38,010 - INFO - Epoch 12/1000, Train Loss: 0.0849, Val Loss: 0.1318
2024-12-29 13:14:38,010 - INFO - Early stopping triggered at epoch 12
2024-12-29 13:14:38,010 - INFO - Training completed in 2.59s
2024-12-29 13:14:38,010 - INFO - Final memory usage: CPU 2717.3 MB, GPU 104.2 MB
2024-12-29 13:14:38,011 - INFO - Model training completed in 2.59s
2024-12-29 13:14:38,058 - INFO - Prediction completed in 0.05s
2024-12-29 13:14:38,066 - INFO - Poison rate 0.03 completed in 2.65s
2024-12-29 13:14:38,067 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:14:38,068 - INFO - Label flipping details:
2024-12-29 13:14:38,068 - INFO - - Source class: 1
2024-12-29 13:14:38,068 - INFO - - Target class: 0
2024-12-29 13:14:38,068 - INFO - - Available samples in source class: 955
2024-12-29 13:14:38,068 - INFO - - Requested samples to poison: 473
2024-12-29 13:14:38,068 - INFO - - Actual samples to flip: 473
2024-12-29 13:14:38,068 - INFO - - Samples remaining in source class: 482
2024-12-29 13:14:38,068 - INFO - Successfully flipped 473 labels from class 1 to 0
2024-12-29 13:14:38,068 - INFO - Total number of labels flipped: 473
2024-12-29 13:14:38,068 - INFO - Label flipping completed in 0.00s
2024-12-29 13:14:38,068 - INFO - Training set processing completed in 0.00s
2024-12-29 13:14:38,068 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:14:38,069 - INFO - Memory usage at start_fit: CPU 2691.9 MB, GPU 104.1 MB
2024-12-29 13:14:38,069 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:14:38,074 - INFO - Number of unique classes: 10
2024-12-29 13:14:38,144 - INFO - Fitted scaler and transformed data
2024-12-29 13:14:38,144 - INFO - Scaling time: 0.07s
2024-12-29 13:14:38,355 - INFO - Epoch 1/1000, Train Loss: 0.5781, Val Loss: 0.2187
2024-12-29 13:14:38,584 - INFO - Epoch 2/1000, Train Loss: 0.1720, Val Loss: 0.1741
2024-12-29 13:14:38,782 - INFO - Epoch 3/1000, Train Loss: 0.1414, Val Loss: 0.1599
2024-12-29 13:14:39,004 - INFO - Epoch 4/1000, Train Loss: 0.1254, Val Loss: 0.1488
2024-12-29 13:14:39,233 - INFO - Epoch 5/1000, Train Loss: 0.1162, Val Loss: 0.1471
2024-12-29 13:14:39,491 - INFO - Epoch 6/1000, Train Loss: 0.1102, Val Loss: 0.1544
2024-12-29 13:14:39,717 - INFO - Epoch 7/1000, Train Loss: 0.1062, Val Loss: 0.1469
2024-12-29 13:14:39,927 - INFO - Epoch 8/1000, Train Loss: 0.1017, Val Loss: 0.1383
2024-12-29 13:14:40,140 - INFO - Epoch 9/1000, Train Loss: 0.0990, Val Loss: 0.1430
2024-12-29 13:14:40,366 - INFO - Epoch 10/1000, Train Loss: 0.0967, Val Loss: 0.1389
2024-12-29 13:14:40,592 - INFO - Epoch 11/1000, Train Loss: 0.0956, Val Loss: 0.1352
2024-12-29 13:14:40,782 - INFO - Epoch 12/1000, Train Loss: 0.0933, Val Loss: 0.1368
2024-12-29 13:14:40,977 - INFO - Epoch 13/1000, Train Loss: 0.0921, Val Loss: 0.1421
2024-12-29 13:14:41,180 - INFO - Epoch 14/1000, Train Loss: 0.0911, Val Loss: 0.1370
2024-12-29 13:14:41,403 - INFO - Epoch 15/1000, Train Loss: 0.0905, Val Loss: 0.1351
2024-12-29 13:14:41,584 - INFO - Epoch 16/1000, Train Loss: 0.0901, Val Loss: 0.1424
2024-12-29 13:14:41,585 - INFO - Early stopping triggered at epoch 16
2024-12-29 13:14:41,585 - INFO - Training completed in 3.52s
2024-12-29 13:14:41,585 - INFO - Final memory usage: CPU 2717.4 MB, GPU 104.2 MB
2024-12-29 13:14:41,586 - INFO - Model training completed in 3.52s
2024-12-29 13:14:41,636 - INFO - Prediction completed in 0.05s
2024-12-29 13:14:41,644 - INFO - Poison rate 0.05 completed in 3.58s
2024-12-29 13:14:41,644 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:14:41,645 - INFO - Label flipping details:
2024-12-29 13:14:41,645 - INFO - - Source class: 1
2024-12-29 13:14:41,645 - INFO - - Target class: 0
2024-12-29 13:14:41,645 - INFO - - Available samples in source class: 955
2024-12-29 13:14:41,645 - INFO - - Requested samples to poison: 662
2024-12-29 13:14:41,645 - INFO - - Actual samples to flip: 662
2024-12-29 13:14:41,645 - INFO - - Samples remaining in source class: 293
2024-12-29 13:14:41,645 - INFO - Successfully flipped 662 labels from class 1 to 0
2024-12-29 13:14:41,646 - INFO - Total number of labels flipped: 662
2024-12-29 13:14:41,646 - INFO - Label flipping completed in 0.00s
2024-12-29 13:14:41,646 - INFO - Training set processing completed in 0.00s
2024-12-29 13:14:41,646 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:14:41,647 - INFO - Memory usage at start_fit: CPU 2691.7 MB, GPU 104.1 MB
2024-12-29 13:14:41,647 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:14:41,651 - INFO - Number of unique classes: 10
2024-12-29 13:14:41,721 - INFO - Fitted scaler and transformed data
2024-12-29 13:14:41,721 - INFO - Scaling time: 0.07s
2024-12-29 13:14:41,935 - INFO - Epoch 1/1000, Train Loss: 0.5483, Val Loss: 0.1813
2024-12-29 13:14:42,140 - INFO - Epoch 2/1000, Train Loss: 0.1664, Val Loss: 0.1413
2024-12-29 13:14:42,338 - INFO - Epoch 3/1000, Train Loss: 0.1346, Val Loss: 0.1293
2024-12-29 13:14:42,536 - INFO - Epoch 4/1000, Train Loss: 0.1192, Val Loss: 0.1229
2024-12-29 13:14:42,738 - INFO - Epoch 5/1000, Train Loss: 0.1104, Val Loss: 0.1213
2024-12-29 13:14:42,936 - INFO - Epoch 6/1000, Train Loss: 0.1039, Val Loss: 0.1197
2024-12-29 13:14:43,136 - INFO - Epoch 7/1000, Train Loss: 0.1000, Val Loss: 0.1169
2024-12-29 13:14:43,348 - INFO - Epoch 8/1000, Train Loss: 0.0962, Val Loss: 0.1176
2024-12-29 13:14:43,543 - INFO - Epoch 9/1000, Train Loss: 0.0938, Val Loss: 0.1169
2024-12-29 13:14:43,753 - INFO - Epoch 10/1000, Train Loss: 0.0920, Val Loss: 0.1172
2024-12-29 13:14:43,962 - INFO - Epoch 11/1000, Train Loss: 0.0908, Val Loss: 0.1165
2024-12-29 13:14:44,160 - INFO - Epoch 12/1000, Train Loss: 0.0889, Val Loss: 0.1152
2024-12-29 13:14:44,372 - INFO - Epoch 13/1000, Train Loss: 0.0884, Val Loss: 0.1151
2024-12-29 13:14:44,600 - INFO - Epoch 14/1000, Train Loss: 0.0870, Val Loss: 0.1161
2024-12-29 13:14:44,823 - INFO - Epoch 15/1000, Train Loss: 0.0871, Val Loss: 0.1174
2024-12-29 13:14:45,002 - INFO - Epoch 16/1000, Train Loss: 0.0863, Val Loss: 0.1148
2024-12-29 13:14:45,203 - INFO - Epoch 17/1000, Train Loss: 0.0852, Val Loss: 0.1172
2024-12-29 13:14:45,203 - INFO - Early stopping triggered at epoch 17
2024-12-29 13:14:45,204 - INFO - Training completed in 3.56s
2024-12-29 13:14:45,204 - INFO - Final memory usage: CPU 2717.5 MB, GPU 104.2 MB
2024-12-29 13:14:45,207 - INFO - Model training completed in 3.56s
2024-12-29 13:14:45,287 - INFO - Prediction completed in 0.08s
2024-12-29 13:14:45,296 - INFO - Poison rate 0.07 completed in 3.65s
2024-12-29 13:14:45,297 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:14:45,297 - INFO - Label flipping details:
2024-12-29 13:14:45,297 - INFO - - Source class: 1
2024-12-29 13:14:45,297 - INFO - - Target class: 0
2024-12-29 13:14:45,297 - INFO - - Available samples in source class: 955
2024-12-29 13:14:45,297 - INFO - - Requested samples to poison: 946
2024-12-29 13:14:45,298 - INFO - - Actual samples to flip: 946
2024-12-29 13:14:45,298 - INFO - - Samples remaining in source class: 9
2024-12-29 13:14:45,298 - INFO - Successfully flipped 946 labels from class 1 to 0
2024-12-29 13:14:45,298 - INFO - Total number of labels flipped: 946
2024-12-29 13:14:45,298 - INFO - Label flipping completed in 0.00s
2024-12-29 13:14:45,298 - INFO - Training set processing completed in 0.00s
2024-12-29 13:14:45,298 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:14:45,299 - INFO - Memory usage at start_fit: CPU 2691.8 MB, GPU 104.1 MB
2024-12-29 13:14:45,299 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:14:45,302 - INFO - Number of unique classes: 10
2024-12-29 13:14:45,372 - INFO - Fitted scaler and transformed data
2024-12-29 13:14:45,372 - INFO - Scaling time: 0.07s
2024-12-29 13:14:45,597 - INFO - Epoch 1/1000, Train Loss: 0.5447, Val Loss: 0.1370
2024-12-29 13:14:45,802 - INFO - Epoch 2/1000, Train Loss: 0.1061, Val Loss: 0.0952
2024-12-29 13:14:46,030 - INFO - Epoch 3/1000, Train Loss: 0.0763, Val Loss: 0.0789
2024-12-29 13:14:46,250 - INFO - Epoch 4/1000, Train Loss: 0.0624, Val Loss: 0.0712
2024-12-29 13:14:46,449 - INFO - Epoch 5/1000, Train Loss: 0.0538, Val Loss: 0.0668
2024-12-29 13:14:46,654 - INFO - Epoch 6/1000, Train Loss: 0.0481, Val Loss: 0.0643
2024-12-29 13:14:46,872 - INFO - Epoch 7/1000, Train Loss: 0.0444, Val Loss: 0.0620
2024-12-29 13:14:47,070 - INFO - Epoch 8/1000, Train Loss: 0.0420, Val Loss: 0.0617
2024-12-29 13:14:47,286 - INFO - Epoch 9/1000, Train Loss: 0.0397, Val Loss: 0.0601
2024-12-29 13:14:47,511 - INFO - Epoch 10/1000, Train Loss: 0.0383, Val Loss: 0.0601
2024-12-29 13:14:47,718 - INFO - Epoch 11/1000, Train Loss: 0.0364, Val Loss: 0.0588
2024-12-29 13:14:47,919 - INFO - Epoch 12/1000, Train Loss: 0.0356, Val Loss: 0.0582
2024-12-29 13:14:48,127 - INFO - Epoch 13/1000, Train Loss: 0.0349, Val Loss: 0.0585
2024-12-29 13:14:48,320 - INFO - Epoch 14/1000, Train Loss: 0.0345, Val Loss: 0.0581
2024-12-29 13:14:48,536 - INFO - Epoch 15/1000, Train Loss: 0.0342, Val Loss: 0.0585
2024-12-29 13:14:48,726 - INFO - Epoch 16/1000, Train Loss: 0.0336, Val Loss: 0.0587
2024-12-29 13:14:48,726 - INFO - Early stopping triggered at epoch 16
2024-12-29 13:14:48,726 - INFO - Training completed in 3.43s
2024-12-29 13:14:48,727 - INFO - Final memory usage: CPU 2717.4 MB, GPU 104.2 MB
2024-12-29 13:14:48,728 - INFO - Model training completed in 3.43s
2024-12-29 13:14:48,819 - INFO - Prediction completed in 0.09s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 13:14:48,828 - INFO - Poison rate 0.1 completed in 3.53s
2024-12-29 13:14:48,828 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:14:48,829 - INFO - Label flipping details:
2024-12-29 13:14:48,829 - INFO - - Source class: 1
2024-12-29 13:14:48,829 - INFO - - Target class: 0
2024-12-29 13:14:48,829 - INFO - - Available samples in source class: 955
2024-12-29 13:14:48,829 - INFO - - Requested samples to poison: 1893
2024-12-29 13:14:48,829 - INFO - - Actual samples to flip: 954
2024-12-29 13:14:48,829 - INFO - - Samples remaining in source class: 1
2024-12-29 13:14:48,829 - INFO - Successfully flipped 954 labels from class 1 to 0
2024-12-29 13:14:48,829 - INFO - Total number of labels flipped: 954
2024-12-29 13:14:48,829 - INFO - Label flipping completed in 0.00s
2024-12-29 13:14:48,830 - INFO - Training set processing completed in 0.00s
2024-12-29 13:14:48,830 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:14:48,831 - INFO - Memory usage at start_fit: CPU 2691.9 MB, GPU 104.1 MB
2024-12-29 13:14:48,831 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:14:48,834 - INFO - Number of unique classes: 10
2024-12-29 13:14:48,921 - INFO - Fitted scaler and transformed data
2024-12-29 13:14:48,921 - INFO - Scaling time: 0.09s
2024-12-29 13:14:49,159 - INFO - Epoch 1/1000, Train Loss: 0.4748, Val Loss: 0.1087
2024-12-29 13:14:49,360 - INFO - Epoch 2/1000, Train Loss: 0.0981, Val Loss: 0.0722
2024-12-29 13:14:49,570 - INFO - Epoch 3/1000, Train Loss: 0.0708, Val Loss: 0.0590
2024-12-29 13:14:49,793 - INFO - Epoch 4/1000, Train Loss: 0.0575, Val Loss: 0.0518
2024-12-29 13:14:50,015 - INFO - Epoch 5/1000, Train Loss: 0.0498, Val Loss: 0.0482
2024-12-29 13:14:50,242 - INFO - Epoch 6/1000, Train Loss: 0.0445, Val Loss: 0.0460
2024-12-29 13:14:50,453 - INFO - Epoch 7/1000, Train Loss: 0.0409, Val Loss: 0.0453
2024-12-29 13:14:50,676 - INFO - Epoch 8/1000, Train Loss: 0.0382, Val Loss: 0.0446
2024-12-29 13:14:50,896 - INFO - Epoch 9/1000, Train Loss: 0.0363, Val Loss: 0.0437
2024-12-29 13:14:51,104 - INFO - Epoch 10/1000, Train Loss: 0.0349, Val Loss: 0.0433
2024-12-29 13:14:51,323 - INFO - Epoch 11/1000, Train Loss: 0.0337, Val Loss: 0.0434
2024-12-29 13:14:51,555 - INFO - Epoch 12/1000, Train Loss: 0.0327, Val Loss: 0.0430
2024-12-29 13:14:51,765 - INFO - Epoch 13/1000, Train Loss: 0.0322, Val Loss: 0.0432
2024-12-29 13:14:51,972 - INFO - Epoch 14/1000, Train Loss: 0.0318, Val Loss: 0.0430
2024-12-29 13:14:52,175 - INFO - Epoch 15/1000, Train Loss: 0.0312, Val Loss: 0.0424
2024-12-29 13:14:52,175 - INFO - Early stopping triggered at epoch 15
2024-12-29 13:14:52,175 - INFO - Training completed in 3.34s
2024-12-29 13:14:52,175 - INFO - Final memory usage: CPU 2717.5 MB, GPU 104.2 MB
2024-12-29 13:14:52,175 - INFO - Model training completed in 3.35s
2024-12-29 13:14:52,235 - INFO - Prediction completed in 0.06s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 13:14:52,245 - INFO - Poison rate 0.2 completed in 3.42s
2024-12-29 13:14:52,248 - INFO - Loaded 126 existing results
2024-12-29 13:14:52,248 - INFO - Total results to save: 133
2024-12-29 13:14:52,249 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:14:52,254 - INFO - Saved 133 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:14:52,254 - INFO - Total evaluation time: 58.17s
2024-12-29 13:14:52,255 - INFO - 
Progress: 20.8% - Evaluating GTSRB with LogisticRegression (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:14:52,460 - INFO - Loading datasets...
2024-12-29 13:14:52,481 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:14:52,481 - INFO - Extracting validation features...
2024-12-29 13:14:52,481 - INFO - Extracting features from 3925 samples...
2024-12-29 13:15:01,476 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:15:01,481 - INFO - Validation feature extraction completed in 9.00s
2024-12-29 13:15:01,482 - INFO - Extracting training features...
2024-12-29 13:15:01,482 - INFO - Extracting features from 9469 samples...
2024-12-29 13:15:22,950 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:15:22,954 - INFO - Training feature extraction completed in 21.47s
2024-12-29 13:15:22,954 - INFO - Creating model for classifier: LogisticRegression
2024-12-29 13:15:22,954 - INFO - Using device: cuda
2024-12-29 13:15:22,954 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:15:22,954 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:15:22,954 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:15:23,512 - INFO - Feature scaling completed in 0.56s
2024-12-29 13:15:23,512 - INFO - Starting feature selection (k=50)
2024-12-29 13:15:23,521 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:15:23,521 - INFO - Starting anomaly detection
2024-12-29 13:15:25,499 - INFO - Anomaly detection completed in 1.98s
2024-12-29 13:15:25,499 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:15:25,499 - INFO - Total fit_transform time: 2.54s
2024-12-29 13:15:25,499 - INFO - Training set processing completed in 2.55s
2024-12-29 13:15:25,499 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:15:25,501 - INFO - Memory usage at start_fit: CPU 2766.6 MB, GPU 104.0 MB
2024-12-29 13:15:25,501 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:15:25,505 - INFO - Number of unique classes: 10
2024-12-29 13:15:25,588 - INFO - Fitted scaler and transformed data
2024-12-29 13:15:25,589 - INFO - Scaling time: 0.08s
2024-12-29 13:15:25,820 - INFO - Epoch 1/1000, Train Loss: 0.4331, Val Loss: 0.1228
2024-12-29 13:15:26,021 - INFO - Epoch 2/1000, Train Loss: 0.0910, Val Loss: 0.0869
2024-12-29 13:15:26,219 - INFO - Epoch 3/1000, Train Loss: 0.0658, Val Loss: 0.0739
2024-12-29 13:15:26,416 - INFO - Epoch 4/1000, Train Loss: 0.0531, Val Loss: 0.0675
2024-12-29 13:15:26,639 - INFO - Epoch 5/1000, Train Loss: 0.0459, Val Loss: 0.0641
2024-12-29 13:15:26,900 - INFO - Epoch 6/1000, Train Loss: 0.0410, Val Loss: 0.0630
2024-12-29 13:15:27,130 - INFO - Epoch 7/1000, Train Loss: 0.0377, Val Loss: 0.0611
2024-12-29 13:15:27,349 - INFO - Epoch 8/1000, Train Loss: 0.0353, Val Loss: 0.0609
2024-12-29 13:15:27,604 - INFO - Epoch 9/1000, Train Loss: 0.0333, Val Loss: 0.0602
2024-12-29 13:15:27,855 - INFO - Epoch 10/1000, Train Loss: 0.0321, Val Loss: 0.0610
2024-12-29 13:15:28,080 - INFO - Epoch 11/1000, Train Loss: 0.0311, Val Loss: 0.0599
2024-12-29 13:15:28,304 - INFO - Epoch 12/1000, Train Loss: 0.0304, Val Loss: 0.0603
2024-12-29 13:15:28,556 - INFO - Epoch 13/1000, Train Loss: 0.0302, Val Loss: 0.0605
2024-12-29 13:15:28,766 - INFO - Epoch 14/1000, Train Loss: 0.0293, Val Loss: 0.0606
2024-12-29 13:15:28,980 - INFO - Epoch 15/1000, Train Loss: 0.0288, Val Loss: 0.0598
2024-12-29 13:15:29,197 - INFO - Epoch 16/1000, Train Loss: 0.0290, Val Loss: 0.0596
2024-12-29 13:15:29,197 - INFO - Early stopping triggered at epoch 16
2024-12-29 13:15:29,197 - INFO - Training completed in 3.70s
2024-12-29 13:15:29,198 - INFO - Final memory usage: CPU 2783.0 MB, GPU 104.2 MB
2024-12-29 13:15:29,204 - INFO - Model training completed in 3.70s
2024-12-29 13:15:29,289 - INFO - Prediction completed in 0.08s
2024-12-29 13:15:29,298 - INFO - Poison rate 0.0 completed in 6.34s
2024-12-29 13:15:29,298 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:15:29,299 - INFO - Label flipping details:
2024-12-29 13:15:29,299 - INFO - - Source class: 1
2024-12-29 13:15:29,299 - INFO - - Target class: 0
2024-12-29 13:15:29,299 - INFO - - Available samples in source class: 955
2024-12-29 13:15:29,299 - INFO - - Requested samples to poison: 94
2024-12-29 13:15:29,299 - INFO - - Actual samples to flip: 94
2024-12-29 13:15:29,299 - INFO - - Samples remaining in source class: 861
2024-12-29 13:15:29,299 - INFO - Successfully flipped 94 labels from class 1 to 0
2024-12-29 13:15:29,299 - INFO - Total number of labels flipped: 94
2024-12-29 13:15:29,299 - INFO - Label flipping completed in 0.00s
2024-12-29 13:15:29,299 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:15:29,300 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:15:29,896 - INFO - Feature scaling completed in 0.60s
2024-12-29 13:15:29,896 - INFO - Starting feature selection (k=50)
2024-12-29 13:15:29,910 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:15:29,911 - INFO - Starting anomaly detection
2024-12-29 13:15:34,003 - INFO - Anomaly detection completed in 4.09s
2024-12-29 13:15:34,003 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:15:34,003 - INFO - Total fit_transform time: 4.70s
2024-12-29 13:15:34,003 - INFO - Training set processing completed in 4.70s
2024-12-29 13:15:34,003 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:15:34,005 - INFO - Memory usage at start_fit: CPU 2712.6 MB, GPU 104.1 MB
2024-12-29 13:15:34,005 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:15:34,008 - INFO - Number of unique classes: 10
2024-12-29 13:15:34,081 - INFO - Fitted scaler and transformed data
2024-12-29 13:15:34,081 - INFO - Scaling time: 0.07s
2024-12-29 13:15:34,306 - INFO - Epoch 1/1000, Train Loss: 0.5546, Val Loss: 0.1567
2024-12-29 13:15:34,511 - INFO - Epoch 2/1000, Train Loss: 0.1343, Val Loss: 0.1129
2024-12-29 13:15:34,761 - INFO - Epoch 3/1000, Train Loss: 0.1051, Val Loss: 0.0964
2024-12-29 13:15:35,020 - INFO - Epoch 4/1000, Train Loss: 0.0901, Val Loss: 0.0881
2024-12-29 13:15:35,249 - INFO - Epoch 5/1000, Train Loss: 0.0814, Val Loss: 0.0827
2024-12-29 13:15:35,466 - INFO - Epoch 6/1000, Train Loss: 0.0753, Val Loss: 0.0818
2024-12-29 13:15:35,691 - INFO - Epoch 7/1000, Train Loss: 0.0712, Val Loss: 0.0787
2024-12-29 13:15:35,903 - INFO - Epoch 8/1000, Train Loss: 0.0675, Val Loss: 0.0771
2024-12-29 13:15:36,165 - INFO - Epoch 9/1000, Train Loss: 0.0657, Val Loss: 0.0763
2024-12-29 13:15:36,448 - INFO - Epoch 10/1000, Train Loss: 0.0629, Val Loss: 0.0789
2024-12-29 13:15:36,734 - INFO - Epoch 11/1000, Train Loss: 0.0617, Val Loss: 0.0760
2024-12-29 13:15:36,939 - INFO - Epoch 12/1000, Train Loss: 0.0605, Val Loss: 0.0783
2024-12-29 13:15:37,175 - INFO - Epoch 13/1000, Train Loss: 0.0603, Val Loss: 0.0740
2024-12-29 13:15:37,363 - INFO - Epoch 14/1000, Train Loss: 0.0588, Val Loss: 0.0750
2024-12-29 13:15:37,581 - INFO - Epoch 15/1000, Train Loss: 0.0582, Val Loss: 0.0744
2024-12-29 13:15:37,817 - INFO - Epoch 16/1000, Train Loss: 0.0576, Val Loss: 0.0768
2024-12-29 13:15:38,023 - INFO - Epoch 17/1000, Train Loss: 0.0577, Val Loss: 0.0740
2024-12-29 13:15:38,272 - INFO - Epoch 18/1000, Train Loss: 0.0569, Val Loss: 0.0742
2024-12-29 13:15:38,273 - INFO - Early stopping triggered at epoch 18
2024-12-29 13:15:38,273 - INFO - Training completed in 4.27s
2024-12-29 13:15:38,274 - INFO - Final memory usage: CPU 2717.8 MB, GPU 104.2 MB
2024-12-29 13:15:38,276 - INFO - Model training completed in 4.27s
2024-12-29 13:15:38,344 - INFO - Prediction completed in 0.07s
2024-12-29 13:15:38,352 - INFO - Poison rate 0.01 completed in 9.05s
2024-12-29 13:15:38,353 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:15:38,353 - INFO - Label flipping details:
2024-12-29 13:15:38,353 - INFO - - Source class: 1
2024-12-29 13:15:38,353 - INFO - - Target class: 0
2024-12-29 13:15:38,353 - INFO - - Available samples in source class: 955
2024-12-29 13:15:38,353 - INFO - - Requested samples to poison: 284
2024-12-29 13:15:38,353 - INFO - - Actual samples to flip: 284
2024-12-29 13:15:38,354 - INFO - - Samples remaining in source class: 671
2024-12-29 13:15:38,354 - INFO - Successfully flipped 284 labels from class 1 to 0
2024-12-29 13:15:38,354 - INFO - Total number of labels flipped: 284
2024-12-29 13:15:38,354 - INFO - Label flipping completed in 0.00s
2024-12-29 13:15:38,354 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:15:38,354 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:15:38,945 - INFO - Feature scaling completed in 0.59s
2024-12-29 13:15:38,946 - INFO - Starting feature selection (k=50)
2024-12-29 13:15:38,963 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 13:15:38,964 - INFO - Starting anomaly detection
2024-12-29 13:15:43,128 - INFO - Anomaly detection completed in 4.16s
2024-12-29 13:15:43,129 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:15:43,129 - INFO - Total fit_transform time: 4.77s
2024-12-29 13:15:43,129 - INFO - Training set processing completed in 4.77s
2024-12-29 13:15:43,129 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:15:43,130 - INFO - Memory usage at start_fit: CPU 2712.1 MB, GPU 104.1 MB
2024-12-29 13:15:43,130 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:15:43,132 - INFO - Number of unique classes: 10
2024-12-29 13:15:43,200 - INFO - Fitted scaler and transformed data
2024-12-29 13:15:43,200 - INFO - Scaling time: 0.07s
2024-12-29 13:15:43,415 - INFO - Epoch 1/1000, Train Loss: 0.5514, Val Loss: 0.2075
2024-12-29 13:15:43,614 - INFO - Epoch 2/1000, Train Loss: 0.1623, Val Loss: 0.1631
2024-12-29 13:15:43,838 - INFO - Epoch 3/1000, Train Loss: 0.1328, Val Loss: 0.1482
2024-12-29 13:15:44,043 - INFO - Epoch 4/1000, Train Loss: 0.1170, Val Loss: 0.1379
2024-12-29 13:15:44,256 - INFO - Epoch 5/1000, Train Loss: 0.1084, Val Loss: 0.1329
2024-12-29 13:15:44,494 - INFO - Epoch 6/1000, Train Loss: 0.1015, Val Loss: 0.1299
2024-12-29 13:15:44,746 - INFO - Epoch 7/1000, Train Loss: 0.0976, Val Loss: 0.1279
2024-12-29 13:15:45,001 - INFO - Epoch 8/1000, Train Loss: 0.0938, Val Loss: 0.1275
2024-12-29 13:15:45,220 - INFO - Epoch 9/1000, Train Loss: 0.0912, Val Loss: 0.1266
2024-12-29 13:15:45,427 - INFO - Epoch 10/1000, Train Loss: 0.0890, Val Loss: 0.1271
2024-12-29 13:15:45,650 - INFO - Epoch 11/1000, Train Loss: 0.0876, Val Loss: 0.1266
2024-12-29 13:15:45,866 - INFO - Epoch 12/1000, Train Loss: 0.0865, Val Loss: 0.1264
2024-12-29 13:15:46,072 - INFO - Epoch 13/1000, Train Loss: 0.0857, Val Loss: 0.1258
2024-12-29 13:15:46,276 - INFO - Epoch 14/1000, Train Loss: 0.0843, Val Loss: 0.1263
2024-12-29 13:15:46,276 - INFO - Early stopping triggered at epoch 14
2024-12-29 13:15:46,276 - INFO - Training completed in 3.15s
2024-12-29 13:15:46,276 - INFO - Final memory usage: CPU 2730.8 MB, GPU 104.2 MB
2024-12-29 13:15:46,277 - INFO - Model training completed in 3.15s
2024-12-29 13:15:46,344 - INFO - Prediction completed in 0.07s
2024-12-29 13:15:46,352 - INFO - Poison rate 0.03 completed in 8.00s
2024-12-29 13:15:46,353 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:15:46,353 - INFO - Label flipping details:
2024-12-29 13:15:46,353 - INFO - - Source class: 1
2024-12-29 13:15:46,353 - INFO - - Target class: 0
2024-12-29 13:15:46,353 - INFO - - Available samples in source class: 955
2024-12-29 13:15:46,354 - INFO - - Requested samples to poison: 473
2024-12-29 13:15:46,354 - INFO - - Actual samples to flip: 473
2024-12-29 13:15:46,354 - INFO - - Samples remaining in source class: 482
2024-12-29 13:15:46,354 - INFO - Successfully flipped 473 labels from class 1 to 0
2024-12-29 13:15:46,354 - INFO - Total number of labels flipped: 473
2024-12-29 13:15:46,354 - INFO - Label flipping completed in 0.00s
2024-12-29 13:15:46,354 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:15:46,354 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:15:46,855 - INFO - Feature scaling completed in 0.50s
2024-12-29 13:15:46,856 - INFO - Starting feature selection (k=50)
2024-12-29 13:15:46,870 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:15:46,870 - INFO - Starting anomaly detection
2024-12-29 13:15:50,702 - INFO - Anomaly detection completed in 3.83s
2024-12-29 13:15:50,703 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:15:50,705 - INFO - Total fit_transform time: 4.35s
2024-12-29 13:15:50,705 - INFO - Training set processing completed in 4.35s
2024-12-29 13:15:50,705 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:15:50,706 - INFO - Memory usage at start_fit: CPU 2712.7 MB, GPU 104.1 MB
2024-12-29 13:15:50,707 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:15:50,709 - INFO - Number of unique classes: 10
2024-12-29 13:15:50,782 - INFO - Fitted scaler and transformed data
2024-12-29 13:15:50,782 - INFO - Scaling time: 0.07s
2024-12-29 13:15:51,021 - INFO - Epoch 1/1000, Train Loss: 0.5469, Val Loss: 0.2090
2024-12-29 13:15:51,255 - INFO - Epoch 2/1000, Train Loss: 0.1677, Val Loss: 0.1698
2024-12-29 13:15:51,549 - INFO - Epoch 3/1000, Train Loss: 0.1385, Val Loss: 0.1571
2024-12-29 13:15:51,799 - INFO - Epoch 4/1000, Train Loss: 0.1254, Val Loss: 0.1499
2024-12-29 13:15:51,998 - INFO - Epoch 5/1000, Train Loss: 0.1158, Val Loss: 0.1471
2024-12-29 13:15:52,192 - INFO - Epoch 6/1000, Train Loss: 0.1111, Val Loss: 0.1418
2024-12-29 13:15:52,392 - INFO - Epoch 7/1000, Train Loss: 0.1061, Val Loss: 0.1392
2024-12-29 13:15:52,587 - INFO - Epoch 8/1000, Train Loss: 0.1033, Val Loss: 0.1395
2024-12-29 13:15:52,801 - INFO - Epoch 9/1000, Train Loss: 0.1001, Val Loss: 0.1371
2024-12-29 13:15:53,063 - INFO - Epoch 10/1000, Train Loss: 0.0986, Val Loss: 0.1361
2024-12-29 13:15:53,338 - INFO - Epoch 11/1000, Train Loss: 0.0962, Val Loss: 0.1378
2024-12-29 13:15:53,573 - INFO - Epoch 12/1000, Train Loss: 0.0953, Val Loss: 0.1389
2024-12-29 13:15:53,974 - INFO - Epoch 13/1000, Train Loss: 0.0942, Val Loss: 0.1352
2024-12-29 13:15:54,392 - INFO - Epoch 14/1000, Train Loss: 0.0940, Val Loss: 0.1364
2024-12-29 13:15:54,675 - INFO - Epoch 15/1000, Train Loss: 0.0937, Val Loss: 0.1353
2024-12-29 13:15:54,887 - INFO - Epoch 16/1000, Train Loss: 0.0920, Val Loss: 0.1370
2024-12-29 13:15:55,154 - INFO - Epoch 17/1000, Train Loss: 0.0918, Val Loss: 0.1347
2024-12-29 13:15:55,369 - INFO - Epoch 18/1000, Train Loss: 0.0918, Val Loss: 0.1357
2024-12-29 13:15:55,369 - INFO - Early stopping triggered at epoch 18
2024-12-29 13:15:55,369 - INFO - Training completed in 4.66s
2024-12-29 13:15:55,370 - INFO - Final memory usage: CPU 2721.8 MB, GPU 104.2 MB
2024-12-29 13:15:55,373 - INFO - Model training completed in 4.67s
2024-12-29 13:15:55,435 - INFO - Prediction completed in 0.06s
2024-12-29 13:15:55,443 - INFO - Poison rate 0.05 completed in 9.09s
2024-12-29 13:15:55,444 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:15:55,444 - INFO - Label flipping details:
2024-12-29 13:15:55,444 - INFO - - Source class: 1
2024-12-29 13:15:55,444 - INFO - - Target class: 0
2024-12-29 13:15:55,444 - INFO - - Available samples in source class: 955
2024-12-29 13:15:55,444 - INFO - - Requested samples to poison: 662
2024-12-29 13:15:55,444 - INFO - - Actual samples to flip: 662
2024-12-29 13:15:55,444 - INFO - - Samples remaining in source class: 293
2024-12-29 13:15:55,444 - INFO - Successfully flipped 662 labels from class 1 to 0
2024-12-29 13:15:55,445 - INFO - Total number of labels flipped: 662
2024-12-29 13:15:55,445 - INFO - Label flipping completed in 0.00s
2024-12-29 13:15:55,445 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:15:55,445 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:15:55,982 - INFO - Feature scaling completed in 0.54s
2024-12-29 13:15:55,983 - INFO - Starting feature selection (k=50)
2024-12-29 13:15:55,997 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:15:55,998 - INFO - Starting anomaly detection
2024-12-29 13:15:59,228 - INFO - Anomaly detection completed in 3.23s
2024-12-29 13:15:59,229 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:15:59,229 - INFO - Total fit_transform time: 3.78s
2024-12-29 13:15:59,229 - INFO - Training set processing completed in 3.78s
2024-12-29 13:15:59,229 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:15:59,230 - INFO - Memory usage at start_fit: CPU 2712.4 MB, GPU 104.1 MB
2024-12-29 13:15:59,230 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:15:59,233 - INFO - Number of unique classes: 10
2024-12-29 13:15:59,301 - INFO - Fitted scaler and transformed data
2024-12-29 13:15:59,301 - INFO - Scaling time: 0.07s
2024-12-29 13:15:59,498 - INFO - Epoch 1/1000, Train Loss: 0.5235, Val Loss: 0.1824
2024-12-29 13:15:59,695 - INFO - Epoch 2/1000, Train Loss: 0.1633, Val Loss: 0.1422
2024-12-29 13:15:59,888 - INFO - Epoch 3/1000, Train Loss: 0.1324, Val Loss: 0.1295
2024-12-29 13:16:00,101 - INFO - Epoch 4/1000, Train Loss: 0.1188, Val Loss: 0.1210
2024-12-29 13:16:00,279 - INFO - Epoch 5/1000, Train Loss: 0.1086, Val Loss: 0.1182
2024-12-29 13:16:00,483 - INFO - Epoch 6/1000, Train Loss: 0.1030, Val Loss: 0.1134
2024-12-29 13:16:00,675 - INFO - Epoch 7/1000, Train Loss: 0.0984, Val Loss: 0.1131
2024-12-29 13:16:00,867 - INFO - Epoch 8/1000, Train Loss: 0.0946, Val Loss: 0.1122
2024-12-29 13:16:01,065 - INFO - Epoch 9/1000, Train Loss: 0.0924, Val Loss: 0.1123
2024-12-29 13:16:01,269 - INFO - Epoch 10/1000, Train Loss: 0.0907, Val Loss: 0.1151
2024-12-29 13:16:01,490 - INFO - Epoch 11/1000, Train Loss: 0.0892, Val Loss: 0.1124
2024-12-29 13:16:01,685 - INFO - Epoch 12/1000, Train Loss: 0.0883, Val Loss: 0.1121
2024-12-29 13:16:01,883 - INFO - Epoch 13/1000, Train Loss: 0.0866, Val Loss: 0.1158
2024-12-29 13:16:01,883 - INFO - Early stopping triggered at epoch 13
2024-12-29 13:16:01,883 - INFO - Training completed in 2.65s
2024-12-29 13:16:01,883 - INFO - Final memory usage: CPU 2731.2 MB, GPU 104.2 MB
2024-12-29 13:16:01,884 - INFO - Model training completed in 2.66s
2024-12-29 13:16:01,956 - INFO - Prediction completed in 0.07s
2024-12-29 13:16:01,965 - INFO - Poison rate 0.07 completed in 6.52s
2024-12-29 13:16:01,966 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:16:01,966 - INFO - Label flipping details:
2024-12-29 13:16:01,966 - INFO - - Source class: 1
2024-12-29 13:16:01,966 - INFO - - Target class: 0
2024-12-29 13:16:01,966 - INFO - - Available samples in source class: 955
2024-12-29 13:16:01,966 - INFO - - Requested samples to poison: 946
2024-12-29 13:16:01,966 - INFO - - Actual samples to flip: 946
2024-12-29 13:16:01,966 - INFO - - Samples remaining in source class: 9
2024-12-29 13:16:01,967 - INFO - Successfully flipped 946 labels from class 1 to 0
2024-12-29 13:16:01,967 - INFO - Total number of labels flipped: 946
2024-12-29 13:16:01,967 - INFO - Label flipping completed in 0.00s
2024-12-29 13:16:01,967 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:16:01,967 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:16:02,510 - INFO - Feature scaling completed in 0.54s
2024-12-29 13:16:02,510 - INFO - Starting feature selection (k=50)
2024-12-29 13:16:02,525 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:16:02,525 - INFO - Starting anomaly detection
2024-12-29 13:16:06,227 - INFO - Anomaly detection completed in 3.70s
2024-12-29 13:16:06,227 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:16:06,227 - INFO - Total fit_transform time: 4.26s
2024-12-29 13:16:06,227 - INFO - Training set processing completed in 4.26s
2024-12-29 13:16:06,227 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:16:06,229 - INFO - Memory usage at start_fit: CPU 2712.4 MB, GPU 104.1 MB
2024-12-29 13:16:06,229 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:16:06,232 - INFO - Number of unique classes: 10
2024-12-29 13:16:06,302 - INFO - Fitted scaler and transformed data
2024-12-29 13:16:06,302 - INFO - Scaling time: 0.07s
2024-12-29 13:16:06,514 - INFO - Epoch 1/1000, Train Loss: 0.5114, Val Loss: 0.1268
2024-12-29 13:16:06,709 - INFO - Epoch 2/1000, Train Loss: 0.1029, Val Loss: 0.0857
2024-12-29 13:16:06,902 - INFO - Epoch 3/1000, Train Loss: 0.0751, Val Loss: 0.0718
2024-12-29 13:16:07,090 - INFO - Epoch 4/1000, Train Loss: 0.0618, Val Loss: 0.0642
2024-12-29 13:16:07,329 - INFO - Epoch 5/1000, Train Loss: 0.0542, Val Loss: 0.0591
2024-12-29 13:16:07,583 - INFO - Epoch 6/1000, Train Loss: 0.0486, Val Loss: 0.0564
2024-12-29 13:16:07,775 - INFO - Epoch 7/1000, Train Loss: 0.0448, Val Loss: 0.0546
2024-12-29 13:16:07,981 - INFO - Epoch 8/1000, Train Loss: 0.0418, Val Loss: 0.0536
2024-12-29 13:16:08,178 - INFO - Epoch 9/1000, Train Loss: 0.0399, Val Loss: 0.0528
2024-12-29 13:16:08,398 - INFO - Epoch 10/1000, Train Loss: 0.0387, Val Loss: 0.0520
2024-12-29 13:16:08,763 - INFO - Epoch 11/1000, Train Loss: 0.0369, Val Loss: 0.0516
2024-12-29 13:16:08,975 - INFO - Epoch 12/1000, Train Loss: 0.0361, Val Loss: 0.0509
2024-12-29 13:16:09,388 - INFO - Epoch 13/1000, Train Loss: 0.0355, Val Loss: 0.0506
2024-12-29 13:16:09,816 - INFO - Epoch 14/1000, Train Loss: 0.0346, Val Loss: 0.0499
2024-12-29 13:16:10,230 - INFO - Epoch 15/1000, Train Loss: 0.0345, Val Loss: 0.0497
2024-12-29 13:16:10,601 - INFO - Epoch 16/1000, Train Loss: 0.0340, Val Loss: 0.0504
2024-12-29 13:16:10,921 - INFO - Epoch 17/1000, Train Loss: 0.0337, Val Loss: 0.0494
2024-12-29 13:16:11,242 - INFO - Epoch 18/1000, Train Loss: 0.0335, Val Loss: 0.0499
2024-12-29 13:16:11,669 - INFO - Epoch 19/1000, Train Loss: 0.0331, Val Loss: 0.0497
2024-12-29 13:16:12,080 - INFO - Epoch 20/1000, Train Loss: 0.0333, Val Loss: 0.0488
2024-12-29 13:16:12,080 - INFO - Early stopping triggered at epoch 20
2024-12-29 13:16:12,080 - INFO - Training completed in 5.85s
2024-12-29 13:16:12,081 - INFO - Final memory usage: CPU 2722.0 MB, GPU 104.2 MB
2024-12-29 13:16:12,083 - INFO - Model training completed in 5.86s
2024-12-29 13:16:12,130 - INFO - Prediction completed in 0.05s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 13:16:12,140 - INFO - Poison rate 0.1 completed in 10.17s
2024-12-29 13:16:12,140 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:16:12,141 - INFO - Label flipping details:
2024-12-29 13:16:12,141 - INFO - - Source class: 1
2024-12-29 13:16:12,141 - INFO - - Target class: 0
2024-12-29 13:16:12,141 - INFO - - Available samples in source class: 955
2024-12-29 13:16:12,141 - INFO - - Requested samples to poison: 1893
2024-12-29 13:16:12,141 - INFO - - Actual samples to flip: 954
2024-12-29 13:16:12,141 - INFO - - Samples remaining in source class: 1
2024-12-29 13:16:12,142 - INFO - Successfully flipped 954 labels from class 1 to 0
2024-12-29 13:16:12,142 - INFO - Total number of labels flipped: 954
2024-12-29 13:16:12,142 - INFO - Label flipping completed in 0.00s
2024-12-29 13:16:12,142 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:16:12,142 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:16:12,664 - INFO - Feature scaling completed in 0.52s
2024-12-29 13:16:12,665 - INFO - Starting feature selection (k=50)
2024-12-29 13:16:12,679 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:16:12,679 - INFO - Starting anomaly detection
2024-12-29 13:16:16,012 - INFO - Anomaly detection completed in 3.33s
2024-12-29 13:16:16,012 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:16:16,012 - INFO - Total fit_transform time: 3.87s
2024-12-29 13:16:16,012 - INFO - Training set processing completed in 3.87s
2024-12-29 13:16:16,013 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:16:16,013 - INFO - Memory usage at start_fit: CPU 2712.6 MB, GPU 104.1 MB
2024-12-29 13:16:16,014 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:16:16,016 - INFO - Number of unique classes: 10
2024-12-29 13:16:16,083 - INFO - Fitted scaler and transformed data
2024-12-29 13:16:16,084 - INFO - Scaling time: 0.07s
2024-12-29 13:16:16,424 - INFO - Epoch 1/1000, Train Loss: 0.5119, Val Loss: 0.1233
2024-12-29 13:16:16,841 - INFO - Epoch 2/1000, Train Loss: 0.0980, Val Loss: 0.0853
2024-12-29 13:16:17,241 - INFO - Epoch 3/1000, Train Loss: 0.0704, Val Loss: 0.0705
2024-12-29 13:16:17,567 - INFO - Epoch 4/1000, Train Loss: 0.0573, Val Loss: 0.0628
2024-12-29 13:16:17,896 - INFO - Epoch 5/1000, Train Loss: 0.0495, Val Loss: 0.0586
2024-12-29 13:16:18,317 - INFO - Epoch 6/1000, Train Loss: 0.0444, Val Loss: 0.0554
2024-12-29 13:16:18,593 - INFO - Epoch 7/1000, Train Loss: 0.0408, Val Loss: 0.0534
2024-12-29 13:16:18,836 - INFO - Epoch 8/1000, Train Loss: 0.0383, Val Loss: 0.0519
2024-12-29 13:16:19,093 - INFO - Epoch 9/1000, Train Loss: 0.0364, Val Loss: 0.0513
2024-12-29 13:16:19,381 - INFO - Epoch 10/1000, Train Loss: 0.0350, Val Loss: 0.0505
2024-12-29 13:16:19,620 - INFO - Epoch 11/1000, Train Loss: 0.0335, Val Loss: 0.0501
2024-12-29 13:16:19,828 - INFO - Epoch 12/1000, Train Loss: 0.0328, Val Loss: 0.0499
2024-12-29 13:16:20,053 - INFO - Epoch 13/1000, Train Loss: 0.0320, Val Loss: 0.0494
2024-12-29 13:16:20,297 - INFO - Epoch 14/1000, Train Loss: 0.0318, Val Loss: 0.0494
2024-12-29 13:16:20,497 - INFO - Epoch 15/1000, Train Loss: 0.0311, Val Loss: 0.0488
2024-12-29 13:16:20,721 - INFO - Epoch 16/1000, Train Loss: 0.0307, Val Loss: 0.0488
2024-12-29 13:16:20,924 - INFO - Epoch 17/1000, Train Loss: 0.0304, Val Loss: 0.0485
2024-12-29 13:16:21,133 - INFO - Epoch 18/1000, Train Loss: 0.0303, Val Loss: 0.0485
2024-12-29 13:16:21,133 - INFO - Early stopping triggered at epoch 18
2024-12-29 13:16:21,133 - INFO - Training completed in 5.12s
2024-12-29 13:16:21,133 - INFO - Final memory usage: CPU 2731.2 MB, GPU 104.2 MB
2024-12-29 13:16:21,135 - INFO - Model training completed in 5.12s
2024-12-29 13:16:21,200 - INFO - Prediction completed in 0.06s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 13:16:21,209 - INFO - Poison rate 0.2 completed in 9.07s
2024-12-29 13:16:21,212 - INFO - Loaded 133 existing results
2024-12-29 13:16:21,212 - INFO - Total results to save: 140
2024-12-29 13:16:21,213 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:16:21,218 - INFO - Saved 140 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:16:21,218 - INFO - Total evaluation time: 88.76s
2024-12-29 13:16:21,220 - INFO - 
Progress: 21.9% - Evaluating GTSRB with RandomForest (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:16:21,400 - INFO - Loading datasets...
2024-12-29 13:16:21,420 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:16:21,420 - INFO - Extracting validation features...
2024-12-29 13:16:21,420 - INFO - Extracting features from 3925 samples...
2024-12-29 13:16:30,586 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:16:30,588 - INFO - Validation feature extraction completed in 9.17s
2024-12-29 13:16:30,589 - INFO - Extracting training features...
2024-12-29 13:16:30,589 - INFO - Extracting features from 9469 samples...
2024-12-29 13:16:52,083 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:16:52,091 - INFO - Training feature extraction completed in 21.50s
2024-12-29 13:16:52,091 - INFO - Creating model for classifier: RandomForest
2024-12-29 13:16:52,091 - INFO - Using device: cuda
2024-12-29 13:16:52,092 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:16:52,092 - INFO - Training set processing completed in 0.00s
2024-12-29 13:16:52,092 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:16:52,093 - INFO - Memory usage at start_fit: CPU 2765.6 MB, GPU 104.6 MB
2024-12-29 13:16:52,094 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:16:52,316 - INFO - Fitted scaler and transformed data
2024-12-29 13:16:52,316 - INFO - Scaling time: 0.22s
2024-12-29 13:16:52,323 - INFO - Number of unique classes: 10
2024-12-29 13:16:55,691 - INFO - Epoch 1/10, Train Loss: 2.3019, Val Loss: 2.3013
2024-12-29 13:16:58,195 - INFO - Epoch 2/10, Train Loss: 2.3005, Val Loss: 2.3000
2024-12-29 13:17:01,326 - INFO - Epoch 3/10, Train Loss: 2.2991, Val Loss: 2.2986
2024-12-29 13:17:04,562 - INFO - Epoch 4/10, Train Loss: 2.2976, Val Loss: 2.2973
2024-12-29 13:17:04,562 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:17:04,562 - INFO - Training completed in 12.47s
2024-12-29 13:17:04,562 - INFO - Final memory usage: CPU 2708.5 MB, GPU 126.5 MB
2024-12-29 13:17:04,563 - INFO - Model training completed in 12.47s
2024-12-29 13:17:04,814 - INFO - Prediction completed in 0.25s
2024-12-29 13:17:04,823 - INFO - Poison rate 0.0 completed in 12.73s
2024-12-29 13:17:04,823 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:17:04,823 - INFO - Label flipping details:
2024-12-29 13:17:04,824 - INFO - - Source class: 1
2024-12-29 13:17:04,824 - INFO - - Target class: 0
2024-12-29 13:17:04,824 - INFO - - Available samples in source class: 955
2024-12-29 13:17:04,824 - INFO - - Requested samples to poison: 94
2024-12-29 13:17:04,824 - INFO - - Actual samples to flip: 94
2024-12-29 13:17:04,824 - INFO - - Samples remaining in source class: 861
2024-12-29 13:17:04,824 - INFO - Successfully flipped 94 labels from class 1 to 0
2024-12-29 13:17:04,824 - INFO - Total number of labels flipped: 94
2024-12-29 13:17:04,824 - INFO - Label flipping completed in 0.00s
2024-12-29 13:17:04,824 - INFO - Training set processing completed in 0.00s
2024-12-29 13:17:04,824 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:17:04,825 - INFO - Memory usage at start_fit: CPU 2708.5 MB, GPU 106.7 MB
2024-12-29 13:17:04,825 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:17:04,999 - INFO - Fitted scaler and transformed data
2024-12-29 13:17:05,000 - INFO - Scaling time: 0.17s
2024-12-29 13:17:05,010 - INFO - Number of unique classes: 10
2024-12-29 13:17:08,170 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3014
2024-12-29 13:17:11,406 - INFO - Epoch 2/10, Train Loss: 2.3006, Val Loss: 2.3001
2024-12-29 13:17:14,355 - INFO - Epoch 3/10, Train Loss: 2.2992, Val Loss: 2.2988
2024-12-29 13:17:17,027 - INFO - Epoch 4/10, Train Loss: 2.2978, Val Loss: 2.2976
2024-12-29 13:17:17,028 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:17:17,028 - INFO - Training completed in 12.20s
2024-12-29 13:17:17,028 - INFO - Final memory usage: CPU 2708.5 MB, GPU 126.5 MB
2024-12-29 13:17:17,028 - INFO - Model training completed in 12.20s
2024-12-29 13:17:17,325 - INFO - Prediction completed in 0.30s
2024-12-29 13:17:17,333 - INFO - Poison rate 0.01 completed in 12.51s
2024-12-29 13:17:17,334 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:17:17,334 - INFO - Label flipping details:
2024-12-29 13:17:17,334 - INFO - - Source class: 1
2024-12-29 13:17:17,334 - INFO - - Target class: 0
2024-12-29 13:17:17,334 - INFO - - Available samples in source class: 955
2024-12-29 13:17:17,334 - INFO - - Requested samples to poison: 284
2024-12-29 13:17:17,334 - INFO - - Actual samples to flip: 284
2024-12-29 13:17:17,335 - INFO - - Samples remaining in source class: 671
2024-12-29 13:17:17,335 - INFO - Successfully flipped 284 labels from class 1 to 0
2024-12-29 13:17:17,335 - INFO - Total number of labels flipped: 284
2024-12-29 13:17:17,335 - INFO - Label flipping completed in 0.00s
2024-12-29 13:17:17,335 - INFO - Training set processing completed in 0.00s
2024-12-29 13:17:17,335 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:17:17,336 - INFO - Memory usage at start_fit: CPU 2708.5 MB, GPU 106.7 MB
2024-12-29 13:17:17,336 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:17:17,564 - INFO - Fitted scaler and transformed data
2024-12-29 13:17:17,564 - INFO - Scaling time: 0.23s
2024-12-29 13:17:17,575 - INFO - Number of unique classes: 10
2024-12-29 13:17:20,343 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3014
2024-12-29 13:17:23,046 - INFO - Epoch 2/10, Train Loss: 2.3006, Val Loss: 2.3001
2024-12-29 13:17:25,712 - INFO - Epoch 3/10, Train Loss: 2.2992, Val Loss: 2.2989
2024-12-29 13:17:28,820 - INFO - Epoch 4/10, Train Loss: 2.2978, Val Loss: 2.2977
2024-12-29 13:17:28,820 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:17:28,820 - INFO - Training completed in 11.48s
2024-12-29 13:17:28,820 - INFO - Final memory usage: CPU 2708.5 MB, GPU 126.5 MB
2024-12-29 13:17:28,821 - INFO - Model training completed in 11.49s
2024-12-29 13:17:29,108 - INFO - Prediction completed in 0.29s
2024-12-29 13:17:29,117 - INFO - Poison rate 0.03 completed in 11.78s
2024-12-29 13:17:29,118 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:17:29,118 - INFO - Label flipping details:
2024-12-29 13:17:29,118 - INFO - - Source class: 1
2024-12-29 13:17:29,119 - INFO - - Target class: 0
2024-12-29 13:17:29,119 - INFO - - Available samples in source class: 955
2024-12-29 13:17:29,119 - INFO - - Requested samples to poison: 473
2024-12-29 13:17:29,119 - INFO - - Actual samples to flip: 473
2024-12-29 13:17:29,119 - INFO - - Samples remaining in source class: 482
2024-12-29 13:17:29,119 - INFO - Successfully flipped 473 labels from class 1 to 0
2024-12-29 13:17:29,119 - INFO - Total number of labels flipped: 473
2024-12-29 13:17:29,119 - INFO - Label flipping completed in 0.00s
2024-12-29 13:17:29,119 - INFO - Training set processing completed in 0.00s
2024-12-29 13:17:29,119 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:17:29,120 - INFO - Memory usage at start_fit: CPU 2708.5 MB, GPU 106.7 MB
2024-12-29 13:17:29,120 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:17:29,315 - INFO - Fitted scaler and transformed data
2024-12-29 13:17:29,316 - INFO - Scaling time: 0.20s
2024-12-29 13:17:29,326 - INFO - Number of unique classes: 10
2024-12-29 13:17:32,237 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3013
2024-12-29 13:17:35,212 - INFO - Epoch 2/10, Train Loss: 2.3006, Val Loss: 2.3000
2024-12-29 13:17:38,190 - INFO - Epoch 3/10, Train Loss: 2.2992, Val Loss: 2.2987
2024-12-29 13:17:41,126 - INFO - Epoch 4/10, Train Loss: 2.2978, Val Loss: 2.2974
2024-12-29 13:17:41,126 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:17:41,126 - INFO - Training completed in 12.01s
2024-12-29 13:17:41,126 - INFO - Final memory usage: CPU 2708.5 MB, GPU 126.5 MB
2024-12-29 13:17:41,127 - INFO - Model training completed in 12.01s
2024-12-29 13:17:41,341 - INFO - Prediction completed in 0.21s
2024-12-29 13:17:41,351 - INFO - Poison rate 0.05 completed in 12.23s
2024-12-29 13:17:41,351 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:17:41,352 - INFO - Label flipping details:
2024-12-29 13:17:41,352 - INFO - - Source class: 1
2024-12-29 13:17:41,352 - INFO - - Target class: 0
2024-12-29 13:17:41,352 - INFO - - Available samples in source class: 955
2024-12-29 13:17:41,352 - INFO - - Requested samples to poison: 662
2024-12-29 13:17:41,352 - INFO - - Actual samples to flip: 662
2024-12-29 13:17:41,352 - INFO - - Samples remaining in source class: 293
2024-12-29 13:17:41,352 - INFO - Successfully flipped 662 labels from class 1 to 0
2024-12-29 13:17:41,352 - INFO - Total number of labels flipped: 662
2024-12-29 13:17:41,352 - INFO - Label flipping completed in 0.00s
2024-12-29 13:17:41,353 - INFO - Training set processing completed in 0.00s
2024-12-29 13:17:41,353 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:17:41,353 - INFO - Memory usage at start_fit: CPU 2708.5 MB, GPU 106.7 MB
2024-12-29 13:17:41,354 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:17:41,529 - INFO - Fitted scaler and transformed data
2024-12-29 13:17:41,530 - INFO - Scaling time: 0.18s
2024-12-29 13:17:41,540 - INFO - Number of unique classes: 10
2024-12-29 13:17:44,678 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3013
2024-12-29 13:17:47,527 - INFO - Epoch 2/10, Train Loss: 2.3006, Val Loss: 2.3000
2024-12-29 13:17:50,304 - INFO - Epoch 3/10, Train Loss: 2.2992, Val Loss: 2.2987
2024-12-29 13:17:53,557 - INFO - Epoch 4/10, Train Loss: 2.2978, Val Loss: 2.2974
2024-12-29 13:17:53,557 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:17:53,558 - INFO - Training completed in 12.20s
2024-12-29 13:17:53,558 - INFO - Final memory usage: CPU 2708.5 MB, GPU 126.5 MB
2024-12-29 13:17:53,558 - INFO - Model training completed in 12.21s
2024-12-29 13:17:53,832 - INFO - Prediction completed in 0.27s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 13:17:53,841 - INFO - Poison rate 0.07 completed in 12.49s
2024-12-29 13:17:53,841 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:17:53,842 - INFO - Label flipping details:
2024-12-29 13:17:53,842 - INFO - - Source class: 1
2024-12-29 13:17:53,842 - INFO - - Target class: 0
2024-12-29 13:17:53,842 - INFO - - Available samples in source class: 955
2024-12-29 13:17:53,842 - INFO - - Requested samples to poison: 946
2024-12-29 13:17:53,842 - INFO - - Actual samples to flip: 946
2024-12-29 13:17:53,842 - INFO - - Samples remaining in source class: 9
2024-12-29 13:17:53,842 - INFO - Successfully flipped 946 labels from class 1 to 0
2024-12-29 13:17:53,842 - INFO - Total number of labels flipped: 946
2024-12-29 13:17:53,843 - INFO - Label flipping completed in 0.00s
2024-12-29 13:17:53,843 - INFO - Training set processing completed in 0.00s
2024-12-29 13:17:53,843 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:17:53,844 - INFO - Memory usage at start_fit: CPU 2708.5 MB, GPU 106.7 MB
2024-12-29 13:17:53,844 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:17:54,076 - INFO - Fitted scaler and transformed data
2024-12-29 13:17:54,077 - INFO - Scaling time: 0.23s
2024-12-29 13:17:54,087 - INFO - Number of unique classes: 10
2024-12-29 13:17:57,352 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3013
2024-12-29 13:18:00,246 - INFO - Epoch 2/10, Train Loss: 2.3005, Val Loss: 2.2999
2024-12-29 13:18:03,027 - INFO - Epoch 3/10, Train Loss: 2.2991, Val Loss: 2.2986
2024-12-29 13:18:05,930 - INFO - Epoch 4/10, Train Loss: 2.2976, Val Loss: 2.2972
2024-12-29 13:18:05,930 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:18:05,930 - INFO - Training completed in 12.09s
2024-12-29 13:18:05,931 - INFO - Final memory usage: CPU 2708.5 MB, GPU 126.5 MB
2024-12-29 13:18:05,931 - INFO - Model training completed in 12.09s
2024-12-29 13:18:06,086 - INFO - Prediction completed in 0.15s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 13:18:06,096 - INFO - Poison rate 0.1 completed in 12.25s
2024-12-29 13:18:06,096 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:18:06,097 - INFO - Label flipping details:
2024-12-29 13:18:06,097 - INFO - - Source class: 1
2024-12-29 13:18:06,097 - INFO - - Target class: 0
2024-12-29 13:18:06,097 - INFO - - Available samples in source class: 955
2024-12-29 13:18:06,097 - INFO - - Requested samples to poison: 1893
2024-12-29 13:18:06,097 - INFO - - Actual samples to flip: 954
2024-12-29 13:18:06,097 - INFO - - Samples remaining in source class: 1
2024-12-29 13:18:06,097 - INFO - Successfully flipped 954 labels from class 1 to 0
2024-12-29 13:18:06,097 - INFO - Total number of labels flipped: 954
2024-12-29 13:18:06,097 - INFO - Label flipping completed in 0.00s
2024-12-29 13:18:06,097 - INFO - Training set processing completed in 0.00s
2024-12-29 13:18:06,097 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:18:06,098 - INFO - Memory usage at start_fit: CPU 2708.5 MB, GPU 106.7 MB
2024-12-29 13:18:06,098 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:18:06,271 - INFO - Fitted scaler and transformed data
2024-12-29 13:18:06,271 - INFO - Scaling time: 0.17s
2024-12-29 13:18:06,281 - INFO - Number of unique classes: 10
2024-12-29 13:18:09,723 - INFO - Epoch 1/10, Train Loss: 2.3019, Val Loss: 2.3012
2024-12-29 13:18:13,185 - INFO - Epoch 2/10, Train Loss: 2.3005, Val Loss: 2.2999
2024-12-29 13:18:16,192 - INFO - Epoch 3/10, Train Loss: 2.2990, Val Loss: 2.2985
2024-12-29 13:18:19,307 - INFO - Epoch 4/10, Train Loss: 2.2975, Val Loss: 2.2971
2024-12-29 13:18:19,307 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:18:19,307 - INFO - Training completed in 13.21s
2024-12-29 13:18:19,307 - INFO - Final memory usage: CPU 2708.5 MB, GPU 126.5 MB
2024-12-29 13:18:19,308 - INFO - Model training completed in 13.21s
2024-12-29 13:18:19,572 - INFO - Prediction completed in 0.26s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 13:18:19,584 - INFO - Poison rate 0.2 completed in 13.49s
2024-12-29 13:18:19,588 - INFO - Loaded 140 existing results
2024-12-29 13:18:19,588 - INFO - Total results to save: 147
2024-12-29 13:18:19,588 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:18:19,594 - INFO - Saved 147 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:18:19,594 - INFO - Total evaluation time: 118.19s
2024-12-29 13:18:19,596 - INFO - 
Progress: 22.9% - Evaluating GTSRB with RandomForest (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:18:19,778 - INFO - Loading datasets...
2024-12-29 13:18:19,799 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:18:19,799 - INFO - Extracting validation features...
2024-12-29 13:18:19,799 - INFO - Extracting features from 3925 samples...
2024-12-29 13:18:29,046 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:18:29,051 - INFO - Validation feature extraction completed in 9.25s
2024-12-29 13:18:29,051 - INFO - Extracting training features...
2024-12-29 13:18:29,051 - INFO - Extracting features from 9469 samples...
2024-12-29 13:18:51,160 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:18:51,169 - INFO - Training feature extraction completed in 22.12s
2024-12-29 13:18:51,169 - INFO - Creating model for classifier: RandomForest
2024-12-29 13:18:51,169 - INFO - Using device: cuda
2024-12-29 13:18:51,169 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:18:51,169 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:18:51,170 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:18:51,753 - INFO - Feature scaling completed in 0.58s
2024-12-29 13:18:51,754 - INFO - Starting feature selection (k=50)
2024-12-29 13:18:51,766 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:18:51,766 - INFO - Starting anomaly detection
2024-12-29 13:18:54,216 - INFO - Anomaly detection completed in 2.45s
2024-12-29 13:18:54,216 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:18:54,216 - INFO - Total fit_transform time: 3.05s
2024-12-29 13:18:54,217 - INFO - Training set processing completed in 3.05s
2024-12-29 13:18:54,217 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:18:54,218 - INFO - Memory usage at start_fit: CPU 2708.6 MB, GPU 104.0 MB
2024-12-29 13:18:54,218 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:18:54,416 - INFO - Fitted scaler and transformed data
2024-12-29 13:18:54,416 - INFO - Scaling time: 0.20s
2024-12-29 13:18:54,424 - INFO - Number of unique classes: 10
2024-12-29 13:18:57,884 - INFO - Epoch 1/10, Train Loss: 2.1855, Val Loss: 2.3013
2024-12-29 13:19:01,288 - INFO - Epoch 2/10, Train Loss: 2.1841, Val Loss: 2.3000
2024-12-29 13:19:04,357 - INFO - Epoch 3/10, Train Loss: 2.1828, Val Loss: 2.2988
2024-12-29 13:19:07,248 - INFO - Epoch 4/10, Train Loss: 2.1814, Val Loss: 2.2975
2024-12-29 13:19:07,249 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:19:07,249 - INFO - Training completed in 13.03s
2024-12-29 13:19:07,249 - INFO - Final memory usage: CPU 2708.6 MB, GPU 125.9 MB
2024-12-29 13:19:07,250 - INFO - Model training completed in 13.03s
2024-12-29 13:19:07,519 - INFO - Prediction completed in 0.27s
2024-12-29 13:19:07,528 - INFO - Poison rate 0.0 completed in 16.36s
2024-12-29 13:19:07,528 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:19:07,529 - INFO - Label flipping details:
2024-12-29 13:19:07,529 - INFO - - Source class: 1
2024-12-29 13:19:07,529 - INFO - - Target class: 0
2024-12-29 13:19:07,529 - INFO - - Available samples in source class: 955
2024-12-29 13:19:07,529 - INFO - - Requested samples to poison: 94
2024-12-29 13:19:07,529 - INFO - - Actual samples to flip: 94
2024-12-29 13:19:07,529 - INFO - - Samples remaining in source class: 861
2024-12-29 13:19:07,529 - INFO - Successfully flipped 94 labels from class 1 to 0
2024-12-29 13:19:07,529 - INFO - Total number of labels flipped: 94
2024-12-29 13:19:07,529 - INFO - Label flipping completed in 0.00s
2024-12-29 13:19:07,529 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:19:07,529 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:19:08,059 - INFO - Feature scaling completed in 0.53s
2024-12-29 13:19:08,059 - INFO - Starting feature selection (k=50)
2024-12-29 13:19:08,073 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:19:08,073 - INFO - Starting anomaly detection
2024-12-29 13:19:11,317 - INFO - Anomaly detection completed in 3.24s
2024-12-29 13:19:11,317 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:19:11,317 - INFO - Total fit_transform time: 3.79s
2024-12-29 13:19:11,317 - INFO - Training set processing completed in 3.79s
2024-12-29 13:19:11,317 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:19:11,319 - INFO - Memory usage at start_fit: CPU 2708.6 MB, GPU 106.0 MB
2024-12-29 13:19:11,319 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:19:11,501 - INFO - Fitted scaler and transformed data
2024-12-29 13:19:11,501 - INFO - Scaling time: 0.18s
2024-12-29 13:19:11,507 - INFO - Number of unique classes: 10
2024-12-29 13:19:14,696 - INFO - Epoch 1/10, Train Loss: 2.1857, Val Loss: 2.3014
2024-12-29 13:19:17,740 - INFO - Epoch 2/10, Train Loss: 2.1844, Val Loss: 2.3001
2024-12-29 13:19:21,219 - INFO - Epoch 3/10, Train Loss: 2.1831, Val Loss: 2.2989
2024-12-29 13:19:24,774 - INFO - Epoch 4/10, Train Loss: 2.1818, Val Loss: 2.2976
2024-12-29 13:19:24,775 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:19:24,775 - INFO - Training completed in 13.46s
2024-12-29 13:19:24,775 - INFO - Final memory usage: CPU 2708.6 MB, GPU 125.9 MB
2024-12-29 13:19:24,775 - INFO - Model training completed in 13.46s
2024-12-29 13:19:25,073 - INFO - Prediction completed in 0.30s
2024-12-29 13:19:25,082 - INFO - Poison rate 0.01 completed in 17.55s
2024-12-29 13:19:25,082 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:19:25,083 - INFO - Label flipping details:
2024-12-29 13:19:25,083 - INFO - - Source class: 1
2024-12-29 13:19:25,083 - INFO - - Target class: 0
2024-12-29 13:19:25,083 - INFO - - Available samples in source class: 955
2024-12-29 13:19:25,083 - INFO - - Requested samples to poison: 284
2024-12-29 13:19:25,083 - INFO - - Actual samples to flip: 284
2024-12-29 13:19:25,083 - INFO - - Samples remaining in source class: 671
2024-12-29 13:19:25,083 - INFO - Successfully flipped 284 labels from class 1 to 0
2024-12-29 13:19:25,083 - INFO - Total number of labels flipped: 284
2024-12-29 13:19:25,084 - INFO - Label flipping completed in 0.00s
2024-12-29 13:19:25,084 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:19:25,084 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:19:25,672 - INFO - Feature scaling completed in 0.59s
2024-12-29 13:19:25,673 - INFO - Starting feature selection (k=50)
2024-12-29 13:19:25,689 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 13:19:25,690 - INFO - Starting anomaly detection
2024-12-29 13:19:29,906 - INFO - Anomaly detection completed in 4.22s
2024-12-29 13:19:29,906 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:19:29,906 - INFO - Total fit_transform time: 4.82s
2024-12-29 13:19:29,906 - INFO - Training set processing completed in 4.82s
2024-12-29 13:19:29,906 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:19:29,907 - INFO - Memory usage at start_fit: CPU 2708.6 MB, GPU 106.0 MB
2024-12-29 13:19:29,907 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:19:30,081 - INFO - Fitted scaler and transformed data
2024-12-29 13:19:30,082 - INFO - Scaling time: 0.17s
2024-12-29 13:19:30,089 - INFO - Number of unique classes: 10
2024-12-29 13:19:34,213 - INFO - Epoch 1/10, Train Loss: 2.1863, Val Loss: 2.3014
2024-12-29 13:19:37,792 - INFO - Epoch 2/10, Train Loss: 2.1850, Val Loss: 2.3001
2024-12-29 13:19:41,464 - INFO - Epoch 3/10, Train Loss: 2.1837, Val Loss: 2.2988
2024-12-29 13:19:44,924 - INFO - Epoch 4/10, Train Loss: 2.1823, Val Loss: 2.2975
2024-12-29 13:19:44,925 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:19:44,925 - INFO - Training completed in 15.02s
2024-12-29 13:19:44,926 - INFO - Final memory usage: CPU 2708.6 MB, GPU 125.9 MB
2024-12-29 13:19:44,927 - INFO - Model training completed in 15.02s
2024-12-29 13:19:45,097 - INFO - Prediction completed in 0.17s
2024-12-29 13:19:45,106 - INFO - Poison rate 0.03 completed in 20.02s
2024-12-29 13:19:45,107 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:19:45,107 - INFO - Label flipping details:
2024-12-29 13:19:45,107 - INFO - - Source class: 1
2024-12-29 13:19:45,107 - INFO - - Target class: 0
2024-12-29 13:19:45,107 - INFO - - Available samples in source class: 955
2024-12-29 13:19:45,107 - INFO - - Requested samples to poison: 473
2024-12-29 13:19:45,107 - INFO - - Actual samples to flip: 473
2024-12-29 13:19:45,108 - INFO - - Samples remaining in source class: 482
2024-12-29 13:19:45,108 - INFO - Successfully flipped 473 labels from class 1 to 0
2024-12-29 13:19:45,108 - INFO - Total number of labels flipped: 473
2024-12-29 13:19:45,108 - INFO - Label flipping completed in 0.00s
2024-12-29 13:19:45,108 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:19:45,108 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:19:45,622 - INFO - Feature scaling completed in 0.51s
2024-12-29 13:19:45,622 - INFO - Starting feature selection (k=50)
2024-12-29 13:19:45,635 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:19:45,635 - INFO - Starting anomaly detection
2024-12-29 13:19:50,003 - INFO - Anomaly detection completed in 4.37s
2024-12-29 13:19:50,004 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:19:50,004 - INFO - Total fit_transform time: 4.90s
2024-12-29 13:19:50,004 - INFO - Training set processing completed in 4.90s
2024-12-29 13:19:50,004 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:19:50,005 - INFO - Memory usage at start_fit: CPU 2708.6 MB, GPU 106.0 MB
2024-12-29 13:19:50,005 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:19:50,201 - INFO - Fitted scaler and transformed data
2024-12-29 13:19:50,201 - INFO - Scaling time: 0.20s
2024-12-29 13:19:50,208 - INFO - Number of unique classes: 10
2024-12-29 13:19:53,295 - INFO - Epoch 1/10, Train Loss: 2.1886, Val Loss: 2.3013
2024-12-29 13:19:56,756 - INFO - Epoch 2/10, Train Loss: 2.1873, Val Loss: 2.3001
2024-12-29 13:19:59,779 - INFO - Epoch 3/10, Train Loss: 2.1860, Val Loss: 2.2988
2024-12-29 13:20:03,312 - INFO - Epoch 4/10, Train Loss: 2.1846, Val Loss: 2.2975
2024-12-29 13:20:03,313 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:20:03,313 - INFO - Training completed in 13.31s
2024-12-29 13:20:03,313 - INFO - Final memory usage: CPU 2708.6 MB, GPU 125.9 MB
2024-12-29 13:20:03,314 - INFO - Model training completed in 13.31s
2024-12-29 13:20:03,490 - INFO - Prediction completed in 0.18s
2024-12-29 13:20:03,499 - INFO - Poison rate 0.05 completed in 18.39s
2024-12-29 13:20:03,499 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:20:03,500 - INFO - Label flipping details:
2024-12-29 13:20:03,500 - INFO - - Source class: 1
2024-12-29 13:20:03,500 - INFO - - Target class: 0
2024-12-29 13:20:03,500 - INFO - - Available samples in source class: 955
2024-12-29 13:20:03,500 - INFO - - Requested samples to poison: 662
2024-12-29 13:20:03,500 - INFO - - Actual samples to flip: 662
2024-12-29 13:20:03,500 - INFO - - Samples remaining in source class: 293
2024-12-29 13:20:03,500 - INFO - Successfully flipped 662 labels from class 1 to 0
2024-12-29 13:20:03,501 - INFO - Total number of labels flipped: 662
2024-12-29 13:20:03,501 - INFO - Label flipping completed in 0.00s
2024-12-29 13:20:03,501 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:20:03,501 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:20:04,028 - INFO - Feature scaling completed in 0.53s
2024-12-29 13:20:04,028 - INFO - Starting feature selection (k=50)
2024-12-29 13:20:04,042 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:20:04,042 - INFO - Starting anomaly detection
2024-12-29 13:20:08,330 - INFO - Anomaly detection completed in 4.29s
2024-12-29 13:20:08,330 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:20:08,330 - INFO - Total fit_transform time: 4.83s
2024-12-29 13:20:08,331 - INFO - Training set processing completed in 4.83s
2024-12-29 13:20:08,331 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:20:08,332 - INFO - Memory usage at start_fit: CPU 2708.6 MB, GPU 106.0 MB
2024-12-29 13:20:08,332 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:20:08,532 - INFO - Fitted scaler and transformed data
2024-12-29 13:20:08,532 - INFO - Scaling time: 0.20s
2024-12-29 13:20:08,539 - INFO - Number of unique classes: 10
2024-12-29 13:20:12,026 - INFO - Epoch 1/10, Train Loss: 2.1857, Val Loss: 2.3013
2024-12-29 13:20:15,386 - INFO - Epoch 2/10, Train Loss: 2.1843, Val Loss: 2.3000
2024-12-29 13:20:18,711 - INFO - Epoch 3/10, Train Loss: 2.1830, Val Loss: 2.2987
2024-12-29 13:20:21,796 - INFO - Epoch 4/10, Train Loss: 2.1817, Val Loss: 2.2973
2024-12-29 13:20:21,796 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:20:21,796 - INFO - Training completed in 13.47s
2024-12-29 13:20:21,797 - INFO - Final memory usage: CPU 2708.6 MB, GPU 125.9 MB
2024-12-29 13:20:21,797 - INFO - Model training completed in 13.47s
2024-12-29 13:20:21,971 - INFO - Prediction completed in 0.17s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 13:20:21,981 - INFO - Poison rate 0.07 completed in 18.48s
2024-12-29 13:20:21,981 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:20:21,982 - INFO - Label flipping details:
2024-12-29 13:20:21,982 - INFO - - Source class: 1
2024-12-29 13:20:21,982 - INFO - - Target class: 0
2024-12-29 13:20:21,982 - INFO - - Available samples in source class: 955
2024-12-29 13:20:21,982 - INFO - - Requested samples to poison: 946
2024-12-29 13:20:21,982 - INFO - - Actual samples to flip: 946
2024-12-29 13:20:21,982 - INFO - - Samples remaining in source class: 9
2024-12-29 13:20:21,982 - INFO - Successfully flipped 946 labels from class 1 to 0
2024-12-29 13:20:21,983 - INFO - Total number of labels flipped: 946
2024-12-29 13:20:21,983 - INFO - Label flipping completed in 0.00s
2024-12-29 13:20:21,983 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:20:21,983 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:20:22,521 - INFO - Feature scaling completed in 0.54s
2024-12-29 13:20:22,522 - INFO - Starting feature selection (k=50)
2024-12-29 13:20:22,534 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:20:22,534 - INFO - Starting anomaly detection
2024-12-29 13:20:26,066 - INFO - Anomaly detection completed in 3.53s
2024-12-29 13:20:26,066 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:20:26,066 - INFO - Total fit_transform time: 4.08s
2024-12-29 13:20:26,066 - INFO - Training set processing completed in 4.08s
2024-12-29 13:20:26,066 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:20:26,067 - INFO - Memory usage at start_fit: CPU 2708.6 MB, GPU 106.0 MB
2024-12-29 13:20:26,068 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:20:26,286 - INFO - Fitted scaler and transformed data
2024-12-29 13:20:26,286 - INFO - Scaling time: 0.22s
2024-12-29 13:20:26,293 - INFO - Number of unique classes: 10
2024-12-29 13:20:29,428 - INFO - Epoch 1/10, Train Loss: 2.1864, Val Loss: 2.3013
2024-12-29 13:20:32,362 - INFO - Epoch 2/10, Train Loss: 2.1850, Val Loss: 2.3000
2024-12-29 13:20:35,285 - INFO - Epoch 3/10, Train Loss: 2.1836, Val Loss: 2.2986
2024-12-29 13:20:38,610 - INFO - Epoch 4/10, Train Loss: 2.1822, Val Loss: 2.2972
2024-12-29 13:20:38,610 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:20:38,611 - INFO - Training completed in 12.54s
2024-12-29 13:20:38,611 - INFO - Final memory usage: CPU 2708.6 MB, GPU 125.9 MB
2024-12-29 13:20:38,611 - INFO - Model training completed in 12.54s
2024-12-29 13:20:38,821 - INFO - Prediction completed in 0.21s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 13:20:38,831 - INFO - Poison rate 0.1 completed in 16.85s
2024-12-29 13:20:38,831 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:20:38,832 - INFO - Label flipping details:
2024-12-29 13:20:38,832 - INFO - - Source class: 1
2024-12-29 13:20:38,832 - INFO - - Target class: 0
2024-12-29 13:20:38,832 - INFO - - Available samples in source class: 955
2024-12-29 13:20:38,832 - INFO - - Requested samples to poison: 1893
2024-12-29 13:20:38,832 - INFO - - Actual samples to flip: 954
2024-12-29 13:20:38,832 - INFO - - Samples remaining in source class: 1
2024-12-29 13:20:38,833 - INFO - Successfully flipped 954 labels from class 1 to 0
2024-12-29 13:20:38,833 - INFO - Total number of labels flipped: 954
2024-12-29 13:20:38,833 - INFO - Label flipping completed in 0.00s
2024-12-29 13:20:38,833 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:20:38,833 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:20:39,358 - INFO - Feature scaling completed in 0.52s
2024-12-29 13:20:39,358 - INFO - Starting feature selection (k=50)
2024-12-29 13:20:39,372 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:20:39,372 - INFO - Starting anomaly detection
2024-12-29 13:20:43,584 - INFO - Anomaly detection completed in 4.21s
2024-12-29 13:20:43,584 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:20:43,584 - INFO - Total fit_transform time: 4.75s
2024-12-29 13:20:43,584 - INFO - Training set processing completed in 4.75s
2024-12-29 13:20:43,584 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:20:43,585 - INFO - Memory usage at start_fit: CPU 2708.6 MB, GPU 106.0 MB
2024-12-29 13:20:43,585 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:20:43,780 - INFO - Fitted scaler and transformed data
2024-12-29 13:20:43,780 - INFO - Scaling time: 0.20s
2024-12-29 13:20:43,787 - INFO - Number of unique classes: 10
2024-12-29 13:20:47,031 - INFO - Epoch 1/10, Train Loss: 2.1878, Val Loss: 2.3013
2024-12-29 13:20:50,387 - INFO - Epoch 2/10, Train Loss: 2.1864, Val Loss: 2.2999
2024-12-29 13:20:54,250 - INFO - Epoch 3/10, Train Loss: 2.1850, Val Loss: 2.2986
2024-12-29 13:20:57,665 - INFO - Epoch 4/10, Train Loss: 2.1836, Val Loss: 2.2972
2024-12-29 13:20:57,665 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:20:57,666 - INFO - Training completed in 14.08s
2024-12-29 13:20:57,666 - INFO - Final memory usage: CPU 2708.6 MB, GPU 125.9 MB
2024-12-29 13:20:57,666 - INFO - Model training completed in 14.08s
2024-12-29 13:20:57,894 - INFO - Prediction completed in 0.23s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 13:20:57,904 - INFO - Poison rate 0.2 completed in 19.07s
2024-12-29 13:20:57,907 - INFO - Loaded 147 existing results
2024-12-29 13:20:57,907 - INFO - Total results to save: 154
2024-12-29 13:20:57,908 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:20:57,914 - INFO - Saved 154 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:20:57,914 - INFO - Total evaluation time: 158.14s
2024-12-29 13:20:57,916 - INFO - 
Progress: 24.0% - Evaluating GTSRB with KNeighbors (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:20:58,118 - INFO - Loading datasets...
2024-12-29 13:20:58,140 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:20:58,140 - INFO - Extracting validation features...
2024-12-29 13:20:58,140 - INFO - Extracting features from 3925 samples...
2024-12-29 13:21:07,600 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:21:07,606 - INFO - Validation feature extraction completed in 9.47s
2024-12-29 13:21:07,606 - INFO - Extracting training features...
2024-12-29 13:21:07,606 - INFO - Extracting features from 9469 samples...
2024-12-29 13:21:29,538 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:21:29,546 - INFO - Training feature extraction completed in 21.94s
2024-12-29 13:21:29,547 - INFO - Creating model for classifier: KNeighbors
2024-12-29 13:21:29,547 - INFO - Using device: cuda
2024-12-29 13:21:29,547 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:21:29,547 - INFO - Training set processing completed in 0.00s
2024-12-29 13:21:29,547 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:21:29,549 - INFO - Memory usage at start_fit: CPU 2681.1 MB, GPU 104.6 MB
2024-12-29 13:21:29,549 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:21:29,737 - INFO - Fitted scaler and transformed data
2024-12-29 13:21:29,737 - INFO - Scaling time: 0.19s
2024-12-29 13:21:29,744 - INFO - Training completed in 0.20s
2024-12-29 13:21:29,745 - INFO - Final memory usage: CPU 2708.4 MB, GPU 123.2 MB
2024-12-29 13:21:29,745 - INFO - Model training completed in 0.20s
2024-12-29 13:21:29,824 - INFO - Prediction completed in 0.08s
2024-12-29 13:21:29,834 - INFO - Poison rate 0.0 completed in 0.29s
2024-12-29 13:21:29,834 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:21:29,835 - INFO - Label flipping details:
2024-12-29 13:21:29,835 - INFO - - Source class: 1
2024-12-29 13:21:29,835 - INFO - - Target class: 0
2024-12-29 13:21:29,835 - INFO - - Available samples in source class: 955
2024-12-29 13:21:29,835 - INFO - - Requested samples to poison: 94
2024-12-29 13:21:29,835 - INFO - - Actual samples to flip: 94
2024-12-29 13:21:29,835 - INFO - - Samples remaining in source class: 861
2024-12-29 13:21:29,835 - INFO - Successfully flipped 94 labels from class 1 to 0
2024-12-29 13:21:29,835 - INFO - Total number of labels flipped: 94
2024-12-29 13:21:29,835 - INFO - Label flipping completed in 0.00s
2024-12-29 13:21:29,835 - INFO - Training set processing completed in 0.00s
2024-12-29 13:21:29,835 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:21:29,836 - INFO - Memory usage at start_fit: CPU 2708.5 MB, GPU 123.2 MB
2024-12-29 13:21:29,836 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:21:30,014 - INFO - Fitted scaler and transformed data
2024-12-29 13:21:30,015 - INFO - Scaling time: 0.18s
2024-12-29 13:21:30,023 - INFO - Training completed in 0.19s
2024-12-29 13:21:30,024 - INFO - Final memory usage: CPU 2711.0 MB, GPU 123.2 MB
2024-12-29 13:21:30,024 - INFO - Model training completed in 0.19s
2024-12-29 13:21:30,099 - INFO - Prediction completed in 0.07s
2024-12-29 13:21:30,107 - INFO - Poison rate 0.01 completed in 0.27s
2024-12-29 13:21:30,107 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:21:30,108 - INFO - Label flipping details:
2024-12-29 13:21:30,108 - INFO - - Source class: 1
2024-12-29 13:21:30,108 - INFO - - Target class: 0
2024-12-29 13:21:30,108 - INFO - - Available samples in source class: 955
2024-12-29 13:21:30,108 - INFO - - Requested samples to poison: 284
2024-12-29 13:21:30,108 - INFO - - Actual samples to flip: 284
2024-12-29 13:21:30,108 - INFO - - Samples remaining in source class: 671
2024-12-29 13:21:30,108 - INFO - Successfully flipped 284 labels from class 1 to 0
2024-12-29 13:21:30,109 - INFO - Total number of labels flipped: 284
2024-12-29 13:21:30,109 - INFO - Label flipping completed in 0.00s
2024-12-29 13:21:30,109 - INFO - Training set processing completed in 0.00s
2024-12-29 13:21:30,109 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:21:30,110 - INFO - Memory usage at start_fit: CPU 2711.0 MB, GPU 123.2 MB
2024-12-29 13:21:30,110 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:21:30,280 - INFO - Fitted scaler and transformed data
2024-12-29 13:21:30,280 - INFO - Scaling time: 0.17s
2024-12-29 13:21:30,294 - INFO - Training completed in 0.18s
2024-12-29 13:21:30,294 - INFO - Final memory usage: CPU 2718.4 MB, GPU 123.2 MB
2024-12-29 13:21:30,294 - INFO - Model training completed in 0.19s
2024-12-29 13:21:30,367 - INFO - Prediction completed in 0.07s
2024-12-29 13:21:30,376 - INFO - Poison rate 0.03 completed in 0.27s
2024-12-29 13:21:30,376 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:21:30,376 - INFO - Label flipping details:
2024-12-29 13:21:30,377 - INFO - - Source class: 1
2024-12-29 13:21:30,377 - INFO - - Target class: 0
2024-12-29 13:21:30,377 - INFO - - Available samples in source class: 955
2024-12-29 13:21:30,377 - INFO - - Requested samples to poison: 473
2024-12-29 13:21:30,377 - INFO - - Actual samples to flip: 473
2024-12-29 13:21:30,377 - INFO - - Samples remaining in source class: 482
2024-12-29 13:21:30,377 - INFO - Successfully flipped 473 labels from class 1 to 0
2024-12-29 13:21:30,377 - INFO - Total number of labels flipped: 473
2024-12-29 13:21:30,377 - INFO - Label flipping completed in 0.00s
2024-12-29 13:21:30,377 - INFO - Training set processing completed in 0.00s
2024-12-29 13:21:30,377 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:21:30,378 - INFO - Memory usage at start_fit: CPU 2680.9 MB, GPU 123.2 MB
2024-12-29 13:21:30,378 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:21:30,574 - INFO - Fitted scaler and transformed data
2024-12-29 13:21:30,574 - INFO - Scaling time: 0.20s
2024-12-29 13:21:30,582 - INFO - Training completed in 0.20s
2024-12-29 13:21:30,583 - INFO - Final memory usage: CPU 2708.4 MB, GPU 123.2 MB
2024-12-29 13:21:30,583 - INFO - Model training completed in 0.21s
2024-12-29 13:21:30,655 - INFO - Prediction completed in 0.07s
2024-12-29 13:21:30,664 - INFO - Poison rate 0.05 completed in 0.29s
2024-12-29 13:21:30,664 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:21:30,665 - INFO - Label flipping details:
2024-12-29 13:21:30,665 - INFO - - Source class: 1
2024-12-29 13:21:30,665 - INFO - - Target class: 0
2024-12-29 13:21:30,665 - INFO - - Available samples in source class: 955
2024-12-29 13:21:30,665 - INFO - - Requested samples to poison: 662
2024-12-29 13:21:30,665 - INFO - - Actual samples to flip: 662
2024-12-29 13:21:30,665 - INFO - - Samples remaining in source class: 293
2024-12-29 13:21:30,665 - INFO - Successfully flipped 662 labels from class 1 to 0
2024-12-29 13:21:30,665 - INFO - Total number of labels flipped: 662
2024-12-29 13:21:30,665 - INFO - Label flipping completed in 0.00s
2024-12-29 13:21:30,665 - INFO - Training set processing completed in 0.00s
2024-12-29 13:21:30,665 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:21:30,666 - INFO - Memory usage at start_fit: CPU 2708.4 MB, GPU 123.2 MB
2024-12-29 13:21:30,666 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:21:30,839 - INFO - Fitted scaler and transformed data
2024-12-29 13:21:30,839 - INFO - Scaling time: 0.17s
2024-12-29 13:21:30,845 - INFO - Training completed in 0.18s
2024-12-29 13:21:30,846 - INFO - Final memory usage: CPU 2708.5 MB, GPU 123.2 MB
2024-12-29 13:21:30,846 - INFO - Model training completed in 0.18s
2024-12-29 13:21:30,927 - INFO - Prediction completed in 0.08s
2024-12-29 13:21:30,937 - INFO - Poison rate 0.07 completed in 0.27s
2024-12-29 13:21:30,937 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:21:30,938 - INFO - Label flipping details:
2024-12-29 13:21:30,938 - INFO - - Source class: 1
2024-12-29 13:21:30,938 - INFO - - Target class: 0
2024-12-29 13:21:30,938 - INFO - - Available samples in source class: 955
2024-12-29 13:21:30,938 - INFO - - Requested samples to poison: 946
2024-12-29 13:21:30,938 - INFO - - Actual samples to flip: 946
2024-12-29 13:21:30,938 - INFO - - Samples remaining in source class: 9
2024-12-29 13:21:30,938 - INFO - Successfully flipped 946 labels from class 1 to 0
2024-12-29 13:21:30,938 - INFO - Total number of labels flipped: 946
2024-12-29 13:21:30,939 - INFO - Label flipping completed in 0.00s
2024-12-29 13:21:30,939 - INFO - Training set processing completed in 0.00s
2024-12-29 13:21:30,939 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:21:30,940 - INFO - Memory usage at start_fit: CPU 2708.5 MB, GPU 123.2 MB
2024-12-29 13:21:30,940 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:21:31,142 - INFO - Fitted scaler and transformed data
2024-12-29 13:21:31,143 - INFO - Scaling time: 0.20s
2024-12-29 13:21:31,149 - INFO - Training completed in 0.21s
2024-12-29 13:21:31,150 - INFO - Final memory usage: CPU 2708.5 MB, GPU 123.2 MB
2024-12-29 13:21:31,150 - INFO - Model training completed in 0.21s
2024-12-29 13:21:31,222 - INFO - Prediction completed in 0.07s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 13:21:31,232 - INFO - Poison rate 0.1 completed in 0.29s
2024-12-29 13:21:31,232 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:21:31,233 - INFO - Label flipping details:
2024-12-29 13:21:31,233 - INFO - - Source class: 1
2024-12-29 13:21:31,233 - INFO - - Target class: 0
2024-12-29 13:21:31,233 - INFO - - Available samples in source class: 955
2024-12-29 13:21:31,233 - INFO - - Requested samples to poison: 1893
2024-12-29 13:21:31,233 - INFO - - Actual samples to flip: 954
2024-12-29 13:21:31,233 - INFO - - Samples remaining in source class: 1
2024-12-29 13:21:31,233 - INFO - Successfully flipped 954 labels from class 1 to 0
2024-12-29 13:21:31,233 - INFO - Total number of labels flipped: 954
2024-12-29 13:21:31,233 - INFO - Label flipping completed in 0.00s
2024-12-29 13:21:31,233 - INFO - Training set processing completed in 0.00s
2024-12-29 13:21:31,234 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:21:31,234 - INFO - Memory usage at start_fit: CPU 2708.5 MB, GPU 123.2 MB
2024-12-29 13:21:31,235 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:21:31,404 - INFO - Fitted scaler and transformed data
2024-12-29 13:21:31,405 - INFO - Scaling time: 0.17s
2024-12-29 13:21:31,410 - INFO - Training completed in 0.18s
2024-12-29 13:21:31,411 - INFO - Final memory usage: CPU 2708.5 MB, GPU 123.2 MB
2024-12-29 13:21:31,411 - INFO - Model training completed in 0.18s
2024-12-29 13:21:31,484 - INFO - Prediction completed in 0.07s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 13:21:31,494 - INFO - Poison rate 0.2 completed in 0.26s
2024-12-29 13:21:31,497 - INFO - Loaded 154 existing results
2024-12-29 13:21:31,498 - INFO - Total results to save: 161
2024-12-29 13:21:31,499 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:21:31,505 - INFO - Saved 161 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:21:31,505 - INFO - Total evaluation time: 33.39s
2024-12-29 13:21:31,507 - INFO - 
Progress: 25.0% - Evaluating GTSRB with KNeighbors (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:21:31,676 - INFO - Loading datasets...
2024-12-29 13:21:31,707 - INFO - Dataset loading completed in 0.03s
2024-12-29 13:21:31,707 - INFO - Extracting validation features...
2024-12-29 13:21:31,707 - INFO - Extracting features from 3925 samples...
2024-12-29 13:21:41,392 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:21:41,399 - INFO - Validation feature extraction completed in 9.69s
2024-12-29 13:21:41,400 - INFO - Extracting training features...
2024-12-29 13:21:41,400 - INFO - Extracting features from 9469 samples...
2024-12-29 13:22:03,273 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:22:03,281 - INFO - Training feature extraction completed in 21.88s
2024-12-29 13:22:03,282 - INFO - Creating model for classifier: KNeighbors
2024-12-29 13:22:03,282 - INFO - Using device: cuda
2024-12-29 13:22:03,282 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:22:03,282 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:22:03,282 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:22:03,850 - INFO - Feature scaling completed in 0.57s
2024-12-29 13:22:03,850 - INFO - Starting feature selection (k=50)
2024-12-29 13:22:03,859 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:22:03,859 - INFO - Starting anomaly detection
2024-12-29 13:22:07,453 - INFO - Anomaly detection completed in 3.59s
2024-12-29 13:22:07,453 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:22:07,453 - INFO - Total fit_transform time: 4.17s
2024-12-29 13:22:07,453 - INFO - Training set processing completed in 4.17s
2024-12-29 13:22:07,454 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:22:07,455 - INFO - Memory usage at start_fit: CPU 2708.6 MB, GPU 104.0 MB
2024-12-29 13:22:07,455 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:22:07,656 - INFO - Fitted scaler and transformed data
2024-12-29 13:22:07,656 - INFO - Scaling time: 0.20s
2024-12-29 13:22:07,663 - INFO - Training completed in 0.21s
2024-12-29 13:22:07,663 - INFO - Final memory usage: CPU 2708.6 MB, GPU 122.6 MB
2024-12-29 13:22:07,663 - INFO - Model training completed in 0.21s
2024-12-29 13:22:07,785 - INFO - Prediction completed in 0.12s
2024-12-29 13:22:07,794 - INFO - Poison rate 0.0 completed in 4.51s
2024-12-29 13:22:07,794 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:22:07,795 - INFO - Label flipping details:
2024-12-29 13:22:07,795 - INFO - - Source class: 1
2024-12-29 13:22:07,795 - INFO - - Target class: 0
2024-12-29 13:22:07,795 - INFO - - Available samples in source class: 955
2024-12-29 13:22:07,795 - INFO - - Requested samples to poison: 94
2024-12-29 13:22:07,795 - INFO - - Actual samples to flip: 94
2024-12-29 13:22:07,795 - INFO - - Samples remaining in source class: 861
2024-12-29 13:22:07,796 - INFO - Successfully flipped 94 labels from class 1 to 0
2024-12-29 13:22:07,796 - INFO - Total number of labels flipped: 94
2024-12-29 13:22:07,796 - INFO - Label flipping completed in 0.00s
2024-12-29 13:22:07,796 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:22:07,796 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:22:08,378 - INFO - Feature scaling completed in 0.58s
2024-12-29 13:22:08,378 - INFO - Starting feature selection (k=50)
2024-12-29 13:22:08,391 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:22:08,391 - INFO - Starting anomaly detection
2024-12-29 13:22:12,715 - INFO - Anomaly detection completed in 4.32s
2024-12-29 13:22:12,715 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:22:12,715 - INFO - Total fit_transform time: 4.92s
2024-12-29 13:22:12,715 - INFO - Training set processing completed in 4.92s
2024-12-29 13:22:12,715 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:22:12,716 - INFO - Memory usage at start_fit: CPU 2708.6 MB, GPU 122.6 MB
2024-12-29 13:22:12,717 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:22:12,898 - INFO - Fitted scaler and transformed data
2024-12-29 13:22:12,898 - INFO - Scaling time: 0.18s
2024-12-29 13:22:12,905 - INFO - Training completed in 0.19s
2024-12-29 13:22:12,906 - INFO - Final memory usage: CPU 2708.6 MB, GPU 122.6 MB
2024-12-29 13:22:12,906 - INFO - Model training completed in 0.19s
2024-12-29 13:22:13,021 - INFO - Prediction completed in 0.11s
2024-12-29 13:22:13,030 - INFO - Poison rate 0.01 completed in 5.24s
2024-12-29 13:22:13,030 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:22:13,031 - INFO - Label flipping details:
2024-12-29 13:22:13,031 - INFO - - Source class: 1
2024-12-29 13:22:13,031 - INFO - - Target class: 0
2024-12-29 13:22:13,031 - INFO - - Available samples in source class: 955
2024-12-29 13:22:13,031 - INFO - - Requested samples to poison: 284
2024-12-29 13:22:13,031 - INFO - - Actual samples to flip: 284
2024-12-29 13:22:13,031 - INFO - - Samples remaining in source class: 671
2024-12-29 13:22:13,031 - INFO - Successfully flipped 284 labels from class 1 to 0
2024-12-29 13:22:13,031 - INFO - Total number of labels flipped: 284
2024-12-29 13:22:13,031 - INFO - Label flipping completed in 0.00s
2024-12-29 13:22:13,031 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:22:13,031 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:22:13,544 - INFO - Feature scaling completed in 0.51s
2024-12-29 13:22:13,544 - INFO - Starting feature selection (k=50)
2024-12-29 13:22:13,552 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:22:13,553 - INFO - Starting anomaly detection
2024-12-29 13:22:17,628 - INFO - Anomaly detection completed in 4.08s
2024-12-29 13:22:17,629 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:22:17,629 - INFO - Total fit_transform time: 4.60s
2024-12-29 13:22:17,629 - INFO - Training set processing completed in 4.60s
2024-12-29 13:22:17,629 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:22:17,630 - INFO - Memory usage at start_fit: CPU 2708.6 MB, GPU 122.6 MB
2024-12-29 13:22:17,631 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:22:17,833 - INFO - Fitted scaler and transformed data
2024-12-29 13:22:17,833 - INFO - Scaling time: 0.20s
2024-12-29 13:22:17,846 - INFO - Training completed in 0.22s
2024-12-29 13:22:17,847 - INFO - Final memory usage: CPU 2710.4 MB, GPU 122.6 MB
2024-12-29 13:22:17,848 - INFO - Model training completed in 0.22s
2024-12-29 13:22:17,970 - INFO - Prediction completed in 0.12s
2024-12-29 13:22:17,979 - INFO - Poison rate 0.03 completed in 4.95s
2024-12-29 13:22:17,979 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:22:17,980 - INFO - Label flipping details:
2024-12-29 13:22:17,980 - INFO - - Source class: 1
2024-12-29 13:22:17,980 - INFO - - Target class: 0
2024-12-29 13:22:17,980 - INFO - - Available samples in source class: 955
2024-12-29 13:22:17,980 - INFO - - Requested samples to poison: 473
2024-12-29 13:22:17,980 - INFO - - Actual samples to flip: 473
2024-12-29 13:22:17,980 - INFO - - Samples remaining in source class: 482
2024-12-29 13:22:17,980 - INFO - Successfully flipped 473 labels from class 1 to 0
2024-12-29 13:22:17,981 - INFO - Total number of labels flipped: 473
2024-12-29 13:22:17,981 - INFO - Label flipping completed in 0.00s
2024-12-29 13:22:17,981 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:22:17,981 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:22:18,572 - INFO - Feature scaling completed in 0.59s
2024-12-29 13:22:18,572 - INFO - Starting feature selection (k=50)
2024-12-29 13:22:18,581 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:22:18,581 - INFO - Starting anomaly detection
2024-12-29 13:22:20,944 - INFO - Anomaly detection completed in 2.36s
2024-12-29 13:22:20,944 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:22:20,944 - INFO - Total fit_transform time: 2.96s
2024-12-29 13:22:20,944 - INFO - Training set processing completed in 2.96s
2024-12-29 13:22:20,944 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:22:20,945 - INFO - Memory usage at start_fit: CPU 2710.4 MB, GPU 122.6 MB
2024-12-29 13:22:20,945 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:22:21,121 - INFO - Fitted scaler and transformed data
2024-12-29 13:22:21,121 - INFO - Scaling time: 0.18s
2024-12-29 13:22:21,128 - INFO - Training completed in 0.18s
2024-12-29 13:22:21,129 - INFO - Final memory usage: CPU 2710.4 MB, GPU 122.6 MB
2024-12-29 13:22:21,129 - INFO - Model training completed in 0.18s
2024-12-29 13:22:21,229 - INFO - Prediction completed in 0.10s
2024-12-29 13:22:21,238 - INFO - Poison rate 0.05 completed in 3.26s
2024-12-29 13:22:21,238 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:22:21,238 - INFO - Label flipping details:
2024-12-29 13:22:21,239 - INFO - - Source class: 1
2024-12-29 13:22:21,239 - INFO - - Target class: 0
2024-12-29 13:22:21,239 - INFO - - Available samples in source class: 955
2024-12-29 13:22:21,239 - INFO - - Requested samples to poison: 662
2024-12-29 13:22:21,239 - INFO - - Actual samples to flip: 662
2024-12-29 13:22:21,239 - INFO - - Samples remaining in source class: 293
2024-12-29 13:22:21,239 - INFO - Successfully flipped 662 labels from class 1 to 0
2024-12-29 13:22:21,239 - INFO - Total number of labels flipped: 662
2024-12-29 13:22:21,239 - INFO - Label flipping completed in 0.00s
2024-12-29 13:22:21,239 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:22:21,239 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:22:21,813 - INFO - Feature scaling completed in 0.57s
2024-12-29 13:22:21,813 - INFO - Starting feature selection (k=50)
2024-12-29 13:22:21,824 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:22:21,825 - INFO - Starting anomaly detection
2024-12-29 13:22:25,796 - INFO - Anomaly detection completed in 3.97s
2024-12-29 13:22:25,796 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:22:25,797 - INFO - Total fit_transform time: 4.56s
2024-12-29 13:22:25,797 - INFO - Training set processing completed in 4.56s
2024-12-29 13:22:25,797 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:22:25,798 - INFO - Memory usage at start_fit: CPU 2717.7 MB, GPU 122.6 MB
2024-12-29 13:22:25,798 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:22:25,982 - INFO - Fitted scaler and transformed data
2024-12-29 13:22:25,982 - INFO - Scaling time: 0.18s
2024-12-29 13:22:25,989 - INFO - Training completed in 0.19s
2024-12-29 13:22:25,989 - INFO - Final memory usage: CPU 2717.7 MB, GPU 122.6 MB
2024-12-29 13:22:25,990 - INFO - Model training completed in 0.19s
2024-12-29 13:22:26,092 - INFO - Prediction completed in 0.10s
2024-12-29 13:22:26,101 - INFO - Poison rate 0.07 completed in 4.86s
2024-12-29 13:22:26,101 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:22:26,101 - INFO - Label flipping details:
2024-12-29 13:22:26,102 - INFO - - Source class: 1
2024-12-29 13:22:26,102 - INFO - - Target class: 0
2024-12-29 13:22:26,102 - INFO - - Available samples in source class: 955
2024-12-29 13:22:26,102 - INFO - - Requested samples to poison: 946
2024-12-29 13:22:26,102 - INFO - - Actual samples to flip: 946
2024-12-29 13:22:26,102 - INFO - - Samples remaining in source class: 9
2024-12-29 13:22:26,102 - INFO - Successfully flipped 946 labels from class 1 to 0
2024-12-29 13:22:26,102 - INFO - Total number of labels flipped: 946
2024-12-29 13:22:26,102 - INFO - Label flipping completed in 0.00s
2024-12-29 13:22:26,102 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:22:26,102 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:22:26,664 - INFO - Feature scaling completed in 0.56s
2024-12-29 13:22:26,664 - INFO - Starting feature selection (k=50)
2024-12-29 13:22:26,681 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 13:22:26,682 - INFO - Starting anomaly detection
2024-12-29 13:22:30,373 - INFO - Anomaly detection completed in 3.69s
2024-12-29 13:22:30,373 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:22:30,373 - INFO - Total fit_transform time: 4.27s
2024-12-29 13:22:30,373 - INFO - Training set processing completed in 4.27s
2024-12-29 13:22:30,373 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:22:30,374 - INFO - Memory usage at start_fit: CPU 2708.1 MB, GPU 122.6 MB
2024-12-29 13:22:30,374 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:22:30,576 - INFO - Fitted scaler and transformed data
2024-12-29 13:22:30,576 - INFO - Scaling time: 0.20s
2024-12-29 13:22:30,583 - INFO - Training completed in 0.21s
2024-12-29 13:22:30,584 - INFO - Final memory usage: CPU 2708.2 MB, GPU 122.6 MB
2024-12-29 13:22:30,584 - INFO - Model training completed in 0.21s
2024-12-29 13:22:30,685 - INFO - Prediction completed in 0.10s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 13:22:30,695 - INFO - Poison rate 0.1 completed in 4.59s
2024-12-29 13:22:30,695 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:22:30,696 - INFO - Label flipping details:
2024-12-29 13:22:30,696 - INFO - - Source class: 1
2024-12-29 13:22:30,696 - INFO - - Target class: 0
2024-12-29 13:22:30,696 - INFO - - Available samples in source class: 955
2024-12-29 13:22:30,696 - INFO - - Requested samples to poison: 1893
2024-12-29 13:22:30,696 - INFO - - Actual samples to flip: 954
2024-12-29 13:22:30,696 - INFO - - Samples remaining in source class: 1
2024-12-29 13:22:30,696 - INFO - Successfully flipped 954 labels from class 1 to 0
2024-12-29 13:22:30,696 - INFO - Total number of labels flipped: 954
2024-12-29 13:22:30,697 - INFO - Label flipping completed in 0.00s
2024-12-29 13:22:30,697 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:22:30,697 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:22:31,211 - INFO - Feature scaling completed in 0.51s
2024-12-29 13:22:31,211 - INFO - Starting feature selection (k=50)
2024-12-29 13:22:31,224 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:22:31,224 - INFO - Starting anomaly detection
2024-12-29 13:22:35,416 - INFO - Anomaly detection completed in 4.19s
2024-12-29 13:22:35,416 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:22:35,416 - INFO - Total fit_transform time: 4.72s
2024-12-29 13:22:35,416 - INFO - Training set processing completed in 4.72s
2024-12-29 13:22:35,416 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:22:35,418 - INFO - Memory usage at start_fit: CPU 2708.2 MB, GPU 122.6 MB
2024-12-29 13:22:35,418 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:22:35,601 - INFO - Fitted scaler and transformed data
2024-12-29 13:22:35,601 - INFO - Scaling time: 0.18s
2024-12-29 13:22:35,608 - INFO - Training completed in 0.19s
2024-12-29 13:22:35,609 - INFO - Final memory usage: CPU 2708.2 MB, GPU 122.6 MB
2024-12-29 13:22:35,609 - INFO - Model training completed in 0.19s
2024-12-29 13:22:35,714 - INFO - Prediction completed in 0.10s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 13:22:35,724 - INFO - Poison rate 0.2 completed in 5.03s
2024-12-29 13:22:35,727 - INFO - Loaded 161 existing results
2024-12-29 13:22:35,727 - INFO - Total results to save: 168
2024-12-29 13:22:35,728 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:22:35,734 - INFO - Saved 168 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:22:35,735 - INFO - Total evaluation time: 64.06s
2024-12-29 13:22:35,736 - INFO - Completed evaluation for GTSRB
2024-12-29 13:22:35,736 - INFO - 
Processing dataset: GTSRB
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:22:35,909 - INFO - 
Progress: 26.0% - Evaluating GTSRB with SVM (standard mode, iteration 1/1)
2024-12-29 13:22:36,168 - INFO - Loading datasets...
2024-12-29 13:22:36,189 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:22:36,189 - INFO - Extracting validation features...
2024-12-29 13:22:36,189 - INFO - Extracting features from 3925 samples...
2024-12-29 13:22:45,715 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:22:45,717 - INFO - Validation feature extraction completed in 9.53s
2024-12-29 13:22:45,718 - INFO - Extracting training features...
2024-12-29 13:22:45,718 - INFO - Extracting features from 9469 samples...
2024-12-29 13:23:07,548 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:23:07,557 - INFO - Training feature extraction completed in 21.84s
2024-12-29 13:23:07,557 - INFO - Creating model for classifier: SVM
2024-12-29 13:23:07,558 - INFO - Using device: cuda
2024-12-29 13:23:07,558 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-29 13:23:07,558 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:23:07,558 - INFO - Training set processing completed in 0.00s
2024-12-29 13:23:07,558 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:23:07,560 - INFO - Memory usage at start_fit: CPU 2680.6 MB, GPU 104.0 MB
2024-12-29 13:23:07,560 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:23:07,564 - INFO - Number of unique classes: 10
2024-12-29 13:23:07,630 - INFO - Fitted scaler and transformed data
2024-12-29 13:23:07,630 - INFO - Scaling time: 0.06s
2024-12-29 13:23:07,984 - INFO - Epoch 1/500, Train Loss: 0.8126, Val Loss: 0.1148
2024-12-29 13:23:08,312 - INFO - Epoch 2/500, Train Loss: 0.0918, Val Loss: 0.0836
2024-12-29 13:23:08,630 - INFO - Epoch 3/500, Train Loss: 0.0604, Val Loss: 0.0736
2024-12-29 13:23:08,955 - INFO - Epoch 4/500, Train Loss: 0.0432, Val Loss: 0.0690
2024-12-29 13:23:09,294 - INFO - Epoch 5/500, Train Loss: 0.0336, Val Loss: 0.0651
2024-12-29 13:23:09,620 - INFO - Epoch 6/500, Train Loss: 0.0266, Val Loss: 0.0626
2024-12-29 13:23:09,947 - INFO - Epoch 7/500, Train Loss: 0.0215, Val Loss: 0.0640
2024-12-29 13:23:10,282 - INFO - Epoch 8/500, Train Loss: 0.0174, Val Loss: 0.0647
2024-12-29 13:23:10,594 - INFO - Epoch 9/500, Train Loss: 0.0149, Val Loss: 0.0633
2024-12-29 13:23:10,934 - INFO - Epoch 10/500, Train Loss: 0.0124, Val Loss: 0.0643
2024-12-29 13:23:11,304 - INFO - Epoch 11/500, Train Loss: 0.0109, Val Loss: 0.0632
2024-12-29 13:23:11,304 - INFO - Early stopping triggered at epoch 11
2024-12-29 13:23:11,304 - INFO - Training completed in 3.75s
2024-12-29 13:23:11,305 - INFO - Final memory usage: CPU 2717.6 MB, GPU 104.2 MB
2024-12-29 13:23:11,306 - INFO - Model training completed in 3.75s
2024-12-29 13:23:11,352 - INFO - Prediction completed in 0.05s
2024-12-29 13:23:11,361 - INFO - Poison rate 0.0 completed in 3.80s
2024-12-29 13:23:11,361 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:23:11,363 - INFO - Total number of labels flipped: 94
2024-12-29 13:23:11,363 - INFO - Label flipping completed in 0.00s
2024-12-29 13:23:11,363 - INFO - Training set processing completed in 0.00s
2024-12-29 13:23:11,363 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:23:11,364 - INFO - Memory usage at start_fit: CPU 2688.0 MB, GPU 104.1 MB
2024-12-29 13:23:11,364 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:23:11,368 - INFO - Number of unique classes: 10
2024-12-29 13:23:11,443 - INFO - Fitted scaler and transformed data
2024-12-29 13:23:11,444 - INFO - Scaling time: 0.07s
2024-12-29 13:23:11,798 - INFO - Epoch 1/500, Train Loss: 0.8426, Val Loss: 0.3410
2024-12-29 13:23:12,132 - INFO - Epoch 2/500, Train Loss: 0.2056, Val Loss: 0.3364
2024-12-29 13:23:12,507 - INFO - Epoch 3/500, Train Loss: 0.1587, Val Loss: 0.3430
2024-12-29 13:23:12,862 - INFO - Epoch 4/500, Train Loss: 0.1278, Val Loss: 0.3523
2024-12-29 13:23:13,226 - INFO - Epoch 5/500, Train Loss: 0.1090, Val Loss: 0.3555
2024-12-29 13:23:13,601 - INFO - Epoch 6/500, Train Loss: 0.0935, Val Loss: 0.3602
2024-12-29 13:23:13,941 - INFO - Epoch 7/500, Train Loss: 0.0821, Val Loss: 0.3577
2024-12-29 13:23:13,941 - INFO - Early stopping triggered at epoch 7
2024-12-29 13:23:13,941 - INFO - Training completed in 2.58s
2024-12-29 13:23:13,942 - INFO - Final memory usage: CPU 2717.1 MB, GPU 104.2 MB
2024-12-29 13:23:13,943 - INFO - Model training completed in 2.58s
2024-12-29 13:23:13,990 - INFO - Prediction completed in 0.05s
2024-12-29 13:23:13,999 - INFO - Poison rate 0.01 completed in 2.64s
2024-12-29 13:23:13,999 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:23:14,003 - INFO - Total number of labels flipped: 284
2024-12-29 13:23:14,004 - INFO - Label flipping completed in 0.00s
2024-12-29 13:23:14,004 - INFO - Training set processing completed in 0.00s
2024-12-29 13:23:14,004 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:23:14,005 - INFO - Memory usage at start_fit: CPU 2687.8 MB, GPU 104.1 MB
2024-12-29 13:23:14,005 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:23:14,009 - INFO - Number of unique classes: 10
2024-12-29 13:23:14,082 - INFO - Fitted scaler and transformed data
2024-12-29 13:23:14,083 - INFO - Scaling time: 0.07s
2024-12-29 13:23:14,437 - INFO - Epoch 1/500, Train Loss: 1.3671, Val Loss: 0.5994
2024-12-29 13:23:14,786 - INFO - Epoch 2/500, Train Loss: 0.4774, Val Loss: 0.5501
2024-12-29 13:23:15,143 - INFO - Epoch 3/500, Train Loss: 0.3955, Val Loss: 0.5372
2024-12-29 13:23:15,485 - INFO - Epoch 4/500, Train Loss: 0.3390, Val Loss: 0.5275
2024-12-29 13:23:15,847 - INFO - Epoch 5/500, Train Loss: 0.2935, Val Loss: 0.5226
2024-12-29 13:23:16,182 - INFO - Epoch 6/500, Train Loss: 0.2624, Val Loss: 0.5286
2024-12-29 13:23:16,535 - INFO - Epoch 7/500, Train Loss: 0.2365, Val Loss: 0.5329
2024-12-29 13:23:16,880 - INFO - Epoch 8/500, Train Loss: 0.2162, Val Loss: 0.5371
2024-12-29 13:23:17,261 - INFO - Epoch 9/500, Train Loss: 0.1993, Val Loss: 0.5224
2024-12-29 13:23:17,608 - INFO - Epoch 10/500, Train Loss: 0.1866, Val Loss: 0.5262
2024-12-29 13:23:17,609 - INFO - Early stopping triggered at epoch 10
2024-12-29 13:23:17,609 - INFO - Training completed in 3.60s
2024-12-29 13:23:17,610 - INFO - Final memory usage: CPU 2717.4 MB, GPU 104.2 MB
2024-12-29 13:23:17,613 - INFO - Model training completed in 3.61s
2024-12-29 13:23:17,681 - INFO - Prediction completed in 0.07s
2024-12-29 13:23:17,690 - INFO - Poison rate 0.03 completed in 3.69s
2024-12-29 13:23:17,690 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:23:17,696 - INFO - Total number of labels flipped: 473
2024-12-29 13:23:17,697 - INFO - Label flipping completed in 0.01s
2024-12-29 13:23:17,697 - INFO - Training set processing completed in 0.00s
2024-12-29 13:23:17,697 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:23:17,698 - INFO - Memory usage at start_fit: CPU 2687.8 MB, GPU 104.1 MB
2024-12-29 13:23:17,698 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:23:17,703 - INFO - Number of unique classes: 10
2024-12-29 13:23:17,792 - INFO - Fitted scaler and transformed data
2024-12-29 13:23:17,792 - INFO - Scaling time: 0.09s
2024-12-29 13:23:18,154 - INFO - Epoch 1/500, Train Loss: 1.3694, Val Loss: 0.9520
2024-12-29 13:23:18,534 - INFO - Epoch 2/500, Train Loss: 0.6734, Val Loss: 0.8963
2024-12-29 13:23:18,907 - INFO - Epoch 3/500, Train Loss: 0.5731, Val Loss: 0.8960
2024-12-29 13:23:19,260 - INFO - Epoch 4/500, Train Loss: 0.5056, Val Loss: 0.8839
2024-12-29 13:23:19,612 - INFO - Epoch 5/500, Train Loss: 0.4526, Val Loss: 0.8930
2024-12-29 13:23:19,969 - INFO - Epoch 6/500, Train Loss: 0.4146, Val Loss: 0.8703
2024-12-29 13:23:20,346 - INFO - Epoch 7/500, Train Loss: 0.3880, Val Loss: 0.8835
2024-12-29 13:23:20,697 - INFO - Epoch 8/500, Train Loss: 0.3646, Val Loss: 0.8737
2024-12-29 13:23:21,037 - INFO - Epoch 9/500, Train Loss: 0.3446, Val Loss: 0.8751
2024-12-29 13:23:21,382 - INFO - Epoch 10/500, Train Loss: 0.3275, Val Loss: 0.8979
2024-12-29 13:23:21,716 - INFO - Epoch 11/500, Train Loss: 0.3207, Val Loss: 0.9128
2024-12-29 13:23:21,717 - INFO - Early stopping triggered at epoch 11
2024-12-29 13:23:21,717 - INFO - Training completed in 4.02s
2024-12-29 13:23:21,717 - INFO - Final memory usage: CPU 2717.4 MB, GPU 104.2 MB
2024-12-29 13:23:21,718 - INFO - Model training completed in 4.02s
2024-12-29 13:23:21,766 - INFO - Prediction completed in 0.05s
2024-12-29 13:23:21,780 - INFO - Poison rate 0.05 completed in 4.09s
2024-12-29 13:23:21,781 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:23:21,797 - INFO - Total number of labels flipped: 662
2024-12-29 13:23:21,797 - INFO - Label flipping completed in 0.02s
2024-12-29 13:23:21,797 - INFO - Training set processing completed in 0.00s
2024-12-29 13:23:21,797 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:23:21,798 - INFO - Memory usage at start_fit: CPU 2687.8 MB, GPU 104.1 MB
2024-12-29 13:23:21,799 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:23:21,805 - INFO - Number of unique classes: 10
2024-12-29 13:23:21,890 - INFO - Fitted scaler and transformed data
2024-12-29 13:23:21,891 - INFO - Scaling time: 0.08s
2024-12-29 13:23:22,287 - INFO - Epoch 1/500, Train Loss: 1.6569, Val Loss: 1.1403
2024-12-29 13:23:22,634 - INFO - Epoch 2/500, Train Loss: 0.9069, Val Loss: 1.1285
2024-12-29 13:23:23,025 - INFO - Epoch 3/500, Train Loss: 0.7827, Val Loss: 1.1389
2024-12-29 13:23:23,388 - INFO - Epoch 4/500, Train Loss: 0.6986, Val Loss: 1.1391
2024-12-29 13:23:23,754 - INFO - Epoch 5/500, Train Loss: 0.6399, Val Loss: 1.1522
2024-12-29 13:23:24,132 - INFO - Epoch 6/500, Train Loss: 0.5968, Val Loss: 1.1644
2024-12-29 13:23:24,553 - INFO - Epoch 7/500, Train Loss: 0.5598, Val Loss: 1.1805
2024-12-29 13:23:24,553 - INFO - Early stopping triggered at epoch 7
2024-12-29 13:23:24,553 - INFO - Training completed in 2.75s
2024-12-29 13:23:24,553 - INFO - Final memory usage: CPU 2717.4 MB, GPU 104.2 MB
2024-12-29 13:23:24,554 - INFO - Model training completed in 2.76s
2024-12-29 13:23:24,600 - INFO - Prediction completed in 0.04s
2024-12-29 13:23:24,608 - INFO - Poison rate 0.07 completed in 2.83s
2024-12-29 13:23:24,608 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:23:24,620 - INFO - Total number of labels flipped: 946
2024-12-29 13:23:24,620 - INFO - Label flipping completed in 0.01s
2024-12-29 13:23:24,620 - INFO - Training set processing completed in 0.00s
2024-12-29 13:23:24,620 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:23:24,621 - INFO - Memory usage at start_fit: CPU 2687.9 MB, GPU 104.1 MB
2024-12-29 13:23:24,621 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:23:24,624 - INFO - Number of unique classes: 10
2024-12-29 13:23:24,709 - INFO - Fitted scaler and transformed data
2024-12-29 13:23:24,709 - INFO - Scaling time: 0.08s
2024-12-29 13:23:25,145 - INFO - Epoch 1/500, Train Loss: 1.9993, Val Loss: 1.3416
2024-12-29 13:23:25,491 - INFO - Epoch 2/500, Train Loss: 1.2175, Val Loss: 1.3358
2024-12-29 13:23:25,847 - INFO - Epoch 3/500, Train Loss: 1.0938, Val Loss: 1.3241
2024-12-29 13:23:26,181 - INFO - Epoch 4/500, Train Loss: 0.9976, Val Loss: 1.3391
2024-12-29 13:23:26,545 - INFO - Epoch 5/500, Train Loss: 0.9337, Val Loss: 1.3315
2024-12-29 13:23:26,909 - INFO - Epoch 6/500, Train Loss: 0.8732, Val Loss: 1.3141
2024-12-29 13:23:27,351 - INFO - Epoch 7/500, Train Loss: 0.8389, Val Loss: 1.3401
2024-12-29 13:23:27,754 - INFO - Epoch 8/500, Train Loss: 0.8090, Val Loss: 1.3642
2024-12-29 13:23:28,120 - INFO - Epoch 9/500, Train Loss: 0.7734, Val Loss: 1.3516
2024-12-29 13:23:28,463 - INFO - Epoch 10/500, Train Loss: 0.7550, Val Loss: 1.3639
2024-12-29 13:23:28,812 - INFO - Epoch 11/500, Train Loss: 0.7352, Val Loss: 1.3664
2024-12-29 13:23:28,813 - INFO - Early stopping triggered at epoch 11
2024-12-29 13:23:28,813 - INFO - Training completed in 4.19s
2024-12-29 13:23:28,813 - INFO - Final memory usage: CPU 2717.8 MB, GPU 104.2 MB
2024-12-29 13:23:28,814 - INFO - Model training completed in 4.19s
2024-12-29 13:23:28,863 - INFO - Prediction completed in 0.05s
2024-12-29 13:23:28,873 - INFO - Poison rate 0.1 completed in 4.26s
2024-12-29 13:23:28,873 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:23:28,897 - INFO - Total number of labels flipped: 1893
2024-12-29 13:23:28,898 - INFO - Label flipping completed in 0.02s
2024-12-29 13:23:28,898 - INFO - Training set processing completed in 0.00s
2024-12-29 13:23:28,898 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:23:28,899 - INFO - Memory usage at start_fit: CPU 2688.2 MB, GPU 104.1 MB
2024-12-29 13:23:28,900 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:23:28,904 - INFO - Number of unique classes: 10
2024-12-29 13:23:28,979 - INFO - Fitted scaler and transformed data
2024-12-29 13:23:28,979 - INFO - Scaling time: 0.07s
2024-12-29 13:23:29,338 - INFO - Epoch 1/500, Train Loss: 3.0974, Val Loss: 2.6901
2024-12-29 13:23:29,685 - INFO - Epoch 2/500, Train Loss: 2.2854, Val Loss: 2.6995
2024-12-29 13:23:30,040 - INFO - Epoch 3/500, Train Loss: 2.0748, Val Loss: 2.6857
2024-12-29 13:23:30,394 - INFO - Epoch 4/500, Train Loss: 1.9420, Val Loss: 2.7145
2024-12-29 13:23:30,788 - INFO - Epoch 5/500, Train Loss: 1.8299, Val Loss: 2.7046
2024-12-29 13:23:31,129 - INFO - Epoch 6/500, Train Loss: 1.7761, Val Loss: 2.7210
2024-12-29 13:23:31,535 - INFO - Epoch 7/500, Train Loss: 1.7155, Val Loss: 2.7123
2024-12-29 13:23:31,864 - INFO - Epoch 8/500, Train Loss: 1.6698, Val Loss: 2.7707
2024-12-29 13:23:31,865 - INFO - Early stopping triggered at epoch 8
2024-12-29 13:23:31,865 - INFO - Training completed in 2.97s
2024-12-29 13:23:31,865 - INFO - Final memory usage: CPU 2717.5 MB, GPU 104.2 MB
2024-12-29 13:23:31,866 - INFO - Model training completed in 2.97s
2024-12-29 13:23:31,934 - INFO - Prediction completed in 0.07s
2024-12-29 13:23:31,943 - INFO - Poison rate 0.2 completed in 3.07s
2024-12-29 13:23:31,946 - INFO - Loaded 168 existing results
2024-12-29 13:23:31,947 - INFO - Total results to save: 175
2024-12-29 13:23:31,947 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:23:31,954 - INFO - Saved 175 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:23:31,954 - INFO - Total evaluation time: 55.79s
2024-12-29 13:23:31,956 - INFO - 
Progress: 27.1% - Evaluating GTSRB with SVM (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:23:32,190 - INFO - Loading datasets...
2024-12-29 13:23:32,212 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:23:32,212 - INFO - Extracting validation features...
2024-12-29 13:23:32,212 - INFO - Extracting features from 3925 samples...
2024-12-29 13:23:41,642 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:23:41,648 - INFO - Validation feature extraction completed in 9.44s
2024-12-29 13:23:41,648 - INFO - Extracting training features...
2024-12-29 13:23:41,649 - INFO - Extracting features from 9469 samples...
2024-12-29 13:24:03,260 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:24:03,268 - INFO - Training feature extraction completed in 21.62s
2024-12-29 13:24:03,269 - INFO - Creating model for classifier: SVM
2024-12-29 13:24:03,269 - INFO - Using device: cuda
2024-12-29 13:24:03,270 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-29 13:24:03,270 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:24:03,270 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:24:03,270 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:24:03,796 - INFO - Feature scaling completed in 0.53s
2024-12-29 13:24:03,796 - INFO - Starting feature selection (k=50)
2024-12-29 13:24:03,807 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:24:03,807 - INFO - Starting anomaly detection
2024-12-29 13:24:07,262 - INFO - Anomaly detection completed in 3.45s
2024-12-29 13:24:07,263 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:24:07,263 - INFO - Total fit_transform time: 3.99s
2024-12-29 13:24:07,264 - INFO - Training set processing completed in 3.99s
2024-12-29 13:24:07,264 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:24:07,266 - INFO - Memory usage at start_fit: CPU 2708.4 MB, GPU 104.6 MB
2024-12-29 13:24:07,266 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:24:07,269 - INFO - Number of unique classes: 10
2024-12-29 13:24:07,343 - INFO - Fitted scaler and transformed data
2024-12-29 13:24:07,343 - INFO - Scaling time: 0.07s
2024-12-29 13:24:07,721 - INFO - Epoch 1/500, Train Loss: 0.6384, Val Loss: 0.1421
2024-12-29 13:24:08,026 - INFO - Epoch 2/500, Train Loss: 0.0813, Val Loss: 0.1102
2024-12-29 13:24:08,376 - INFO - Epoch 3/500, Train Loss: 0.0519, Val Loss: 0.0932
2024-12-29 13:24:08,747 - INFO - Epoch 4/500, Train Loss: 0.0377, Val Loss: 0.0885
2024-12-29 13:24:09,121 - INFO - Epoch 5/500, Train Loss: 0.0280, Val Loss: 0.0821
2024-12-29 13:24:09,515 - INFO - Epoch 6/500, Train Loss: 0.0219, Val Loss: 0.0791
2024-12-29 13:24:09,884 - INFO - Epoch 7/500, Train Loss: 0.0177, Val Loss: 0.0776
2024-12-29 13:24:10,267 - INFO - Epoch 8/500, Train Loss: 0.0142, Val Loss: 0.0721
2024-12-29 13:24:10,638 - INFO - Epoch 9/500, Train Loss: 0.0119, Val Loss: 0.0726
2024-12-29 13:24:11,008 - INFO - Epoch 10/500, Train Loss: 0.0102, Val Loss: 0.0704
2024-12-29 13:24:11,354 - INFO - Epoch 11/500, Train Loss: 0.0089, Val Loss: 0.0713
2024-12-29 13:24:11,687 - INFO - Epoch 12/500, Train Loss: 0.0074, Val Loss: 0.0722
2024-12-29 13:24:12,017 - INFO - Epoch 13/500, Train Loss: 0.0071, Val Loss: 0.0717
2024-12-29 13:24:12,398 - INFO - Epoch 14/500, Train Loss: 0.0061, Val Loss: 0.0718
2024-12-29 13:24:12,777 - INFO - Epoch 15/500, Train Loss: 0.0053, Val Loss: 0.0710
2024-12-29 13:24:12,777 - INFO - Early stopping triggered at epoch 15
2024-12-29 13:24:12,777 - INFO - Training completed in 5.51s
2024-12-29 13:24:12,777 - INFO - Final memory usage: CPU 2717.8 MB, GPU 104.8 MB
2024-12-29 13:24:12,779 - INFO - Model training completed in 5.51s
2024-12-29 13:24:12,842 - INFO - Prediction completed in 0.06s
2024-12-29 13:24:12,852 - INFO - Poison rate 0.0 completed in 9.58s
2024-12-29 13:24:12,852 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:24:12,854 - INFO - Total number of labels flipped: 94
2024-12-29 13:24:12,854 - INFO - Label flipping completed in 0.00s
2024-12-29 13:24:12,854 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:24:12,854 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:24:13,383 - INFO - Feature scaling completed in 0.53s
2024-12-29 13:24:13,383 - INFO - Starting feature selection (k=50)
2024-12-29 13:24:13,398 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:24:13,398 - INFO - Starting anomaly detection
2024-12-29 13:24:17,620 - INFO - Anomaly detection completed in 4.22s
2024-12-29 13:24:17,620 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:24:17,620 - INFO - Total fit_transform time: 4.77s
2024-12-29 13:24:17,620 - INFO - Training set processing completed in 4.77s
2024-12-29 13:24:17,620 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:24:17,622 - INFO - Memory usage at start_fit: CPU 2708.2 MB, GPU 104.7 MB
2024-12-29 13:24:17,622 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:24:17,625 - INFO - Number of unique classes: 10
2024-12-29 13:24:17,697 - INFO - Fitted scaler and transformed data
2024-12-29 13:24:17,697 - INFO - Scaling time: 0.07s
2024-12-29 13:24:18,014 - INFO - Epoch 1/500, Train Loss: 0.8183, Val Loss: 0.1653
2024-12-29 13:24:18,326 - INFO - Epoch 2/500, Train Loss: 0.2089, Val Loss: 0.1409
2024-12-29 13:24:18,632 - INFO - Epoch 3/500, Train Loss: 0.1632, Val Loss: 0.1324
2024-12-29 13:24:18,953 - INFO - Epoch 4/500, Train Loss: 0.1341, Val Loss: 0.1308
2024-12-29 13:24:19,277 - INFO - Epoch 5/500, Train Loss: 0.1136, Val Loss: 0.1331
2024-12-29 13:24:19,590 - INFO - Epoch 6/500, Train Loss: 0.0999, Val Loss: 0.1322
2024-12-29 13:24:19,933 - INFO - Epoch 7/500, Train Loss: 0.0883, Val Loss: 0.1319
2024-12-29 13:24:20,312 - INFO - Epoch 8/500, Train Loss: 0.0804, Val Loss: 0.1360
2024-12-29 13:24:20,636 - INFO - Epoch 9/500, Train Loss: 0.0721, Val Loss: 0.1409
2024-12-29 13:24:20,636 - INFO - Early stopping triggered at epoch 9
2024-12-29 13:24:20,637 - INFO - Training completed in 3.02s
2024-12-29 13:24:20,637 - INFO - Final memory usage: CPU 2717.7 MB, GPU 104.8 MB
2024-12-29 13:24:20,638 - INFO - Model training completed in 3.02s
2024-12-29 13:24:20,684 - INFO - Prediction completed in 0.05s
2024-12-29 13:24:20,692 - INFO - Poison rate 0.01 completed in 7.84s
2024-12-29 13:24:20,692 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:24:20,697 - INFO - Total number of labels flipped: 284
2024-12-29 13:24:20,697 - INFO - Label flipping completed in 0.00s
2024-12-29 13:24:20,697 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:24:20,697 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:24:21,232 - INFO - Feature scaling completed in 0.53s
2024-12-29 13:24:21,232 - INFO - Starting feature selection (k=50)
2024-12-29 13:24:21,246 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:24:21,246 - INFO - Starting anomaly detection
2024-12-29 13:24:25,326 - INFO - Anomaly detection completed in 4.08s
2024-12-29 13:24:25,326 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:24:25,326 - INFO - Total fit_transform time: 4.63s
2024-12-29 13:24:25,326 - INFO - Training set processing completed in 4.63s
2024-12-29 13:24:25,327 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:24:25,328 - INFO - Memory usage at start_fit: CPU 2708.1 MB, GPU 104.7 MB
2024-12-29 13:24:25,328 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:24:25,331 - INFO - Number of unique classes: 10
2024-12-29 13:24:25,404 - INFO - Fitted scaler and transformed data
2024-12-29 13:24:25,404 - INFO - Scaling time: 0.07s
2024-12-29 13:24:25,754 - INFO - Epoch 1/500, Train Loss: 1.1056, Val Loss: 0.5369
2024-12-29 13:24:26,096 - INFO - Epoch 2/500, Train Loss: 0.4226, Val Loss: 0.5180
2024-12-29 13:24:26,450 - INFO - Epoch 3/500, Train Loss: 0.3564, Val Loss: 0.5229
2024-12-29 13:24:26,782 - INFO - Epoch 4/500, Train Loss: 0.3086, Val Loss: 0.5143
2024-12-29 13:24:27,101 - INFO - Epoch 5/500, Train Loss: 0.2756, Val Loss: 0.5157
2024-12-29 13:24:27,491 - INFO - Epoch 6/500, Train Loss: 0.2491, Val Loss: 0.5152
2024-12-29 13:24:27,822 - INFO - Epoch 7/500, Train Loss: 0.2280, Val Loss: 0.5204
2024-12-29 13:24:28,175 - INFO - Epoch 8/500, Train Loss: 0.2164, Val Loss: 0.5077
2024-12-29 13:24:28,508 - INFO - Epoch 9/500, Train Loss: 0.1995, Val Loss: 0.5137
2024-12-29 13:24:28,842 - INFO - Epoch 10/500, Train Loss: 0.1862, Val Loss: 0.5166
2024-12-29 13:24:29,210 - INFO - Epoch 11/500, Train Loss: 0.1808, Val Loss: 0.5082
2024-12-29 13:24:29,544 - INFO - Epoch 12/500, Train Loss: 0.1737, Val Loss: 0.5134
2024-12-29 13:24:29,924 - INFO - Epoch 13/500, Train Loss: 0.1649, Val Loss: 0.5173
2024-12-29 13:24:29,924 - INFO - Early stopping triggered at epoch 13
2024-12-29 13:24:29,924 - INFO - Training completed in 4.60s
2024-12-29 13:24:29,925 - INFO - Final memory usage: CPU 2717.7 MB, GPU 104.8 MB
2024-12-29 13:24:29,927 - INFO - Model training completed in 4.60s
2024-12-29 13:24:29,972 - INFO - Prediction completed in 0.04s
2024-12-29 13:24:29,995 - INFO - Poison rate 0.03 completed in 9.30s
2024-12-29 13:24:29,995 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:24:30,006 - INFO - Total number of labels flipped: 473
2024-12-29 13:24:30,006 - INFO - Label flipping completed in 0.01s
2024-12-29 13:24:30,006 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:24:30,006 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:24:30,610 - INFO - Feature scaling completed in 0.60s
2024-12-29 13:24:30,610 - INFO - Starting feature selection (k=50)
2024-12-29 13:24:30,627 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 13:24:30,627 - INFO - Starting anomaly detection
2024-12-29 13:24:33,378 - INFO - Anomaly detection completed in 2.75s
2024-12-29 13:24:33,379 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:24:33,379 - INFO - Total fit_transform time: 3.37s
2024-12-29 13:24:33,379 - INFO - Training set processing completed in 3.37s
2024-12-29 13:24:33,379 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:24:33,380 - INFO - Memory usage at start_fit: CPU 2708.4 MB, GPU 104.7 MB
2024-12-29 13:24:33,380 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:24:33,382 - INFO - Number of unique classes: 10
2024-12-29 13:24:33,453 - INFO - Fitted scaler and transformed data
2024-12-29 13:24:33,454 - INFO - Scaling time: 0.07s
2024-12-29 13:24:33,801 - INFO - Epoch 1/500, Train Loss: 1.3608, Val Loss: 0.8330
2024-12-29 13:24:34,137 - INFO - Epoch 2/500, Train Loss: 0.6814, Val Loss: 0.8267
2024-12-29 13:24:34,441 - INFO - Epoch 3/500, Train Loss: 0.5806, Val Loss: 0.8638
2024-12-29 13:24:34,754 - INFO - Epoch 4/500, Train Loss: 0.5075, Val Loss: 0.8907
2024-12-29 13:24:35,084 - INFO - Epoch 5/500, Train Loss: 0.4592, Val Loss: 0.8819
2024-12-29 13:24:35,479 - INFO - Epoch 6/500, Train Loss: 0.4211, Val Loss: 0.9059
2024-12-29 13:24:35,805 - INFO - Epoch 7/500, Train Loss: 0.3870, Val Loss: 0.9263
2024-12-29 13:24:35,806 - INFO - Early stopping triggered at epoch 7
2024-12-29 13:24:35,806 - INFO - Training completed in 2.43s
2024-12-29 13:24:35,806 - INFO - Final memory usage: CPU 2717.7 MB, GPU 104.8 MB
2024-12-29 13:24:35,808 - INFO - Model training completed in 2.43s
2024-12-29 13:24:35,851 - INFO - Prediction completed in 0.04s
2024-12-29 13:24:35,860 - INFO - Poison rate 0.05 completed in 5.86s
2024-12-29 13:24:35,860 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:24:35,868 - INFO - Total number of labels flipped: 662
2024-12-29 13:24:35,868 - INFO - Label flipping completed in 0.01s
2024-12-29 13:24:35,869 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:24:35,869 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:24:36,433 - INFO - Feature scaling completed in 0.56s
2024-12-29 13:24:36,433 - INFO - Starting feature selection (k=50)
2024-12-29 13:24:36,447 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:24:36,447 - INFO - Starting anomaly detection
2024-12-29 13:24:40,110 - INFO - Anomaly detection completed in 3.66s
2024-12-29 13:24:40,111 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:24:40,111 - INFO - Total fit_transform time: 4.24s
2024-12-29 13:24:40,111 - INFO - Training set processing completed in 4.24s
2024-12-29 13:24:40,111 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:24:40,112 - INFO - Memory usage at start_fit: CPU 2708.4 MB, GPU 104.7 MB
2024-12-29 13:24:40,112 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:24:40,114 - INFO - Number of unique classes: 10
2024-12-29 13:24:40,184 - INFO - Fitted scaler and transformed data
2024-12-29 13:24:40,184 - INFO - Scaling time: 0.07s
2024-12-29 13:24:40,553 - INFO - Epoch 1/500, Train Loss: 1.4558, Val Loss: 1.3021
2024-12-29 13:24:40,871 - INFO - Epoch 2/500, Train Loss: 0.8575, Val Loss: 1.2471
2024-12-29 13:24:41,215 - INFO - Epoch 3/500, Train Loss: 0.7500, Val Loss: 1.2252
2024-12-29 13:24:41,522 - INFO - Epoch 4/500, Train Loss: 0.6697, Val Loss: 1.2321
2024-12-29 13:24:41,840 - INFO - Epoch 5/500, Train Loss: 0.6103, Val Loss: 1.2311
2024-12-29 13:24:42,192 - INFO - Epoch 6/500, Train Loss: 0.5726, Val Loss: 1.2380
2024-12-29 13:24:42,504 - INFO - Epoch 7/500, Train Loss: 0.5451, Val Loss: 1.2477
2024-12-29 13:24:42,837 - INFO - Epoch 8/500, Train Loss: 0.5150, Val Loss: 1.2679
2024-12-29 13:24:42,837 - INFO - Early stopping triggered at epoch 8
2024-12-29 13:24:42,837 - INFO - Training completed in 2.73s
2024-12-29 13:24:42,837 - INFO - Final memory usage: CPU 2717.7 MB, GPU 104.8 MB
2024-12-29 13:24:42,838 - INFO - Model training completed in 2.73s
2024-12-29 13:24:42,901 - INFO - Prediction completed in 0.06s
2024-12-29 13:24:42,909 - INFO - Poison rate 0.07 completed in 7.05s
2024-12-29 13:24:42,909 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:24:42,920 - INFO - Total number of labels flipped: 946
2024-12-29 13:24:42,920 - INFO - Label flipping completed in 0.01s
2024-12-29 13:24:42,920 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:24:42,920 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:24:43,468 - INFO - Feature scaling completed in 0.55s
2024-12-29 13:24:43,468 - INFO - Starting feature selection (k=50)
2024-12-29 13:24:43,482 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:24:43,483 - INFO - Starting anomaly detection
2024-12-29 13:24:46,159 - INFO - Anomaly detection completed in 2.68s
2024-12-29 13:24:46,159 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:24:46,159 - INFO - Total fit_transform time: 3.24s
2024-12-29 13:24:46,160 - INFO - Training set processing completed in 3.24s
2024-12-29 13:24:46,160 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:24:46,161 - INFO - Memory usage at start_fit: CPU 2708.4 MB, GPU 104.7 MB
2024-12-29 13:24:46,161 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:24:46,164 - INFO - Number of unique classes: 10
2024-12-29 13:24:46,239 - INFO - Fitted scaler and transformed data
2024-12-29 13:24:46,239 - INFO - Scaling time: 0.07s
2024-12-29 13:24:46,575 - INFO - Epoch 1/500, Train Loss: 2.0047, Val Loss: 1.2909
2024-12-29 13:24:46,886 - INFO - Epoch 2/500, Train Loss: 1.2130, Val Loss: 1.2312
2024-12-29 13:24:47,217 - INFO - Epoch 3/500, Train Loss: 1.0716, Val Loss: 1.2317
2024-12-29 13:24:47,550 - INFO - Epoch 4/500, Train Loss: 0.9752, Val Loss: 1.2015
2024-12-29 13:24:47,847 - INFO - Epoch 5/500, Train Loss: 0.9073, Val Loss: 1.2014
2024-12-29 13:24:48,146 - INFO - Epoch 6/500, Train Loss: 0.8543, Val Loss: 1.2224
2024-12-29 13:24:48,473 - INFO - Epoch 7/500, Train Loss: 0.8176, Val Loss: 1.2248
2024-12-29 13:24:48,790 - INFO - Epoch 8/500, Train Loss: 0.7828, Val Loss: 1.2434
2024-12-29 13:24:49,082 - INFO - Epoch 9/500, Train Loss: 0.7566, Val Loss: 1.2499
2024-12-29 13:24:49,082 - INFO - Early stopping triggered at epoch 9
2024-12-29 13:24:49,082 - INFO - Training completed in 2.92s
2024-12-29 13:24:49,083 - INFO - Final memory usage: CPU 2717.7 MB, GPU 104.8 MB
2024-12-29 13:24:49,084 - INFO - Model training completed in 2.92s
2024-12-29 13:24:49,127 - INFO - Prediction completed in 0.04s
2024-12-29 13:24:49,144 - INFO - Poison rate 0.1 completed in 6.23s
2024-12-29 13:24:49,144 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:24:49,165 - INFO - Total number of labels flipped: 1893
2024-12-29 13:24:49,166 - INFO - Label flipping completed in 0.02s
2024-12-29 13:24:49,166 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:24:49,166 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:24:49,782 - INFO - Feature scaling completed in 0.62s
2024-12-29 13:24:49,782 - INFO - Starting feature selection (k=50)
2024-12-29 13:24:49,795 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:24:49,795 - INFO - Starting anomaly detection
2024-12-29 13:24:52,630 - INFO - Anomaly detection completed in 2.83s
2024-12-29 13:24:52,630 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:24:52,630 - INFO - Total fit_transform time: 3.46s
2024-12-29 13:24:52,630 - INFO - Training set processing completed in 3.46s
2024-12-29 13:24:52,630 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:24:52,631 - INFO - Memory usage at start_fit: CPU 2708.4 MB, GPU 104.7 MB
2024-12-29 13:24:52,631 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:24:52,634 - INFO - Number of unique classes: 10
2024-12-29 13:24:52,715 - INFO - Fitted scaler and transformed data
2024-12-29 13:24:52,715 - INFO - Scaling time: 0.08s
2024-12-29 13:24:53,046 - INFO - Epoch 1/500, Train Loss: 2.9621, Val Loss: 2.7251
2024-12-29 13:24:53,418 - INFO - Epoch 2/500, Train Loss: 2.2081, Val Loss: 2.6426
2024-12-29 13:24:53,751 - INFO - Epoch 3/500, Train Loss: 2.0249, Val Loss: 2.6600
2024-12-29 13:24:54,093 - INFO - Epoch 4/500, Train Loss: 1.9083, Val Loss: 2.7155
2024-12-29 13:24:54,433 - INFO - Epoch 5/500, Train Loss: 1.8214, Val Loss: 2.7315
2024-12-29 13:24:54,794 - INFO - Epoch 6/500, Train Loss: 1.7569, Val Loss: 2.7531
2024-12-29 13:24:55,121 - INFO - Epoch 7/500, Train Loss: 1.7122, Val Loss: 2.7932
2024-12-29 13:24:55,121 - INFO - Early stopping triggered at epoch 7
2024-12-29 13:24:55,121 - INFO - Training completed in 2.49s
2024-12-29 13:24:55,122 - INFO - Final memory usage: CPU 2717.4 MB, GPU 104.8 MB
2024-12-29 13:24:55,123 - INFO - Model training completed in 2.49s
2024-12-29 13:24:55,182 - INFO - Prediction completed in 0.06s
2024-12-29 13:24:55,191 - INFO - Poison rate 0.2 completed in 6.05s
2024-12-29 13:24:55,201 - INFO - Loaded 175 existing results
2024-12-29 13:24:55,201 - INFO - Total results to save: 182
2024-12-29 13:24:55,204 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:24:55,220 - INFO - Saved 182 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:24:55,221 - INFO - Total evaluation time: 83.03s
2024-12-29 13:24:55,224 - INFO - 
Progress: 28.1% - Evaluating GTSRB with LogisticRegression (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:24:55,449 - INFO - Loading datasets...
2024-12-29 13:24:55,470 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:24:55,470 - INFO - Extracting validation features...
2024-12-29 13:24:55,470 - INFO - Extracting features from 3925 samples...
2024-12-29 13:25:04,639 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:25:04,645 - INFO - Validation feature extraction completed in 9.17s
2024-12-29 13:25:04,645 - INFO - Extracting training features...
2024-12-29 13:25:04,645 - INFO - Extracting features from 9469 samples...
2024-12-29 13:25:26,576 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:25:26,582 - INFO - Training feature extraction completed in 21.94s
2024-12-29 13:25:26,583 - INFO - Creating model for classifier: LogisticRegression
2024-12-29 13:25:26,583 - INFO - Using device: cuda
2024-12-29 13:25:26,583 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:25:26,583 - INFO - Training set processing completed in 0.00s
2024-12-29 13:25:26,583 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:25:26,585 - INFO - Memory usage at start_fit: CPU 2680.7 MB, GPU 104.0 MB
2024-12-29 13:25:26,585 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:25:26,590 - INFO - Number of unique classes: 10
2024-12-29 13:25:26,663 - INFO - Fitted scaler and transformed data
2024-12-29 13:25:26,663 - INFO - Scaling time: 0.07s
2024-12-29 13:25:26,868 - INFO - Epoch 1/1000, Train Loss: 0.4978, Val Loss: 0.1313
2024-12-29 13:25:27,072 - INFO - Epoch 2/1000, Train Loss: 0.0951, Val Loss: 0.0933
2024-12-29 13:25:27,296 - INFO - Epoch 3/1000, Train Loss: 0.0686, Val Loss: 0.0790
2024-12-29 13:25:27,494 - INFO - Epoch 4/1000, Train Loss: 0.0553, Val Loss: 0.0715
2024-12-29 13:25:27,708 - INFO - Epoch 5/1000, Train Loss: 0.0477, Val Loss: 0.0672
2024-12-29 13:25:27,932 - INFO - Epoch 6/1000, Train Loss: 0.0425, Val Loss: 0.0644
2024-12-29 13:25:28,125 - INFO - Epoch 7/1000, Train Loss: 0.0389, Val Loss: 0.0626
2024-12-29 13:25:28,318 - INFO - Epoch 8/1000, Train Loss: 0.0361, Val Loss: 0.0615
2024-12-29 13:25:28,497 - INFO - Epoch 9/1000, Train Loss: 0.0347, Val Loss: 0.0606
2024-12-29 13:25:28,734 - INFO - Epoch 10/1000, Train Loss: 0.0328, Val Loss: 0.0600
2024-12-29 13:25:28,930 - INFO - Epoch 11/1000, Train Loss: 0.0319, Val Loss: 0.0599
2024-12-29 13:25:29,121 - INFO - Epoch 12/1000, Train Loss: 0.0309, Val Loss: 0.0596
2024-12-29 13:25:29,316 - INFO - Epoch 13/1000, Train Loss: 0.0305, Val Loss: 0.0592
2024-12-29 13:25:29,519 - INFO - Epoch 14/1000, Train Loss: 0.0300, Val Loss: 0.0588
2024-12-29 13:25:29,733 - INFO - Epoch 15/1000, Train Loss: 0.0295, Val Loss: 0.0588
2024-12-29 13:25:29,965 - INFO - Epoch 16/1000, Train Loss: 0.0290, Val Loss: 0.0584
2024-12-29 13:25:30,171 - INFO - Epoch 17/1000, Train Loss: 0.0289, Val Loss: 0.0585
2024-12-29 13:25:30,384 - INFO - Epoch 18/1000, Train Loss: 0.0290, Val Loss: 0.0573
2024-12-29 13:25:30,588 - INFO - Epoch 19/1000, Train Loss: 0.0286, Val Loss: 0.0577
2024-12-29 13:25:30,809 - INFO - Epoch 20/1000, Train Loss: 0.0283, Val Loss: 0.0578
2024-12-29 13:25:31,034 - INFO - Epoch 21/1000, Train Loss: 0.0282, Val Loss: 0.0570
2024-12-29 13:25:31,260 - INFO - Epoch 22/1000, Train Loss: 0.0281, Val Loss: 0.0581
2024-12-29 13:25:31,459 - INFO - Epoch 23/1000, Train Loss: 0.0281, Val Loss: 0.0568
2024-12-29 13:25:31,459 - INFO - Early stopping triggered at epoch 23
2024-12-29 13:25:31,459 - INFO - Training completed in 4.88s
2024-12-29 13:25:31,459 - INFO - Final memory usage: CPU 2717.7 MB, GPU 104.2 MB
2024-12-29 13:25:31,460 - INFO - Model training completed in 4.88s
2024-12-29 13:25:31,519 - INFO - Prediction completed in 0.06s
2024-12-29 13:25:31,528 - INFO - Poison rate 0.0 completed in 4.95s
2024-12-29 13:25:31,529 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:25:31,530 - INFO - Total number of labels flipped: 94
2024-12-29 13:25:31,531 - INFO - Label flipping completed in 0.00s
2024-12-29 13:25:31,531 - INFO - Training set processing completed in 0.00s
2024-12-29 13:25:31,531 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:25:31,532 - INFO - Memory usage at start_fit: CPU 2688.3 MB, GPU 104.1 MB
2024-12-29 13:25:31,532 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:25:31,535 - INFO - Number of unique classes: 10
2024-12-29 13:25:31,622 - INFO - Fitted scaler and transformed data
2024-12-29 13:25:31,623 - INFO - Scaling time: 0.09s
2024-12-29 13:25:31,842 - INFO - Epoch 1/1000, Train Loss: 0.5325, Val Loss: 0.1804
2024-12-29 13:25:32,064 - INFO - Epoch 2/1000, Train Loss: 0.1668, Val Loss: 0.1569
2024-12-29 13:25:32,285 - INFO - Epoch 3/1000, Train Loss: 0.1464, Val Loss: 0.1505
2024-12-29 13:25:32,508 - INFO - Epoch 4/1000, Train Loss: 0.1327, Val Loss: 0.1473
2024-12-29 13:25:32,745 - INFO - Epoch 5/1000, Train Loss: 0.1250, Val Loss: 0.1458
2024-12-29 13:25:32,952 - INFO - Epoch 6/1000, Train Loss: 0.1186, Val Loss: 0.1456
2024-12-29 13:25:33,148 - INFO - Epoch 7/1000, Train Loss: 0.1139, Val Loss: 0.1469
2024-12-29 13:25:33,363 - INFO - Epoch 8/1000, Train Loss: 0.1101, Val Loss: 0.1467
2024-12-29 13:25:33,604 - INFO - Epoch 9/1000, Train Loss: 0.1079, Val Loss: 0.1471
2024-12-29 13:25:33,813 - INFO - Epoch 10/1000, Train Loss: 0.1045, Val Loss: 0.1473
2024-12-29 13:25:33,813 - INFO - Early stopping triggered at epoch 10
2024-12-29 13:25:33,813 - INFO - Training completed in 2.28s
2024-12-29 13:25:33,814 - INFO - Final memory usage: CPU 2717.6 MB, GPU 104.2 MB
2024-12-29 13:25:33,816 - INFO - Model training completed in 2.28s
2024-12-29 13:25:33,868 - INFO - Prediction completed in 0.05s
2024-12-29 13:25:33,876 - INFO - Poison rate 0.01 completed in 2.35s
2024-12-29 13:25:33,876 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:25:33,880 - INFO - Total number of labels flipped: 284
2024-12-29 13:25:33,880 - INFO - Label flipping completed in 0.00s
2024-12-29 13:25:33,881 - INFO - Training set processing completed in 0.00s
2024-12-29 13:25:33,881 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:25:33,882 - INFO - Memory usage at start_fit: CPU 2692.1 MB, GPU 104.1 MB
2024-12-29 13:25:33,882 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:25:33,886 - INFO - Number of unique classes: 10
2024-12-29 13:25:33,964 - INFO - Fitted scaler and transformed data
2024-12-29 13:25:33,965 - INFO - Scaling time: 0.08s
2024-12-29 13:25:34,197 - INFO - Epoch 1/1000, Train Loss: 0.6744, Val Loss: 0.3678
2024-12-29 13:25:34,441 - INFO - Epoch 2/1000, Train Loss: 0.2914, Val Loss: 0.3507
2024-12-29 13:25:34,655 - INFO - Epoch 3/1000, Train Loss: 0.2703, Val Loss: 0.3437
2024-12-29 13:25:34,864 - INFO - Epoch 4/1000, Train Loss: 0.2566, Val Loss: 0.3415
2024-12-29 13:25:35,068 - INFO - Epoch 5/1000, Train Loss: 0.2449, Val Loss: 0.3410
2024-12-29 13:25:35,273 - INFO - Epoch 6/1000, Train Loss: 0.2372, Val Loss: 0.3401
2024-12-29 13:25:35,470 - INFO - Epoch 7/1000, Train Loss: 0.2300, Val Loss: 0.3407
2024-12-29 13:25:35,671 - INFO - Epoch 8/1000, Train Loss: 0.2246, Val Loss: 0.3444
2024-12-29 13:25:35,872 - INFO - Epoch 9/1000, Train Loss: 0.2190, Val Loss: 0.3424
2024-12-29 13:25:36,102 - INFO - Epoch 10/1000, Train Loss: 0.2168, Val Loss: 0.3433
2024-12-29 13:25:36,317 - INFO - Epoch 11/1000, Train Loss: 0.2130, Val Loss: 0.3458
2024-12-29 13:25:36,317 - INFO - Early stopping triggered at epoch 11
2024-12-29 13:25:36,318 - INFO - Training completed in 2.44s
2024-12-29 13:25:36,318 - INFO - Final memory usage: CPU 2717.5 MB, GPU 104.2 MB
2024-12-29 13:25:36,321 - INFO - Model training completed in 2.44s
2024-12-29 13:25:36,389 - INFO - Prediction completed in 0.07s
2024-12-29 13:25:36,397 - INFO - Poison rate 0.03 completed in 2.52s
2024-12-29 13:25:36,397 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:25:36,403 - INFO - Total number of labels flipped: 473
2024-12-29 13:25:36,404 - INFO - Label flipping completed in 0.01s
2024-12-29 13:25:36,404 - INFO - Training set processing completed in 0.00s
2024-12-29 13:25:36,404 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:25:36,405 - INFO - Memory usage at start_fit: CPU 2692.0 MB, GPU 104.1 MB
2024-12-29 13:25:36,405 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:25:36,408 - INFO - Number of unique classes: 10
2024-12-29 13:25:36,492 - INFO - Fitted scaler and transformed data
2024-12-29 13:25:36,492 - INFO - Scaling time: 0.08s
2024-12-29 13:25:36,714 - INFO - Epoch 1/1000, Train Loss: 0.6980, Val Loss: 0.4221
2024-12-29 13:25:36,940 - INFO - Epoch 2/1000, Train Loss: 0.4061, Val Loss: 0.4140
2024-12-29 13:25:37,143 - INFO - Epoch 3/1000, Train Loss: 0.3846, Val Loss: 0.4108
2024-12-29 13:25:37,369 - INFO - Epoch 4/1000, Train Loss: 0.3689, Val Loss: 0.4117
2024-12-29 13:25:37,602 - INFO - Epoch 5/1000, Train Loss: 0.3594, Val Loss: 0.4167
2024-12-29 13:25:37,804 - INFO - Epoch 6/1000, Train Loss: 0.3489, Val Loss: 0.4148
2024-12-29 13:25:38,181 - INFO - Epoch 7/1000, Train Loss: 0.3417, Val Loss: 0.4100
2024-12-29 13:25:38,567 - INFO - Epoch 8/1000, Train Loss: 0.3342, Val Loss: 0.4157
2024-12-29 13:25:38,568 - INFO - Early stopping triggered at epoch 8
2024-12-29 13:25:38,568 - INFO - Training completed in 2.16s
2024-12-29 13:25:38,569 - INFO - Final memory usage: CPU 2717.3 MB, GPU 104.2 MB
2024-12-29 13:25:38,571 - INFO - Model training completed in 2.17s
2024-12-29 13:25:38,667 - INFO - Prediction completed in 0.09s
2024-12-29 13:25:38,691 - INFO - Poison rate 0.05 completed in 2.29s
2024-12-29 13:25:38,691 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:25:38,707 - INFO - Total number of labels flipped: 662
2024-12-29 13:25:38,707 - INFO - Label flipping completed in 0.02s
2024-12-29 13:25:38,707 - INFO - Training set processing completed in 0.00s
2024-12-29 13:25:38,707 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:25:38,709 - INFO - Memory usage at start_fit: CPU 2691.9 MB, GPU 104.1 MB
2024-12-29 13:25:38,709 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:25:38,713 - INFO - Number of unique classes: 10
2024-12-29 13:25:38,801 - INFO - Fitted scaler and transformed data
2024-12-29 13:25:38,801 - INFO - Scaling time: 0.09s
2024-12-29 13:25:39,192 - INFO - Epoch 1/1000, Train Loss: 0.8048, Val Loss: 0.6357
2024-12-29 13:25:39,615 - INFO - Epoch 2/1000, Train Loss: 0.5125, Val Loss: 0.6170
2024-12-29 13:25:40,033 - INFO - Epoch 3/1000, Train Loss: 0.4876, Val Loss: 0.6136
2024-12-29 13:25:40,456 - INFO - Epoch 4/1000, Train Loss: 0.4675, Val Loss: 0.6089
2024-12-29 13:25:40,816 - INFO - Epoch 5/1000, Train Loss: 0.4559, Val Loss: 0.6147
2024-12-29 13:25:41,177 - INFO - Epoch 6/1000, Train Loss: 0.4434, Val Loss: 0.6199
2024-12-29 13:25:41,511 - INFO - Epoch 7/1000, Train Loss: 0.4359, Val Loss: 0.6293
2024-12-29 13:25:41,945 - INFO - Epoch 8/1000, Train Loss: 0.4302, Val Loss: 0.6200
2024-12-29 13:25:42,386 - INFO - Epoch 9/1000, Train Loss: 0.4231, Val Loss: 0.6271
2024-12-29 13:25:42,386 - INFO - Early stopping triggered at epoch 9
2024-12-29 13:25:42,386 - INFO - Training completed in 3.68s
2024-12-29 13:25:42,387 - INFO - Final memory usage: CPU 2717.7 MB, GPU 104.2 MB
2024-12-29 13:25:42,389 - INFO - Model training completed in 3.68s
2024-12-29 13:25:42,438 - INFO - Prediction completed in 0.05s
2024-12-29 13:25:42,448 - INFO - Poison rate 0.07 completed in 3.76s
2024-12-29 13:25:42,448 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:25:42,459 - INFO - Total number of labels flipped: 946
2024-12-29 13:25:42,459 - INFO - Label flipping completed in 0.01s
2024-12-29 13:25:42,459 - INFO - Training set processing completed in 0.00s
2024-12-29 13:25:42,459 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:25:42,461 - INFO - Memory usage at start_fit: CPU 2692.0 MB, GPU 104.1 MB
2024-12-29 13:25:42,461 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:25:42,466 - INFO - Number of unique classes: 10
2024-12-29 13:25:42,546 - INFO - Fitted scaler and transformed data
2024-12-29 13:25:42,546 - INFO - Scaling time: 0.08s
2024-12-29 13:25:42,955 - INFO - Epoch 1/1000, Train Loss: 0.9077, Val Loss: 0.6265
2024-12-29 13:25:43,372 - INFO - Epoch 2/1000, Train Loss: 0.6615, Val Loss: 0.6256
2024-12-29 13:25:43,799 - INFO - Epoch 3/1000, Train Loss: 0.6329, Val Loss: 0.6260
2024-12-29 13:25:44,212 - INFO - Epoch 4/1000, Train Loss: 0.6113, Val Loss: 0.6390
2024-12-29 13:25:44,595 - INFO - Epoch 5/1000, Train Loss: 0.5978, Val Loss: 0.6385
2024-12-29 13:25:44,906 - INFO - Epoch 6/1000, Train Loss: 0.5898, Val Loss: 0.6423
2024-12-29 13:25:44,907 - INFO - Early stopping triggered at epoch 6
2024-12-29 13:25:44,907 - INFO - Training completed in 2.45s
2024-12-29 13:25:44,908 - INFO - Final memory usage: CPU 2717.5 MB, GPU 104.2 MB
2024-12-29 13:25:44,910 - INFO - Model training completed in 2.45s
2024-12-29 13:25:44,980 - INFO - Prediction completed in 0.07s
2024-12-29 13:25:44,992 - INFO - Poison rate 0.1 completed in 2.54s
2024-12-29 13:25:44,992 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:25:45,013 - INFO - Total number of labels flipped: 1893
2024-12-29 13:25:45,014 - INFO - Label flipping completed in 0.02s
2024-12-29 13:25:45,014 - INFO - Training set processing completed in 0.00s
2024-12-29 13:25:45,014 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:25:45,015 - INFO - Memory usage at start_fit: CPU 2691.8 MB, GPU 104.1 MB
2024-12-29 13:25:45,015 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:25:45,018 - INFO - Number of unique classes: 10
2024-12-29 13:25:45,091 - INFO - Fitted scaler and transformed data
2024-12-29 13:25:45,091 - INFO - Scaling time: 0.07s
2024-12-29 13:25:45,327 - INFO - Epoch 1/1000, Train Loss: 1.2592, Val Loss: 1.0246
2024-12-29 13:25:45,565 - INFO - Epoch 2/1000, Train Loss: 1.0520, Val Loss: 1.0100
2024-12-29 13:25:45,775 - INFO - Epoch 3/1000, Train Loss: 1.0167, Val Loss: 1.0159
2024-12-29 13:25:45,989 - INFO - Epoch 4/1000, Train Loss: 0.9938, Val Loss: 1.0113
2024-12-29 13:25:46,189 - INFO - Epoch 5/1000, Train Loss: 0.9756, Val Loss: 1.0179
2024-12-29 13:25:46,417 - INFO - Epoch 6/1000, Train Loss: 0.9673, Val Loss: 1.0100
2024-12-29 13:25:46,620 - INFO - Epoch 7/1000, Train Loss: 0.9516, Val Loss: 1.0144
2024-12-29 13:25:46,621 - INFO - Early stopping triggered at epoch 7
2024-12-29 13:25:46,621 - INFO - Training completed in 1.61s
2024-12-29 13:25:46,621 - INFO - Final memory usage: CPU 2717.6 MB, GPU 104.2 MB
2024-12-29 13:25:46,622 - INFO - Model training completed in 1.61s
2024-12-29 13:25:46,687 - INFO - Prediction completed in 0.06s
2024-12-29 13:25:46,696 - INFO - Poison rate 0.2 completed in 1.70s
2024-12-29 13:25:46,700 - INFO - Loaded 182 existing results
2024-12-29 13:25:46,700 - INFO - Total results to save: 189
2024-12-29 13:25:46,701 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:25:46,707 - INFO - Saved 189 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:25:46,707 - INFO - Total evaluation time: 51.26s
2024-12-29 13:25:46,709 - INFO - 
Progress: 29.2% - Evaluating GTSRB with LogisticRegression (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:25:46,926 - INFO - Loading datasets...
2024-12-29 13:25:46,946 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:25:46,947 - INFO - Extracting validation features...
2024-12-29 13:25:46,947 - INFO - Extracting features from 3925 samples...
2024-12-29 13:25:56,356 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:25:56,361 - INFO - Validation feature extraction completed in 9.41s
2024-12-29 13:25:56,361 - INFO - Extracting training features...
2024-12-29 13:25:56,361 - INFO - Extracting features from 9469 samples...
2024-12-29 13:26:17,711 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:26:17,719 - INFO - Training feature extraction completed in 21.36s
2024-12-29 13:26:17,720 - INFO - Creating model for classifier: LogisticRegression
2024-12-29 13:26:17,721 - INFO - Using device: cuda
2024-12-29 13:26:17,721 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:26:17,721 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:26:17,721 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:26:18,285 - INFO - Feature scaling completed in 0.56s
2024-12-29 13:26:18,285 - INFO - Starting feature selection (k=50)
2024-12-29 13:26:18,293 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:26:18,293 - INFO - Starting anomaly detection
2024-12-29 13:26:20,428 - INFO - Anomaly detection completed in 2.13s
2024-12-29 13:26:20,428 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:26:20,428 - INFO - Total fit_transform time: 2.71s
2024-12-29 13:26:20,428 - INFO - Training set processing completed in 2.71s
2024-12-29 13:26:20,428 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:26:20,430 - INFO - Memory usage at start_fit: CPU 2708.5 MB, GPU 104.6 MB
2024-12-29 13:26:20,430 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:26:20,433 - INFO - Number of unique classes: 10
2024-12-29 13:26:20,521 - INFO - Fitted scaler and transformed data
2024-12-29 13:26:20,521 - INFO - Scaling time: 0.09s
2024-12-29 13:26:20,793 - INFO - Epoch 1/1000, Train Loss: 0.4871, Val Loss: 0.1079
2024-12-29 13:26:21,113 - INFO - Epoch 2/1000, Train Loss: 0.0952, Val Loss: 0.0735
2024-12-29 13:26:21,502 - INFO - Epoch 3/1000, Train Loss: 0.0679, Val Loss: 0.0610
2024-12-29 13:26:21,829 - INFO - Epoch 4/1000, Train Loss: 0.0551, Val Loss: 0.0550
2024-12-29 13:26:22,245 - INFO - Epoch 5/1000, Train Loss: 0.0475, Val Loss: 0.0516
2024-12-29 13:26:22,615 - INFO - Epoch 6/1000, Train Loss: 0.0425, Val Loss: 0.0492
2024-12-29 13:26:23,038 - INFO - Epoch 7/1000, Train Loss: 0.0388, Val Loss: 0.0483
2024-12-29 13:26:23,309 - INFO - Epoch 8/1000, Train Loss: 0.0364, Val Loss: 0.0469
2024-12-29 13:26:23,512 - INFO - Epoch 9/1000, Train Loss: 0.0348, Val Loss: 0.0464
2024-12-29 13:26:23,720 - INFO - Epoch 10/1000, Train Loss: 0.0334, Val Loss: 0.0463
2024-12-29 13:26:23,962 - INFO - Epoch 11/1000, Train Loss: 0.0322, Val Loss: 0.0455
2024-12-29 13:26:24,157 - INFO - Epoch 12/1000, Train Loss: 0.0313, Val Loss: 0.0453
2024-12-29 13:26:24,354 - INFO - Epoch 13/1000, Train Loss: 0.0306, Val Loss: 0.0453
2024-12-29 13:26:24,544 - INFO - Epoch 14/1000, Train Loss: 0.0302, Val Loss: 0.0448
2024-12-29 13:26:24,746 - INFO - Epoch 15/1000, Train Loss: 0.0298, Val Loss: 0.0447
2024-12-29 13:26:24,988 - INFO - Epoch 16/1000, Train Loss: 0.0295, Val Loss: 0.0447
2024-12-29 13:26:24,988 - INFO - Early stopping triggered at epoch 16
2024-12-29 13:26:24,988 - INFO - Training completed in 4.56s
2024-12-29 13:26:24,989 - INFO - Final memory usage: CPU 2717.5 MB, GPU 104.8 MB
2024-12-29 13:26:24,990 - INFO - Model training completed in 4.56s
2024-12-29 13:26:25,061 - INFO - Prediction completed in 0.07s
2024-12-29 13:26:25,069 - INFO - Poison rate 0.0 completed in 7.35s
2024-12-29 13:26:25,069 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:26:25,071 - INFO - Total number of labels flipped: 94
2024-12-29 13:26:25,072 - INFO - Label flipping completed in 0.00s
2024-12-29 13:26:25,072 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:26:25,072 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:26:25,680 - INFO - Feature scaling completed in 0.61s
2024-12-29 13:26:25,681 - INFO - Starting feature selection (k=50)
2024-12-29 13:26:25,695 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:26:25,696 - INFO - Starting anomaly detection
2024-12-29 13:26:29,995 - INFO - Anomaly detection completed in 4.30s
2024-12-29 13:26:29,995 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:26:29,996 - INFO - Total fit_transform time: 4.92s
2024-12-29 13:26:29,996 - INFO - Training set processing completed in 4.92s
2024-12-29 13:26:29,996 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:26:29,996 - INFO - Memory usage at start_fit: CPU 2708.2 MB, GPU 104.7 MB
2024-12-29 13:26:29,997 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:26:30,000 - INFO - Number of unique classes: 10
2024-12-29 13:26:30,069 - INFO - Fitted scaler and transformed data
2024-12-29 13:26:30,070 - INFO - Scaling time: 0.07s
2024-12-29 13:26:30,320 - INFO - Epoch 1/1000, Train Loss: 0.4933, Val Loss: 0.1443
2024-12-29 13:26:30,624 - INFO - Epoch 2/1000, Train Loss: 0.1678, Val Loss: 0.1164
2024-12-29 13:26:30,907 - INFO - Epoch 3/1000, Train Loss: 0.1464, Val Loss: 0.1066
2024-12-29 13:26:31,167 - INFO - Epoch 4/1000, Train Loss: 0.1347, Val Loss: 0.1034
2024-12-29 13:26:31,402 - INFO - Epoch 5/1000, Train Loss: 0.1280, Val Loss: 0.1012
2024-12-29 13:26:31,652 - INFO - Epoch 6/1000, Train Loss: 0.1211, Val Loss: 0.1007
2024-12-29 13:26:31,960 - INFO - Epoch 7/1000, Train Loss: 0.1175, Val Loss: 0.0992
2024-12-29 13:26:32,190 - INFO - Epoch 8/1000, Train Loss: 0.1123, Val Loss: 0.0994
2024-12-29 13:26:32,521 - INFO - Epoch 9/1000, Train Loss: 0.1102, Val Loss: 0.0990
2024-12-29 13:26:32,774 - INFO - Epoch 10/1000, Train Loss: 0.1074, Val Loss: 0.0999
2024-12-29 13:26:33,046 - INFO - Epoch 11/1000, Train Loss: 0.1051, Val Loss: 0.0991
2024-12-29 13:26:33,323 - INFO - Epoch 12/1000, Train Loss: 0.1034, Val Loss: 0.0990
2024-12-29 13:26:33,323 - INFO - Early stopping triggered at epoch 12
2024-12-29 13:26:33,323 - INFO - Training completed in 3.33s
2024-12-29 13:26:33,324 - INFO - Final memory usage: CPU 2728.6 MB, GPU 104.8 MB
2024-12-29 13:26:33,326 - INFO - Model training completed in 3.33s
2024-12-29 13:26:33,396 - INFO - Prediction completed in 0.07s
2024-12-29 13:26:33,405 - INFO - Poison rate 0.01 completed in 8.34s
2024-12-29 13:26:33,405 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:26:33,409 - INFO - Total number of labels flipped: 284
2024-12-29 13:26:33,409 - INFO - Label flipping completed in 0.00s
2024-12-29 13:26:33,409 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:26:33,409 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:26:33,922 - INFO - Feature scaling completed in 0.51s
2024-12-29 13:26:33,923 - INFO - Starting feature selection (k=50)
2024-12-29 13:26:33,937 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:26:33,937 - INFO - Starting anomaly detection
2024-12-29 13:26:37,058 - INFO - Anomaly detection completed in 3.12s
2024-12-29 13:26:37,058 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:26:37,059 - INFO - Total fit_transform time: 3.65s
2024-12-29 13:26:37,059 - INFO - Training set processing completed in 3.65s
2024-12-29 13:26:37,059 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:26:37,060 - INFO - Memory usage at start_fit: CPU 2710.1 MB, GPU 104.7 MB
2024-12-29 13:26:37,061 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:26:37,063 - INFO - Number of unique classes: 10
2024-12-29 13:26:37,133 - INFO - Fitted scaler and transformed data
2024-12-29 13:26:37,133 - INFO - Scaling time: 0.07s
2024-12-29 13:26:37,419 - INFO - Epoch 1/1000, Train Loss: 0.5927, Val Loss: 0.2990
2024-12-29 13:26:37,741 - INFO - Epoch 2/1000, Train Loss: 0.2917, Val Loss: 0.2836
2024-12-29 13:26:38,129 - INFO - Epoch 3/1000, Train Loss: 0.2714, Val Loss: 0.2806
2024-12-29 13:26:38,547 - INFO - Epoch 4/1000, Train Loss: 0.2581, Val Loss: 0.2808
2024-12-29 13:26:38,892 - INFO - Epoch 5/1000, Train Loss: 0.2485, Val Loss: 0.2797
2024-12-29 13:26:39,253 - INFO - Epoch 6/1000, Train Loss: 0.2413, Val Loss: 0.2828
2024-12-29 13:26:39,451 - INFO - Epoch 7/1000, Train Loss: 0.2363, Val Loss: 0.2847
2024-12-29 13:26:39,663 - INFO - Epoch 8/1000, Train Loss: 0.2300, Val Loss: 0.2867
2024-12-29 13:26:39,663 - INFO - Early stopping triggered at epoch 8
2024-12-29 13:26:39,663 - INFO - Training completed in 2.60s
2024-12-29 13:26:39,664 - INFO - Final memory usage: CPU 2717.6 MB, GPU 104.8 MB
2024-12-29 13:26:39,665 - INFO - Model training completed in 2.61s
2024-12-29 13:26:39,754 - INFO - Prediction completed in 0.09s
2024-12-29 13:26:39,763 - INFO - Poison rate 0.03 completed in 6.36s
2024-12-29 13:26:39,763 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:26:39,769 - INFO - Total number of labels flipped: 473
2024-12-29 13:26:39,769 - INFO - Label flipping completed in 0.01s
2024-12-29 13:26:39,769 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:26:39,769 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:26:40,389 - INFO - Feature scaling completed in 0.62s
2024-12-29 13:26:40,389 - INFO - Starting feature selection (k=50)
2024-12-29 13:26:40,403 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:26:40,403 - INFO - Starting anomaly detection
2024-12-29 13:26:44,715 - INFO - Anomaly detection completed in 4.31s
2024-12-29 13:26:44,715 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:26:44,715 - INFO - Total fit_transform time: 4.95s
2024-12-29 13:26:44,715 - INFO - Training set processing completed in 4.95s
2024-12-29 13:26:44,715 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:26:44,717 - INFO - Memory usage at start_fit: CPU 2708.4 MB, GPU 104.7 MB
2024-12-29 13:26:44,717 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:26:44,720 - INFO - Number of unique classes: 10
2024-12-29 13:26:44,793 - INFO - Fitted scaler and transformed data
2024-12-29 13:26:44,794 - INFO - Scaling time: 0.07s
2024-12-29 13:26:45,008 - INFO - Epoch 1/1000, Train Loss: 0.7214, Val Loss: 0.4741
2024-12-29 13:26:45,209 - INFO - Epoch 2/1000, Train Loss: 0.4026, Val Loss: 0.4583
2024-12-29 13:26:45,420 - INFO - Epoch 3/1000, Train Loss: 0.3808, Val Loss: 0.4534
2024-12-29 13:26:45,616 - INFO - Epoch 4/1000, Train Loss: 0.3653, Val Loss: 0.4509
2024-12-29 13:26:45,822 - INFO - Epoch 5/1000, Train Loss: 0.3536, Val Loss: 0.4517
2024-12-29 13:26:46,017 - INFO - Epoch 6/1000, Train Loss: 0.3454, Val Loss: 0.4513
2024-12-29 13:26:46,213 - INFO - Epoch 7/1000, Train Loss: 0.3404, Val Loss: 0.4511
2024-12-29 13:26:46,417 - INFO - Epoch 8/1000, Train Loss: 0.3328, Val Loss: 0.4535
2024-12-29 13:26:46,648 - INFO - Epoch 9/1000, Train Loss: 0.3256, Val Loss: 0.4567
2024-12-29 13:26:46,649 - INFO - Early stopping triggered at epoch 9
2024-12-29 13:26:46,649 - INFO - Training completed in 1.93s
2024-12-29 13:26:46,650 - INFO - Final memory usage: CPU 2728.6 MB, GPU 104.8 MB
2024-12-29 13:26:46,651 - INFO - Model training completed in 1.94s
2024-12-29 13:26:46,711 - INFO - Prediction completed in 0.06s
2024-12-29 13:26:46,719 - INFO - Poison rate 0.05 completed in 6.96s
2024-12-29 13:26:46,719 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:26:46,727 - INFO - Total number of labels flipped: 662
2024-12-29 13:26:46,728 - INFO - Label flipping completed in 0.01s
2024-12-29 13:26:46,728 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:26:46,728 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:26:47,306 - INFO - Feature scaling completed in 0.58s
2024-12-29 13:26:47,306 - INFO - Starting feature selection (k=50)
2024-12-29 13:26:47,319 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:26:47,320 - INFO - Starting anomaly detection
2024-12-29 13:26:51,498 - INFO - Anomaly detection completed in 4.18s
2024-12-29 13:26:51,498 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:26:51,498 - INFO - Total fit_transform time: 4.77s
2024-12-29 13:26:51,498 - INFO - Training set processing completed in 4.77s
2024-12-29 13:26:51,498 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:26:51,499 - INFO - Memory usage at start_fit: CPU 2709.8 MB, GPU 104.7 MB
2024-12-29 13:26:51,500 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:26:51,502 - INFO - Number of unique classes: 10
2024-12-29 13:26:51,572 - INFO - Fitted scaler and transformed data
2024-12-29 13:26:51,573 - INFO - Scaling time: 0.07s
2024-12-29 13:26:51,949 - INFO - Epoch 1/1000, Train Loss: 0.7914, Val Loss: 0.5900
2024-12-29 13:26:52,375 - INFO - Epoch 2/1000, Train Loss: 0.5109, Val Loss: 0.5786
2024-12-29 13:26:52,736 - INFO - Epoch 3/1000, Train Loss: 0.4842, Val Loss: 0.5736
2024-12-29 13:26:52,939 - INFO - Epoch 4/1000, Train Loss: 0.4681, Val Loss: 0.5700
2024-12-29 13:26:53,137 - INFO - Epoch 5/1000, Train Loss: 0.4544, Val Loss: 0.5752
2024-12-29 13:26:53,324 - INFO - Epoch 6/1000, Train Loss: 0.4438, Val Loss: 0.5768
2024-12-29 13:26:53,526 - INFO - Epoch 7/1000, Train Loss: 0.4355, Val Loss: 0.5789
2024-12-29 13:26:53,722 - INFO - Epoch 8/1000, Train Loss: 0.4279, Val Loss: 0.5812
2024-12-29 13:26:53,918 - INFO - Epoch 9/1000, Train Loss: 0.4246, Val Loss: 0.5857
2024-12-29 13:26:53,919 - INFO - Early stopping triggered at epoch 9
2024-12-29 13:26:53,919 - INFO - Training completed in 2.42s
2024-12-29 13:26:53,919 - INFO - Final memory usage: CPU 2728.5 MB, GPU 104.8 MB
2024-12-29 13:26:53,921 - INFO - Model training completed in 2.42s
2024-12-29 13:26:54,003 - INFO - Prediction completed in 0.08s
2024-12-29 13:26:54,012 - INFO - Poison rate 0.07 completed in 7.29s
2024-12-29 13:26:54,012 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:26:54,027 - INFO - Total number of labels flipped: 946
2024-12-29 13:26:54,028 - INFO - Label flipping completed in 0.02s
2024-12-29 13:26:54,028 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:26:54,029 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:26:54,600 - INFO - Feature scaling completed in 0.57s
2024-12-29 13:26:54,600 - INFO - Starting feature selection (k=50)
2024-12-29 13:26:54,614 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:26:54,614 - INFO - Starting anomaly detection
2024-12-29 13:26:57,088 - INFO - Anomaly detection completed in 2.47s
2024-12-29 13:26:57,088 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:26:57,088 - INFO - Total fit_transform time: 3.06s
2024-12-29 13:26:57,088 - INFO - Training set processing completed in 3.06s
2024-12-29 13:26:57,089 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:26:57,089 - INFO - Memory usage at start_fit: CPU 2709.9 MB, GPU 104.7 MB
2024-12-29 13:26:57,090 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:26:57,092 - INFO - Number of unique classes: 10
2024-12-29 13:26:57,166 - INFO - Fitted scaler and transformed data
2024-12-29 13:26:57,166 - INFO - Scaling time: 0.07s
2024-12-29 13:26:57,368 - INFO - Epoch 1/1000, Train Loss: 0.9415, Val Loss: 0.6765
2024-12-29 13:26:57,545 - INFO - Epoch 2/1000, Train Loss: 0.6690, Val Loss: 0.6730
2024-12-29 13:26:57,727 - INFO - Epoch 3/1000, Train Loss: 0.6387, Val Loss: 0.6727
2024-12-29 13:26:57,919 - INFO - Epoch 4/1000, Train Loss: 0.6194, Val Loss: 0.6726
2024-12-29 13:26:58,127 - INFO - Epoch 5/1000, Train Loss: 0.6052, Val Loss: 0.6803
2024-12-29 13:26:58,316 - INFO - Epoch 6/1000, Train Loss: 0.5942, Val Loss: 0.6798
2024-12-29 13:26:58,495 - INFO - Epoch 7/1000, Train Loss: 0.5868, Val Loss: 0.6824
2024-12-29 13:26:58,496 - INFO - Early stopping triggered at epoch 7
2024-12-29 13:26:58,496 - INFO - Training completed in 1.41s
2024-12-29 13:26:58,497 - INFO - Final memory usage: CPU 2717.4 MB, GPU 104.8 MB
2024-12-29 13:26:58,499 - INFO - Model training completed in 1.41s
2024-12-29 13:26:58,571 - INFO - Prediction completed in 0.07s
2024-12-29 13:26:58,579 - INFO - Poison rate 0.1 completed in 4.57s
2024-12-29 13:26:58,579 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:26:58,601 - INFO - Total number of labels flipped: 1893
2024-12-29 13:26:58,601 - INFO - Label flipping completed in 0.02s
2024-12-29 13:26:58,602 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:26:58,602 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:26:59,195 - INFO - Feature scaling completed in 0.59s
2024-12-29 13:26:59,196 - INFO - Starting feature selection (k=50)
2024-12-29 13:26:59,206 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:26:59,206 - INFO - Starting anomaly detection
2024-12-29 13:27:03,145 - INFO - Anomaly detection completed in 3.94s
2024-12-29 13:27:03,145 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:27:03,145 - INFO - Total fit_transform time: 4.54s
2024-12-29 13:27:03,145 - INFO - Training set processing completed in 4.54s
2024-12-29 13:27:03,145 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:27:03,147 - INFO - Memory usage at start_fit: CPU 2707.8 MB, GPU 104.7 MB
2024-12-29 13:27:03,147 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:27:03,150 - INFO - Number of unique classes: 10
2024-12-29 13:27:03,225 - INFO - Fitted scaler and transformed data
2024-12-29 13:27:03,225 - INFO - Scaling time: 0.07s
2024-12-29 13:27:03,439 - INFO - Epoch 1/1000, Train Loss: 1.2634, Val Loss: 1.0875
2024-12-29 13:27:03,660 - INFO - Epoch 2/1000, Train Loss: 1.0538, Val Loss: 1.0782
2024-12-29 13:27:03,865 - INFO - Epoch 3/1000, Train Loss: 1.0197, Val Loss: 1.0731
2024-12-29 13:27:04,088 - INFO - Epoch 4/1000, Train Loss: 0.9967, Val Loss: 1.0795
2024-12-29 13:27:04,307 - INFO - Epoch 5/1000, Train Loss: 0.9817, Val Loss: 1.0779
2024-12-29 13:27:04,512 - INFO - Epoch 6/1000, Train Loss: 0.9712, Val Loss: 1.0844
2024-12-29 13:27:04,740 - INFO - Epoch 7/1000, Train Loss: 0.9614, Val Loss: 1.0820
2024-12-29 13:27:04,984 - INFO - Epoch 8/1000, Train Loss: 0.9538, Val Loss: 1.0954
2024-12-29 13:27:04,984 - INFO - Early stopping triggered at epoch 8
2024-12-29 13:27:04,984 - INFO - Training completed in 1.84s
2024-12-29 13:27:04,985 - INFO - Final memory usage: CPU 2717.3 MB, GPU 104.8 MB
2024-12-29 13:27:04,987 - INFO - Model training completed in 1.84s
2024-12-29 13:27:05,042 - INFO - Prediction completed in 0.05s
2024-12-29 13:27:05,051 - INFO - Poison rate 0.2 completed in 6.47s
2024-12-29 13:27:05,054 - INFO - Loaded 189 existing results
2024-12-29 13:27:05,055 - INFO - Total results to save: 196
2024-12-29 13:27:05,056 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:27:05,063 - INFO - Saved 196 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:27:05,063 - INFO - Total evaluation time: 78.14s
2024-12-29 13:27:05,065 - INFO - 
Progress: 30.2% - Evaluating GTSRB with RandomForest (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:27:05,275 - INFO - Loading datasets...
2024-12-29 13:27:05,303 - INFO - Dataset loading completed in 0.03s
2024-12-29 13:27:05,303 - INFO - Extracting validation features...
2024-12-29 13:27:05,303 - INFO - Extracting features from 3925 samples...
2024-12-29 13:27:14,603 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:27:14,609 - INFO - Validation feature extraction completed in 9.31s
2024-12-29 13:27:14,609 - INFO - Extracting training features...
2024-12-29 13:27:14,610 - INFO - Extracting features from 9469 samples...
2024-12-29 13:27:36,724 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:27:36,732 - INFO - Training feature extraction completed in 22.12s
2024-12-29 13:27:36,732 - INFO - Creating model for classifier: RandomForest
2024-12-29 13:27:36,732 - INFO - Using device: cuda
2024-12-29 13:27:36,732 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:27:36,733 - INFO - Training set processing completed in 0.00s
2024-12-29 13:27:36,733 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:27:36,734 - INFO - Memory usage at start_fit: CPU 2680.3 MB, GPU 104.0 MB
2024-12-29 13:27:36,734 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:27:36,943 - INFO - Fitted scaler and transformed data
2024-12-29 13:27:36,943 - INFO - Scaling time: 0.21s
2024-12-29 13:27:36,952 - INFO - Number of unique classes: 10
2024-12-29 13:27:40,464 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3014
2024-12-29 13:27:43,315 - INFO - Epoch 2/10, Train Loss: 2.3006, Val Loss: 2.3001
2024-12-29 13:27:47,177 - INFO - Epoch 3/10, Train Loss: 2.2992, Val Loss: 2.2988
2024-12-29 13:27:50,326 - INFO - Epoch 4/10, Train Loss: 2.2977, Val Loss: 2.2975
2024-12-29 13:27:50,327 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:27:50,327 - INFO - Training completed in 13.59s
2024-12-29 13:27:50,327 - INFO - Final memory usage: CPU 2707.9 MB, GPU 125.9 MB
2024-12-29 13:27:50,327 - INFO - Model training completed in 13.59s
2024-12-29 13:27:50,620 - INFO - Prediction completed in 0.29s
2024-12-29 13:27:50,632 - INFO - Poison rate 0.0 completed in 13.90s
2024-12-29 13:27:50,632 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:27:50,634 - INFO - Total number of labels flipped: 94
2024-12-29 13:27:50,634 - INFO - Label flipping completed in 0.00s
2024-12-29 13:27:50,634 - INFO - Training set processing completed in 0.00s
2024-12-29 13:27:50,634 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:27:50,635 - INFO - Memory usage at start_fit: CPU 2707.9 MB, GPU 106.0 MB
2024-12-29 13:27:50,636 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:27:50,809 - INFO - Fitted scaler and transformed data
2024-12-29 13:27:50,809 - INFO - Scaling time: 0.17s
2024-12-29 13:27:50,820 - INFO - Number of unique classes: 10
2024-12-29 13:27:54,427 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3013
2024-12-29 13:27:58,070 - INFO - Epoch 2/10, Train Loss: 2.3006, Val Loss: 2.3000
2024-12-29 13:28:01,732 - INFO - Epoch 3/10, Train Loss: 2.2992, Val Loss: 2.2987
2024-12-29 13:28:06,147 - INFO - Epoch 4/10, Train Loss: 2.2978, Val Loss: 2.2973
2024-12-29 13:28:06,147 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:28:06,147 - INFO - Training completed in 15.51s
2024-12-29 13:28:06,148 - INFO - Final memory usage: CPU 2707.9 MB, GPU 125.9 MB
2024-12-29 13:28:06,148 - INFO - Model training completed in 15.51s
2024-12-29 13:28:06,324 - INFO - Prediction completed in 0.18s
2024-12-29 13:28:06,333 - INFO - Poison rate 0.01 completed in 15.70s
2024-12-29 13:28:06,333 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:28:06,337 - INFO - Total number of labels flipped: 284
2024-12-29 13:28:06,337 - INFO - Label flipping completed in 0.00s
2024-12-29 13:28:06,337 - INFO - Training set processing completed in 0.00s
2024-12-29 13:28:06,337 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:28:06,338 - INFO - Memory usage at start_fit: CPU 2707.9 MB, GPU 106.0 MB
2024-12-29 13:28:06,338 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:28:06,560 - INFO - Fitted scaler and transformed data
2024-12-29 13:28:06,561 - INFO - Scaling time: 0.22s
2024-12-29 13:28:06,571 - INFO - Number of unique classes: 10
2024-12-29 13:28:10,403 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3013
2024-12-29 13:28:13,551 - INFO - Epoch 2/10, Train Loss: 2.3006, Val Loss: 2.3001
2024-12-29 13:28:17,347 - INFO - Epoch 3/10, Train Loss: 2.2993, Val Loss: 2.2988
2024-12-29 13:28:20,423 - INFO - Epoch 4/10, Train Loss: 2.2979, Val Loss: 2.2975
2024-12-29 13:28:20,423 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:28:20,423 - INFO - Training completed in 14.09s
2024-12-29 13:28:20,424 - INFO - Final memory usage: CPU 2707.9 MB, GPU 125.9 MB
2024-12-29 13:28:20,424 - INFO - Model training completed in 14.09s
2024-12-29 13:28:20,688 - INFO - Prediction completed in 0.26s
2024-12-29 13:28:20,697 - INFO - Poison rate 0.03 completed in 14.36s
2024-12-29 13:28:20,697 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:28:20,703 - INFO - Total number of labels flipped: 473
2024-12-29 13:28:20,703 - INFO - Label flipping completed in 0.01s
2024-12-29 13:28:20,704 - INFO - Training set processing completed in 0.00s
2024-12-29 13:28:20,704 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:28:20,704 - INFO - Memory usage at start_fit: CPU 2707.9 MB, GPU 106.0 MB
2024-12-29 13:28:20,705 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:28:20,903 - INFO - Fitted scaler and transformed data
2024-12-29 13:28:20,903 - INFO - Scaling time: 0.20s
2024-12-29 13:28:20,913 - INFO - Number of unique classes: 10
2024-12-29 13:28:25,021 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3014
2024-12-29 13:28:29,301 - INFO - Epoch 2/10, Train Loss: 2.3007, Val Loss: 2.3002
2024-12-29 13:28:33,189 - INFO - Epoch 3/10, Train Loss: 2.2994, Val Loss: 2.2990
2024-12-29 13:28:37,101 - INFO - Epoch 4/10, Train Loss: 2.2981, Val Loss: 2.2978
2024-12-29 13:28:37,101 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:28:37,101 - INFO - Training completed in 16.40s
2024-12-29 13:28:37,101 - INFO - Final memory usage: CPU 2707.9 MB, GPU 125.9 MB
2024-12-29 13:28:37,102 - INFO - Model training completed in 16.40s
2024-12-29 13:28:37,389 - INFO - Prediction completed in 0.29s
2024-12-29 13:28:37,398 - INFO - Poison rate 0.05 completed in 16.70s
2024-12-29 13:28:37,398 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:28:37,407 - INFO - Total number of labels flipped: 662
2024-12-29 13:28:37,407 - INFO - Label flipping completed in 0.01s
2024-12-29 13:28:37,407 - INFO - Training set processing completed in 0.00s
2024-12-29 13:28:37,407 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:28:37,408 - INFO - Memory usage at start_fit: CPU 2707.9 MB, GPU 106.0 MB
2024-12-29 13:28:37,408 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:28:37,586 - INFO - Fitted scaler and transformed data
2024-12-29 13:28:37,587 - INFO - Scaling time: 0.18s
2024-12-29 13:28:37,597 - INFO - Number of unique classes: 10
2024-12-29 13:28:41,555 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3015
2024-12-29 13:28:44,771 - INFO - Epoch 2/10, Train Loss: 2.3007, Val Loss: 2.3004
2024-12-29 13:28:48,449 - INFO - Epoch 3/10, Train Loss: 2.2995, Val Loss: 2.2993
2024-12-29 13:28:51,947 - INFO - Epoch 4/10, Train Loss: 2.2982, Val Loss: 2.2981
2024-12-29 13:28:51,948 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:28:51,948 - INFO - Training completed in 14.54s
2024-12-29 13:28:51,948 - INFO - Final memory usage: CPU 2707.9 MB, GPU 125.9 MB
2024-12-29 13:28:51,948 - INFO - Model training completed in 14.54s
2024-12-29 13:28:52,134 - INFO - Prediction completed in 0.19s
2024-12-29 13:28:52,143 - INFO - Poison rate 0.07 completed in 14.74s
2024-12-29 13:28:52,143 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:28:52,155 - INFO - Total number of labels flipped: 946
2024-12-29 13:28:52,155 - INFO - Label flipping completed in 0.01s
2024-12-29 13:28:52,155 - INFO - Training set processing completed in 0.00s
2024-12-29 13:28:52,155 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:28:52,156 - INFO - Memory usage at start_fit: CPU 2707.9 MB, GPU 106.0 MB
2024-12-29 13:28:52,156 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:28:52,344 - INFO - Fitted scaler and transformed data
2024-12-29 13:28:52,344 - INFO - Scaling time: 0.19s
2024-12-29 13:28:52,354 - INFO - Number of unique classes: 10
2024-12-29 13:28:55,304 - INFO - Epoch 1/10, Train Loss: 2.3021, Val Loss: 2.3015
2024-12-29 13:28:58,071 - INFO - Epoch 2/10, Train Loss: 2.3009, Val Loss: 2.3004
2024-12-29 13:29:01,210 - INFO - Epoch 3/10, Train Loss: 2.2997, Val Loss: 2.2994
2024-12-29 13:29:04,795 - INFO - Epoch 4/10, Train Loss: 2.2984, Val Loss: 2.2983
2024-12-29 13:29:04,795 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:29:04,795 - INFO - Training completed in 12.64s
2024-12-29 13:29:04,795 - INFO - Final memory usage: CPU 2707.9 MB, GPU 125.9 MB
2024-12-29 13:29:04,796 - INFO - Model training completed in 12.64s
2024-12-29 13:29:04,947 - INFO - Prediction completed in 0.15s
2024-12-29 13:29:04,956 - INFO - Poison rate 0.1 completed in 12.81s
2024-12-29 13:29:04,956 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:29:04,978 - INFO - Total number of labels flipped: 1893
2024-12-29 13:29:04,978 - INFO - Label flipping completed in 0.02s
2024-12-29 13:29:04,979 - INFO - Training set processing completed in 0.00s
2024-12-29 13:29:04,979 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:29:04,980 - INFO - Memory usage at start_fit: CPU 2707.9 MB, GPU 106.0 MB
2024-12-29 13:29:04,980 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:29:05,172 - INFO - Fitted scaler and transformed data
2024-12-29 13:29:05,172 - INFO - Scaling time: 0.19s
2024-12-29 13:29:05,183 - INFO - Number of unique classes: 10
2024-12-29 13:29:07,991 - INFO - Epoch 1/10, Train Loss: 2.3022, Val Loss: 2.3017
2024-12-29 13:29:10,794 - INFO - Epoch 2/10, Train Loss: 2.3011, Val Loss: 2.3008
2024-12-29 13:29:13,365 - INFO - Epoch 3/10, Train Loss: 2.3001, Val Loss: 2.3000
2024-12-29 13:29:16,206 - INFO - Epoch 4/10, Train Loss: 2.2991, Val Loss: 2.2991
2024-12-29 13:29:16,206 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:29:16,206 - INFO - Training completed in 11.23s
2024-12-29 13:29:16,207 - INFO - Final memory usage: CPU 2707.9 MB, GPU 125.9 MB
2024-12-29 13:29:16,207 - INFO - Model training completed in 11.23s
2024-12-29 13:29:16,357 - INFO - Prediction completed in 0.15s
2024-12-29 13:29:16,366 - INFO - Poison rate 0.2 completed in 11.41s
2024-12-29 13:29:16,370 - INFO - Loaded 196 existing results
2024-12-29 13:29:16,371 - INFO - Total results to save: 203
2024-12-29 13:29:16,371 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:29:16,378 - INFO - Saved 203 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:29:16,379 - INFO - Total evaluation time: 131.10s
2024-12-29 13:29:16,380 - INFO - 
Progress: 31.2% - Evaluating GTSRB with RandomForest (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:29:16,565 - INFO - Loading datasets...
2024-12-29 13:29:16,585 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:29:16,586 - INFO - Extracting validation features...
2024-12-29 13:29:16,586 - INFO - Extracting features from 3925 samples...
2024-12-29 13:29:25,937 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:29:25,943 - INFO - Validation feature extraction completed in 9.36s
2024-12-29 13:29:25,944 - INFO - Extracting training features...
2024-12-29 13:29:25,944 - INFO - Extracting features from 9469 samples...
2024-12-29 13:29:48,148 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:29:48,157 - INFO - Training feature extraction completed in 22.21s
2024-12-29 13:29:48,157 - INFO - Creating model for classifier: RandomForest
2024-12-29 13:29:48,158 - INFO - Using device: cuda
2024-12-29 13:29:48,158 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:29:48,158 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:29:48,159 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:29:48,732 - INFO - Feature scaling completed in 0.57s
2024-12-29 13:29:48,732 - INFO - Starting feature selection (k=50)
2024-12-29 13:29:48,745 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:29:48,746 - INFO - Starting anomaly detection
2024-12-29 13:29:52,548 - INFO - Anomaly detection completed in 3.80s
2024-12-29 13:29:52,549 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:29:52,549 - INFO - Total fit_transform time: 4.39s
2024-12-29 13:29:52,549 - INFO - Training set processing completed in 4.39s
2024-12-29 13:29:52,549 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:29:52,551 - INFO - Memory usage at start_fit: CPU 2708.0 MB, GPU 104.6 MB
2024-12-29 13:29:52,551 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:29:52,735 - INFO - Fitted scaler and transformed data
2024-12-29 13:29:52,736 - INFO - Scaling time: 0.18s
2024-12-29 13:29:52,743 - INFO - Number of unique classes: 10
2024-12-29 13:29:56,074 - INFO - Epoch 1/10, Train Loss: 2.1867, Val Loss: 2.3013
2024-12-29 13:29:59,454 - INFO - Epoch 2/10, Train Loss: 2.1853, Val Loss: 2.3000
2024-12-29 13:30:02,582 - INFO - Epoch 3/10, Train Loss: 2.1840, Val Loss: 2.2987
2024-12-29 13:30:05,556 - INFO - Epoch 4/10, Train Loss: 2.1826, Val Loss: 2.2973
2024-12-29 13:30:05,556 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:30:05,556 - INFO - Training completed in 13.01s
2024-12-29 13:30:05,556 - INFO - Final memory usage: CPU 2708.0 MB, GPU 126.5 MB
2024-12-29 13:30:05,557 - INFO - Model training completed in 13.01s
2024-12-29 13:30:05,738 - INFO - Prediction completed in 0.18s
2024-12-29 13:30:05,751 - INFO - Poison rate 0.0 completed in 17.59s
2024-12-29 13:30:05,752 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:30:05,754 - INFO - Total number of labels flipped: 94
2024-12-29 13:30:05,754 - INFO - Label flipping completed in 0.00s
2024-12-29 13:30:05,755 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:30:05,755 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:30:06,292 - INFO - Feature scaling completed in 0.54s
2024-12-29 13:30:06,292 - INFO - Starting feature selection (k=50)
2024-12-29 13:30:06,305 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:30:06,305 - INFO - Starting anomaly detection
2024-12-29 13:30:09,599 - INFO - Anomaly detection completed in 3.29s
2024-12-29 13:30:09,600 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:30:09,600 - INFO - Total fit_transform time: 3.85s
2024-12-29 13:30:09,600 - INFO - Training set processing completed in 3.85s
2024-12-29 13:30:09,600 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:30:09,601 - INFO - Memory usage at start_fit: CPU 2708.0 MB, GPU 106.7 MB
2024-12-29 13:30:09,601 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:30:09,796 - INFO - Fitted scaler and transformed data
2024-12-29 13:30:09,796 - INFO - Scaling time: 0.19s
2024-12-29 13:30:09,804 - INFO - Number of unique classes: 10
2024-12-29 13:30:12,990 - INFO - Epoch 1/10, Train Loss: 2.1866, Val Loss: 2.3013
2024-12-29 13:30:15,689 - INFO - Epoch 2/10, Train Loss: 2.1853, Val Loss: 2.3000
2024-12-29 13:30:18,370 - INFO - Epoch 3/10, Train Loss: 2.1839, Val Loss: 2.2987
2024-12-29 13:30:21,604 - INFO - Epoch 4/10, Train Loss: 2.1826, Val Loss: 2.2974
2024-12-29 13:30:21,604 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:30:21,605 - INFO - Training completed in 12.00s
2024-12-29 13:30:21,605 - INFO - Final memory usage: CPU 2708.0 MB, GPU 126.5 MB
2024-12-29 13:30:21,606 - INFO - Model training completed in 12.01s
2024-12-29 13:30:21,777 - INFO - Prediction completed in 0.17s
2024-12-29 13:30:21,786 - INFO - Poison rate 0.01 completed in 16.03s
2024-12-29 13:30:21,786 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:30:21,790 - INFO - Total number of labels flipped: 284
2024-12-29 13:30:21,790 - INFO - Label flipping completed in 0.00s
2024-12-29 13:30:21,790 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:30:21,790 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:30:22,352 - INFO - Feature scaling completed in 0.56s
2024-12-29 13:30:22,353 - INFO - Starting feature selection (k=50)
2024-12-29 13:30:22,369 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 13:30:22,369 - INFO - Starting anomaly detection
2024-12-29 13:30:26,179 - INFO - Anomaly detection completed in 3.81s
2024-12-29 13:30:26,179 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:30:26,180 - INFO - Total fit_transform time: 4.39s
2024-12-29 13:30:26,180 - INFO - Training set processing completed in 4.39s
2024-12-29 13:30:26,180 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:30:26,181 - INFO - Memory usage at start_fit: CPU 2708.0 MB, GPU 106.7 MB
2024-12-29 13:30:26,181 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:30:26,359 - INFO - Fitted scaler and transformed data
2024-12-29 13:30:26,360 - INFO - Scaling time: 0.18s
2024-12-29 13:30:26,369 - INFO - Number of unique classes: 10
2024-12-29 13:30:29,575 - INFO - Epoch 1/10, Train Loss: 2.1865, Val Loss: 2.3014
2024-12-29 13:30:32,094 - INFO - Epoch 2/10, Train Loss: 2.1852, Val Loss: 2.3002
2024-12-29 13:30:34,477 - INFO - Epoch 3/10, Train Loss: 2.1839, Val Loss: 2.2989
2024-12-29 13:30:36,972 - INFO - Epoch 4/10, Train Loss: 2.1826, Val Loss: 2.2977
2024-12-29 13:30:36,973 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:30:36,973 - INFO - Training completed in 10.79s
2024-12-29 13:30:36,973 - INFO - Final memory usage: CPU 2708.0 MB, GPU 126.5 MB
2024-12-29 13:30:36,973 - INFO - Model training completed in 10.79s
2024-12-29 13:30:37,118 - INFO - Prediction completed in 0.14s
2024-12-29 13:30:37,127 - INFO - Poison rate 0.03 completed in 15.34s
2024-12-29 13:30:37,127 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:30:37,134 - INFO - Total number of labels flipped: 473
2024-12-29 13:30:37,134 - INFO - Label flipping completed in 0.01s
2024-12-29 13:30:37,134 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:30:37,134 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:30:37,668 - INFO - Feature scaling completed in 0.53s
2024-12-29 13:30:37,668 - INFO - Starting feature selection (k=50)
2024-12-29 13:30:37,681 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:30:37,681 - INFO - Starting anomaly detection
2024-12-29 13:30:41,940 - INFO - Anomaly detection completed in 4.26s
2024-12-29 13:30:41,940 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:30:41,940 - INFO - Total fit_transform time: 4.81s
2024-12-29 13:30:41,940 - INFO - Training set processing completed in 4.81s
2024-12-29 13:30:41,940 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:30:41,941 - INFO - Memory usage at start_fit: CPU 2708.0 MB, GPU 106.7 MB
2024-12-29 13:30:41,941 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:30:42,141 - INFO - Fitted scaler and transformed data
2024-12-29 13:30:42,142 - INFO - Scaling time: 0.20s
2024-12-29 13:30:42,154 - INFO - Number of unique classes: 10
2024-12-29 13:30:44,964 - INFO - Epoch 1/10, Train Loss: 2.1857, Val Loss: 2.3014
2024-12-29 13:30:47,227 - INFO - Epoch 2/10, Train Loss: 2.1845, Val Loss: 2.3003
2024-12-29 13:30:50,397 - INFO - Epoch 3/10, Train Loss: 2.1833, Val Loss: 2.2991
2024-12-29 13:30:53,620 - INFO - Epoch 4/10, Train Loss: 2.1820, Val Loss: 2.2979
2024-12-29 13:30:53,620 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:30:53,620 - INFO - Training completed in 11.68s
2024-12-29 13:30:53,621 - INFO - Final memory usage: CPU 2708.0 MB, GPU 126.5 MB
2024-12-29 13:30:53,621 - INFO - Model training completed in 11.68s
2024-12-29 13:30:53,764 - INFO - Prediction completed in 0.14s
2024-12-29 13:30:53,773 - INFO - Poison rate 0.05 completed in 16.65s
2024-12-29 13:30:53,773 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:30:53,781 - INFO - Total number of labels flipped: 662
2024-12-29 13:30:53,781 - INFO - Label flipping completed in 0.01s
2024-12-29 13:30:53,781 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:30:53,781 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:30:54,311 - INFO - Feature scaling completed in 0.53s
2024-12-29 13:30:54,311 - INFO - Starting feature selection (k=50)
2024-12-29 13:30:54,324 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:30:54,324 - INFO - Starting anomaly detection
2024-12-29 13:30:57,294 - INFO - Anomaly detection completed in 2.97s
2024-12-29 13:30:57,294 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:30:57,294 - INFO - Total fit_transform time: 3.51s
2024-12-29 13:30:57,294 - INFO - Training set processing completed in 3.51s
2024-12-29 13:30:57,294 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:30:57,296 - INFO - Memory usage at start_fit: CPU 2708.0 MB, GPU 106.7 MB
2024-12-29 13:30:57,296 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:30:57,489 - INFO - Fitted scaler and transformed data
2024-12-29 13:30:57,490 - INFO - Scaling time: 0.19s
2024-12-29 13:30:57,501 - INFO - Number of unique classes: 10
2024-12-29 13:31:00,433 - INFO - Epoch 1/10, Train Loss: 2.1880, Val Loss: 2.3015
2024-12-29 13:31:02,958 - INFO - Epoch 2/10, Train Loss: 2.1868, Val Loss: 2.3004
2024-12-29 13:31:06,069 - INFO - Epoch 3/10, Train Loss: 2.1856, Val Loss: 2.2992
2024-12-29 13:31:08,657 - INFO - Epoch 4/10, Train Loss: 2.1844, Val Loss: 2.2981
2024-12-29 13:31:08,658 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:31:08,658 - INFO - Training completed in 11.36s
2024-12-29 13:31:08,658 - INFO - Final memory usage: CPU 2709.8 MB, GPU 126.5 MB
2024-12-29 13:31:08,658 - INFO - Model training completed in 11.36s
2024-12-29 13:31:08,804 - INFO - Prediction completed in 0.15s
2024-12-29 13:31:08,813 - INFO - Poison rate 0.07 completed in 15.04s
2024-12-29 13:31:08,813 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:31:08,825 - INFO - Total number of labels flipped: 946
2024-12-29 13:31:08,825 - INFO - Label flipping completed in 0.01s
2024-12-29 13:31:08,826 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:31:08,826 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:31:09,373 - INFO - Feature scaling completed in 0.55s
2024-12-29 13:31:09,373 - INFO - Starting feature selection (k=50)
2024-12-29 13:31:09,386 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:31:09,386 - INFO - Starting anomaly detection
2024-12-29 13:31:12,252 - INFO - Anomaly detection completed in 2.87s
2024-12-29 13:31:12,252 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:31:12,252 - INFO - Total fit_transform time: 3.43s
2024-12-29 13:31:12,252 - INFO - Training set processing completed in 3.43s
2024-12-29 13:31:12,252 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:31:12,253 - INFO - Memory usage at start_fit: CPU 2709.8 MB, GPU 106.7 MB
2024-12-29 13:31:12,253 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:31:12,426 - INFO - Fitted scaler and transformed data
2024-12-29 13:31:12,426 - INFO - Scaling time: 0.17s
2024-12-29 13:31:12,433 - INFO - Number of unique classes: 10
2024-12-29 13:31:15,488 - INFO - Epoch 1/10, Train Loss: 2.1882, Val Loss: 2.3015
2024-12-29 13:31:18,786 - INFO - Epoch 2/10, Train Loss: 2.1870, Val Loss: 2.3004
2024-12-29 13:31:21,867 - INFO - Epoch 3/10, Train Loss: 2.1859, Val Loss: 2.2993
2024-12-29 13:31:24,558 - INFO - Epoch 4/10, Train Loss: 2.1847, Val Loss: 2.2982
2024-12-29 13:31:24,559 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:31:24,559 - INFO - Training completed in 12.31s
2024-12-29 13:31:24,559 - INFO - Final memory usage: CPU 2709.8 MB, GPU 126.5 MB
2024-12-29 13:31:24,559 - INFO - Model training completed in 12.31s
2024-12-29 13:31:24,755 - INFO - Prediction completed in 0.20s
2024-12-29 13:31:24,764 - INFO - Poison rate 0.1 completed in 15.95s
2024-12-29 13:31:24,764 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:31:24,786 - INFO - Total number of labels flipped: 1893
2024-12-29 13:31:24,786 - INFO - Label flipping completed in 0.02s
2024-12-29 13:31:24,786 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:31:24,786 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:31:25,295 - INFO - Feature scaling completed in 0.51s
2024-12-29 13:31:25,295 - INFO - Starting feature selection (k=50)
2024-12-29 13:31:25,308 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:31:25,308 - INFO - Starting anomaly detection
2024-12-29 13:31:28,508 - INFO - Anomaly detection completed in 3.20s
2024-12-29 13:31:28,509 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:31:28,509 - INFO - Total fit_transform time: 3.72s
2024-12-29 13:31:28,509 - INFO - Training set processing completed in 3.72s
2024-12-29 13:31:28,509 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:31:28,510 - INFO - Memory usage at start_fit: CPU 2709.8 MB, GPU 106.7 MB
2024-12-29 13:31:28,510 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:31:28,711 - INFO - Fitted scaler and transformed data
2024-12-29 13:31:28,711 - INFO - Scaling time: 0.20s
2024-12-29 13:31:28,717 - INFO - Number of unique classes: 10
2024-12-29 13:31:31,449 - INFO - Epoch 1/10, Train Loss: 2.1851, Val Loss: 2.3017
2024-12-29 13:31:34,072 - INFO - Epoch 2/10, Train Loss: 2.1842, Val Loss: 2.3008
2024-12-29 13:31:37,068 - INFO - Epoch 3/10, Train Loss: 2.1832, Val Loss: 2.2998
2024-12-29 13:31:39,526 - INFO - Epoch 4/10, Train Loss: 2.1823, Val Loss: 2.2989
2024-12-29 13:31:39,526 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:31:39,526 - INFO - Training completed in 11.02s
2024-12-29 13:31:39,527 - INFO - Final memory usage: CPU 2709.8 MB, GPU 126.5 MB
2024-12-29 13:31:39,527 - INFO - Model training completed in 11.02s
2024-12-29 13:31:39,726 - INFO - Prediction completed in 0.20s
2024-12-29 13:31:39,734 - INFO - Poison rate 0.2 completed in 14.97s
2024-12-29 13:31:39,738 - INFO - Loaded 203 existing results
2024-12-29 13:31:39,739 - INFO - Total results to save: 210
2024-12-29 13:31:39,739 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:31:39,747 - INFO - Saved 210 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:31:39,747 - INFO - Total evaluation time: 143.18s
2024-12-29 13:31:39,748 - INFO - 
Progress: 32.3% - Evaluating GTSRB with KNeighbors (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:31:39,930 - INFO - Loading datasets...
2024-12-29 13:31:39,950 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:31:39,950 - INFO - Extracting validation features...
2024-12-29 13:31:39,950 - INFO - Extracting features from 3925 samples...
2024-12-29 13:31:49,317 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:31:49,321 - INFO - Validation feature extraction completed in 9.37s
2024-12-29 13:31:49,321 - INFO - Extracting training features...
2024-12-29 13:31:49,321 - INFO - Extracting features from 9469 samples...
2024-12-29 13:32:11,203 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:32:11,211 - INFO - Training feature extraction completed in 21.89s
2024-12-29 13:32:11,212 - INFO - Creating model for classifier: KNeighbors
2024-12-29 13:32:11,212 - INFO - Using device: cuda
2024-12-29 13:32:11,212 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:32:11,213 - INFO - Training set processing completed in 0.00s
2024-12-29 13:32:11,213 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:32:11,214 - INFO - Memory usage at start_fit: CPU 2680.5 MB, GPU 104.0 MB
2024-12-29 13:32:11,215 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:32:11,387 - INFO - Fitted scaler and transformed data
2024-12-29 13:32:11,387 - INFO - Scaling time: 0.17s
2024-12-29 13:32:11,394 - INFO - Training completed in 0.18s
2024-12-29 13:32:11,394 - INFO - Final memory usage: CPU 2708.2 MB, GPU 122.6 MB
2024-12-29 13:32:11,395 - INFO - Model training completed in 0.18s
2024-12-29 13:32:11,465 - INFO - Prediction completed in 0.07s
2024-12-29 13:32:11,474 - INFO - Poison rate 0.0 completed in 0.26s
2024-12-29 13:32:11,475 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:32:11,477 - INFO - Total number of labels flipped: 94
2024-12-29 13:32:11,477 - INFO - Label flipping completed in 0.00s
2024-12-29 13:32:11,477 - INFO - Training set processing completed in 0.00s
2024-12-29 13:32:11,477 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:32:11,478 - INFO - Memory usage at start_fit: CPU 2708.4 MB, GPU 122.6 MB
2024-12-29 13:32:11,478 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:32:11,662 - INFO - Fitted scaler and transformed data
2024-12-29 13:32:11,662 - INFO - Scaling time: 0.18s
2024-12-29 13:32:11,670 - INFO - Training completed in 0.19s
2024-12-29 13:32:11,671 - INFO - Final memory usage: CPU 2710.6 MB, GPU 122.6 MB
2024-12-29 13:32:11,671 - INFO - Model training completed in 0.19s
2024-12-29 13:32:11,756 - INFO - Prediction completed in 0.08s
2024-12-29 13:32:11,764 - INFO - Poison rate 0.01 completed in 0.29s
2024-12-29 13:32:11,764 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:32:11,768 - INFO - Total number of labels flipped: 284
2024-12-29 13:32:11,769 - INFO - Label flipping completed in 0.00s
2024-12-29 13:32:11,769 - INFO - Training set processing completed in 0.00s
2024-12-29 13:32:11,769 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:32:11,769 - INFO - Memory usage at start_fit: CPU 2710.6 MB, GPU 122.6 MB
2024-12-29 13:32:11,770 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:32:11,937 - INFO - Fitted scaler and transformed data
2024-12-29 13:32:11,938 - INFO - Scaling time: 0.17s
2024-12-29 13:32:11,944 - INFO - Training completed in 0.17s
2024-12-29 13:32:11,944 - INFO - Final memory usage: CPU 2710.6 MB, GPU 122.6 MB
2024-12-29 13:32:11,944 - INFO - Model training completed in 0.18s
2024-12-29 13:32:12,016 - INFO - Prediction completed in 0.07s
2024-12-29 13:32:12,024 - INFO - Poison rate 0.03 completed in 0.26s
2024-12-29 13:32:12,024 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:32:12,030 - INFO - Total number of labels flipped: 473
2024-12-29 13:32:12,031 - INFO - Label flipping completed in 0.01s
2024-12-29 13:32:12,031 - INFO - Training set processing completed in 0.00s
2024-12-29 13:32:12,031 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:32:12,031 - INFO - Memory usage at start_fit: CPU 2710.6 MB, GPU 122.6 MB
2024-12-29 13:32:12,032 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:32:12,200 - INFO - Fitted scaler and transformed data
2024-12-29 13:32:12,200 - INFO - Scaling time: 0.17s
2024-12-29 13:32:12,206 - INFO - Training completed in 0.17s
2024-12-29 13:32:12,206 - INFO - Final memory usage: CPU 2710.6 MB, GPU 122.6 MB
2024-12-29 13:32:12,207 - INFO - Model training completed in 0.18s
2024-12-29 13:32:12,278 - INFO - Prediction completed in 0.07s
2024-12-29 13:32:12,287 - INFO - Poison rate 0.05 completed in 0.26s
2024-12-29 13:32:12,287 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:32:12,295 - INFO - Total number of labels flipped: 662
2024-12-29 13:32:12,295 - INFO - Label flipping completed in 0.01s
2024-12-29 13:32:12,295 - INFO - Training set processing completed in 0.00s
2024-12-29 13:32:12,295 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:32:12,296 - INFO - Memory usage at start_fit: CPU 2710.6 MB, GPU 122.6 MB
2024-12-29 13:32:12,296 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:32:12,465 - INFO - Fitted scaler and transformed data
2024-12-29 13:32:12,466 - INFO - Scaling time: 0.17s
2024-12-29 13:32:12,473 - INFO - Training completed in 0.18s
2024-12-29 13:32:12,474 - INFO - Final memory usage: CPU 2718.1 MB, GPU 122.6 MB
2024-12-29 13:32:12,474 - INFO - Model training completed in 0.18s
2024-12-29 13:32:12,570 - INFO - Prediction completed in 0.10s
2024-12-29 13:32:12,578 - INFO - Poison rate 0.07 completed in 0.29s
2024-12-29 13:32:12,579 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:32:12,590 - INFO - Total number of labels flipped: 946
2024-12-29 13:32:12,590 - INFO - Label flipping completed in 0.01s
2024-12-29 13:32:12,590 - INFO - Training set processing completed in 0.00s
2024-12-29 13:32:12,590 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:32:12,591 - INFO - Memory usage at start_fit: CPU 2718.1 MB, GPU 122.6 MB
2024-12-29 13:32:12,591 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:32:12,761 - INFO - Fitted scaler and transformed data
2024-12-29 13:32:12,761 - INFO - Scaling time: 0.17s
2024-12-29 13:32:12,767 - INFO - Training completed in 0.18s
2024-12-29 13:32:12,768 - INFO - Final memory usage: CPU 2718.1 MB, GPU 122.6 MB
2024-12-29 13:32:12,768 - INFO - Model training completed in 0.18s
2024-12-29 13:32:12,842 - INFO - Prediction completed in 0.07s
2024-12-29 13:32:12,852 - INFO - Poison rate 0.1 completed in 0.27s
2024-12-29 13:32:12,852 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:32:12,873 - INFO - Total number of labels flipped: 1893
2024-12-29 13:32:12,873 - INFO - Label flipping completed in 0.02s
2024-12-29 13:32:12,873 - INFO - Training set processing completed in 0.00s
2024-12-29 13:32:12,873 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:32:12,874 - INFO - Memory usage at start_fit: CPU 2680.5 MB, GPU 122.6 MB
2024-12-29 13:32:12,874 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:32:13,065 - INFO - Fitted scaler and transformed data
2024-12-29 13:32:13,065 - INFO - Scaling time: 0.19s
2024-12-29 13:32:13,072 - INFO - Training completed in 0.20s
2024-12-29 13:32:13,072 - INFO - Final memory usage: CPU 2708.1 MB, GPU 122.6 MB
2024-12-29 13:32:13,073 - INFO - Model training completed in 0.20s
2024-12-29 13:32:13,147 - INFO - Prediction completed in 0.07s
2024-12-29 13:32:13,155 - INFO - Poison rate 0.2 completed in 0.30s
2024-12-29 13:32:13,160 - INFO - Loaded 210 existing results
2024-12-29 13:32:13,160 - INFO - Total results to save: 217
2024-12-29 13:32:13,161 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:32:13,170 - INFO - Saved 217 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:32:13,171 - INFO - Total evaluation time: 33.24s
2024-12-29 13:32:13,173 - INFO - 
Progress: 33.3% - Evaluating GTSRB with KNeighbors (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:32:13,357 - INFO - Loading datasets...
2024-12-29 13:32:13,378 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:32:13,378 - INFO - Extracting validation features...
2024-12-29 13:32:13,378 - INFO - Extracting features from 3925 samples...
2024-12-29 13:32:22,985 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:32:22,991 - INFO - Validation feature extraction completed in 9.61s
2024-12-29 13:32:22,991 - INFO - Extracting training features...
2024-12-29 13:32:22,991 - INFO - Extracting features from 9469 samples...
2024-12-29 13:32:45,046 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:32:45,055 - INFO - Training feature extraction completed in 22.06s
2024-12-29 13:32:45,056 - INFO - Creating model for classifier: KNeighbors
2024-12-29 13:32:45,056 - INFO - Using device: cuda
2024-12-29 13:32:45,056 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:32:45,056 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:32:45,056 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:32:45,656 - INFO - Feature scaling completed in 0.60s
2024-12-29 13:32:45,656 - INFO - Starting feature selection (k=50)
2024-12-29 13:32:45,667 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:32:45,667 - INFO - Starting anomaly detection
2024-12-29 13:32:49,130 - INFO - Anomaly detection completed in 3.46s
2024-12-29 13:32:49,131 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:32:49,131 - INFO - Total fit_transform time: 4.07s
2024-12-29 13:32:49,131 - INFO - Training set processing completed in 4.07s
2024-12-29 13:32:49,131 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:32:49,132 - INFO - Memory usage at start_fit: CPU 2708.5 MB, GPU 104.6 MB
2024-12-29 13:32:49,132 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:32:49,322 - INFO - Fitted scaler and transformed data
2024-12-29 13:32:49,322 - INFO - Scaling time: 0.19s
2024-12-29 13:32:49,329 - INFO - Training completed in 0.20s
2024-12-29 13:32:49,330 - INFO - Final memory usage: CPU 2708.5 MB, GPU 123.2 MB
2024-12-29 13:32:49,330 - INFO - Model training completed in 0.20s
2024-12-29 13:32:49,439 - INFO - Prediction completed in 0.11s
2024-12-29 13:32:49,448 - INFO - Poison rate 0.0 completed in 4.39s
2024-12-29 13:32:49,448 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:32:49,450 - INFO - Total number of labels flipped: 94
2024-12-29 13:32:49,450 - INFO - Label flipping completed in 0.00s
2024-12-29 13:32:49,450 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:32:49,450 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:32:50,087 - INFO - Feature scaling completed in 0.64s
2024-12-29 13:32:50,087 - INFO - Starting feature selection (k=50)
2024-12-29 13:32:50,098 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:32:50,098 - INFO - Starting anomaly detection
2024-12-29 13:32:53,732 - INFO - Anomaly detection completed in 3.63s
2024-12-29 13:32:53,732 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:32:53,732 - INFO - Total fit_transform time: 4.28s
2024-12-29 13:32:53,732 - INFO - Training set processing completed in 4.28s
2024-12-29 13:32:53,732 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:32:53,734 - INFO - Memory usage at start_fit: CPU 2710.5 MB, GPU 123.2 MB
2024-12-29 13:32:53,734 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:32:53,927 - INFO - Fitted scaler and transformed data
2024-12-29 13:32:53,927 - INFO - Scaling time: 0.19s
2024-12-29 13:32:53,936 - INFO - Training completed in 0.20s
2024-12-29 13:32:53,937 - INFO - Final memory usage: CPU 2710.5 MB, GPU 123.2 MB
2024-12-29 13:32:53,937 - INFO - Model training completed in 0.20s
2024-12-29 13:32:54,038 - INFO - Prediction completed in 0.10s
2024-12-29 13:32:54,047 - INFO - Poison rate 0.01 completed in 4.60s
2024-12-29 13:32:54,048 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:32:54,051 - INFO - Total number of labels flipped: 284
2024-12-29 13:32:54,052 - INFO - Label flipping completed in 0.00s
2024-12-29 13:32:54,052 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:32:54,052 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:32:54,684 - INFO - Feature scaling completed in 0.63s
2024-12-29 13:32:54,684 - INFO - Starting feature selection (k=50)
2024-12-29 13:32:54,696 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:32:54,696 - INFO - Starting anomaly detection
2024-12-29 13:32:58,021 - INFO - Anomaly detection completed in 3.32s
2024-12-29 13:32:58,021 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:32:58,021 - INFO - Total fit_transform time: 3.97s
2024-12-29 13:32:58,021 - INFO - Training set processing completed in 3.97s
2024-12-29 13:32:58,021 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:32:58,022 - INFO - Memory usage at start_fit: CPU 2710.5 MB, GPU 123.2 MB
2024-12-29 13:32:58,023 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:32:58,208 - INFO - Fitted scaler and transformed data
2024-12-29 13:32:58,208 - INFO - Scaling time: 0.19s
2024-12-29 13:32:58,215 - INFO - Training completed in 0.19s
2024-12-29 13:32:58,217 - INFO - Final memory usage: CPU 2710.5 MB, GPU 123.2 MB
2024-12-29 13:32:58,217 - INFO - Model training completed in 0.20s
2024-12-29 13:32:58,316 - INFO - Prediction completed in 0.10s
2024-12-29 13:32:58,324 - INFO - Poison rate 0.03 completed in 4.28s
2024-12-29 13:32:58,324 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:32:58,330 - INFO - Total number of labels flipped: 473
2024-12-29 13:32:58,331 - INFO - Label flipping completed in 0.01s
2024-12-29 13:32:58,331 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:32:58,331 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:32:58,871 - INFO - Feature scaling completed in 0.54s
2024-12-29 13:32:58,871 - INFO - Starting feature selection (k=50)
2024-12-29 13:32:58,880 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:32:58,880 - INFO - Starting anomaly detection
2024-12-29 13:33:02,743 - INFO - Anomaly detection completed in 3.86s
2024-12-29 13:33:02,744 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:33:02,744 - INFO - Total fit_transform time: 4.41s
2024-12-29 13:33:02,744 - INFO - Training set processing completed in 4.41s
2024-12-29 13:33:02,744 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:33:02,745 - INFO - Memory usage at start_fit: CPU 2710.5 MB, GPU 123.2 MB
2024-12-29 13:33:02,745 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:33:02,920 - INFO - Fitted scaler and transformed data
2024-12-29 13:33:02,920 - INFO - Scaling time: 0.17s
2024-12-29 13:33:02,928 - INFO - Training completed in 0.18s
2024-12-29 13:33:02,929 - INFO - Final memory usage: CPU 2710.5 MB, GPU 123.2 MB
2024-12-29 13:33:02,930 - INFO - Model training completed in 0.19s
2024-12-29 13:33:03,050 - INFO - Prediction completed in 0.12s
2024-12-29 13:33:03,058 - INFO - Poison rate 0.05 completed in 4.73s
2024-12-29 13:33:03,059 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:33:03,067 - INFO - Total number of labels flipped: 662
2024-12-29 13:33:03,067 - INFO - Label flipping completed in 0.01s
2024-12-29 13:33:03,067 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:33:03,067 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:33:03,635 - INFO - Feature scaling completed in 0.57s
2024-12-29 13:33:03,636 - INFO - Starting feature selection (k=50)
2024-12-29 13:33:03,647 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:33:03,647 - INFO - Starting anomaly detection
2024-12-29 13:33:07,549 - INFO - Anomaly detection completed in 3.90s
2024-12-29 13:33:07,550 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:33:07,550 - INFO - Total fit_transform time: 4.48s
2024-12-29 13:33:07,550 - INFO - Training set processing completed in 4.48s
2024-12-29 13:33:07,550 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:33:07,551 - INFO - Memory usage at start_fit: CPU 2710.5 MB, GPU 123.2 MB
2024-12-29 13:33:07,552 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:33:07,753 - INFO - Fitted scaler and transformed data
2024-12-29 13:33:07,753 - INFO - Scaling time: 0.20s
2024-12-29 13:33:07,759 - INFO - Training completed in 0.21s
2024-12-29 13:33:07,759 - INFO - Final memory usage: CPU 2710.5 MB, GPU 123.2 MB
2024-12-29 13:33:07,760 - INFO - Model training completed in 0.21s
2024-12-29 13:33:07,887 - INFO - Prediction completed in 0.13s
2024-12-29 13:33:07,895 - INFO - Poison rate 0.07 completed in 4.84s
2024-12-29 13:33:07,895 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:33:07,907 - INFO - Total number of labels flipped: 946
2024-12-29 13:33:07,907 - INFO - Label flipping completed in 0.01s
2024-12-29 13:33:07,907 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:33:07,907 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:33:08,507 - INFO - Feature scaling completed in 0.60s
2024-12-29 13:33:08,507 - INFO - Starting feature selection (k=50)
2024-12-29 13:33:08,516 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:33:08,516 - INFO - Starting anomaly detection
2024-12-29 13:33:11,155 - INFO - Anomaly detection completed in 2.64s
2024-12-29 13:33:11,155 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:33:11,155 - INFO - Total fit_transform time: 3.25s
2024-12-29 13:33:11,155 - INFO - Training set processing completed in 3.25s
2024-12-29 13:33:11,156 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:33:11,157 - INFO - Memory usage at start_fit: CPU 2710.5 MB, GPU 123.2 MB
2024-12-29 13:33:11,157 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:33:11,349 - INFO - Fitted scaler and transformed data
2024-12-29 13:33:11,350 - INFO - Scaling time: 0.19s
2024-12-29 13:33:11,357 - INFO - Training completed in 0.20s
2024-12-29 13:33:11,357 - INFO - Final memory usage: CPU 2710.5 MB, GPU 123.2 MB
2024-12-29 13:33:11,357 - INFO - Model training completed in 0.20s
2024-12-29 13:33:11,480 - INFO - Prediction completed in 0.12s
2024-12-29 13:33:11,489 - INFO - Poison rate 0.1 completed in 3.59s
2024-12-29 13:33:11,489 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:33:11,510 - INFO - Total number of labels flipped: 1893
2024-12-29 13:33:11,511 - INFO - Label flipping completed in 0.02s
2024-12-29 13:33:11,511 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:33:11,511 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:33:12,056 - INFO - Feature scaling completed in 0.55s
2024-12-29 13:33:12,056 - INFO - Starting feature selection (k=50)
2024-12-29 13:33:12,064 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:33:12,064 - INFO - Starting anomaly detection
2024-12-29 13:33:14,405 - INFO - Anomaly detection completed in 2.34s
2024-12-29 13:33:14,405 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:33:14,406 - INFO - Total fit_transform time: 2.89s
2024-12-29 13:33:14,406 - INFO - Training set processing completed in 2.90s
2024-12-29 13:33:14,406 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:33:14,407 - INFO - Memory usage at start_fit: CPU 2710.5 MB, GPU 123.2 MB
2024-12-29 13:33:14,407 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:33:14,588 - INFO - Fitted scaler and transformed data
2024-12-29 13:33:14,588 - INFO - Scaling time: 0.18s
2024-12-29 13:33:14,594 - INFO - Training completed in 0.19s
2024-12-29 13:33:14,595 - INFO - Final memory usage: CPU 2710.5 MB, GPU 123.2 MB
2024-12-29 13:33:14,595 - INFO - Model training completed in 0.19s
2024-12-29 13:33:14,690 - INFO - Prediction completed in 0.09s
2024-12-29 13:33:14,698 - INFO - Poison rate 0.2 completed in 3.21s
2024-12-29 13:33:14,703 - INFO - Loaded 217 existing results
2024-12-29 13:33:14,703 - INFO - Total results to save: 224
2024-12-29 13:33:14,704 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:33:14,711 - INFO - Saved 224 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:33:14,712 - INFO - Total evaluation time: 61.36s
2024-12-29 13:33:14,713 - INFO - Completed evaluation for GTSRB
2024-12-29 13:33:14,714 - INFO - 
Processing dataset: ImageNette
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:33:14,904 - INFO - 
Progress: 34.4% - Evaluating ImageNette with SVM (standard mode, iteration 1/1)
2024-12-29 13:33:15,075 - INFO - Loading datasets...
2024-12-29 13:33:15,096 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:33:15,096 - INFO - Extracting validation features...
2024-12-29 13:33:15,096 - INFO - Extracting features from 3925 samples...
2024-12-29 13:33:24,506 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:33:24,511 - INFO - Validation feature extraction completed in 9.41s
2024-12-29 13:33:24,512 - INFO - Extracting training features...
2024-12-29 13:33:24,512 - INFO - Extracting features from 9469 samples...
2024-12-29 13:33:46,314 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:33:46,322 - INFO - Training feature extraction completed in 21.81s
2024-12-29 13:33:46,323 - INFO - Creating model for classifier: SVM
2024-12-29 13:33:46,323 - INFO - Using device: cuda
2024-12-29 13:33:46,323 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-29 13:33:46,323 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:33:46,323 - INFO - Training set processing completed in 0.00s
2024-12-29 13:33:46,323 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:33:46,325 - INFO - Memory usage at start_fit: CPU 2680.7 MB, GPU 104.0 MB
2024-12-29 13:33:46,325 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:33:46,330 - INFO - Number of unique classes: 10
2024-12-29 13:33:46,409 - INFO - Fitted scaler and transformed data
2024-12-29 13:33:46,409 - INFO - Scaling time: 0.08s
2024-12-29 13:33:46,819 - INFO - Epoch 1/500, Train Loss: 0.7068, Val Loss: 0.1321
2024-12-29 13:33:47,164 - INFO - Epoch 2/500, Train Loss: 0.0914, Val Loss: 0.1030
2024-12-29 13:33:47,463 - INFO - Epoch 3/500, Train Loss: 0.0586, Val Loss: 0.0882
2024-12-29 13:33:47,809 - INFO - Epoch 4/500, Train Loss: 0.0415, Val Loss: 0.0819
2024-12-29 13:33:48,118 - INFO - Epoch 5/500, Train Loss: 0.0313, Val Loss: 0.0782
2024-12-29 13:33:48,464 - INFO - Epoch 6/500, Train Loss: 0.0251, Val Loss: 0.0793
2024-12-29 13:33:48,818 - INFO - Epoch 7/500, Train Loss: 0.0203, Val Loss: 0.0799
2024-12-29 13:33:49,170 - INFO - Epoch 8/500, Train Loss: 0.0170, Val Loss: 0.0776
2024-12-29 13:33:49,509 - INFO - Epoch 9/500, Train Loss: 0.0143, Val Loss: 0.0766
2024-12-29 13:33:49,829 - INFO - Epoch 10/500, Train Loss: 0.0120, Val Loss: 0.0775
2024-12-29 13:33:50,202 - INFO - Epoch 11/500, Train Loss: 0.0102, Val Loss: 0.0789
2024-12-29 13:33:50,580 - INFO - Epoch 12/500, Train Loss: 0.0085, Val Loss: 0.0800
2024-12-29 13:33:50,934 - INFO - Epoch 13/500, Train Loss: 0.0075, Val Loss: 0.0759
2024-12-29 13:33:51,308 - INFO - Epoch 14/500, Train Loss: 0.0070, Val Loss: 0.0792
2024-12-29 13:33:51,308 - INFO - Early stopping triggered at epoch 14
2024-12-29 13:33:51,308 - INFO - Training completed in 4.98s
2024-12-29 13:33:51,308 - INFO - Final memory usage: CPU 2717.5 MB, GPU 104.2 MB
2024-12-29 13:33:51,309 - INFO - Model training completed in 4.99s
2024-12-29 13:33:51,373 - INFO - Prediction completed in 0.06s
2024-12-29 13:33:51,382 - INFO - Poison rate 0.0 completed in 5.06s
2024-12-29 13:33:51,382 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:33:51,384 - INFO - Total number of labels flipped: 94
2024-12-29 13:33:51,384 - INFO - Label flipping completed in 0.00s
2024-12-29 13:33:51,384 - INFO - Training set processing completed in 0.00s
2024-12-29 13:33:51,384 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:33:51,385 - INFO - Memory usage at start_fit: CPU 2692.0 MB, GPU 104.1 MB
2024-12-29 13:33:51,386 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:33:51,390 - INFO - Number of unique classes: 10
2024-12-29 13:33:51,465 - INFO - Fitted scaler and transformed data
2024-12-29 13:33:51,465 - INFO - Scaling time: 0.07s
2024-12-29 13:33:51,836 - INFO - Epoch 1/500, Train Loss: 1.0120, Val Loss: 0.2970
2024-12-29 13:33:52,167 - INFO - Epoch 2/500, Train Loss: 0.2350, Val Loss: 0.2760
2024-12-29 13:33:52,523 - INFO - Epoch 3/500, Train Loss: 0.1800, Val Loss: 0.2629
2024-12-29 13:33:52,879 - INFO - Epoch 4/500, Train Loss: 0.1469, Val Loss: 0.2580
2024-12-29 13:33:53,212 - INFO - Epoch 5/500, Train Loss: 0.1211, Val Loss: 0.2535
2024-12-29 13:33:53,555 - INFO - Epoch 6/500, Train Loss: 0.1039, Val Loss: 0.2548
2024-12-29 13:33:53,962 - INFO - Epoch 7/500, Train Loss: 0.0921, Val Loss: 0.2562
2024-12-29 13:33:54,302 - INFO - Epoch 8/500, Train Loss: 0.0836, Val Loss: 0.2528
2024-12-29 13:33:54,675 - INFO - Epoch 9/500, Train Loss: 0.0764, Val Loss: 0.2569
2024-12-29 13:33:54,996 - INFO - Epoch 10/500, Train Loss: 0.0694, Val Loss: 0.2533
2024-12-29 13:33:54,997 - INFO - Early stopping triggered at epoch 10
2024-12-29 13:33:54,997 - INFO - Training completed in 3.61s
2024-12-29 13:33:54,997 - INFO - Final memory usage: CPU 2717.6 MB, GPU 104.2 MB
2024-12-29 13:33:54,998 - INFO - Model training completed in 3.61s
2024-12-29 13:33:55,045 - INFO - Prediction completed in 0.05s
2024-12-29 13:33:55,053 - INFO - Poison rate 0.01 completed in 3.67s
2024-12-29 13:33:55,054 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:33:55,057 - INFO - Total number of labels flipped: 284
2024-12-29 13:33:55,058 - INFO - Label flipping completed in 0.00s
2024-12-29 13:33:55,058 - INFO - Training set processing completed in 0.00s
2024-12-29 13:33:55,058 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:33:55,059 - INFO - Memory usage at start_fit: CPU 2691.8 MB, GPU 104.1 MB
2024-12-29 13:33:55,059 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:33:55,062 - INFO - Number of unique classes: 10
2024-12-29 13:33:55,144 - INFO - Fitted scaler and transformed data
2024-12-29 13:33:55,145 - INFO - Scaling time: 0.08s
2024-12-29 13:33:55,532 - INFO - Epoch 1/500, Train Loss: 1.1485, Val Loss: 0.4899
2024-12-29 13:33:55,953 - INFO - Epoch 2/500, Train Loss: 0.4486, Val Loss: 0.4665
2024-12-29 13:33:56,314 - INFO - Epoch 3/500, Train Loss: 0.3745, Val Loss: 0.4607
2024-12-29 13:33:56,635 - INFO - Epoch 4/500, Train Loss: 0.3296, Val Loss: 0.4561
2024-12-29 13:33:56,962 - INFO - Epoch 5/500, Train Loss: 0.2881, Val Loss: 0.4524
2024-12-29 13:33:57,329 - INFO - Epoch 6/500, Train Loss: 0.2604, Val Loss: 0.4641
2024-12-29 13:33:57,684 - INFO - Epoch 7/500, Train Loss: 0.2418, Val Loss: 0.4719
2024-12-29 13:33:58,064 - INFO - Epoch 8/500, Train Loss: 0.2247, Val Loss: 0.4755
2024-12-29 13:33:58,440 - INFO - Epoch 9/500, Train Loss: 0.2067, Val Loss: 0.4743
2024-12-29 13:33:58,782 - INFO - Epoch 10/500, Train Loss: 0.1960, Val Loss: 0.4612
2024-12-29 13:33:58,782 - INFO - Early stopping triggered at epoch 10
2024-12-29 13:33:58,782 - INFO - Training completed in 3.72s
2024-12-29 13:33:58,783 - INFO - Final memory usage: CPU 2717.7 MB, GPU 104.2 MB
2024-12-29 13:33:58,784 - INFO - Model training completed in 3.73s
2024-12-29 13:33:58,844 - INFO - Prediction completed in 0.06s
2024-12-29 13:33:58,853 - INFO - Poison rate 0.03 completed in 3.80s
2024-12-29 13:33:58,853 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:33:58,859 - INFO - Total number of labels flipped: 473
2024-12-29 13:33:58,859 - INFO - Label flipping completed in 0.01s
2024-12-29 13:33:58,859 - INFO - Training set processing completed in 0.00s
2024-12-29 13:33:58,859 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:33:58,860 - INFO - Memory usage at start_fit: CPU 2691.9 MB, GPU 104.1 MB
2024-12-29 13:33:58,860 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:33:58,864 - INFO - Number of unique classes: 10
2024-12-29 13:33:58,938 - INFO - Fitted scaler and transformed data
2024-12-29 13:33:58,939 - INFO - Scaling time: 0.07s
2024-12-29 13:33:59,297 - INFO - Epoch 1/500, Train Loss: 1.3267, Val Loss: 0.6683
2024-12-29 13:33:59,632 - INFO - Epoch 2/500, Train Loss: 0.6789, Val Loss: 0.6498
2024-12-29 13:34:00,013 - INFO - Epoch 3/500, Train Loss: 0.5781, Val Loss: 0.6461
2024-12-29 13:34:00,357 - INFO - Epoch 4/500, Train Loss: 0.5100, Val Loss: 0.6527
2024-12-29 13:34:00,752 - INFO - Epoch 5/500, Train Loss: 0.4651, Val Loss: 0.6562
2024-12-29 13:34:01,049 - INFO - Epoch 6/500, Train Loss: 0.4260, Val Loss: 0.6591
2024-12-29 13:34:01,363 - INFO - Epoch 7/500, Train Loss: 0.3997, Val Loss: 0.6605
2024-12-29 13:34:01,678 - INFO - Epoch 8/500, Train Loss: 0.3763, Val Loss: 0.6715
2024-12-29 13:34:01,679 - INFO - Early stopping triggered at epoch 8
2024-12-29 13:34:01,679 - INFO - Training completed in 2.82s
2024-12-29 13:34:01,680 - INFO - Final memory usage: CPU 2717.7 MB, GPU 104.2 MB
2024-12-29 13:34:01,682 - INFO - Model training completed in 2.82s
2024-12-29 13:34:01,744 - INFO - Prediction completed in 0.06s
2024-12-29 13:34:01,752 - INFO - Poison rate 0.05 completed in 2.90s
2024-12-29 13:34:01,752 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:34:01,761 - INFO - Total number of labels flipped: 662
2024-12-29 13:34:01,761 - INFO - Label flipping completed in 0.01s
2024-12-29 13:34:01,761 - INFO - Training set processing completed in 0.00s
2024-12-29 13:34:01,761 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:34:01,762 - INFO - Memory usage at start_fit: CPU 2692.2 MB, GPU 104.1 MB
2024-12-29 13:34:01,762 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:34:01,765 - INFO - Number of unique classes: 10
2024-12-29 13:34:01,839 - INFO - Fitted scaler and transformed data
2024-12-29 13:34:01,840 - INFO - Scaling time: 0.07s
2024-12-29 13:34:02,193 - INFO - Epoch 1/500, Train Loss: 1.8034, Val Loss: 0.9705
2024-12-29 13:34:02,531 - INFO - Epoch 2/500, Train Loss: 0.9563, Val Loss: 0.9674
2024-12-29 13:34:02,868 - INFO - Epoch 3/500, Train Loss: 0.8275, Val Loss: 0.9849
2024-12-29 13:34:03,219 - INFO - Epoch 4/500, Train Loss: 0.7400, Val Loss: 0.9658
2024-12-29 13:34:03,561 - INFO - Epoch 5/500, Train Loss: 0.6768, Val Loss: 0.9859
2024-12-29 13:34:03,897 - INFO - Epoch 6/500, Train Loss: 0.6341, Val Loss: 1.0162
2024-12-29 13:34:04,287 - INFO - Epoch 7/500, Train Loss: 0.5873, Val Loss: 1.0030
2024-12-29 13:34:04,619 - INFO - Epoch 8/500, Train Loss: 0.5599, Val Loss: 1.0236
2024-12-29 13:34:04,947 - INFO - Epoch 9/500, Train Loss: 0.5372, Val Loss: 1.0370
2024-12-29 13:34:04,947 - INFO - Early stopping triggered at epoch 9
2024-12-29 13:34:04,948 - INFO - Training completed in 3.19s
2024-12-29 13:34:04,948 - INFO - Final memory usage: CPU 2717.8 MB, GPU 104.2 MB
2024-12-29 13:34:04,949 - INFO - Model training completed in 3.19s
2024-12-29 13:34:04,994 - INFO - Prediction completed in 0.04s
2024-12-29 13:34:05,002 - INFO - Poison rate 0.07 completed in 3.25s
2024-12-29 13:34:05,003 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:34:05,014 - INFO - Total number of labels flipped: 946
2024-12-29 13:34:05,014 - INFO - Label flipping completed in 0.01s
2024-12-29 13:34:05,014 - INFO - Training set processing completed in 0.00s
2024-12-29 13:34:05,014 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:34:05,015 - INFO - Memory usage at start_fit: CPU 2692.3 MB, GPU 104.1 MB
2024-12-29 13:34:05,015 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:34:05,018 - INFO - Number of unique classes: 10
2024-12-29 13:34:05,093 - INFO - Fitted scaler and transformed data
2024-12-29 13:34:05,093 - INFO - Scaling time: 0.07s
2024-12-29 13:34:05,447 - INFO - Epoch 1/500, Train Loss: 2.1035, Val Loss: 1.5437
2024-12-29 13:34:05,795 - INFO - Epoch 2/500, Train Loss: 1.2683, Val Loss: 1.4968
2024-12-29 13:34:06,118 - INFO - Epoch 3/500, Train Loss: 1.1255, Val Loss: 1.4846
2024-12-29 13:34:06,485 - INFO - Epoch 4/500, Train Loss: 1.0173, Val Loss: 1.4708
2024-12-29 13:34:06,815 - INFO - Epoch 5/500, Train Loss: 0.9408, Val Loss: 1.4929
2024-12-29 13:34:07,170 - INFO - Epoch 6/500, Train Loss: 0.8871, Val Loss: 1.4899
2024-12-29 13:34:07,506 - INFO - Epoch 7/500, Train Loss: 0.8466, Val Loss: 1.5076
2024-12-29 13:34:07,842 - INFO - Epoch 8/500, Train Loss: 0.8137, Val Loss: 1.5422
2024-12-29 13:34:08,189 - INFO - Epoch 9/500, Train Loss: 0.7771, Val Loss: 1.5405
2024-12-29 13:34:08,189 - INFO - Early stopping triggered at epoch 9
2024-12-29 13:34:08,189 - INFO - Training completed in 3.17s
2024-12-29 13:34:08,189 - INFO - Final memory usage: CPU 2717.6 MB, GPU 104.2 MB
2024-12-29 13:34:08,190 - INFO - Model training completed in 3.18s
2024-12-29 13:34:08,237 - INFO - Prediction completed in 0.05s
2024-12-29 13:34:08,246 - INFO - Poison rate 0.1 completed in 3.24s
2024-12-29 13:34:08,246 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:34:08,267 - INFO - Total number of labels flipped: 1893
2024-12-29 13:34:08,268 - INFO - Label flipping completed in 0.02s
2024-12-29 13:34:08,268 - INFO - Training set processing completed in 0.00s
2024-12-29 13:34:08,268 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:34:08,268 - INFO - Memory usage at start_fit: CPU 2692.3 MB, GPU 104.1 MB
2024-12-29 13:34:08,269 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:34:08,272 - INFO - Number of unique classes: 10
2024-12-29 13:34:08,350 - INFO - Fitted scaler and transformed data
2024-12-29 13:34:08,350 - INFO - Scaling time: 0.08s
2024-12-29 13:34:08,692 - INFO - Epoch 1/500, Train Loss: 3.0679, Val Loss: 2.4051
2024-12-29 13:34:09,070 - INFO - Epoch 2/500, Train Loss: 2.2833, Val Loss: 2.3317
2024-12-29 13:34:09,433 - INFO - Epoch 3/500, Train Loss: 2.0828, Val Loss: 2.3483
2024-12-29 13:34:09,772 - INFO - Epoch 4/500, Train Loss: 1.9410, Val Loss: 2.3480
2024-12-29 13:34:10,086 - INFO - Epoch 5/500, Train Loss: 1.8550, Val Loss: 2.3287
2024-12-29 13:34:10,544 - INFO - Epoch 6/500, Train Loss: 1.7793, Val Loss: 2.3764
2024-12-29 13:34:10,895 - INFO - Epoch 7/500, Train Loss: 1.7269, Val Loss: 2.3961
2024-12-29 13:34:11,257 - INFO - Epoch 8/500, Train Loss: 1.6862, Val Loss: 2.3990
2024-12-29 13:34:11,578 - INFO - Epoch 9/500, Train Loss: 1.6460, Val Loss: 2.3807
2024-12-29 13:34:11,939 - INFO - Epoch 10/500, Train Loss: 1.6137, Val Loss: 2.4330
2024-12-29 13:34:11,940 - INFO - Early stopping triggered at epoch 10
2024-12-29 13:34:11,940 - INFO - Training completed in 3.67s
2024-12-29 13:34:11,941 - INFO - Final memory usage: CPU 2718.2 MB, GPU 104.2 MB
2024-12-29 13:34:11,943 - INFO - Model training completed in 3.68s
2024-12-29 13:34:12,007 - INFO - Prediction completed in 0.06s
2024-12-29 13:34:12,015 - INFO - Poison rate 0.2 completed in 3.77s
2024-12-29 13:34:12,021 - INFO - Loaded 224 existing results
2024-12-29 13:34:12,021 - INFO - Total results to save: 231
2024-12-29 13:34:12,022 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:34:12,030 - INFO - Saved 231 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:34:12,030 - INFO - Total evaluation time: 56.96s
2024-12-29 13:34:12,032 - INFO - 
Progress: 35.4% - Evaluating ImageNette with SVM (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:34:12,218 - INFO - Loading datasets...
2024-12-29 13:34:12,239 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:34:12,239 - INFO - Extracting validation features...
2024-12-29 13:34:12,239 - INFO - Extracting features from 3925 samples...
2024-12-29 13:34:21,642 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:34:21,645 - INFO - Validation feature extraction completed in 9.41s
2024-12-29 13:34:21,646 - INFO - Extracting training features...
2024-12-29 13:34:21,646 - INFO - Extracting features from 9469 samples...
2024-12-29 13:34:43,960 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:34:43,967 - INFO - Training feature extraction completed in 22.32s
2024-12-29 13:34:43,967 - INFO - Creating model for classifier: SVM
2024-12-29 13:34:43,968 - INFO - Using device: cuda
2024-12-29 13:34:43,968 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-29 13:34:43,968 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:34:43,968 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:34:43,968 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:34:44,488 - INFO - Feature scaling completed in 0.52s
2024-12-29 13:34:44,488 - INFO - Starting feature selection (k=50)
2024-12-29 13:34:44,509 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 13:34:44,510 - INFO - Starting anomaly detection
2024-12-29 13:34:48,026 - INFO - Anomaly detection completed in 3.52s
2024-12-29 13:34:48,026 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:34:48,026 - INFO - Total fit_transform time: 4.06s
2024-12-29 13:34:48,026 - INFO - Training set processing completed in 4.06s
2024-12-29 13:34:48,026 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:34:48,028 - INFO - Memory usage at start_fit: CPU 2708.5 MB, GPU 103.4 MB
2024-12-29 13:34:48,028 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:34:48,031 - INFO - Number of unique classes: 10
2024-12-29 13:34:48,108 - INFO - Fitted scaler and transformed data
2024-12-29 13:34:48,108 - INFO - Scaling time: 0.08s
2024-12-29 13:34:48,449 - INFO - Epoch 1/500, Train Loss: 0.7427, Val Loss: 0.1315
2024-12-29 13:34:48,777 - INFO - Epoch 2/500, Train Loss: 0.0862, Val Loss: 0.0931
2024-12-29 13:34:49,135 - INFO - Epoch 3/500, Train Loss: 0.0560, Val Loss: 0.0816
2024-12-29 13:34:49,484 - INFO - Epoch 4/500, Train Loss: 0.0392, Val Loss: 0.0742
2024-12-29 13:34:49,913 - INFO - Epoch 5/500, Train Loss: 0.0298, Val Loss: 0.0707
2024-12-29 13:34:50,255 - INFO - Epoch 6/500, Train Loss: 0.0238, Val Loss: 0.0687
2024-12-29 13:34:50,563 - INFO - Epoch 7/500, Train Loss: 0.0192, Val Loss: 0.0661
2024-12-29 13:34:50,956 - INFO - Epoch 8/500, Train Loss: 0.0157, Val Loss: 0.0657
2024-12-29 13:34:51,274 - INFO - Epoch 9/500, Train Loss: 0.0132, Val Loss: 0.0650
2024-12-29 13:34:51,615 - INFO - Epoch 10/500, Train Loss: 0.0114, Val Loss: 0.0658
2024-12-29 13:34:51,987 - INFO - Epoch 11/500, Train Loss: 0.0098, Val Loss: 0.0642
2024-12-29 13:34:52,322 - INFO - Epoch 12/500, Train Loss: 0.0086, Val Loss: 0.0632
2024-12-29 13:34:52,676 - INFO - Epoch 13/500, Train Loss: 0.0073, Val Loss: 0.0651
2024-12-29 13:34:53,030 - INFO - Epoch 14/500, Train Loss: 0.0066, Val Loss: 0.0629
2024-12-29 13:34:53,362 - INFO - Epoch 15/500, Train Loss: 0.0063, Val Loss: 0.0643
2024-12-29 13:34:53,720 - INFO - Epoch 16/500, Train Loss: 0.0056, Val Loss: 0.0650
2024-12-29 13:34:54,039 - INFO - Epoch 17/500, Train Loss: 0.0049, Val Loss: 0.0625
2024-12-29 13:34:54,039 - INFO - Early stopping triggered at epoch 17
2024-12-29 13:34:54,039 - INFO - Training completed in 6.01s
2024-12-29 13:34:54,040 - INFO - Final memory usage: CPU 2717.8 MB, GPU 103.6 MB
2024-12-29 13:34:54,042 - INFO - Model training completed in 6.02s
2024-12-29 13:34:54,091 - INFO - Prediction completed in 0.05s
2024-12-29 13:34:54,115 - INFO - Poison rate 0.0 completed in 10.15s
2024-12-29 13:34:54,116 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:34:54,120 - INFO - Total number of labels flipped: 94
2024-12-29 13:34:54,120 - INFO - Label flipping completed in 0.00s
2024-12-29 13:34:54,120 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:34:54,120 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:34:54,738 - INFO - Feature scaling completed in 0.62s
2024-12-29 13:34:54,739 - INFO - Starting feature selection (k=50)
2024-12-29 13:34:54,754 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 13:34:54,754 - INFO - Starting anomaly detection
2024-12-29 13:34:58,930 - INFO - Anomaly detection completed in 4.18s
2024-12-29 13:34:58,930 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:34:58,931 - INFO - Total fit_transform time: 4.81s
2024-12-29 13:34:58,931 - INFO - Training set processing completed in 4.81s
2024-12-29 13:34:58,931 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:34:58,932 - INFO - Memory usage at start_fit: CPU 2708.7 MB, GPU 103.5 MB
2024-12-29 13:34:58,933 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:34:58,935 - INFO - Number of unique classes: 10
2024-12-29 13:34:59,024 - INFO - Fitted scaler and transformed data
2024-12-29 13:34:59,024 - INFO - Scaling time: 0.09s
2024-12-29 13:34:59,409 - INFO - Epoch 1/500, Train Loss: 0.9014, Val Loss: 0.2537
2024-12-29 13:34:59,788 - INFO - Epoch 2/500, Train Loss: 0.2056, Val Loss: 0.2238
2024-12-29 13:35:00,132 - INFO - Epoch 3/500, Train Loss: 0.1593, Val Loss: 0.2156
2024-12-29 13:35:00,471 - INFO - Epoch 4/500, Train Loss: 0.1275, Val Loss: 0.2160
2024-12-29 13:35:00,792 - INFO - Epoch 5/500, Train Loss: 0.1080, Val Loss: 0.2165
2024-12-29 13:35:01,157 - INFO - Epoch 6/500, Train Loss: 0.0919, Val Loss: 0.2163
2024-12-29 13:35:01,485 - INFO - Epoch 7/500, Train Loss: 0.0821, Val Loss: 0.2179
2024-12-29 13:35:01,787 - INFO - Epoch 8/500, Train Loss: 0.0749, Val Loss: 0.2159
2024-12-29 13:35:01,787 - INFO - Early stopping triggered at epoch 8
2024-12-29 13:35:01,788 - INFO - Training completed in 2.86s
2024-12-29 13:35:01,788 - INFO - Final memory usage: CPU 2718.0 MB, GPU 103.6 MB
2024-12-29 13:35:01,790 - INFO - Model training completed in 2.86s
2024-12-29 13:35:01,835 - INFO - Prediction completed in 0.05s
2024-12-29 13:35:01,844 - INFO - Poison rate 0.01 completed in 7.73s
2024-12-29 13:35:01,844 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:35:01,848 - INFO - Total number of labels flipped: 284
2024-12-29 13:35:01,848 - INFO - Label flipping completed in 0.00s
2024-12-29 13:35:01,848 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:35:01,848 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:35:02,378 - INFO - Feature scaling completed in 0.53s
2024-12-29 13:35:02,379 - INFO - Starting feature selection (k=50)
2024-12-29 13:35:02,394 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 13:35:02,394 - INFO - Starting anomaly detection
2024-12-29 13:35:05,932 - INFO - Anomaly detection completed in 3.54s
2024-12-29 13:35:05,933 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:35:05,933 - INFO - Total fit_transform time: 4.08s
2024-12-29 13:35:05,933 - INFO - Training set processing completed in 4.08s
2024-12-29 13:35:05,933 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:35:05,934 - INFO - Memory usage at start_fit: CPU 2708.8 MB, GPU 103.5 MB
2024-12-29 13:35:05,934 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:35:05,936 - INFO - Number of unique classes: 10
2024-12-29 13:35:06,009 - INFO - Fitted scaler and transformed data
2024-12-29 13:35:06,009 - INFO - Scaling time: 0.07s
2024-12-29 13:35:06,351 - INFO - Epoch 1/500, Train Loss: 1.2051, Val Loss: 0.5459
2024-12-29 13:35:06,681 - INFO - Epoch 2/500, Train Loss: 0.4349, Val Loss: 0.5427
2024-12-29 13:35:07,023 - INFO - Epoch 3/500, Train Loss: 0.3569, Val Loss: 0.5347
2024-12-29 13:35:07,354 - INFO - Epoch 4/500, Train Loss: 0.3087, Val Loss: 0.5403
2024-12-29 13:35:07,677 - INFO - Epoch 5/500, Train Loss: 0.2740, Val Loss: 0.5398
2024-12-29 13:35:07,992 - INFO - Epoch 6/500, Train Loss: 0.2446, Val Loss: 0.5447
2024-12-29 13:35:08,344 - INFO - Epoch 7/500, Train Loss: 0.2279, Val Loss: 0.5496
2024-12-29 13:35:08,679 - INFO - Epoch 8/500, Train Loss: 0.2119, Val Loss: 0.5429
2024-12-29 13:35:08,679 - INFO - Early stopping triggered at epoch 8
2024-12-29 13:35:08,679 - INFO - Training completed in 2.75s
2024-12-29 13:35:08,680 - INFO - Final memory usage: CPU 2718.0 MB, GPU 103.6 MB
2024-12-29 13:35:08,681 - INFO - Model training completed in 2.75s
2024-12-29 13:35:08,726 - INFO - Prediction completed in 0.04s
2024-12-29 13:35:08,735 - INFO - Poison rate 0.03 completed in 6.89s
2024-12-29 13:35:08,735 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:35:08,741 - INFO - Total number of labels flipped: 473
2024-12-29 13:35:08,741 - INFO - Label flipping completed in 0.01s
2024-12-29 13:35:08,742 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:35:08,742 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:35:09,309 - INFO - Feature scaling completed in 0.57s
2024-12-29 13:35:09,309 - INFO - Starting feature selection (k=50)
2024-12-29 13:35:09,322 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:35:09,322 - INFO - Starting anomaly detection
2024-12-29 13:35:12,177 - INFO - Anomaly detection completed in 2.85s
2024-12-29 13:35:12,177 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:35:12,177 - INFO - Total fit_transform time: 3.44s
2024-12-29 13:35:12,178 - INFO - Training set processing completed in 3.44s
2024-12-29 13:35:12,178 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:35:12,178 - INFO - Memory usage at start_fit: CPU 2708.4 MB, GPU 103.5 MB
2024-12-29 13:35:12,179 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:35:12,181 - INFO - Number of unique classes: 10
2024-12-29 13:35:12,250 - INFO - Fitted scaler and transformed data
2024-12-29 13:35:12,250 - INFO - Scaling time: 0.07s
2024-12-29 13:35:12,591 - INFO - Epoch 1/500, Train Loss: 1.2715, Val Loss: 0.8315
2024-12-29 13:35:12,920 - INFO - Epoch 2/500, Train Loss: 0.6477, Val Loss: 0.7970
2024-12-29 13:35:13,245 - INFO - Epoch 3/500, Train Loss: 0.5532, Val Loss: 0.7886
2024-12-29 13:35:13,578 - INFO - Epoch 4/500, Train Loss: 0.4887, Val Loss: 0.7942
2024-12-29 13:35:13,921 - INFO - Epoch 5/500, Train Loss: 0.4421, Val Loss: 0.8186
2024-12-29 13:35:14,290 - INFO - Epoch 6/500, Train Loss: 0.4078, Val Loss: 0.8097
2024-12-29 13:35:14,606 - INFO - Epoch 7/500, Train Loss: 0.3831, Val Loss: 0.8309
2024-12-29 13:35:14,916 - INFO - Epoch 8/500, Train Loss: 0.3575, Val Loss: 0.8290
2024-12-29 13:35:14,916 - INFO - Early stopping triggered at epoch 8
2024-12-29 13:35:14,916 - INFO - Training completed in 2.74s
2024-12-29 13:35:14,916 - INFO - Final memory usage: CPU 2717.9 MB, GPU 103.6 MB
2024-12-29 13:35:14,917 - INFO - Model training completed in 2.74s
2024-12-29 13:35:14,963 - INFO - Prediction completed in 0.05s
2024-12-29 13:35:14,971 - INFO - Poison rate 0.05 completed in 6.24s
2024-12-29 13:35:14,972 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:35:14,980 - INFO - Total number of labels flipped: 662
2024-12-29 13:35:14,980 - INFO - Label flipping completed in 0.01s
2024-12-29 13:35:14,980 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:35:14,980 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:35:15,502 - INFO - Feature scaling completed in 0.52s
2024-12-29 13:35:15,502 - INFO - Starting feature selection (k=50)
2024-12-29 13:35:15,518 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 13:35:15,518 - INFO - Starting anomaly detection
2024-12-29 13:35:17,749 - INFO - Anomaly detection completed in 2.23s
2024-12-29 13:35:17,749 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:35:17,749 - INFO - Total fit_transform time: 2.77s
2024-12-29 13:35:17,749 - INFO - Training set processing completed in 2.77s
2024-12-29 13:35:17,749 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:35:17,751 - INFO - Memory usage at start_fit: CPU 2708.6 MB, GPU 103.5 MB
2024-12-29 13:35:17,751 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:35:17,754 - INFO - Number of unique classes: 10
2024-12-29 13:35:17,829 - INFO - Fitted scaler and transformed data
2024-12-29 13:35:17,829 - INFO - Scaling time: 0.07s
2024-12-29 13:35:18,148 - INFO - Epoch 1/500, Train Loss: 1.5613, Val Loss: 1.1916
2024-12-29 13:35:18,501 - INFO - Epoch 2/500, Train Loss: 0.8756, Val Loss: 1.1560
2024-12-29 13:35:18,813 - INFO - Epoch 3/500, Train Loss: 0.7541, Val Loss: 1.1429
2024-12-29 13:35:19,212 - INFO - Epoch 4/500, Train Loss: 0.6760, Val Loss: 1.1492
2024-12-29 13:35:19,578 - INFO - Epoch 5/500, Train Loss: 0.6247, Val Loss: 1.1669
2024-12-29 13:35:19,917 - INFO - Epoch 6/500, Train Loss: 0.5818, Val Loss: 1.1556
2024-12-29 13:35:20,281 - INFO - Epoch 7/500, Train Loss: 0.5437, Val Loss: 1.1715
2024-12-29 13:35:20,687 - INFO - Epoch 8/500, Train Loss: 0.5169, Val Loss: 1.1753
2024-12-29 13:35:20,688 - INFO - Early stopping triggered at epoch 8
2024-12-29 13:35:20,688 - INFO - Training completed in 2.94s
2024-12-29 13:35:20,688 - INFO - Final memory usage: CPU 2717.9 MB, GPU 103.6 MB
2024-12-29 13:35:20,689 - INFO - Model training completed in 2.94s
2024-12-29 13:35:20,733 - INFO - Prediction completed in 0.04s
2024-12-29 13:35:20,741 - INFO - Poison rate 0.07 completed in 5.77s
2024-12-29 13:35:20,742 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:35:20,753 - INFO - Total number of labels flipped: 946
2024-12-29 13:35:20,753 - INFO - Label flipping completed in 0.01s
2024-12-29 13:35:20,753 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:35:20,753 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:35:21,354 - INFO - Feature scaling completed in 0.60s
2024-12-29 13:35:21,354 - INFO - Starting feature selection (k=50)
2024-12-29 13:35:21,365 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:35:21,365 - INFO - Starting anomaly detection
2024-12-29 13:35:24,969 - INFO - Anomaly detection completed in 3.60s
2024-12-29 13:35:24,970 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:35:24,970 - INFO - Total fit_transform time: 4.22s
2024-12-29 13:35:24,970 - INFO - Training set processing completed in 4.22s
2024-12-29 13:35:24,971 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:35:24,972 - INFO - Memory usage at start_fit: CPU 2708.6 MB, GPU 103.5 MB
2024-12-29 13:35:24,972 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:35:24,975 - INFO - Number of unique classes: 10
2024-12-29 13:35:25,059 - INFO - Fitted scaler and transformed data
2024-12-29 13:35:25,059 - INFO - Scaling time: 0.08s
2024-12-29 13:35:25,382 - INFO - Epoch 1/500, Train Loss: 1.9312, Val Loss: 1.3689
2024-12-29 13:35:25,777 - INFO - Epoch 2/500, Train Loss: 1.2026, Val Loss: 1.3443
2024-12-29 13:35:26,187 - INFO - Epoch 3/500, Train Loss: 1.0618, Val Loss: 1.3189
2024-12-29 13:35:26,543 - INFO - Epoch 4/500, Train Loss: 0.9693, Val Loss: 1.3460
2024-12-29 13:35:26,897 - INFO - Epoch 5/500, Train Loss: 0.9037, Val Loss: 1.3354
2024-12-29 13:35:27,278 - INFO - Epoch 6/500, Train Loss: 0.8512, Val Loss: 1.3447
2024-12-29 13:35:27,686 - INFO - Epoch 7/500, Train Loss: 0.8047, Val Loss: 1.3323
2024-12-29 13:35:28,073 - INFO - Epoch 8/500, Train Loss: 0.7725, Val Loss: 1.3326
2024-12-29 13:35:28,074 - INFO - Early stopping triggered at epoch 8
2024-12-29 13:35:28,074 - INFO - Training completed in 3.10s
2024-12-29 13:35:28,074 - INFO - Final memory usage: CPU 2717.9 MB, GPU 103.6 MB
2024-12-29 13:35:28,075 - INFO - Model training completed in 3.10s
2024-12-29 13:35:28,127 - INFO - Prediction completed in 0.05s
2024-12-29 13:35:28,135 - INFO - Poison rate 0.1 completed in 7.39s
2024-12-29 13:35:28,135 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:35:28,157 - INFO - Total number of labels flipped: 1893
2024-12-29 13:35:28,157 - INFO - Label flipping completed in 0.02s
2024-12-29 13:35:28,157 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:35:28,157 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:35:28,694 - INFO - Feature scaling completed in 0.54s
2024-12-29 13:35:28,695 - INFO - Starting feature selection (k=50)
2024-12-29 13:35:28,709 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:35:28,709 - INFO - Starting anomaly detection
2024-12-29 13:35:32,925 - INFO - Anomaly detection completed in 4.22s
2024-12-29 13:35:32,925 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:35:32,925 - INFO - Total fit_transform time: 4.77s
2024-12-29 13:35:32,925 - INFO - Training set processing completed in 4.77s
2024-12-29 13:35:32,925 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:35:32,926 - INFO - Memory usage at start_fit: CPU 2708.6 MB, GPU 103.5 MB
2024-12-29 13:35:32,927 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:35:32,929 - INFO - Number of unique classes: 10
2024-12-29 13:35:33,005 - INFO - Fitted scaler and transformed data
2024-12-29 13:35:33,006 - INFO - Scaling time: 0.07s
2024-12-29 13:35:33,366 - INFO - Epoch 1/500, Train Loss: 3.0699, Val Loss: 2.2683
2024-12-29 13:35:33,700 - INFO - Epoch 2/500, Train Loss: 2.2329, Val Loss: 2.2431
2024-12-29 13:35:34,098 - INFO - Epoch 3/500, Train Loss: 2.0285, Val Loss: 2.2660
2024-12-29 13:35:34,481 - INFO - Epoch 4/500, Train Loss: 1.9117, Val Loss: 2.2769
2024-12-29 13:35:34,807 - INFO - Epoch 5/500, Train Loss: 1.8148, Val Loss: 2.2826
2024-12-29 13:35:35,176 - INFO - Epoch 6/500, Train Loss: 1.7464, Val Loss: 2.3019
2024-12-29 13:35:35,534 - INFO - Epoch 7/500, Train Loss: 1.6956, Val Loss: 2.3088
2024-12-29 13:35:35,534 - INFO - Early stopping triggered at epoch 7
2024-12-29 13:35:35,534 - INFO - Training completed in 2.61s
2024-12-29 13:35:35,534 - INFO - Final memory usage: CPU 2717.6 MB, GPU 103.6 MB
2024-12-29 13:35:35,535 - INFO - Model training completed in 2.61s
2024-12-29 13:35:35,585 - INFO - Prediction completed in 0.05s
2024-12-29 13:35:35,595 - INFO - Poison rate 0.2 completed in 7.46s
2024-12-29 13:35:35,599 - INFO - Loaded 231 existing results
2024-12-29 13:35:35,599 - INFO - Total results to save: 238
2024-12-29 13:35:35,600 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:35:35,609 - INFO - Saved 238 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:35:35,609 - INFO - Total evaluation time: 83.39s
2024-12-29 13:35:35,611 - INFO - 
Progress: 36.5% - Evaluating ImageNette with LogisticRegression (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:35:35,826 - INFO - Loading datasets...
2024-12-29 13:35:35,847 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:35:35,847 - INFO - Extracting validation features...
2024-12-29 13:35:35,847 - INFO - Extracting features from 3925 samples...
2024-12-29 13:35:45,117 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:35:45,123 - INFO - Validation feature extraction completed in 9.28s
2024-12-29 13:35:45,123 - INFO - Extracting training features...
2024-12-29 13:35:45,123 - INFO - Extracting features from 9469 samples...
2024-12-29 13:36:07,353 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:36:07,361 - INFO - Training feature extraction completed in 22.24s
2024-12-29 13:36:07,361 - INFO - Creating model for classifier: LogisticRegression
2024-12-29 13:36:07,361 - INFO - Using device: cuda
2024-12-29 13:36:07,361 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:36:07,361 - INFO - Training set processing completed in 0.00s
2024-12-29 13:36:07,362 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:36:07,363 - INFO - Memory usage at start_fit: CPU 2680.8 MB, GPU 104.0 MB
2024-12-29 13:36:07,363 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:36:07,368 - INFO - Number of unique classes: 10
2024-12-29 13:36:07,442 - INFO - Fitted scaler and transformed data
2024-12-29 13:36:07,442 - INFO - Scaling time: 0.07s
2024-12-29 13:36:07,728 - INFO - Epoch 1/1000, Train Loss: 0.5029, Val Loss: 0.1103
2024-12-29 13:36:08,055 - INFO - Epoch 2/1000, Train Loss: 0.0956, Val Loss: 0.0739
2024-12-29 13:36:08,315 - INFO - Epoch 3/1000, Train Loss: 0.0688, Val Loss: 0.0602
2024-12-29 13:36:08,495 - INFO - Epoch 4/1000, Train Loss: 0.0554, Val Loss: 0.0536
2024-12-29 13:36:08,672 - INFO - Epoch 5/1000, Train Loss: 0.0478, Val Loss: 0.0502
2024-12-29 13:36:08,857 - INFO - Epoch 6/1000, Train Loss: 0.0426, Val Loss: 0.0475
2024-12-29 13:36:09,059 - INFO - Epoch 7/1000, Train Loss: 0.0392, Val Loss: 0.0461
2024-12-29 13:36:09,291 - INFO - Epoch 8/1000, Train Loss: 0.0374, Val Loss: 0.0451
2024-12-29 13:36:09,531 - INFO - Epoch 9/1000, Train Loss: 0.0349, Val Loss: 0.0445
2024-12-29 13:36:09,724 - INFO - Epoch 10/1000, Train Loss: 0.0335, Val Loss: 0.0449
2024-12-29 13:36:09,923 - INFO - Epoch 11/1000, Train Loss: 0.0326, Val Loss: 0.0438
2024-12-29 13:36:10,119 - INFO - Epoch 12/1000, Train Loss: 0.0318, Val Loss: 0.0437
2024-12-29 13:36:10,334 - INFO - Epoch 13/1000, Train Loss: 0.0313, Val Loss: 0.0431
2024-12-29 13:36:10,522 - INFO - Epoch 14/1000, Train Loss: 0.0304, Val Loss: 0.0431
2024-12-29 13:36:10,725 - INFO - Epoch 15/1000, Train Loss: 0.0300, Val Loss: 0.0426
2024-12-29 13:36:10,915 - INFO - Epoch 16/1000, Train Loss: 0.0300, Val Loss: 0.0435
2024-12-29 13:36:11,107 - INFO - Epoch 17/1000, Train Loss: 0.0294, Val Loss: 0.0422
2024-12-29 13:36:11,301 - INFO - Epoch 18/1000, Train Loss: 0.0293, Val Loss: 0.0429
2024-12-29 13:36:11,496 - INFO - Epoch 19/1000, Train Loss: 0.0290, Val Loss: 0.0421
2024-12-29 13:36:11,699 - INFO - Epoch 20/1000, Train Loss: 0.0289, Val Loss: 0.0420
2024-12-29 13:36:11,699 - INFO - Early stopping triggered at epoch 20
2024-12-29 13:36:11,699 - INFO - Training completed in 4.34s
2024-12-29 13:36:11,699 - INFO - Final memory usage: CPU 2717.9 MB, GPU 104.2 MB
2024-12-29 13:36:11,701 - INFO - Model training completed in 4.34s
2024-12-29 13:36:11,774 - INFO - Prediction completed in 0.07s
2024-12-29 13:36:11,794 - INFO - Poison rate 0.0 completed in 4.43s
2024-12-29 13:36:11,795 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:36:11,797 - INFO - Total number of labels flipped: 94
2024-12-29 13:36:11,797 - INFO - Label flipping completed in 0.00s
2024-12-29 13:36:11,797 - INFO - Training set processing completed in 0.00s
2024-12-29 13:36:11,797 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:36:11,798 - INFO - Memory usage at start_fit: CPU 2692.5 MB, GPU 104.1 MB
2024-12-29 13:36:11,798 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:36:11,801 - INFO - Number of unique classes: 10
2024-12-29 13:36:11,881 - INFO - Fitted scaler and transformed data
2024-12-29 13:36:11,881 - INFO - Scaling time: 0.08s
2024-12-29 13:36:12,096 - INFO - Epoch 1/1000, Train Loss: 0.5083, Val Loss: 0.1981
2024-12-29 13:36:12,296 - INFO - Epoch 2/1000, Train Loss: 0.1707, Val Loss: 0.1780
2024-12-29 13:36:12,491 - INFO - Epoch 3/1000, Train Loss: 0.1475, Val Loss: 0.1736
2024-12-29 13:36:12,692 - INFO - Epoch 4/1000, Train Loss: 0.1351, Val Loss: 0.1719
2024-12-29 13:36:12,882 - INFO - Epoch 5/1000, Train Loss: 0.1275, Val Loss: 0.1735
2024-12-29 13:36:13,076 - INFO - Epoch 6/1000, Train Loss: 0.1215, Val Loss: 0.1725
2024-12-29 13:36:13,268 - INFO - Epoch 7/1000, Train Loss: 0.1160, Val Loss: 0.1750
2024-12-29 13:36:13,480 - INFO - Epoch 8/1000, Train Loss: 0.1121, Val Loss: 0.1758
2024-12-29 13:36:13,700 - INFO - Epoch 9/1000, Train Loss: 0.1091, Val Loss: 0.1762
2024-12-29 13:36:13,700 - INFO - Early stopping triggered at epoch 9
2024-12-29 13:36:13,700 - INFO - Training completed in 1.90s
2024-12-29 13:36:13,700 - INFO - Final memory usage: CPU 2718.0 MB, GPU 104.2 MB
2024-12-29 13:36:13,702 - INFO - Model training completed in 1.91s
2024-12-29 13:36:13,786 - INFO - Prediction completed in 0.08s
2024-12-29 13:36:13,795 - INFO - Poison rate 0.01 completed in 2.00s
2024-12-29 13:36:13,795 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:36:13,799 - INFO - Total number of labels flipped: 284
2024-12-29 13:36:13,800 - INFO - Label flipping completed in 0.00s
2024-12-29 13:36:13,800 - INFO - Training set processing completed in 0.00s
2024-12-29 13:36:13,800 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:36:13,801 - INFO - Memory usage at start_fit: CPU 2692.3 MB, GPU 104.1 MB
2024-12-29 13:36:13,801 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:36:13,804 - INFO - Number of unique classes: 10
2024-12-29 13:36:13,882 - INFO - Fitted scaler and transformed data
2024-12-29 13:36:13,883 - INFO - Scaling time: 0.08s
2024-12-29 13:36:14,095 - INFO - Epoch 1/1000, Train Loss: 0.6180, Val Loss: 0.3541
2024-12-29 13:36:14,315 - INFO - Epoch 2/1000, Train Loss: 0.2876, Val Loss: 0.3366
2024-12-29 13:36:14,521 - INFO - Epoch 3/1000, Train Loss: 0.2655, Val Loss: 0.3319
2024-12-29 13:36:14,739 - INFO - Epoch 4/1000, Train Loss: 0.2547, Val Loss: 0.3277
2024-12-29 13:36:14,952 - INFO - Epoch 5/1000, Train Loss: 0.2423, Val Loss: 0.3252
2024-12-29 13:36:15,151 - INFO - Epoch 6/1000, Train Loss: 0.2352, Val Loss: 0.3254
2024-12-29 13:36:15,351 - INFO - Epoch 7/1000, Train Loss: 0.2280, Val Loss: 0.3260
2024-12-29 13:36:15,553 - INFO - Epoch 8/1000, Train Loss: 0.2232, Val Loss: 0.3256
2024-12-29 13:36:15,762 - INFO - Epoch 9/1000, Train Loss: 0.2180, Val Loss: 0.3251
2024-12-29 13:36:15,978 - INFO - Epoch 10/1000, Train Loss: 0.2145, Val Loss: 0.3260
2024-12-29 13:36:15,979 - INFO - Early stopping triggered at epoch 10
2024-12-29 13:36:15,979 - INFO - Training completed in 2.18s
2024-12-29 13:36:15,980 - INFO - Final memory usage: CPU 2718.1 MB, GPU 104.2 MB
2024-12-29 13:36:15,982 - INFO - Model training completed in 2.18s
2024-12-29 13:36:16,043 - INFO - Prediction completed in 0.06s
2024-12-29 13:36:16,052 - INFO - Poison rate 0.03 completed in 2.26s
2024-12-29 13:36:16,052 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:36:16,058 - INFO - Total number of labels flipped: 473
2024-12-29 13:36:16,058 - INFO - Label flipping completed in 0.01s
2024-12-29 13:36:16,058 - INFO - Training set processing completed in 0.00s
2024-12-29 13:36:16,058 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:36:16,059 - INFO - Memory usage at start_fit: CPU 2692.6 MB, GPU 104.1 MB
2024-12-29 13:36:16,060 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:36:16,064 - INFO - Number of unique classes: 10
2024-12-29 13:36:16,144 - INFO - Fitted scaler and transformed data
2024-12-29 13:36:16,144 - INFO - Scaling time: 0.08s
2024-12-29 13:36:16,375 - INFO - Epoch 1/1000, Train Loss: 0.7312, Val Loss: 0.4740
2024-12-29 13:36:16,569 - INFO - Epoch 2/1000, Train Loss: 0.4160, Val Loss: 0.4610
2024-12-29 13:36:16,764 - INFO - Epoch 3/1000, Train Loss: 0.3921, Val Loss: 0.4609
2024-12-29 13:36:16,962 - INFO - Epoch 4/1000, Train Loss: 0.3759, Val Loss: 0.4604
2024-12-29 13:36:17,170 - INFO - Epoch 5/1000, Train Loss: 0.3637, Val Loss: 0.4622
2024-12-29 13:36:17,426 - INFO - Epoch 6/1000, Train Loss: 0.3538, Val Loss: 0.4632
2024-12-29 13:36:17,790 - INFO - Epoch 7/1000, Train Loss: 0.3472, Val Loss: 0.4662
2024-12-29 13:36:17,790 - INFO - Early stopping triggered at epoch 7
2024-12-29 13:36:17,790 - INFO - Training completed in 1.73s
2024-12-29 13:36:17,791 - INFO - Final memory usage: CPU 2717.9 MB, GPU 104.2 MB
2024-12-29 13:36:17,792 - INFO - Model training completed in 1.73s
2024-12-29 13:36:17,839 - INFO - Prediction completed in 0.05s
2024-12-29 13:36:17,848 - INFO - Poison rate 0.05 completed in 1.80s
2024-12-29 13:36:17,848 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:36:17,856 - INFO - Total number of labels flipped: 662
2024-12-29 13:36:17,857 - INFO - Label flipping completed in 0.01s
2024-12-29 13:36:17,857 - INFO - Training set processing completed in 0.00s
2024-12-29 13:36:17,857 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:36:17,858 - INFO - Memory usage at start_fit: CPU 2692.4 MB, GPU 104.1 MB
2024-12-29 13:36:17,858 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:36:17,862 - INFO - Number of unique classes: 10
2024-12-29 13:36:17,943 - INFO - Fitted scaler and transformed data
2024-12-29 13:36:17,943 - INFO - Scaling time: 0.08s
2024-12-29 13:36:18,284 - INFO - Epoch 1/1000, Train Loss: 0.8230, Val Loss: 0.5301
2024-12-29 13:36:18,583 - INFO - Epoch 2/1000, Train Loss: 0.5207, Val Loss: 0.5225
2024-12-29 13:36:18,969 - INFO - Epoch 3/1000, Train Loss: 0.4932, Val Loss: 0.5168
2024-12-29 13:36:19,379 - INFO - Epoch 4/1000, Train Loss: 0.4776, Val Loss: 0.5204
2024-12-29 13:36:19,799 - INFO - Epoch 5/1000, Train Loss: 0.4657, Val Loss: 0.5183
2024-12-29 13:36:20,229 - INFO - Epoch 6/1000, Train Loss: 0.4543, Val Loss: 0.5190
2024-12-29 13:36:20,626 - INFO - Epoch 7/1000, Train Loss: 0.4450, Val Loss: 0.5222
2024-12-29 13:36:20,993 - INFO - Epoch 8/1000, Train Loss: 0.4392, Val Loss: 0.5176
2024-12-29 13:36:20,994 - INFO - Early stopping triggered at epoch 8
2024-12-29 13:36:20,994 - INFO - Training completed in 3.14s
2024-12-29 13:36:20,994 - INFO - Final memory usage: CPU 2718.0 MB, GPU 104.2 MB
2024-12-29 13:36:20,995 - INFO - Model training completed in 3.14s
2024-12-29 13:36:21,041 - INFO - Prediction completed in 0.05s
2024-12-29 13:36:21,050 - INFO - Poison rate 0.07 completed in 3.20s
2024-12-29 13:36:21,050 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:36:21,061 - INFO - Total number of labels flipped: 946
2024-12-29 13:36:21,061 - INFO - Label flipping completed in 0.01s
2024-12-29 13:36:21,061 - INFO - Training set processing completed in 0.00s
2024-12-29 13:36:21,061 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:36:21,062 - INFO - Memory usage at start_fit: CPU 2692.5 MB, GPU 104.1 MB
2024-12-29 13:36:21,062 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:36:21,066 - INFO - Number of unique classes: 10
2024-12-29 13:36:21,139 - INFO - Fitted scaler and transformed data
2024-12-29 13:36:21,140 - INFO - Scaling time: 0.07s
2024-12-29 13:36:21,556 - INFO - Epoch 1/1000, Train Loss: 0.9054, Val Loss: 0.7187
2024-12-29 13:36:21,977 - INFO - Epoch 2/1000, Train Loss: 0.6564, Val Loss: 0.6966
2024-12-29 13:36:22,385 - INFO - Epoch 3/1000, Train Loss: 0.6258, Val Loss: 0.6938
2024-12-29 13:36:22,809 - INFO - Epoch 4/1000, Train Loss: 0.6087, Val Loss: 0.6932
2024-12-29 13:36:23,222 - INFO - Epoch 5/1000, Train Loss: 0.5935, Val Loss: 0.6940
2024-12-29 13:36:23,634 - INFO - Epoch 6/1000, Train Loss: 0.5835, Val Loss: 0.6991
2024-12-29 13:36:24,025 - INFO - Epoch 7/1000, Train Loss: 0.5724, Val Loss: 0.6958
2024-12-29 13:36:24,417 - INFO - Epoch 8/1000, Train Loss: 0.5682, Val Loss: 0.7064
2024-12-29 13:36:24,418 - INFO - Early stopping triggered at epoch 8
2024-12-29 13:36:24,418 - INFO - Training completed in 3.36s
2024-12-29 13:36:24,419 - INFO - Final memory usage: CPU 2718.1 MB, GPU 104.2 MB
2024-12-29 13:36:24,421 - INFO - Model training completed in 3.36s
2024-12-29 13:36:24,486 - INFO - Prediction completed in 0.06s
2024-12-29 13:36:24,495 - INFO - Poison rate 0.1 completed in 3.44s
2024-12-29 13:36:24,495 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:36:24,516 - INFO - Total number of labels flipped: 1893
2024-12-29 13:36:24,516 - INFO - Label flipping completed in 0.02s
2024-12-29 13:36:24,516 - INFO - Training set processing completed in 0.00s
2024-12-29 13:36:24,516 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:36:24,518 - INFO - Memory usage at start_fit: CPU 2692.3 MB, GPU 104.1 MB
2024-12-29 13:36:24,518 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:36:24,522 - INFO - Number of unique classes: 10
2024-12-29 13:36:24,611 - INFO - Fitted scaler and transformed data
2024-12-29 13:36:24,611 - INFO - Scaling time: 0.09s
2024-12-29 13:36:25,033 - INFO - Epoch 1/1000, Train Loss: 1.2616, Val Loss: 1.1129
2024-12-29 13:36:25,446 - INFO - Epoch 2/1000, Train Loss: 1.0478, Val Loss: 1.0991
2024-12-29 13:36:25,881 - INFO - Epoch 3/1000, Train Loss: 1.0156, Val Loss: 1.0925
2024-12-29 13:36:26,307 - INFO - Epoch 4/1000, Train Loss: 0.9947, Val Loss: 1.0939
2024-12-29 13:36:26,731 - INFO - Epoch 5/1000, Train Loss: 0.9779, Val Loss: 1.0918
2024-12-29 13:36:26,996 - INFO - Epoch 6/1000, Train Loss: 0.9670, Val Loss: 1.0930
2024-12-29 13:36:27,233 - INFO - Epoch 7/1000, Train Loss: 0.9573, Val Loss: 1.0926
2024-12-29 13:36:27,472 - INFO - Epoch 8/1000, Train Loss: 0.9482, Val Loss: 1.1002
2024-12-29 13:36:27,473 - INFO - Early stopping triggered at epoch 8
2024-12-29 13:36:27,473 - INFO - Training completed in 2.96s
2024-12-29 13:36:27,474 - INFO - Final memory usage: CPU 2718.2 MB, GPU 104.2 MB
2024-12-29 13:36:27,476 - INFO - Model training completed in 2.96s
2024-12-29 13:36:27,534 - INFO - Prediction completed in 0.06s
2024-12-29 13:36:27,543 - INFO - Poison rate 0.2 completed in 3.05s
2024-12-29 13:36:27,548 - INFO - Loaded 238 existing results
2024-12-29 13:36:27,548 - INFO - Total results to save: 245
2024-12-29 13:36:27,549 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:36:27,557 - INFO - Saved 245 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:36:27,558 - INFO - Total evaluation time: 51.73s
2024-12-29 13:36:27,559 - INFO - 
Progress: 37.5% - Evaluating ImageNette with LogisticRegression (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:36:27,787 - INFO - Loading datasets...
2024-12-29 13:36:27,812 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:36:27,812 - INFO - Extracting validation features...
2024-12-29 13:36:27,812 - INFO - Extracting features from 3925 samples...
2024-12-29 13:36:36,973 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:36:36,979 - INFO - Validation feature extraction completed in 9.17s
2024-12-29 13:36:36,980 - INFO - Extracting training features...
2024-12-29 13:36:36,980 - INFO - Extracting features from 9469 samples...
2024-12-29 13:36:58,639 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:36:58,647 - INFO - Training feature extraction completed in 21.67s
2024-12-29 13:36:58,648 - INFO - Creating model for classifier: LogisticRegression
2024-12-29 13:36:58,649 - INFO - Using device: cuda
2024-12-29 13:36:58,649 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:36:58,649 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:36:58,650 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:36:59,250 - INFO - Feature scaling completed in 0.60s
2024-12-29 13:36:59,251 - INFO - Starting feature selection (k=50)
2024-12-29 13:36:59,261 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:36:59,262 - INFO - Starting anomaly detection
2024-12-29 13:37:02,976 - INFO - Anomaly detection completed in 3.71s
2024-12-29 13:37:02,976 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:37:02,977 - INFO - Total fit_transform time: 4.33s
2024-12-29 13:37:02,977 - INFO - Training set processing completed in 4.33s
2024-12-29 13:37:02,977 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:37:02,978 - INFO - Memory usage at start_fit: CPU 2708.9 MB, GPU 103.4 MB
2024-12-29 13:37:02,978 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:37:02,980 - INFO - Number of unique classes: 10
2024-12-29 13:37:03,052 - INFO - Fitted scaler and transformed data
2024-12-29 13:37:03,052 - INFO - Scaling time: 0.07s
2024-12-29 13:37:03,389 - INFO - Epoch 1/1000, Train Loss: 0.5099, Val Loss: 0.1292
2024-12-29 13:37:03,725 - INFO - Epoch 2/1000, Train Loss: 0.0952, Val Loss: 0.0918
2024-12-29 13:37:04,090 - INFO - Epoch 3/1000, Train Loss: 0.0674, Val Loss: 0.0786
2024-12-29 13:37:04,468 - INFO - Epoch 4/1000, Train Loss: 0.0545, Val Loss: 0.0722
2024-12-29 13:37:04,811 - INFO - Epoch 5/1000, Train Loss: 0.0469, Val Loss: 0.0679
2024-12-29 13:37:05,133 - INFO - Epoch 6/1000, Train Loss: 0.0413, Val Loss: 0.0666
2024-12-29 13:37:05,545 - INFO - Epoch 7/1000, Train Loss: 0.0377, Val Loss: 0.0653
2024-12-29 13:37:05,896 - INFO - Epoch 8/1000, Train Loss: 0.0355, Val Loss: 0.0642
2024-12-29 13:37:06,207 - INFO - Epoch 9/1000, Train Loss: 0.0336, Val Loss: 0.0640
2024-12-29 13:37:06,548 - INFO - Epoch 10/1000, Train Loss: 0.0322, Val Loss: 0.0639
2024-12-29 13:37:06,844 - INFO - Epoch 11/1000, Train Loss: 0.0316, Val Loss: 0.0635
2024-12-29 13:37:07,194 - INFO - Epoch 12/1000, Train Loss: 0.0306, Val Loss: 0.0631
2024-12-29 13:37:07,470 - INFO - Epoch 13/1000, Train Loss: 0.0299, Val Loss: 0.0623
2024-12-29 13:37:07,768 - INFO - Epoch 14/1000, Train Loss: 0.0296, Val Loss: 0.0624
2024-12-29 13:37:08,114 - INFO - Epoch 15/1000, Train Loss: 0.0291, Val Loss: 0.0621
2024-12-29 13:37:08,359 - INFO - Epoch 16/1000, Train Loss: 0.0286, Val Loss: 0.0628
2024-12-29 13:37:08,642 - INFO - Epoch 17/1000, Train Loss: 0.0285, Val Loss: 0.0619
2024-12-29 13:37:08,980 - INFO - Epoch 18/1000, Train Loss: 0.0281, Val Loss: 0.0607
2024-12-29 13:37:09,283 - INFO - Epoch 19/1000, Train Loss: 0.0280, Val Loss: 0.0614
2024-12-29 13:37:09,565 - INFO - Epoch 20/1000, Train Loss: 0.0278, Val Loss: 0.0609
2024-12-29 13:37:09,913 - INFO - Epoch 21/1000, Train Loss: 0.0278, Val Loss: 0.0615
2024-12-29 13:37:10,234 - INFO - Epoch 22/1000, Train Loss: 0.0277, Val Loss: 0.0618
2024-12-29 13:37:10,518 - INFO - Epoch 23/1000, Train Loss: 0.0274, Val Loss: 0.0599
2024-12-29 13:37:10,519 - INFO - Early stopping triggered at epoch 23
2024-12-29 13:37:10,519 - INFO - Training completed in 7.54s
2024-12-29 13:37:10,520 - INFO - Final memory usage: CPU 2718.2 MB, GPU 103.6 MB
2024-12-29 13:37:10,522 - INFO - Model training completed in 7.55s
2024-12-29 13:37:10,587 - INFO - Prediction completed in 0.06s
2024-12-29 13:37:10,596 - INFO - Poison rate 0.0 completed in 11.95s
2024-12-29 13:37:10,597 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:37:10,598 - INFO - Total number of labels flipped: 94
2024-12-29 13:37:10,599 - INFO - Label flipping completed in 0.00s
2024-12-29 13:37:10,599 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:37:10,599 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:37:11,200 - INFO - Feature scaling completed in 0.60s
2024-12-29 13:37:11,200 - INFO - Starting feature selection (k=50)
2024-12-29 13:37:11,215 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:37:11,215 - INFO - Starting anomaly detection
2024-12-29 13:37:15,036 - INFO - Anomaly detection completed in 3.82s
2024-12-29 13:37:15,036 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:37:15,036 - INFO - Total fit_transform time: 4.44s
2024-12-29 13:37:15,036 - INFO - Training set processing completed in 4.44s
2024-12-29 13:37:15,037 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:37:15,038 - INFO - Memory usage at start_fit: CPU 2708.8 MB, GPU 103.5 MB
2024-12-29 13:37:15,038 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:37:15,041 - INFO - Number of unique classes: 10
2024-12-29 13:37:15,134 - INFO - Fitted scaler and transformed data
2024-12-29 13:37:15,134 - INFO - Scaling time: 0.09s
2024-12-29 13:37:15,452 - INFO - Epoch 1/1000, Train Loss: 0.5364, Val Loss: 0.1732
2024-12-29 13:37:15,733 - INFO - Epoch 2/1000, Train Loss: 0.1680, Val Loss: 0.1482
2024-12-29 13:37:16,027 - INFO - Epoch 3/1000, Train Loss: 0.1470, Val Loss: 0.1406
2024-12-29 13:37:16,345 - INFO - Epoch 4/1000, Train Loss: 0.1346, Val Loss: 0.1388
2024-12-29 13:37:16,633 - INFO - Epoch 5/1000, Train Loss: 0.1266, Val Loss: 0.1378
2024-12-29 13:37:16,991 - INFO - Epoch 6/1000, Train Loss: 0.1201, Val Loss: 0.1378
2024-12-29 13:37:17,299 - INFO - Epoch 7/1000, Train Loss: 0.1153, Val Loss: 0.1379
2024-12-29 13:37:17,652 - INFO - Epoch 8/1000, Train Loss: 0.1114, Val Loss: 0.1395
2024-12-29 13:37:18,068 - INFO - Epoch 9/1000, Train Loss: 0.1086, Val Loss: 0.1376
2024-12-29 13:37:18,370 - INFO - Epoch 10/1000, Train Loss: 0.1058, Val Loss: 0.1407
2024-12-29 13:37:18,720 - INFO - Epoch 11/1000, Train Loss: 0.1037, Val Loss: 0.1407
2024-12-29 13:37:19,135 - INFO - Epoch 12/1000, Train Loss: 0.1032, Val Loss: 0.1412
2024-12-29 13:37:19,430 - INFO - Epoch 13/1000, Train Loss: 0.1000, Val Loss: 0.1416
2024-12-29 13:37:19,760 - INFO - Epoch 14/1000, Train Loss: 0.0997, Val Loss: 0.1408
2024-12-29 13:37:19,761 - INFO - Early stopping triggered at epoch 14
2024-12-29 13:37:19,761 - INFO - Training completed in 4.72s
2024-12-29 13:37:19,761 - INFO - Final memory usage: CPU 2718.2 MB, GPU 103.6 MB
2024-12-29 13:37:19,763 - INFO - Model training completed in 4.73s
2024-12-29 13:37:19,829 - INFO - Prediction completed in 0.07s
2024-12-29 13:37:19,838 - INFO - Poison rate 0.01 completed in 9.24s
2024-12-29 13:37:19,838 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:37:19,842 - INFO - Total number of labels flipped: 284
2024-12-29 13:37:19,842 - INFO - Label flipping completed in 0.00s
2024-12-29 13:37:19,843 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:37:19,843 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:37:20,387 - INFO - Feature scaling completed in 0.54s
2024-12-29 13:37:20,387 - INFO - Starting feature selection (k=50)
2024-12-29 13:37:20,408 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 13:37:20,409 - INFO - Starting anomaly detection
2024-12-29 13:37:24,503 - INFO - Anomaly detection completed in 4.09s
2024-12-29 13:37:24,503 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:37:24,503 - INFO - Total fit_transform time: 4.66s
2024-12-29 13:37:24,504 - INFO - Training set processing completed in 4.66s
2024-12-29 13:37:24,504 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:37:24,505 - INFO - Memory usage at start_fit: CPU 2708.8 MB, GPU 103.5 MB
2024-12-29 13:37:24,505 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:37:24,508 - INFO - Number of unique classes: 10
2024-12-29 13:37:24,595 - INFO - Fitted scaler and transformed data
2024-12-29 13:37:24,595 - INFO - Scaling time: 0.09s
2024-12-29 13:37:24,958 - INFO - Epoch 1/1000, Train Loss: 0.6369, Val Loss: 0.3267
2024-12-29 13:37:25,232 - INFO - Epoch 2/1000, Train Loss: 0.2920, Val Loss: 0.3108
2024-12-29 13:37:25,473 - INFO - Epoch 3/1000, Train Loss: 0.2701, Val Loss: 0.3040
2024-12-29 13:37:25,814 - INFO - Epoch 4/1000, Train Loss: 0.2566, Val Loss: 0.3016
2024-12-29 13:37:26,155 - INFO - Epoch 5/1000, Train Loss: 0.2450, Val Loss: 0.3028
2024-12-29 13:37:26,373 - INFO - Epoch 6/1000, Train Loss: 0.2383, Val Loss: 0.3033
2024-12-29 13:37:26,616 - INFO - Epoch 7/1000, Train Loss: 0.2323, Val Loss: 0.3013
2024-12-29 13:37:26,856 - INFO - Epoch 8/1000, Train Loss: 0.2261, Val Loss: 0.3099
2024-12-29 13:37:27,074 - INFO - Epoch 9/1000, Train Loss: 0.2226, Val Loss: 0.3048
2024-12-29 13:37:27,074 - INFO - Early stopping triggered at epoch 9
2024-12-29 13:37:27,074 - INFO - Training completed in 2.57s
2024-12-29 13:37:27,075 - INFO - Final memory usage: CPU 2718.1 MB, GPU 103.6 MB
2024-12-29 13:37:27,075 - INFO - Model training completed in 2.57s
2024-12-29 13:37:27,144 - INFO - Prediction completed in 0.07s
2024-12-29 13:37:27,153 - INFO - Poison rate 0.03 completed in 7.31s
2024-12-29 13:37:27,153 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:37:27,159 - INFO - Total number of labels flipped: 473
2024-12-29 13:37:27,159 - INFO - Label flipping completed in 0.01s
2024-12-29 13:37:27,159 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:37:27,159 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:37:27,739 - INFO - Feature scaling completed in 0.58s
2024-12-29 13:37:27,739 - INFO - Starting feature selection (k=50)
2024-12-29 13:37:27,756 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 13:37:27,756 - INFO - Starting anomaly detection
2024-12-29 13:37:31,915 - INFO - Anomaly detection completed in 4.16s
2024-12-29 13:37:31,915 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:37:31,915 - INFO - Total fit_transform time: 4.76s
2024-12-29 13:37:31,915 - INFO - Training set processing completed in 4.76s
2024-12-29 13:37:31,915 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:37:31,916 - INFO - Memory usage at start_fit: CPU 2708.9 MB, GPU 103.5 MB
2024-12-29 13:37:31,916 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:37:31,919 - INFO - Number of unique classes: 10
2024-12-29 13:37:31,995 - INFO - Fitted scaler and transformed data
2024-12-29 13:37:31,996 - INFO - Scaling time: 0.08s
2024-12-29 13:37:32,208 - INFO - Epoch 1/1000, Train Loss: 0.7126, Val Loss: 0.4561
2024-12-29 13:37:32,421 - INFO - Epoch 2/1000, Train Loss: 0.4094, Val Loss: 0.4412
2024-12-29 13:37:32,653 - INFO - Epoch 3/1000, Train Loss: 0.3860, Val Loss: 0.4368
2024-12-29 13:37:32,885 - INFO - Epoch 4/1000, Train Loss: 0.3704, Val Loss: 0.4355
2024-12-29 13:37:33,121 - INFO - Epoch 5/1000, Train Loss: 0.3584, Val Loss: 0.4365
2024-12-29 13:37:33,357 - INFO - Epoch 6/1000, Train Loss: 0.3499, Val Loss: 0.4406
2024-12-29 13:37:33,579 - INFO - Epoch 7/1000, Train Loss: 0.3436, Val Loss: 0.4367
2024-12-29 13:37:33,809 - INFO - Epoch 8/1000, Train Loss: 0.3359, Val Loss: 0.4389
2024-12-29 13:37:34,010 - INFO - Epoch 9/1000, Train Loss: 0.3312, Val Loss: 0.4377
2024-12-29 13:37:34,010 - INFO - Early stopping triggered at epoch 9
2024-12-29 13:37:34,010 - INFO - Training completed in 2.09s
2024-12-29 13:37:34,011 - INFO - Final memory usage: CPU 2718.1 MB, GPU 103.6 MB
2024-12-29 13:37:34,012 - INFO - Model training completed in 2.10s
2024-12-29 13:37:34,094 - INFO - Prediction completed in 0.08s
2024-12-29 13:37:34,114 - INFO - Poison rate 0.05 completed in 6.96s
2024-12-29 13:37:34,115 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:37:34,130 - INFO - Total number of labels flipped: 662
2024-12-29 13:37:34,131 - INFO - Label flipping completed in 0.02s
2024-12-29 13:37:34,131 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:37:34,131 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:37:34,702 - INFO - Feature scaling completed in 0.57s
2024-12-29 13:37:34,702 - INFO - Starting feature selection (k=50)
2024-12-29 13:37:34,716 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:37:34,717 - INFO - Starting anomaly detection
2024-12-29 13:37:38,971 - INFO - Anomaly detection completed in 4.25s
2024-12-29 13:37:38,972 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:37:38,972 - INFO - Total fit_transform time: 4.84s
2024-12-29 13:37:38,972 - INFO - Training set processing completed in 4.84s
2024-12-29 13:37:38,972 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:37:38,973 - INFO - Memory usage at start_fit: CPU 2708.8 MB, GPU 103.5 MB
2024-12-29 13:37:38,973 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:37:38,977 - INFO - Number of unique classes: 10
2024-12-29 13:37:39,054 - INFO - Fitted scaler and transformed data
2024-12-29 13:37:39,055 - INFO - Scaling time: 0.08s
2024-12-29 13:37:39,324 - INFO - Epoch 1/1000, Train Loss: 0.7919, Val Loss: 0.5935
2024-12-29 13:37:39,603 - INFO - Epoch 2/1000, Train Loss: 0.5137, Val Loss: 0.5848
2024-12-29 13:37:39,897 - INFO - Epoch 3/1000, Train Loss: 0.4891, Val Loss: 0.5826
2024-12-29 13:37:40,222 - INFO - Epoch 4/1000, Train Loss: 0.4713, Val Loss: 0.5818
2024-12-29 13:37:40,516 - INFO - Epoch 5/1000, Train Loss: 0.4576, Val Loss: 0.5853
2024-12-29 13:37:40,806 - INFO - Epoch 6/1000, Train Loss: 0.4462, Val Loss: 0.5882
2024-12-29 13:37:41,123 - INFO - Epoch 7/1000, Train Loss: 0.4398, Val Loss: 0.5886
2024-12-29 13:37:41,416 - INFO - Epoch 8/1000, Train Loss: 0.4334, Val Loss: 0.5912
2024-12-29 13:37:41,416 - INFO - Early stopping triggered at epoch 8
2024-12-29 13:37:41,417 - INFO - Training completed in 2.44s
2024-12-29 13:37:41,417 - INFO - Final memory usage: CPU 2717.8 MB, GPU 103.6 MB
2024-12-29 13:37:41,418 - INFO - Model training completed in 2.45s
2024-12-29 13:37:41,470 - INFO - Prediction completed in 0.05s
2024-12-29 13:37:41,479 - INFO - Poison rate 0.07 completed in 7.36s
2024-12-29 13:37:41,479 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:37:41,496 - INFO - Total number of labels flipped: 946
2024-12-29 13:37:41,497 - INFO - Label flipping completed in 0.02s
2024-12-29 13:37:41,497 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:37:41,497 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:37:42,086 - INFO - Feature scaling completed in 0.59s
2024-12-29 13:37:42,086 - INFO - Starting feature selection (k=50)
2024-12-29 13:37:42,101 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:37:42,101 - INFO - Starting anomaly detection
2024-12-29 13:37:46,331 - INFO - Anomaly detection completed in 4.23s
2024-12-29 13:37:46,331 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:37:46,332 - INFO - Total fit_transform time: 4.83s
2024-12-29 13:37:46,332 - INFO - Training set processing completed in 4.83s
2024-12-29 13:37:46,332 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:37:46,333 - INFO - Memory usage at start_fit: CPU 2708.5 MB, GPU 103.5 MB
2024-12-29 13:37:46,333 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:37:46,336 - INFO - Number of unique classes: 10
2024-12-29 13:37:46,413 - INFO - Fitted scaler and transformed data
2024-12-29 13:37:46,413 - INFO - Scaling time: 0.08s
2024-12-29 13:37:46,618 - INFO - Epoch 1/1000, Train Loss: 0.8997, Val Loss: 0.6590
2024-12-29 13:37:46,875 - INFO - Epoch 2/1000, Train Loss: 0.6576, Val Loss: 0.6555
2024-12-29 13:37:47,073 - INFO - Epoch 3/1000, Train Loss: 0.6316, Val Loss: 0.6539
2024-12-29 13:37:47,263 - INFO - Epoch 4/1000, Train Loss: 0.6128, Val Loss: 0.6540
2024-12-29 13:37:47,465 - INFO - Epoch 5/1000, Train Loss: 0.6009, Val Loss: 0.6599
2024-12-29 13:37:47,686 - INFO - Epoch 6/1000, Train Loss: 0.5895, Val Loss: 0.6592
2024-12-29 13:37:47,880 - INFO - Epoch 7/1000, Train Loss: 0.5819, Val Loss: 0.6686
2024-12-29 13:37:48,088 - INFO - Epoch 8/1000, Train Loss: 0.5765, Val Loss: 0.6630
2024-12-29 13:37:48,088 - INFO - Early stopping triggered at epoch 8
2024-12-29 13:37:48,088 - INFO - Training completed in 1.76s
2024-12-29 13:37:48,089 - INFO - Final memory usage: CPU 2718.1 MB, GPU 103.6 MB
2024-12-29 13:37:48,091 - INFO - Model training completed in 1.76s
2024-12-29 13:37:48,150 - INFO - Prediction completed in 0.06s
2024-12-29 13:37:48,159 - INFO - Poison rate 0.1 completed in 6.68s
2024-12-29 13:37:48,159 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:37:48,181 - INFO - Total number of labels flipped: 1893
2024-12-29 13:37:48,181 - INFO - Label flipping completed in 0.02s
2024-12-29 13:37:48,181 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:37:48,181 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:37:48,749 - INFO - Feature scaling completed in 0.57s
2024-12-29 13:37:48,750 - INFO - Starting feature selection (k=50)
2024-12-29 13:37:48,764 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:37:48,764 - INFO - Starting anomaly detection
2024-12-29 13:37:52,753 - INFO - Anomaly detection completed in 3.99s
2024-12-29 13:37:52,753 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:37:52,753 - INFO - Total fit_transform time: 4.57s
2024-12-29 13:37:52,754 - INFO - Training set processing completed in 4.57s
2024-12-29 13:37:52,754 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:37:52,755 - INFO - Memory usage at start_fit: CPU 2708.5 MB, GPU 103.5 MB
2024-12-29 13:37:52,755 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:37:52,757 - INFO - Number of unique classes: 10
2024-12-29 13:37:52,828 - INFO - Fitted scaler and transformed data
2024-12-29 13:37:52,829 - INFO - Scaling time: 0.07s
2024-12-29 13:37:53,076 - INFO - Epoch 1/1000, Train Loss: 1.2610, Val Loss: 1.1143
2024-12-29 13:37:53,276 - INFO - Epoch 2/1000, Train Loss: 1.0555, Val Loss: 1.1068
2024-12-29 13:37:53,487 - INFO - Epoch 3/1000, Train Loss: 1.0230, Val Loss: 1.1077
2024-12-29 13:37:53,684 - INFO - Epoch 4/1000, Train Loss: 1.0037, Val Loss: 1.1026
2024-12-29 13:37:53,892 - INFO - Epoch 5/1000, Train Loss: 0.9852, Val Loss: 1.1161
2024-12-29 13:37:54,095 - INFO - Epoch 6/1000, Train Loss: 0.9737, Val Loss: 1.1146
2024-12-29 13:37:54,306 - INFO - Epoch 7/1000, Train Loss: 0.9678, Val Loss: 1.1184
2024-12-29 13:37:54,526 - INFO - Epoch 8/1000, Train Loss: 0.9570, Val Loss: 1.1231
2024-12-29 13:37:54,749 - INFO - Epoch 9/1000, Train Loss: 0.9495, Val Loss: 1.1242
2024-12-29 13:37:54,749 - INFO - Early stopping triggered at epoch 9
2024-12-29 13:37:54,749 - INFO - Training completed in 2.00s
2024-12-29 13:37:54,750 - INFO - Final memory usage: CPU 2717.8 MB, GPU 103.6 MB
2024-12-29 13:37:54,752 - INFO - Model training completed in 2.00s
2024-12-29 13:37:54,816 - INFO - Prediction completed in 0.06s
2024-12-29 13:37:54,825 - INFO - Poison rate 0.2 completed in 6.67s
2024-12-29 13:37:54,830 - INFO - Loaded 245 existing results
2024-12-29 13:37:54,830 - INFO - Total results to save: 252
2024-12-29 13:37:54,831 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:37:54,846 - INFO - Saved 252 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:37:54,847 - INFO - Total evaluation time: 87.06s
2024-12-29 13:37:54,851 - INFO - 
Progress: 38.5% - Evaluating ImageNette with RandomForest (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:37:55,069 - INFO - Loading datasets...
2024-12-29 13:37:55,091 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:37:55,091 - INFO - Extracting validation features...
2024-12-29 13:37:55,091 - INFO - Extracting features from 3925 samples...
2024-12-29 13:38:04,725 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:38:04,731 - INFO - Validation feature extraction completed in 9.64s
2024-12-29 13:38:04,731 - INFO - Extracting training features...
2024-12-29 13:38:04,731 - INFO - Extracting features from 9469 samples...
2024-12-29 13:38:26,937 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:38:26,941 - INFO - Training feature extraction completed in 22.21s
2024-12-29 13:38:26,941 - INFO - Creating model for classifier: RandomForest
2024-12-29 13:38:26,941 - INFO - Using device: cuda
2024-12-29 13:38:26,942 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:38:26,942 - INFO - Training set processing completed in 0.00s
2024-12-29 13:38:26,942 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:38:26,943 - INFO - Memory usage at start_fit: CPU 2681.0 MB, GPU 104.0 MB
2024-12-29 13:38:26,944 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:38:27,131 - INFO - Fitted scaler and transformed data
2024-12-29 13:38:27,132 - INFO - Scaling time: 0.19s
2024-12-29 13:38:27,139 - INFO - Number of unique classes: 10
2024-12-29 13:38:30,883 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3013
2024-12-29 13:38:34,332 - INFO - Epoch 2/10, Train Loss: 2.3006, Val Loss: 2.3000
2024-12-29 13:38:37,682 - INFO - Epoch 3/10, Train Loss: 2.2992, Val Loss: 2.2987
2024-12-29 13:38:41,100 - INFO - Epoch 4/10, Train Loss: 2.2977, Val Loss: 2.2974
2024-12-29 13:38:41,101 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:38:41,101 - INFO - Training completed in 14.16s
2024-12-29 13:38:41,101 - INFO - Final memory usage: CPU 2708.7 MB, GPU 125.9 MB
2024-12-29 13:38:41,101 - INFO - Model training completed in 14.16s
2024-12-29 13:38:41,329 - INFO - Prediction completed in 0.23s
2024-12-29 13:38:41,338 - INFO - Poison rate 0.0 completed in 14.40s
2024-12-29 13:38:41,338 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:38:41,340 - INFO - Total number of labels flipped: 94
2024-12-29 13:38:41,340 - INFO - Label flipping completed in 0.00s
2024-12-29 13:38:41,340 - INFO - Training set processing completed in 0.00s
2024-12-29 13:38:41,341 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:38:41,341 - INFO - Memory usage at start_fit: CPU 2708.7 MB, GPU 106.0 MB
2024-12-29 13:38:41,341 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:38:41,516 - INFO - Fitted scaler and transformed data
2024-12-29 13:38:41,517 - INFO - Scaling time: 0.18s
2024-12-29 13:38:41,527 - INFO - Number of unique classes: 10
2024-12-29 13:38:44,497 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3013
2024-12-29 13:38:47,544 - INFO - Epoch 2/10, Train Loss: 2.3006, Val Loss: 2.3001
2024-12-29 13:38:50,871 - INFO - Epoch 3/10, Train Loss: 2.2991, Val Loss: 2.2988
2024-12-29 13:38:54,658 - INFO - Epoch 4/10, Train Loss: 2.2977, Val Loss: 2.2975
2024-12-29 13:38:54,658 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:38:54,658 - INFO - Training completed in 13.32s
2024-12-29 13:38:54,659 - INFO - Final memory usage: CPU 2708.7 MB, GPU 125.9 MB
2024-12-29 13:38:54,659 - INFO - Model training completed in 13.32s
2024-12-29 13:38:54,809 - INFO - Prediction completed in 0.15s
2024-12-29 13:38:54,818 - INFO - Poison rate 0.01 completed in 13.48s
2024-12-29 13:38:54,818 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:38:54,823 - INFO - Total number of labels flipped: 284
2024-12-29 13:38:54,823 - INFO - Label flipping completed in 0.00s
2024-12-29 13:38:54,823 - INFO - Training set processing completed in 0.00s
2024-12-29 13:38:54,823 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:38:54,824 - INFO - Memory usage at start_fit: CPU 2708.7 MB, GPU 106.0 MB
2024-12-29 13:38:54,824 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:38:54,999 - INFO - Fitted scaler and transformed data
2024-12-29 13:38:55,000 - INFO - Scaling time: 0.18s
2024-12-29 13:38:55,010 - INFO - Number of unique classes: 10
2024-12-29 13:38:58,751 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3014
2024-12-29 13:39:02,360 - INFO - Epoch 2/10, Train Loss: 2.3007, Val Loss: 2.3002
2024-12-29 13:39:05,442 - INFO - Epoch 3/10, Train Loss: 2.2993, Val Loss: 2.2989
2024-12-29 13:39:08,710 - INFO - Epoch 4/10, Train Loss: 2.2979, Val Loss: 2.2977
2024-12-29 13:39:08,711 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:39:08,711 - INFO - Training completed in 13.89s
2024-12-29 13:39:08,711 - INFO - Final memory usage: CPU 2708.7 MB, GPU 125.9 MB
2024-12-29 13:39:08,711 - INFO - Model training completed in 13.89s
2024-12-29 13:39:08,948 - INFO - Prediction completed in 0.24s
2024-12-29 13:39:08,957 - INFO - Poison rate 0.03 completed in 14.14s
2024-12-29 13:39:08,957 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:39:08,963 - INFO - Total number of labels flipped: 473
2024-12-29 13:39:08,963 - INFO - Label flipping completed in 0.01s
2024-12-29 13:39:08,963 - INFO - Training set processing completed in 0.00s
2024-12-29 13:39:08,963 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:39:08,964 - INFO - Memory usage at start_fit: CPU 2708.7 MB, GPU 106.0 MB
2024-12-29 13:39:08,964 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:39:09,137 - INFO - Fitted scaler and transformed data
2024-12-29 13:39:09,137 - INFO - Scaling time: 0.17s
2024-12-29 13:39:09,147 - INFO - Number of unique classes: 10
2024-12-29 13:39:12,344 - INFO - Epoch 1/10, Train Loss: 2.3021, Val Loss: 2.3014
2024-12-29 13:39:15,716 - INFO - Epoch 2/10, Train Loss: 2.3007, Val Loss: 2.3003
2024-12-29 13:39:18,406 - INFO - Epoch 3/10, Train Loss: 2.2994, Val Loss: 2.2991
2024-12-29 13:39:21,368 - INFO - Epoch 4/10, Train Loss: 2.2981, Val Loss: 2.2978
2024-12-29 13:39:21,368 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:39:21,368 - INFO - Training completed in 12.40s
2024-12-29 13:39:21,369 - INFO - Final memory usage: CPU 2708.7 MB, GPU 125.9 MB
2024-12-29 13:39:21,369 - INFO - Model training completed in 12.41s
2024-12-29 13:39:21,561 - INFO - Prediction completed in 0.19s
2024-12-29 13:39:21,569 - INFO - Poison rate 0.05 completed in 12.61s
2024-12-29 13:39:21,570 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:39:21,578 - INFO - Total number of labels flipped: 662
2024-12-29 13:39:21,578 - INFO - Label flipping completed in 0.01s
2024-12-29 13:39:21,578 - INFO - Training set processing completed in 0.00s
2024-12-29 13:39:21,578 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:39:21,579 - INFO - Memory usage at start_fit: CPU 2708.7 MB, GPU 106.0 MB
2024-12-29 13:39:21,579 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:39:21,756 - INFO - Fitted scaler and transformed data
2024-12-29 13:39:21,756 - INFO - Scaling time: 0.18s
2024-12-29 13:39:21,767 - INFO - Number of unique classes: 10
2024-12-29 13:39:24,893 - INFO - Epoch 1/10, Train Loss: 2.3021, Val Loss: 2.3015
2024-12-29 13:39:28,675 - INFO - Epoch 2/10, Train Loss: 2.3008, Val Loss: 2.3004
2024-12-29 13:39:31,989 - INFO - Epoch 3/10, Train Loss: 2.2996, Val Loss: 2.2993
2024-12-29 13:39:35,314 - INFO - Epoch 4/10, Train Loss: 2.2983, Val Loss: 2.2981
2024-12-29 13:39:35,314 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:39:35,314 - INFO - Training completed in 13.74s
2024-12-29 13:39:35,315 - INFO - Final memory usage: CPU 2708.7 MB, GPU 125.9 MB
2024-12-29 13:39:35,315 - INFO - Model training completed in 13.74s
2024-12-29 13:39:35,531 - INFO - Prediction completed in 0.22s
2024-12-29 13:39:35,540 - INFO - Poison rate 0.07 completed in 13.97s
2024-12-29 13:39:35,540 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:39:35,551 - INFO - Total number of labels flipped: 946
2024-12-29 13:39:35,552 - INFO - Label flipping completed in 0.01s
2024-12-29 13:39:35,552 - INFO - Training set processing completed in 0.00s
2024-12-29 13:39:35,552 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:39:35,553 - INFO - Memory usage at start_fit: CPU 2708.7 MB, GPU 106.0 MB
2024-12-29 13:39:35,553 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:39:35,788 - INFO - Fitted scaler and transformed data
2024-12-29 13:39:35,788 - INFO - Scaling time: 0.24s
2024-12-29 13:39:35,799 - INFO - Number of unique classes: 10
2024-12-29 13:39:39,468 - INFO - Epoch 1/10, Train Loss: 2.3021, Val Loss: 2.3016
2024-12-29 13:39:42,727 - INFO - Epoch 2/10, Train Loss: 2.3009, Val Loss: 2.3005
2024-12-29 13:39:45,194 - INFO - Epoch 3/10, Train Loss: 2.2997, Val Loss: 2.2995
2024-12-29 13:39:48,283 - INFO - Epoch 4/10, Train Loss: 2.2985, Val Loss: 2.2984
2024-12-29 13:39:48,283 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:39:48,283 - INFO - Training completed in 12.73s
2024-12-29 13:39:48,283 - INFO - Final memory usage: CPU 2708.7 MB, GPU 125.9 MB
2024-12-29 13:39:48,284 - INFO - Model training completed in 12.73s
2024-12-29 13:39:48,466 - INFO - Prediction completed in 0.18s
2024-12-29 13:39:48,475 - INFO - Poison rate 0.1 completed in 12.93s
2024-12-29 13:39:48,475 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:39:48,497 - INFO - Total number of labels flipped: 1893
2024-12-29 13:39:48,497 - INFO - Label flipping completed in 0.02s
2024-12-29 13:39:48,497 - INFO - Training set processing completed in 0.00s
2024-12-29 13:39:48,497 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:39:48,498 - INFO - Memory usage at start_fit: CPU 2708.7 MB, GPU 106.0 MB
2024-12-29 13:39:48,498 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:39:48,673 - INFO - Fitted scaler and transformed data
2024-12-29 13:39:48,673 - INFO - Scaling time: 0.17s
2024-12-29 13:39:48,683 - INFO - Number of unique classes: 10
2024-12-29 13:39:51,750 - INFO - Epoch 1/10, Train Loss: 2.3022, Val Loss: 2.3017
2024-12-29 13:39:54,608 - INFO - Epoch 2/10, Train Loss: 2.3012, Val Loss: 2.3008
2024-12-29 13:39:57,997 - INFO - Epoch 3/10, Train Loss: 2.3002, Val Loss: 2.3000
2024-12-29 13:40:00,865 - INFO - Epoch 4/10, Train Loss: 2.2992, Val Loss: 2.2991
2024-12-29 13:40:00,865 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:40:00,865 - INFO - Training completed in 12.37s
2024-12-29 13:40:00,866 - INFO - Final memory usage: CPU 2708.7 MB, GPU 125.9 MB
2024-12-29 13:40:00,866 - INFO - Model training completed in 12.37s
2024-12-29 13:40:01,057 - INFO - Prediction completed in 0.19s
2024-12-29 13:40:01,066 - INFO - Poison rate 0.2 completed in 12.59s
2024-12-29 13:40:01,071 - INFO - Loaded 252 existing results
2024-12-29 13:40:01,071 - INFO - Total results to save: 259
2024-12-29 13:40:01,072 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:40:01,081 - INFO - Saved 259 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:40:01,081 - INFO - Total evaluation time: 126.01s
2024-12-29 13:40:01,083 - INFO - 
Progress: 39.6% - Evaluating ImageNette with RandomForest (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:40:01,295 - INFO - Loading datasets...
2024-12-29 13:40:01,317 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:40:01,317 - INFO - Extracting validation features...
2024-12-29 13:40:01,317 - INFO - Extracting features from 3925 samples...
2024-12-29 13:40:10,394 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:40:10,398 - INFO - Validation feature extraction completed in 9.08s
2024-12-29 13:40:10,398 - INFO - Extracting training features...
2024-12-29 13:40:10,398 - INFO - Extracting features from 9469 samples...
2024-12-29 13:40:31,998 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:40:32,006 - INFO - Training feature extraction completed in 21.61s
2024-12-29 13:40:32,007 - INFO - Creating model for classifier: RandomForest
2024-12-29 13:40:32,007 - INFO - Using device: cuda
2024-12-29 13:40:32,008 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:40:32,008 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:40:32,008 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:40:32,567 - INFO - Feature scaling completed in 0.56s
2024-12-29 13:40:32,567 - INFO - Starting feature selection (k=50)
2024-12-29 13:40:32,576 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:40:32,576 - INFO - Starting anomaly detection
2024-12-29 13:40:36,207 - INFO - Anomaly detection completed in 3.63s
2024-12-29 13:40:36,207 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:40:36,207 - INFO - Total fit_transform time: 4.20s
2024-12-29 13:40:36,207 - INFO - Training set processing completed in 4.20s
2024-12-29 13:40:36,207 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:40:36,209 - INFO - Memory usage at start_fit: CPU 2708.8 MB, GPU 103.4 MB
2024-12-29 13:40:36,209 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:40:36,406 - INFO - Fitted scaler and transformed data
2024-12-29 13:40:36,406 - INFO - Scaling time: 0.20s
2024-12-29 13:40:36,413 - INFO - Number of unique classes: 10
2024-12-29 13:40:39,209 - INFO - Epoch 1/10, Train Loss: 2.1861, Val Loss: 2.3013
2024-12-29 13:40:42,070 - INFO - Epoch 2/10, Train Loss: 2.1847, Val Loss: 2.3000
2024-12-29 13:40:45,213 - INFO - Epoch 3/10, Train Loss: 2.1834, Val Loss: 2.2987
2024-12-29 13:40:48,301 - INFO - Epoch 4/10, Train Loss: 2.1820, Val Loss: 2.2974
2024-12-29 13:40:48,301 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:40:48,301 - INFO - Training completed in 12.09s
2024-12-29 13:40:48,301 - INFO - Final memory usage: CPU 2708.8 MB, GPU 125.3 MB
2024-12-29 13:40:48,302 - INFO - Model training completed in 12.09s
2024-12-29 13:40:48,495 - INFO - Prediction completed in 0.19s
2024-12-29 13:40:48,504 - INFO - Poison rate 0.0 completed in 16.50s
2024-12-29 13:40:48,504 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:40:48,506 - INFO - Total number of labels flipped: 94
2024-12-29 13:40:48,506 - INFO - Label flipping completed in 0.00s
2024-12-29 13:40:48,507 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:40:48,507 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:40:49,016 - INFO - Feature scaling completed in 0.51s
2024-12-29 13:40:49,016 - INFO - Starting feature selection (k=50)
2024-12-29 13:40:49,029 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:40:49,029 - INFO - Starting anomaly detection
2024-12-29 13:40:53,210 - INFO - Anomaly detection completed in 4.18s
2024-12-29 13:40:53,210 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:40:53,210 - INFO - Total fit_transform time: 4.70s
2024-12-29 13:40:53,210 - INFO - Training set processing completed in 4.70s
2024-12-29 13:40:53,211 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:40:53,211 - INFO - Memory usage at start_fit: CPU 2708.8 MB, GPU 105.4 MB
2024-12-29 13:40:53,212 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:40:53,388 - INFO - Fitted scaler and transformed data
2024-12-29 13:40:53,389 - INFO - Scaling time: 0.18s
2024-12-29 13:40:53,395 - INFO - Number of unique classes: 10
2024-12-29 13:40:56,215 - INFO - Epoch 1/10, Train Loss: 2.1888, Val Loss: 2.3013
2024-12-29 13:40:58,927 - INFO - Epoch 2/10, Train Loss: 2.1875, Val Loss: 2.3001
2024-12-29 13:41:01,934 - INFO - Epoch 3/10, Train Loss: 2.1862, Val Loss: 2.2988
2024-12-29 13:41:05,002 - INFO - Epoch 4/10, Train Loss: 2.1848, Val Loss: 2.2975
2024-12-29 13:41:05,002 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:41:05,003 - INFO - Training completed in 11.79s
2024-12-29 13:41:05,003 - INFO - Final memory usage: CPU 2708.8 MB, GPU 125.3 MB
2024-12-29 13:41:05,004 - INFO - Model training completed in 11.79s
2024-12-29 13:41:05,158 - INFO - Prediction completed in 0.15s
2024-12-29 13:41:05,167 - INFO - Poison rate 0.01 completed in 16.66s
2024-12-29 13:41:05,167 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:41:05,171 - INFO - Total number of labels flipped: 284
2024-12-29 13:41:05,171 - INFO - Label flipping completed in 0.00s
2024-12-29 13:41:05,171 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:41:05,171 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:41:05,750 - INFO - Feature scaling completed in 0.58s
2024-12-29 13:41:05,750 - INFO - Starting feature selection (k=50)
2024-12-29 13:41:05,764 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:41:05,765 - INFO - Starting anomaly detection
2024-12-29 13:41:09,535 - INFO - Anomaly detection completed in 3.77s
2024-12-29 13:41:09,535 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:41:09,535 - INFO - Total fit_transform time: 4.36s
2024-12-29 13:41:09,536 - INFO - Training set processing completed in 4.36s
2024-12-29 13:41:09,536 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:41:09,536 - INFO - Memory usage at start_fit: CPU 2708.8 MB, GPU 105.4 MB
2024-12-29 13:41:09,537 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:41:09,730 - INFO - Fitted scaler and transformed data
2024-12-29 13:41:09,730 - INFO - Scaling time: 0.19s
2024-12-29 13:41:09,737 - INFO - Number of unique classes: 10
2024-12-29 13:41:12,978 - INFO - Epoch 1/10, Train Loss: 2.1855, Val Loss: 2.3014
2024-12-29 13:41:15,994 - INFO - Epoch 2/10, Train Loss: 2.1842, Val Loss: 2.3002
2024-12-29 13:41:18,992 - INFO - Epoch 3/10, Train Loss: 2.1829, Val Loss: 2.2989
2024-12-29 13:41:21,870 - INFO - Epoch 4/10, Train Loss: 2.1816, Val Loss: 2.2977
2024-12-29 13:41:21,871 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:41:21,871 - INFO - Training completed in 12.33s
2024-12-29 13:41:21,871 - INFO - Final memory usage: CPU 2708.8 MB, GPU 125.3 MB
2024-12-29 13:41:21,871 - INFO - Model training completed in 12.34s
2024-12-29 13:41:22,064 - INFO - Prediction completed in 0.19s
2024-12-29 13:41:22,073 - INFO - Poison rate 0.03 completed in 16.91s
2024-12-29 13:41:22,073 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:41:22,079 - INFO - Total number of labels flipped: 473
2024-12-29 13:41:22,079 - INFO - Label flipping completed in 0.01s
2024-12-29 13:41:22,080 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:41:22,080 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:41:22,604 - INFO - Feature scaling completed in 0.52s
2024-12-29 13:41:22,604 - INFO - Starting feature selection (k=50)
2024-12-29 13:41:22,617 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:41:22,618 - INFO - Starting anomaly detection
2024-12-29 13:41:26,442 - INFO - Anomaly detection completed in 3.82s
2024-12-29 13:41:26,443 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:41:26,443 - INFO - Total fit_transform time: 4.36s
2024-12-29 13:41:26,443 - INFO - Training set processing completed in 4.36s
2024-12-29 13:41:26,443 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:41:26,444 - INFO - Memory usage at start_fit: CPU 2708.8 MB, GPU 105.4 MB
2024-12-29 13:41:26,444 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:41:26,681 - INFO - Fitted scaler and transformed data
2024-12-29 13:41:26,681 - INFO - Scaling time: 0.24s
2024-12-29 13:41:26,688 - INFO - Number of unique classes: 10
2024-12-29 13:41:29,197 - INFO - Epoch 1/10, Train Loss: 2.1864, Val Loss: 2.3014
2024-12-29 13:41:32,995 - INFO - Epoch 2/10, Train Loss: 2.1852, Val Loss: 2.3002
2024-12-29 13:41:36,529 - INFO - Epoch 3/10, Train Loss: 2.1840, Val Loss: 2.2990
2024-12-29 13:41:39,664 - INFO - Epoch 4/10, Train Loss: 2.1827, Val Loss: 2.2978
2024-12-29 13:41:39,664 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:41:39,664 - INFO - Training completed in 13.22s
2024-12-29 13:41:39,664 - INFO - Final memory usage: CPU 2708.8 MB, GPU 125.3 MB
2024-12-29 13:41:39,665 - INFO - Model training completed in 13.22s
2024-12-29 13:41:39,811 - INFO - Prediction completed in 0.15s
2024-12-29 13:41:39,820 - INFO - Poison rate 0.05 completed in 17.75s
2024-12-29 13:41:39,820 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:41:39,829 - INFO - Total number of labels flipped: 662
2024-12-29 13:41:39,829 - INFO - Label flipping completed in 0.01s
2024-12-29 13:41:39,829 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:41:39,829 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:41:40,421 - INFO - Feature scaling completed in 0.59s
2024-12-29 13:41:40,422 - INFO - Starting feature selection (k=50)
2024-12-29 13:41:40,435 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:41:40,435 - INFO - Starting anomaly detection
2024-12-29 13:41:44,660 - INFO - Anomaly detection completed in 4.22s
2024-12-29 13:41:44,660 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:41:44,660 - INFO - Total fit_transform time: 4.83s
2024-12-29 13:41:44,660 - INFO - Training set processing completed in 4.83s
2024-12-29 13:41:44,660 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:41:44,661 - INFO - Memory usage at start_fit: CPU 2708.8 MB, GPU 105.4 MB
2024-12-29 13:41:44,661 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:41:44,888 - INFO - Fitted scaler and transformed data
2024-12-29 13:41:44,888 - INFO - Scaling time: 0.23s
2024-12-29 13:41:44,899 - INFO - Number of unique classes: 10
2024-12-29 13:41:48,099 - INFO - Epoch 1/10, Train Loss: 2.1876, Val Loss: 2.3015
2024-12-29 13:41:50,704 - INFO - Epoch 2/10, Train Loss: 2.1864, Val Loss: 2.3003
2024-12-29 13:41:53,427 - INFO - Epoch 3/10, Train Loss: 2.1852, Val Loss: 2.2992
2024-12-29 13:41:55,904 - INFO - Epoch 4/10, Train Loss: 2.1840, Val Loss: 2.2980
2024-12-29 13:41:55,904 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:41:55,904 - INFO - Training completed in 11.24s
2024-12-29 13:41:55,905 - INFO - Final memory usage: CPU 2708.8 MB, GPU 125.3 MB
2024-12-29 13:41:55,905 - INFO - Model training completed in 11.24s
2024-12-29 13:41:56,065 - INFO - Prediction completed in 0.16s
2024-12-29 13:41:56,073 - INFO - Poison rate 0.07 completed in 16.25s
2024-12-29 13:41:56,074 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:41:56,085 - INFO - Total number of labels flipped: 946
2024-12-29 13:41:56,085 - INFO - Label flipping completed in 0.01s
2024-12-29 13:41:56,085 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:41:56,086 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:41:56,623 - INFO - Feature scaling completed in 0.54s
2024-12-29 13:41:56,623 - INFO - Starting feature selection (k=50)
2024-12-29 13:41:56,637 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:41:56,637 - INFO - Starting anomaly detection
2024-12-29 13:41:59,704 - INFO - Anomaly detection completed in 3.07s
2024-12-29 13:41:59,704 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:41:59,704 - INFO - Total fit_transform time: 3.62s
2024-12-29 13:41:59,704 - INFO - Training set processing completed in 3.62s
2024-12-29 13:41:59,704 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:41:59,705 - INFO - Memory usage at start_fit: CPU 2708.8 MB, GPU 105.4 MB
2024-12-29 13:41:59,706 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:41:59,881 - INFO - Fitted scaler and transformed data
2024-12-29 13:41:59,881 - INFO - Scaling time: 0.18s
2024-12-29 13:41:59,893 - INFO - Number of unique classes: 10
2024-12-29 13:42:03,292 - INFO - Epoch 1/10, Train Loss: 2.1850, Val Loss: 2.3015
2024-12-29 13:42:06,335 - INFO - Epoch 2/10, Train Loss: 2.1839, Val Loss: 2.3004
2024-12-29 13:42:09,127 - INFO - Epoch 3/10, Train Loss: 2.1827, Val Loss: 2.2993
2024-12-29 13:42:12,145 - INFO - Epoch 4/10, Train Loss: 2.1816, Val Loss: 2.2981
2024-12-29 13:42:12,146 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:42:12,146 - INFO - Training completed in 12.44s
2024-12-29 13:42:12,146 - INFO - Final memory usage: CPU 2708.8 MB, GPU 125.3 MB
2024-12-29 13:42:12,146 - INFO - Model training completed in 12.44s
2024-12-29 13:42:12,296 - INFO - Prediction completed in 0.15s
2024-12-29 13:42:12,305 - INFO - Poison rate 0.1 completed in 16.23s
2024-12-29 13:42:12,305 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:42:12,327 - INFO - Total number of labels flipped: 1893
2024-12-29 13:42:12,328 - INFO - Label flipping completed in 0.02s
2024-12-29 13:42:12,328 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:42:12,328 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:42:12,901 - INFO - Feature scaling completed in 0.57s
2024-12-29 13:42:12,901 - INFO - Starting feature selection (k=50)
2024-12-29 13:42:12,914 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:42:12,914 - INFO - Starting anomaly detection
2024-12-29 13:42:15,652 - INFO - Anomaly detection completed in 2.74s
2024-12-29 13:42:15,652 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:42:15,652 - INFO - Total fit_transform time: 3.32s
2024-12-29 13:42:15,652 - INFO - Training set processing completed in 3.32s
2024-12-29 13:42:15,652 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:42:15,653 - INFO - Memory usage at start_fit: CPU 2708.8 MB, GPU 105.4 MB
2024-12-29 13:42:15,653 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:42:15,824 - INFO - Fitted scaler and transformed data
2024-12-29 13:42:15,824 - INFO - Scaling time: 0.17s
2024-12-29 13:42:15,830 - INFO - Number of unique classes: 10
2024-12-29 13:42:18,422 - INFO - Epoch 1/10, Train Loss: 2.1876, Val Loss: 2.3017
2024-12-29 13:42:21,083 - INFO - Epoch 2/10, Train Loss: 2.1866, Val Loss: 2.3008
2024-12-29 13:42:24,454 - INFO - Epoch 3/10, Train Loss: 2.1856, Val Loss: 2.3000
2024-12-29 13:42:27,525 - INFO - Epoch 4/10, Train Loss: 2.1847, Val Loss: 2.2991
2024-12-29 13:42:27,525 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:42:27,525 - INFO - Training completed in 11.87s
2024-12-29 13:42:27,526 - INFO - Final memory usage: CPU 2708.8 MB, GPU 125.3 MB
2024-12-29 13:42:27,526 - INFO - Model training completed in 11.87s
2024-12-29 13:42:27,674 - INFO - Prediction completed in 0.15s
2024-12-29 13:42:27,683 - INFO - Poison rate 0.2 completed in 15.38s
2024-12-29 13:42:27,688 - INFO - Loaded 259 existing results
2024-12-29 13:42:27,688 - INFO - Total results to save: 266
2024-12-29 13:42:27,689 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:42:27,699 - INFO - Saved 266 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:42:27,699 - INFO - Total evaluation time: 146.40s
2024-12-29 13:42:27,701 - INFO - 
Progress: 40.6% - Evaluating ImageNette with KNeighbors (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:42:27,888 - INFO - Loading datasets...
2024-12-29 13:42:27,919 - INFO - Dataset loading completed in 0.03s
2024-12-29 13:42:27,919 - INFO - Extracting validation features...
2024-12-29 13:42:27,919 - INFO - Extracting features from 3925 samples...
2024-12-29 13:42:37,198 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:42:37,204 - INFO - Validation feature extraction completed in 9.29s
2024-12-29 13:42:37,205 - INFO - Extracting training features...
2024-12-29 13:42:37,205 - INFO - Extracting features from 9469 samples...
2024-12-29 13:42:59,569 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:42:59,577 - INFO - Training feature extraction completed in 22.37s
2024-12-29 13:42:59,578 - INFO - Creating model for classifier: KNeighbors
2024-12-29 13:42:59,578 - INFO - Using device: cuda
2024-12-29 13:42:59,578 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:42:59,579 - INFO - Training set processing completed in 0.00s
2024-12-29 13:42:59,579 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:42:59,580 - INFO - Memory usage at start_fit: CPU 2681.3 MB, GPU 104.0 MB
2024-12-29 13:42:59,580 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:42:59,777 - INFO - Fitted scaler and transformed data
2024-12-29 13:42:59,777 - INFO - Scaling time: 0.20s
2024-12-29 13:42:59,784 - INFO - Training completed in 0.20s
2024-12-29 13:42:59,785 - INFO - Final memory usage: CPU 2708.8 MB, GPU 122.6 MB
2024-12-29 13:42:59,785 - INFO - Model training completed in 0.21s
2024-12-29 13:42:59,858 - INFO - Prediction completed in 0.07s
2024-12-29 13:42:59,867 - INFO - Poison rate 0.0 completed in 0.29s
2024-12-29 13:42:59,867 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:42:59,869 - INFO - Total number of labels flipped: 94
2024-12-29 13:42:59,869 - INFO - Label flipping completed in 0.00s
2024-12-29 13:42:59,869 - INFO - Training set processing completed in 0.00s
2024-12-29 13:42:59,869 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:42:59,870 - INFO - Memory usage at start_fit: CPU 2708.9 MB, GPU 122.6 MB
2024-12-29 13:42:59,870 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:43:00,043 - INFO - Fitted scaler and transformed data
2024-12-29 13:43:00,043 - INFO - Scaling time: 0.17s
2024-12-29 13:43:00,050 - INFO - Training completed in 0.18s
2024-12-29 13:43:00,051 - INFO - Final memory usage: CPU 2708.9 MB, GPU 122.6 MB
2024-12-29 13:43:00,051 - INFO - Model training completed in 0.18s
2024-12-29 13:43:00,133 - INFO - Prediction completed in 0.08s
2024-12-29 13:43:00,143 - INFO - Poison rate 0.01 completed in 0.28s
2024-12-29 13:43:00,143 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:43:00,147 - INFO - Total number of labels flipped: 284
2024-12-29 13:43:00,147 - INFO - Label flipping completed in 0.00s
2024-12-29 13:43:00,147 - INFO - Training set processing completed in 0.00s
2024-12-29 13:43:00,147 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:43:00,148 - INFO - Memory usage at start_fit: CPU 2708.9 MB, GPU 122.6 MB
2024-12-29 13:43:00,148 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:43:00,345 - INFO - Fitted scaler and transformed data
2024-12-29 13:43:00,345 - INFO - Scaling time: 0.20s
2024-12-29 13:43:00,351 - INFO - Training completed in 0.20s
2024-12-29 13:43:00,352 - INFO - Final memory usage: CPU 2708.9 MB, GPU 122.6 MB
2024-12-29 13:43:00,352 - INFO - Model training completed in 0.20s
2024-12-29 13:43:00,438 - INFO - Prediction completed in 0.09s
2024-12-29 13:43:00,446 - INFO - Poison rate 0.03 completed in 0.30s
2024-12-29 13:43:00,446 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:43:00,461 - INFO - Total number of labels flipped: 473
2024-12-29 13:43:00,462 - INFO - Label flipping completed in 0.02s
2024-12-29 13:43:00,462 - INFO - Training set processing completed in 0.00s
2024-12-29 13:43:00,462 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:43:00,463 - INFO - Memory usage at start_fit: CPU 2708.9 MB, GPU 122.6 MB
2024-12-29 13:43:00,464 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:43:00,650 - INFO - Fitted scaler and transformed data
2024-12-29 13:43:00,650 - INFO - Scaling time: 0.19s
2024-12-29 13:43:00,657 - INFO - Training completed in 0.19s
2024-12-29 13:43:00,657 - INFO - Final memory usage: CPU 2708.9 MB, GPU 122.6 MB
2024-12-29 13:43:00,657 - INFO - Model training completed in 0.20s
2024-12-29 13:43:00,736 - INFO - Prediction completed in 0.08s
2024-12-29 13:43:00,744 - INFO - Poison rate 0.05 completed in 0.30s
2024-12-29 13:43:00,744 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:43:00,753 - INFO - Total number of labels flipped: 662
2024-12-29 13:43:00,754 - INFO - Label flipping completed in 0.01s
2024-12-29 13:43:00,754 - INFO - Training set processing completed in 0.00s
2024-12-29 13:43:00,754 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:43:00,754 - INFO - Memory usage at start_fit: CPU 2708.9 MB, GPU 122.6 MB
2024-12-29 13:43:00,755 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:43:00,928 - INFO - Fitted scaler and transformed data
2024-12-29 13:43:00,928 - INFO - Scaling time: 0.17s
2024-12-29 13:43:00,934 - INFO - Training completed in 0.18s
2024-12-29 13:43:00,935 - INFO - Final memory usage: CPU 2708.9 MB, GPU 122.6 MB
2024-12-29 13:43:00,935 - INFO - Model training completed in 0.18s
2024-12-29 13:43:01,017 - INFO - Prediction completed in 0.08s
2024-12-29 13:43:01,026 - INFO - Poison rate 0.07 completed in 0.28s
2024-12-29 13:43:01,026 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:43:01,037 - INFO - Total number of labels flipped: 946
2024-12-29 13:43:01,038 - INFO - Label flipping completed in 0.01s
2024-12-29 13:43:01,038 - INFO - Training set processing completed in 0.00s
2024-12-29 13:43:01,038 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:43:01,039 - INFO - Memory usage at start_fit: CPU 2708.9 MB, GPU 122.6 MB
2024-12-29 13:43:01,039 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:43:01,237 - INFO - Fitted scaler and transformed data
2024-12-29 13:43:01,238 - INFO - Scaling time: 0.20s
2024-12-29 13:43:01,244 - INFO - Training completed in 0.21s
2024-12-29 13:43:01,245 - INFO - Final memory usage: CPU 2708.9 MB, GPU 122.6 MB
2024-12-29 13:43:01,245 - INFO - Model training completed in 0.21s
2024-12-29 13:43:01,328 - INFO - Prediction completed in 0.08s
2024-12-29 13:43:01,351 - INFO - Poison rate 0.1 completed in 0.33s
2024-12-29 13:43:01,352 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:43:01,378 - INFO - Total number of labels flipped: 1893
2024-12-29 13:43:01,378 - INFO - Label flipping completed in 0.03s
2024-12-29 13:43:01,378 - INFO - Training set processing completed in 0.00s
2024-12-29 13:43:01,378 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:43:01,379 - INFO - Memory usage at start_fit: CPU 2708.9 MB, GPU 122.6 MB
2024-12-29 13:43:01,379 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:43:01,548 - INFO - Fitted scaler and transformed data
2024-12-29 13:43:01,548 - INFO - Scaling time: 0.17s
2024-12-29 13:43:01,555 - INFO - Training completed in 0.18s
2024-12-29 13:43:01,555 - INFO - Final memory usage: CPU 2708.9 MB, GPU 122.6 MB
2024-12-29 13:43:01,556 - INFO - Model training completed in 0.18s
2024-12-29 13:43:01,629 - INFO - Prediction completed in 0.07s
2024-12-29 13:43:01,638 - INFO - Poison rate 0.2 completed in 0.29s
2024-12-29 13:43:01,644 - INFO - Loaded 266 existing results
2024-12-29 13:43:01,644 - INFO - Total results to save: 273
2024-12-29 13:43:01,645 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:43:01,655 - INFO - Saved 273 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:43:01,655 - INFO - Total evaluation time: 33.77s
2024-12-29 13:43:01,657 - INFO - 
Progress: 41.7% - Evaluating ImageNette with KNeighbors (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:43:01,833 - INFO - Loading datasets...
2024-12-29 13:43:01,864 - INFO - Dataset loading completed in 0.03s
2024-12-29 13:43:01,864 - INFO - Extracting validation features...
2024-12-29 13:43:01,864 - INFO - Extracting features from 3925 samples...
2024-12-29 13:43:11,336 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:43:11,341 - INFO - Validation feature extraction completed in 9.48s
2024-12-29 13:43:11,341 - INFO - Extracting training features...
2024-12-29 13:43:11,341 - INFO - Extracting features from 9469 samples...
2024-12-29 13:43:33,546 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:43:33,555 - INFO - Training feature extraction completed in 22.21s
2024-12-29 13:43:33,556 - INFO - Creating model for classifier: KNeighbors
2024-12-29 13:43:33,556 - INFO - Using device: cuda
2024-12-29 13:43:33,556 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:43:33,556 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:43:33,556 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:43:34,127 - INFO - Feature scaling completed in 0.57s
2024-12-29 13:43:34,127 - INFO - Starting feature selection (k=50)
2024-12-29 13:43:34,135 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:43:34,136 - INFO - Starting anomaly detection
2024-12-29 13:43:37,859 - INFO - Anomaly detection completed in 3.72s
2024-12-29 13:43:37,859 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:43:37,859 - INFO - Total fit_transform time: 4.30s
2024-12-29 13:43:37,859 - INFO - Training set processing completed in 4.30s
2024-12-29 13:43:37,859 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:43:37,860 - INFO - Memory usage at start_fit: CPU 2709.2 MB, GPU 103.4 MB
2024-12-29 13:43:37,860 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:43:38,056 - INFO - Fitted scaler and transformed data
2024-12-29 13:43:38,056 - INFO - Scaling time: 0.20s
2024-12-29 13:43:38,063 - INFO - Training completed in 0.20s
2024-12-29 13:43:38,064 - INFO - Final memory usage: CPU 2709.2 MB, GPU 121.9 MB
2024-12-29 13:43:38,064 - INFO - Model training completed in 0.20s
2024-12-29 13:43:38,165 - INFO - Prediction completed in 0.10s
2024-12-29 13:43:38,174 - INFO - Poison rate 0.0 completed in 4.62s
2024-12-29 13:43:38,174 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:43:38,176 - INFO - Total number of labels flipped: 94
2024-12-29 13:43:38,177 - INFO - Label flipping completed in 0.00s
2024-12-29 13:43:38,177 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:43:38,177 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:43:38,723 - INFO - Feature scaling completed in 0.55s
2024-12-29 13:43:38,723 - INFO - Starting feature selection (k=50)
2024-12-29 13:43:38,735 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:43:38,735 - INFO - Starting anomaly detection
2024-12-29 13:43:42,992 - INFO - Anomaly detection completed in 4.26s
2024-12-29 13:43:42,992 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:43:42,992 - INFO - Total fit_transform time: 4.82s
2024-12-29 13:43:42,993 - INFO - Training set processing completed in 4.82s
2024-12-29 13:43:42,993 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:43:42,994 - INFO - Memory usage at start_fit: CPU 2709.2 MB, GPU 121.9 MB
2024-12-29 13:43:42,994 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:43:43,199 - INFO - Fitted scaler and transformed data
2024-12-29 13:43:43,199 - INFO - Scaling time: 0.21s
2024-12-29 13:43:43,205 - INFO - Training completed in 0.21s
2024-12-29 13:43:43,206 - INFO - Final memory usage: CPU 2709.2 MB, GPU 121.9 MB
2024-12-29 13:43:43,208 - INFO - Model training completed in 0.22s
2024-12-29 13:43:43,310 - INFO - Prediction completed in 0.10s
2024-12-29 13:43:43,321 - INFO - Poison rate 0.01 completed in 5.15s
2024-12-29 13:43:43,321 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:43:43,326 - INFO - Total number of labels flipped: 284
2024-12-29 13:43:43,326 - INFO - Label flipping completed in 0.00s
2024-12-29 13:43:43,326 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:43:43,326 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:43:43,912 - INFO - Feature scaling completed in 0.58s
2024-12-29 13:43:43,912 - INFO - Starting feature selection (k=50)
2024-12-29 13:43:43,920 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:43:43,920 - INFO - Starting anomaly detection
2024-12-29 13:43:47,495 - INFO - Anomaly detection completed in 3.57s
2024-12-29 13:43:47,495 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:43:47,495 - INFO - Total fit_transform time: 4.17s
2024-12-29 13:43:47,495 - INFO - Training set processing completed in 4.17s
2024-12-29 13:43:47,496 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:43:47,497 - INFO - Memory usage at start_fit: CPU 2709.2 MB, GPU 121.9 MB
2024-12-29 13:43:47,497 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:43:47,676 - INFO - Fitted scaler and transformed data
2024-12-29 13:43:47,676 - INFO - Scaling time: 0.18s
2024-12-29 13:43:47,683 - INFO - Training completed in 0.19s
2024-12-29 13:43:47,684 - INFO - Final memory usage: CPU 2709.2 MB, GPU 121.9 MB
2024-12-29 13:43:47,684 - INFO - Model training completed in 0.19s
2024-12-29 13:43:47,809 - INFO - Prediction completed in 0.12s
2024-12-29 13:43:47,817 - INFO - Poison rate 0.03 completed in 4.50s
2024-12-29 13:43:47,817 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:43:47,824 - INFO - Total number of labels flipped: 473
2024-12-29 13:43:47,824 - INFO - Label flipping completed in 0.01s
2024-12-29 13:43:47,824 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:43:47,824 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:43:48,405 - INFO - Feature scaling completed in 0.58s
2024-12-29 13:43:48,405 - INFO - Starting feature selection (k=50)
2024-12-29 13:43:48,417 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:43:48,417 - INFO - Starting anomaly detection
2024-12-29 13:43:52,408 - INFO - Anomaly detection completed in 3.99s
2024-12-29 13:43:52,408 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:43:52,409 - INFO - Total fit_transform time: 4.58s
2024-12-29 13:43:52,409 - INFO - Training set processing completed in 4.59s
2024-12-29 13:43:52,409 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:43:52,411 - INFO - Memory usage at start_fit: CPU 2709.2 MB, GPU 121.9 MB
2024-12-29 13:43:52,411 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:43:52,657 - INFO - Fitted scaler and transformed data
2024-12-29 13:43:52,658 - INFO - Scaling time: 0.25s
2024-12-29 13:43:52,664 - INFO - Training completed in 0.25s
2024-12-29 13:43:52,664 - INFO - Final memory usage: CPU 2709.2 MB, GPU 121.9 MB
2024-12-29 13:43:52,665 - INFO - Model training completed in 0.26s
2024-12-29 13:43:52,766 - INFO - Prediction completed in 0.10s
2024-12-29 13:43:52,775 - INFO - Poison rate 0.05 completed in 4.96s
2024-12-29 13:43:52,776 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:43:52,784 - INFO - Total number of labels flipped: 662
2024-12-29 13:43:52,784 - INFO - Label flipping completed in 0.01s
2024-12-29 13:43:52,784 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:43:52,784 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:43:53,298 - INFO - Feature scaling completed in 0.51s
2024-12-29 13:43:53,298 - INFO - Starting feature selection (k=50)
2024-12-29 13:43:53,306 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:43:53,307 - INFO - Starting anomaly detection
2024-12-29 13:43:57,010 - INFO - Anomaly detection completed in 3.70s
2024-12-29 13:43:57,011 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:43:57,011 - INFO - Total fit_transform time: 4.23s
2024-12-29 13:43:57,011 - INFO - Training set processing completed in 4.23s
2024-12-29 13:43:57,011 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:43:57,012 - INFO - Memory usage at start_fit: CPU 2709.2 MB, GPU 121.9 MB
2024-12-29 13:43:57,012 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:43:57,242 - INFO - Fitted scaler and transformed data
2024-12-29 13:43:57,242 - INFO - Scaling time: 0.23s
2024-12-29 13:43:57,249 - INFO - Training completed in 0.24s
2024-12-29 13:43:57,249 - INFO - Final memory usage: CPU 2709.2 MB, GPU 121.9 MB
2024-12-29 13:43:57,250 - INFO - Model training completed in 0.24s
2024-12-29 13:43:57,361 - INFO - Prediction completed in 0.11s
2024-12-29 13:43:57,370 - INFO - Poison rate 0.07 completed in 4.59s
2024-12-29 13:43:57,371 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:43:57,382 - INFO - Total number of labels flipped: 946
2024-12-29 13:43:57,383 - INFO - Label flipping completed in 0.01s
2024-12-29 13:43:57,383 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:43:57,383 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:43:57,894 - INFO - Feature scaling completed in 0.51s
2024-12-29 13:43:57,895 - INFO - Starting feature selection (k=50)
2024-12-29 13:43:57,906 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:43:57,906 - INFO - Starting anomaly detection
2024-12-29 13:44:00,870 - INFO - Anomaly detection completed in 2.96s
2024-12-29 13:44:00,870 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:44:00,870 - INFO - Total fit_transform time: 3.49s
2024-12-29 13:44:00,870 - INFO - Training set processing completed in 3.49s
2024-12-29 13:44:00,870 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:44:00,871 - INFO - Memory usage at start_fit: CPU 2709.2 MB, GPU 121.9 MB
2024-12-29 13:44:00,871 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:44:01,047 - INFO - Fitted scaler and transformed data
2024-12-29 13:44:01,048 - INFO - Scaling time: 0.18s
2024-12-29 13:44:01,055 - INFO - Training completed in 0.18s
2024-12-29 13:44:01,055 - INFO - Final memory usage: CPU 2709.2 MB, GPU 121.9 MB
2024-12-29 13:44:01,055 - INFO - Model training completed in 0.19s
2024-12-29 13:44:01,157 - INFO - Prediction completed in 0.10s
2024-12-29 13:44:01,169 - INFO - Poison rate 0.1 completed in 3.80s
2024-12-29 13:44:01,169 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:44:01,191 - INFO - Total number of labels flipped: 1893
2024-12-29 13:44:01,191 - INFO - Label flipping completed in 0.02s
2024-12-29 13:44:01,191 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:44:01,191 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:44:01,704 - INFO - Feature scaling completed in 0.51s
2024-12-29 13:44:01,704 - INFO - Starting feature selection (k=50)
2024-12-29 13:44:01,713 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:44:01,713 - INFO - Starting anomaly detection
2024-12-29 13:44:04,418 - INFO - Anomaly detection completed in 2.70s
2024-12-29 13:44:04,418 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:44:04,418 - INFO - Total fit_transform time: 3.23s
2024-12-29 13:44:04,418 - INFO - Training set processing completed in 3.23s
2024-12-29 13:44:04,418 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:44:04,419 - INFO - Memory usage at start_fit: CPU 2709.2 MB, GPU 121.9 MB
2024-12-29 13:44:04,419 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:44:04,596 - INFO - Fitted scaler and transformed data
2024-12-29 13:44:04,596 - INFO - Scaling time: 0.18s
2024-12-29 13:44:04,603 - INFO - Training completed in 0.18s
2024-12-29 13:44:04,603 - INFO - Final memory usage: CPU 2709.2 MB, GPU 121.9 MB
2024-12-29 13:44:04,604 - INFO - Model training completed in 0.19s
2024-12-29 13:44:04,700 - INFO - Prediction completed in 0.10s
2024-12-29 13:44:04,709 - INFO - Poison rate 0.2 completed in 3.54s
2024-12-29 13:44:04,715 - INFO - Loaded 273 existing results
2024-12-29 13:44:04,715 - INFO - Total results to save: 280
2024-12-29 13:44:04,716 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:44:04,726 - INFO - Saved 280 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:44:04,726 - INFO - Total evaluation time: 62.89s
2024-12-29 13:44:04,728 - INFO - Completed evaluation for ImageNette
2024-12-29 13:44:04,728 - INFO - 
Processing dataset: ImageNette
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:44:04,899 - INFO - 
Progress: 42.7% - Evaluating ImageNette with SVM (standard mode, iteration 1/1)
2024-12-29 13:44:05,099 - INFO - Loading datasets...
2024-12-29 13:44:05,125 - INFO - Dataset loading completed in 0.03s
2024-12-29 13:44:05,125 - INFO - Extracting validation features...
2024-12-29 13:44:05,125 - INFO - Extracting features from 3925 samples...
2024-12-29 13:44:14,440 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:44:14,446 - INFO - Validation feature extraction completed in 9.32s
2024-12-29 13:44:14,447 - INFO - Extracting training features...
2024-12-29 13:44:14,447 - INFO - Extracting features from 9469 samples...
2024-12-29 13:44:36,237 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:44:36,245 - INFO - Training feature extraction completed in 21.80s
2024-12-29 13:44:36,246 - INFO - Creating model for classifier: SVM
2024-12-29 13:44:36,246 - INFO - Using device: cuda
2024-12-29 13:44:36,246 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-29 13:44:36,246 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:44:36,247 - INFO - Training set processing completed in 0.00s
2024-12-29 13:44:36,247 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:44:36,248 - INFO - Memory usage at start_fit: CPU 2681.5 MB, GPU 104.6 MB
2024-12-29 13:44:36,249 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:44:36,253 - INFO - Number of unique classes: 10
2024-12-29 13:44:36,327 - INFO - Fitted scaler and transformed data
2024-12-29 13:44:36,328 - INFO - Scaling time: 0.07s
2024-12-29 13:44:36,667 - INFO - Epoch 1/500, Train Loss: 0.7581, Val Loss: 0.1263
2024-12-29 13:44:36,970 - INFO - Epoch 2/500, Train Loss: 0.0920, Val Loss: 0.0989
2024-12-29 13:44:37,348 - INFO - Epoch 3/500, Train Loss: 0.0597, Val Loss: 0.0833
2024-12-29 13:44:37,655 - INFO - Epoch 4/500, Train Loss: 0.0423, Val Loss: 0.0749
2024-12-29 13:44:37,968 - INFO - Epoch 5/500, Train Loss: 0.0320, Val Loss: 0.0675
2024-12-29 13:44:38,326 - INFO - Epoch 6/500, Train Loss: 0.0256, Val Loss: 0.0655
2024-12-29 13:44:38,651 - INFO - Epoch 7/500, Train Loss: 0.0206, Val Loss: 0.0620
2024-12-29 13:44:38,999 - INFO - Epoch 8/500, Train Loss: 0.0172, Val Loss: 0.0605
2024-12-29 13:44:39,371 - INFO - Epoch 9/500, Train Loss: 0.0141, Val Loss: 0.0591
2024-12-29 13:44:39,726 - INFO - Epoch 10/500, Train Loss: 0.0125, Val Loss: 0.0580
2024-12-29 13:44:40,060 - INFO - Epoch 11/500, Train Loss: 0.0106, Val Loss: 0.0565
2024-12-29 13:44:40,439 - INFO - Epoch 12/500, Train Loss: 0.0094, Val Loss: 0.0555
2024-12-29 13:44:40,798 - INFO - Epoch 13/500, Train Loss: 0.0085, Val Loss: 0.0585
2024-12-29 13:44:41,189 - INFO - Epoch 14/500, Train Loss: 0.0071, Val Loss: 0.0582
2024-12-29 13:44:41,551 - INFO - Epoch 15/500, Train Loss: 0.0065, Val Loss: 0.0561
2024-12-29 13:44:41,892 - INFO - Epoch 16/500, Train Loss: 0.0062, Val Loss: 0.0554
2024-12-29 13:44:42,256 - INFO - Epoch 17/500, Train Loss: 0.0056, Val Loss: 0.0577
2024-12-29 13:44:42,256 - INFO - Early stopping triggered at epoch 17
2024-12-29 13:44:42,256 - INFO - Training completed in 6.01s
2024-12-29 13:44:42,257 - INFO - Final memory usage: CPU 2718.3 MB, GPU 104.8 MB
2024-12-29 13:44:42,258 - INFO - Model training completed in 6.01s
2024-12-29 13:44:42,329 - INFO - Prediction completed in 0.07s
2024-12-29 13:44:42,339 - INFO - Poison rate 0.0 completed in 6.09s
2024-12-29 13:44:42,339 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:44:42,340 - INFO - Total number of labels flipped: 85
2024-12-29 13:44:42,340 - INFO - Label flipping completed in 0.00s
2024-12-29 13:44:42,340 - INFO - Training set processing completed in 0.00s
2024-12-29 13:44:42,340 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:44:42,341 - INFO - Memory usage at start_fit: CPU 2689.0 MB, GPU 104.7 MB
2024-12-29 13:44:42,342 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:44:42,346 - INFO - Number of unique classes: 10
2024-12-29 13:44:42,419 - INFO - Fitted scaler and transformed data
2024-12-29 13:44:42,419 - INFO - Scaling time: 0.07s
2024-12-29 13:44:42,796 - INFO - Epoch 1/500, Train Loss: 1.0930, Val Loss: 0.3194
2024-12-29 13:44:43,128 - INFO - Epoch 2/500, Train Loss: 0.2031, Val Loss: 0.2777
2024-12-29 13:44:43,463 - INFO - Epoch 3/500, Train Loss: 0.1574, Val Loss: 0.2539
2024-12-29 13:44:43,792 - INFO - Epoch 4/500, Train Loss: 0.1278, Val Loss: 0.2411
2024-12-29 13:44:44,135 - INFO - Epoch 5/500, Train Loss: 0.1092, Val Loss: 0.2356
2024-12-29 13:44:44,515 - INFO - Epoch 6/500, Train Loss: 0.0942, Val Loss: 0.2283
2024-12-29 13:44:44,879 - INFO - Epoch 7/500, Train Loss: 0.0839, Val Loss: 0.2288
2024-12-29 13:44:45,217 - INFO - Epoch 8/500, Train Loss: 0.0746, Val Loss: 0.2295
2024-12-29 13:44:45,579 - INFO - Epoch 9/500, Train Loss: 0.0674, Val Loss: 0.2284
2024-12-29 13:44:45,946 - INFO - Epoch 10/500, Train Loss: 0.0625, Val Loss: 0.2281
2024-12-29 13:44:46,293 - INFO - Epoch 11/500, Train Loss: 0.0587, Val Loss: 0.2218
2024-12-29 13:44:46,656 - INFO - Epoch 12/500, Train Loss: 0.0538, Val Loss: 0.2220
2024-12-29 13:44:47,044 - INFO - Epoch 13/500, Train Loss: 0.0503, Val Loss: 0.2232
2024-12-29 13:44:47,393 - INFO - Epoch 14/500, Train Loss: 0.0487, Val Loss: 0.2199
2024-12-29 13:44:47,703 - INFO - Epoch 15/500, Train Loss: 0.0459, Val Loss: 0.2196
2024-12-29 13:44:48,034 - INFO - Epoch 16/500, Train Loss: 0.0434, Val Loss: 0.2180
2024-12-29 13:44:48,395 - INFO - Epoch 17/500, Train Loss: 0.0411, Val Loss: 0.2175
2024-12-29 13:44:48,735 - INFO - Epoch 18/500, Train Loss: 0.0398, Val Loss: 0.2169
2024-12-29 13:44:49,056 - INFO - Epoch 19/500, Train Loss: 0.0398, Val Loss: 0.2220
2024-12-29 13:44:49,449 - INFO - Epoch 20/500, Train Loss: 0.0382, Val Loss: 0.2184
2024-12-29 13:44:49,802 - INFO - Epoch 21/500, Train Loss: 0.0372, Val Loss: 0.2149
2024-12-29 13:44:50,129 - INFO - Epoch 22/500, Train Loss: 0.0355, Val Loss: 0.2173
2024-12-29 13:44:50,483 - INFO - Epoch 23/500, Train Loss: 0.0345, Val Loss: 0.2172
2024-12-29 13:44:50,827 - INFO - Epoch 24/500, Train Loss: 0.0342, Val Loss: 0.2151
2024-12-29 13:44:51,229 - INFO - Epoch 25/500, Train Loss: 0.0337, Val Loss: 0.2131
2024-12-29 13:44:51,589 - INFO - Epoch 26/500, Train Loss: 0.0341, Val Loss: 0.2130
2024-12-29 13:44:51,972 - INFO - Epoch 27/500, Train Loss: 0.0335, Val Loss: 0.2114
2024-12-29 13:44:52,393 - INFO - Epoch 28/500, Train Loss: 0.0325, Val Loss: 0.2143
2024-12-29 13:44:52,721 - INFO - Epoch 29/500, Train Loss: 0.0313, Val Loss: 0.2119
2024-12-29 13:44:53,133 - INFO - Epoch 30/500, Train Loss: 0.0313, Val Loss: 0.2104
2024-12-29 13:44:53,509 - INFO - Epoch 31/500, Train Loss: 0.0311, Val Loss: 0.2140
2024-12-29 13:44:53,861 - INFO - Epoch 32/500, Train Loss: 0.0309, Val Loss: 0.2094
2024-12-29 13:44:54,262 - INFO - Epoch 33/500, Train Loss: 0.0302, Val Loss: 0.2104
2024-12-29 13:44:54,661 - INFO - Epoch 34/500, Train Loss: 0.0307, Val Loss: 0.2124
2024-12-29 13:44:55,083 - INFO - Epoch 35/500, Train Loss: 0.0303, Val Loss: 0.2089
2024-12-29 13:44:55,471 - INFO - Epoch 36/500, Train Loss: 0.0300, Val Loss: 0.2090
2024-12-29 13:44:55,849 - INFO - Epoch 37/500, Train Loss: 0.0293, Val Loss: 0.2047
2024-12-29 13:44:56,252 - INFO - Epoch 38/500, Train Loss: 0.0290, Val Loss: 0.2121
2024-12-29 13:44:56,630 - INFO - Epoch 39/500, Train Loss: 0.0297, Val Loss: 0.2114
2024-12-29 13:44:57,008 - INFO - Epoch 40/500, Train Loss: 0.0296, Val Loss: 0.2031
2024-12-29 13:44:57,386 - INFO - Epoch 41/500, Train Loss: 0.0303, Val Loss: 0.2000
2024-12-29 13:44:57,747 - INFO - Epoch 42/500, Train Loss: 0.0302, Val Loss: 0.2085
2024-12-29 13:44:58,102 - INFO - Epoch 43/500, Train Loss: 0.0294, Val Loss: 0.2053
2024-12-29 13:44:58,493 - INFO - Epoch 44/500, Train Loss: 0.0284, Val Loss: 0.1977
2024-12-29 13:44:58,866 - INFO - Epoch 45/500, Train Loss: 0.0285, Val Loss: 0.2071
2024-12-29 13:44:59,226 - INFO - Epoch 46/500, Train Loss: 0.0286, Val Loss: 0.2092
2024-12-29 13:44:59,594 - INFO - Epoch 47/500, Train Loss: 0.0305, Val Loss: 0.2169
2024-12-29 13:44:59,976 - INFO - Epoch 48/500, Train Loss: 0.0298, Val Loss: 0.1944
2024-12-29 13:45:00,342 - INFO - Epoch 49/500, Train Loss: 0.0294, Val Loss: 0.2004
2024-12-29 13:45:00,707 - INFO - Epoch 50/500, Train Loss: 0.0292, Val Loss: 0.2064
2024-12-29 13:45:01,121 - INFO - Epoch 51/500, Train Loss: 0.0286, Val Loss: 0.2022
2024-12-29 13:45:01,496 - INFO - Epoch 52/500, Train Loss: 0.0272, Val Loss: 0.2011
2024-12-29 13:45:01,845 - INFO - Epoch 53/500, Train Loss: 0.0283, Val Loss: 0.2037
2024-12-29 13:45:01,845 - INFO - Early stopping triggered at epoch 53
2024-12-29 13:45:01,846 - INFO - Training completed in 19.50s
2024-12-29 13:45:01,846 - INFO - Final memory usage: CPU 2718.2 MB, GPU 104.8 MB
2024-12-29 13:45:01,847 - INFO - Model training completed in 19.51s
2024-12-29 13:45:01,913 - INFO - Prediction completed in 0.07s
2024-12-29 13:45:01,922 - INFO - Poison rate 0.01 completed in 19.58s
2024-12-29 13:45:01,922 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:45:01,923 - INFO - Total number of labels flipped: 258
2024-12-29 13:45:01,923 - INFO - Label flipping completed in 0.00s
2024-12-29 13:45:01,923 - INFO - Training set processing completed in 0.00s
2024-12-29 13:45:01,923 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:45:01,924 - INFO - Memory usage at start_fit: CPU 2688.9 MB, GPU 104.7 MB
2024-12-29 13:45:01,924 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:45:01,928 - INFO - Number of unique classes: 10
2024-12-29 13:45:02,004 - INFO - Fitted scaler and transformed data
2024-12-29 13:45:02,005 - INFO - Scaling time: 0.07s
2024-12-29 13:45:02,386 - INFO - Epoch 1/500, Train Loss: 1.1605, Val Loss: 0.5688
2024-12-29 13:45:02,752 - INFO - Epoch 2/500, Train Loss: 0.4048, Val Loss: 0.4983
2024-12-29 13:45:03,174 - INFO - Epoch 3/500, Train Loss: 0.3277, Val Loss: 0.4489
2024-12-29 13:45:03,546 - INFO - Epoch 4/500, Train Loss: 0.2805, Val Loss: 0.4288
2024-12-29 13:45:03,889 - INFO - Epoch 5/500, Train Loss: 0.2422, Val Loss: 0.3961
2024-12-29 13:45:04,234 - INFO - Epoch 6/500, Train Loss: 0.2188, Val Loss: 0.3762
2024-12-29 13:45:04,566 - INFO - Epoch 7/500, Train Loss: 0.1976, Val Loss: 0.3595
2024-12-29 13:45:04,893 - INFO - Epoch 8/500, Train Loss: 0.1814, Val Loss: 0.3579
2024-12-29 13:45:05,291 - INFO - Epoch 9/500, Train Loss: 0.1685, Val Loss: 0.3360
2024-12-29 13:45:05,676 - INFO - Epoch 10/500, Train Loss: 0.1566, Val Loss: 0.3391
2024-12-29 13:45:06,014 - INFO - Epoch 11/500, Train Loss: 0.1469, Val Loss: 0.3208
2024-12-29 13:45:06,345 - INFO - Epoch 12/500, Train Loss: 0.1413, Val Loss: 0.3177
2024-12-29 13:45:06,732 - INFO - Epoch 13/500, Train Loss: 0.1330, Val Loss: 0.3088
2024-12-29 13:45:07,091 - INFO - Epoch 14/500, Train Loss: 0.1271, Val Loss: 0.3118
2024-12-29 13:45:07,475 - INFO - Epoch 15/500, Train Loss: 0.1219, Val Loss: 0.3070
2024-12-29 13:45:07,854 - INFO - Epoch 16/500, Train Loss: 0.1165, Val Loss: 0.3051
2024-12-29 13:45:08,213 - INFO - Epoch 17/500, Train Loss: 0.1127, Val Loss: 0.3066
2024-12-29 13:45:08,604 - INFO - Epoch 18/500, Train Loss: 0.1095, Val Loss: 0.2985
2024-12-29 13:45:08,982 - INFO - Epoch 19/500, Train Loss: 0.1082, Val Loss: 0.3030
2024-12-29 13:45:09,354 - INFO - Epoch 20/500, Train Loss: 0.1067, Val Loss: 0.2977
2024-12-29 13:45:09,737 - INFO - Epoch 21/500, Train Loss: 0.1036, Val Loss: 0.2984
2024-12-29 13:45:10,117 - INFO - Epoch 22/500, Train Loss: 0.0997, Val Loss: 0.3034
2024-12-29 13:45:10,514 - INFO - Epoch 23/500, Train Loss: 0.0979, Val Loss: 0.3066
2024-12-29 13:45:10,514 - INFO - Early stopping triggered at epoch 23
2024-12-29 13:45:10,514 - INFO - Training completed in 8.59s
2024-12-29 13:45:10,515 - INFO - Final memory usage: CPU 2718.0 MB, GPU 104.8 MB
2024-12-29 13:45:10,516 - INFO - Model training completed in 8.59s
2024-12-29 13:45:10,569 - INFO - Prediction completed in 0.05s
2024-12-29 13:45:10,578 - INFO - Poison rate 0.03 completed in 8.66s
2024-12-29 13:45:10,578 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:45:10,579 - INFO - Total number of labels flipped: 427
2024-12-29 13:45:10,579 - INFO - Label flipping completed in 0.00s
2024-12-29 13:45:10,579 - INFO - Training set processing completed in 0.00s
2024-12-29 13:45:10,580 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:45:10,580 - INFO - Memory usage at start_fit: CPU 2688.7 MB, GPU 104.7 MB
2024-12-29 13:45:10,581 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:45:10,584 - INFO - Number of unique classes: 10
2024-12-29 13:45:10,655 - INFO - Fitted scaler and transformed data
2024-12-29 13:45:10,655 - INFO - Scaling time: 0.07s
2024-12-29 13:45:11,034 - INFO - Epoch 1/500, Train Loss: 1.2936, Val Loss: 0.6534
2024-12-29 13:45:11,421 - INFO - Epoch 2/500, Train Loss: 0.5835, Val Loss: 0.5803
2024-12-29 13:45:11,838 - INFO - Epoch 3/500, Train Loss: 0.4867, Val Loss: 0.5384
2024-12-29 13:45:12,266 - INFO - Epoch 4/500, Train Loss: 0.4207, Val Loss: 0.5097
2024-12-29 13:45:12,640 - INFO - Epoch 5/500, Train Loss: 0.3655, Val Loss: 0.4665
2024-12-29 13:45:13,004 - INFO - Epoch 6/500, Train Loss: 0.3267, Val Loss: 0.4479
2024-12-29 13:45:13,367 - INFO - Epoch 7/500, Train Loss: 0.2913, Val Loss: 0.4193
2024-12-29 13:45:13,738 - INFO - Epoch 8/500, Train Loss: 0.2622, Val Loss: 0.3884
2024-12-29 13:45:14,153 - INFO - Epoch 9/500, Train Loss: 0.2422, Val Loss: 0.3663
2024-12-29 13:45:14,502 - INFO - Epoch 10/500, Train Loss: 0.2284, Val Loss: 0.3708
2024-12-29 13:45:14,904 - INFO - Epoch 11/500, Train Loss: 0.2127, Val Loss: 0.3550
2024-12-29 13:45:15,285 - INFO - Epoch 12/500, Train Loss: 0.2027, Val Loss: 0.3384
2024-12-29 13:45:15,608 - INFO - Epoch 13/500, Train Loss: 0.1923, Val Loss: 0.3310
2024-12-29 13:45:15,938 - INFO - Epoch 14/500, Train Loss: 0.1842, Val Loss: 0.3254
2024-12-29 13:45:16,358 - INFO - Epoch 15/500, Train Loss: 0.1807, Val Loss: 0.3240
2024-12-29 13:45:16,733 - INFO - Epoch 16/500, Train Loss: 0.1763, Val Loss: 0.3200
2024-12-29 13:45:17,081 - INFO - Epoch 17/500, Train Loss: 0.1702, Val Loss: 0.3130
2024-12-29 13:45:17,471 - INFO - Epoch 18/500, Train Loss: 0.1667, Val Loss: 0.3256
2024-12-29 13:45:17,854 - INFO - Epoch 19/500, Train Loss: 0.1642, Val Loss: 0.3153
2024-12-29 13:45:18,223 - INFO - Epoch 20/500, Train Loss: 0.1595, Val Loss: 0.3059
2024-12-29 13:45:18,581 - INFO - Epoch 21/500, Train Loss: 0.1561, Val Loss: 0.3065
2024-12-29 13:45:18,920 - INFO - Epoch 22/500, Train Loss: 0.1561, Val Loss: 0.3120
2024-12-29 13:45:19,296 - INFO - Epoch 23/500, Train Loss: 0.1537, Val Loss: 0.2986
2024-12-29 13:45:19,707 - INFO - Epoch 24/500, Train Loss: 0.1517, Val Loss: 0.3076
2024-12-29 13:45:20,099 - INFO - Epoch 25/500, Train Loss: 0.1480, Val Loss: 0.3026
2024-12-29 13:45:20,479 - INFO - Epoch 26/500, Train Loss: 0.1469, Val Loss: 0.3018
2024-12-29 13:45:20,919 - INFO - Epoch 27/500, Train Loss: 0.1452, Val Loss: 0.2961
2024-12-29 13:45:21,335 - INFO - Epoch 28/500, Train Loss: 0.1451, Val Loss: 0.3134
2024-12-29 13:45:21,701 - INFO - Epoch 29/500, Train Loss: 0.1423, Val Loss: 0.3073
2024-12-29 13:45:22,109 - INFO - Epoch 30/500, Train Loss: 0.1421, Val Loss: 0.3039
2024-12-29 13:45:22,459 - INFO - Epoch 31/500, Train Loss: 0.1423, Val Loss: 0.2927
2024-12-29 13:45:22,886 - INFO - Epoch 32/500, Train Loss: 0.1405, Val Loss: 0.3038
2024-12-29 13:45:23,277 - INFO - Epoch 33/500, Train Loss: 0.1386, Val Loss: 0.2917
2024-12-29 13:45:23,653 - INFO - Epoch 34/500, Train Loss: 0.1391, Val Loss: 0.2996
2024-12-29 13:45:24,063 - INFO - Epoch 35/500, Train Loss: 0.1382, Val Loss: 0.3017
2024-12-29 13:45:24,480 - INFO - Epoch 36/500, Train Loss: 0.1380, Val Loss: 0.2967
2024-12-29 13:45:24,480 - INFO - Early stopping triggered at epoch 36
2024-12-29 13:45:24,480 - INFO - Training completed in 13.90s
2024-12-29 13:45:24,481 - INFO - Final memory usage: CPU 2718.0 MB, GPU 104.8 MB
2024-12-29 13:45:24,482 - INFO - Model training completed in 13.90s
2024-12-29 13:45:24,532 - INFO - Prediction completed in 0.05s
2024-12-29 13:45:24,541 - INFO - Poison rate 0.05 completed in 13.96s
2024-12-29 13:45:24,541 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:45:24,543 - INFO - Total number of labels flipped: 586
2024-12-29 13:45:24,543 - INFO - Label flipping completed in 0.00s
2024-12-29 13:45:24,543 - INFO - Training set processing completed in 0.00s
2024-12-29 13:45:24,543 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:45:24,544 - INFO - Memory usage at start_fit: CPU 2688.7 MB, GPU 104.7 MB
2024-12-29 13:45:24,544 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:45:24,549 - INFO - Number of unique classes: 10
2024-12-29 13:45:24,626 - INFO - Fitted scaler and transformed data
2024-12-29 13:45:24,626 - INFO - Scaling time: 0.07s
2024-12-29 13:45:25,023 - INFO - Epoch 1/500, Train Loss: 1.5251, Val Loss: 0.7814
2024-12-29 13:45:25,414 - INFO - Epoch 2/500, Train Loss: 0.7466, Val Loss: 0.7157
2024-12-29 13:45:25,829 - INFO - Epoch 3/500, Train Loss: 0.6261, Val Loss: 0.6696
2024-12-29 13:45:26,222 - INFO - Epoch 4/500, Train Loss: 0.5390, Val Loss: 0.6520
2024-12-29 13:45:26,626 - INFO - Epoch 5/500, Train Loss: 0.4755, Val Loss: 0.5967
2024-12-29 13:45:26,978 - INFO - Epoch 6/500, Train Loss: 0.4173, Val Loss: 0.5409
2024-12-29 13:45:27,351 - INFO - Epoch 7/500, Train Loss: 0.3776, Val Loss: 0.5180
2024-12-29 13:45:27,767 - INFO - Epoch 8/500, Train Loss: 0.3414, Val Loss: 0.4921
2024-12-29 13:45:28,126 - INFO - Epoch 9/500, Train Loss: 0.3150, Val Loss: 0.4581
2024-12-29 13:45:28,474 - INFO - Epoch 10/500, Train Loss: 0.2949, Val Loss: 0.4567
2024-12-29 13:45:28,945 - INFO - Epoch 11/500, Train Loss: 0.2743, Val Loss: 0.4315
2024-12-29 13:45:29,377 - INFO - Epoch 12/500, Train Loss: 0.2619, Val Loss: 0.3990
2024-12-29 13:45:29,719 - INFO - Epoch 13/500, Train Loss: 0.2552, Val Loss: 0.4048
2024-12-29 13:45:30,105 - INFO - Epoch 14/500, Train Loss: 0.2419, Val Loss: 0.3860
2024-12-29 13:45:30,477 - INFO - Epoch 15/500, Train Loss: 0.2365, Val Loss: 0.3877
2024-12-29 13:45:30,818 - INFO - Epoch 16/500, Train Loss: 0.2285, Val Loss: 0.3873
2024-12-29 13:45:31,182 - INFO - Epoch 17/500, Train Loss: 0.2229, Val Loss: 0.3753
2024-12-29 13:45:31,523 - INFO - Epoch 18/500, Train Loss: 0.2168, Val Loss: 0.3728
2024-12-29 13:45:31,907 - INFO - Epoch 19/500, Train Loss: 0.2141, Val Loss: 0.3677
2024-12-29 13:45:32,315 - INFO - Epoch 20/500, Train Loss: 0.2119, Val Loss: 0.3729
2024-12-29 13:45:32,691 - INFO - Epoch 21/500, Train Loss: 0.2087, Val Loss: 0.3661
2024-12-29 13:45:33,028 - INFO - Epoch 22/500, Train Loss: 0.2058, Val Loss: 0.3667
2024-12-29 13:45:33,369 - INFO - Epoch 23/500, Train Loss: 0.1999, Val Loss: 0.3685
2024-12-29 13:45:33,712 - INFO - Epoch 24/500, Train Loss: 0.2010, Val Loss: 0.3633
2024-12-29 13:45:34,100 - INFO - Epoch 25/500, Train Loss: 0.1975, Val Loss: 0.3596
2024-12-29 13:45:34,475 - INFO - Epoch 26/500, Train Loss: 0.1951, Val Loss: 0.3624
2024-12-29 13:45:34,848 - INFO - Epoch 27/500, Train Loss: 0.1926, Val Loss: 0.3530
2024-12-29 13:45:35,216 - INFO - Epoch 28/500, Train Loss: 0.1921, Val Loss: 0.3539
2024-12-29 13:45:35,618 - INFO - Epoch 29/500, Train Loss: 0.1906, Val Loss: 0.3614
2024-12-29 13:45:35,956 - INFO - Epoch 30/500, Train Loss: 0.1889, Val Loss: 0.3669
2024-12-29 13:45:36,300 - INFO - Epoch 31/500, Train Loss: 0.1865, Val Loss: 0.3559
2024-12-29 13:45:36,666 - INFO - Epoch 32/500, Train Loss: 0.1863, Val Loss: 0.3557
2024-12-29 13:45:36,666 - INFO - Early stopping triggered at epoch 32
2024-12-29 13:45:36,666 - INFO - Training completed in 12.12s
2024-12-29 13:45:36,666 - INFO - Final memory usage: CPU 2718.0 MB, GPU 104.8 MB
2024-12-29 13:45:36,667 - INFO - Model training completed in 12.12s
2024-12-29 13:45:36,716 - INFO - Prediction completed in 0.05s
2024-12-29 13:45:36,725 - INFO - Poison rate 0.07 completed in 12.18s
2024-12-29 13:45:36,725 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:45:36,727 - INFO - Total number of labels flipped: 863
2024-12-29 13:45:36,727 - INFO - Label flipping completed in 0.00s
2024-12-29 13:45:36,727 - INFO - Training set processing completed in 0.00s
2024-12-29 13:45:36,727 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:45:36,728 - INFO - Memory usage at start_fit: CPU 2688.7 MB, GPU 104.7 MB
2024-12-29 13:45:36,729 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:45:36,734 - INFO - Number of unique classes: 10
2024-12-29 13:45:36,809 - INFO - Fitted scaler and transformed data
2024-12-29 13:45:36,809 - INFO - Scaling time: 0.07s
2024-12-29 13:45:37,179 - INFO - Epoch 1/500, Train Loss: 1.8913, Val Loss: 1.1154
2024-12-29 13:45:37,530 - INFO - Epoch 2/500, Train Loss: 1.0372, Val Loss: 0.9822
2024-12-29 13:45:37,888 - INFO - Epoch 3/500, Train Loss: 0.8729, Val Loss: 0.9079
2024-12-29 13:45:38,272 - INFO - Epoch 4/500, Train Loss: 0.7456, Val Loss: 0.8193
2024-12-29 13:45:38,626 - INFO - Epoch 5/500, Train Loss: 0.6457, Val Loss: 0.7634
2024-12-29 13:45:39,010 - INFO - Epoch 6/500, Train Loss: 0.5667, Val Loss: 0.7077
2024-12-29 13:45:39,358 - INFO - Epoch 7/500, Train Loss: 0.4991, Val Loss: 0.6559
2024-12-29 13:45:39,701 - INFO - Epoch 8/500, Train Loss: 0.4505, Val Loss: 0.6153
2024-12-29 13:45:40,063 - INFO - Epoch 9/500, Train Loss: 0.4148, Val Loss: 0.5777
2024-12-29 13:45:40,433 - INFO - Epoch 10/500, Train Loss: 0.3854, Val Loss: 0.5582
2024-12-29 13:45:40,815 - INFO - Epoch 11/500, Train Loss: 0.3662, Val Loss: 0.5382
2024-12-29 13:45:41,178 - INFO - Epoch 12/500, Train Loss: 0.3474, Val Loss: 0.5228
2024-12-29 13:45:41,530 - INFO - Epoch 13/500, Train Loss: 0.3342, Val Loss: 0.5134
2024-12-29 13:45:41,858 - INFO - Epoch 14/500, Train Loss: 0.3243, Val Loss: 0.5096
2024-12-29 13:45:42,190 - INFO - Epoch 15/500, Train Loss: 0.3178, Val Loss: 0.4953
2024-12-29 13:45:42,522 - INFO - Epoch 16/500, Train Loss: 0.3092, Val Loss: 0.4903
2024-12-29 13:45:42,860 - INFO - Epoch 17/500, Train Loss: 0.3047, Val Loss: 0.4877
2024-12-29 13:45:43,223 - INFO - Epoch 18/500, Train Loss: 0.2957, Val Loss: 0.4902
2024-12-29 13:45:43,533 - INFO - Epoch 19/500, Train Loss: 0.2937, Val Loss: 0.4882
2024-12-29 13:45:43,862 - INFO - Epoch 20/500, Train Loss: 0.2886, Val Loss: 0.4898
2024-12-29 13:45:44,224 - INFO - Epoch 21/500, Train Loss: 0.2840, Val Loss: 0.4828
2024-12-29 13:45:44,554 - INFO - Epoch 22/500, Train Loss: 0.2844, Val Loss: 0.4904
2024-12-29 13:45:44,886 - INFO - Epoch 23/500, Train Loss: 0.2822, Val Loss: 0.4889
2024-12-29 13:45:45,223 - INFO - Epoch 24/500, Train Loss: 0.2781, Val Loss: 0.4830
2024-12-29 13:45:45,559 - INFO - Epoch 25/500, Train Loss: 0.2758, Val Loss: 0.4783
2024-12-29 13:45:45,897 - INFO - Epoch 26/500, Train Loss: 0.2741, Val Loss: 0.4805
2024-12-29 13:45:46,259 - INFO - Epoch 27/500, Train Loss: 0.2714, Val Loss: 0.4789
2024-12-29 13:45:46,587 - INFO - Epoch 28/500, Train Loss: 0.2702, Val Loss: 0.4819
2024-12-29 13:45:46,931 - INFO - Epoch 29/500, Train Loss: 0.2677, Val Loss: 0.4851
2024-12-29 13:45:47,271 - INFO - Epoch 30/500, Train Loss: 0.2661, Val Loss: 0.4863
2024-12-29 13:45:47,271 - INFO - Early stopping triggered at epoch 30
2024-12-29 13:45:47,271 - INFO - Training completed in 10.54s
2024-12-29 13:45:47,272 - INFO - Final memory usage: CPU 2717.8 MB, GPU 104.8 MB
2024-12-29 13:45:47,274 - INFO - Model training completed in 10.55s
2024-12-29 13:45:47,330 - INFO - Prediction completed in 0.06s
2024-12-29 13:45:47,338 - INFO - Poison rate 0.1 completed in 10.61s
2024-12-29 13:45:47,338 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:45:47,340 - INFO - Total number of labels flipped: 1703
2024-12-29 13:45:47,340 - INFO - Label flipping completed in 0.00s
2024-12-29 13:45:47,340 - INFO - Training set processing completed in 0.00s
2024-12-29 13:45:47,340 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:45:47,342 - INFO - Memory usage at start_fit: CPU 2688.5 MB, GPU 104.7 MB
2024-12-29 13:45:47,342 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:45:47,346 - INFO - Number of unique classes: 10
2024-12-29 13:45:47,442 - INFO - Fitted scaler and transformed data
2024-12-29 13:45:47,442 - INFO - Scaling time: 0.09s
2024-12-29 13:45:47,798 - INFO - Epoch 1/500, Train Loss: 2.7275, Val Loss: 1.9133
2024-12-29 13:45:48,162 - INFO - Epoch 2/500, Train Loss: 1.8194, Val Loss: 1.6594
2024-12-29 13:45:48,563 - INFO - Epoch 3/500, Train Loss: 1.5090, Val Loss: 1.5180
2024-12-29 13:45:48,919 - INFO - Epoch 4/500, Train Loss: 1.2698, Val Loss: 1.3257
2024-12-29 13:45:49,238 - INFO - Epoch 5/500, Train Loss: 1.0814, Val Loss: 1.2070
2024-12-29 13:45:49,574 - INFO - Epoch 6/500, Train Loss: 0.9283, Val Loss: 1.0706
2024-12-29 13:45:49,901 - INFO - Epoch 7/500, Train Loss: 0.8097, Val Loss: 0.9423
2024-12-29 13:45:50,242 - INFO - Epoch 8/500, Train Loss: 0.7334, Val Loss: 0.8578
2024-12-29 13:45:50,615 - INFO - Epoch 9/500, Train Loss: 0.6708, Val Loss: 0.8225
2024-12-29 13:45:50,945 - INFO - Epoch 10/500, Train Loss: 0.6319, Val Loss: 0.7716
2024-12-29 13:45:51,360 - INFO - Epoch 11/500, Train Loss: 0.6034, Val Loss: 0.7518
2024-12-29 13:45:51,686 - INFO - Epoch 12/500, Train Loss: 0.5791, Val Loss: 0.7319
2024-12-29 13:45:52,128 - INFO - Epoch 13/500, Train Loss: 0.5637, Val Loss: 0.7103
2024-12-29 13:45:52,510 - INFO - Epoch 14/500, Train Loss: 0.5508, Val Loss: 0.7148
2024-12-29 13:45:52,869 - INFO - Epoch 15/500, Train Loss: 0.5400, Val Loss: 0.6885
2024-12-29 13:45:53,210 - INFO - Epoch 16/500, Train Loss: 0.5301, Val Loss: 0.7064
2024-12-29 13:45:53,554 - INFO - Epoch 17/500, Train Loss: 0.5204, Val Loss: 0.7040
2024-12-29 13:45:53,887 - INFO - Epoch 18/500, Train Loss: 0.5149, Val Loss: 0.6918
2024-12-29 13:45:54,230 - INFO - Epoch 19/500, Train Loss: 0.5084, Val Loss: 0.6854
2024-12-29 13:45:54,544 - INFO - Epoch 20/500, Train Loss: 0.5013, Val Loss: 0.6774
2024-12-29 13:45:54,889 - INFO - Epoch 21/500, Train Loss: 0.4960, Val Loss: 0.6932
2024-12-29 13:45:55,273 - INFO - Epoch 22/500, Train Loss: 0.4946, Val Loss: 0.6824
2024-12-29 13:45:55,729 - INFO - Epoch 23/500, Train Loss: 0.4897, Val Loss: 0.6893
2024-12-29 13:45:56,109 - INFO - Epoch 24/500, Train Loss: 0.4847, Val Loss: 0.6877
2024-12-29 13:45:56,496 - INFO - Epoch 25/500, Train Loss: 0.4802, Val Loss: 0.6755
2024-12-29 13:45:56,852 - INFO - Epoch 26/500, Train Loss: 0.4794, Val Loss: 0.6807
2024-12-29 13:45:57,216 - INFO - Epoch 27/500, Train Loss: 0.4778, Val Loss: 0.6808
2024-12-29 13:45:57,581 - INFO - Epoch 28/500, Train Loss: 0.4783, Val Loss: 0.6756
2024-12-29 13:45:57,916 - INFO - Epoch 29/500, Train Loss: 0.4682, Val Loss: 0.6871
2024-12-29 13:45:58,257 - INFO - Epoch 30/500, Train Loss: 0.4668, Val Loss: 0.6880
2024-12-29 13:45:58,257 - INFO - Early stopping triggered at epoch 30
2024-12-29 13:45:58,257 - INFO - Training completed in 10.92s
2024-12-29 13:45:58,258 - INFO - Final memory usage: CPU 2717.9 MB, GPU 104.8 MB
2024-12-29 13:45:58,259 - INFO - Model training completed in 10.92s
2024-12-29 13:45:58,304 - INFO - Prediction completed in 0.04s
2024-12-29 13:45:58,313 - INFO - Poison rate 0.2 completed in 10.98s
2024-12-29 13:45:58,319 - INFO - Loaded 280 existing results
2024-12-29 13:45:58,319 - INFO - Total results to save: 287
2024-12-29 13:45:58,320 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:45:58,332 - INFO - Saved 287 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:45:58,332 - INFO - Total evaluation time: 113.23s
2024-12-29 13:45:58,334 - INFO - 
Progress: 43.8% - Evaluating ImageNette with SVM (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:45:58,517 - INFO - Loading datasets...
2024-12-29 13:45:58,538 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:45:58,539 - INFO - Extracting validation features...
2024-12-29 13:45:58,539 - INFO - Extracting features from 3925 samples...
2024-12-29 13:46:08,054 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:46:08,060 - INFO - Validation feature extraction completed in 9.52s
2024-12-29 13:46:08,061 - INFO - Extracting training features...
2024-12-29 13:46:08,061 - INFO - Extracting features from 9469 samples...
2024-12-29 13:46:29,240 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:46:29,246 - INFO - Training feature extraction completed in 21.19s
2024-12-29 13:46:29,246 - INFO - Creating model for classifier: SVM
2024-12-29 13:46:29,246 - INFO - Using device: cuda
2024-12-29 13:46:29,246 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-29 13:46:29,247 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:46:29,247 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:46:29,247 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:46:29,779 - INFO - Feature scaling completed in 0.53s
2024-12-29 13:46:29,780 - INFO - Starting feature selection (k=50)
2024-12-29 13:46:29,795 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 13:46:29,795 - INFO - Starting anomaly detection
2024-12-29 13:46:33,426 - INFO - Anomaly detection completed in 3.63s
2024-12-29 13:46:33,427 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:46:33,427 - INFO - Total fit_transform time: 4.18s
2024-12-29 13:46:33,427 - INFO - Training set processing completed in 4.18s
2024-12-29 13:46:33,427 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:46:33,428 - INFO - Memory usage at start_fit: CPU 2708.8 MB, GPU 104.0 MB
2024-12-29 13:46:33,428 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:46:33,430 - INFO - Number of unique classes: 10
2024-12-29 13:46:33,508 - INFO - Fitted scaler and transformed data
2024-12-29 13:46:33,508 - INFO - Scaling time: 0.08s
2024-12-29 13:46:33,887 - INFO - Epoch 1/500, Train Loss: 0.8819, Val Loss: 0.1593
2024-12-29 13:46:34,202 - INFO - Epoch 2/500, Train Loss: 0.0968, Val Loss: 0.1149
2024-12-29 13:46:34,527 - INFO - Epoch 3/500, Train Loss: 0.0627, Val Loss: 0.0983
2024-12-29 13:46:34,853 - INFO - Epoch 4/500, Train Loss: 0.0436, Val Loss: 0.0901
2024-12-29 13:46:35,212 - INFO - Epoch 5/500, Train Loss: 0.0335, Val Loss: 0.0870
2024-12-29 13:46:35,551 - INFO - Epoch 6/500, Train Loss: 0.0259, Val Loss: 0.0823
2024-12-29 13:46:35,872 - INFO - Epoch 7/500, Train Loss: 0.0215, Val Loss: 0.0812
2024-12-29 13:46:36,236 - INFO - Epoch 8/500, Train Loss: 0.0173, Val Loss: 0.0802
2024-12-29 13:46:36,585 - INFO - Epoch 9/500, Train Loss: 0.0146, Val Loss: 0.0772
2024-12-29 13:46:36,944 - INFO - Epoch 10/500, Train Loss: 0.0125, Val Loss: 0.0778
2024-12-29 13:46:37,262 - INFO - Epoch 11/500, Train Loss: 0.0108, Val Loss: 0.0759
2024-12-29 13:46:37,642 - INFO - Epoch 12/500, Train Loss: 0.0093, Val Loss: 0.0759
2024-12-29 13:46:38,028 - INFO - Epoch 13/500, Train Loss: 0.0081, Val Loss: 0.0754
2024-12-29 13:46:38,367 - INFO - Epoch 14/500, Train Loss: 0.0070, Val Loss: 0.0739
2024-12-29 13:46:38,725 - INFO - Epoch 15/500, Train Loss: 0.0065, Val Loss: 0.0751
2024-12-29 13:46:39,069 - INFO - Epoch 16/500, Train Loss: 0.0060, Val Loss: 0.0753
2024-12-29 13:46:39,411 - INFO - Epoch 17/500, Train Loss: 0.0052, Val Loss: 0.0745
2024-12-29 13:46:39,752 - INFO - Epoch 18/500, Train Loss: 0.0049, Val Loss: 0.0715
2024-12-29 13:46:40,112 - INFO - Epoch 19/500, Train Loss: 0.0047, Val Loss: 0.0776
2024-12-29 13:46:40,444 - INFO - Epoch 20/500, Train Loss: 0.0048, Val Loss: 0.0802
2024-12-29 13:46:40,828 - INFO - Epoch 21/500, Train Loss: 0.0044, Val Loss: 0.0715
2024-12-29 13:46:41,175 - INFO - Epoch 22/500, Train Loss: 0.0039, Val Loss: 0.0750
2024-12-29 13:46:41,519 - INFO - Epoch 23/500, Train Loss: 0.0035, Val Loss: 0.0771
2024-12-29 13:46:41,520 - INFO - Early stopping triggered at epoch 23
2024-12-29 13:46:41,520 - INFO - Training completed in 8.09s
2024-12-29 13:46:41,521 - INFO - Final memory usage: CPU 2718.1 MB, GPU 104.2 MB
2024-12-29 13:46:41,522 - INFO - Model training completed in 8.10s
2024-12-29 13:46:41,582 - INFO - Prediction completed in 0.06s
2024-12-29 13:46:41,591 - INFO - Poison rate 0.0 completed in 12.34s
2024-12-29 13:46:41,591 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:46:41,592 - INFO - Total number of labels flipped: 83
2024-12-29 13:46:41,592 - INFO - Label flipping completed in 0.00s
2024-12-29 13:46:41,592 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:46:41,592 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:46:42,128 - INFO - Feature scaling completed in 0.54s
2024-12-29 13:46:42,129 - INFO - Starting feature selection (k=50)
2024-12-29 13:46:42,144 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:46:42,144 - INFO - Starting anomaly detection
2024-12-29 13:46:45,640 - INFO - Anomaly detection completed in 3.50s
2024-12-29 13:46:45,640 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:46:45,641 - INFO - Total fit_transform time: 4.05s
2024-12-29 13:46:45,641 - INFO - Training set processing completed in 4.05s
2024-12-29 13:46:45,641 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:46:45,642 - INFO - Memory usage at start_fit: CPU 2708.5 MB, GPU 104.1 MB
2024-12-29 13:46:45,642 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:46:45,644 - INFO - Number of unique classes: 10
2024-12-29 13:46:45,713 - INFO - Fitted scaler and transformed data
2024-12-29 13:46:45,714 - INFO - Scaling time: 0.07s
2024-12-29 13:46:46,094 - INFO - Epoch 1/500, Train Loss: 0.8404, Val Loss: 0.3880
2024-12-29 13:46:46,407 - INFO - Epoch 2/500, Train Loss: 0.1811, Val Loss: 0.3498
2024-12-29 13:46:46,711 - INFO - Epoch 3/500, Train Loss: 0.1351, Val Loss: 0.3324
2024-12-29 13:46:47,016 - INFO - Epoch 4/500, Train Loss: 0.1092, Val Loss: 0.3295
2024-12-29 13:46:47,389 - INFO - Epoch 5/500, Train Loss: 0.0916, Val Loss: 0.3288
2024-12-29 13:46:47,717 - INFO - Epoch 6/500, Train Loss: 0.0783, Val Loss: 0.3241
2024-12-29 13:46:48,098 - INFO - Epoch 7/500, Train Loss: 0.0696, Val Loss: 0.3200
2024-12-29 13:46:48,417 - INFO - Epoch 8/500, Train Loss: 0.0622, Val Loss: 0.3253
2024-12-29 13:46:48,724 - INFO - Epoch 9/500, Train Loss: 0.0564, Val Loss: 0.3228
2024-12-29 13:46:49,070 - INFO - Epoch 10/500, Train Loss: 0.0519, Val Loss: 0.3227
2024-12-29 13:46:49,395 - INFO - Epoch 11/500, Train Loss: 0.0484, Val Loss: 0.3204
2024-12-29 13:46:49,734 - INFO - Epoch 12/500, Train Loss: 0.0451, Val Loss: 0.3188
2024-12-29 13:46:50,050 - INFO - Epoch 13/500, Train Loss: 0.0416, Val Loss: 0.3145
2024-12-29 13:46:50,420 - INFO - Epoch 14/500, Train Loss: 0.0404, Val Loss: 0.3168
2024-12-29 13:46:50,726 - INFO - Epoch 15/500, Train Loss: 0.0385, Val Loss: 0.3215
2024-12-29 13:46:51,070 - INFO - Epoch 16/500, Train Loss: 0.0370, Val Loss: 0.3105
2024-12-29 13:46:51,411 - INFO - Epoch 17/500, Train Loss: 0.0348, Val Loss: 0.3144
2024-12-29 13:46:51,734 - INFO - Epoch 18/500, Train Loss: 0.0339, Val Loss: 0.3137
2024-12-29 13:46:52,078 - INFO - Epoch 19/500, Train Loss: 0.0331, Val Loss: 0.3087
2024-12-29 13:46:52,437 - INFO - Epoch 20/500, Train Loss: 0.0319, Val Loss: 0.3161
2024-12-29 13:46:52,796 - INFO - Epoch 21/500, Train Loss: 0.0309, Val Loss: 0.3100
2024-12-29 13:46:53,116 - INFO - Epoch 22/500, Train Loss: 0.0309, Val Loss: 0.3072
2024-12-29 13:46:53,489 - INFO - Epoch 23/500, Train Loss: 0.0294, Val Loss: 0.3085
2024-12-29 13:46:53,855 - INFO - Epoch 24/500, Train Loss: 0.0290, Val Loss: 0.3079
2024-12-29 13:46:54,213 - INFO - Epoch 25/500, Train Loss: 0.0278, Val Loss: 0.3118
2024-12-29 13:46:54,554 - INFO - Epoch 26/500, Train Loss: 0.0277, Val Loss: 0.3022
2024-12-29 13:46:54,890 - INFO - Epoch 27/500, Train Loss: 0.0271, Val Loss: 0.3014
2024-12-29 13:46:55,212 - INFO - Epoch 28/500, Train Loss: 0.0275, Val Loss: 0.2988
2024-12-29 13:46:55,545 - INFO - Epoch 29/500, Train Loss: 0.0267, Val Loss: 0.3064
2024-12-29 13:46:55,858 - INFO - Epoch 30/500, Train Loss: 0.0271, Val Loss: 0.3004
2024-12-29 13:46:56,185 - INFO - Epoch 31/500, Train Loss: 0.0262, Val Loss: 0.2995
2024-12-29 13:46:56,505 - INFO - Epoch 32/500, Train Loss: 0.0257, Val Loss: 0.3018
2024-12-29 13:46:56,852 - INFO - Epoch 33/500, Train Loss: 0.0268, Val Loss: 0.2926
2024-12-29 13:46:57,166 - INFO - Epoch 34/500, Train Loss: 0.0260, Val Loss: 0.3088
2024-12-29 13:46:57,520 - INFO - Epoch 35/500, Train Loss: 0.0249, Val Loss: 0.3100
2024-12-29 13:46:57,856 - INFO - Epoch 36/500, Train Loss: 0.0248, Val Loss: 0.3119
2024-12-29 13:46:58,162 - INFO - Epoch 37/500, Train Loss: 0.0262, Val Loss: 0.3023
2024-12-29 13:46:58,483 - INFO - Epoch 38/500, Train Loss: 0.0249, Val Loss: 0.3178
2024-12-29 13:46:58,483 - INFO - Early stopping triggered at epoch 38
2024-12-29 13:46:58,483 - INFO - Training completed in 12.84s
2024-12-29 13:46:58,484 - INFO - Final memory usage: CPU 2718.1 MB, GPU 104.2 MB
2024-12-29 13:46:58,485 - INFO - Model training completed in 12.84s
2024-12-29 13:46:58,529 - INFO - Prediction completed in 0.04s
2024-12-29 13:46:58,537 - INFO - Poison rate 0.01 completed in 16.95s
2024-12-29 13:46:58,538 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:46:58,538 - INFO - Total number of labels flipped: 258
2024-12-29 13:46:58,539 - INFO - Label flipping completed in 0.00s
2024-12-29 13:46:58,539 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:46:58,539 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:46:59,101 - INFO - Feature scaling completed in 0.56s
2024-12-29 13:46:59,101 - INFO - Starting feature selection (k=50)
2024-12-29 13:46:59,115 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:46:59,116 - INFO - Starting anomaly detection
2024-12-29 13:47:03,423 - INFO - Anomaly detection completed in 4.31s
2024-12-29 13:47:03,423 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:47:03,424 - INFO - Total fit_transform time: 4.88s
2024-12-29 13:47:03,424 - INFO - Training set processing completed in 4.89s
2024-12-29 13:47:03,424 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:47:03,425 - INFO - Memory usage at start_fit: CPU 2708.5 MB, GPU 104.1 MB
2024-12-29 13:47:03,425 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:47:03,429 - INFO - Number of unique classes: 10
2024-12-29 13:47:03,502 - INFO - Fitted scaler and transformed data
2024-12-29 13:47:03,502 - INFO - Scaling time: 0.07s
2024-12-29 13:47:03,839 - INFO - Epoch 1/500, Train Loss: 1.1018, Val Loss: 0.5580
2024-12-29 13:47:04,225 - INFO - Epoch 2/500, Train Loss: 0.3485, Val Loss: 0.5036
2024-12-29 13:47:04,554 - INFO - Epoch 3/500, Train Loss: 0.2831, Val Loss: 0.4688
2024-12-29 13:47:04,867 - INFO - Epoch 4/500, Train Loss: 0.2427, Val Loss: 0.4278
2024-12-29 13:47:05,228 - INFO - Epoch 5/500, Train Loss: 0.2143, Val Loss: 0.4038
2024-12-29 13:47:05,563 - INFO - Epoch 6/500, Train Loss: 0.1914, Val Loss: 0.3889
2024-12-29 13:47:05,874 - INFO - Epoch 7/500, Train Loss: 0.1721, Val Loss: 0.3652
2024-12-29 13:47:06,195 - INFO - Epoch 8/500, Train Loss: 0.1573, Val Loss: 0.3558
2024-12-29 13:47:06,536 - INFO - Epoch 9/500, Train Loss: 0.1461, Val Loss: 0.3547
2024-12-29 13:47:06,829 - INFO - Epoch 10/500, Train Loss: 0.1375, Val Loss: 0.3354
2024-12-29 13:47:07,128 - INFO - Epoch 11/500, Train Loss: 0.1282, Val Loss: 0.3289
2024-12-29 13:47:07,439 - INFO - Epoch 12/500, Train Loss: 0.1198, Val Loss: 0.3189
2024-12-29 13:47:07,748 - INFO - Epoch 13/500, Train Loss: 0.1160, Val Loss: 0.3181
2024-12-29 13:47:08,074 - INFO - Epoch 14/500, Train Loss: 0.1122, Val Loss: 0.3117
2024-12-29 13:47:08,464 - INFO - Epoch 15/500, Train Loss: 0.1077, Val Loss: 0.3110
2024-12-29 13:47:08,799 - INFO - Epoch 16/500, Train Loss: 0.1044, Val Loss: 0.2937
2024-12-29 13:47:09,192 - INFO - Epoch 17/500, Train Loss: 0.1005, Val Loss: 0.2974
2024-12-29 13:47:09,580 - INFO - Epoch 18/500, Train Loss: 0.0986, Val Loss: 0.2895
2024-12-29 13:47:09,910 - INFO - Epoch 19/500, Train Loss: 0.0961, Val Loss: 0.2887
2024-12-29 13:47:10,268 - INFO - Epoch 20/500, Train Loss: 0.0935, Val Loss: 0.2917
2024-12-29 13:47:10,635 - INFO - Epoch 21/500, Train Loss: 0.0923, Val Loss: 0.2872
2024-12-29 13:47:11,013 - INFO - Epoch 22/500, Train Loss: 0.0899, Val Loss: 0.2866
2024-12-29 13:47:11,335 - INFO - Epoch 23/500, Train Loss: 0.0890, Val Loss: 0.2870
2024-12-29 13:47:11,691 - INFO - Epoch 24/500, Train Loss: 0.0875, Val Loss: 0.2829
2024-12-29 13:47:12,052 - INFO - Epoch 25/500, Train Loss: 0.0860, Val Loss: 0.2798
2024-12-29 13:47:12,387 - INFO - Epoch 26/500, Train Loss: 0.0849, Val Loss: 0.2788
2024-12-29 13:47:12,726 - INFO - Epoch 27/500, Train Loss: 0.0848, Val Loss: 0.2802
2024-12-29 13:47:13,098 - INFO - Epoch 28/500, Train Loss: 0.0837, Val Loss: 0.2815
2024-12-29 13:47:13,397 - INFO - Epoch 29/500, Train Loss: 0.0831, Val Loss: 0.2855
2024-12-29 13:47:13,761 - INFO - Epoch 30/500, Train Loss: 0.0823, Val Loss: 0.2714
2024-12-29 13:47:14,098 - INFO - Epoch 31/500, Train Loss: 0.0818, Val Loss: 0.2713
2024-12-29 13:47:14,476 - INFO - Epoch 32/500, Train Loss: 0.0804, Val Loss: 0.2785
2024-12-29 13:47:14,824 - INFO - Epoch 33/500, Train Loss: 0.0805, Val Loss: 0.2626
2024-12-29 13:47:15,177 - INFO - Epoch 34/500, Train Loss: 0.0795, Val Loss: 0.2608
2024-12-29 13:47:15,534 - INFO - Epoch 35/500, Train Loss: 0.0792, Val Loss: 0.2631
2024-12-29 13:47:15,909 - INFO - Epoch 36/500, Train Loss: 0.0789, Val Loss: 0.2743
2024-12-29 13:47:16,246 - INFO - Epoch 37/500, Train Loss: 0.0788, Val Loss: 0.2655
2024-12-29 13:47:16,634 - INFO - Epoch 38/500, Train Loss: 0.0782, Val Loss: 0.2710
2024-12-29 13:47:16,998 - INFO - Epoch 39/500, Train Loss: 0.0780, Val Loss: 0.2652
2024-12-29 13:47:16,998 - INFO - Early stopping triggered at epoch 39
2024-12-29 13:47:16,998 - INFO - Training completed in 13.57s
2024-12-29 13:47:16,999 - INFO - Final memory usage: CPU 2718.0 MB, GPU 104.2 MB
2024-12-29 13:47:17,000 - INFO - Model training completed in 13.58s
2024-12-29 13:47:17,059 - INFO - Prediction completed in 0.06s
2024-12-29 13:47:17,073 - INFO - Poison rate 0.03 completed in 18.54s
2024-12-29 13:47:17,073 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:47:17,074 - INFO - Total number of labels flipped: 420
2024-12-29 13:47:17,074 - INFO - Label flipping completed in 0.00s
2024-12-29 13:47:17,074 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:47:17,074 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:47:17,647 - INFO - Feature scaling completed in 0.57s
2024-12-29 13:47:17,648 - INFO - Starting feature selection (k=50)
2024-12-29 13:47:17,666 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 13:47:17,667 - INFO - Starting anomaly detection
2024-12-29 13:47:20,712 - INFO - Anomaly detection completed in 3.04s
2024-12-29 13:47:20,712 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:47:20,712 - INFO - Total fit_transform time: 3.64s
2024-12-29 13:47:20,712 - INFO - Training set processing completed in 3.64s
2024-12-29 13:47:20,712 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:47:20,713 - INFO - Memory usage at start_fit: CPU 2708.5 MB, GPU 104.1 MB
2024-12-29 13:47:20,714 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:47:20,717 - INFO - Number of unique classes: 10
2024-12-29 13:47:20,790 - INFO - Fitted scaler and transformed data
2024-12-29 13:47:20,790 - INFO - Scaling time: 0.07s
2024-12-29 13:47:21,105 - INFO - Epoch 1/500, Train Loss: 1.3803, Val Loss: 0.5559
2024-12-29 13:47:21,431 - INFO - Epoch 2/500, Train Loss: 0.5633, Val Loss: 0.5005
2024-12-29 13:47:21,834 - INFO - Epoch 3/500, Train Loss: 0.4642, Val Loss: 0.4608
2024-12-29 13:47:22,165 - INFO - Epoch 4/500, Train Loss: 0.3968, Val Loss: 0.4384
2024-12-29 13:47:22,464 - INFO - Epoch 5/500, Train Loss: 0.3462, Val Loss: 0.4309
2024-12-29 13:47:22,800 - INFO - Epoch 6/500, Train Loss: 0.3083, Val Loss: 0.4015
2024-12-29 13:47:23,188 - INFO - Epoch 7/500, Train Loss: 0.2771, Val Loss: 0.3817
2024-12-29 13:47:23,514 - INFO - Epoch 8/500, Train Loss: 0.2517, Val Loss: 0.3826
2024-12-29 13:47:23,928 - INFO - Epoch 9/500, Train Loss: 0.2332, Val Loss: 0.3698
2024-12-29 13:47:24,332 - INFO - Epoch 10/500, Train Loss: 0.2203, Val Loss: 0.3606
2024-12-29 13:47:24,720 - INFO - Epoch 11/500, Train Loss: 0.2074, Val Loss: 0.3530
2024-12-29 13:47:25,039 - INFO - Epoch 12/500, Train Loss: 0.1963, Val Loss: 0.3551
2024-12-29 13:47:25,391 - INFO - Epoch 13/500, Train Loss: 0.1861, Val Loss: 0.3440
2024-12-29 13:47:25,751 - INFO - Epoch 14/500, Train Loss: 0.1763, Val Loss: 0.3408
2024-12-29 13:47:26,134 - INFO - Epoch 15/500, Train Loss: 0.1697, Val Loss: 0.3370
2024-12-29 13:47:26,463 - INFO - Epoch 16/500, Train Loss: 0.1659, Val Loss: 0.3238
2024-12-29 13:47:26,791 - INFO - Epoch 17/500, Train Loss: 0.1616, Val Loss: 0.3288
2024-12-29 13:47:27,183 - INFO - Epoch 18/500, Train Loss: 0.1580, Val Loss: 0.3306
2024-12-29 13:47:27,545 - INFO - Epoch 19/500, Train Loss: 0.1544, Val Loss: 0.3218
2024-12-29 13:47:27,872 - INFO - Epoch 20/500, Train Loss: 0.1517, Val Loss: 0.3119
2024-12-29 13:47:28,220 - INFO - Epoch 21/500, Train Loss: 0.1500, Val Loss: 0.3225
2024-12-29 13:47:28,564 - INFO - Epoch 22/500, Train Loss: 0.1458, Val Loss: 0.3166
2024-12-29 13:47:28,928 - INFO - Epoch 23/500, Train Loss: 0.1426, Val Loss: 0.3193
2024-12-29 13:47:29,267 - INFO - Epoch 24/500, Train Loss: 0.1410, Val Loss: 0.3110
2024-12-29 13:47:29,605 - INFO - Epoch 25/500, Train Loss: 0.1415, Val Loss: 0.3180
2024-12-29 13:47:29,606 - INFO - Early stopping triggered at epoch 25
2024-12-29 13:47:29,606 - INFO - Training completed in 8.89s
2024-12-29 13:47:29,606 - INFO - Final memory usage: CPU 2718.0 MB, GPU 104.2 MB
2024-12-29 13:47:29,607 - INFO - Model training completed in 8.89s
2024-12-29 13:47:29,652 - INFO - Prediction completed in 0.05s
2024-12-29 13:47:29,661 - INFO - Poison rate 0.05 completed in 12.59s
2024-12-29 13:47:29,661 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:47:29,662 - INFO - Total number of labels flipped: 590
2024-12-29 13:47:29,663 - INFO - Label flipping completed in 0.00s
2024-12-29 13:47:29,663 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:47:29,663 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:47:30,233 - INFO - Feature scaling completed in 0.57s
2024-12-29 13:47:30,233 - INFO - Starting feature selection (k=50)
2024-12-29 13:47:30,248 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:47:30,248 - INFO - Starting anomaly detection
2024-12-29 13:47:33,571 - INFO - Anomaly detection completed in 3.32s
2024-12-29 13:47:33,571 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:47:33,572 - INFO - Total fit_transform time: 3.91s
2024-12-29 13:47:33,572 - INFO - Training set processing completed in 3.91s
2024-12-29 13:47:33,572 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:47:33,573 - INFO - Memory usage at start_fit: CPU 2708.7 MB, GPU 104.1 MB
2024-12-29 13:47:33,573 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:47:33,576 - INFO - Number of unique classes: 10
2024-12-29 13:47:33,648 - INFO - Fitted scaler and transformed data
2024-12-29 13:47:33,649 - INFO - Scaling time: 0.07s
2024-12-29 13:47:33,988 - INFO - Epoch 1/500, Train Loss: 1.3189, Val Loss: 0.8415
2024-12-29 13:47:34,325 - INFO - Epoch 2/500, Train Loss: 0.6733, Val Loss: 0.7332
2024-12-29 13:47:34,617 - INFO - Epoch 3/500, Train Loss: 0.5606, Val Loss: 0.6814
2024-12-29 13:47:34,962 - INFO - Epoch 4/500, Train Loss: 0.4760, Val Loss: 0.6139
2024-12-29 13:47:35,328 - INFO - Epoch 5/500, Train Loss: 0.4134, Val Loss: 0.5972
2024-12-29 13:47:35,727 - INFO - Epoch 6/500, Train Loss: 0.3601, Val Loss: 0.5533
2024-12-29 13:47:36,130 - INFO - Epoch 7/500, Train Loss: 0.3275, Val Loss: 0.5278
2024-12-29 13:47:36,483 - INFO - Epoch 8/500, Train Loss: 0.2986, Val Loss: 0.5065
2024-12-29 13:47:36,852 - INFO - Epoch 9/500, Train Loss: 0.2779, Val Loss: 0.4913
2024-12-29 13:47:37,201 - INFO - Epoch 10/500, Train Loss: 0.2573, Val Loss: 0.4769
2024-12-29 13:47:37,536 - INFO - Epoch 11/500, Train Loss: 0.2465, Val Loss: 0.4647
2024-12-29 13:47:37,886 - INFO - Epoch 12/500, Train Loss: 0.2345, Val Loss: 0.4556
2024-12-29 13:47:38,247 - INFO - Epoch 13/500, Train Loss: 0.2268, Val Loss: 0.4536
2024-12-29 13:47:38,636 - INFO - Epoch 14/500, Train Loss: 0.2186, Val Loss: 0.4405
2024-12-29 13:47:39,020 - INFO - Epoch 15/500, Train Loss: 0.2126, Val Loss: 0.4308
2024-12-29 13:47:39,399 - INFO - Epoch 16/500, Train Loss: 0.2068, Val Loss: 0.4309
2024-12-29 13:47:39,752 - INFO - Epoch 17/500, Train Loss: 0.2011, Val Loss: 0.4242
2024-12-29 13:47:40,080 - INFO - Epoch 18/500, Train Loss: 0.2001, Val Loss: 0.4172
2024-12-29 13:47:40,424 - INFO - Epoch 19/500, Train Loss: 0.1963, Val Loss: 0.4304
2024-12-29 13:47:40,734 - INFO - Epoch 20/500, Train Loss: 0.1935, Val Loss: 0.4194
2024-12-29 13:47:41,085 - INFO - Epoch 21/500, Train Loss: 0.1896, Val Loss: 0.4276
2024-12-29 13:47:41,446 - INFO - Epoch 22/500, Train Loss: 0.1858, Val Loss: 0.4136
2024-12-29 13:47:41,774 - INFO - Epoch 23/500, Train Loss: 0.1841, Val Loss: 0.4301
2024-12-29 13:47:42,112 - INFO - Epoch 24/500, Train Loss: 0.1842, Val Loss: 0.4167
2024-12-29 13:47:42,451 - INFO - Epoch 25/500, Train Loss: 0.1801, Val Loss: 0.4064
2024-12-29 13:47:42,801 - INFO - Epoch 26/500, Train Loss: 0.1789, Val Loss: 0.4175
2024-12-29 13:47:43,143 - INFO - Epoch 27/500, Train Loss: 0.1771, Val Loss: 0.4164
2024-12-29 13:47:43,516 - INFO - Epoch 28/500, Train Loss: 0.1744, Val Loss: 0.4058
2024-12-29 13:47:43,857 - INFO - Epoch 29/500, Train Loss: 0.1736, Val Loss: 0.4134
2024-12-29 13:47:44,195 - INFO - Epoch 30/500, Train Loss: 0.1729, Val Loss: 0.4172
2024-12-29 13:47:44,195 - INFO - Early stopping triggered at epoch 30
2024-12-29 13:47:44,195 - INFO - Training completed in 10.62s
2024-12-29 13:47:44,196 - INFO - Final memory usage: CPU 2718.2 MB, GPU 104.2 MB
2024-12-29 13:47:44,197 - INFO - Model training completed in 10.62s
2024-12-29 13:47:44,262 - INFO - Prediction completed in 0.07s
2024-12-29 13:47:44,271 - INFO - Poison rate 0.07 completed in 14.61s
2024-12-29 13:47:44,271 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:47:44,272 - INFO - Total number of labels flipped: 831
2024-12-29 13:47:44,272 - INFO - Label flipping completed in 0.00s
2024-12-29 13:47:44,272 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:47:44,272 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:47:44,803 - INFO - Feature scaling completed in 0.53s
2024-12-29 13:47:44,804 - INFO - Starting feature selection (k=50)
2024-12-29 13:47:44,823 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 13:47:44,823 - INFO - Starting anomaly detection
2024-12-29 13:47:47,310 - INFO - Anomaly detection completed in 2.49s
2024-12-29 13:47:47,310 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:47:47,310 - INFO - Total fit_transform time: 3.04s
2024-12-29 13:47:47,310 - INFO - Training set processing completed in 3.04s
2024-12-29 13:47:47,310 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:47:47,311 - INFO - Memory usage at start_fit: CPU 2708.7 MB, GPU 104.1 MB
2024-12-29 13:47:47,312 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:47:47,315 - INFO - Number of unique classes: 10
2024-12-29 13:47:47,389 - INFO - Fitted scaler and transformed data
2024-12-29 13:47:47,390 - INFO - Scaling time: 0.07s
2024-12-29 13:47:47,718 - INFO - Epoch 1/500, Train Loss: 1.6912, Val Loss: 0.9588
2024-12-29 13:47:48,034 - INFO - Epoch 2/500, Train Loss: 0.9517, Val Loss: 0.8747
2024-12-29 13:47:48,349 - INFO - Epoch 3/500, Train Loss: 0.7899, Val Loss: 0.7817
2024-12-29 13:47:48,657 - INFO - Epoch 4/500, Train Loss: 0.6762, Val Loss: 0.6986
2024-12-29 13:47:49,016 - INFO - Epoch 5/500, Train Loss: 0.5800, Val Loss: 0.6566
2024-12-29 13:47:49,326 - INFO - Epoch 6/500, Train Loss: 0.5126, Val Loss: 0.5934
2024-12-29 13:47:49,706 - INFO - Epoch 7/500, Train Loss: 0.4582, Val Loss: 0.5551
2024-12-29 13:47:50,043 - INFO - Epoch 8/500, Train Loss: 0.4134, Val Loss: 0.5193
2024-12-29 13:47:50,384 - INFO - Epoch 9/500, Train Loss: 0.3839, Val Loss: 0.4954
2024-12-29 13:47:50,771 - INFO - Epoch 10/500, Train Loss: 0.3586, Val Loss: 0.4661
2024-12-29 13:47:51,086 - INFO - Epoch 11/500, Train Loss: 0.3379, Val Loss: 0.4533
2024-12-29 13:47:51,421 - INFO - Epoch 12/500, Train Loss: 0.3230, Val Loss: 0.4419
2024-12-29 13:47:51,768 - INFO - Epoch 13/500, Train Loss: 0.3125, Val Loss: 0.4331
2024-12-29 13:47:52,172 - INFO - Epoch 14/500, Train Loss: 0.3039, Val Loss: 0.4307
2024-12-29 13:47:52,522 - INFO - Epoch 15/500, Train Loss: 0.2956, Val Loss: 0.4128
2024-12-29 13:47:52,878 - INFO - Epoch 16/500, Train Loss: 0.2897, Val Loss: 0.4163
2024-12-29 13:47:53,219 - INFO - Epoch 17/500, Train Loss: 0.2838, Val Loss: 0.4128
2024-12-29 13:47:53,554 - INFO - Epoch 18/500, Train Loss: 0.2792, Val Loss: 0.4075
2024-12-29 13:47:53,945 - INFO - Epoch 19/500, Train Loss: 0.2743, Val Loss: 0.4112
2024-12-29 13:47:54,369 - INFO - Epoch 20/500, Train Loss: 0.2701, Val Loss: 0.4091
2024-12-29 13:47:54,689 - INFO - Epoch 21/500, Train Loss: 0.2681, Val Loss: 0.4107
2024-12-29 13:47:55,010 - INFO - Epoch 22/500, Train Loss: 0.2625, Val Loss: 0.4054
2024-12-29 13:47:55,403 - INFO - Epoch 23/500, Train Loss: 0.2595, Val Loss: 0.3985
2024-12-29 13:47:55,770 - INFO - Epoch 24/500, Train Loss: 0.2593, Val Loss: 0.4101
2024-12-29 13:47:56,199 - INFO - Epoch 25/500, Train Loss: 0.2574, Val Loss: 0.4001
2024-12-29 13:47:56,547 - INFO - Epoch 26/500, Train Loss: 0.2559, Val Loss: 0.4102
2024-12-29 13:47:56,974 - INFO - Epoch 27/500, Train Loss: 0.2522, Val Loss: 0.4049
2024-12-29 13:47:57,382 - INFO - Epoch 28/500, Train Loss: 0.2510, Val Loss: 0.3919
2024-12-29 13:47:57,743 - INFO - Epoch 29/500, Train Loss: 0.2501, Val Loss: 0.3973
2024-12-29 13:47:58,151 - INFO - Epoch 30/500, Train Loss: 0.2472, Val Loss: 0.4167
2024-12-29 13:47:58,520 - INFO - Epoch 31/500, Train Loss: 0.2442, Val Loss: 0.4119
2024-12-29 13:47:58,869 - INFO - Epoch 32/500, Train Loss: 0.2460, Val Loss: 0.3989
2024-12-29 13:47:59,218 - INFO - Epoch 33/500, Train Loss: 0.2449, Val Loss: 0.4151
2024-12-29 13:47:59,218 - INFO - Early stopping triggered at epoch 33
2024-12-29 13:47:59,218 - INFO - Training completed in 11.91s
2024-12-29 13:47:59,218 - INFO - Final memory usage: CPU 2718.2 MB, GPU 104.2 MB
2024-12-29 13:47:59,220 - INFO - Model training completed in 11.91s
2024-12-29 13:47:59,284 - INFO - Prediction completed in 0.06s
2024-12-29 13:47:59,294 - INFO - Poison rate 0.1 completed in 15.02s
2024-12-29 13:47:59,294 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:47:59,296 - INFO - Total number of labels flipped: 1684
2024-12-29 13:47:59,296 - INFO - Label flipping completed in 0.00s
2024-12-29 13:47:59,296 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:47:59,296 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:47:59,856 - INFO - Feature scaling completed in 0.56s
2024-12-29 13:47:59,857 - INFO - Starting feature selection (k=50)
2024-12-29 13:47:59,871 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:47:59,871 - INFO - Starting anomaly detection
2024-12-29 13:48:02,573 - INFO - Anomaly detection completed in 2.70s
2024-12-29 13:48:02,574 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:48:02,574 - INFO - Total fit_transform time: 3.28s
2024-12-29 13:48:02,575 - INFO - Training set processing completed in 3.28s
2024-12-29 13:48:02,575 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:48:02,576 - INFO - Memory usage at start_fit: CPU 2708.7 MB, GPU 104.1 MB
2024-12-29 13:48:02,576 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:48:02,578 - INFO - Number of unique classes: 10
2024-12-29 13:48:02,663 - INFO - Fitted scaler and transformed data
2024-12-29 13:48:02,663 - INFO - Scaling time: 0.08s
2024-12-29 13:48:03,030 - INFO - Epoch 1/500, Train Loss: 2.6600, Val Loss: 1.9402
2024-12-29 13:48:03,330 - INFO - Epoch 2/500, Train Loss: 1.7101, Val Loss: 1.7144
2024-12-29 13:48:03,662 - INFO - Epoch 3/500, Train Loss: 1.4423, Val Loss: 1.5605
2024-12-29 13:48:03,978 - INFO - Epoch 4/500, Train Loss: 1.2147, Val Loss: 1.3936
2024-12-29 13:48:04,293 - INFO - Epoch 5/500, Train Loss: 1.0323, Val Loss: 1.2491
2024-12-29 13:48:04,598 - INFO - Epoch 6/500, Train Loss: 0.8864, Val Loss: 1.0951
2024-12-29 13:48:04,905 - INFO - Epoch 7/500, Train Loss: 0.7776, Val Loss: 0.9754
2024-12-29 13:48:05,205 - INFO - Epoch 8/500, Train Loss: 0.6971, Val Loss: 0.9053
2024-12-29 13:48:05,607 - INFO - Epoch 9/500, Train Loss: 0.6337, Val Loss: 0.8286
2024-12-29 13:48:05,960 - INFO - Epoch 10/500, Train Loss: 0.5906, Val Loss: 0.7846
2024-12-29 13:48:06,302 - INFO - Epoch 11/500, Train Loss: 0.5634, Val Loss: 0.7491
2024-12-29 13:48:06,627 - INFO - Epoch 12/500, Train Loss: 0.5449, Val Loss: 0.7316
2024-12-29 13:48:06,939 - INFO - Epoch 13/500, Train Loss: 0.5285, Val Loss: 0.7250
2024-12-29 13:48:07,256 - INFO - Epoch 14/500, Train Loss: 0.5110, Val Loss: 0.7164
2024-12-29 13:48:07,610 - INFO - Epoch 15/500, Train Loss: 0.5029, Val Loss: 0.6958
2024-12-29 13:48:07,976 - INFO - Epoch 16/500, Train Loss: 0.4920, Val Loss: 0.6967
2024-12-29 13:48:08,333 - INFO - Epoch 17/500, Train Loss: 0.4861, Val Loss: 0.6884
2024-12-29 13:48:08,677 - INFO - Epoch 18/500, Train Loss: 0.4798, Val Loss: 0.6897
2024-12-29 13:48:09,083 - INFO - Epoch 19/500, Train Loss: 0.4726, Val Loss: 0.6907
2024-12-29 13:48:09,478 - INFO - Epoch 20/500, Train Loss: 0.4681, Val Loss: 0.6873
2024-12-29 13:48:09,827 - INFO - Epoch 21/500, Train Loss: 0.4652, Val Loss: 0.6764
2024-12-29 13:48:10,260 - INFO - Epoch 22/500, Train Loss: 0.4602, Val Loss: 0.6811
2024-12-29 13:48:10,604 - INFO - Epoch 23/500, Train Loss: 0.4562, Val Loss: 0.6859
2024-12-29 13:48:11,024 - INFO - Epoch 24/500, Train Loss: 0.4526, Val Loss: 0.6877
2024-12-29 13:48:11,395 - INFO - Epoch 25/500, Train Loss: 0.4484, Val Loss: 0.6808
2024-12-29 13:48:11,768 - INFO - Epoch 26/500, Train Loss: 0.4462, Val Loss: 0.6952
2024-12-29 13:48:11,769 - INFO - Early stopping triggered at epoch 26
2024-12-29 13:48:11,769 - INFO - Training completed in 9.19s
2024-12-29 13:48:11,769 - INFO - Final memory usage: CPU 2718.2 MB, GPU 104.2 MB
2024-12-29 13:48:11,772 - INFO - Model training completed in 9.20s
2024-12-29 13:48:11,836 - INFO - Prediction completed in 0.06s
2024-12-29 13:48:11,845 - INFO - Poison rate 0.2 completed in 12.55s
2024-12-29 13:48:11,852 - INFO - Loaded 287 existing results
2024-12-29 13:48:11,852 - INFO - Total results to save: 294
2024-12-29 13:48:11,853 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:48:11,863 - INFO - Saved 294 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:48:11,863 - INFO - Total evaluation time: 133.35s
2024-12-29 13:48:11,865 - INFO - 
Progress: 44.8% - Evaluating ImageNette with LogisticRegression (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:48:12,064 - INFO - Loading datasets...
2024-12-29 13:48:12,085 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:48:12,086 - INFO - Extracting validation features...
2024-12-29 13:48:12,086 - INFO - Extracting features from 3925 samples...
2024-12-29 13:48:21,456 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:48:21,461 - INFO - Validation feature extraction completed in 9.38s
2024-12-29 13:48:21,462 - INFO - Extracting training features...
2024-12-29 13:48:21,462 - INFO - Extracting features from 9469 samples...
2024-12-29 13:48:43,749 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:48:43,758 - INFO - Training feature extraction completed in 22.30s
2024-12-29 13:48:43,758 - INFO - Creating model for classifier: LogisticRegression
2024-12-29 13:48:43,758 - INFO - Using device: cuda
2024-12-29 13:48:43,758 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:48:43,759 - INFO - Training set processing completed in 0.00s
2024-12-29 13:48:43,759 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:48:43,760 - INFO - Memory usage at start_fit: CPU 2681.5 MB, GPU 104.6 MB
2024-12-29 13:48:43,760 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:48:43,765 - INFO - Number of unique classes: 10
2024-12-29 13:48:43,835 - INFO - Fitted scaler and transformed data
2024-12-29 13:48:43,836 - INFO - Scaling time: 0.07s
2024-12-29 13:48:44,218 - INFO - Epoch 1/1000, Train Loss: 0.4943, Val Loss: 0.1010
2024-12-29 13:48:44,415 - INFO - Epoch 2/1000, Train Loss: 0.0962, Val Loss: 0.0689
2024-12-29 13:48:44,616 - INFO - Epoch 3/1000, Train Loss: 0.0691, Val Loss: 0.0565
2024-12-29 13:48:44,842 - INFO - Epoch 4/1000, Train Loss: 0.0559, Val Loss: 0.0511
2024-12-29 13:48:45,041 - INFO - Epoch 5/1000, Train Loss: 0.0481, Val Loss: 0.0476
2024-12-29 13:48:45,222 - INFO - Epoch 6/1000, Train Loss: 0.0429, Val Loss: 0.0461
2024-12-29 13:48:45,414 - INFO - Epoch 7/1000, Train Loss: 0.0392, Val Loss: 0.0449
2024-12-29 13:48:45,600 - INFO - Epoch 8/1000, Train Loss: 0.0365, Val Loss: 0.0436
2024-12-29 13:48:45,782 - INFO - Epoch 9/1000, Train Loss: 0.0349, Val Loss: 0.0436
2024-12-29 13:48:45,979 - INFO - Epoch 10/1000, Train Loss: 0.0334, Val Loss: 0.0428
2024-12-29 13:48:46,173 - INFO - Epoch 11/1000, Train Loss: 0.0324, Val Loss: 0.0425
2024-12-29 13:48:46,361 - INFO - Epoch 12/1000, Train Loss: 0.0317, Val Loss: 0.0423
2024-12-29 13:48:46,554 - INFO - Epoch 13/1000, Train Loss: 0.0311, Val Loss: 0.0425
2024-12-29 13:48:46,821 - INFO - Epoch 14/1000, Train Loss: 0.0305, Val Loss: 0.0419
2024-12-29 13:48:47,158 - INFO - Epoch 15/1000, Train Loss: 0.0297, Val Loss: 0.0411
2024-12-29 13:48:47,515 - INFO - Epoch 16/1000, Train Loss: 0.0298, Val Loss: 0.0414
2024-12-29 13:48:47,906 - INFO - Epoch 17/1000, Train Loss: 0.0296, Val Loss: 0.0413
2024-12-29 13:48:48,276 - INFO - Epoch 18/1000, Train Loss: 0.0292, Val Loss: 0.0407
2024-12-29 13:48:48,684 - INFO - Epoch 19/1000, Train Loss: 0.0289, Val Loss: 0.0412
2024-12-29 13:48:49,097 - INFO - Epoch 20/1000, Train Loss: 0.0287, Val Loss: 0.0408
2024-12-29 13:48:49,097 - INFO - Early stopping triggered at epoch 20
2024-12-29 13:48:49,097 - INFO - Training completed in 5.34s
2024-12-29 13:48:49,098 - INFO - Final memory usage: CPU 2718.2 MB, GPU 104.8 MB
2024-12-29 13:48:49,099 - INFO - Model training completed in 5.34s
2024-12-29 13:48:49,179 - INFO - Prediction completed in 0.08s
2024-12-29 13:48:49,188 - INFO - Poison rate 0.0 completed in 5.43s
2024-12-29 13:48:49,189 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:48:49,190 - INFO - Total number of labels flipped: 84
2024-12-29 13:48:49,190 - INFO - Label flipping completed in 0.00s
2024-12-29 13:48:49,190 - INFO - Training set processing completed in 0.00s
2024-12-29 13:48:49,190 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:48:49,191 - INFO - Memory usage at start_fit: CPU 2689.0 MB, GPU 104.7 MB
2024-12-29 13:48:49,192 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:48:49,195 - INFO - Number of unique classes: 10
2024-12-29 13:48:49,266 - INFO - Fitted scaler and transformed data
2024-12-29 13:48:49,266 - INFO - Scaling time: 0.07s
2024-12-29 13:48:49,644 - INFO - Epoch 1/1000, Train Loss: 0.5656, Val Loss: 0.1588
2024-12-29 13:48:50,042 - INFO - Epoch 2/1000, Train Loss: 0.1629, Val Loss: 0.1314
2024-12-29 13:48:50,408 - INFO - Epoch 3/1000, Train Loss: 0.1397, Val Loss: 0.1264
2024-12-29 13:48:50,813 - INFO - Epoch 4/1000, Train Loss: 0.1251, Val Loss: 0.1240
2024-12-29 13:48:51,240 - INFO - Epoch 5/1000, Train Loss: 0.1169, Val Loss: 0.1237
2024-12-29 13:48:51,662 - INFO - Epoch 6/1000, Train Loss: 0.1092, Val Loss: 0.1245
2024-12-29 13:48:52,031 - INFO - Epoch 7/1000, Train Loss: 0.1042, Val Loss: 0.1256
2024-12-29 13:48:52,449 - INFO - Epoch 8/1000, Train Loss: 0.1015, Val Loss: 0.1246
2024-12-29 13:48:52,816 - INFO - Epoch 9/1000, Train Loss: 0.0986, Val Loss: 0.1246
2024-12-29 13:48:52,816 - INFO - Early stopping triggered at epoch 9
2024-12-29 13:48:52,816 - INFO - Training completed in 3.63s
2024-12-29 13:48:52,817 - INFO - Final memory usage: CPU 2718.1 MB, GPU 104.8 MB
2024-12-29 13:48:52,818 - INFO - Model training completed in 3.63s
2024-12-29 13:48:52,866 - INFO - Prediction completed in 0.05s
2024-12-29 13:48:52,875 - INFO - Poison rate 0.01 completed in 3.69s
2024-12-29 13:48:52,875 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:48:52,876 - INFO - Total number of labels flipped: 257
2024-12-29 13:48:52,876 - INFO - Label flipping completed in 0.00s
2024-12-29 13:48:52,876 - INFO - Training set processing completed in 0.00s
2024-12-29 13:48:52,876 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:48:52,877 - INFO - Memory usage at start_fit: CPU 2688.8 MB, GPU 104.7 MB
2024-12-29 13:48:52,877 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:48:52,880 - INFO - Number of unique classes: 10
2024-12-29 13:48:52,970 - INFO - Fitted scaler and transformed data
2024-12-29 13:48:52,970 - INFO - Scaling time: 0.09s
2024-12-29 13:48:53,330 - INFO - Epoch 1/1000, Train Loss: 0.5960, Val Loss: 0.3648
2024-12-29 13:48:53,724 - INFO - Epoch 2/1000, Train Loss: 0.2778, Val Loss: 0.3395
2024-12-29 13:48:54,061 - INFO - Epoch 3/1000, Train Loss: 0.2547, Val Loss: 0.3274
2024-12-29 13:48:54,479 - INFO - Epoch 4/1000, Train Loss: 0.2401, Val Loss: 0.3172
2024-12-29 13:48:54,894 - INFO - Epoch 5/1000, Train Loss: 0.2298, Val Loss: 0.3133
2024-12-29 13:48:55,133 - INFO - Epoch 6/1000, Train Loss: 0.2208, Val Loss: 0.3086
2024-12-29 13:48:55,406 - INFO - Epoch 7/1000, Train Loss: 0.2136, Val Loss: 0.3056
2024-12-29 13:48:55,608 - INFO - Epoch 8/1000, Train Loss: 0.2087, Val Loss: 0.3043
2024-12-29 13:48:55,813 - INFO - Epoch 9/1000, Train Loss: 0.2035, Val Loss: 0.3009
2024-12-29 13:48:56,048 - INFO - Epoch 10/1000, Train Loss: 0.1998, Val Loss: 0.2992
2024-12-29 13:48:56,251 - INFO - Epoch 11/1000, Train Loss: 0.1956, Val Loss: 0.2988
2024-12-29 13:48:56,450 - INFO - Epoch 12/1000, Train Loss: 0.1909, Val Loss: 0.2965
2024-12-29 13:48:56,690 - INFO - Epoch 13/1000, Train Loss: 0.1892, Val Loss: 0.2952
2024-12-29 13:48:56,935 - INFO - Epoch 14/1000, Train Loss: 0.1856, Val Loss: 0.2935
2024-12-29 13:48:57,141 - INFO - Epoch 15/1000, Train Loss: 0.1843, Val Loss: 0.2901
2024-12-29 13:48:57,337 - INFO - Epoch 16/1000, Train Loss: 0.1822, Val Loss: 0.2948
2024-12-29 13:48:57,524 - INFO - Epoch 17/1000, Train Loss: 0.1799, Val Loss: 0.2909
2024-12-29 13:48:57,705 - INFO - Epoch 18/1000, Train Loss: 0.1777, Val Loss: 0.2886
2024-12-29 13:48:57,896 - INFO - Epoch 19/1000, Train Loss: 0.1768, Val Loss: 0.2888
2024-12-29 13:48:58,091 - INFO - Epoch 20/1000, Train Loss: 0.1757, Val Loss: 0.2903
2024-12-29 13:48:58,295 - INFO - Epoch 21/1000, Train Loss: 0.1750, Val Loss: 0.2867
2024-12-29 13:48:58,482 - INFO - Epoch 22/1000, Train Loss: 0.1725, Val Loss: 0.2826
2024-12-29 13:48:58,676 - INFO - Epoch 23/1000, Train Loss: 0.1724, Val Loss: 0.2851
2024-12-29 13:48:58,863 - INFO - Epoch 24/1000, Train Loss: 0.1725, Val Loss: 0.2816
2024-12-29 13:48:59,047 - INFO - Epoch 25/1000, Train Loss: 0.1701, Val Loss: 0.2870
2024-12-29 13:48:59,240 - INFO - Epoch 26/1000, Train Loss: 0.1691, Val Loss: 0.2897
2024-12-29 13:48:59,426 - INFO - Epoch 27/1000, Train Loss: 0.1680, Val Loss: 0.2799
2024-12-29 13:48:59,616 - INFO - Epoch 28/1000, Train Loss: 0.1693, Val Loss: 0.2789
2024-12-29 13:48:59,813 - INFO - Epoch 29/1000, Train Loss: 0.1678, Val Loss: 0.2802
2024-12-29 13:49:00,014 - INFO - Epoch 30/1000, Train Loss: 0.1667, Val Loss: 0.2790
2024-12-29 13:49:00,210 - INFO - Epoch 31/1000, Train Loss: 0.1670, Val Loss: 0.2853
2024-12-29 13:49:00,439 - INFO - Epoch 32/1000, Train Loss: 0.1662, Val Loss: 0.2771
2024-12-29 13:49:00,687 - INFO - Epoch 33/1000, Train Loss: 0.1648, Val Loss: 0.2810
2024-12-29 13:49:00,917 - INFO - Epoch 34/1000, Train Loss: 0.1654, Val Loss: 0.2777
2024-12-29 13:49:01,125 - INFO - Epoch 35/1000, Train Loss: 0.1641, Val Loss: 0.2757
2024-12-29 13:49:01,333 - INFO - Epoch 36/1000, Train Loss: 0.1653, Val Loss: 0.2758
2024-12-29 13:49:01,553 - INFO - Epoch 37/1000, Train Loss: 0.1648, Val Loss: 0.2753
2024-12-29 13:49:01,751 - INFO - Epoch 38/1000, Train Loss: 0.1634, Val Loss: 0.2804
2024-12-29 13:49:01,948 - INFO - Epoch 39/1000, Train Loss: 0.1638, Val Loss: 0.2773
2024-12-29 13:49:02,145 - INFO - Epoch 40/1000, Train Loss: 0.1642, Val Loss: 0.2760
2024-12-29 13:49:02,145 - INFO - Early stopping triggered at epoch 40
2024-12-29 13:49:02,145 - INFO - Training completed in 9.27s
2024-12-29 13:49:02,146 - INFO - Final memory usage: CPU 2717.9 MB, GPU 104.8 MB
2024-12-29 13:49:02,146 - INFO - Model training completed in 9.27s
2024-12-29 13:49:02,215 - INFO - Prediction completed in 0.07s
2024-12-29 13:49:02,223 - INFO - Poison rate 0.03 completed in 9.35s
2024-12-29 13:49:02,224 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:49:02,225 - INFO - Total number of labels flipped: 420
2024-12-29 13:49:02,225 - INFO - Label flipping completed in 0.00s
2024-12-29 13:49:02,225 - INFO - Training set processing completed in 0.00s
2024-12-29 13:49:02,225 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:49:02,226 - INFO - Memory usage at start_fit: CPU 2688.6 MB, GPU 104.7 MB
2024-12-29 13:49:02,226 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:49:02,229 - INFO - Number of unique classes: 10
2024-12-29 13:49:02,302 - INFO - Fitted scaler and transformed data
2024-12-29 13:49:02,302 - INFO - Scaling time: 0.07s
2024-12-29 13:49:02,510 - INFO - Epoch 1/1000, Train Loss: 0.6586, Val Loss: 0.3969
2024-12-29 13:49:02,725 - INFO - Epoch 2/1000, Train Loss: 0.3714, Val Loss: 0.3817
2024-12-29 13:49:02,930 - INFO - Epoch 3/1000, Train Loss: 0.3481, Val Loss: 0.3754
2024-12-29 13:49:03,124 - INFO - Epoch 4/1000, Train Loss: 0.3341, Val Loss: 0.3738
2024-12-29 13:49:03,316 - INFO - Epoch 5/1000, Train Loss: 0.3197, Val Loss: 0.3690
2024-12-29 13:49:03,514 - INFO - Epoch 6/1000, Train Loss: 0.3098, Val Loss: 0.3671
2024-12-29 13:49:03,709 - INFO - Epoch 7/1000, Train Loss: 0.3004, Val Loss: 0.3667
2024-12-29 13:49:03,916 - INFO - Epoch 8/1000, Train Loss: 0.2927, Val Loss: 0.3628
2024-12-29 13:49:04,101 - INFO - Epoch 9/1000, Train Loss: 0.2855, Val Loss: 0.3611
2024-12-29 13:49:04,300 - INFO - Epoch 10/1000, Train Loss: 0.2795, Val Loss: 0.3635
2024-12-29 13:49:04,514 - INFO - Epoch 11/1000, Train Loss: 0.2744, Val Loss: 0.3547
2024-12-29 13:49:04,712 - INFO - Epoch 12/1000, Train Loss: 0.2708, Val Loss: 0.3552
2024-12-29 13:49:04,930 - INFO - Epoch 13/1000, Train Loss: 0.2664, Val Loss: 0.3540
2024-12-29 13:49:05,118 - INFO - Epoch 14/1000, Train Loss: 0.2622, Val Loss: 0.3549
2024-12-29 13:49:05,318 - INFO - Epoch 15/1000, Train Loss: 0.2594, Val Loss: 0.3526
2024-12-29 13:49:05,517 - INFO - Epoch 16/1000, Train Loss: 0.2546, Val Loss: 0.3506
2024-12-29 13:49:05,714 - INFO - Epoch 17/1000, Train Loss: 0.2529, Val Loss: 0.3478
2024-12-29 13:49:05,916 - INFO - Epoch 18/1000, Train Loss: 0.2502, Val Loss: 0.3473
2024-12-29 13:49:06,123 - INFO - Epoch 19/1000, Train Loss: 0.2489, Val Loss: 0.3455
2024-12-29 13:49:06,327 - INFO - Epoch 20/1000, Train Loss: 0.2440, Val Loss: 0.3444
2024-12-29 13:49:06,543 - INFO - Epoch 21/1000, Train Loss: 0.2436, Val Loss: 0.3481
2024-12-29 13:49:06,760 - INFO - Epoch 22/1000, Train Loss: 0.2431, Val Loss: 0.3448
2024-12-29 13:49:06,965 - INFO - Epoch 23/1000, Train Loss: 0.2397, Val Loss: 0.3437
2024-12-29 13:49:07,167 - INFO - Epoch 24/1000, Train Loss: 0.2366, Val Loss: 0.3448
2024-12-29 13:49:07,367 - INFO - Epoch 25/1000, Train Loss: 0.2384, Val Loss: 0.3395
2024-12-29 13:49:07,569 - INFO - Epoch 26/1000, Train Loss: 0.2339, Val Loss: 0.3383
2024-12-29 13:49:07,764 - INFO - Epoch 27/1000, Train Loss: 0.2346, Val Loss: 0.3417
2024-12-29 13:49:07,982 - INFO - Epoch 28/1000, Train Loss: 0.2329, Val Loss: 0.3380
2024-12-29 13:49:08,222 - INFO - Epoch 29/1000, Train Loss: 0.2311, Val Loss: 0.3406
2024-12-29 13:49:08,421 - INFO - Epoch 30/1000, Train Loss: 0.2304, Val Loss: 0.3395
2024-12-29 13:49:08,633 - INFO - Epoch 31/1000, Train Loss: 0.2295, Val Loss: 0.3367
2024-12-29 13:49:08,825 - INFO - Epoch 32/1000, Train Loss: 0.2270, Val Loss: 0.3362
2024-12-29 13:49:09,032 - INFO - Epoch 33/1000, Train Loss: 0.2283, Val Loss: 0.3359
2024-12-29 13:49:09,225 - INFO - Epoch 34/1000, Train Loss: 0.2265, Val Loss: 0.3338
2024-12-29 13:49:09,420 - INFO - Epoch 35/1000, Train Loss: 0.2274, Val Loss: 0.3321
2024-12-29 13:49:09,623 - INFO - Epoch 36/1000, Train Loss: 0.2248, Val Loss: 0.3365
2024-12-29 13:49:09,825 - INFO - Epoch 37/1000, Train Loss: 0.2243, Val Loss: 0.3350
2024-12-29 13:49:10,002 - INFO - Epoch 38/1000, Train Loss: 0.2241, Val Loss: 0.3342
2024-12-29 13:49:10,209 - INFO - Epoch 39/1000, Train Loss: 0.2237, Val Loss: 0.3321
2024-12-29 13:49:10,396 - INFO - Epoch 40/1000, Train Loss: 0.2236, Val Loss: 0.3274
2024-12-29 13:49:10,594 - INFO - Epoch 41/1000, Train Loss: 0.2232, Val Loss: 0.3275
2024-12-29 13:49:10,792 - INFO - Epoch 42/1000, Train Loss: 0.2218, Val Loss: 0.3316
2024-12-29 13:49:10,988 - INFO - Epoch 43/1000, Train Loss: 0.2221, Val Loss: 0.3301
2024-12-29 13:49:11,189 - INFO - Epoch 44/1000, Train Loss: 0.2207, Val Loss: 0.3276
2024-12-29 13:49:11,386 - INFO - Epoch 45/1000, Train Loss: 0.2213, Val Loss: 0.3272
2024-12-29 13:49:11,386 - INFO - Early stopping triggered at epoch 45
2024-12-29 13:49:11,386 - INFO - Training completed in 9.16s
2024-12-29 13:49:11,387 - INFO - Final memory usage: CPU 2718.0 MB, GPU 104.8 MB
2024-12-29 13:49:11,389 - INFO - Model training completed in 9.16s
2024-12-29 13:49:11,454 - INFO - Prediction completed in 0.06s
2024-12-29 13:49:11,462 - INFO - Poison rate 0.05 completed in 9.24s
2024-12-29 13:49:11,463 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:49:11,464 - INFO - Total number of labels flipped: 589
2024-12-29 13:49:11,464 - INFO - Label flipping completed in 0.00s
2024-12-29 13:49:11,464 - INFO - Training set processing completed in 0.00s
2024-12-29 13:49:11,464 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:49:11,465 - INFO - Memory usage at start_fit: CPU 2688.7 MB, GPU 104.7 MB
2024-12-29 13:49:11,465 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:49:11,469 - INFO - Number of unique classes: 10
2024-12-29 13:49:11,536 - INFO - Fitted scaler and transformed data
2024-12-29 13:49:11,536 - INFO - Scaling time: 0.07s
2024-12-29 13:49:11,745 - INFO - Epoch 1/1000, Train Loss: 0.7658, Val Loss: 0.5496
2024-12-29 13:49:11,936 - INFO - Epoch 2/1000, Train Loss: 0.4657, Val Loss: 0.5231
2024-12-29 13:49:12,149 - INFO - Epoch 3/1000, Train Loss: 0.4392, Val Loss: 0.5130
2024-12-29 13:49:12,371 - INFO - Epoch 4/1000, Train Loss: 0.4186, Val Loss: 0.5082
2024-12-29 13:49:12,609 - INFO - Epoch 5/1000, Train Loss: 0.4021, Val Loss: 0.4980
2024-12-29 13:49:12,846 - INFO - Epoch 6/1000, Train Loss: 0.3911, Val Loss: 0.4908
2024-12-29 13:49:13,045 - INFO - Epoch 7/1000, Train Loss: 0.3784, Val Loss: 0.4878
2024-12-29 13:49:13,262 - INFO - Epoch 8/1000, Train Loss: 0.3705, Val Loss: 0.4813
2024-12-29 13:49:13,466 - INFO - Epoch 9/1000, Train Loss: 0.3630, Val Loss: 0.4783
2024-12-29 13:49:13,656 - INFO - Epoch 10/1000, Train Loss: 0.3549, Val Loss: 0.4744
2024-12-29 13:49:13,873 - INFO - Epoch 11/1000, Train Loss: 0.3500, Val Loss: 0.4719
2024-12-29 13:49:14,095 - INFO - Epoch 12/1000, Train Loss: 0.3432, Val Loss: 0.4678
2024-12-29 13:49:14,298 - INFO - Epoch 13/1000, Train Loss: 0.3379, Val Loss: 0.4692
2024-12-29 13:49:14,488 - INFO - Epoch 14/1000, Train Loss: 0.3333, Val Loss: 0.4661
2024-12-29 13:49:14,692 - INFO - Epoch 15/1000, Train Loss: 0.3289, Val Loss: 0.4574
2024-12-29 13:49:14,912 - INFO - Epoch 16/1000, Train Loss: 0.3255, Val Loss: 0.4580
2024-12-29 13:49:15,114 - INFO - Epoch 17/1000, Train Loss: 0.3204, Val Loss: 0.4566
2024-12-29 13:49:15,315 - INFO - Epoch 18/1000, Train Loss: 0.3173, Val Loss: 0.4506
2024-12-29 13:49:15,520 - INFO - Epoch 19/1000, Train Loss: 0.3150, Val Loss: 0.4516
2024-12-29 13:49:15,723 - INFO - Epoch 20/1000, Train Loss: 0.3114, Val Loss: 0.4495
2024-12-29 13:49:15,929 - INFO - Epoch 21/1000, Train Loss: 0.3085, Val Loss: 0.4480
2024-12-29 13:49:16,116 - INFO - Epoch 22/1000, Train Loss: 0.3062, Val Loss: 0.4445
2024-12-29 13:49:16,316 - INFO - Epoch 23/1000, Train Loss: 0.3050, Val Loss: 0.4377
2024-12-29 13:49:16,533 - INFO - Epoch 24/1000, Train Loss: 0.3039, Val Loss: 0.4400
2024-12-29 13:49:16,738 - INFO - Epoch 25/1000, Train Loss: 0.3022, Val Loss: 0.4409
2024-12-29 13:49:16,937 - INFO - Epoch 26/1000, Train Loss: 0.2987, Val Loss: 0.4363
2024-12-29 13:49:17,146 - INFO - Epoch 27/1000, Train Loss: 0.2964, Val Loss: 0.4445
2024-12-29 13:49:17,355 - INFO - Epoch 28/1000, Train Loss: 0.2943, Val Loss: 0.4346
2024-12-29 13:49:17,578 - INFO - Epoch 29/1000, Train Loss: 0.2953, Val Loss: 0.4322
2024-12-29 13:49:17,775 - INFO - Epoch 30/1000, Train Loss: 0.2911, Val Loss: 0.4329
2024-12-29 13:49:17,989 - INFO - Epoch 31/1000, Train Loss: 0.2913, Val Loss: 0.4338
2024-12-29 13:49:18,188 - INFO - Epoch 32/1000, Train Loss: 0.2902, Val Loss: 0.4288
2024-12-29 13:49:18,383 - INFO - Epoch 33/1000, Train Loss: 0.2871, Val Loss: 0.4215
2024-12-29 13:49:18,578 - INFO - Epoch 34/1000, Train Loss: 0.2875, Val Loss: 0.4322
2024-12-29 13:49:18,781 - INFO - Epoch 35/1000, Train Loss: 0.2872, Val Loss: 0.4224
2024-12-29 13:49:18,992 - INFO - Epoch 36/1000, Train Loss: 0.2852, Val Loss: 0.4233
2024-12-29 13:49:19,200 - INFO - Epoch 37/1000, Train Loss: 0.2850, Val Loss: 0.4258
2024-12-29 13:49:19,405 - INFO - Epoch 38/1000, Train Loss: 0.2839, Val Loss: 0.4222
2024-12-29 13:49:19,406 - INFO - Early stopping triggered at epoch 38
2024-12-29 13:49:19,406 - INFO - Training completed in 7.94s
2024-12-29 13:49:19,407 - INFO - Final memory usage: CPU 2718.0 MB, GPU 104.8 MB
2024-12-29 13:49:19,409 - INFO - Model training completed in 7.94s
2024-12-29 13:49:19,462 - INFO - Prediction completed in 0.05s
2024-12-29 13:49:19,470 - INFO - Poison rate 0.07 completed in 8.01s
2024-12-29 13:49:19,470 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:49:19,471 - INFO - Total number of labels flipped: 847
2024-12-29 13:49:19,472 - INFO - Label flipping completed in 0.00s
2024-12-29 13:49:19,472 - INFO - Training set processing completed in 0.00s
2024-12-29 13:49:19,472 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:49:19,473 - INFO - Memory usage at start_fit: CPU 2688.7 MB, GPU 104.7 MB
2024-12-29 13:49:19,473 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:49:19,476 - INFO - Number of unique classes: 10
2024-12-29 13:49:19,557 - INFO - Fitted scaler and transformed data
2024-12-29 13:49:19,558 - INFO - Scaling time: 0.08s
2024-12-29 13:49:19,779 - INFO - Epoch 1/1000, Train Loss: 0.8490, Val Loss: 0.6376
2024-12-29 13:49:19,996 - INFO - Epoch 2/1000, Train Loss: 0.5947, Val Loss: 0.6138
2024-12-29 13:49:20,216 - INFO - Epoch 3/1000, Train Loss: 0.5604, Val Loss: 0.6066
2024-12-29 13:49:20,422 - INFO - Epoch 4/1000, Train Loss: 0.5381, Val Loss: 0.5944
2024-12-29 13:49:20,662 - INFO - Epoch 5/1000, Train Loss: 0.5190, Val Loss: 0.5926
2024-12-29 13:49:20,874 - INFO - Epoch 6/1000, Train Loss: 0.5044, Val Loss: 0.5808
2024-12-29 13:49:21,075 - INFO - Epoch 7/1000, Train Loss: 0.4899, Val Loss: 0.5763
2024-12-29 13:49:21,278 - INFO - Epoch 8/1000, Train Loss: 0.4760, Val Loss: 0.5649
2024-12-29 13:49:21,500 - INFO - Epoch 9/1000, Train Loss: 0.4675, Val Loss: 0.5647
2024-12-29 13:49:21,702 - INFO - Epoch 10/1000, Train Loss: 0.4575, Val Loss: 0.5613
2024-12-29 13:49:21,901 - INFO - Epoch 11/1000, Train Loss: 0.4489, Val Loss: 0.5565
2024-12-29 13:49:22,107 - INFO - Epoch 12/1000, Train Loss: 0.4400, Val Loss: 0.5432
2024-12-29 13:49:22,313 - INFO - Epoch 13/1000, Train Loss: 0.4329, Val Loss: 0.5434
2024-12-29 13:49:22,504 - INFO - Epoch 14/1000, Train Loss: 0.4267, Val Loss: 0.5367
2024-12-29 13:49:22,700 - INFO - Epoch 15/1000, Train Loss: 0.4217, Val Loss: 0.5326
2024-12-29 13:49:22,886 - INFO - Epoch 16/1000, Train Loss: 0.4149, Val Loss: 0.5242
2024-12-29 13:49:23,072 - INFO - Epoch 17/1000, Train Loss: 0.4110, Val Loss: 0.5190
2024-12-29 13:49:23,268 - INFO - Epoch 18/1000, Train Loss: 0.4038, Val Loss: 0.5113
2024-12-29 13:49:23,450 - INFO - Epoch 19/1000, Train Loss: 0.4027, Val Loss: 0.5104
2024-12-29 13:49:23,644 - INFO - Epoch 20/1000, Train Loss: 0.3967, Val Loss: 0.5053
2024-12-29 13:49:23,843 - INFO - Epoch 21/1000, Train Loss: 0.3929, Val Loss: 0.5057
2024-12-29 13:49:24,062 - INFO - Epoch 22/1000, Train Loss: 0.3913, Val Loss: 0.5000
2024-12-29 13:49:24,289 - INFO - Epoch 23/1000, Train Loss: 0.3867, Val Loss: 0.4973
2024-12-29 13:49:24,467 - INFO - Epoch 24/1000, Train Loss: 0.3845, Val Loss: 0.4953
2024-12-29 13:49:24,699 - INFO - Epoch 25/1000, Train Loss: 0.3806, Val Loss: 0.4985
2024-12-29 13:49:24,913 - INFO - Epoch 26/1000, Train Loss: 0.3776, Val Loss: 0.4843
2024-12-29 13:49:25,137 - INFO - Epoch 27/1000, Train Loss: 0.3744, Val Loss: 0.4864
2024-12-29 13:49:25,443 - INFO - Epoch 28/1000, Train Loss: 0.3723, Val Loss: 0.4827
2024-12-29 13:49:25,731 - INFO - Epoch 29/1000, Train Loss: 0.3701, Val Loss: 0.4858
2024-12-29 13:49:26,153 - INFO - Epoch 30/1000, Train Loss: 0.3680, Val Loss: 0.4836
2024-12-29 13:49:26,396 - INFO - Epoch 31/1000, Train Loss: 0.3675, Val Loss: 0.4787
2024-12-29 13:49:26,599 - INFO - Epoch 32/1000, Train Loss: 0.3665, Val Loss: 0.4746
2024-12-29 13:49:26,787 - INFO - Epoch 33/1000, Train Loss: 0.3616, Val Loss: 0.4777
2024-12-29 13:49:26,991 - INFO - Epoch 34/1000, Train Loss: 0.3607, Val Loss: 0.4732
2024-12-29 13:49:27,187 - INFO - Epoch 35/1000, Train Loss: 0.3579, Val Loss: 0.4722
2024-12-29 13:49:27,388 - INFO - Epoch 36/1000, Train Loss: 0.3586, Val Loss: 0.4701
2024-12-29 13:49:27,573 - INFO - Epoch 37/1000, Train Loss: 0.3547, Val Loss: 0.4722
2024-12-29 13:49:27,845 - INFO - Epoch 38/1000, Train Loss: 0.3553, Val Loss: 0.4684
2024-12-29 13:49:28,189 - INFO - Epoch 39/1000, Train Loss: 0.3545, Val Loss: 0.4648
2024-12-29 13:49:28,501 - INFO - Epoch 40/1000, Train Loss: 0.3520, Val Loss: 0.4626
2024-12-29 13:49:28,898 - INFO - Epoch 41/1000, Train Loss: 0.3511, Val Loss: 0.4731
2024-12-29 13:49:29,313 - INFO - Epoch 42/1000, Train Loss: 0.3510, Val Loss: 0.4750
2024-12-29 13:49:29,730 - INFO - Epoch 43/1000, Train Loss: 0.3486, Val Loss: 0.4666
2024-12-29 13:49:30,156 - INFO - Epoch 44/1000, Train Loss: 0.3473, Val Loss: 0.4648
2024-12-29 13:49:30,488 - INFO - Epoch 45/1000, Train Loss: 0.3471, Val Loss: 0.4639
2024-12-29 13:49:30,488 - INFO - Early stopping triggered at epoch 45
2024-12-29 13:49:30,488 - INFO - Training completed in 11.02s
2024-12-29 13:49:30,488 - INFO - Final memory usage: CPU 2718.1 MB, GPU 104.8 MB
2024-12-29 13:49:30,489 - INFO - Model training completed in 11.02s
2024-12-29 13:49:30,539 - INFO - Prediction completed in 0.05s
2024-12-29 13:49:30,563 - INFO - Poison rate 0.1 completed in 11.09s
2024-12-29 13:49:30,564 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:49:30,568 - INFO - Total number of labels flipped: 1708
2024-12-29 13:49:30,568 - INFO - Label flipping completed in 0.00s
2024-12-29 13:49:30,569 - INFO - Training set processing completed in 0.00s
2024-12-29 13:49:30,569 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:49:30,570 - INFO - Memory usage at start_fit: CPU 2688.7 MB, GPU 104.7 MB
2024-12-29 13:49:30,570 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:49:30,575 - INFO - Number of unique classes: 10
2024-12-29 13:49:30,653 - INFO - Fitted scaler and transformed data
2024-12-29 13:49:30,654 - INFO - Scaling time: 0.08s
2024-12-29 13:49:31,062 - INFO - Epoch 1/1000, Train Loss: 1.2122, Val Loss: 1.0330
2024-12-29 13:49:31,428 - INFO - Epoch 2/1000, Train Loss: 0.9604, Val Loss: 0.9948
2024-12-29 13:49:31,654 - INFO - Epoch 3/1000, Train Loss: 0.9142, Val Loss: 0.9713
2024-12-29 13:49:31,874 - INFO - Epoch 4/1000, Train Loss: 0.8807, Val Loss: 0.9442
2024-12-29 13:49:32,098 - INFO - Epoch 5/1000, Train Loss: 0.8498, Val Loss: 0.9321
2024-12-29 13:49:32,317 - INFO - Epoch 6/1000, Train Loss: 0.8208, Val Loss: 0.9158
2024-12-29 13:49:32,511 - INFO - Epoch 7/1000, Train Loss: 0.7960, Val Loss: 0.8990
2024-12-29 13:49:32,689 - INFO - Epoch 8/1000, Train Loss: 0.7755, Val Loss: 0.8790
2024-12-29 13:49:32,882 - INFO - Epoch 9/1000, Train Loss: 0.7553, Val Loss: 0.8674
2024-12-29 13:49:33,076 - INFO - Epoch 10/1000, Train Loss: 0.7367, Val Loss: 0.8541
2024-12-29 13:49:33,272 - INFO - Epoch 11/1000, Train Loss: 0.7226, Val Loss: 0.8450
2024-12-29 13:49:33,471 - INFO - Epoch 12/1000, Train Loss: 0.7079, Val Loss: 0.8282
2024-12-29 13:49:33,691 - INFO - Epoch 13/1000, Train Loss: 0.6936, Val Loss: 0.8139
2024-12-29 13:49:33,890 - INFO - Epoch 14/1000, Train Loss: 0.6781, Val Loss: 0.8045
2024-12-29 13:49:34,084 - INFO - Epoch 15/1000, Train Loss: 0.6652, Val Loss: 0.7933
2024-12-29 13:49:34,275 - INFO - Epoch 16/1000, Train Loss: 0.6570, Val Loss: 0.7893
2024-12-29 13:49:34,470 - INFO - Epoch 17/1000, Train Loss: 0.6487, Val Loss: 0.7717
2024-12-29 13:49:34,677 - INFO - Epoch 18/1000, Train Loss: 0.6377, Val Loss: 0.7647
2024-12-29 13:49:34,878 - INFO - Epoch 19/1000, Train Loss: 0.6249, Val Loss: 0.7628
2024-12-29 13:49:35,074 - INFO - Epoch 20/1000, Train Loss: 0.6177, Val Loss: 0.7471
2024-12-29 13:49:35,266 - INFO - Epoch 21/1000, Train Loss: 0.6118, Val Loss: 0.7412
2024-12-29 13:49:35,446 - INFO - Epoch 22/1000, Train Loss: 0.6040, Val Loss: 0.7356
2024-12-29 13:49:35,636 - INFO - Epoch 23/1000, Train Loss: 0.5965, Val Loss: 0.7282
2024-12-29 13:49:35,839 - INFO - Epoch 24/1000, Train Loss: 0.5901, Val Loss: 0.7240
2024-12-29 13:49:36,067 - INFO - Epoch 25/1000, Train Loss: 0.5824, Val Loss: 0.7165
2024-12-29 13:49:36,269 - INFO - Epoch 26/1000, Train Loss: 0.5780, Val Loss: 0.7187
2024-12-29 13:49:36,474 - INFO - Epoch 27/1000, Train Loss: 0.5740, Val Loss: 0.7142
2024-12-29 13:49:36,661 - INFO - Epoch 28/1000, Train Loss: 0.5700, Val Loss: 0.7052
2024-12-29 13:49:36,867 - INFO - Epoch 29/1000, Train Loss: 0.5651, Val Loss: 0.7096
2024-12-29 13:49:37,073 - INFO - Epoch 30/1000, Train Loss: 0.5598, Val Loss: 0.7010
2024-12-29 13:49:37,267 - INFO - Epoch 31/1000, Train Loss: 0.5584, Val Loss: 0.6948
2024-12-29 13:49:37,490 - INFO - Epoch 32/1000, Train Loss: 0.5558, Val Loss: 0.6897
2024-12-29 13:49:37,713 - INFO - Epoch 33/1000, Train Loss: 0.5519, Val Loss: 0.6918
2024-12-29 13:49:37,943 - INFO - Epoch 34/1000, Train Loss: 0.5477, Val Loss: 0.6834
2024-12-29 13:49:38,178 - INFO - Epoch 35/1000, Train Loss: 0.5450, Val Loss: 0.6801
2024-12-29 13:49:38,391 - INFO - Epoch 36/1000, Train Loss: 0.5428, Val Loss: 0.6816
2024-12-29 13:49:38,644 - INFO - Epoch 37/1000, Train Loss: 0.5400, Val Loss: 0.6773
2024-12-29 13:49:38,868 - INFO - Epoch 38/1000, Train Loss: 0.5389, Val Loss: 0.6737
2024-12-29 13:49:39,091 - INFO - Epoch 39/1000, Train Loss: 0.5369, Val Loss: 0.6818
2024-12-29 13:49:39,315 - INFO - Epoch 40/1000, Train Loss: 0.5329, Val Loss: 0.6796
2024-12-29 13:49:39,535 - INFO - Epoch 41/1000, Train Loss: 0.5329, Val Loss: 0.6673
2024-12-29 13:49:39,754 - INFO - Epoch 42/1000, Train Loss: 0.5318, Val Loss: 0.6685
2024-12-29 13:49:39,966 - INFO - Epoch 43/1000, Train Loss: 0.5254, Val Loss: 0.6709
2024-12-29 13:49:40,173 - INFO - Epoch 44/1000, Train Loss: 0.5256, Val Loss: 0.6674
2024-12-29 13:49:40,378 - INFO - Epoch 45/1000, Train Loss: 0.5227, Val Loss: 0.6630
2024-12-29 13:49:40,583 - INFO - Epoch 46/1000, Train Loss: 0.5216, Val Loss: 0.6650
2024-12-29 13:49:40,805 - INFO - Epoch 47/1000, Train Loss: 0.5202, Val Loss: 0.6624
2024-12-29 13:49:41,009 - INFO - Epoch 48/1000, Train Loss: 0.5185, Val Loss: 0.6611
2024-12-29 13:49:41,219 - INFO - Epoch 49/1000, Train Loss: 0.5165, Val Loss: 0.6586
2024-12-29 13:49:41,496 - INFO - Epoch 50/1000, Train Loss: 0.5156, Val Loss: 0.6581
2024-12-29 13:49:41,743 - INFO - Epoch 51/1000, Train Loss: 0.5171, Val Loss: 0.6635
2024-12-29 13:49:41,955 - INFO - Epoch 52/1000, Train Loss: 0.5136, Val Loss: 0.6599
2024-12-29 13:49:42,179 - INFO - Epoch 53/1000, Train Loss: 0.5110, Val Loss: 0.6582
2024-12-29 13:49:42,385 - INFO - Epoch 54/1000, Train Loss: 0.5108, Val Loss: 0.6555
2024-12-29 13:49:42,593 - INFO - Epoch 55/1000, Train Loss: 0.5093, Val Loss: 0.6511
2024-12-29 13:49:42,815 - INFO - Epoch 56/1000, Train Loss: 0.5070, Val Loss: 0.6508
2024-12-29 13:49:43,048 - INFO - Epoch 57/1000, Train Loss: 0.5068, Val Loss: 0.6540
2024-12-29 13:49:43,274 - INFO - Epoch 58/1000, Train Loss: 0.5060, Val Loss: 0.6486
2024-12-29 13:49:43,470 - INFO - Epoch 59/1000, Train Loss: 0.5062, Val Loss: 0.6519
2024-12-29 13:49:43,697 - INFO - Epoch 60/1000, Train Loss: 0.5070, Val Loss: 0.6485
2024-12-29 13:49:43,957 - INFO - Epoch 61/1000, Train Loss: 0.5064, Val Loss: 0.6496
2024-12-29 13:49:44,203 - INFO - Epoch 62/1000, Train Loss: 0.5028, Val Loss: 0.6469
2024-12-29 13:49:44,429 - INFO - Epoch 63/1000, Train Loss: 0.5025, Val Loss: 0.6501
2024-12-29 13:49:44,666 - INFO - Epoch 64/1000, Train Loss: 0.5006, Val Loss: 0.6466
2024-12-29 13:49:44,881 - INFO - Epoch 65/1000, Train Loss: 0.4996, Val Loss: 0.6484
2024-12-29 13:49:45,087 - INFO - Epoch 66/1000, Train Loss: 0.5027, Val Loss: 0.6460
2024-12-29 13:49:45,335 - INFO - Epoch 67/1000, Train Loss: 0.5009, Val Loss: 0.6489
2024-12-29 13:49:45,335 - INFO - Early stopping triggered at epoch 67
2024-12-29 13:49:45,335 - INFO - Training completed in 14.77s
2024-12-29 13:49:45,336 - INFO - Final memory usage: CPU 2717.9 MB, GPU 104.8 MB
2024-12-29 13:49:45,339 - INFO - Model training completed in 14.77s
2024-12-29 13:49:45,429 - INFO - Prediction completed in 0.09s
2024-12-29 13:49:45,438 - INFO - Poison rate 0.2 completed in 14.87s
2024-12-29 13:49:45,444 - INFO - Loaded 294 existing results
2024-12-29 13:49:45,444 - INFO - Total results to save: 301
2024-12-29 13:49:45,445 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:49:45,455 - INFO - Saved 301 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:49:45,455 - INFO - Total evaluation time: 93.39s
2024-12-29 13:49:45,457 - INFO - 
Progress: 45.8% - Evaluating ImageNette with LogisticRegression (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:49:45,686 - INFO - Loading datasets...
2024-12-29 13:49:45,708 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:49:45,708 - INFO - Extracting validation features...
2024-12-29 13:49:45,708 - INFO - Extracting features from 3925 samples...
2024-12-29 13:49:55,119 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:49:55,125 - INFO - Validation feature extraction completed in 9.42s
2024-12-29 13:49:55,126 - INFO - Extracting training features...
2024-12-29 13:49:55,126 - INFO - Extracting features from 9469 samples...
2024-12-29 13:50:16,874 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:50:16,882 - INFO - Training feature extraction completed in 21.76s
2024-12-29 13:50:16,882 - INFO - Creating model for classifier: LogisticRegression
2024-12-29 13:50:16,883 - INFO - Using device: cuda
2024-12-29 13:50:16,883 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:50:16,883 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:50:16,883 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:50:17,440 - INFO - Feature scaling completed in 0.56s
2024-12-29 13:50:17,440 - INFO - Starting feature selection (k=50)
2024-12-29 13:50:17,448 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:50:17,449 - INFO - Starting anomaly detection
2024-12-29 13:50:20,799 - INFO - Anomaly detection completed in 3.35s
2024-12-29 13:50:20,799 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:50:20,799 - INFO - Total fit_transform time: 3.92s
2024-12-29 13:50:20,799 - INFO - Training set processing completed in 3.92s
2024-12-29 13:50:20,799 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:50:20,801 - INFO - Memory usage at start_fit: CPU 2709.3 MB, GPU 104.0 MB
2024-12-29 13:50:20,801 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:50:20,805 - INFO - Number of unique classes: 10
2024-12-29 13:50:20,878 - INFO - Fitted scaler and transformed data
2024-12-29 13:50:20,878 - INFO - Scaling time: 0.07s
2024-12-29 13:50:21,136 - INFO - Epoch 1/1000, Train Loss: 0.4971, Val Loss: 0.1179
2024-12-29 13:50:21,355 - INFO - Epoch 2/1000, Train Loss: 0.0947, Val Loss: 0.0826
2024-12-29 13:50:21,559 - INFO - Epoch 3/1000, Train Loss: 0.0680, Val Loss: 0.0683
2024-12-29 13:50:21,827 - INFO - Epoch 4/1000, Train Loss: 0.0546, Val Loss: 0.0618
2024-12-29 13:50:22,049 - INFO - Epoch 5/1000, Train Loss: 0.0474, Val Loss: 0.0575
2024-12-29 13:50:22,282 - INFO - Epoch 6/1000, Train Loss: 0.0422, Val Loss: 0.0545
2024-12-29 13:50:22,509 - INFO - Epoch 7/1000, Train Loss: 0.0388, Val Loss: 0.0527
2024-12-29 13:50:22,795 - INFO - Epoch 8/1000, Train Loss: 0.0363, Val Loss: 0.0512
2024-12-29 13:50:23,066 - INFO - Epoch 9/1000, Train Loss: 0.0346, Val Loss: 0.0504
2024-12-29 13:50:23,281 - INFO - Epoch 10/1000, Train Loss: 0.0332, Val Loss: 0.0499
2024-12-29 13:50:23,532 - INFO - Epoch 11/1000, Train Loss: 0.0323, Val Loss: 0.0492
2024-12-29 13:50:23,731 - INFO - Epoch 12/1000, Train Loss: 0.0315, Val Loss: 0.0487
2024-12-29 13:50:23,945 - INFO - Epoch 13/1000, Train Loss: 0.0307, Val Loss: 0.0491
2024-12-29 13:50:24,157 - INFO - Epoch 14/1000, Train Loss: 0.0303, Val Loss: 0.0476
2024-12-29 13:50:24,365 - INFO - Epoch 15/1000, Train Loss: 0.0299, Val Loss: 0.0479
2024-12-29 13:50:24,573 - INFO - Epoch 16/1000, Train Loss: 0.0296, Val Loss: 0.0474
2024-12-29 13:50:24,787 - INFO - Epoch 17/1000, Train Loss: 0.0294, Val Loss: 0.0476
2024-12-29 13:50:24,992 - INFO - Epoch 18/1000, Train Loss: 0.0292, Val Loss: 0.0478
2024-12-29 13:50:25,195 - INFO - Epoch 19/1000, Train Loss: 0.0288, Val Loss: 0.0470
2024-12-29 13:50:25,195 - INFO - Early stopping triggered at epoch 19
2024-12-29 13:50:25,195 - INFO - Training completed in 4.40s
2024-12-29 13:50:25,196 - INFO - Final memory usage: CPU 2718.3 MB, GPU 104.2 MB
2024-12-29 13:50:25,197 - INFO - Model training completed in 4.40s
2024-12-29 13:50:25,243 - INFO - Prediction completed in 0.05s
2024-12-29 13:50:25,252 - INFO - Poison rate 0.0 completed in 8.37s
2024-12-29 13:50:25,252 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:50:25,253 - INFO - Total number of labels flipped: 84
2024-12-29 13:50:25,253 - INFO - Label flipping completed in 0.00s
2024-12-29 13:50:25,253 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:50:25,254 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:50:25,790 - INFO - Feature scaling completed in 0.54s
2024-12-29 13:50:25,790 - INFO - Starting feature selection (k=50)
2024-12-29 13:50:25,804 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:50:25,805 - INFO - Starting anomaly detection
2024-12-29 13:50:29,966 - INFO - Anomaly detection completed in 4.16s
2024-12-29 13:50:29,966 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:50:29,967 - INFO - Total fit_transform time: 4.71s
2024-12-29 13:50:29,967 - INFO - Training set processing completed in 4.71s
2024-12-29 13:50:29,967 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:50:29,968 - INFO - Memory usage at start_fit: CPU 2709.0 MB, GPU 104.1 MB
2024-12-29 13:50:29,968 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:50:29,970 - INFO - Number of unique classes: 10
2024-12-29 13:50:30,042 - INFO - Fitted scaler and transformed data
2024-12-29 13:50:30,043 - INFO - Scaling time: 0.07s
2024-12-29 13:50:30,262 - INFO - Epoch 1/1000, Train Loss: 0.5295, Val Loss: 0.1932
2024-12-29 13:50:30,480 - INFO - Epoch 2/1000, Train Loss: 0.1543, Val Loss: 0.1671
2024-12-29 13:50:30,753 - INFO - Epoch 3/1000, Train Loss: 0.1328, Val Loss: 0.1570
2024-12-29 13:50:30,961 - INFO - Epoch 4/1000, Train Loss: 0.1185, Val Loss: 0.1519
2024-12-29 13:50:31,156 - INFO - Epoch 5/1000, Train Loss: 0.1104, Val Loss: 0.1502
2024-12-29 13:50:31,356 - INFO - Epoch 6/1000, Train Loss: 0.1059, Val Loss: 0.1487
2024-12-29 13:50:31,549 - INFO - Epoch 7/1000, Train Loss: 0.1012, Val Loss: 0.1474
2024-12-29 13:50:31,736 - INFO - Epoch 8/1000, Train Loss: 0.0969, Val Loss: 0.1485
2024-12-29 13:50:31,932 - INFO - Epoch 9/1000, Train Loss: 0.0933, Val Loss: 0.1470
2024-12-29 13:50:32,161 - INFO - Epoch 10/1000, Train Loss: 0.0917, Val Loss: 0.1462
2024-12-29 13:50:32,378 - INFO - Epoch 11/1000, Train Loss: 0.0892, Val Loss: 0.1454
2024-12-29 13:50:32,593 - INFO - Epoch 12/1000, Train Loss: 0.0878, Val Loss: 0.1471
2024-12-29 13:50:32,808 - INFO - Epoch 13/1000, Train Loss: 0.0863, Val Loss: 0.1452
2024-12-29 13:50:33,012 - INFO - Epoch 14/1000, Train Loss: 0.0850, Val Loss: 0.1436
2024-12-29 13:50:33,204 - INFO - Epoch 15/1000, Train Loss: 0.0847, Val Loss: 0.1462
2024-12-29 13:50:33,399 - INFO - Epoch 16/1000, Train Loss: 0.0833, Val Loss: 0.1452
2024-12-29 13:50:33,608 - INFO - Epoch 17/1000, Train Loss: 0.0824, Val Loss: 0.1459
2024-12-29 13:50:33,792 - INFO - Epoch 18/1000, Train Loss: 0.0817, Val Loss: 0.1465
2024-12-29 13:50:34,001 - INFO - Epoch 19/1000, Train Loss: 0.0805, Val Loss: 0.1460
2024-12-29 13:50:34,001 - INFO - Early stopping triggered at epoch 19
2024-12-29 13:50:34,002 - INFO - Training completed in 4.03s
2024-12-29 13:50:34,003 - INFO - Final memory usage: CPU 2718.3 MB, GPU 104.2 MB
2024-12-29 13:50:34,005 - INFO - Model training completed in 4.04s
2024-12-29 13:50:34,094 - INFO - Prediction completed in 0.09s
2024-12-29 13:50:34,103 - INFO - Poison rate 0.01 completed in 8.85s
2024-12-29 13:50:34,103 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:50:34,104 - INFO - Total number of labels flipped: 263
2024-12-29 13:50:34,104 - INFO - Label flipping completed in 0.00s
2024-12-29 13:50:34,104 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:50:34,104 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:50:34,650 - INFO - Feature scaling completed in 0.55s
2024-12-29 13:50:34,650 - INFO - Starting feature selection (k=50)
2024-12-29 13:50:34,664 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:50:34,664 - INFO - Starting anomaly detection
2024-12-29 13:50:38,735 - INFO - Anomaly detection completed in 4.07s
2024-12-29 13:50:38,735 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:50:38,735 - INFO - Total fit_transform time: 4.63s
2024-12-29 13:50:38,735 - INFO - Training set processing completed in 4.63s
2024-12-29 13:50:38,735 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:50:38,736 - INFO - Memory usage at start_fit: CPU 2709.0 MB, GPU 104.1 MB
2024-12-29 13:50:38,736 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:50:38,739 - INFO - Number of unique classes: 10
2024-12-29 13:50:38,811 - INFO - Fitted scaler and transformed data
2024-12-29 13:50:38,811 - INFO - Scaling time: 0.07s
2024-12-29 13:50:39,028 - INFO - Epoch 1/1000, Train Loss: 0.6282, Val Loss: 0.3036
2024-12-29 13:50:39,239 - INFO - Epoch 2/1000, Train Loss: 0.2815, Val Loss: 0.2875
2024-12-29 13:50:39,426 - INFO - Epoch 3/1000, Train Loss: 0.2588, Val Loss: 0.2803
2024-12-29 13:50:39,614 - INFO - Epoch 4/1000, Train Loss: 0.2436, Val Loss: 0.2775
2024-12-29 13:50:39,823 - INFO - Epoch 5/1000, Train Loss: 0.2328, Val Loss: 0.2768
2024-12-29 13:50:40,039 - INFO - Epoch 6/1000, Train Loss: 0.2230, Val Loss: 0.2761
2024-12-29 13:50:40,252 - INFO - Epoch 7/1000, Train Loss: 0.2170, Val Loss: 0.2748
2024-12-29 13:50:40,489 - INFO - Epoch 8/1000, Train Loss: 0.2114, Val Loss: 0.2743
2024-12-29 13:50:40,689 - INFO - Epoch 9/1000, Train Loss: 0.2049, Val Loss: 0.2756
2024-12-29 13:50:40,889 - INFO - Epoch 10/1000, Train Loss: 0.2002, Val Loss: 0.2732
2024-12-29 13:50:41,118 - INFO - Epoch 11/1000, Train Loss: 0.1989, Val Loss: 0.2735
2024-12-29 13:50:41,347 - INFO - Epoch 12/1000, Train Loss: 0.1938, Val Loss: 0.2730
2024-12-29 13:50:41,563 - INFO - Epoch 13/1000, Train Loss: 0.1901, Val Loss: 0.2716
2024-12-29 13:50:41,772 - INFO - Epoch 14/1000, Train Loss: 0.1881, Val Loss: 0.2743
2024-12-29 13:50:41,973 - INFO - Epoch 15/1000, Train Loss: 0.1850, Val Loss: 0.2702
2024-12-29 13:50:42,166 - INFO - Epoch 16/1000, Train Loss: 0.1854, Val Loss: 0.2712
2024-12-29 13:50:42,363 - INFO - Epoch 17/1000, Train Loss: 0.1816, Val Loss: 0.2703
2024-12-29 13:50:42,553 - INFO - Epoch 18/1000, Train Loss: 0.1793, Val Loss: 0.2702
2024-12-29 13:50:42,751 - INFO - Epoch 19/1000, Train Loss: 0.1796, Val Loss: 0.2664
2024-12-29 13:50:43,003 - INFO - Epoch 20/1000, Train Loss: 0.1765, Val Loss: 0.2684
2024-12-29 13:50:43,241 - INFO - Epoch 21/1000, Train Loss: 0.1776, Val Loss: 0.2680
2024-12-29 13:50:43,459 - INFO - Epoch 22/1000, Train Loss: 0.1754, Val Loss: 0.2715
2024-12-29 13:50:43,667 - INFO - Epoch 23/1000, Train Loss: 0.1745, Val Loss: 0.2696
2024-12-29 13:50:43,886 - INFO - Epoch 24/1000, Train Loss: 0.1734, Val Loss: 0.2686
2024-12-29 13:50:43,887 - INFO - Early stopping triggered at epoch 24
2024-12-29 13:50:43,887 - INFO - Training completed in 5.15s
2024-12-29 13:50:43,887 - INFO - Final memory usage: CPU 2718.3 MB, GPU 104.2 MB
2024-12-29 13:50:43,889 - INFO - Model training completed in 5.15s
2024-12-29 13:50:43,948 - INFO - Prediction completed in 0.06s
2024-12-29 13:50:43,958 - INFO - Poison rate 0.03 completed in 9.85s
2024-12-29 13:50:43,958 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:50:43,959 - INFO - Total number of labels flipped: 421
2024-12-29 13:50:43,959 - INFO - Label flipping completed in 0.00s
2024-12-29 13:50:43,959 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:50:43,959 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:50:44,542 - INFO - Feature scaling completed in 0.58s
2024-12-29 13:50:44,542 - INFO - Starting feature selection (k=50)
2024-12-29 13:50:44,560 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 13:50:44,561 - INFO - Starting anomaly detection
2024-12-29 13:50:48,698 - INFO - Anomaly detection completed in 4.14s
2024-12-29 13:50:48,698 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:50:48,698 - INFO - Total fit_transform time: 4.74s
2024-12-29 13:50:48,699 - INFO - Training set processing completed in 4.74s
2024-12-29 13:50:48,699 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:50:48,700 - INFO - Memory usage at start_fit: CPU 2708.7 MB, GPU 104.1 MB
2024-12-29 13:50:48,700 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:50:48,702 - INFO - Number of unique classes: 10
2024-12-29 13:50:48,774 - INFO - Fitted scaler and transformed data
2024-12-29 13:50:48,774 - INFO - Scaling time: 0.07s
2024-12-29 13:50:49,010 - INFO - Epoch 1/1000, Train Loss: 0.7020, Val Loss: 0.4184
2024-12-29 13:50:49,233 - INFO - Epoch 2/1000, Train Loss: 0.3775, Val Loss: 0.4016
2024-12-29 13:50:49,432 - INFO - Epoch 3/1000, Train Loss: 0.3523, Val Loss: 0.3943
2024-12-29 13:50:49,651 - INFO - Epoch 4/1000, Train Loss: 0.3348, Val Loss: 0.3877
2024-12-29 13:50:49,873 - INFO - Epoch 5/1000, Train Loss: 0.3221, Val Loss: 0.3834
2024-12-29 13:50:50,093 - INFO - Epoch 6/1000, Train Loss: 0.3104, Val Loss: 0.3819
2024-12-29 13:50:50,298 - INFO - Epoch 7/1000, Train Loss: 0.3022, Val Loss: 0.3770
2024-12-29 13:50:50,521 - INFO - Epoch 8/1000, Train Loss: 0.2941, Val Loss: 0.3761
2024-12-29 13:50:50,705 - INFO - Epoch 9/1000, Train Loss: 0.2878, Val Loss: 0.3700
2024-12-29 13:50:50,962 - INFO - Epoch 10/1000, Train Loss: 0.2810, Val Loss: 0.3715
2024-12-29 13:50:51,251 - INFO - Epoch 11/1000, Train Loss: 0.2758, Val Loss: 0.3723
2024-12-29 13:50:51,501 - INFO - Epoch 12/1000, Train Loss: 0.2716, Val Loss: 0.3672
2024-12-29 13:50:51,804 - INFO - Epoch 13/1000, Train Loss: 0.2677, Val Loss: 0.3674
2024-12-29 13:50:52,079 - INFO - Epoch 14/1000, Train Loss: 0.2650, Val Loss: 0.3653
2024-12-29 13:50:52,294 - INFO - Epoch 15/1000, Train Loss: 0.2604, Val Loss: 0.3639
2024-12-29 13:50:52,515 - INFO - Epoch 16/1000, Train Loss: 0.2583, Val Loss: 0.3634
2024-12-29 13:50:52,711 - INFO - Epoch 17/1000, Train Loss: 0.2563, Val Loss: 0.3584
2024-12-29 13:50:52,910 - INFO - Epoch 18/1000, Train Loss: 0.2522, Val Loss: 0.3551
2024-12-29 13:50:53,103 - INFO - Epoch 19/1000, Train Loss: 0.2504, Val Loss: 0.3526
2024-12-29 13:50:53,333 - INFO - Epoch 20/1000, Train Loss: 0.2489, Val Loss: 0.3543
2024-12-29 13:50:53,548 - INFO - Epoch 21/1000, Train Loss: 0.2466, Val Loss: 0.3514
2024-12-29 13:50:53,756 - INFO - Epoch 22/1000, Train Loss: 0.2447, Val Loss: 0.3517
2024-12-29 13:50:53,948 - INFO - Epoch 23/1000, Train Loss: 0.2441, Val Loss: 0.3529
2024-12-29 13:50:54,163 - INFO - Epoch 24/1000, Train Loss: 0.2415, Val Loss: 0.3477
2024-12-29 13:50:54,374 - INFO - Epoch 25/1000, Train Loss: 0.2437, Val Loss: 0.3436
2024-12-29 13:50:54,590 - INFO - Epoch 26/1000, Train Loss: 0.2398, Val Loss: 0.3451
2024-12-29 13:50:54,809 - INFO - Epoch 27/1000, Train Loss: 0.2380, Val Loss: 0.3452
2024-12-29 13:50:55,012 - INFO - Epoch 28/1000, Train Loss: 0.2371, Val Loss: 0.3427
2024-12-29 13:50:55,205 - INFO - Epoch 29/1000, Train Loss: 0.2355, Val Loss: 0.3405
2024-12-29 13:50:55,397 - INFO - Epoch 30/1000, Train Loss: 0.2334, Val Loss: 0.3431
2024-12-29 13:50:55,598 - INFO - Epoch 31/1000, Train Loss: 0.2338, Val Loss: 0.3435
2024-12-29 13:50:55,805 - INFO - Epoch 32/1000, Train Loss: 0.2333, Val Loss: 0.3405
2024-12-29 13:50:56,030 - INFO - Epoch 33/1000, Train Loss: 0.2319, Val Loss: 0.3421
2024-12-29 13:50:56,255 - INFO - Epoch 34/1000, Train Loss: 0.2311, Val Loss: 0.3365
2024-12-29 13:50:56,489 - INFO - Epoch 35/1000, Train Loss: 0.2301, Val Loss: 0.3368
2024-12-29 13:50:56,680 - INFO - Epoch 36/1000, Train Loss: 0.2295, Val Loss: 0.3347
2024-12-29 13:50:56,876 - INFO - Epoch 37/1000, Train Loss: 0.2298, Val Loss: 0.3365
2024-12-29 13:50:57,110 - INFO - Epoch 38/1000, Train Loss: 0.2274, Val Loss: 0.3373
2024-12-29 13:50:57,337 - INFO - Epoch 39/1000, Train Loss: 0.2276, Val Loss: 0.3364
2024-12-29 13:50:57,543 - INFO - Epoch 40/1000, Train Loss: 0.2270, Val Loss: 0.3358
2024-12-29 13:50:57,749 - INFO - Epoch 41/1000, Train Loss: 0.2276, Val Loss: 0.3346
2024-12-29 13:50:57,750 - INFO - Early stopping triggered at epoch 41
2024-12-29 13:50:57,750 - INFO - Training completed in 9.05s
2024-12-29 13:50:57,751 - INFO - Final memory usage: CPU 2718.3 MB, GPU 104.2 MB
2024-12-29 13:50:57,753 - INFO - Model training completed in 9.05s
2024-12-29 13:50:57,811 - INFO - Prediction completed in 0.06s
2024-12-29 13:50:57,822 - INFO - Poison rate 0.05 completed in 13.86s
2024-12-29 13:50:57,823 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:50:57,824 - INFO - Total number of labels flipped: 575
2024-12-29 13:50:57,824 - INFO - Label flipping completed in 0.00s
2024-12-29 13:50:57,825 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:50:57,825 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:50:58,429 - INFO - Feature scaling completed in 0.60s
2024-12-29 13:50:58,429 - INFO - Starting feature selection (k=50)
2024-12-29 13:50:58,451 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 13:50:58,451 - INFO - Starting anomaly detection
2024-12-29 13:51:02,499 - INFO - Anomaly detection completed in 4.05s
2024-12-29 13:51:02,500 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:51:02,500 - INFO - Total fit_transform time: 4.68s
2024-12-29 13:51:02,500 - INFO - Training set processing completed in 4.68s
2024-12-29 13:51:02,500 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:51:02,501 - INFO - Memory usage at start_fit: CPU 2709.0 MB, GPU 104.1 MB
2024-12-29 13:51:02,502 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:51:02,505 - INFO - Number of unique classes: 10
2024-12-29 13:51:02,578 - INFO - Fitted scaler and transformed data
2024-12-29 13:51:02,578 - INFO - Scaling time: 0.07s
2024-12-29 13:51:02,801 - INFO - Epoch 1/1000, Train Loss: 0.7488, Val Loss: 0.4703
2024-12-29 13:51:03,010 - INFO - Epoch 2/1000, Train Loss: 0.4642, Val Loss: 0.4525
2024-12-29 13:51:03,227 - INFO - Epoch 3/1000, Train Loss: 0.4374, Val Loss: 0.4490
2024-12-29 13:51:03,419 - INFO - Epoch 4/1000, Train Loss: 0.4153, Val Loss: 0.4436
2024-12-29 13:51:03,657 - INFO - Epoch 5/1000, Train Loss: 0.3997, Val Loss: 0.4412
2024-12-29 13:51:03,841 - INFO - Epoch 6/1000, Train Loss: 0.3876, Val Loss: 0.4367
2024-12-29 13:51:04,026 - INFO - Epoch 7/1000, Train Loss: 0.3760, Val Loss: 0.4348
2024-12-29 13:51:04,233 - INFO - Epoch 8/1000, Train Loss: 0.3667, Val Loss: 0.4369
2024-12-29 13:51:04,451 - INFO - Epoch 9/1000, Train Loss: 0.3571, Val Loss: 0.4316
2024-12-29 13:51:04,757 - INFO - Epoch 10/1000, Train Loss: 0.3512, Val Loss: 0.4297
2024-12-29 13:51:05,078 - INFO - Epoch 11/1000, Train Loss: 0.3452, Val Loss: 0.4258
2024-12-29 13:51:05,489 - INFO - Epoch 12/1000, Train Loss: 0.3389, Val Loss: 0.4223
2024-12-29 13:51:05,916 - INFO - Epoch 13/1000, Train Loss: 0.3343, Val Loss: 0.4264
2024-12-29 13:51:06,219 - INFO - Epoch 14/1000, Train Loss: 0.3292, Val Loss: 0.4202
2024-12-29 13:51:06,434 - INFO - Epoch 15/1000, Train Loss: 0.3241, Val Loss: 0.4135
2024-12-29 13:51:06,645 - INFO - Epoch 16/1000, Train Loss: 0.3212, Val Loss: 0.4108
2024-12-29 13:51:06,851 - INFO - Epoch 17/1000, Train Loss: 0.3163, Val Loss: 0.4141
2024-12-29 13:51:07,057 - INFO - Epoch 18/1000, Train Loss: 0.3142, Val Loss: 0.4121
2024-12-29 13:51:07,249 - INFO - Epoch 19/1000, Train Loss: 0.3099, Val Loss: 0.4038
2024-12-29 13:51:07,452 - INFO - Epoch 20/1000, Train Loss: 0.3073, Val Loss: 0.4067
2024-12-29 13:51:07,662 - INFO - Epoch 21/1000, Train Loss: 0.3043, Val Loss: 0.4012
2024-12-29 13:51:07,854 - INFO - Epoch 22/1000, Train Loss: 0.3023, Val Loss: 0.4004
2024-12-29 13:51:08,074 - INFO - Epoch 23/1000, Train Loss: 0.3019, Val Loss: 0.4007
2024-12-29 13:51:08,269 - INFO - Epoch 24/1000, Train Loss: 0.2978, Val Loss: 0.4006
2024-12-29 13:51:08,460 - INFO - Epoch 25/1000, Train Loss: 0.2969, Val Loss: 0.3971
2024-12-29 13:51:08,671 - INFO - Epoch 26/1000, Train Loss: 0.2934, Val Loss: 0.3980
2024-12-29 13:51:08,865 - INFO - Epoch 27/1000, Train Loss: 0.2940, Val Loss: 0.3925
2024-12-29 13:51:09,070 - INFO - Epoch 28/1000, Train Loss: 0.2902, Val Loss: 0.3973
2024-12-29 13:51:09,266 - INFO - Epoch 29/1000, Train Loss: 0.2887, Val Loss: 0.3906
2024-12-29 13:51:09,459 - INFO - Epoch 30/1000, Train Loss: 0.2866, Val Loss: 0.3943
2024-12-29 13:51:09,652 - INFO - Epoch 31/1000, Train Loss: 0.2851, Val Loss: 0.3935
2024-12-29 13:51:09,836 - INFO - Epoch 32/1000, Train Loss: 0.2855, Val Loss: 0.3872
2024-12-29 13:51:10,027 - INFO - Epoch 33/1000, Train Loss: 0.2837, Val Loss: 0.3912
2024-12-29 13:51:10,226 - INFO - Epoch 34/1000, Train Loss: 0.2846, Val Loss: 0.3917
2024-12-29 13:51:10,422 - INFO - Epoch 35/1000, Train Loss: 0.2815, Val Loss: 0.3852
2024-12-29 13:51:10,614 - INFO - Epoch 36/1000, Train Loss: 0.2814, Val Loss: 0.3866
2024-12-29 13:51:10,802 - INFO - Epoch 37/1000, Train Loss: 0.2793, Val Loss: 0.3800
2024-12-29 13:51:10,995 - INFO - Epoch 38/1000, Train Loss: 0.2796, Val Loss: 0.3878
2024-12-29 13:51:11,195 - INFO - Epoch 39/1000, Train Loss: 0.2766, Val Loss: 0.3772
2024-12-29 13:51:11,403 - INFO - Epoch 40/1000, Train Loss: 0.2759, Val Loss: 0.3902
2024-12-29 13:51:11,617 - INFO - Epoch 41/1000, Train Loss: 0.2770, Val Loss: 0.3881
2024-12-29 13:51:11,806 - INFO - Epoch 42/1000, Train Loss: 0.2777, Val Loss: 0.3775
2024-12-29 13:51:12,007 - INFO - Epoch 43/1000, Train Loss: 0.2746, Val Loss: 0.3807
2024-12-29 13:51:12,195 - INFO - Epoch 44/1000, Train Loss: 0.2743, Val Loss: 0.3783
2024-12-29 13:51:12,196 - INFO - Early stopping triggered at epoch 44
2024-12-29 13:51:12,196 - INFO - Training completed in 9.70s
2024-12-29 13:51:12,196 - INFO - Final memory usage: CPU 2718.5 MB, GPU 104.2 MB
2024-12-29 13:51:12,197 - INFO - Model training completed in 9.70s
2024-12-29 13:51:12,276 - INFO - Prediction completed in 0.08s
2024-12-29 13:51:12,285 - INFO - Poison rate 0.07 completed in 14.46s
2024-12-29 13:51:12,285 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:51:12,287 - INFO - Total number of labels flipped: 846
2024-12-29 13:51:12,287 - INFO - Label flipping completed in 0.00s
2024-12-29 13:51:12,287 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:51:12,287 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:51:12,909 - INFO - Feature scaling completed in 0.62s
2024-12-29 13:51:12,909 - INFO - Starting feature selection (k=50)
2024-12-29 13:51:12,925 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 13:51:12,925 - INFO - Starting anomaly detection
2024-12-29 13:51:17,071 - INFO - Anomaly detection completed in 4.15s
2024-12-29 13:51:17,071 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:51:17,071 - INFO - Total fit_transform time: 4.78s
2024-12-29 13:51:17,071 - INFO - Training set processing completed in 4.78s
2024-12-29 13:51:17,071 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:51:17,072 - INFO - Memory usage at start_fit: CPU 2709.0 MB, GPU 104.1 MB
2024-12-29 13:51:17,073 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:51:17,075 - INFO - Number of unique classes: 10
2024-12-29 13:51:17,150 - INFO - Fitted scaler and transformed data
2024-12-29 13:51:17,151 - INFO - Scaling time: 0.07s
2024-12-29 13:51:17,521 - INFO - Epoch 1/1000, Train Loss: 0.8710, Val Loss: 0.5279
2024-12-29 13:51:17,871 - INFO - Epoch 2/1000, Train Loss: 0.6121, Val Loss: 0.5140
2024-12-29 13:51:18,257 - INFO - Epoch 3/1000, Train Loss: 0.5786, Val Loss: 0.5022
2024-12-29 13:51:18,650 - INFO - Epoch 4/1000, Train Loss: 0.5531, Val Loss: 0.5023
2024-12-29 13:51:19,027 - INFO - Epoch 5/1000, Train Loss: 0.5315, Val Loss: 0.4904
2024-12-29 13:51:19,464 - INFO - Epoch 6/1000, Train Loss: 0.5166, Val Loss: 0.4886
2024-12-29 13:51:19,749 - INFO - Epoch 7/1000, Train Loss: 0.4987, Val Loss: 0.4863
2024-12-29 13:51:19,969 - INFO - Epoch 8/1000, Train Loss: 0.4868, Val Loss: 0.4755
2024-12-29 13:51:20,181 - INFO - Epoch 9/1000, Train Loss: 0.4758, Val Loss: 0.4728
2024-12-29 13:51:20,366 - INFO - Epoch 10/1000, Train Loss: 0.4691, Val Loss: 0.4590
2024-12-29 13:51:20,550 - INFO - Epoch 11/1000, Train Loss: 0.4590, Val Loss: 0.4677
2024-12-29 13:51:20,755 - INFO - Epoch 12/1000, Train Loss: 0.4503, Val Loss: 0.4638
2024-12-29 13:51:20,951 - INFO - Epoch 13/1000, Train Loss: 0.4430, Val Loss: 0.4614
2024-12-29 13:51:21,144 - INFO - Epoch 14/1000, Train Loss: 0.4349, Val Loss: 0.4489
2024-12-29 13:51:21,359 - INFO - Epoch 15/1000, Train Loss: 0.4302, Val Loss: 0.4511
2024-12-29 13:51:21,584 - INFO - Epoch 16/1000, Train Loss: 0.4233, Val Loss: 0.4416
2024-12-29 13:51:21,801 - INFO - Epoch 17/1000, Train Loss: 0.4196, Val Loss: 0.4411
2024-12-29 13:51:21,992 - INFO - Epoch 18/1000, Train Loss: 0.4145, Val Loss: 0.4406
2024-12-29 13:51:22,197 - INFO - Epoch 19/1000, Train Loss: 0.4074, Val Loss: 0.4361
2024-12-29 13:51:22,417 - INFO - Epoch 20/1000, Train Loss: 0.4036, Val Loss: 0.4305
2024-12-29 13:51:22,635 - INFO - Epoch 21/1000, Train Loss: 0.4002, Val Loss: 0.4318
2024-12-29 13:51:22,840 - INFO - Epoch 22/1000, Train Loss: 0.3955, Val Loss: 0.4276
2024-12-29 13:51:23,057 - INFO - Epoch 23/1000, Train Loss: 0.3944, Val Loss: 0.4302
2024-12-29 13:51:23,251 - INFO - Epoch 24/1000, Train Loss: 0.3903, Val Loss: 0.4267
2024-12-29 13:51:23,472 - INFO - Epoch 25/1000, Train Loss: 0.3878, Val Loss: 0.4277
2024-12-29 13:51:23,667 - INFO - Epoch 26/1000, Train Loss: 0.3847, Val Loss: 0.4245
2024-12-29 13:51:23,868 - INFO - Epoch 27/1000, Train Loss: 0.3811, Val Loss: 0.4314
2024-12-29 13:51:24,082 - INFO - Epoch 28/1000, Train Loss: 0.3800, Val Loss: 0.4182
2024-12-29 13:51:24,285 - INFO - Epoch 29/1000, Train Loss: 0.3751, Val Loss: 0.4223
2024-12-29 13:51:24,499 - INFO - Epoch 30/1000, Train Loss: 0.3746, Val Loss: 0.4209
2024-12-29 13:51:24,711 - INFO - Epoch 31/1000, Train Loss: 0.3735, Val Loss: 0.4157
2024-12-29 13:51:24,957 - INFO - Epoch 32/1000, Train Loss: 0.3722, Val Loss: 0.4112
2024-12-29 13:51:25,177 - INFO - Epoch 33/1000, Train Loss: 0.3679, Val Loss: 0.4145
2024-12-29 13:51:25,393 - INFO - Epoch 34/1000, Train Loss: 0.3681, Val Loss: 0.4099
2024-12-29 13:51:25,605 - INFO - Epoch 35/1000, Train Loss: 0.3637, Val Loss: 0.4076
2024-12-29 13:51:25,809 - INFO - Epoch 36/1000, Train Loss: 0.3636, Val Loss: 0.4111
2024-12-29 13:51:26,028 - INFO - Epoch 37/1000, Train Loss: 0.3622, Val Loss: 0.4098
2024-12-29 13:51:26,236 - INFO - Epoch 38/1000, Train Loss: 0.3606, Val Loss: 0.4063
2024-12-29 13:51:26,479 - INFO - Epoch 39/1000, Train Loss: 0.3590, Val Loss: 0.4085
2024-12-29 13:51:26,676 - INFO - Epoch 40/1000, Train Loss: 0.3580, Val Loss: 0.4027
2024-12-29 13:51:26,876 - INFO - Epoch 41/1000, Train Loss: 0.3582, Val Loss: 0.4100
2024-12-29 13:51:27,102 - INFO - Epoch 42/1000, Train Loss: 0.3550, Val Loss: 0.4051
2024-12-29 13:51:27,305 - INFO - Epoch 43/1000, Train Loss: 0.3528, Val Loss: 0.3989
2024-12-29 13:51:27,534 - INFO - Epoch 44/1000, Train Loss: 0.3550, Val Loss: 0.3991
2024-12-29 13:51:27,738 - INFO - Epoch 45/1000, Train Loss: 0.3523, Val Loss: 0.4103
2024-12-29 13:51:27,939 - INFO - Epoch 46/1000, Train Loss: 0.3515, Val Loss: 0.4080
2024-12-29 13:51:28,138 - INFO - Epoch 47/1000, Train Loss: 0.3519, Val Loss: 0.4012
2024-12-29 13:51:28,345 - INFO - Epoch 48/1000, Train Loss: 0.3487, Val Loss: 0.4095
2024-12-29 13:51:28,345 - INFO - Early stopping triggered at epoch 48
2024-12-29 13:51:28,345 - INFO - Training completed in 11.27s
2024-12-29 13:51:28,346 - INFO - Final memory usage: CPU 2718.5 MB, GPU 104.2 MB
2024-12-29 13:51:28,347 - INFO - Model training completed in 11.28s
2024-12-29 13:51:28,418 - INFO - Prediction completed in 0.07s
2024-12-29 13:51:28,426 - INFO - Poison rate 0.1 completed in 16.14s
2024-12-29 13:51:28,427 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:51:28,429 - INFO - Total number of labels flipped: 1698
2024-12-29 13:51:28,429 - INFO - Label flipping completed in 0.00s
2024-12-29 13:51:28,429 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:51:28,429 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:51:29,020 - INFO - Feature scaling completed in 0.59s
2024-12-29 13:51:29,020 - INFO - Starting feature selection (k=50)
2024-12-29 13:51:29,036 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 13:51:29,037 - INFO - Starting anomaly detection
2024-12-29 13:51:31,921 - INFO - Anomaly detection completed in 2.88s
2024-12-29 13:51:31,921 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:51:31,921 - INFO - Total fit_transform time: 3.49s
2024-12-29 13:51:31,921 - INFO - Training set processing completed in 3.49s
2024-12-29 13:51:31,921 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 13:51:31,923 - INFO - Memory usage at start_fit: CPU 2709.0 MB, GPU 104.1 MB
2024-12-29 13:51:31,923 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:51:31,926 - INFO - Number of unique classes: 10
2024-12-29 13:51:32,002 - INFO - Fitted scaler and transformed data
2024-12-29 13:51:32,003 - INFO - Scaling time: 0.07s
2024-12-29 13:51:32,213 - INFO - Epoch 1/1000, Train Loss: 1.1748, Val Loss: 1.0692
2024-12-29 13:51:32,418 - INFO - Epoch 2/1000, Train Loss: 0.9564, Val Loss: 1.0258
2024-12-29 13:51:32,649 - INFO - Epoch 3/1000, Train Loss: 0.9077, Val Loss: 1.0016
2024-12-29 13:51:32,839 - INFO - Epoch 4/1000, Train Loss: 0.8727, Val Loss: 0.9776
2024-12-29 13:51:33,038 - INFO - Epoch 5/1000, Train Loss: 0.8410, Val Loss: 0.9580
2024-12-29 13:51:33,224 - INFO - Epoch 6/1000, Train Loss: 0.8172, Val Loss: 0.9399
2024-12-29 13:51:33,425 - INFO - Epoch 7/1000, Train Loss: 0.7925, Val Loss: 0.9280
2024-12-29 13:51:33,615 - INFO - Epoch 8/1000, Train Loss: 0.7714, Val Loss: 0.9072
2024-12-29 13:51:33,806 - INFO - Epoch 9/1000, Train Loss: 0.7488, Val Loss: 0.8964
2024-12-29 13:51:33,996 - INFO - Epoch 10/1000, Train Loss: 0.7315, Val Loss: 0.8768
2024-12-29 13:51:34,202 - INFO - Epoch 11/1000, Train Loss: 0.7189, Val Loss: 0.8658
2024-12-29 13:51:34,395 - INFO - Epoch 12/1000, Train Loss: 0.7004, Val Loss: 0.8627
2024-12-29 13:51:34,586 - INFO - Epoch 13/1000, Train Loss: 0.6919, Val Loss: 0.8425
2024-12-29 13:51:34,787 - INFO - Epoch 14/1000, Train Loss: 0.6748, Val Loss: 0.8330
2024-12-29 13:51:34,973 - INFO - Epoch 15/1000, Train Loss: 0.6627, Val Loss: 0.8212
2024-12-29 13:51:35,167 - INFO - Epoch 16/1000, Train Loss: 0.6537, Val Loss: 0.8158
2024-12-29 13:51:35,358 - INFO - Epoch 17/1000, Train Loss: 0.6404, Val Loss: 0.8095
2024-12-29 13:51:35,564 - INFO - Epoch 18/1000, Train Loss: 0.6307, Val Loss: 0.8006
2024-12-29 13:51:35,766 - INFO - Epoch 19/1000, Train Loss: 0.6220, Val Loss: 0.7863
2024-12-29 13:51:35,958 - INFO - Epoch 20/1000, Train Loss: 0.6144, Val Loss: 0.7889
2024-12-29 13:51:36,151 - INFO - Epoch 21/1000, Train Loss: 0.6085, Val Loss: 0.7708
2024-12-29 13:51:36,338 - INFO - Epoch 22/1000, Train Loss: 0.6005, Val Loss: 0.7697
2024-12-29 13:51:36,526 - INFO - Epoch 23/1000, Train Loss: 0.5917, Val Loss: 0.7701
2024-12-29 13:51:36,718 - INFO - Epoch 24/1000, Train Loss: 0.5855, Val Loss: 0.7575
2024-12-29 13:51:36,910 - INFO - Epoch 25/1000, Train Loss: 0.5798, Val Loss: 0.7458
2024-12-29 13:51:37,100 - INFO - Epoch 26/1000, Train Loss: 0.5752, Val Loss: 0.7453
2024-12-29 13:51:37,320 - INFO - Epoch 27/1000, Train Loss: 0.5701, Val Loss: 0.7410
2024-12-29 13:51:37,505 - INFO - Epoch 28/1000, Train Loss: 0.5674, Val Loss: 0.7325
2024-12-29 13:51:37,695 - INFO - Epoch 29/1000, Train Loss: 0.5604, Val Loss: 0.7442
2024-12-29 13:51:37,906 - INFO - Epoch 30/1000, Train Loss: 0.5593, Val Loss: 0.7285
2024-12-29 13:51:38,102 - INFO - Epoch 31/1000, Train Loss: 0.5533, Val Loss: 0.7283
2024-12-29 13:51:38,306 - INFO - Epoch 32/1000, Train Loss: 0.5491, Val Loss: 0.7347
2024-12-29 13:51:38,514 - INFO - Epoch 33/1000, Train Loss: 0.5483, Val Loss: 0.7170
2024-12-29 13:51:38,699 - INFO - Epoch 34/1000, Train Loss: 0.5445, Val Loss: 0.7210
2024-12-29 13:51:38,905 - INFO - Epoch 35/1000, Train Loss: 0.5410, Val Loss: 0.7145
2024-12-29 13:51:39,124 - INFO - Epoch 36/1000, Train Loss: 0.5390, Val Loss: 0.7113
2024-12-29 13:51:39,316 - INFO - Epoch 37/1000, Train Loss: 0.5347, Val Loss: 0.7120
2024-12-29 13:51:39,514 - INFO - Epoch 38/1000, Train Loss: 0.5316, Val Loss: 0.7065
2024-12-29 13:51:39,713 - INFO - Epoch 39/1000, Train Loss: 0.5312, Val Loss: 0.7036
2024-12-29 13:51:39,901 - INFO - Epoch 40/1000, Train Loss: 0.5286, Val Loss: 0.7067
2024-12-29 13:51:40,097 - INFO - Epoch 41/1000, Train Loss: 0.5274, Val Loss: 0.6993
2024-12-29 13:51:40,300 - INFO - Epoch 42/1000, Train Loss: 0.5240, Val Loss: 0.7005
2024-12-29 13:51:40,492 - INFO - Epoch 43/1000, Train Loss: 0.5224, Val Loss: 0.6979
2024-12-29 13:51:40,725 - INFO - Epoch 44/1000, Train Loss: 0.5212, Val Loss: 0.6963
2024-12-29 13:51:40,911 - INFO - Epoch 45/1000, Train Loss: 0.5204, Val Loss: 0.6934
2024-12-29 13:51:41,107 - INFO - Epoch 46/1000, Train Loss: 0.5165, Val Loss: 0.6960
2024-12-29 13:51:41,310 - INFO - Epoch 47/1000, Train Loss: 0.5153, Val Loss: 0.7028
2024-12-29 13:51:41,500 - INFO - Epoch 48/1000, Train Loss: 0.5147, Val Loss: 0.6945
2024-12-29 13:51:41,694 - INFO - Epoch 49/1000, Train Loss: 0.5121, Val Loss: 0.6955
2024-12-29 13:51:41,911 - INFO - Epoch 50/1000, Train Loss: 0.5110, Val Loss: 0.6934
2024-12-29 13:51:41,911 - INFO - Early stopping triggered at epoch 50
2024-12-29 13:51:41,911 - INFO - Training completed in 9.99s
2024-12-29 13:51:41,912 - INFO - Final memory usage: CPU 2718.2 MB, GPU 104.2 MB
2024-12-29 13:51:41,915 - INFO - Model training completed in 9.99s
2024-12-29 13:51:41,992 - INFO - Prediction completed in 0.08s
2024-12-29 13:51:42,001 - INFO - Poison rate 0.2 completed in 13.57s
2024-12-29 13:51:42,007 - INFO - Loaded 301 existing results
2024-12-29 13:51:42,007 - INFO - Total results to save: 308
2024-12-29 13:51:42,008 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:51:42,019 - INFO - Saved 308 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:51:42,019 - INFO - Total evaluation time: 116.33s
2024-12-29 13:51:42,021 - INFO - 
Progress: 46.9% - Evaluating ImageNette with RandomForest (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:51:42,263 - INFO - Loading datasets...
2024-12-29 13:51:42,286 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:51:42,286 - INFO - Extracting validation features...
2024-12-29 13:51:42,286 - INFO - Extracting features from 3925 samples...
2024-12-29 13:51:51,391 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:51:51,397 - INFO - Validation feature extraction completed in 9.11s
2024-12-29 13:51:51,397 - INFO - Extracting training features...
2024-12-29 13:51:51,398 - INFO - Extracting features from 9469 samples...
2024-12-29 13:52:13,099 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:52:13,108 - INFO - Training feature extraction completed in 21.71s
2024-12-29 13:52:13,108 - INFO - Creating model for classifier: RandomForest
2024-12-29 13:52:13,109 - INFO - Using device: cuda
2024-12-29 13:52:13,109 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:52:13,109 - INFO - Training set processing completed in 0.00s
2024-12-29 13:52:13,109 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:52:13,110 - INFO - Memory usage at start_fit: CPU 2681.2 MB, GPU 104.6 MB
2024-12-29 13:52:13,111 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:52:13,297 - INFO - Fitted scaler and transformed data
2024-12-29 13:52:13,297 - INFO - Scaling time: 0.19s
2024-12-29 13:52:13,304 - INFO - Number of unique classes: 10
2024-12-29 13:52:16,658 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3013
2024-12-29 13:52:20,137 - INFO - Epoch 2/10, Train Loss: 2.3006, Val Loss: 2.3000
2024-12-29 13:52:23,307 - INFO - Epoch 3/10, Train Loss: 2.2992, Val Loss: 2.2987
2024-12-29 13:52:26,240 - INFO - Epoch 4/10, Train Loss: 2.2978, Val Loss: 2.2974
2024-12-29 13:52:26,240 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:52:26,240 - INFO - Training completed in 13.13s
2024-12-29 13:52:26,241 - INFO - Final memory usage: CPU 2709.1 MB, GPU 126.5 MB
2024-12-29 13:52:26,241 - INFO - Model training completed in 13.13s
2024-12-29 13:52:26,486 - INFO - Prediction completed in 0.24s
2024-12-29 13:52:26,495 - INFO - Poison rate 0.0 completed in 13.39s
2024-12-29 13:52:26,495 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:52:26,496 - INFO - Total number of labels flipped: 85
2024-12-29 13:52:26,497 - INFO - Label flipping completed in 0.00s
2024-12-29 13:52:26,497 - INFO - Training set processing completed in 0.00s
2024-12-29 13:52:26,497 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:52:26,498 - INFO - Memory usage at start_fit: CPU 2709.1 MB, GPU 106.7 MB
2024-12-29 13:52:26,498 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:52:26,694 - INFO - Fitted scaler and transformed data
2024-12-29 13:52:26,694 - INFO - Scaling time: 0.20s
2024-12-29 13:52:26,704 - INFO - Number of unique classes: 10
2024-12-29 13:52:30,158 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3014
2024-12-29 13:52:33,628 - INFO - Epoch 2/10, Train Loss: 2.3006, Val Loss: 2.3001
2024-12-29 13:52:36,943 - INFO - Epoch 3/10, Train Loss: 2.2992, Val Loss: 2.2989
2024-12-29 13:52:39,992 - INFO - Epoch 4/10, Train Loss: 2.2978, Val Loss: 2.2976
2024-12-29 13:52:39,992 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:52:39,992 - INFO - Training completed in 13.49s
2024-12-29 13:52:39,992 - INFO - Final memory usage: CPU 2709.1 MB, GPU 126.5 MB
2024-12-29 13:52:39,993 - INFO - Model training completed in 13.50s
2024-12-29 13:52:40,191 - INFO - Prediction completed in 0.20s
2024-12-29 13:52:40,207 - INFO - Poison rate 0.01 completed in 13.71s
2024-12-29 13:52:40,207 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:52:40,209 - INFO - Total number of labels flipped: 255
2024-12-29 13:52:40,209 - INFO - Label flipping completed in 0.00s
2024-12-29 13:52:40,209 - INFO - Training set processing completed in 0.00s
2024-12-29 13:52:40,209 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:52:40,210 - INFO - Memory usage at start_fit: CPU 2709.1 MB, GPU 106.7 MB
2024-12-29 13:52:40,211 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:52:40,391 - INFO - Fitted scaler and transformed data
2024-12-29 13:52:40,392 - INFO - Scaling time: 0.18s
2024-12-29 13:52:40,402 - INFO - Number of unique classes: 10
2024-12-29 13:52:43,757 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3014
2024-12-29 13:52:48,040 - INFO - Epoch 2/10, Train Loss: 2.3007, Val Loss: 2.3002
2024-12-29 13:52:51,420 - INFO - Epoch 3/10, Train Loss: 2.2993, Val Loss: 2.2990
2024-12-29 13:52:54,684 - INFO - Epoch 4/10, Train Loss: 2.2980, Val Loss: 2.2978
2024-12-29 13:52:54,684 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:52:54,684 - INFO - Training completed in 14.47s
2024-12-29 13:52:54,684 - INFO - Final memory usage: CPU 2709.1 MB, GPU 126.5 MB
2024-12-29 13:52:54,685 - INFO - Model training completed in 14.48s
2024-12-29 13:52:54,939 - INFO - Prediction completed in 0.25s
2024-12-29 13:52:54,958 - INFO - Poison rate 0.03 completed in 14.75s
2024-12-29 13:52:54,959 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:52:54,962 - INFO - Total number of labels flipped: 420
2024-12-29 13:52:54,963 - INFO - Label flipping completed in 0.00s
2024-12-29 13:52:54,963 - INFO - Training set processing completed in 0.00s
2024-12-29 13:52:54,963 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:52:54,964 - INFO - Memory usage at start_fit: CPU 2709.1 MB, GPU 106.7 MB
2024-12-29 13:52:54,965 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:52:55,164 - INFO - Fitted scaler and transformed data
2024-12-29 13:52:55,164 - INFO - Scaling time: 0.20s
2024-12-29 13:52:55,175 - INFO - Number of unique classes: 10
2024-12-29 13:52:58,634 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3013
2024-12-29 13:53:01,683 - INFO - Epoch 2/10, Train Loss: 2.3007, Val Loss: 2.3001
2024-12-29 13:53:04,354 - INFO - Epoch 3/10, Train Loss: 2.2993, Val Loss: 2.2988
2024-12-29 13:53:07,811 - INFO - Epoch 4/10, Train Loss: 2.2980, Val Loss: 2.2975
2024-12-29 13:53:07,811 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:53:07,811 - INFO - Training completed in 12.85s
2024-12-29 13:53:07,811 - INFO - Final memory usage: CPU 2709.1 MB, GPU 126.5 MB
2024-12-29 13:53:07,812 - INFO - Model training completed in 12.85s
2024-12-29 13:53:08,095 - INFO - Prediction completed in 0.28s
2024-12-29 13:53:08,118 - INFO - Poison rate 0.05 completed in 13.16s
2024-12-29 13:53:08,119 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:53:08,121 - INFO - Total number of labels flipped: 596
2024-12-29 13:53:08,121 - INFO - Label flipping completed in 0.00s
2024-12-29 13:53:08,121 - INFO - Training set processing completed in 0.00s
2024-12-29 13:53:08,122 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:53:08,122 - INFO - Memory usage at start_fit: CPU 2709.1 MB, GPU 106.7 MB
2024-12-29 13:53:08,123 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:53:08,307 - INFO - Fitted scaler and transformed data
2024-12-29 13:53:08,307 - INFO - Scaling time: 0.18s
2024-12-29 13:53:08,318 - INFO - Number of unique classes: 10
2024-12-29 13:53:11,908 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3014
2024-12-29 13:53:15,773 - INFO - Epoch 2/10, Train Loss: 2.3007, Val Loss: 2.3002
2024-12-29 13:53:19,121 - INFO - Epoch 3/10, Train Loss: 2.2994, Val Loss: 2.2991
2024-12-29 13:53:22,306 - INFO - Epoch 4/10, Train Loss: 2.2981, Val Loss: 2.2978
2024-12-29 13:53:22,306 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:53:22,306 - INFO - Training completed in 14.18s
2024-12-29 13:53:22,307 - INFO - Final memory usage: CPU 2709.1 MB, GPU 126.5 MB
2024-12-29 13:53:22,307 - INFO - Model training completed in 14.19s
2024-12-29 13:53:22,468 - INFO - Prediction completed in 0.16s
2024-12-29 13:53:22,477 - INFO - Poison rate 0.07 completed in 14.36s
2024-12-29 13:53:22,477 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:53:22,478 - INFO - Total number of labels flipped: 857
2024-12-29 13:53:22,478 - INFO - Label flipping completed in 0.00s
2024-12-29 13:53:22,478 - INFO - Training set processing completed in 0.00s
2024-12-29 13:53:22,478 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:53:22,479 - INFO - Memory usage at start_fit: CPU 2709.1 MB, GPU 106.7 MB
2024-12-29 13:53:22,479 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:53:22,655 - INFO - Fitted scaler and transformed data
2024-12-29 13:53:22,655 - INFO - Scaling time: 0.18s
2024-12-29 13:53:22,666 - INFO - Number of unique classes: 10
2024-12-29 13:53:26,385 - INFO - Epoch 1/10, Train Loss: 2.3021, Val Loss: 2.3014
2024-12-29 13:53:29,454 - INFO - Epoch 2/10, Train Loss: 2.3007, Val Loss: 2.3002
2024-12-29 13:53:32,115 - INFO - Epoch 3/10, Train Loss: 2.2994, Val Loss: 2.2989
2024-12-29 13:53:34,703 - INFO - Epoch 4/10, Train Loss: 2.2981, Val Loss: 2.2977
2024-12-29 13:53:34,703 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:53:34,703 - INFO - Training completed in 12.22s
2024-12-29 13:53:34,704 - INFO - Final memory usage: CPU 2709.1 MB, GPU 126.5 MB
2024-12-29 13:53:34,704 - INFO - Model training completed in 12.23s
2024-12-29 13:53:34,847 - INFO - Prediction completed in 0.14s
2024-12-29 13:53:34,856 - INFO - Poison rate 0.1 completed in 12.38s
2024-12-29 13:53:34,857 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:53:34,858 - INFO - Total number of labels flipped: 1720
2024-12-29 13:53:34,858 - INFO - Label flipping completed in 0.00s
2024-12-29 13:53:34,859 - INFO - Training set processing completed in 0.00s
2024-12-29 13:53:34,859 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:53:34,859 - INFO - Memory usage at start_fit: CPU 2709.1 MB, GPU 106.7 MB
2024-12-29 13:53:34,859 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:53:35,039 - INFO - Fitted scaler and transformed data
2024-12-29 13:53:35,039 - INFO - Scaling time: 0.18s
2024-12-29 13:53:35,050 - INFO - Number of unique classes: 10
2024-12-29 13:53:38,146 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3014
2024-12-29 13:53:41,341 - INFO - Epoch 2/10, Train Loss: 2.3007, Val Loss: 2.3003
2024-12-29 13:53:44,544 - INFO - Epoch 3/10, Train Loss: 2.2994, Val Loss: 2.2991
2024-12-29 13:53:47,657 - INFO - Epoch 4/10, Train Loss: 2.2981, Val Loss: 2.2979
2024-12-29 13:53:47,658 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:53:47,658 - INFO - Training completed in 12.80s
2024-12-29 13:53:47,658 - INFO - Final memory usage: CPU 2709.1 MB, GPU 126.5 MB
2024-12-29 13:53:47,658 - INFO - Model training completed in 12.80s
2024-12-29 13:53:47,804 - INFO - Prediction completed in 0.15s
2024-12-29 13:53:47,816 - INFO - Poison rate 0.2 completed in 12.96s
2024-12-29 13:53:47,822 - INFO - Loaded 308 existing results
2024-12-29 13:53:47,822 - INFO - Total results to save: 315
2024-12-29 13:53:47,823 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:53:47,834 - INFO - Saved 315 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:53:47,834 - INFO - Total evaluation time: 125.57s
2024-12-29 13:53:47,836 - INFO - 
Progress: 47.9% - Evaluating ImageNette with RandomForest (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:53:48,050 - INFO - Loading datasets...
2024-12-29 13:53:48,071 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:53:48,071 - INFO - Extracting validation features...
2024-12-29 13:53:48,071 - INFO - Extracting features from 3925 samples...
2024-12-29 13:53:57,246 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:53:57,251 - INFO - Validation feature extraction completed in 9.18s
2024-12-29 13:53:57,252 - INFO - Extracting training features...
2024-12-29 13:53:57,252 - INFO - Extracting features from 9469 samples...
2024-12-29 13:54:19,030 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:54:19,039 - INFO - Training feature extraction completed in 21.79s
2024-12-29 13:54:19,039 - INFO - Creating model for classifier: RandomForest
2024-12-29 13:54:19,040 - INFO - Using device: cuda
2024-12-29 13:54:19,040 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:54:19,041 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:54:19,041 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:54:19,579 - INFO - Feature scaling completed in 0.54s
2024-12-29 13:54:19,580 - INFO - Starting feature selection (k=50)
2024-12-29 13:54:19,588 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:54:19,588 - INFO - Starting anomaly detection
2024-12-29 13:54:22,603 - INFO - Anomaly detection completed in 3.01s
2024-12-29 13:54:22,603 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:54:22,603 - INFO - Total fit_transform time: 3.56s
2024-12-29 13:54:22,603 - INFO - Training set processing completed in 3.56s
2024-12-29 13:54:22,603 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:54:22,605 - INFO - Memory usage at start_fit: CPU 2709.3 MB, GPU 104.0 MB
2024-12-29 13:54:22,605 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:54:22,790 - INFO - Fitted scaler and transformed data
2024-12-29 13:54:22,790 - INFO - Scaling time: 0.18s
2024-12-29 13:54:22,798 - INFO - Number of unique classes: 10
2024-12-29 13:54:25,773 - INFO - Epoch 1/10, Train Loss: 2.1865, Val Loss: 2.3014
2024-12-29 13:54:28,460 - INFO - Epoch 2/10, Train Loss: 2.1852, Val Loss: 2.3001
2024-12-29 13:54:31,269 - INFO - Epoch 3/10, Train Loss: 2.1838, Val Loss: 2.2988
2024-12-29 13:54:34,809 - INFO - Epoch 4/10, Train Loss: 2.1825, Val Loss: 2.2975
2024-12-29 13:54:34,809 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:54:34,810 - INFO - Training completed in 12.21s
2024-12-29 13:54:34,810 - INFO - Final memory usage: CPU 2709.3 MB, GPU 125.9 MB
2024-12-29 13:54:34,810 - INFO - Model training completed in 12.21s
2024-12-29 13:54:34,978 - INFO - Prediction completed in 0.17s
2024-12-29 13:54:34,987 - INFO - Poison rate 0.0 completed in 15.95s
2024-12-29 13:54:34,987 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:54:34,988 - INFO - Total number of labels flipped: 82
2024-12-29 13:54:34,988 - INFO - Label flipping completed in 0.00s
2024-12-29 13:54:34,988 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:54:34,988 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:54:35,570 - INFO - Feature scaling completed in 0.58s
2024-12-29 13:54:35,571 - INFO - Starting feature selection (k=50)
2024-12-29 13:54:35,584 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:54:35,585 - INFO - Starting anomaly detection
2024-12-29 13:54:39,158 - INFO - Anomaly detection completed in 3.57s
2024-12-29 13:54:39,158 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:54:39,158 - INFO - Total fit_transform time: 4.17s
2024-12-29 13:54:39,158 - INFO - Training set processing completed in 4.17s
2024-12-29 13:54:39,158 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:54:39,159 - INFO - Memory usage at start_fit: CPU 2709.3 MB, GPU 106.0 MB
2024-12-29 13:54:39,160 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:54:39,346 - INFO - Fitted scaler and transformed data
2024-12-29 13:54:39,347 - INFO - Scaling time: 0.19s
2024-12-29 13:54:39,354 - INFO - Number of unique classes: 10
2024-12-29 13:54:43,247 - INFO - Epoch 1/10, Train Loss: 2.1882, Val Loss: 2.3014
2024-12-29 13:54:46,347 - INFO - Epoch 2/10, Train Loss: 2.1869, Val Loss: 2.3002
2024-12-29 13:54:49,319 - INFO - Epoch 3/10, Train Loss: 2.1856, Val Loss: 2.2990
2024-12-29 13:54:52,185 - INFO - Epoch 4/10, Train Loss: 2.1843, Val Loss: 2.2977
2024-12-29 13:54:52,185 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:54:52,186 - INFO - Training completed in 13.03s
2024-12-29 13:54:52,186 - INFO - Final memory usage: CPU 2709.3 MB, GPU 125.9 MB
2024-12-29 13:54:52,186 - INFO - Model training completed in 13.03s
2024-12-29 13:54:52,368 - INFO - Prediction completed in 0.18s
2024-12-29 13:54:52,376 - INFO - Poison rate 0.01 completed in 17.39s
2024-12-29 13:54:52,376 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:54:52,377 - INFO - Total number of labels flipped: 256
2024-12-29 13:54:52,378 - INFO - Label flipping completed in 0.00s
2024-12-29 13:54:52,378 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:54:52,378 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:54:52,944 - INFO - Feature scaling completed in 0.57s
2024-12-29 13:54:52,944 - INFO - Starting feature selection (k=50)
2024-12-29 13:54:52,958 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:54:52,959 - INFO - Starting anomaly detection
2024-12-29 13:54:56,415 - INFO - Anomaly detection completed in 3.46s
2024-12-29 13:54:56,415 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:54:56,415 - INFO - Total fit_transform time: 4.04s
2024-12-29 13:54:56,415 - INFO - Training set processing completed in 4.04s
2024-12-29 13:54:56,416 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:54:56,417 - INFO - Memory usage at start_fit: CPU 2709.3 MB, GPU 106.0 MB
2024-12-29 13:54:56,417 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:54:56,598 - INFO - Fitted scaler and transformed data
2024-12-29 13:54:56,598 - INFO - Scaling time: 0.18s
2024-12-29 13:54:56,605 - INFO - Number of unique classes: 10
2024-12-29 13:54:59,756 - INFO - Epoch 1/10, Train Loss: 2.1860, Val Loss: 2.3013
2024-12-29 13:55:03,463 - INFO - Epoch 2/10, Train Loss: 2.1847, Val Loss: 2.3001
2024-12-29 13:55:06,823 - INFO - Epoch 3/10, Train Loss: 2.1834, Val Loss: 2.2988
2024-12-29 13:55:09,812 - INFO - Epoch 4/10, Train Loss: 2.1821, Val Loss: 2.2975
2024-12-29 13:55:09,812 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:55:09,813 - INFO - Training completed in 13.40s
2024-12-29 13:55:09,813 - INFO - Final memory usage: CPU 2709.3 MB, GPU 125.9 MB
2024-12-29 13:55:09,813 - INFO - Model training completed in 13.40s
2024-12-29 13:55:09,993 - INFO - Prediction completed in 0.18s
2024-12-29 13:55:10,002 - INFO - Poison rate 0.03 completed in 17.63s
2024-12-29 13:55:10,003 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:55:10,004 - INFO - Total number of labels flipped: 430
2024-12-29 13:55:10,004 - INFO - Label flipping completed in 0.00s
2024-12-29 13:55:10,004 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:55:10,004 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:55:10,589 - INFO - Feature scaling completed in 0.58s
2024-12-29 13:55:10,589 - INFO - Starting feature selection (k=50)
2024-12-29 13:55:10,602 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:55:10,602 - INFO - Starting anomaly detection
2024-12-29 13:55:14,796 - INFO - Anomaly detection completed in 4.19s
2024-12-29 13:55:14,796 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:55:14,797 - INFO - Total fit_transform time: 4.79s
2024-12-29 13:55:14,797 - INFO - Training set processing completed in 4.79s
2024-12-29 13:55:14,797 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:55:14,798 - INFO - Memory usage at start_fit: CPU 2709.3 MB, GPU 106.0 MB
2024-12-29 13:55:14,798 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:55:15,003 - INFO - Fitted scaler and transformed data
2024-12-29 13:55:15,004 - INFO - Scaling time: 0.21s
2024-12-29 13:55:15,011 - INFO - Number of unique classes: 10
2024-12-29 13:55:17,690 - INFO - Epoch 1/10, Train Loss: 2.1858, Val Loss: 2.3014
2024-12-29 13:55:20,476 - INFO - Epoch 2/10, Train Loss: 2.1845, Val Loss: 2.3002
2024-12-29 13:55:23,775 - INFO - Epoch 3/10, Train Loss: 2.1833, Val Loss: 2.2990
2024-12-29 13:55:26,627 - INFO - Epoch 4/10, Train Loss: 2.1820, Val Loss: 2.2978
2024-12-29 13:55:26,627 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:55:26,627 - INFO - Training completed in 11.83s
2024-12-29 13:55:26,627 - INFO - Final memory usage: CPU 2709.3 MB, GPU 125.9 MB
2024-12-29 13:55:26,628 - INFO - Model training completed in 11.83s
2024-12-29 13:55:26,856 - INFO - Prediction completed in 0.23s
2024-12-29 13:55:26,869 - INFO - Poison rate 0.05 completed in 16.87s
2024-12-29 13:55:26,869 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:55:26,872 - INFO - Total number of labels flipped: 597
2024-12-29 13:55:26,872 - INFO - Label flipping completed in 0.00s
2024-12-29 13:55:26,872 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:55:26,873 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:55:27,416 - INFO - Feature scaling completed in 0.54s
2024-12-29 13:55:27,416 - INFO - Starting feature selection (k=50)
2024-12-29 13:55:27,429 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:55:27,429 - INFO - Starting anomaly detection
2024-12-29 13:55:29,978 - INFO - Anomaly detection completed in 2.55s
2024-12-29 13:55:29,978 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:55:29,978 - INFO - Total fit_transform time: 3.11s
2024-12-29 13:55:29,978 - INFO - Training set processing completed in 3.11s
2024-12-29 13:55:29,978 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:55:29,980 - INFO - Memory usage at start_fit: CPU 2709.3 MB, GPU 106.0 MB
2024-12-29 13:55:29,980 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:55:30,172 - INFO - Fitted scaler and transformed data
2024-12-29 13:55:30,172 - INFO - Scaling time: 0.19s
2024-12-29 13:55:30,178 - INFO - Number of unique classes: 10
2024-12-29 13:55:33,339 - INFO - Epoch 1/10, Train Loss: 2.1868, Val Loss: 2.3015
2024-12-29 13:55:36,058 - INFO - Epoch 2/10, Train Loss: 2.1855, Val Loss: 2.3003
2024-12-29 13:55:38,660 - INFO - Epoch 3/10, Train Loss: 2.1843, Val Loss: 2.2992
2024-12-29 13:55:41,884 - INFO - Epoch 4/10, Train Loss: 2.1830, Val Loss: 2.2980
2024-12-29 13:55:41,884 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:55:41,884 - INFO - Training completed in 11.91s
2024-12-29 13:55:41,885 - INFO - Final memory usage: CPU 2709.3 MB, GPU 125.9 MB
2024-12-29 13:55:41,885 - INFO - Model training completed in 11.91s
2024-12-29 13:55:42,032 - INFO - Prediction completed in 0.15s
2024-12-29 13:55:42,041 - INFO - Poison rate 0.07 completed in 15.17s
2024-12-29 13:55:42,041 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:55:42,042 - INFO - Total number of labels flipped: 864
2024-12-29 13:55:42,042 - INFO - Label flipping completed in 0.00s
2024-12-29 13:55:42,042 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:55:42,042 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:55:42,811 - INFO - Feature scaling completed in 0.77s
2024-12-29 13:55:42,812 - INFO - Starting feature selection (k=50)
2024-12-29 13:55:42,825 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:55:42,825 - INFO - Starting anomaly detection
2024-12-29 13:55:46,944 - INFO - Anomaly detection completed in 4.12s
2024-12-29 13:55:46,944 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:55:46,945 - INFO - Total fit_transform time: 4.90s
2024-12-29 13:55:46,945 - INFO - Training set processing completed in 4.90s
2024-12-29 13:55:46,945 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:55:46,946 - INFO - Memory usage at start_fit: CPU 2709.3 MB, GPU 106.0 MB
2024-12-29 13:55:46,946 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:55:47,133 - INFO - Fitted scaler and transformed data
2024-12-29 13:55:47,134 - INFO - Scaling time: 0.19s
2024-12-29 13:55:47,140 - INFO - Number of unique classes: 10
2024-12-29 13:55:50,217 - INFO - Epoch 1/10, Train Loss: 2.1881, Val Loss: 2.3014
2024-12-29 13:55:52,874 - INFO - Epoch 2/10, Train Loss: 2.1868, Val Loss: 2.3002
2024-12-29 13:55:55,604 - INFO - Epoch 3/10, Train Loss: 2.1856, Val Loss: 2.2990
2024-12-29 13:55:58,992 - INFO - Epoch 4/10, Train Loss: 2.1843, Val Loss: 2.2978
2024-12-29 13:55:58,992 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:55:58,992 - INFO - Training completed in 12.05s
2024-12-29 13:55:58,993 - INFO - Final memory usage: CPU 2709.3 MB, GPU 125.9 MB
2024-12-29 13:55:58,993 - INFO - Model training completed in 12.05s
2024-12-29 13:55:59,140 - INFO - Prediction completed in 0.15s
2024-12-29 13:55:59,149 - INFO - Poison rate 0.1 completed in 17.11s
2024-12-29 13:55:59,149 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:55:59,151 - INFO - Total number of labels flipped: 1688
2024-12-29 13:55:59,151 - INFO - Label flipping completed in 0.00s
2024-12-29 13:55:59,151 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:55:59,151 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:55:59,663 - INFO - Feature scaling completed in 0.51s
2024-12-29 13:55:59,663 - INFO - Starting feature selection (k=50)
2024-12-29 13:55:59,676 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:55:59,676 - INFO - Starting anomaly detection
2024-12-29 13:56:02,408 - INFO - Anomaly detection completed in 2.73s
2024-12-29 13:56:02,408 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:56:02,408 - INFO - Total fit_transform time: 3.26s
2024-12-29 13:56:02,408 - INFO - Training set processing completed in 3.26s
2024-12-29 13:56:02,408 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 13:56:02,409 - INFO - Memory usage at start_fit: CPU 2709.3 MB, GPU 106.0 MB
2024-12-29 13:56:02,409 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:56:02,584 - INFO - Fitted scaler and transformed data
2024-12-29 13:56:02,584 - INFO - Scaling time: 0.18s
2024-12-29 13:56:02,591 - INFO - Number of unique classes: 10
2024-12-29 13:56:05,931 - INFO - Epoch 1/10, Train Loss: 2.1877, Val Loss: 2.3014
2024-12-29 13:56:09,945 - INFO - Epoch 2/10, Train Loss: 2.1865, Val Loss: 2.3003
2024-12-29 13:56:13,315 - INFO - Epoch 3/10, Train Loss: 2.1852, Val Loss: 2.2991
2024-12-29 13:56:16,263 - INFO - Epoch 4/10, Train Loss: 2.1840, Val Loss: 2.2979
2024-12-29 13:56:16,263 - INFO - Early stopping triggered at epoch 4
2024-12-29 13:56:16,263 - INFO - Training completed in 13.85s
2024-12-29 13:56:16,264 - INFO - Final memory usage: CPU 2709.3 MB, GPU 125.9 MB
2024-12-29 13:56:16,264 - INFO - Model training completed in 13.86s
2024-12-29 13:56:16,495 - INFO - Prediction completed in 0.23s
2024-12-29 13:56:16,507 - INFO - Poison rate 0.2 completed in 17.36s
2024-12-29 13:56:16,513 - INFO - Loaded 315 existing results
2024-12-29 13:56:16,513 - INFO - Total results to save: 322
2024-12-29 13:56:16,514 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:56:16,525 - INFO - Saved 322 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:56:16,526 - INFO - Total evaluation time: 148.48s
2024-12-29 13:56:16,527 - INFO - 
Progress: 49.0% - Evaluating ImageNette with KNeighbors (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:56:16,707 - INFO - Loading datasets...
2024-12-29 13:56:16,728 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:56:16,729 - INFO - Extracting validation features...
2024-12-29 13:56:16,729 - INFO - Extracting features from 3925 samples...
2024-12-29 13:56:26,118 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:56:26,125 - INFO - Validation feature extraction completed in 9.40s
2024-12-29 13:56:26,125 - INFO - Extracting training features...
2024-12-29 13:56:26,125 - INFO - Extracting features from 9469 samples...
2024-12-29 13:56:48,521 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:56:48,528 - INFO - Training feature extraction completed in 22.40s
2024-12-29 13:56:48,528 - INFO - Creating model for classifier: KNeighbors
2024-12-29 13:56:48,528 - INFO - Using device: cuda
2024-12-29 13:56:48,528 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:56:48,528 - INFO - Training set processing completed in 0.00s
2024-12-29 13:56:48,529 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:56:48,530 - INFO - Memory usage at start_fit: CPU 2685.5 MB, GPU 104.6 MB
2024-12-29 13:56:48,530 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:56:48,711 - INFO - Fitted scaler and transformed data
2024-12-29 13:56:48,712 - INFO - Scaling time: 0.18s
2024-12-29 13:56:48,719 - INFO - Training completed in 0.19s
2024-12-29 13:56:48,720 - INFO - Final memory usage: CPU 2713.2 MB, GPU 123.2 MB
2024-12-29 13:56:48,720 - INFO - Model training completed in 0.19s
2024-12-29 13:56:48,802 - INFO - Prediction completed in 0.08s
2024-12-29 13:56:48,812 - INFO - Poison rate 0.0 completed in 0.28s
2024-12-29 13:56:48,812 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:56:48,813 - INFO - Total number of labels flipped: 87
2024-12-29 13:56:48,813 - INFO - Label flipping completed in 0.00s
2024-12-29 13:56:48,813 - INFO - Training set processing completed in 0.00s
2024-12-29 13:56:48,813 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:56:48,814 - INFO - Memory usage at start_fit: CPU 2713.2 MB, GPU 123.2 MB
2024-12-29 13:56:48,814 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:56:48,982 - INFO - Fitted scaler and transformed data
2024-12-29 13:56:48,983 - INFO - Scaling time: 0.17s
2024-12-29 13:56:48,988 - INFO - Training completed in 0.17s
2024-12-29 13:56:48,989 - INFO - Final memory usage: CPU 2713.2 MB, GPU 123.2 MB
2024-12-29 13:56:48,989 - INFO - Model training completed in 0.18s
2024-12-29 13:56:49,107 - INFO - Prediction completed in 0.12s
2024-12-29 13:56:49,120 - INFO - Poison rate 0.01 completed in 0.31s
2024-12-29 13:56:49,120 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:56:49,123 - INFO - Total number of labels flipped: 255
2024-12-29 13:56:49,124 - INFO - Label flipping completed in 0.00s
2024-12-29 13:56:49,124 - INFO - Training set processing completed in 0.00s
2024-12-29 13:56:49,124 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:56:49,125 - INFO - Memory usage at start_fit: CPU 2713.2 MB, GPU 123.2 MB
2024-12-29 13:56:49,125 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:56:49,295 - INFO - Fitted scaler and transformed data
2024-12-29 13:56:49,295 - INFO - Scaling time: 0.17s
2024-12-29 13:56:49,302 - INFO - Training completed in 0.18s
2024-12-29 13:56:49,302 - INFO - Final memory usage: CPU 2713.2 MB, GPU 123.2 MB
2024-12-29 13:56:49,303 - INFO - Model training completed in 0.18s
2024-12-29 13:56:49,388 - INFO - Prediction completed in 0.08s
2024-12-29 13:56:49,397 - INFO - Poison rate 0.03 completed in 0.28s
2024-12-29 13:56:49,397 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:56:49,398 - INFO - Total number of labels flipped: 415
2024-12-29 13:56:49,399 - INFO - Label flipping completed in 0.00s
2024-12-29 13:56:49,399 - INFO - Training set processing completed in 0.00s
2024-12-29 13:56:49,399 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:56:49,400 - INFO - Memory usage at start_fit: CPU 2713.2 MB, GPU 123.2 MB
2024-12-29 13:56:49,400 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:56:49,579 - INFO - Fitted scaler and transformed data
2024-12-29 13:56:49,579 - INFO - Scaling time: 0.18s
2024-12-29 13:56:49,585 - INFO - Training completed in 0.19s
2024-12-29 13:56:49,586 - INFO - Final memory usage: CPU 2713.2 MB, GPU 123.2 MB
2024-12-29 13:56:49,586 - INFO - Model training completed in 0.19s
2024-12-29 13:56:49,657 - INFO - Prediction completed in 0.07s
2024-12-29 13:56:49,666 - INFO - Poison rate 0.05 completed in 0.27s
2024-12-29 13:56:49,666 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:56:49,667 - INFO - Total number of labels flipped: 587
2024-12-29 13:56:49,667 - INFO - Label flipping completed in 0.00s
2024-12-29 13:56:49,667 - INFO - Training set processing completed in 0.00s
2024-12-29 13:56:49,667 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:56:49,668 - INFO - Memory usage at start_fit: CPU 2713.2 MB, GPU 123.2 MB
2024-12-29 13:56:49,669 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:56:49,893 - INFO - Fitted scaler and transformed data
2024-12-29 13:56:49,893 - INFO - Scaling time: 0.22s
2024-12-29 13:56:49,899 - INFO - Training completed in 0.23s
2024-12-29 13:56:49,900 - INFO - Final memory usage: CPU 2713.2 MB, GPU 123.2 MB
2024-12-29 13:56:49,900 - INFO - Model training completed in 0.23s
2024-12-29 13:56:49,971 - INFO - Prediction completed in 0.07s
2024-12-29 13:56:49,979 - INFO - Poison rate 0.07 completed in 0.31s
2024-12-29 13:56:49,979 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:56:49,981 - INFO - Total number of labels flipped: 841
2024-12-29 13:56:49,981 - INFO - Label flipping completed in 0.00s
2024-12-29 13:56:49,981 - INFO - Training set processing completed in 0.00s
2024-12-29 13:56:49,981 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:56:49,982 - INFO - Memory usage at start_fit: CPU 2713.2 MB, GPU 123.2 MB
2024-12-29 13:56:49,982 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:56:50,195 - INFO - Fitted scaler and transformed data
2024-12-29 13:56:50,195 - INFO - Scaling time: 0.21s
2024-12-29 13:56:50,201 - INFO - Training completed in 0.22s
2024-12-29 13:56:50,202 - INFO - Final memory usage: CPU 2713.2 MB, GPU 123.2 MB
2024-12-29 13:56:50,202 - INFO - Model training completed in 0.22s
2024-12-29 13:56:50,271 - INFO - Prediction completed in 0.07s
2024-12-29 13:56:50,279 - INFO - Poison rate 0.1 completed in 0.30s
2024-12-29 13:56:50,279 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:56:50,281 - INFO - Total number of labels flipped: 1700
2024-12-29 13:56:50,281 - INFO - Label flipping completed in 0.00s
2024-12-29 13:56:50,281 - INFO - Training set processing completed in 0.00s
2024-12-29 13:56:50,282 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:56:50,282 - INFO - Memory usage at start_fit: CPU 2713.2 MB, GPU 123.2 MB
2024-12-29 13:56:50,282 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:56:50,453 - INFO - Fitted scaler and transformed data
2024-12-29 13:56:50,454 - INFO - Scaling time: 0.17s
2024-12-29 13:56:50,460 - INFO - Training completed in 0.18s
2024-12-29 13:56:50,460 - INFO - Final memory usage: CPU 2713.2 MB, GPU 123.2 MB
2024-12-29 13:56:50,460 - INFO - Model training completed in 0.18s
2024-12-29 13:56:50,535 - INFO - Prediction completed in 0.07s
2024-12-29 13:56:50,544 - INFO - Poison rate 0.2 completed in 0.26s
2024-12-29 13:56:50,550 - INFO - Loaded 322 existing results
2024-12-29 13:56:50,551 - INFO - Total results to save: 329
2024-12-29 13:56:50,552 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:56:50,563 - INFO - Saved 329 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:56:50,564 - INFO - Total evaluation time: 33.86s
2024-12-29 13:56:50,566 - INFO - 
Progress: 50.0% - Evaluating ImageNette with KNeighbors (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:56:50,735 - INFO - Loading datasets...
2024-12-29 13:56:50,756 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:56:50,756 - INFO - Extracting validation features...
2024-12-29 13:56:50,756 - INFO - Extracting features from 3925 samples...
2024-12-29 13:57:00,241 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:57:00,247 - INFO - Validation feature extraction completed in 9.49s
2024-12-29 13:57:00,247 - INFO - Extracting training features...
2024-12-29 13:57:00,248 - INFO - Extracting features from 9469 samples...
2024-12-29 13:57:22,179 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:57:22,186 - INFO - Training feature extraction completed in 21.94s
2024-12-29 13:57:22,186 - INFO - Creating model for classifier: KNeighbors
2024-12-29 13:57:22,187 - INFO - Using device: cuda
2024-12-29 13:57:22,187 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:57:22,187 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:57:22,187 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:57:22,733 - INFO - Feature scaling completed in 0.55s
2024-12-29 13:57:22,733 - INFO - Starting feature selection (k=50)
2024-12-29 13:57:22,743 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:57:22,743 - INFO - Starting anomaly detection
2024-12-29 13:57:26,504 - INFO - Anomaly detection completed in 3.76s
2024-12-29 13:57:26,505 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:57:26,505 - INFO - Total fit_transform time: 4.32s
2024-12-29 13:57:26,505 - INFO - Training set processing completed in 4.32s
2024-12-29 13:57:26,506 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:57:26,508 - INFO - Memory usage at start_fit: CPU 2709.4 MB, GPU 104.0 MB
2024-12-29 13:57:26,508 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:57:26,710 - INFO - Fitted scaler and transformed data
2024-12-29 13:57:26,710 - INFO - Scaling time: 0.20s
2024-12-29 13:57:26,717 - INFO - Training completed in 0.21s
2024-12-29 13:57:26,718 - INFO - Final memory usage: CPU 2709.4 MB, GPU 122.6 MB
2024-12-29 13:57:26,718 - INFO - Model training completed in 0.21s
2024-12-29 13:57:26,820 - INFO - Prediction completed in 0.10s
2024-12-29 13:57:26,829 - INFO - Poison rate 0.0 completed in 4.64s
2024-12-29 13:57:26,829 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:57:26,830 - INFO - Total number of labels flipped: 87
2024-12-29 13:57:26,830 - INFO - Label flipping completed in 0.00s
2024-12-29 13:57:26,830 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:57:26,830 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:57:27,385 - INFO - Feature scaling completed in 0.55s
2024-12-29 13:57:27,385 - INFO - Starting feature selection (k=50)
2024-12-29 13:57:27,397 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:57:27,398 - INFO - Starting anomaly detection
2024-12-29 13:57:30,974 - INFO - Anomaly detection completed in 3.58s
2024-12-29 13:57:30,974 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:57:30,974 - INFO - Total fit_transform time: 4.14s
2024-12-29 13:57:30,975 - INFO - Training set processing completed in 4.14s
2024-12-29 13:57:30,975 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:57:30,976 - INFO - Memory usage at start_fit: CPU 2709.4 MB, GPU 122.6 MB
2024-12-29 13:57:30,976 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:57:31,157 - INFO - Fitted scaler and transformed data
2024-12-29 13:57:31,157 - INFO - Scaling time: 0.18s
2024-12-29 13:57:31,164 - INFO - Training completed in 0.19s
2024-12-29 13:57:31,164 - INFO - Final memory usage: CPU 2709.4 MB, GPU 122.6 MB
2024-12-29 13:57:31,165 - INFO - Model training completed in 0.19s
2024-12-29 13:57:31,269 - INFO - Prediction completed in 0.10s
2024-12-29 13:57:31,278 - INFO - Poison rate 0.01 completed in 4.45s
2024-12-29 13:57:31,278 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:57:31,279 - INFO - Total number of labels flipped: 258
2024-12-29 13:57:31,279 - INFO - Label flipping completed in 0.00s
2024-12-29 13:57:31,279 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:57:31,279 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:57:31,858 - INFO - Feature scaling completed in 0.58s
2024-12-29 13:57:31,859 - INFO - Starting feature selection (k=50)
2024-12-29 13:57:31,867 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:57:31,867 - INFO - Starting anomaly detection
2024-12-29 13:57:35,486 - INFO - Anomaly detection completed in 3.62s
2024-12-29 13:57:35,486 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:57:35,486 - INFO - Total fit_transform time: 4.21s
2024-12-29 13:57:35,486 - INFO - Training set processing completed in 4.21s
2024-12-29 13:57:35,486 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:57:35,487 - INFO - Memory usage at start_fit: CPU 2709.4 MB, GPU 122.6 MB
2024-12-29 13:57:35,487 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:57:35,693 - INFO - Fitted scaler and transformed data
2024-12-29 13:57:35,693 - INFO - Scaling time: 0.21s
2024-12-29 13:57:35,700 - INFO - Training completed in 0.21s
2024-12-29 13:57:35,701 - INFO - Final memory usage: CPU 2709.4 MB, GPU 122.6 MB
2024-12-29 13:57:35,701 - INFO - Model training completed in 0.21s
2024-12-29 13:57:35,803 - INFO - Prediction completed in 0.10s
2024-12-29 13:57:35,811 - INFO - Poison rate 0.03 completed in 4.53s
2024-12-29 13:57:35,812 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:57:35,813 - INFO - Total number of labels flipped: 419
2024-12-29 13:57:35,813 - INFO - Label flipping completed in 0.00s
2024-12-29 13:57:35,813 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:57:35,813 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:57:36,342 - INFO - Feature scaling completed in 0.53s
2024-12-29 13:57:36,342 - INFO - Starting feature selection (k=50)
2024-12-29 13:57:36,354 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:57:36,354 - INFO - Starting anomaly detection
2024-12-29 13:57:40,497 - INFO - Anomaly detection completed in 4.14s
2024-12-29 13:57:40,497 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:57:40,497 - INFO - Total fit_transform time: 4.68s
2024-12-29 13:57:40,497 - INFO - Training set processing completed in 4.68s
2024-12-29 13:57:40,497 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:57:40,498 - INFO - Memory usage at start_fit: CPU 2709.4 MB, GPU 122.6 MB
2024-12-29 13:57:40,499 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:57:40,675 - INFO - Fitted scaler and transformed data
2024-12-29 13:57:40,675 - INFO - Scaling time: 0.18s
2024-12-29 13:57:40,682 - INFO - Training completed in 0.18s
2024-12-29 13:57:40,683 - INFO - Final memory usage: CPU 2709.4 MB, GPU 122.6 MB
2024-12-29 13:57:40,683 - INFO - Model training completed in 0.19s
2024-12-29 13:57:40,799 - INFO - Prediction completed in 0.12s
2024-12-29 13:57:40,823 - INFO - Poison rate 0.05 completed in 5.01s
2024-12-29 13:57:40,823 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:57:40,825 - INFO - Total number of labels flipped: 588
2024-12-29 13:57:40,825 - INFO - Label flipping completed in 0.00s
2024-12-29 13:57:40,825 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:57:40,825 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:57:41,323 - INFO - Feature scaling completed in 0.50s
2024-12-29 13:57:41,323 - INFO - Starting feature selection (k=50)
2024-12-29 13:57:41,331 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:57:41,332 - INFO - Starting anomaly detection
2024-12-29 13:57:45,332 - INFO - Anomaly detection completed in 4.00s
2024-12-29 13:57:45,332 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:57:45,332 - INFO - Total fit_transform time: 4.51s
2024-12-29 13:57:45,332 - INFO - Training set processing completed in 4.51s
2024-12-29 13:57:45,332 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:57:45,333 - INFO - Memory usage at start_fit: CPU 2709.4 MB, GPU 122.6 MB
2024-12-29 13:57:45,333 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:57:45,528 - INFO - Fitted scaler and transformed data
2024-12-29 13:57:45,528 - INFO - Scaling time: 0.19s
2024-12-29 13:57:45,535 - INFO - Training completed in 0.20s
2024-12-29 13:57:45,536 - INFO - Final memory usage: CPU 2709.4 MB, GPU 122.6 MB
2024-12-29 13:57:45,536 - INFO - Model training completed in 0.20s
2024-12-29 13:57:45,638 - INFO - Prediction completed in 0.10s
2024-12-29 13:57:45,647 - INFO - Poison rate 0.07 completed in 4.82s
2024-12-29 13:57:45,647 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:57:45,649 - INFO - Total number of labels flipped: 856
2024-12-29 13:57:45,649 - INFO - Label flipping completed in 0.00s
2024-12-29 13:57:45,649 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:57:45,649 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:57:46,206 - INFO - Feature scaling completed in 0.56s
2024-12-29 13:57:46,206 - INFO - Starting feature selection (k=50)
2024-12-29 13:57:46,214 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:57:46,214 - INFO - Starting anomaly detection
2024-12-29 13:57:49,898 - INFO - Anomaly detection completed in 3.68s
2024-12-29 13:57:49,898 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:57:49,898 - INFO - Total fit_transform time: 4.25s
2024-12-29 13:57:49,898 - INFO - Training set processing completed in 4.25s
2024-12-29 13:57:49,898 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:57:49,899 - INFO - Memory usage at start_fit: CPU 2709.4 MB, GPU 122.6 MB
2024-12-29 13:57:49,899 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:57:50,076 - INFO - Fitted scaler and transformed data
2024-12-29 13:57:50,076 - INFO - Scaling time: 0.18s
2024-12-29 13:57:50,083 - INFO - Training completed in 0.18s
2024-12-29 13:57:50,084 - INFO - Final memory usage: CPU 2709.4 MB, GPU 122.6 MB
2024-12-29 13:57:50,084 - INFO - Model training completed in 0.19s
2024-12-29 13:57:50,202 - INFO - Prediction completed in 0.12s
2024-12-29 13:57:50,211 - INFO - Poison rate 0.1 completed in 4.56s
2024-12-29 13:57:50,211 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:57:50,212 - INFO - Total number of labels flipped: 1681
2024-12-29 13:57:50,213 - INFO - Label flipping completed in 0.00s
2024-12-29 13:57:50,213 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:57:50,213 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:57:50,755 - INFO - Feature scaling completed in 0.54s
2024-12-29 13:57:50,756 - INFO - Starting feature selection (k=50)
2024-12-29 13:57:50,764 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 13:57:50,764 - INFO - Starting anomaly detection
2024-12-29 13:57:54,720 - INFO - Anomaly detection completed in 3.96s
2024-12-29 13:57:54,721 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:57:54,721 - INFO - Total fit_transform time: 4.51s
2024-12-29 13:57:54,721 - INFO - Training set processing completed in 4.51s
2024-12-29 13:57:54,721 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 13:57:54,722 - INFO - Memory usage at start_fit: CPU 2709.4 MB, GPU 122.6 MB
2024-12-29 13:57:54,722 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:57:54,918 - INFO - Fitted scaler and transformed data
2024-12-29 13:57:54,918 - INFO - Scaling time: 0.20s
2024-12-29 13:57:54,928 - INFO - Training completed in 0.21s
2024-12-29 13:57:54,928 - INFO - Final memory usage: CPU 2709.4 MB, GPU 122.6 MB
2024-12-29 13:57:54,928 - INFO - Model training completed in 0.21s
2024-12-29 13:57:55,028 - INFO - Prediction completed in 0.10s
2024-12-29 13:57:55,036 - INFO - Poison rate 0.2 completed in 4.83s
2024-12-29 13:57:55,043 - INFO - Loaded 329 existing results
2024-12-29 13:57:55,043 - INFO - Total results to save: 336
2024-12-29 13:57:55,044 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:57:55,056 - INFO - Saved 336 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:57:55,056 - INFO - Total evaluation time: 64.32s
2024-12-29 13:57:55,058 - INFO - Completed evaluation for ImageNette
2024-12-29 13:57:55,058 - INFO - 
Processing dataset: ImageNette
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:57:55,228 - INFO - 
Progress: 51.0% - Evaluating ImageNette with SVM (standard mode, iteration 1/1)
2024-12-29 13:57:55,428 - INFO - Loading datasets...
2024-12-29 13:57:55,458 - INFO - Dataset loading completed in 0.03s
2024-12-29 13:57:55,458 - INFO - Extracting validation features...
2024-12-29 13:57:55,458 - INFO - Extracting features from 3925 samples...
2024-12-29 13:58:04,850 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:58:04,856 - INFO - Validation feature extraction completed in 9.40s
2024-12-29 13:58:04,857 - INFO - Extracting training features...
2024-12-29 13:58:04,857 - INFO - Extracting features from 9469 samples...
2024-12-29 13:58:26,691 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:58:26,696 - INFO - Training feature extraction completed in 21.84s
2024-12-29 13:58:26,697 - INFO - Creating model for classifier: SVM
2024-12-29 13:58:26,697 - INFO - Using device: cuda
2024-12-29 13:58:26,698 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-29 13:58:26,698 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:58:26,698 - INFO - Training set processing completed in 0.00s
2024-12-29 13:58:26,699 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:58:26,701 - INFO - Memory usage at start_fit: CPU 2681.8 MB, GPU 104.6 MB
2024-12-29 13:58:26,701 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:58:26,706 - INFO - Number of unique classes: 10
2024-12-29 13:58:26,780 - INFO - Fitted scaler and transformed data
2024-12-29 13:58:26,780 - INFO - Scaling time: 0.07s
2024-12-29 13:58:27,116 - INFO - Epoch 1/500, Train Loss: 0.6731, Val Loss: 0.1489
2024-12-29 13:58:27,432 - INFO - Epoch 2/500, Train Loss: 0.0854, Val Loss: 0.1119
2024-12-29 13:58:27,786 - INFO - Epoch 3/500, Train Loss: 0.0545, Val Loss: 0.0923
2024-12-29 13:58:28,115 - INFO - Epoch 4/500, Train Loss: 0.0379, Val Loss: 0.0834
2024-12-29 13:58:28,515 - INFO - Epoch 5/500, Train Loss: 0.0277, Val Loss: 0.0797
2024-12-29 13:58:28,829 - INFO - Epoch 6/500, Train Loss: 0.0219, Val Loss: 0.0776
2024-12-29 13:58:29,165 - INFO - Epoch 7/500, Train Loss: 0.0178, Val Loss: 0.0765
2024-12-29 13:58:29,473 - INFO - Epoch 8/500, Train Loss: 0.0151, Val Loss: 0.0752
2024-12-29 13:58:29,850 - INFO - Epoch 9/500, Train Loss: 0.0133, Val Loss: 0.0727
2024-12-29 13:58:30,208 - INFO - Epoch 10/500, Train Loss: 0.0112, Val Loss: 0.0714
2024-12-29 13:58:30,533 - INFO - Epoch 11/500, Train Loss: 0.0094, Val Loss: 0.0697
2024-12-29 13:58:30,847 - INFO - Epoch 12/500, Train Loss: 0.0083, Val Loss: 0.0689
2024-12-29 13:58:31,162 - INFO - Epoch 13/500, Train Loss: 0.0073, Val Loss: 0.0714
2024-12-29 13:58:31,541 - INFO - Epoch 14/500, Train Loss: 0.0068, Val Loss: 0.0684
2024-12-29 13:58:31,887 - INFO - Epoch 15/500, Train Loss: 0.0056, Val Loss: 0.0702
2024-12-29 13:58:32,217 - INFO - Epoch 16/500, Train Loss: 0.0051, Val Loss: 0.0664
2024-12-29 13:58:32,580 - INFO - Epoch 17/500, Train Loss: 0.0047, Val Loss: 0.0687
2024-12-29 13:58:32,898 - INFO - Epoch 18/500, Train Loss: 0.0045, Val Loss: 0.0724
2024-12-29 13:58:33,220 - INFO - Epoch 19/500, Train Loss: 0.0043, Val Loss: 0.0631
2024-12-29 13:58:33,621 - INFO - Epoch 20/500, Train Loss: 0.0038, Val Loss: 0.0643
2024-12-29 13:58:33,974 - INFO - Epoch 21/500, Train Loss: 0.0038, Val Loss: 0.0635
2024-12-29 13:58:34,326 - INFO - Epoch 22/500, Train Loss: 0.0036, Val Loss: 0.0673
2024-12-29 13:58:34,679 - INFO - Epoch 23/500, Train Loss: 0.0031, Val Loss: 0.0632
2024-12-29 13:58:34,977 - INFO - Epoch 24/500, Train Loss: 0.0029, Val Loss: 0.0641
2024-12-29 13:58:34,977 - INFO - Early stopping triggered at epoch 24
2024-12-29 13:58:34,977 - INFO - Training completed in 8.28s
2024-12-29 13:58:34,978 - INFO - Final memory usage: CPU 2718.8 MB, GPU 104.8 MB
2024-12-29 13:58:34,978 - INFO - Model training completed in 8.28s
2024-12-29 13:58:35,046 - INFO - Prediction completed in 0.07s
2024-12-29 13:58:35,055 - INFO - Poison rate 0.0 completed in 8.36s
2024-12-29 13:58:35,055 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:58:35,056 - INFO - Label flipping details:
2024-12-29 13:58:35,056 - INFO - - Source class: 1
2024-12-29 13:58:35,056 - INFO - - Target class: 0
2024-12-29 13:58:35,056 - INFO - - Available samples in source class: 955
2024-12-29 13:58:35,056 - INFO - - Requested samples to poison: 94
2024-12-29 13:58:35,056 - INFO - - Actual samples to flip: 94
2024-12-29 13:58:35,056 - INFO - - Samples remaining in source class: 861
2024-12-29 13:58:35,056 - INFO - Successfully flipped 94 labels from class 1 to 0
2024-12-29 13:58:35,057 - INFO - Total number of labels flipped: 94
2024-12-29 13:58:35,057 - INFO - Label flipping completed in 0.00s
2024-12-29 13:58:35,057 - INFO - Training set processing completed in 0.00s
2024-12-29 13:58:35,057 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:58:35,058 - INFO - Memory usage at start_fit: CPU 2689.2 MB, GPU 104.7 MB
2024-12-29 13:58:35,058 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:58:35,062 - INFO - Number of unique classes: 10
2024-12-29 13:58:35,164 - INFO - Fitted scaler and transformed data
2024-12-29 13:58:35,164 - INFO - Scaling time: 0.10s
2024-12-29 13:58:35,628 - INFO - Epoch 1/500, Train Loss: 0.8528, Val Loss: 0.1574
2024-12-29 13:58:36,004 - INFO - Epoch 2/500, Train Loss: 0.1266, Val Loss: 0.1218
2024-12-29 13:58:36,365 - INFO - Epoch 3/500, Train Loss: 0.0923, Val Loss: 0.1038
2024-12-29 13:58:36,717 - INFO - Epoch 4/500, Train Loss: 0.0737, Val Loss: 0.0942
2024-12-29 13:58:37,063 - INFO - Epoch 5/500, Train Loss: 0.0618, Val Loss: 0.0887
2024-12-29 13:58:37,407 - INFO - Epoch 6/500, Train Loss: 0.0532, Val Loss: 0.0867
2024-12-29 13:58:37,784 - INFO - Epoch 7/500, Train Loss: 0.0487, Val Loss: 0.0859
2024-12-29 13:58:38,138 - INFO - Epoch 8/500, Train Loss: 0.0435, Val Loss: 0.0835
2024-12-29 13:58:38,466 - INFO - Epoch 9/500, Train Loss: 0.0394, Val Loss: 0.0825
2024-12-29 13:58:38,846 - INFO - Epoch 10/500, Train Loss: 0.0375, Val Loss: 0.0804
2024-12-29 13:58:39,239 - INFO - Epoch 11/500, Train Loss: 0.0347, Val Loss: 0.0788
2024-12-29 13:58:39,617 - INFO - Epoch 12/500, Train Loss: 0.0330, Val Loss: 0.0810
2024-12-29 13:58:39,977 - INFO - Epoch 13/500, Train Loss: 0.0313, Val Loss: 0.0786
2024-12-29 13:58:40,317 - INFO - Epoch 14/500, Train Loss: 0.0300, Val Loss: 0.0810
2024-12-29 13:58:40,678 - INFO - Epoch 15/500, Train Loss: 0.0292, Val Loss: 0.0847
2024-12-29 13:58:41,012 - INFO - Epoch 16/500, Train Loss: 0.0278, Val Loss: 0.0817
2024-12-29 13:58:41,012 - INFO - Early stopping triggered at epoch 16
2024-12-29 13:58:41,013 - INFO - Training completed in 5.96s
2024-12-29 13:58:41,013 - INFO - Final memory usage: CPU 2718.4 MB, GPU 104.8 MB
2024-12-29 13:58:41,014 - INFO - Model training completed in 5.96s
2024-12-29 13:58:41,063 - INFO - Prediction completed in 0.05s
2024-12-29 13:58:41,072 - INFO - Poison rate 0.01 completed in 6.02s
2024-12-29 13:58:41,072 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:58:41,073 - INFO - Label flipping details:
2024-12-29 13:58:41,073 - INFO - - Source class: 1
2024-12-29 13:58:41,073 - INFO - - Target class: 0
2024-12-29 13:58:41,073 - INFO - - Available samples in source class: 955
2024-12-29 13:58:41,073 - INFO - - Requested samples to poison: 284
2024-12-29 13:58:41,073 - INFO - - Actual samples to flip: 284
2024-12-29 13:58:41,073 - INFO - - Samples remaining in source class: 671
2024-12-29 13:58:41,073 - INFO - Successfully flipped 284 labels from class 1 to 0
2024-12-29 13:58:41,073 - INFO - Total number of labels flipped: 284
2024-12-29 13:58:41,073 - INFO - Label flipping completed in 0.00s
2024-12-29 13:58:41,073 - INFO - Training set processing completed in 0.00s
2024-12-29 13:58:41,073 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:58:41,074 - INFO - Memory usage at start_fit: CPU 2688.8 MB, GPU 104.7 MB
2024-12-29 13:58:41,074 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:58:41,078 - INFO - Number of unique classes: 10
2024-12-29 13:58:41,145 - INFO - Fitted scaler and transformed data
2024-12-29 13:58:41,146 - INFO - Scaling time: 0.07s
2024-12-29 13:58:41,478 - INFO - Epoch 1/500, Train Loss: 1.0419, Val Loss: 0.1930
2024-12-29 13:58:41,828 - INFO - Epoch 2/500, Train Loss: 0.1864, Val Loss: 0.1593
2024-12-29 13:58:42,161 - INFO - Epoch 3/500, Train Loss: 0.1451, Val Loss: 0.1440
2024-12-29 13:58:42,504 - INFO - Epoch 4/500, Train Loss: 0.1227, Val Loss: 0.1345
2024-12-29 13:58:42,941 - INFO - Epoch 5/500, Train Loss: 0.1087, Val Loss: 0.1293
2024-12-29 13:58:43,302 - INFO - Epoch 6/500, Train Loss: 0.0983, Val Loss: 0.1287
2024-12-29 13:58:43,703 - INFO - Epoch 7/500, Train Loss: 0.0926, Val Loss: 0.1279
2024-12-29 13:58:44,100 - INFO - Epoch 8/500, Train Loss: 0.0872, Val Loss: 0.1300
2024-12-29 13:58:44,525 - INFO - Epoch 9/500, Train Loss: 0.0829, Val Loss: 0.1275
2024-12-29 13:58:44,896 - INFO - Epoch 10/500, Train Loss: 0.0797, Val Loss: 0.1316
2024-12-29 13:58:45,315 - INFO - Epoch 11/500, Train Loss: 0.0774, Val Loss: 0.1211
2024-12-29 13:58:45,688 - INFO - Epoch 12/500, Train Loss: 0.0748, Val Loss: 0.1227
2024-12-29 13:58:46,045 - INFO - Epoch 13/500, Train Loss: 0.0727, Val Loss: 0.1241
2024-12-29 13:58:46,401 - INFO - Epoch 14/500, Train Loss: 0.0705, Val Loss: 0.1235
2024-12-29 13:58:46,720 - INFO - Epoch 15/500, Train Loss: 0.0692, Val Loss: 0.1183
2024-12-29 13:58:47,068 - INFO - Epoch 16/500, Train Loss: 0.0691, Val Loss: 0.1266
2024-12-29 13:58:47,399 - INFO - Epoch 17/500, Train Loss: 0.0675, Val Loss: 0.1268
2024-12-29 13:58:47,839 - INFO - Epoch 18/500, Train Loss: 0.0664, Val Loss: 0.1297
2024-12-29 13:58:48,234 - INFO - Epoch 19/500, Train Loss: 0.0659, Val Loss: 0.1224
2024-12-29 13:58:48,654 - INFO - Epoch 20/500, Train Loss: 0.0641, Val Loss: 0.1251
2024-12-29 13:58:48,654 - INFO - Early stopping triggered at epoch 20
2024-12-29 13:58:48,654 - INFO - Training completed in 7.58s
2024-12-29 13:58:48,654 - INFO - Final memory usage: CPU 2718.3 MB, GPU 104.8 MB
2024-12-29 13:58:48,655 - INFO - Model training completed in 7.58s
2024-12-29 13:58:48,700 - INFO - Prediction completed in 0.04s
2024-12-29 13:58:48,709 - INFO - Poison rate 0.03 completed in 7.64s
2024-12-29 13:58:48,709 - INFO - 
Processing poison rate: 0.05
2024-12-29 13:58:48,710 - INFO - Label flipping details:
2024-12-29 13:58:48,710 - INFO - - Source class: 1
2024-12-29 13:58:48,710 - INFO - - Target class: 0
2024-12-29 13:58:48,710 - INFO - - Available samples in source class: 955
2024-12-29 13:58:48,710 - INFO - - Requested samples to poison: 473
2024-12-29 13:58:48,710 - INFO - - Actual samples to flip: 473
2024-12-29 13:58:48,710 - INFO - - Samples remaining in source class: 482
2024-12-29 13:58:48,710 - INFO - Successfully flipped 473 labels from class 1 to 0
2024-12-29 13:58:48,710 - INFO - Total number of labels flipped: 473
2024-12-29 13:58:48,710 - INFO - Label flipping completed in 0.00s
2024-12-29 13:58:48,710 - INFO - Training set processing completed in 0.00s
2024-12-29 13:58:48,710 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:58:48,711 - INFO - Memory usage at start_fit: CPU 2688.8 MB, GPU 104.7 MB
2024-12-29 13:58:48,711 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:58:48,715 - INFO - Number of unique classes: 10
2024-12-29 13:58:48,786 - INFO - Fitted scaler and transformed data
2024-12-29 13:58:48,787 - INFO - Scaling time: 0.07s
2024-12-29 13:58:49,148 - INFO - Epoch 1/500, Train Loss: 1.0038, Val Loss: 0.2190
2024-12-29 13:58:49,580 - INFO - Epoch 2/500, Train Loss: 0.1965, Val Loss: 0.1920
2024-12-29 13:58:49,941 - INFO - Epoch 3/500, Train Loss: 0.1600, Val Loss: 0.1829
2024-12-29 13:58:50,302 - INFO - Epoch 4/500, Train Loss: 0.1378, Val Loss: 0.1789
2024-12-29 13:58:50,735 - INFO - Epoch 5/500, Train Loss: 0.1221, Val Loss: 0.1845
2024-12-29 13:58:51,102 - INFO - Epoch 6/500, Train Loss: 0.1127, Val Loss: 0.1798
2024-12-29 13:58:51,443 - INFO - Epoch 7/500, Train Loss: 0.1046, Val Loss: 0.1863
2024-12-29 13:58:51,852 - INFO - Epoch 8/500, Train Loss: 0.1003, Val Loss: 0.1785
2024-12-29 13:58:52,245 - INFO - Epoch 9/500, Train Loss: 0.0936, Val Loss: 0.1833
2024-12-29 13:58:52,245 - INFO - Early stopping triggered at epoch 9
2024-12-29 13:58:52,245 - INFO - Training completed in 3.53s
2024-12-29 13:58:52,245 - INFO - Final memory usage: CPU 2718.4 MB, GPU 104.8 MB
2024-12-29 13:58:52,246 - INFO - Model training completed in 3.54s
2024-12-29 13:58:52,295 - INFO - Prediction completed in 0.05s
2024-12-29 13:58:52,304 - INFO - Poison rate 0.05 completed in 3.60s
2024-12-29 13:58:52,304 - INFO - 
Processing poison rate: 0.07
2024-12-29 13:58:52,305 - INFO - Label flipping details:
2024-12-29 13:58:52,305 - INFO - - Source class: 1
2024-12-29 13:58:52,305 - INFO - - Target class: 0
2024-12-29 13:58:52,305 - INFO - - Available samples in source class: 955
2024-12-29 13:58:52,305 - INFO - - Requested samples to poison: 662
2024-12-29 13:58:52,305 - INFO - - Actual samples to flip: 662
2024-12-29 13:58:52,305 - INFO - - Samples remaining in source class: 293
2024-12-29 13:58:52,305 - INFO - Successfully flipped 662 labels from class 1 to 0
2024-12-29 13:58:52,306 - INFO - Total number of labels flipped: 662
2024-12-29 13:58:52,306 - INFO - Label flipping completed in 0.00s
2024-12-29 13:58:52,306 - INFO - Training set processing completed in 0.00s
2024-12-29 13:58:52,306 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:58:52,307 - INFO - Memory usage at start_fit: CPU 2688.8 MB, GPU 104.7 MB
2024-12-29 13:58:52,307 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:58:52,312 - INFO - Number of unique classes: 10
2024-12-29 13:58:52,388 - INFO - Fitted scaler and transformed data
2024-12-29 13:58:52,388 - INFO - Scaling time: 0.07s
2024-12-29 13:58:52,822 - INFO - Epoch 1/500, Train Loss: 0.9916, Val Loss: 0.2126
2024-12-29 13:58:53,218 - INFO - Epoch 2/500, Train Loss: 0.1742, Val Loss: 0.1752
2024-12-29 13:58:53,600 - INFO - Epoch 3/500, Train Loss: 0.1378, Val Loss: 0.1581
2024-12-29 13:58:53,974 - INFO - Epoch 4/500, Train Loss: 0.1181, Val Loss: 0.1503
2024-12-29 13:58:54,356 - INFO - Epoch 5/500, Train Loss: 0.1054, Val Loss: 0.1466
2024-12-29 13:58:54,737 - INFO - Epoch 6/500, Train Loss: 0.0969, Val Loss: 0.1427
2024-12-29 13:58:55,097 - INFO - Epoch 7/500, Train Loss: 0.0910, Val Loss: 0.1410
2024-12-29 13:58:55,480 - INFO - Epoch 8/500, Train Loss: 0.0856, Val Loss: 0.1376
2024-12-29 13:58:55,810 - INFO - Epoch 9/500, Train Loss: 0.0827, Val Loss: 0.1427
2024-12-29 13:58:56,189 - INFO - Epoch 10/500, Train Loss: 0.0785, Val Loss: 0.1385
2024-12-29 13:58:56,566 - INFO - Epoch 11/500, Train Loss: 0.0745, Val Loss: 0.1378
2024-12-29 13:58:56,936 - INFO - Epoch 12/500, Train Loss: 0.0735, Val Loss: 0.1420
2024-12-29 13:58:57,294 - INFO - Epoch 13/500, Train Loss: 0.0714, Val Loss: 0.1488
2024-12-29 13:58:57,294 - INFO - Early stopping triggered at epoch 13
2024-12-29 13:58:57,294 - INFO - Training completed in 4.99s
2024-12-29 13:58:57,295 - INFO - Final memory usage: CPU 2718.6 MB, GPU 104.8 MB
2024-12-29 13:58:57,297 - INFO - Model training completed in 4.99s
2024-12-29 13:58:57,347 - INFO - Prediction completed in 0.05s
2024-12-29 13:58:57,356 - INFO - Poison rate 0.07 completed in 5.05s
2024-12-29 13:58:57,356 - INFO - 
Processing poison rate: 0.1
2024-12-29 13:58:57,357 - INFO - Label flipping details:
2024-12-29 13:58:57,357 - INFO - - Source class: 1
2024-12-29 13:58:57,357 - INFO - - Target class: 0
2024-12-29 13:58:57,357 - INFO - - Available samples in source class: 955
2024-12-29 13:58:57,357 - INFO - - Requested samples to poison: 946
2024-12-29 13:58:57,357 - INFO - - Actual samples to flip: 946
2024-12-29 13:58:57,357 - INFO - - Samples remaining in source class: 9
2024-12-29 13:58:57,357 - INFO - Successfully flipped 946 labels from class 1 to 0
2024-12-29 13:58:57,358 - INFO - Total number of labels flipped: 946
2024-12-29 13:58:57,358 - INFO - Label flipping completed in 0.00s
2024-12-29 13:58:57,358 - INFO - Training set processing completed in 0.00s
2024-12-29 13:58:57,358 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:58:57,359 - INFO - Memory usage at start_fit: CPU 2689.0 MB, GPU 104.7 MB
2024-12-29 13:58:57,359 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:58:57,362 - INFO - Number of unique classes: 10
2024-12-29 13:58:57,432 - INFO - Fitted scaler and transformed data
2024-12-29 13:58:57,433 - INFO - Scaling time: 0.07s
2024-12-29 13:58:57,854 - INFO - Epoch 1/500, Train Loss: 0.8694, Val Loss: 0.1381
2024-12-29 13:58:58,214 - INFO - Epoch 2/500, Train Loss: 0.1003, Val Loss: 0.1094
2024-12-29 13:58:58,523 - INFO - Epoch 3/500, Train Loss: 0.0661, Val Loss: 0.0980
2024-12-29 13:58:58,851 - INFO - Epoch 4/500, Train Loss: 0.0492, Val Loss: 0.0937
2024-12-29 13:58:59,211 - INFO - Epoch 5/500, Train Loss: 0.0385, Val Loss: 0.0900
2024-12-29 13:58:59,595 - INFO - Epoch 6/500, Train Loss: 0.0310, Val Loss: 0.0902
2024-12-29 13:58:59,959 - INFO - Epoch 7/500, Train Loss: 0.0257, Val Loss: 0.0883
2024-12-29 13:59:00,317 - INFO - Epoch 8/500, Train Loss: 0.0218, Val Loss: 0.0888
2024-12-29 13:59:00,651 - INFO - Epoch 9/500, Train Loss: 0.0187, Val Loss: 0.0877
2024-12-29 13:59:01,004 - INFO - Epoch 10/500, Train Loss: 0.0160, Val Loss: 0.0891
2024-12-29 13:59:01,391 - INFO - Epoch 11/500, Train Loss: 0.0135, Val Loss: 0.0910
2024-12-29 13:59:01,732 - INFO - Epoch 12/500, Train Loss: 0.0121, Val Loss: 0.0869
2024-12-29 13:59:02,098 - INFO - Epoch 13/500, Train Loss: 0.0108, Val Loss: 0.0893
2024-12-29 13:59:02,428 - INFO - Epoch 14/500, Train Loss: 0.0098, Val Loss: 0.0895
2024-12-29 13:59:02,816 - INFO - Epoch 15/500, Train Loss: 0.0086, Val Loss: 0.0932
2024-12-29 13:59:03,196 - INFO - Epoch 16/500, Train Loss: 0.0079, Val Loss: 0.0965
2024-12-29 13:59:03,586 - INFO - Epoch 17/500, Train Loss: 0.0071, Val Loss: 0.0939
2024-12-29 13:59:03,586 - INFO - Early stopping triggered at epoch 17
2024-12-29 13:59:03,586 - INFO - Training completed in 6.23s
2024-12-29 13:59:03,586 - INFO - Final memory usage: CPU 2718.5 MB, GPU 104.8 MB
2024-12-29 13:59:03,587 - INFO - Model training completed in 6.23s
2024-12-29 13:59:03,634 - INFO - Prediction completed in 0.05s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 13:59:03,648 - INFO - Poison rate 0.1 completed in 6.29s
2024-12-29 13:59:03,648 - INFO - 
Processing poison rate: 0.2
2024-12-29 13:59:03,649 - INFO - Label flipping details:
2024-12-29 13:59:03,649 - INFO - - Source class: 1
2024-12-29 13:59:03,649 - INFO - - Target class: 0
2024-12-29 13:59:03,649 - INFO - - Available samples in source class: 955
2024-12-29 13:59:03,649 - INFO - - Requested samples to poison: 1893
2024-12-29 13:59:03,649 - INFO - - Actual samples to flip: 954
2024-12-29 13:59:03,649 - INFO - - Samples remaining in source class: 1
2024-12-29 13:59:03,649 - INFO - Successfully flipped 954 labels from class 1 to 0
2024-12-29 13:59:03,649 - INFO - Total number of labels flipped: 954
2024-12-29 13:59:03,649 - INFO - Label flipping completed in 0.00s
2024-12-29 13:59:03,649 - INFO - Training set processing completed in 0.00s
2024-12-29 13:59:03,650 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:59:03,650 - INFO - Memory usage at start_fit: CPU 2688.9 MB, GPU 104.7 MB
2024-12-29 13:59:03,650 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:59:03,654 - INFO - Number of unique classes: 10
2024-12-29 13:59:03,743 - INFO - Fitted scaler and transformed data
2024-12-29 13:59:03,743 - INFO - Scaling time: 0.09s
2024-12-29 13:59:04,087 - INFO - Epoch 1/500, Train Loss: 0.8263, Val Loss: 0.1217
2024-12-29 13:59:04,531 - INFO - Epoch 2/500, Train Loss: 0.0917, Val Loss: 0.1021
2024-12-29 13:59:04,925 - INFO - Epoch 3/500, Train Loss: 0.0610, Val Loss: 0.0911
2024-12-29 13:59:05,391 - INFO - Epoch 4/500, Train Loss: 0.0443, Val Loss: 0.0873
2024-12-29 13:59:05,755 - INFO - Epoch 5/500, Train Loss: 0.0345, Val Loss: 0.0850
2024-12-29 13:59:06,083 - INFO - Epoch 6/500, Train Loss: 0.0275, Val Loss: 0.0848
2024-12-29 13:59:06,504 - INFO - Epoch 7/500, Train Loss: 0.0230, Val Loss: 0.0821
2024-12-29 13:59:06,893 - INFO - Epoch 8/500, Train Loss: 0.0190, Val Loss: 0.0828
2024-12-29 13:59:07,285 - INFO - Epoch 9/500, Train Loss: 0.0165, Val Loss: 0.0808
2024-12-29 13:59:07,625 - INFO - Epoch 10/500, Train Loss: 0.0140, Val Loss: 0.0805
2024-12-29 13:59:07,999 - INFO - Epoch 11/500, Train Loss: 0.0119, Val Loss: 0.0795
2024-12-29 13:59:08,340 - INFO - Epoch 12/500, Train Loss: 0.0106, Val Loss: 0.0808
2024-12-29 13:59:08,776 - INFO - Epoch 13/500, Train Loss: 0.0095, Val Loss: 0.0818
2024-12-29 13:59:09,143 - INFO - Epoch 14/500, Train Loss: 0.0081, Val Loss: 0.0811
2024-12-29 13:59:09,567 - INFO - Epoch 15/500, Train Loss: 0.0073, Val Loss: 0.0841
2024-12-29 13:59:09,941 - INFO - Epoch 16/500, Train Loss: 0.0068, Val Loss: 0.0805
2024-12-29 13:59:09,942 - INFO - Early stopping triggered at epoch 16
2024-12-29 13:59:09,942 - INFO - Training completed in 6.29s
2024-12-29 13:59:09,942 - INFO - Final memory usage: CPU 2718.7 MB, GPU 104.8 MB
2024-12-29 13:59:09,943 - INFO - Model training completed in 6.29s
2024-12-29 13:59:09,987 - INFO - Prediction completed in 0.04s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 13:59:09,996 - INFO - Poison rate 0.2 completed in 6.35s
2024-12-29 13:59:10,002 - INFO - Loaded 336 existing results
2024-12-29 13:59:10,002 - INFO - Total results to save: 343
2024-12-29 13:59:10,003 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 13:59:10,026 - INFO - Saved 343 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 13:59:10,028 - INFO - Total evaluation time: 74.60s
2024-12-29 13:59:10,031 - INFO - 
Progress: 52.1% - Evaluating ImageNette with SVM (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 13:59:10,244 - INFO - Loading datasets...
2024-12-29 13:59:10,268 - INFO - Dataset loading completed in 0.02s
2024-12-29 13:59:10,268 - INFO - Extracting validation features...
2024-12-29 13:59:10,268 - INFO - Extracting features from 3925 samples...
2024-12-29 13:59:19,627 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 13:59:19,633 - INFO - Validation feature extraction completed in 9.37s
2024-12-29 13:59:19,634 - INFO - Extracting training features...
2024-12-29 13:59:19,634 - INFO - Extracting features from 9469 samples...
2024-12-29 13:59:41,905 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 13:59:41,910 - INFO - Training feature extraction completed in 22.28s
2024-12-29 13:59:41,910 - INFO - Creating model for classifier: SVM
2024-12-29 13:59:41,910 - INFO - Using device: cuda
2024-12-29 13:59:41,911 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-29 13:59:41,911 - INFO - 
Processing poison rate: 0.0
2024-12-29 13:59:41,911 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:59:41,911 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:59:42,458 - INFO - Feature scaling completed in 0.55s
2024-12-29 13:59:42,458 - INFO - Starting feature selection (k=50)
2024-12-29 13:59:42,474 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 13:59:42,474 - INFO - Starting anomaly detection
2024-12-29 13:59:46,310 - INFO - Anomaly detection completed in 3.83s
2024-12-29 13:59:46,310 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:59:46,310 - INFO - Total fit_transform time: 4.40s
2024-12-29 13:59:46,310 - INFO - Training set processing completed in 4.40s
2024-12-29 13:59:46,310 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:59:46,311 - INFO - Memory usage at start_fit: CPU 2709.3 MB, GPU 104.0 MB
2024-12-29 13:59:46,311 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:59:46,314 - INFO - Number of unique classes: 10
2024-12-29 13:59:46,386 - INFO - Fitted scaler and transformed data
2024-12-29 13:59:46,387 - INFO - Scaling time: 0.07s
2024-12-29 13:59:46,763 - INFO - Epoch 1/500, Train Loss: 0.7030, Val Loss: 0.1020
2024-12-29 13:59:47,144 - INFO - Epoch 2/500, Train Loss: 0.0852, Val Loss: 0.0823
2024-12-29 13:59:47,504 - INFO - Epoch 3/500, Train Loss: 0.0542, Val Loss: 0.0727
2024-12-29 13:59:47,930 - INFO - Epoch 4/500, Train Loss: 0.0391, Val Loss: 0.0721
2024-12-29 13:59:48,310 - INFO - Epoch 5/500, Train Loss: 0.0303, Val Loss: 0.0699
2024-12-29 13:59:48,705 - INFO - Epoch 6/500, Train Loss: 0.0240, Val Loss: 0.0692
2024-12-29 13:59:49,108 - INFO - Epoch 7/500, Train Loss: 0.0198, Val Loss: 0.0701
2024-12-29 13:59:49,457 - INFO - Epoch 8/500, Train Loss: 0.0164, Val Loss: 0.0697
2024-12-29 13:59:49,813 - INFO - Epoch 9/500, Train Loss: 0.0135, Val Loss: 0.0692
2024-12-29 13:59:50,197 - INFO - Epoch 10/500, Train Loss: 0.0116, Val Loss: 0.0713
2024-12-29 13:59:50,198 - INFO - Early stopping triggered at epoch 10
2024-12-29 13:59:50,198 - INFO - Training completed in 3.89s
2024-12-29 13:59:50,199 - INFO - Final memory usage: CPU 2718.7 MB, GPU 104.2 MB
2024-12-29 13:59:50,201 - INFO - Model training completed in 3.89s
2024-12-29 13:59:50,266 - INFO - Prediction completed in 0.06s
2024-12-29 13:59:50,275 - INFO - Poison rate 0.0 completed in 8.36s
2024-12-29 13:59:50,275 - INFO - 
Processing poison rate: 0.01
2024-12-29 13:59:50,276 - INFO - Label flipping details:
2024-12-29 13:59:50,276 - INFO - - Source class: 1
2024-12-29 13:59:50,276 - INFO - - Target class: 0
2024-12-29 13:59:50,276 - INFO - - Available samples in source class: 955
2024-12-29 13:59:50,276 - INFO - - Requested samples to poison: 94
2024-12-29 13:59:50,276 - INFO - - Actual samples to flip: 94
2024-12-29 13:59:50,276 - INFO - - Samples remaining in source class: 861
2024-12-29 13:59:50,276 - INFO - Successfully flipped 94 labels from class 1 to 0
2024-12-29 13:59:50,276 - INFO - Total number of labels flipped: 94
2024-12-29 13:59:50,277 - INFO - Label flipping completed in 0.00s
2024-12-29 13:59:50,277 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:59:50,277 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 13:59:50,777 - INFO - Feature scaling completed in 0.50s
2024-12-29 13:59:50,778 - INFO - Starting feature selection (k=50)
2024-12-29 13:59:50,793 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 13:59:50,794 - INFO - Starting anomaly detection
2024-12-29 13:59:54,727 - INFO - Anomaly detection completed in 3.93s
2024-12-29 13:59:54,728 - INFO - Found 947 outliers (10.0%)
2024-12-29 13:59:54,728 - INFO - Total fit_transform time: 4.45s
2024-12-29 13:59:54,728 - INFO - Training set processing completed in 4.45s
2024-12-29 13:59:54,728 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 13:59:54,729 - INFO - Memory usage at start_fit: CPU 2709.4 MB, GPU 104.1 MB
2024-12-29 13:59:54,729 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 13:59:54,731 - INFO - Number of unique classes: 10
2024-12-29 13:59:54,802 - INFO - Fitted scaler and transformed data
2024-12-29 13:59:54,803 - INFO - Scaling time: 0.07s
2024-12-29 13:59:55,181 - INFO - Epoch 1/500, Train Loss: 0.7890, Val Loss: 0.1938
2024-12-29 13:59:55,502 - INFO - Epoch 2/500, Train Loss: 0.1172, Val Loss: 0.1609
2024-12-29 13:59:55,831 - INFO - Epoch 3/500, Train Loss: 0.0848, Val Loss: 0.1448
2024-12-29 13:59:56,217 - INFO - Epoch 4/500, Train Loss: 0.0681, Val Loss: 0.1368
2024-12-29 13:59:56,592 - INFO - Epoch 5/500, Train Loss: 0.0582, Val Loss: 0.1321
2024-12-29 13:59:56,975 - INFO - Epoch 6/500, Train Loss: 0.0503, Val Loss: 0.1293
2024-12-29 13:59:57,319 - INFO - Epoch 7/500, Train Loss: 0.0451, Val Loss: 0.1298
2024-12-29 13:59:57,714 - INFO - Epoch 8/500, Train Loss: 0.0410, Val Loss: 0.1281
2024-12-29 13:59:58,069 - INFO - Epoch 9/500, Train Loss: 0.0377, Val Loss: 0.1338
2024-12-29 13:59:58,425 - INFO - Epoch 10/500, Train Loss: 0.0351, Val Loss: 0.1329
2024-12-29 13:59:58,815 - INFO - Epoch 11/500, Train Loss: 0.0332, Val Loss: 0.1345
2024-12-29 13:59:59,224 - INFO - Epoch 12/500, Train Loss: 0.0318, Val Loss: 0.1365
2024-12-29 13:59:59,630 - INFO - Epoch 13/500, Train Loss: 0.0294, Val Loss: 0.1389
2024-12-29 13:59:59,630 - INFO - Early stopping triggered at epoch 13
2024-12-29 13:59:59,630 - INFO - Training completed in 4.90s
2024-12-29 13:59:59,631 - INFO - Final memory usage: CPU 2718.2 MB, GPU 104.2 MB
2024-12-29 13:59:59,631 - INFO - Model training completed in 4.90s
2024-12-29 13:59:59,677 - INFO - Prediction completed in 0.05s
2024-12-29 13:59:59,686 - INFO - Poison rate 0.01 completed in 9.41s
2024-12-29 13:59:59,686 - INFO - 
Processing poison rate: 0.03
2024-12-29 13:59:59,687 - INFO - Label flipping details:
2024-12-29 13:59:59,687 - INFO - - Source class: 1
2024-12-29 13:59:59,687 - INFO - - Target class: 0
2024-12-29 13:59:59,687 - INFO - - Available samples in source class: 955
2024-12-29 13:59:59,687 - INFO - - Requested samples to poison: 284
2024-12-29 13:59:59,687 - INFO - - Actual samples to flip: 284
2024-12-29 13:59:59,687 - INFO - - Samples remaining in source class: 671
2024-12-29 13:59:59,687 - INFO - Successfully flipped 284 labels from class 1 to 0
2024-12-29 13:59:59,687 - INFO - Total number of labels flipped: 284
2024-12-29 13:59:59,688 - INFO - Label flipping completed in 0.00s
2024-12-29 13:59:59,688 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 13:59:59,688 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:00:00,208 - INFO - Feature scaling completed in 0.52s
2024-12-29 14:00:00,208 - INFO - Starting feature selection (k=50)
2024-12-29 14:00:00,223 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:00:00,223 - INFO - Starting anomaly detection
2024-12-29 14:00:03,970 - INFO - Anomaly detection completed in 3.75s
2024-12-29 14:00:03,970 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:00:03,970 - INFO - Total fit_transform time: 4.28s
2024-12-29 14:00:03,971 - INFO - Training set processing completed in 4.28s
2024-12-29 14:00:03,971 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:00:03,971 - INFO - Memory usage at start_fit: CPU 2708.9 MB, GPU 104.1 MB
2024-12-29 14:00:03,971 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:00:03,974 - INFO - Number of unique classes: 10
2024-12-29 14:00:04,045 - INFO - Fitted scaler and transformed data
2024-12-29 14:00:04,045 - INFO - Scaling time: 0.07s
2024-12-29 14:00:04,419 - INFO - Epoch 1/500, Train Loss: 0.8887, Val Loss: 0.2323
2024-12-29 14:00:04,794 - INFO - Epoch 2/500, Train Loss: 0.1641, Val Loss: 0.1916
2024-12-29 14:00:05,208 - INFO - Epoch 3/500, Train Loss: 0.1291, Val Loss: 0.1795
2024-12-29 14:00:05,575 - INFO - Epoch 4/500, Train Loss: 0.1106, Val Loss: 0.1732
2024-12-29 14:00:05,941 - INFO - Epoch 5/500, Train Loss: 0.0982, Val Loss: 0.1695
2024-12-29 14:00:06,325 - INFO - Epoch 6/500, Train Loss: 0.0909, Val Loss: 0.1660
2024-12-29 14:00:06,667 - INFO - Epoch 7/500, Train Loss: 0.0841, Val Loss: 0.1627
2024-12-29 14:00:07,068 - INFO - Epoch 8/500, Train Loss: 0.0793, Val Loss: 0.1633
2024-12-29 14:00:07,440 - INFO - Epoch 9/500, Train Loss: 0.0745, Val Loss: 0.1615
2024-12-29 14:00:07,856 - INFO - Epoch 10/500, Train Loss: 0.0728, Val Loss: 0.1619
2024-12-29 14:00:08,185 - INFO - Epoch 11/500, Train Loss: 0.0699, Val Loss: 0.1611
2024-12-29 14:00:08,514 - INFO - Epoch 12/500, Train Loss: 0.0667, Val Loss: 0.1647
2024-12-29 14:00:08,855 - INFO - Epoch 13/500, Train Loss: 0.0664, Val Loss: 0.1636
2024-12-29 14:00:09,182 - INFO - Epoch 14/500, Train Loss: 0.0654, Val Loss: 0.1605
2024-12-29 14:00:09,183 - INFO - Early stopping triggered at epoch 14
2024-12-29 14:00:09,183 - INFO - Training completed in 5.21s
2024-12-29 14:00:09,184 - INFO - Final memory usage: CPU 2718.2 MB, GPU 104.2 MB
2024-12-29 14:00:09,186 - INFO - Model training completed in 5.22s
2024-12-29 14:00:09,259 - INFO - Prediction completed in 0.07s
2024-12-29 14:00:09,267 - INFO - Poison rate 0.03 completed in 9.58s
2024-12-29 14:00:09,268 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:00:09,268 - INFO - Label flipping details:
2024-12-29 14:00:09,268 - INFO - - Source class: 1
2024-12-29 14:00:09,268 - INFO - - Target class: 0
2024-12-29 14:00:09,268 - INFO - - Available samples in source class: 955
2024-12-29 14:00:09,268 - INFO - - Requested samples to poison: 473
2024-12-29 14:00:09,269 - INFO - - Actual samples to flip: 473
2024-12-29 14:00:09,269 - INFO - - Samples remaining in source class: 482
2024-12-29 14:00:09,269 - INFO - Successfully flipped 473 labels from class 1 to 0
2024-12-29 14:00:09,269 - INFO - Total number of labels flipped: 473
2024-12-29 14:00:09,269 - INFO - Label flipping completed in 0.00s
2024-12-29 14:00:09,269 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:00:09,269 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:00:09,791 - INFO - Feature scaling completed in 0.52s
2024-12-29 14:00:09,791 - INFO - Starting feature selection (k=50)
2024-12-29 14:00:09,805 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:00:09,805 - INFO - Starting anomaly detection
2024-12-29 14:00:13,608 - INFO - Anomaly detection completed in 3.80s
2024-12-29 14:00:13,608 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:00:13,608 - INFO - Total fit_transform time: 4.34s
2024-12-29 14:00:13,608 - INFO - Training set processing completed in 4.34s
2024-12-29 14:00:13,608 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:00:13,609 - INFO - Memory usage at start_fit: CPU 2708.9 MB, GPU 104.1 MB
2024-12-29 14:00:13,610 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:00:13,612 - INFO - Number of unique classes: 10
2024-12-29 14:00:13,681 - INFO - Fitted scaler and transformed data
2024-12-29 14:00:13,682 - INFO - Scaling time: 0.07s
2024-12-29 14:00:14,040 - INFO - Epoch 1/500, Train Loss: 0.8958, Val Loss: 0.2182
2024-12-29 14:00:14,348 - INFO - Epoch 2/500, Train Loss: 0.1853, Val Loss: 0.1847
2024-12-29 14:00:14,651 - INFO - Epoch 3/500, Train Loss: 0.1525, Val Loss: 0.1705
2024-12-29 14:00:14,959 - INFO - Epoch 4/500, Train Loss: 0.1339, Val Loss: 0.1594
2024-12-29 14:00:15,259 - INFO - Epoch 5/500, Train Loss: 0.1217, Val Loss: 0.1553
2024-12-29 14:00:15,576 - INFO - Epoch 6/500, Train Loss: 0.1119, Val Loss: 0.1531
2024-12-29 14:00:15,970 - INFO - Epoch 7/500, Train Loss: 0.1040, Val Loss: 0.1493
2024-12-29 14:00:16,310 - INFO - Epoch 8/500, Train Loss: 0.0991, Val Loss: 0.1459
2024-12-29 14:00:16,748 - INFO - Epoch 9/500, Train Loss: 0.0941, Val Loss: 0.1465
2024-12-29 14:00:17,093 - INFO - Epoch 10/500, Train Loss: 0.0911, Val Loss: 0.1470
2024-12-29 14:00:17,446 - INFO - Epoch 11/500, Train Loss: 0.0870, Val Loss: 0.1508
2024-12-29 14:00:17,774 - INFO - Epoch 12/500, Train Loss: 0.0846, Val Loss: 0.1490
2024-12-29 14:00:18,114 - INFO - Epoch 13/500, Train Loss: 0.0832, Val Loss: 0.1509
2024-12-29 14:00:18,115 - INFO - Early stopping triggered at epoch 13
2024-12-29 14:00:18,115 - INFO - Training completed in 4.51s
2024-12-29 14:00:18,115 - INFO - Final memory usage: CPU 2718.2 MB, GPU 104.2 MB
2024-12-29 14:00:18,116 - INFO - Model training completed in 4.51s
2024-12-29 14:00:18,180 - INFO - Prediction completed in 0.06s
2024-12-29 14:00:18,191 - INFO - Poison rate 0.05 completed in 8.92s
2024-12-29 14:00:18,191 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:00:18,192 - INFO - Label flipping details:
2024-12-29 14:00:18,192 - INFO - - Source class: 1
2024-12-29 14:00:18,192 - INFO - - Target class: 0
2024-12-29 14:00:18,192 - INFO - - Available samples in source class: 955
2024-12-29 14:00:18,192 - INFO - - Requested samples to poison: 662
2024-12-29 14:00:18,192 - INFO - - Actual samples to flip: 662
2024-12-29 14:00:18,192 - INFO - - Samples remaining in source class: 293
2024-12-29 14:00:18,192 - INFO - Successfully flipped 662 labels from class 1 to 0
2024-12-29 14:00:18,192 - INFO - Total number of labels flipped: 662
2024-12-29 14:00:18,193 - INFO - Label flipping completed in 0.00s
2024-12-29 14:00:18,193 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:00:18,193 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:00:18,714 - INFO - Feature scaling completed in 0.52s
2024-12-29 14:00:18,714 - INFO - Starting feature selection (k=50)
2024-12-29 14:00:18,733 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 14:00:18,733 - INFO - Starting anomaly detection
2024-12-29 14:00:22,981 - INFO - Anomaly detection completed in 4.25s
2024-12-29 14:00:22,981 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:00:22,982 - INFO - Total fit_transform time: 4.79s
2024-12-29 14:00:22,982 - INFO - Training set processing completed in 4.79s
2024-12-29 14:00:22,982 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:00:22,983 - INFO - Memory usage at start_fit: CPU 2708.9 MB, GPU 104.1 MB
2024-12-29 14:00:22,983 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:00:22,985 - INFO - Number of unique classes: 10
2024-12-29 14:00:23,058 - INFO - Fitted scaler and transformed data
2024-12-29 14:00:23,058 - INFO - Scaling time: 0.07s
2024-12-29 14:00:23,425 - INFO - Epoch 1/500, Train Loss: 0.9108, Val Loss: 0.1799
2024-12-29 14:00:23,800 - INFO - Epoch 2/500, Train Loss: 0.1604, Val Loss: 0.1540
2024-12-29 14:00:24,133 - INFO - Epoch 3/500, Train Loss: 0.1276, Val Loss: 0.1451
2024-12-29 14:00:24,510 - INFO - Epoch 4/500, Train Loss: 0.1083, Val Loss: 0.1460
2024-12-29 14:00:24,887 - INFO - Epoch 5/500, Train Loss: 0.0962, Val Loss: 0.1411
2024-12-29 14:00:25,253 - INFO - Epoch 6/500, Train Loss: 0.0884, Val Loss: 0.1429
2024-12-29 14:00:25,651 - INFO - Epoch 7/500, Train Loss: 0.0819, Val Loss: 0.1449
2024-12-29 14:00:26,023 - INFO - Epoch 8/500, Train Loss: 0.0778, Val Loss: 0.1473
2024-12-29 14:00:26,436 - INFO - Epoch 9/500, Train Loss: 0.0756, Val Loss: 0.1512
2024-12-29 14:00:26,846 - INFO - Epoch 10/500, Train Loss: 0.0716, Val Loss: 0.1491
2024-12-29 14:00:26,846 - INFO - Early stopping triggered at epoch 10
2024-12-29 14:00:26,847 - INFO - Training completed in 3.86s
2024-12-29 14:00:26,847 - INFO - Final memory usage: CPU 2718.4 MB, GPU 104.2 MB
2024-12-29 14:00:26,848 - INFO - Model training completed in 3.87s
2024-12-29 14:00:26,894 - INFO - Prediction completed in 0.05s
2024-12-29 14:00:26,903 - INFO - Poison rate 0.07 completed in 8.71s
2024-12-29 14:00:26,903 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:00:26,904 - INFO - Label flipping details:
2024-12-29 14:00:26,904 - INFO - - Source class: 1
2024-12-29 14:00:26,904 - INFO - - Target class: 0
2024-12-29 14:00:26,904 - INFO - - Available samples in source class: 955
2024-12-29 14:00:26,904 - INFO - - Requested samples to poison: 946
2024-12-29 14:00:26,904 - INFO - - Actual samples to flip: 946
2024-12-29 14:00:26,904 - INFO - - Samples remaining in source class: 9
2024-12-29 14:00:26,904 - INFO - Successfully flipped 946 labels from class 1 to 0
2024-12-29 14:00:26,904 - INFO - Total number of labels flipped: 946
2024-12-29 14:00:26,905 - INFO - Label flipping completed in 0.00s
2024-12-29 14:00:26,905 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:00:26,905 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:00:27,441 - INFO - Feature scaling completed in 0.54s
2024-12-29 14:00:27,441 - INFO - Starting feature selection (k=50)
2024-12-29 14:00:27,456 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:00:27,457 - INFO - Starting anomaly detection
2024-12-29 14:00:31,583 - INFO - Anomaly detection completed in 4.13s
2024-12-29 14:00:31,583 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:00:31,583 - INFO - Total fit_transform time: 4.68s
2024-12-29 14:00:31,584 - INFO - Training set processing completed in 4.68s
2024-12-29 14:00:31,584 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:00:31,585 - INFO - Memory usage at start_fit: CPU 2708.9 MB, GPU 104.1 MB
2024-12-29 14:00:31,586 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:00:31,588 - INFO - Number of unique classes: 10
2024-12-29 14:00:31,668 - INFO - Fitted scaler and transformed data
2024-12-29 14:00:31,668 - INFO - Scaling time: 0.08s
2024-12-29 14:00:32,058 - INFO - Epoch 1/500, Train Loss: 1.0015, Val Loss: 0.1754
2024-12-29 14:00:32,385 - INFO - Epoch 2/500, Train Loss: 0.1030, Val Loss: 0.1484
2024-12-29 14:00:32,756 - INFO - Epoch 3/500, Train Loss: 0.0684, Val Loss: 0.1315
2024-12-29 14:00:33,095 - INFO - Epoch 4/500, Train Loss: 0.0496, Val Loss: 0.1259
2024-12-29 14:00:33,450 - INFO - Epoch 5/500, Train Loss: 0.0391, Val Loss: 0.1185
2024-12-29 14:00:33,796 - INFO - Epoch 6/500, Train Loss: 0.0314, Val Loss: 0.1189
2024-12-29 14:00:34,158 - INFO - Epoch 7/500, Train Loss: 0.0260, Val Loss: 0.1141
2024-12-29 14:00:34,485 - INFO - Epoch 8/500, Train Loss: 0.0223, Val Loss: 0.1149
2024-12-29 14:00:34,824 - INFO - Epoch 9/500, Train Loss: 0.0190, Val Loss: 0.1195
2024-12-29 14:00:35,194 - INFO - Epoch 10/500, Train Loss: 0.0170, Val Loss: 0.1171
2024-12-29 14:00:35,594 - INFO - Epoch 11/500, Train Loss: 0.0146, Val Loss: 0.1172
2024-12-29 14:00:35,944 - INFO - Epoch 12/500, Train Loss: 0.0129, Val Loss: 0.1174
2024-12-29 14:00:35,945 - INFO - Early stopping triggered at epoch 12
2024-12-29 14:00:35,945 - INFO - Training completed in 4.36s
2024-12-29 14:00:35,945 - INFO - Final memory usage: CPU 2718.4 MB, GPU 104.2 MB
2024-12-29 14:00:35,946 - INFO - Model training completed in 4.36s
2024-12-29 14:00:36,014 - INFO - Prediction completed in 0.07s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 14:00:36,024 - INFO - Poison rate 0.1 completed in 9.12s
2024-12-29 14:00:36,024 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:00:36,025 - INFO - Label flipping details:
2024-12-29 14:00:36,025 - INFO - - Source class: 1
2024-12-29 14:00:36,025 - INFO - - Target class: 0
2024-12-29 14:00:36,025 - INFO - - Available samples in source class: 955
2024-12-29 14:00:36,025 - INFO - - Requested samples to poison: 1893
2024-12-29 14:00:36,025 - INFO - - Actual samples to flip: 954
2024-12-29 14:00:36,025 - INFO - - Samples remaining in source class: 1
2024-12-29 14:00:36,025 - INFO - Successfully flipped 954 labels from class 1 to 0
2024-12-29 14:00:36,025 - INFO - Total number of labels flipped: 954
2024-12-29 14:00:36,025 - INFO - Label flipping completed in 0.00s
2024-12-29 14:00:36,026 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:00:36,026 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:00:36,597 - INFO - Feature scaling completed in 0.57s
2024-12-29 14:00:36,597 - INFO - Starting feature selection (k=50)
2024-12-29 14:00:36,612 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 14:00:36,612 - INFO - Starting anomaly detection
2024-12-29 14:00:39,458 - INFO - Anomaly detection completed in 2.85s
2024-12-29 14:00:39,459 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:00:39,459 - INFO - Total fit_transform time: 3.43s
2024-12-29 14:00:39,459 - INFO - Training set processing completed in 3.43s
2024-12-29 14:00:39,459 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:00:39,461 - INFO - Memory usage at start_fit: CPU 2709.0 MB, GPU 104.1 MB
2024-12-29 14:00:39,461 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:00:39,464 - INFO - Number of unique classes: 10
2024-12-29 14:00:39,552 - INFO - Fitted scaler and transformed data
2024-12-29 14:00:39,552 - INFO - Scaling time: 0.09s
2024-12-29 14:00:39,898 - INFO - Epoch 1/500, Train Loss: 0.9259, Val Loss: 0.1012
2024-12-29 14:00:40,215 - INFO - Epoch 2/500, Train Loss: 0.1015, Val Loss: 0.0724
2024-12-29 14:00:40,592 - INFO - Epoch 3/500, Train Loss: 0.0664, Val Loss: 0.0638
2024-12-29 14:00:40,989 - INFO - Epoch 4/500, Train Loss: 0.0484, Val Loss: 0.0609
2024-12-29 14:00:41,346 - INFO - Epoch 5/500, Train Loss: 0.0373, Val Loss: 0.0595
2024-12-29 14:00:41,708 - INFO - Epoch 6/500, Train Loss: 0.0299, Val Loss: 0.0576
2024-12-29 14:00:42,022 - INFO - Epoch 7/500, Train Loss: 0.0244, Val Loss: 0.0592
2024-12-29 14:00:42,388 - INFO - Epoch 8/500, Train Loss: 0.0203, Val Loss: 0.0586
2024-12-29 14:00:42,742 - INFO - Epoch 9/500, Train Loss: 0.0170, Val Loss: 0.0605
2024-12-29 14:00:43,068 - INFO - Epoch 10/500, Train Loss: 0.0148, Val Loss: 0.0617
2024-12-29 14:00:43,412 - INFO - Epoch 11/500, Train Loss: 0.0128, Val Loss: 0.0628
2024-12-29 14:00:43,413 - INFO - Early stopping triggered at epoch 11
2024-12-29 14:00:43,413 - INFO - Training completed in 3.95s
2024-12-29 14:00:43,413 - INFO - Final memory usage: CPU 2718.4 MB, GPU 104.2 MB
2024-12-29 14:00:43,414 - INFO - Model training completed in 3.96s
2024-12-29 14:00:43,460 - INFO - Prediction completed in 0.05s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 14:00:43,470 - INFO - Poison rate 0.2 completed in 7.45s
2024-12-29 14:00:43,476 - INFO - Loaded 343 existing results
2024-12-29 14:00:43,477 - INFO - Total results to save: 350
2024-12-29 14:00:43,478 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:00:43,490 - INFO - Saved 350 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:00:43,490 - INFO - Total evaluation time: 93.25s
2024-12-29 14:00:43,492 - INFO - 
Progress: 53.1% - Evaluating ImageNette with LogisticRegression (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:00:43,701 - INFO - Loading datasets...
2024-12-29 14:00:43,722 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:00:43,723 - INFO - Extracting validation features...
2024-12-29 14:00:43,723 - INFO - Extracting features from 3925 samples...
2024-12-29 14:00:53,066 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:00:53,069 - INFO - Validation feature extraction completed in 9.35s
2024-12-29 14:00:53,069 - INFO - Extracting training features...
2024-12-29 14:00:53,069 - INFO - Extracting features from 9469 samples...
2024-12-29 14:01:14,881 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:01:14,888 - INFO - Training feature extraction completed in 21.82s
2024-12-29 14:01:14,888 - INFO - Creating model for classifier: LogisticRegression
2024-12-29 14:01:14,889 - INFO - Using device: cuda
2024-12-29 14:01:14,889 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:01:14,889 - INFO - Training set processing completed in 0.00s
2024-12-29 14:01:14,889 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:01:14,891 - INFO - Memory usage at start_fit: CPU 2685.3 MB, GPU 104.6 MB
2024-12-29 14:01:14,891 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:01:14,896 - INFO - Number of unique classes: 10
2024-12-29 14:01:14,970 - INFO - Fitted scaler and transformed data
2024-12-29 14:01:14,970 - INFO - Scaling time: 0.07s
2024-12-29 14:01:15,192 - INFO - Epoch 1/1000, Train Loss: 0.5458, Val Loss: 0.1166
2024-12-29 14:01:15,393 - INFO - Epoch 2/1000, Train Loss: 0.1002, Val Loss: 0.0786
2024-12-29 14:01:15,590 - INFO - Epoch 3/1000, Train Loss: 0.0716, Val Loss: 0.0642
2024-12-29 14:01:15,791 - INFO - Epoch 4/1000, Train Loss: 0.0577, Val Loss: 0.0575
2024-12-29 14:01:15,987 - INFO - Epoch 5/1000, Train Loss: 0.0492, Val Loss: 0.0528
2024-12-29 14:01:16,179 - INFO - Epoch 6/1000, Train Loss: 0.0439, Val Loss: 0.0500
2024-12-29 14:01:16,382 - INFO - Epoch 7/1000, Train Loss: 0.0405, Val Loss: 0.0482
2024-12-29 14:01:16,592 - INFO - Epoch 8/1000, Train Loss: 0.0375, Val Loss: 0.0471
2024-12-29 14:01:16,787 - INFO - Epoch 9/1000, Train Loss: 0.0356, Val Loss: 0.0465
2024-12-29 14:01:17,014 - INFO - Epoch 10/1000, Train Loss: 0.0340, Val Loss: 0.0455
2024-12-29 14:01:17,199 - INFO - Epoch 11/1000, Train Loss: 0.0330, Val Loss: 0.0454
2024-12-29 14:01:17,391 - INFO - Epoch 12/1000, Train Loss: 0.0321, Val Loss: 0.0454
2024-12-29 14:01:17,596 - INFO - Epoch 13/1000, Train Loss: 0.0313, Val Loss: 0.0447
2024-12-29 14:01:17,809 - INFO - Epoch 14/1000, Train Loss: 0.0306, Val Loss: 0.0441
2024-12-29 14:01:18,019 - INFO - Epoch 15/1000, Train Loss: 0.0302, Val Loss: 0.0440
2024-12-29 14:01:18,294 - INFO - Epoch 16/1000, Train Loss: 0.0299, Val Loss: 0.0434
2024-12-29 14:01:18,535 - INFO - Epoch 17/1000, Train Loss: 0.0297, Val Loss: 0.0442
2024-12-29 14:01:18,907 - INFO - Epoch 18/1000, Train Loss: 0.0293, Val Loss: 0.0435
2024-12-29 14:01:19,207 - INFO - Epoch 19/1000, Train Loss: 0.0295, Val Loss: 0.0432
2024-12-29 14:01:19,208 - INFO - Early stopping triggered at epoch 19
2024-12-29 14:01:19,208 - INFO - Training completed in 4.32s
2024-12-29 14:01:19,209 - INFO - Final memory usage: CPU 2722.2 MB, GPU 104.8 MB
2024-12-29 14:01:19,210 - INFO - Model training completed in 4.32s
2024-12-29 14:01:19,287 - INFO - Prediction completed in 0.08s
2024-12-29 14:01:19,296 - INFO - Poison rate 0.0 completed in 4.41s
2024-12-29 14:01:19,297 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:01:19,297 - INFO - Label flipping details:
2024-12-29 14:01:19,297 - INFO - - Source class: 1
2024-12-29 14:01:19,297 - INFO - - Target class: 0
2024-12-29 14:01:19,297 - INFO - - Available samples in source class: 955
2024-12-29 14:01:19,298 - INFO - - Requested samples to poison: 94
2024-12-29 14:01:19,298 - INFO - - Actual samples to flip: 94
2024-12-29 14:01:19,298 - INFO - - Samples remaining in source class: 861
2024-12-29 14:01:19,298 - INFO - Successfully flipped 94 labels from class 1 to 0
2024-12-29 14:01:19,298 - INFO - Total number of labels flipped: 94
2024-12-29 14:01:19,298 - INFO - Label flipping completed in 0.00s
2024-12-29 14:01:19,298 - INFO - Training set processing completed in 0.00s
2024-12-29 14:01:19,298 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:01:19,299 - INFO - Memory usage at start_fit: CPU 2693.0 MB, GPU 104.7 MB
2024-12-29 14:01:19,299 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:01:19,303 - INFO - Number of unique classes: 10
2024-12-29 14:01:19,386 - INFO - Fitted scaler and transformed data
2024-12-29 14:01:19,386 - INFO - Scaling time: 0.08s
2024-12-29 14:01:19,623 - INFO - Epoch 1/1000, Train Loss: 0.5477, Val Loss: 0.1797
2024-12-29 14:01:19,877 - INFO - Epoch 2/1000, Train Loss: 0.1358, Val Loss: 0.1330
2024-12-29 14:01:20,137 - INFO - Epoch 3/1000, Train Loss: 0.1059, Val Loss: 0.1163
2024-12-29 14:01:20,349 - INFO - Epoch 4/1000, Train Loss: 0.0911, Val Loss: 0.1088
2024-12-29 14:01:20,567 - INFO - Epoch 5/1000, Train Loss: 0.0820, Val Loss: 0.1043
2024-12-29 14:01:20,761 - INFO - Epoch 6/1000, Train Loss: 0.0762, Val Loss: 0.1019
2024-12-29 14:01:20,965 - INFO - Epoch 7/1000, Train Loss: 0.0717, Val Loss: 0.0996
2024-12-29 14:01:21,163 - INFO - Epoch 8/1000, Train Loss: 0.0683, Val Loss: 0.0989
2024-12-29 14:01:21,361 - INFO - Epoch 9/1000, Train Loss: 0.0661, Val Loss: 0.0971
2024-12-29 14:01:21,566 - INFO - Epoch 10/1000, Train Loss: 0.0640, Val Loss: 0.0983
2024-12-29 14:01:21,773 - INFO - Epoch 11/1000, Train Loss: 0.0626, Val Loss: 0.0971
2024-12-29 14:01:21,987 - INFO - Epoch 12/1000, Train Loss: 0.0613, Val Loss: 0.0968
2024-12-29 14:01:22,184 - INFO - Epoch 13/1000, Train Loss: 0.0604, Val Loss: 0.0966
2024-12-29 14:01:22,400 - INFO - Epoch 14/1000, Train Loss: 0.0593, Val Loss: 0.0973
2024-12-29 14:01:22,401 - INFO - Early stopping triggered at epoch 14
2024-12-29 14:01:22,401 - INFO - Training completed in 3.10s
2024-12-29 14:01:22,402 - INFO - Final memory usage: CPU 2722.2 MB, GPU 104.8 MB
2024-12-29 14:01:22,403 - INFO - Model training completed in 3.11s
2024-12-29 14:01:22,476 - INFO - Prediction completed in 0.07s
2024-12-29 14:01:22,485 - INFO - Poison rate 0.01 completed in 3.19s
2024-12-29 14:01:22,485 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:01:22,486 - INFO - Label flipping details:
2024-12-29 14:01:22,486 - INFO - - Source class: 1
2024-12-29 14:01:22,486 - INFO - - Target class: 0
2024-12-29 14:01:22,486 - INFO - - Available samples in source class: 955
2024-12-29 14:01:22,486 - INFO - - Requested samples to poison: 284
2024-12-29 14:01:22,486 - INFO - - Actual samples to flip: 284
2024-12-29 14:01:22,486 - INFO - - Samples remaining in source class: 671
2024-12-29 14:01:22,486 - INFO - Successfully flipped 284 labels from class 1 to 0
2024-12-29 14:01:22,486 - INFO - Total number of labels flipped: 284
2024-12-29 14:01:22,486 - INFO - Label flipping completed in 0.00s
2024-12-29 14:01:22,487 - INFO - Training set processing completed in 0.00s
2024-12-29 14:01:22,487 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:01:22,487 - INFO - Memory usage at start_fit: CPU 2692.6 MB, GPU 104.7 MB
2024-12-29 14:01:22,488 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:01:22,492 - INFO - Number of unique classes: 10
2024-12-29 14:01:22,564 - INFO - Fitted scaler and transformed data
2024-12-29 14:01:22,565 - INFO - Scaling time: 0.07s
2024-12-29 14:01:22,771 - INFO - Epoch 1/1000, Train Loss: 0.5480, Val Loss: 0.2245
2024-12-29 14:01:22,967 - INFO - Epoch 2/1000, Train Loss: 0.1610, Val Loss: 0.1762
2024-12-29 14:01:23,161 - INFO - Epoch 3/1000, Train Loss: 0.1319, Val Loss: 0.1575
2024-12-29 14:01:23,354 - INFO - Epoch 4/1000, Train Loss: 0.1169, Val Loss: 0.1560
2024-12-29 14:01:23,548 - INFO - Epoch 5/1000, Train Loss: 0.1086, Val Loss: 0.1433
2024-12-29 14:01:23,763 - INFO - Epoch 6/1000, Train Loss: 0.1010, Val Loss: 0.1435
2024-12-29 14:01:23,978 - INFO - Epoch 7/1000, Train Loss: 0.0963, Val Loss: 0.1407
2024-12-29 14:01:24,176 - INFO - Epoch 8/1000, Train Loss: 0.0930, Val Loss: 0.1442
2024-12-29 14:01:24,387 - INFO - Epoch 9/1000, Train Loss: 0.0913, Val Loss: 0.1412
2024-12-29 14:01:24,621 - INFO - Epoch 10/1000, Train Loss: 0.0886, Val Loss: 0.1374
2024-12-29 14:01:24,829 - INFO - Epoch 11/1000, Train Loss: 0.0863, Val Loss: 0.1379
2024-12-29 14:01:25,027 - INFO - Epoch 12/1000, Train Loss: 0.0864, Val Loss: 0.1383
2024-12-29 14:01:25,260 - INFO - Epoch 13/1000, Train Loss: 0.0853, Val Loss: 0.1462
2024-12-29 14:01:25,484 - INFO - Epoch 14/1000, Train Loss: 0.0838, Val Loss: 0.1364
2024-12-29 14:01:25,704 - INFO - Epoch 15/1000, Train Loss: 0.0828, Val Loss: 0.1355
2024-12-29 14:01:25,911 - INFO - Epoch 16/1000, Train Loss: 0.0819, Val Loss: 0.1359
2024-12-29 14:01:26,125 - INFO - Epoch 17/1000, Train Loss: 0.0828, Val Loss: 0.1340
2024-12-29 14:01:26,333 - INFO - Epoch 18/1000, Train Loss: 0.0814, Val Loss: 0.1377
2024-12-29 14:01:26,549 - INFO - Epoch 19/1000, Train Loss: 0.0815, Val Loss: 0.1448
2024-12-29 14:01:26,746 - INFO - Epoch 20/1000, Train Loss: 0.0805, Val Loss: 0.1371
2024-12-29 14:01:26,972 - INFO - Epoch 21/1000, Train Loss: 0.0793, Val Loss: 0.1394
2024-12-29 14:01:27,199 - INFO - Epoch 22/1000, Train Loss: 0.0798, Val Loss: 0.1427
2024-12-29 14:01:27,199 - INFO - Early stopping triggered at epoch 22
2024-12-29 14:01:27,200 - INFO - Training completed in 4.71s
2024-12-29 14:01:27,200 - INFO - Final memory usage: CPU 2722.0 MB, GPU 104.8 MB
2024-12-29 14:01:27,202 - INFO - Model training completed in 4.71s
2024-12-29 14:01:27,249 - INFO - Prediction completed in 0.05s
2024-12-29 14:01:27,257 - INFO - Poison rate 0.03 completed in 4.77s
2024-12-29 14:01:27,257 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:01:27,258 - INFO - Label flipping details:
2024-12-29 14:01:27,258 - INFO - - Source class: 1
2024-12-29 14:01:27,258 - INFO - - Target class: 0
2024-12-29 14:01:27,258 - INFO - - Available samples in source class: 955
2024-12-29 14:01:27,258 - INFO - - Requested samples to poison: 473
2024-12-29 14:01:27,258 - INFO - - Actual samples to flip: 473
2024-12-29 14:01:27,258 - INFO - - Samples remaining in source class: 482
2024-12-29 14:01:27,258 - INFO - Successfully flipped 473 labels from class 1 to 0
2024-12-29 14:01:27,258 - INFO - Total number of labels flipped: 473
2024-12-29 14:01:27,258 - INFO - Label flipping completed in 0.00s
2024-12-29 14:01:27,259 - INFO - Training set processing completed in 0.00s
2024-12-29 14:01:27,259 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:01:27,259 - INFO - Memory usage at start_fit: CPU 2692.7 MB, GPU 104.7 MB
2024-12-29 14:01:27,260 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:01:27,263 - INFO - Number of unique classes: 10
2024-12-29 14:01:27,336 - INFO - Fitted scaler and transformed data
2024-12-29 14:01:27,336 - INFO - Scaling time: 0.07s
2024-12-29 14:01:27,610 - INFO - Epoch 1/1000, Train Loss: 0.5633, Val Loss: 0.2046
2024-12-29 14:01:27,828 - INFO - Epoch 2/1000, Train Loss: 0.1695, Val Loss: 0.1624
2024-12-29 14:01:28,025 - INFO - Epoch 3/1000, Train Loss: 0.1397, Val Loss: 0.1487
2024-12-29 14:01:28,209 - INFO - Epoch 4/1000, Train Loss: 0.1252, Val Loss: 0.1400
2024-12-29 14:01:28,419 - INFO - Epoch 5/1000, Train Loss: 0.1152, Val Loss: 0.1360
2024-12-29 14:01:28,632 - INFO - Epoch 6/1000, Train Loss: 0.1094, Val Loss: 0.1349
2024-12-29 14:01:28,856 - INFO - Epoch 7/1000, Train Loss: 0.1063, Val Loss: 0.1326
2024-12-29 14:01:29,060 - INFO - Epoch 8/1000, Train Loss: 0.1018, Val Loss: 0.1289
2024-12-29 14:01:29,253 - INFO - Epoch 9/1000, Train Loss: 0.0990, Val Loss: 0.1283
2024-12-29 14:01:29,468 - INFO - Epoch 10/1000, Train Loss: 0.0969, Val Loss: 0.1270
2024-12-29 14:01:29,702 - INFO - Epoch 11/1000, Train Loss: 0.0954, Val Loss: 0.1268
2024-12-29 14:01:29,955 - INFO - Epoch 12/1000, Train Loss: 0.0933, Val Loss: 0.1265
2024-12-29 14:01:30,154 - INFO - Epoch 13/1000, Train Loss: 0.0924, Val Loss: 0.1285
2024-12-29 14:01:30,364 - INFO - Epoch 14/1000, Train Loss: 0.0923, Val Loss: 0.1281
2024-12-29 14:01:30,597 - INFO - Epoch 15/1000, Train Loss: 0.0912, Val Loss: 0.1257
2024-12-29 14:01:30,820 - INFO - Epoch 16/1000, Train Loss: 0.0911, Val Loss: 0.1297
2024-12-29 14:01:31,041 - INFO - Epoch 17/1000, Train Loss: 0.0897, Val Loss: 0.1255
2024-12-29 14:01:31,292 - INFO - Epoch 18/1000, Train Loss: 0.0902, Val Loss: 0.1277
2024-12-29 14:01:31,494 - INFO - Epoch 19/1000, Train Loss: 0.0889, Val Loss: 0.1259
2024-12-29 14:01:31,708 - INFO - Epoch 20/1000, Train Loss: 0.0890, Val Loss: 0.1256
2024-12-29 14:01:31,708 - INFO - Early stopping triggered at epoch 20
2024-12-29 14:01:31,708 - INFO - Training completed in 4.45s
2024-12-29 14:01:31,709 - INFO - Final memory usage: CPU 2722.1 MB, GPU 104.8 MB
2024-12-29 14:01:31,709 - INFO - Model training completed in 4.45s
2024-12-29 14:01:31,772 - INFO - Prediction completed in 0.06s
2024-12-29 14:01:31,780 - INFO - Poison rate 0.05 completed in 4.52s
2024-12-29 14:01:31,780 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:01:31,781 - INFO - Label flipping details:
2024-12-29 14:01:31,781 - INFO - - Source class: 1
2024-12-29 14:01:31,781 - INFO - - Target class: 0
2024-12-29 14:01:31,781 - INFO - - Available samples in source class: 955
2024-12-29 14:01:31,781 - INFO - - Requested samples to poison: 662
2024-12-29 14:01:31,781 - INFO - - Actual samples to flip: 662
2024-12-29 14:01:31,781 - INFO - - Samples remaining in source class: 293
2024-12-29 14:01:31,781 - INFO - Successfully flipped 662 labels from class 1 to 0
2024-12-29 14:01:31,782 - INFO - Total number of labels flipped: 662
2024-12-29 14:01:31,782 - INFO - Label flipping completed in 0.00s
2024-12-29 14:01:31,782 - INFO - Training set processing completed in 0.00s
2024-12-29 14:01:31,782 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:01:31,783 - INFO - Memory usage at start_fit: CPU 2692.8 MB, GPU 104.7 MB
2024-12-29 14:01:31,783 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:01:31,786 - INFO - Number of unique classes: 10
2024-12-29 14:01:31,854 - INFO - Fitted scaler and transformed data
2024-12-29 14:01:31,854 - INFO - Scaling time: 0.07s
2024-12-29 14:01:32,067 - INFO - Epoch 1/1000, Train Loss: 0.5849, Val Loss: 0.1608
2024-12-29 14:01:32,269 - INFO - Epoch 2/1000, Train Loss: 0.1672, Val Loss: 0.1260
2024-12-29 14:01:32,467 - INFO - Epoch 3/1000, Train Loss: 0.1364, Val Loss: 0.1140
2024-12-29 14:01:32,710 - INFO - Epoch 4/1000, Train Loss: 0.1205, Val Loss: 0.1061
2024-12-29 14:01:32,916 - INFO - Epoch 5/1000, Train Loss: 0.1106, Val Loss: 0.1033
2024-12-29 14:01:33,121 - INFO - Epoch 6/1000, Train Loss: 0.1042, Val Loss: 0.1036
2024-12-29 14:01:33,335 - INFO - Epoch 7/1000, Train Loss: 0.0992, Val Loss: 0.1009
2024-12-29 14:01:33,577 - INFO - Epoch 8/1000, Train Loss: 0.0965, Val Loss: 0.0985
2024-12-29 14:01:33,781 - INFO - Epoch 9/1000, Train Loss: 0.0931, Val Loss: 0.0996
2024-12-29 14:01:33,994 - INFO - Epoch 10/1000, Train Loss: 0.0909, Val Loss: 0.0990
2024-12-29 14:01:34,206 - INFO - Epoch 11/1000, Train Loss: 0.0889, Val Loss: 0.0989
2024-12-29 14:01:34,434 - INFO - Epoch 12/1000, Train Loss: 0.0877, Val Loss: 0.0994
2024-12-29 14:01:34,630 - INFO - Epoch 13/1000, Train Loss: 0.0865, Val Loss: 0.1005
2024-12-29 14:01:34,631 - INFO - Early stopping triggered at epoch 13
2024-12-29 14:01:34,631 - INFO - Training completed in 2.85s
2024-12-29 14:01:34,632 - INFO - Final memory usage: CPU 2722.1 MB, GPU 104.8 MB
2024-12-29 14:01:34,633 - INFO - Model training completed in 2.85s
2024-12-29 14:01:34,689 - INFO - Prediction completed in 0.06s
2024-12-29 14:01:34,697 - INFO - Poison rate 0.07 completed in 2.92s
2024-12-29 14:01:34,697 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:01:34,698 - INFO - Label flipping details:
2024-12-29 14:01:34,698 - INFO - - Source class: 1
2024-12-29 14:01:34,698 - INFO - - Target class: 0
2024-12-29 14:01:34,698 - INFO - - Available samples in source class: 955
2024-12-29 14:01:34,698 - INFO - - Requested samples to poison: 946
2024-12-29 14:01:34,698 - INFO - - Actual samples to flip: 946
2024-12-29 14:01:34,698 - INFO - - Samples remaining in source class: 9
2024-12-29 14:01:34,698 - INFO - Successfully flipped 946 labels from class 1 to 0
2024-12-29 14:01:34,699 - INFO - Total number of labels flipped: 946
2024-12-29 14:01:34,699 - INFO - Label flipping completed in 0.00s
2024-12-29 14:01:34,699 - INFO - Training set processing completed in 0.00s
2024-12-29 14:01:34,699 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:01:34,700 - INFO - Memory usage at start_fit: CPU 2692.6 MB, GPU 104.7 MB
2024-12-29 14:01:34,700 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:01:34,704 - INFO - Number of unique classes: 10
2024-12-29 14:01:34,782 - INFO - Fitted scaler and transformed data
2024-12-29 14:01:34,783 - INFO - Scaling time: 0.08s
2024-12-29 14:01:35,024 - INFO - Epoch 1/1000, Train Loss: 0.4991, Val Loss: 0.1313
2024-12-29 14:01:35,237 - INFO - Epoch 2/1000, Train Loss: 0.1035, Val Loss: 0.0887
2024-12-29 14:01:35,439 - INFO - Epoch 3/1000, Train Loss: 0.0755, Val Loss: 0.0728
2024-12-29 14:01:35,680 - INFO - Epoch 4/1000, Train Loss: 0.0626, Val Loss: 0.0650
2024-12-29 14:01:35,922 - INFO - Epoch 5/1000, Train Loss: 0.0545, Val Loss: 0.0604
2024-12-29 14:01:36,143 - INFO - Epoch 6/1000, Train Loss: 0.0490, Val Loss: 0.0576
2024-12-29 14:01:36,356 - INFO - Epoch 7/1000, Train Loss: 0.0452, Val Loss: 0.0560
2024-12-29 14:01:36,564 - INFO - Epoch 8/1000, Train Loss: 0.0428, Val Loss: 0.0549
2024-12-29 14:01:36,790 - INFO - Epoch 9/1000, Train Loss: 0.0411, Val Loss: 0.0550
2024-12-29 14:01:37,008 - INFO - Epoch 10/1000, Train Loss: 0.0394, Val Loss: 0.0545
2024-12-29 14:01:37,231 - INFO - Epoch 11/1000, Train Loss: 0.0380, Val Loss: 0.0535
2024-12-29 14:01:37,469 - INFO - Epoch 12/1000, Train Loss: 0.0371, Val Loss: 0.0537
2024-12-29 14:01:37,695 - INFO - Epoch 13/1000, Train Loss: 0.0367, Val Loss: 0.0540
2024-12-29 14:01:37,898 - INFO - Epoch 14/1000, Train Loss: 0.0357, Val Loss: 0.0535
2024-12-29 14:01:38,106 - INFO - Epoch 15/1000, Train Loss: 0.0353, Val Loss: 0.0527
2024-12-29 14:01:38,306 - INFO - Epoch 16/1000, Train Loss: 0.0349, Val Loss: 0.0524
2024-12-29 14:01:38,531 - INFO - Epoch 17/1000, Train Loss: 0.0345, Val Loss: 0.0521
2024-12-29 14:01:38,741 - INFO - Epoch 18/1000, Train Loss: 0.0345, Val Loss: 0.0517
2024-12-29 14:01:38,957 - INFO - Epoch 19/1000, Train Loss: 0.0341, Val Loss: 0.0521
2024-12-29 14:01:39,176 - INFO - Epoch 20/1000, Train Loss: 0.0339, Val Loss: 0.0519
2024-12-29 14:01:39,378 - INFO - Epoch 21/1000, Train Loss: 0.0337, Val Loss: 0.0522
2024-12-29 14:01:39,378 - INFO - Early stopping triggered at epoch 21
2024-12-29 14:01:39,378 - INFO - Training completed in 4.68s
2024-12-29 14:01:39,378 - INFO - Final memory usage: CPU 2722.4 MB, GPU 104.8 MB
2024-12-29 14:01:39,379 - INFO - Model training completed in 4.68s
2024-12-29 14:01:39,451 - INFO - Prediction completed in 0.07s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 14:01:39,465 - INFO - Poison rate 0.1 completed in 4.77s
2024-12-29 14:01:39,465 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:01:39,466 - INFO - Label flipping details:
2024-12-29 14:01:39,466 - INFO - - Source class: 1
2024-12-29 14:01:39,466 - INFO - - Target class: 0
2024-12-29 14:01:39,466 - INFO - - Available samples in source class: 955
2024-12-29 14:01:39,466 - INFO - - Requested samples to poison: 1893
2024-12-29 14:01:39,466 - INFO - - Actual samples to flip: 954
2024-12-29 14:01:39,466 - INFO - - Samples remaining in source class: 1
2024-12-29 14:01:39,466 - INFO - Successfully flipped 954 labels from class 1 to 0
2024-12-29 14:01:39,466 - INFO - Total number of labels flipped: 954
2024-12-29 14:01:39,466 - INFO - Label flipping completed in 0.00s
2024-12-29 14:01:39,466 - INFO - Training set processing completed in 0.00s
2024-12-29 14:01:39,466 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:01:39,467 - INFO - Memory usage at start_fit: CPU 2693.0 MB, GPU 104.7 MB
2024-12-29 14:01:39,467 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:01:39,472 - INFO - Number of unique classes: 10
2024-12-29 14:01:39,551 - INFO - Fitted scaler and transformed data
2024-12-29 14:01:39,551 - INFO - Scaling time: 0.08s
2024-12-29 14:01:39,778 - INFO - Epoch 1/1000, Train Loss: 0.5244, Val Loss: 0.1254
2024-12-29 14:01:39,983 - INFO - Epoch 2/1000, Train Loss: 0.0997, Val Loss: 0.0865
2024-12-29 14:01:40,193 - INFO - Epoch 3/1000, Train Loss: 0.0714, Val Loss: 0.0720
2024-12-29 14:01:40,415 - INFO - Epoch 4/1000, Train Loss: 0.0575, Val Loss: 0.0645
2024-12-29 14:01:40,626 - INFO - Epoch 5/1000, Train Loss: 0.0494, Val Loss: 0.0603
2024-12-29 14:01:40,860 - INFO - Epoch 6/1000, Train Loss: 0.0443, Val Loss: 0.0573
2024-12-29 14:01:41,076 - INFO - Epoch 7/1000, Train Loss: 0.0407, Val Loss: 0.0554
2024-12-29 14:01:41,277 - INFO - Epoch 8/1000, Train Loss: 0.0380, Val Loss: 0.0540
2024-12-29 14:01:41,504 - INFO - Epoch 9/1000, Train Loss: 0.0358, Val Loss: 0.0532
2024-12-29 14:01:41,711 - INFO - Epoch 10/1000, Train Loss: 0.0344, Val Loss: 0.0525
2024-12-29 14:01:41,921 - INFO - Epoch 11/1000, Train Loss: 0.0332, Val Loss: 0.0515
2024-12-29 14:01:42,122 - INFO - Epoch 12/1000, Train Loss: 0.0325, Val Loss: 0.0514
2024-12-29 14:01:42,337 - INFO - Epoch 13/1000, Train Loss: 0.0320, Val Loss: 0.0507
2024-12-29 14:01:42,556 - INFO - Epoch 14/1000, Train Loss: 0.0310, Val Loss: 0.0511
2024-12-29 14:01:42,768 - INFO - Epoch 15/1000, Train Loss: 0.0307, Val Loss: 0.0502
2024-12-29 14:01:42,966 - INFO - Epoch 16/1000, Train Loss: 0.0308, Val Loss: 0.0501
2024-12-29 14:01:43,171 - INFO - Epoch 17/1000, Train Loss: 0.0302, Val Loss: 0.0496
2024-12-29 14:01:43,370 - INFO - Epoch 18/1000, Train Loss: 0.0299, Val Loss: 0.0495
2024-12-29 14:01:43,571 - INFO - Epoch 19/1000, Train Loss: 0.0294, Val Loss: 0.0496
2024-12-29 14:01:43,774 - INFO - Epoch 20/1000, Train Loss: 0.0295, Val Loss: 0.0492
2024-12-29 14:01:43,980 - INFO - Epoch 21/1000, Train Loss: 0.0293, Val Loss: 0.0485
2024-12-29 14:01:44,175 - INFO - Epoch 22/1000, Train Loss: 0.0291, Val Loss: 0.0493
2024-12-29 14:01:44,400 - INFO - Epoch 23/1000, Train Loss: 0.0294, Val Loss: 0.0493
2024-12-29 14:01:44,608 - INFO - Epoch 24/1000, Train Loss: 0.0290, Val Loss: 0.0490
2024-12-29 14:01:44,818 - INFO - Epoch 25/1000, Train Loss: 0.0292, Val Loss: 0.0490
2024-12-29 14:01:44,818 - INFO - Early stopping triggered at epoch 25
2024-12-29 14:01:44,818 - INFO - Training completed in 5.35s
2024-12-29 14:01:44,818 - INFO - Final memory usage: CPU 2722.4 MB, GPU 104.8 MB
2024-12-29 14:01:44,819 - INFO - Model training completed in 5.35s
2024-12-29 14:01:44,888 - INFO - Prediction completed in 0.07s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 14:01:44,898 - INFO - Poison rate 0.2 completed in 5.43s
2024-12-29 14:01:44,904 - INFO - Loaded 350 existing results
2024-12-29 14:01:44,905 - INFO - Total results to save: 357
2024-12-29 14:01:44,906 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:01:44,917 - INFO - Saved 357 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:01:44,917 - INFO - Total evaluation time: 61.22s
2024-12-29 14:01:44,919 - INFO - 
Progress: 54.2% - Evaluating ImageNette with LogisticRegression (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:01:45,116 - INFO - Loading datasets...
2024-12-29 14:01:45,143 - INFO - Dataset loading completed in 0.03s
2024-12-29 14:01:45,143 - INFO - Extracting validation features...
2024-12-29 14:01:45,143 - INFO - Extracting features from 3925 samples...
2024-12-29 14:01:54,261 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:01:54,267 - INFO - Validation feature extraction completed in 9.12s
2024-12-29 14:01:54,267 - INFO - Extracting training features...
2024-12-29 14:01:54,268 - INFO - Extracting features from 9469 samples...
2024-12-29 14:02:15,992 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:02:15,998 - INFO - Training feature extraction completed in 21.73s
2024-12-29 14:02:15,999 - INFO - Creating model for classifier: LogisticRegression
2024-12-29 14:02:15,999 - INFO - Using device: cuda
2024-12-29 14:02:15,999 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:02:15,999 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:02:15,999 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:02:16,559 - INFO - Feature scaling completed in 0.56s
2024-12-29 14:02:16,560 - INFO - Starting feature selection (k=50)
2024-12-29 14:02:16,573 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:02:16,574 - INFO - Starting anomaly detection
2024-12-29 14:02:19,815 - INFO - Anomaly detection completed in 3.24s
2024-12-29 14:02:19,815 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:02:19,815 - INFO - Total fit_transform time: 3.82s
2024-12-29 14:02:19,815 - INFO - Training set processing completed in 3.82s
2024-12-29 14:02:19,815 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:02:19,817 - INFO - Memory usage at start_fit: CPU 2709.6 MB, GPU 104.0 MB
2024-12-29 14:02:19,817 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:02:19,821 - INFO - Number of unique classes: 10
2024-12-29 14:02:19,894 - INFO - Fitted scaler and transformed data
2024-12-29 14:02:19,894 - INFO - Scaling time: 0.07s
2024-12-29 14:02:20,107 - INFO - Epoch 1/1000, Train Loss: 0.5082, Val Loss: 0.1372
2024-12-29 14:02:20,322 - INFO - Epoch 2/1000, Train Loss: 0.0949, Val Loss: 0.0944
2024-12-29 14:02:20,648 - INFO - Epoch 3/1000, Train Loss: 0.0680, Val Loss: 0.0778
2024-12-29 14:02:21,008 - INFO - Epoch 4/1000, Train Loss: 0.0548, Val Loss: 0.0686
2024-12-29 14:02:21,355 - INFO - Epoch 5/1000, Train Loss: 0.0472, Val Loss: 0.0633
2024-12-29 14:02:21,706 - INFO - Epoch 6/1000, Train Loss: 0.0423, Val Loss: 0.0597
2024-12-29 14:02:22,077 - INFO - Epoch 7/1000, Train Loss: 0.0389, Val Loss: 0.0574
2024-12-29 14:02:22,374 - INFO - Epoch 8/1000, Train Loss: 0.0366, Val Loss: 0.0559
2024-12-29 14:02:22,584 - INFO - Epoch 9/1000, Train Loss: 0.0345, Val Loss: 0.0544
2024-12-29 14:02:22,787 - INFO - Epoch 10/1000, Train Loss: 0.0330, Val Loss: 0.0538
2024-12-29 14:02:23,001 - INFO - Epoch 11/1000, Train Loss: 0.0322, Val Loss: 0.0529
2024-12-29 14:02:23,202 - INFO - Epoch 12/1000, Train Loss: 0.0314, Val Loss: 0.0528
2024-12-29 14:02:23,407 - INFO - Epoch 13/1000, Train Loss: 0.0307, Val Loss: 0.0520
2024-12-29 14:02:23,622 - INFO - Epoch 14/1000, Train Loss: 0.0300, Val Loss: 0.0523
2024-12-29 14:02:23,824 - INFO - Epoch 15/1000, Train Loss: 0.0299, Val Loss: 0.0512
2024-12-29 14:02:24,095 - INFO - Epoch 16/1000, Train Loss: 0.0293, Val Loss: 0.0516
2024-12-29 14:02:24,450 - INFO - Epoch 17/1000, Train Loss: 0.0292, Val Loss: 0.0510
2024-12-29 14:02:24,837 - INFO - Epoch 18/1000, Train Loss: 0.0287, Val Loss: 0.0509
2024-12-29 14:02:25,238 - INFO - Epoch 19/1000, Train Loss: 0.0286, Val Loss: 0.0504
2024-12-29 14:02:25,598 - INFO - Epoch 20/1000, Train Loss: 0.0283, Val Loss: 0.0503
2024-12-29 14:02:25,598 - INFO - Early stopping triggered at epoch 20
2024-12-29 14:02:25,598 - INFO - Training completed in 5.78s
2024-12-29 14:02:25,599 - INFO - Final memory usage: CPU 2718.6 MB, GPU 104.2 MB
2024-12-29 14:02:25,601 - INFO - Model training completed in 5.79s
2024-12-29 14:02:25,672 - INFO - Prediction completed in 0.07s
2024-12-29 14:02:25,681 - INFO - Poison rate 0.0 completed in 9.68s
2024-12-29 14:02:25,681 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:02:25,682 - INFO - Label flipping details:
2024-12-29 14:02:25,682 - INFO - - Source class: 1
2024-12-29 14:02:25,682 - INFO - - Target class: 0
2024-12-29 14:02:25,682 - INFO - - Available samples in source class: 955
2024-12-29 14:02:25,682 - INFO - - Requested samples to poison: 94
2024-12-29 14:02:25,682 - INFO - - Actual samples to flip: 94
2024-12-29 14:02:25,682 - INFO - - Samples remaining in source class: 861
2024-12-29 14:02:25,682 - INFO - Successfully flipped 94 labels from class 1 to 0
2024-12-29 14:02:25,682 - INFO - Total number of labels flipped: 94
2024-12-29 14:02:25,682 - INFO - Label flipping completed in 0.00s
2024-12-29 14:02:25,682 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:02:25,682 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:02:26,249 - INFO - Feature scaling completed in 0.57s
2024-12-29 14:02:26,249 - INFO - Starting feature selection (k=50)
2024-12-29 14:02:26,264 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:02:26,264 - INFO - Starting anomaly detection
2024-12-29 14:02:30,884 - INFO - Anomaly detection completed in 4.62s
2024-12-29 14:02:30,885 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:02:30,885 - INFO - Total fit_transform time: 5.20s
2024-12-29 14:02:30,885 - INFO - Training set processing completed in 5.20s
2024-12-29 14:02:30,886 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:02:30,887 - INFO - Memory usage at start_fit: CPU 2709.2 MB, GPU 104.1 MB
2024-12-29 14:02:30,887 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:02:30,889 - INFO - Number of unique classes: 10
2024-12-29 14:02:30,964 - INFO - Fitted scaler and transformed data
2024-12-29 14:02:30,964 - INFO - Scaling time: 0.07s
2024-12-29 14:02:31,302 - INFO - Epoch 1/1000, Train Loss: 0.5126, Val Loss: 0.1544
2024-12-29 14:02:31,645 - INFO - Epoch 2/1000, Train Loss: 0.1329, Val Loss: 0.1152
2024-12-29 14:02:32,018 - INFO - Epoch 3/1000, Train Loss: 0.1039, Val Loss: 0.1020
2024-12-29 14:02:32,353 - INFO - Epoch 4/1000, Train Loss: 0.0894, Val Loss: 0.0967
2024-12-29 14:02:32,726 - INFO - Epoch 5/1000, Train Loss: 0.0801, Val Loss: 0.0928
2024-12-29 14:02:33,080 - INFO - Epoch 6/1000, Train Loss: 0.0740, Val Loss: 0.0905
2024-12-29 14:02:33,309 - INFO - Epoch 7/1000, Train Loss: 0.0698, Val Loss: 0.0889
2024-12-29 14:02:33,522 - INFO - Epoch 8/1000, Train Loss: 0.0667, Val Loss: 0.0883
2024-12-29 14:02:33,738 - INFO - Epoch 9/1000, Train Loss: 0.0643, Val Loss: 0.0873
2024-12-29 14:02:33,939 - INFO - Epoch 10/1000, Train Loss: 0.0624, Val Loss: 0.0875
2024-12-29 14:02:34,156 - INFO - Epoch 11/1000, Train Loss: 0.0608, Val Loss: 0.0868
2024-12-29 14:02:34,349 - INFO - Epoch 12/1000, Train Loss: 0.0598, Val Loss: 0.0883
2024-12-29 14:02:34,559 - INFO - Epoch 13/1000, Train Loss: 0.0593, Val Loss: 0.0864
2024-12-29 14:02:34,757 - INFO - Epoch 14/1000, Train Loss: 0.0576, Val Loss: 0.0867
2024-12-29 14:02:34,757 - INFO - Early stopping triggered at epoch 14
2024-12-29 14:02:34,757 - INFO - Training completed in 3.87s
2024-12-29 14:02:34,758 - INFO - Final memory usage: CPU 2718.3 MB, GPU 104.2 MB
2024-12-29 14:02:34,759 - INFO - Model training completed in 3.87s
2024-12-29 14:02:34,832 - INFO - Prediction completed in 0.07s
2024-12-29 14:02:34,840 - INFO - Poison rate 0.01 completed in 9.16s
2024-12-29 14:02:34,840 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:02:34,841 - INFO - Label flipping details:
2024-12-29 14:02:34,841 - INFO - - Source class: 1
2024-12-29 14:02:34,841 - INFO - - Target class: 0
2024-12-29 14:02:34,841 - INFO - - Available samples in source class: 955
2024-12-29 14:02:34,841 - INFO - - Requested samples to poison: 284
2024-12-29 14:02:34,841 - INFO - - Actual samples to flip: 284
2024-12-29 14:02:34,841 - INFO - - Samples remaining in source class: 671
2024-12-29 14:02:34,841 - INFO - Successfully flipped 284 labels from class 1 to 0
2024-12-29 14:02:34,842 - INFO - Total number of labels flipped: 284
2024-12-29 14:02:34,842 - INFO - Label flipping completed in 0.00s
2024-12-29 14:02:34,842 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:02:34,842 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:02:35,493 - INFO - Feature scaling completed in 0.65s
2024-12-29 14:02:35,493 - INFO - Starting feature selection (k=50)
2024-12-29 14:02:35,508 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:02:35,508 - INFO - Starting anomaly detection
2024-12-29 14:02:39,220 - INFO - Anomaly detection completed in 3.71s
2024-12-29 14:02:39,221 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:02:39,221 - INFO - Total fit_transform time: 4.38s
2024-12-29 14:02:39,221 - INFO - Training set processing completed in 4.38s
2024-12-29 14:02:39,221 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:02:39,222 - INFO - Memory usage at start_fit: CPU 2709.5 MB, GPU 104.1 MB
2024-12-29 14:02:39,222 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:02:39,224 - INFO - Number of unique classes: 10
2024-12-29 14:02:39,296 - INFO - Fitted scaler and transformed data
2024-12-29 14:02:39,296 - INFO - Scaling time: 0.07s
2024-12-29 14:02:39,494 - INFO - Epoch 1/1000, Train Loss: 0.5716, Val Loss: 0.2089
2024-12-29 14:02:39,705 - INFO - Epoch 2/1000, Train Loss: 0.1608, Val Loss: 0.1690
2024-12-29 14:02:39,898 - INFO - Epoch 3/1000, Train Loss: 0.1305, Val Loss: 0.1520
2024-12-29 14:02:40,108 - INFO - Epoch 4/1000, Train Loss: 0.1171, Val Loss: 0.1444
2024-12-29 14:02:40,306 - INFO - Epoch 5/1000, Train Loss: 0.1055, Val Loss: 0.1389
2024-12-29 14:02:40,507 - INFO - Epoch 6/1000, Train Loss: 0.0992, Val Loss: 0.1372
2024-12-29 14:02:40,710 - INFO - Epoch 7/1000, Train Loss: 0.0956, Val Loss: 0.1354
2024-12-29 14:02:40,889 - INFO - Epoch 8/1000, Train Loss: 0.0921, Val Loss: 0.1323
2024-12-29 14:02:41,089 - INFO - Epoch 9/1000, Train Loss: 0.0882, Val Loss: 0.1312
2024-12-29 14:02:41,272 - INFO - Epoch 10/1000, Train Loss: 0.0867, Val Loss: 0.1311
2024-12-29 14:02:41,474 - INFO - Epoch 11/1000, Train Loss: 0.0853, Val Loss: 0.1326
2024-12-29 14:02:41,667 - INFO - Epoch 12/1000, Train Loss: 0.0834, Val Loss: 0.1305
2024-12-29 14:02:41,865 - INFO - Epoch 13/1000, Train Loss: 0.0825, Val Loss: 0.1282
2024-12-29 14:02:42,083 - INFO - Epoch 14/1000, Train Loss: 0.0818, Val Loss: 0.1286
2024-12-29 14:02:42,293 - INFO - Epoch 15/1000, Train Loss: 0.0806, Val Loss: 0.1286
2024-12-29 14:02:42,490 - INFO - Epoch 16/1000, Train Loss: 0.0801, Val Loss: 0.1295
2024-12-29 14:02:42,676 - INFO - Epoch 17/1000, Train Loss: 0.0794, Val Loss: 0.1277
2024-12-29 14:02:42,864 - INFO - Epoch 18/1000, Train Loss: 0.0791, Val Loss: 0.1289
2024-12-29 14:02:42,864 - INFO - Early stopping triggered at epoch 18
2024-12-29 14:02:42,864 - INFO - Training completed in 3.64s
2024-12-29 14:02:42,865 - INFO - Final memory usage: CPU 2718.3 MB, GPU 104.2 MB
2024-12-29 14:02:42,867 - INFO - Model training completed in 3.65s
2024-12-29 14:02:42,924 - INFO - Prediction completed in 0.06s
2024-12-29 14:02:42,933 - INFO - Poison rate 0.03 completed in 8.09s
2024-12-29 14:02:42,933 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:02:42,934 - INFO - Label flipping details:
2024-12-29 14:02:42,934 - INFO - - Source class: 1
2024-12-29 14:02:42,934 - INFO - - Target class: 0
2024-12-29 14:02:42,934 - INFO - - Available samples in source class: 955
2024-12-29 14:02:42,934 - INFO - - Requested samples to poison: 473
2024-12-29 14:02:42,934 - INFO - - Actual samples to flip: 473
2024-12-29 14:02:42,934 - INFO - - Samples remaining in source class: 482
2024-12-29 14:02:42,934 - INFO - Successfully flipped 473 labels from class 1 to 0
2024-12-29 14:02:42,934 - INFO - Total number of labels flipped: 473
2024-12-29 14:02:42,934 - INFO - Label flipping completed in 0.00s
2024-12-29 14:02:42,934 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:02:42,934 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:02:43,494 - INFO - Feature scaling completed in 0.56s
2024-12-29 14:02:43,494 - INFO - Starting feature selection (k=50)
2024-12-29 14:02:43,508 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:02:43,508 - INFO - Starting anomaly detection
2024-12-29 14:02:47,657 - INFO - Anomaly detection completed in 4.15s
2024-12-29 14:02:47,658 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:02:47,658 - INFO - Total fit_transform time: 4.72s
2024-12-29 14:02:47,658 - INFO - Training set processing completed in 4.72s
2024-12-29 14:02:47,659 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:02:47,660 - INFO - Memory usage at start_fit: CPU 2709.0 MB, GPU 104.1 MB
2024-12-29 14:02:47,661 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:02:47,664 - INFO - Number of unique classes: 10
2024-12-29 14:02:47,748 - INFO - Fitted scaler and transformed data
2024-12-29 14:02:47,748 - INFO - Scaling time: 0.08s
2024-12-29 14:02:47,959 - INFO - Epoch 1/1000, Train Loss: 0.5818, Val Loss: 0.2216
2024-12-29 14:02:48,171 - INFO - Epoch 2/1000, Train Loss: 0.1715, Val Loss: 0.1817
2024-12-29 14:02:48,394 - INFO - Epoch 3/1000, Train Loss: 0.1403, Val Loss: 0.1687
2024-12-29 14:02:48,580 - INFO - Epoch 4/1000, Train Loss: 0.1265, Val Loss: 0.1587
2024-12-29 14:02:48,796 - INFO - Epoch 5/1000, Train Loss: 0.1167, Val Loss: 0.1497
2024-12-29 14:02:48,999 - INFO - Epoch 6/1000, Train Loss: 0.1100, Val Loss: 0.1478
2024-12-29 14:02:49,203 - INFO - Epoch 7/1000, Train Loss: 0.1053, Val Loss: 0.1440
2024-12-29 14:02:49,409 - INFO - Epoch 8/1000, Train Loss: 0.1025, Val Loss: 0.1422
2024-12-29 14:02:49,589 - INFO - Epoch 9/1000, Train Loss: 0.1006, Val Loss: 0.1433
2024-12-29 14:02:49,776 - INFO - Epoch 10/1000, Train Loss: 0.0973, Val Loss: 0.1394
2024-12-29 14:02:49,991 - INFO - Epoch 11/1000, Train Loss: 0.0962, Val Loss: 0.1400
2024-12-29 14:02:50,186 - INFO - Epoch 12/1000, Train Loss: 0.0952, Val Loss: 0.1502
2024-12-29 14:02:50,397 - INFO - Epoch 13/1000, Train Loss: 0.0953, Val Loss: 0.1390
2024-12-29 14:02:50,574 - INFO - Epoch 14/1000, Train Loss: 0.0929, Val Loss: 0.1377
2024-12-29 14:02:50,761 - INFO - Epoch 15/1000, Train Loss: 0.0929, Val Loss: 0.1450
2024-12-29 14:02:50,981 - INFO - Epoch 16/1000, Train Loss: 0.0919, Val Loss: 0.1417
2024-12-29 14:02:51,209 - INFO - Epoch 17/1000, Train Loss: 0.0917, Val Loss: 0.1497
2024-12-29 14:02:51,403 - INFO - Epoch 18/1000, Train Loss: 0.0910, Val Loss: 0.1372
2024-12-29 14:02:51,588 - INFO - Epoch 19/1000, Train Loss: 0.0901, Val Loss: 0.1418
2024-12-29 14:02:51,588 - INFO - Early stopping triggered at epoch 19
2024-12-29 14:02:51,588 - INFO - Training completed in 3.93s
2024-12-29 14:02:51,589 - INFO - Final memory usage: CPU 2718.5 MB, GPU 104.2 MB
2024-12-29 14:02:51,590 - INFO - Model training completed in 3.93s
2024-12-29 14:02:51,668 - INFO - Prediction completed in 0.08s
2024-12-29 14:02:51,677 - INFO - Poison rate 0.05 completed in 8.74s
2024-12-29 14:02:51,677 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:02:51,678 - INFO - Label flipping details:
2024-12-29 14:02:51,678 - INFO - - Source class: 1
2024-12-29 14:02:51,678 - INFO - - Target class: 0
2024-12-29 14:02:51,678 - INFO - - Available samples in source class: 955
2024-12-29 14:02:51,678 - INFO - - Requested samples to poison: 662
2024-12-29 14:02:51,678 - INFO - - Actual samples to flip: 662
2024-12-29 14:02:51,678 - INFO - - Samples remaining in source class: 293
2024-12-29 14:02:51,678 - INFO - Successfully flipped 662 labels from class 1 to 0
2024-12-29 14:02:51,678 - INFO - Total number of labels flipped: 662
2024-12-29 14:02:51,679 - INFO - Label flipping completed in 0.00s
2024-12-29 14:02:51,679 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:02:51,679 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:02:52,197 - INFO - Feature scaling completed in 0.52s
2024-12-29 14:02:52,197 - INFO - Starting feature selection (k=50)
2024-12-29 14:02:52,212 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:02:52,212 - INFO - Starting anomaly detection
2024-12-29 14:02:55,309 - INFO - Anomaly detection completed in 3.10s
2024-12-29 14:02:55,310 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:02:55,310 - INFO - Total fit_transform time: 3.63s
2024-12-29 14:02:55,310 - INFO - Training set processing completed in 3.63s
2024-12-29 14:02:55,310 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:02:55,311 - INFO - Memory usage at start_fit: CPU 2709.0 MB, GPU 104.1 MB
2024-12-29 14:02:55,311 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:02:55,314 - INFO - Number of unique classes: 10
2024-12-29 14:02:55,388 - INFO - Fitted scaler and transformed data
2024-12-29 14:02:55,389 - INFO - Scaling time: 0.07s
2024-12-29 14:02:55,616 - INFO - Epoch 1/1000, Train Loss: 0.6108, Val Loss: 0.1955
2024-12-29 14:02:55,807 - INFO - Epoch 2/1000, Train Loss: 0.1648, Val Loss: 0.1598
2024-12-29 14:02:55,999 - INFO - Epoch 3/1000, Train Loss: 0.1336, Val Loss: 0.1423
2024-12-29 14:02:56,193 - INFO - Epoch 4/1000, Train Loss: 0.1178, Val Loss: 0.1355
2024-12-29 14:02:56,388 - INFO - Epoch 5/1000, Train Loss: 0.1071, Val Loss: 0.1345
2024-12-29 14:02:56,603 - INFO - Epoch 6/1000, Train Loss: 0.1020, Val Loss: 0.1293
2024-12-29 14:02:56,780 - INFO - Epoch 7/1000, Train Loss: 0.0969, Val Loss: 0.1331
2024-12-29 14:02:56,966 - INFO - Epoch 8/1000, Train Loss: 0.0940, Val Loss: 0.1286
2024-12-29 14:02:57,165 - INFO - Epoch 9/1000, Train Loss: 0.0913, Val Loss: 0.1259
2024-12-29 14:02:57,346 - INFO - Epoch 10/1000, Train Loss: 0.0894, Val Loss: 0.1268
2024-12-29 14:02:57,535 - INFO - Epoch 11/1000, Train Loss: 0.0871, Val Loss: 0.1261
2024-12-29 14:02:57,737 - INFO - Epoch 12/1000, Train Loss: 0.0857, Val Loss: 0.1255
2024-12-29 14:02:57,947 - INFO - Epoch 13/1000, Train Loss: 0.0851, Val Loss: 0.1266
2024-12-29 14:02:58,149 - INFO - Epoch 14/1000, Train Loss: 0.0837, Val Loss: 0.1268
2024-12-29 14:02:58,149 - INFO - Early stopping triggered at epoch 14
2024-12-29 14:02:58,149 - INFO - Training completed in 2.84s
2024-12-29 14:02:58,149 - INFO - Final memory usage: CPU 2718.2 MB, GPU 104.2 MB
2024-12-29 14:02:58,150 - INFO - Model training completed in 2.84s
2024-12-29 14:02:58,237 - INFO - Prediction completed in 0.09s
2024-12-29 14:02:58,246 - INFO - Poison rate 0.07 completed in 6.57s
2024-12-29 14:02:58,246 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:02:58,249 - INFO - Label flipping details:
2024-12-29 14:02:58,249 - INFO - - Source class: 1
2024-12-29 14:02:58,249 - INFO - - Target class: 0
2024-12-29 14:02:58,249 - INFO - - Available samples in source class: 955
2024-12-29 14:02:58,249 - INFO - - Requested samples to poison: 946
2024-12-29 14:02:58,249 - INFO - - Actual samples to flip: 946
2024-12-29 14:02:58,249 - INFO - - Samples remaining in source class: 9
2024-12-29 14:02:58,249 - INFO - Successfully flipped 946 labels from class 1 to 0
2024-12-29 14:02:58,250 - INFO - Total number of labels flipped: 946
2024-12-29 14:02:58,250 - INFO - Label flipping completed in 0.00s
2024-12-29 14:02:58,250 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:02:58,250 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:02:58,746 - INFO - Feature scaling completed in 0.50s
2024-12-29 14:02:58,746 - INFO - Starting feature selection (k=50)
2024-12-29 14:02:58,757 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:02:58,758 - INFO - Starting anomaly detection
2024-12-29 14:03:02,636 - INFO - Anomaly detection completed in 3.88s
2024-12-29 14:03:02,636 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:03:02,636 - INFO - Total fit_transform time: 4.39s
2024-12-29 14:03:02,636 - INFO - Training set processing completed in 4.39s
2024-12-29 14:03:02,637 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:03:02,638 - INFO - Memory usage at start_fit: CPU 2708.9 MB, GPU 104.1 MB
2024-12-29 14:03:02,638 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:03:02,640 - INFO - Number of unique classes: 10
2024-12-29 14:03:02,729 - INFO - Fitted scaler and transformed data
2024-12-29 14:03:02,730 - INFO - Scaling time: 0.09s
2024-12-29 14:03:02,959 - INFO - Epoch 1/1000, Train Loss: 0.4861, Val Loss: 0.1400
2024-12-29 14:03:03,183 - INFO - Epoch 2/1000, Train Loss: 0.1003, Val Loss: 0.1014
2024-12-29 14:03:03,382 - INFO - Epoch 3/1000, Train Loss: 0.0730, Val Loss: 0.0880
2024-12-29 14:03:03,554 - INFO - Epoch 4/1000, Train Loss: 0.0596, Val Loss: 0.0805
2024-12-29 14:03:03,740 - INFO - Epoch 5/1000, Train Loss: 0.0516, Val Loss: 0.0765
2024-12-29 14:03:03,941 - INFO - Epoch 6/1000, Train Loss: 0.0463, Val Loss: 0.0744
2024-12-29 14:03:04,136 - INFO - Epoch 7/1000, Train Loss: 0.0429, Val Loss: 0.0722
2024-12-29 14:03:04,327 - INFO - Epoch 8/1000, Train Loss: 0.0404, Val Loss: 0.0709
2024-12-29 14:03:04,543 - INFO - Epoch 9/1000, Train Loss: 0.0382, Val Loss: 0.0700
2024-12-29 14:03:04,743 - INFO - Epoch 10/1000, Train Loss: 0.0367, Val Loss: 0.0692
2024-12-29 14:03:04,953 - INFO - Epoch 11/1000, Train Loss: 0.0360, Val Loss: 0.0686
2024-12-29 14:03:05,161 - INFO - Epoch 12/1000, Train Loss: 0.0353, Val Loss: 0.0686
2024-12-29 14:03:05,356 - INFO - Epoch 13/1000, Train Loss: 0.0344, Val Loss: 0.0679
2024-12-29 14:03:05,552 - INFO - Epoch 14/1000, Train Loss: 0.0338, Val Loss: 0.0677
2024-12-29 14:03:05,906 - INFO - Epoch 15/1000, Train Loss: 0.0334, Val Loss: 0.0666
2024-12-29 14:03:06,246 - INFO - Epoch 16/1000, Train Loss: 0.0331, Val Loss: 0.0668
2024-12-29 14:03:06,669 - INFO - Epoch 17/1000, Train Loss: 0.0323, Val Loss: 0.0670
2024-12-29 14:03:07,081 - INFO - Epoch 18/1000, Train Loss: 0.0324, Val Loss: 0.0670
2024-12-29 14:03:07,510 - INFO - Epoch 19/1000, Train Loss: 0.0322, Val Loss: 0.0667
2024-12-29 14:03:07,926 - INFO - Epoch 20/1000, Train Loss: 0.0320, Val Loss: 0.0662
2024-12-29 14:03:07,926 - INFO - Early stopping triggered at epoch 20
2024-12-29 14:03:07,926 - INFO - Training completed in 5.29s
2024-12-29 14:03:07,926 - INFO - Final memory usage: CPU 2718.5 MB, GPU 104.2 MB
2024-12-29 14:03:07,928 - INFO - Model training completed in 5.29s
2024-12-29 14:03:07,976 - INFO - Prediction completed in 0.05s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 14:03:07,986 - INFO - Poison rate 0.1 completed in 9.74s
2024-12-29 14:03:07,987 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:03:07,987 - INFO - Label flipping details:
2024-12-29 14:03:07,987 - INFO - - Source class: 1
2024-12-29 14:03:07,987 - INFO - - Target class: 0
2024-12-29 14:03:07,987 - INFO - - Available samples in source class: 955
2024-12-29 14:03:07,987 - INFO - - Requested samples to poison: 1893
2024-12-29 14:03:07,988 - INFO - - Actual samples to flip: 954
2024-12-29 14:03:07,988 - INFO - - Samples remaining in source class: 1
2024-12-29 14:03:07,988 - INFO - Successfully flipped 954 labels from class 1 to 0
2024-12-29 14:03:07,988 - INFO - Total number of labels flipped: 954
2024-12-29 14:03:07,988 - INFO - Label flipping completed in 0.00s
2024-12-29 14:03:07,988 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:03:07,988 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:03:08,512 - INFO - Feature scaling completed in 0.52s
2024-12-29 14:03:08,512 - INFO - Starting feature selection (k=50)
2024-12-29 14:03:08,526 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:03:08,526 - INFO - Starting anomaly detection
2024-12-29 14:03:12,456 - INFO - Anomaly detection completed in 3.93s
2024-12-29 14:03:12,456 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:03:12,456 - INFO - Total fit_transform time: 4.47s
2024-12-29 14:03:12,456 - INFO - Training set processing completed in 4.47s
2024-12-29 14:03:12,456 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:03:12,457 - INFO - Memory usage at start_fit: CPU 2709.2 MB, GPU 104.1 MB
2024-12-29 14:03:12,457 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:03:12,461 - INFO - Number of unique classes: 10
2024-12-29 14:03:12,530 - INFO - Fitted scaler and transformed data
2024-12-29 14:03:12,531 - INFO - Scaling time: 0.07s
2024-12-29 14:03:12,849 - INFO - Epoch 1/1000, Train Loss: 0.5148, Val Loss: 0.1198
2024-12-29 14:03:13,189 - INFO - Epoch 2/1000, Train Loss: 0.1011, Val Loss: 0.0795
2024-12-29 14:03:13,535 - INFO - Epoch 3/1000, Train Loss: 0.0719, Val Loss: 0.0653
2024-12-29 14:03:13,838 - INFO - Epoch 4/1000, Train Loss: 0.0581, Val Loss: 0.0582
2024-12-29 14:03:14,238 - INFO - Epoch 5/1000, Train Loss: 0.0499, Val Loss: 0.0545
2024-12-29 14:03:14,650 - INFO - Epoch 6/1000, Train Loss: 0.0446, Val Loss: 0.0514
2024-12-29 14:03:15,019 - INFO - Epoch 7/1000, Train Loss: 0.0410, Val Loss: 0.0503
2024-12-29 14:03:15,435 - INFO - Epoch 8/1000, Train Loss: 0.0381, Val Loss: 0.0493
2024-12-29 14:03:15,848 - INFO - Epoch 9/1000, Train Loss: 0.0359, Val Loss: 0.0485
2024-12-29 14:03:16,249 - INFO - Epoch 10/1000, Train Loss: 0.0349, Val Loss: 0.0480
2024-12-29 14:03:16,655 - INFO - Epoch 11/1000, Train Loss: 0.0334, Val Loss: 0.0477
2024-12-29 14:03:17,053 - INFO - Epoch 12/1000, Train Loss: 0.0325, Val Loss: 0.0474
2024-12-29 14:03:17,467 - INFO - Epoch 13/1000, Train Loss: 0.0318, Val Loss: 0.0467
2024-12-29 14:03:17,889 - INFO - Epoch 14/1000, Train Loss: 0.0312, Val Loss: 0.0472
2024-12-29 14:03:18,285 - INFO - Epoch 15/1000, Train Loss: 0.0307, Val Loss: 0.0467
2024-12-29 14:03:18,647 - INFO - Epoch 16/1000, Train Loss: 0.0303, Val Loss: 0.0469
2024-12-29 14:03:19,058 - INFO - Epoch 17/1000, Train Loss: 0.0301, Val Loss: 0.0468
2024-12-29 14:03:19,059 - INFO - Early stopping triggered at epoch 17
2024-12-29 14:03:19,059 - INFO - Training completed in 6.60s
2024-12-29 14:03:19,059 - INFO - Final memory usage: CPU 2729.5 MB, GPU 104.2 MB
2024-12-29 14:03:19,061 - INFO - Model training completed in 6.60s
2024-12-29 14:03:19,159 - INFO - Prediction completed in 0.10s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 14:03:19,169 - INFO - Poison rate 0.2 completed in 11.18s
2024-12-29 14:03:19,176 - INFO - Loaded 357 existing results
2024-12-29 14:03:19,176 - INFO - Total results to save: 364
2024-12-29 14:03:19,177 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:03:19,209 - INFO - Saved 364 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:03:19,210 - INFO - Total evaluation time: 94.09s
2024-12-29 14:03:19,212 - INFO - 
Progress: 55.2% - Evaluating ImageNette with RandomForest (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:03:19,432 - INFO - Loading datasets...
2024-12-29 14:03:19,454 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:03:19,454 - INFO - Extracting validation features...
2024-12-29 14:03:19,454 - INFO - Extracting features from 3925 samples...
2024-12-29 14:03:28,486 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:03:28,491 - INFO - Validation feature extraction completed in 9.04s
2024-12-29 14:03:28,491 - INFO - Extracting training features...
2024-12-29 14:03:28,491 - INFO - Extracting features from 9469 samples...
2024-12-29 14:03:50,787 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:03:50,792 - INFO - Training feature extraction completed in 22.30s
2024-12-29 14:03:50,792 - INFO - Creating model for classifier: RandomForest
2024-12-29 14:03:50,793 - INFO - Using device: cuda
2024-12-29 14:03:50,793 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:03:50,793 - INFO - Training set processing completed in 0.00s
2024-12-29 14:03:50,793 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:03:50,795 - INFO - Memory usage at start_fit: CPU 2681.4 MB, GPU 104.6 MB
2024-12-29 14:03:50,795 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:03:50,984 - INFO - Fitted scaler and transformed data
2024-12-29 14:03:50,984 - INFO - Scaling time: 0.19s
2024-12-29 14:03:50,991 - INFO - Number of unique classes: 10
2024-12-29 14:03:53,844 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3013
2024-12-29 14:03:57,848 - INFO - Epoch 2/10, Train Loss: 2.3006, Val Loss: 2.3001
2024-12-29 14:04:01,383 - INFO - Epoch 3/10, Train Loss: 2.2991, Val Loss: 2.2988
2024-12-29 14:04:04,290 - INFO - Epoch 4/10, Train Loss: 2.2977, Val Loss: 2.2975
2024-12-29 14:04:04,290 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:04:04,290 - INFO - Training completed in 13.50s
2024-12-29 14:04:04,291 - INFO - Final memory usage: CPU 2709.1 MB, GPU 126.5 MB
2024-12-29 14:04:04,291 - INFO - Model training completed in 13.50s
2024-12-29 14:04:04,437 - INFO - Prediction completed in 0.15s
2024-12-29 14:04:04,446 - INFO - Poison rate 0.0 completed in 13.65s
2024-12-29 14:04:04,446 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:04:04,447 - INFO - Label flipping details:
2024-12-29 14:04:04,447 - INFO - - Source class: 1
2024-12-29 14:04:04,447 - INFO - - Target class: 0
2024-12-29 14:04:04,447 - INFO - - Available samples in source class: 955
2024-12-29 14:04:04,447 - INFO - - Requested samples to poison: 94
2024-12-29 14:04:04,447 - INFO - - Actual samples to flip: 94
2024-12-29 14:04:04,447 - INFO - - Samples remaining in source class: 861
2024-12-29 14:04:04,447 - INFO - Successfully flipped 94 labels from class 1 to 0
2024-12-29 14:04:04,448 - INFO - Total number of labels flipped: 94
2024-12-29 14:04:04,448 - INFO - Label flipping completed in 0.00s
2024-12-29 14:04:04,448 - INFO - Training set processing completed in 0.00s
2024-12-29 14:04:04,448 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:04:04,448 - INFO - Memory usage at start_fit: CPU 2709.1 MB, GPU 106.7 MB
2024-12-29 14:04:04,449 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:04:04,628 - INFO - Fitted scaler and transformed data
2024-12-29 14:04:04,628 - INFO - Scaling time: 0.18s
2024-12-29 14:04:04,638 - INFO - Number of unique classes: 10
2024-12-29 14:04:07,431 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3013
2024-12-29 14:04:10,266 - INFO - Epoch 2/10, Train Loss: 2.3006, Val Loss: 2.3001
2024-12-29 14:04:12,989 - INFO - Epoch 3/10, Train Loss: 2.2992, Val Loss: 2.2988
2024-12-29 14:04:15,876 - INFO - Epoch 4/10, Train Loss: 2.2978, Val Loss: 2.2975
2024-12-29 14:04:15,876 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:04:15,876 - INFO - Training completed in 11.43s
2024-12-29 14:04:15,876 - INFO - Final memory usage: CPU 2709.1 MB, GPU 126.5 MB
2024-12-29 14:04:15,877 - INFO - Model training completed in 11.43s
2024-12-29 14:04:16,021 - INFO - Prediction completed in 0.14s
2024-12-29 14:04:16,029 - INFO - Poison rate 0.01 completed in 11.58s
2024-12-29 14:04:16,029 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:04:16,030 - INFO - Label flipping details:
2024-12-29 14:04:16,030 - INFO - - Source class: 1
2024-12-29 14:04:16,030 - INFO - - Target class: 0
2024-12-29 14:04:16,030 - INFO - - Available samples in source class: 955
2024-12-29 14:04:16,030 - INFO - - Requested samples to poison: 284
2024-12-29 14:04:16,030 - INFO - - Actual samples to flip: 284
2024-12-29 14:04:16,030 - INFO - - Samples remaining in source class: 671
2024-12-29 14:04:16,030 - INFO - Successfully flipped 284 labels from class 1 to 0
2024-12-29 14:04:16,031 - INFO - Total number of labels flipped: 284
2024-12-29 14:04:16,031 - INFO - Label flipping completed in 0.00s
2024-12-29 14:04:16,031 - INFO - Training set processing completed in 0.00s
2024-12-29 14:04:16,031 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:04:16,032 - INFO - Memory usage at start_fit: CPU 2709.1 MB, GPU 106.7 MB
2024-12-29 14:04:16,032 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:04:16,203 - INFO - Fitted scaler and transformed data
2024-12-29 14:04:16,204 - INFO - Scaling time: 0.17s
2024-12-29 14:04:16,214 - INFO - Number of unique classes: 10
2024-12-29 14:04:19,468 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3014
2024-12-29 14:04:22,277 - INFO - Epoch 2/10, Train Loss: 2.3007, Val Loss: 2.3002
2024-12-29 14:04:25,158 - INFO - Epoch 3/10, Train Loss: 2.2993, Val Loss: 2.2990
2024-12-29 14:04:27,824 - INFO - Epoch 4/10, Train Loss: 2.2979, Val Loss: 2.2977
2024-12-29 14:04:27,825 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:04:27,825 - INFO - Training completed in 11.79s
2024-12-29 14:04:27,825 - INFO - Final memory usage: CPU 2709.1 MB, GPU 126.5 MB
2024-12-29 14:04:27,825 - INFO - Model training completed in 11.79s
2024-12-29 14:04:27,975 - INFO - Prediction completed in 0.15s
2024-12-29 14:04:27,984 - INFO - Poison rate 0.03 completed in 11.95s
2024-12-29 14:04:27,984 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:04:27,985 - INFO - Label flipping details:
2024-12-29 14:04:27,985 - INFO - - Source class: 1
2024-12-29 14:04:27,985 - INFO - - Target class: 0
2024-12-29 14:04:27,985 - INFO - - Available samples in source class: 955
2024-12-29 14:04:27,985 - INFO - - Requested samples to poison: 473
2024-12-29 14:04:27,985 - INFO - - Actual samples to flip: 473
2024-12-29 14:04:27,985 - INFO - - Samples remaining in source class: 482
2024-12-29 14:04:27,985 - INFO - Successfully flipped 473 labels from class 1 to 0
2024-12-29 14:04:27,985 - INFO - Total number of labels flipped: 473
2024-12-29 14:04:27,985 - INFO - Label flipping completed in 0.00s
2024-12-29 14:04:27,985 - INFO - Training set processing completed in 0.00s
2024-12-29 14:04:27,985 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:04:27,986 - INFO - Memory usage at start_fit: CPU 2709.1 MB, GPU 106.7 MB
2024-12-29 14:04:27,987 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:04:28,204 - INFO - Fitted scaler and transformed data
2024-12-29 14:04:28,204 - INFO - Scaling time: 0.22s
2024-12-29 14:04:28,215 - INFO - Number of unique classes: 10
2024-12-29 14:04:30,852 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3014
2024-12-29 14:04:33,509 - INFO - Epoch 2/10, Train Loss: 2.3007, Val Loss: 2.3001
2024-12-29 14:04:36,573 - INFO - Epoch 3/10, Train Loss: 2.2993, Val Loss: 2.2988
2024-12-29 14:04:39,100 - INFO - Epoch 4/10, Train Loss: 2.2979, Val Loss: 2.2975
2024-12-29 14:04:39,100 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:04:39,100 - INFO - Training completed in 11.11s
2024-12-29 14:04:39,100 - INFO - Final memory usage: CPU 2709.1 MB, GPU 126.5 MB
2024-12-29 14:04:39,101 - INFO - Model training completed in 11.12s
2024-12-29 14:04:39,248 - INFO - Prediction completed in 0.15s
2024-12-29 14:04:39,257 - INFO - Poison rate 0.05 completed in 11.27s
2024-12-29 14:04:39,258 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:04:39,258 - INFO - Label flipping details:
2024-12-29 14:04:39,259 - INFO - - Source class: 1
2024-12-29 14:04:39,259 - INFO - - Target class: 0
2024-12-29 14:04:39,259 - INFO - - Available samples in source class: 955
2024-12-29 14:04:39,259 - INFO - - Requested samples to poison: 662
2024-12-29 14:04:39,259 - INFO - - Actual samples to flip: 662
2024-12-29 14:04:39,259 - INFO - - Samples remaining in source class: 293
2024-12-29 14:04:39,259 - INFO - Successfully flipped 662 labels from class 1 to 0
2024-12-29 14:04:39,259 - INFO - Total number of labels flipped: 662
2024-12-29 14:04:39,259 - INFO - Label flipping completed in 0.00s
2024-12-29 14:04:39,259 - INFO - Training set processing completed in 0.00s
2024-12-29 14:04:39,259 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:04:39,260 - INFO - Memory usage at start_fit: CPU 2709.1 MB, GPU 106.7 MB
2024-12-29 14:04:39,260 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:04:39,435 - INFO - Fitted scaler and transformed data
2024-12-29 14:04:39,435 - INFO - Scaling time: 0.17s
2024-12-29 14:04:39,445 - INFO - Number of unique classes: 10
2024-12-29 14:04:42,368 - INFO - Epoch 1/10, Train Loss: 2.3019, Val Loss: 2.3013
2024-12-29 14:04:44,728 - INFO - Epoch 2/10, Train Loss: 2.3005, Val Loss: 2.3000
2024-12-29 14:04:47,474 - INFO - Epoch 3/10, Train Loss: 2.2991, Val Loss: 2.2987
2024-12-29 14:04:50,112 - INFO - Epoch 4/10, Train Loss: 2.2977, Val Loss: 2.2974
2024-12-29 14:04:50,112 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:04:50,112 - INFO - Training completed in 10.85s
2024-12-29 14:04:50,113 - INFO - Final memory usage: CPU 2709.1 MB, GPU 126.5 MB
2024-12-29 14:04:50,113 - INFO - Model training completed in 10.85s
2024-12-29 14:04:50,312 - INFO - Prediction completed in 0.20s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 14:04:50,325 - INFO - Poison rate 0.07 completed in 11.07s
2024-12-29 14:04:50,325 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:04:50,327 - INFO - Label flipping details:
2024-12-29 14:04:50,327 - INFO - - Source class: 1
2024-12-29 14:04:50,327 - INFO - - Target class: 0
2024-12-29 14:04:50,328 - INFO - - Available samples in source class: 955
2024-12-29 14:04:50,328 - INFO - - Requested samples to poison: 946
2024-12-29 14:04:50,328 - INFO - - Actual samples to flip: 946
2024-12-29 14:04:50,328 - INFO - - Samples remaining in source class: 9
2024-12-29 14:04:50,329 - INFO - Successfully flipped 946 labels from class 1 to 0
2024-12-29 14:04:50,329 - INFO - Total number of labels flipped: 946
2024-12-29 14:04:50,330 - INFO - Label flipping completed in 0.00s
2024-12-29 14:04:50,330 - INFO - Training set processing completed in 0.00s
2024-12-29 14:04:50,330 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:04:50,331 - INFO - Memory usage at start_fit: CPU 2709.1 MB, GPU 106.7 MB
2024-12-29 14:04:50,332 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:04:50,518 - INFO - Fitted scaler and transformed data
2024-12-29 14:04:50,519 - INFO - Scaling time: 0.19s
2024-12-29 14:04:50,530 - INFO - Number of unique classes: 10
2024-12-29 14:04:54,367 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3013
2024-12-29 14:04:57,431 - INFO - Epoch 2/10, Train Loss: 2.3005, Val Loss: 2.2999
2024-12-29 14:05:00,782 - INFO - Epoch 3/10, Train Loss: 2.2991, Val Loss: 2.2985
2024-12-29 14:05:03,834 - INFO - Epoch 4/10, Train Loss: 2.2976, Val Loss: 2.2971
2024-12-29 14:05:03,834 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:05:03,834 - INFO - Training completed in 13.50s
2024-12-29 14:05:03,834 - INFO - Final memory usage: CPU 2709.1 MB, GPU 126.5 MB
2024-12-29 14:05:03,835 - INFO - Model training completed in 13.50s
2024-12-29 14:05:03,986 - INFO - Prediction completed in 0.15s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 14:05:03,995 - INFO - Poison rate 0.1 completed in 13.67s
2024-12-29 14:05:03,996 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:05:03,996 - INFO - Label flipping details:
2024-12-29 14:05:03,996 - INFO - - Source class: 1
2024-12-29 14:05:03,996 - INFO - - Target class: 0
2024-12-29 14:05:03,997 - INFO - - Available samples in source class: 955
2024-12-29 14:05:03,997 - INFO - - Requested samples to poison: 1893
2024-12-29 14:05:03,997 - INFO - - Actual samples to flip: 954
2024-12-29 14:05:03,997 - INFO - - Samples remaining in source class: 1
2024-12-29 14:05:03,997 - INFO - Successfully flipped 954 labels from class 1 to 0
2024-12-29 14:05:03,997 - INFO - Total number of labels flipped: 954
2024-12-29 14:05:03,997 - INFO - Label flipping completed in 0.00s
2024-12-29 14:05:03,997 - INFO - Training set processing completed in 0.00s
2024-12-29 14:05:03,997 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:05:03,998 - INFO - Memory usage at start_fit: CPU 2709.1 MB, GPU 106.7 MB
2024-12-29 14:05:03,998 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:05:04,196 - INFO - Fitted scaler and transformed data
2024-12-29 14:05:04,196 - INFO - Scaling time: 0.20s
2024-12-29 14:05:04,207 - INFO - Number of unique classes: 10
2024-12-29 14:05:07,222 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3012
2024-12-29 14:05:10,252 - INFO - Epoch 2/10, Train Loss: 2.3005, Val Loss: 2.2999
2024-12-29 14:05:12,772 - INFO - Epoch 3/10, Train Loss: 2.2990, Val Loss: 2.2985
2024-12-29 14:05:15,674 - INFO - Epoch 4/10, Train Loss: 2.2975, Val Loss: 2.2971
2024-12-29 14:05:15,675 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:05:15,675 - INFO - Training completed in 11.68s
2024-12-29 14:05:15,675 - INFO - Final memory usage: CPU 2709.1 MB, GPU 126.5 MB
2024-12-29 14:05:15,676 - INFO - Model training completed in 11.68s
2024-12-29 14:05:15,858 - INFO - Prediction completed in 0.18s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 14:05:15,868 - INFO - Poison rate 0.2 completed in 11.87s
2024-12-29 14:05:15,875 - INFO - Loaded 364 existing results
2024-12-29 14:05:15,875 - INFO - Total results to save: 371
2024-12-29 14:05:15,876 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:05:15,889 - INFO - Saved 371 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:05:15,890 - INFO - Total evaluation time: 116.46s
2024-12-29 14:05:15,892 - INFO - 
Progress: 56.2% - Evaluating ImageNette with RandomForest (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:05:16,087 - INFO - Loading datasets...
2024-12-29 14:05:16,108 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:05:16,109 - INFO - Extracting validation features...
2024-12-29 14:05:16,109 - INFO - Extracting features from 3925 samples...
2024-12-29 14:05:25,457 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:05:25,460 - INFO - Validation feature extraction completed in 9.35s
2024-12-29 14:05:25,460 - INFO - Extracting training features...
2024-12-29 14:05:25,460 - INFO - Extracting features from 9469 samples...
2024-12-29 14:05:47,097 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:05:47,102 - INFO - Training feature extraction completed in 21.64s
2024-12-29 14:05:47,103 - INFO - Creating model for classifier: RandomForest
2024-12-29 14:05:47,103 - INFO - Using device: cuda
2024-12-29 14:05:47,104 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:05:47,104 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:05:47,104 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:05:47,612 - INFO - Feature scaling completed in 0.51s
2024-12-29 14:05:47,613 - INFO - Starting feature selection (k=50)
2024-12-29 14:05:47,621 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:05:47,621 - INFO - Starting anomaly detection
2024-12-29 14:05:49,557 - INFO - Anomaly detection completed in 1.94s
2024-12-29 14:05:49,557 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:05:49,557 - INFO - Total fit_transform time: 2.45s
2024-12-29 14:05:49,557 - INFO - Training set processing completed in 2.45s
2024-12-29 14:05:49,557 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:05:49,558 - INFO - Memory usage at start_fit: CPU 2709.0 MB, GPU 104.0 MB
2024-12-29 14:05:49,559 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:05:49,747 - INFO - Fitted scaler and transformed data
2024-12-29 14:05:49,747 - INFO - Scaling time: 0.19s
2024-12-29 14:05:49,754 - INFO - Number of unique classes: 10
2024-12-29 14:05:52,324 - INFO - Epoch 1/10, Train Loss: 2.1862, Val Loss: 2.3013
2024-12-29 14:05:55,093 - INFO - Epoch 2/10, Train Loss: 2.1849, Val Loss: 2.3001
2024-12-29 14:05:58,077 - INFO - Epoch 3/10, Train Loss: 2.1836, Val Loss: 2.2988
2024-12-29 14:06:01,839 - INFO - Epoch 4/10, Train Loss: 2.1822, Val Loss: 2.2974
2024-12-29 14:06:01,839 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:06:01,839 - INFO - Training completed in 12.28s
2024-12-29 14:06:01,840 - INFO - Final memory usage: CPU 2709.0 MB, GPU 125.9 MB
2024-12-29 14:06:01,840 - INFO - Model training completed in 12.28s
2024-12-29 14:06:01,988 - INFO - Prediction completed in 0.15s
2024-12-29 14:06:01,997 - INFO - Poison rate 0.0 completed in 14.89s
2024-12-29 14:06:01,997 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:06:01,998 - INFO - Label flipping details:
2024-12-29 14:06:01,998 - INFO - - Source class: 1
2024-12-29 14:06:01,998 - INFO - - Target class: 0
2024-12-29 14:06:01,998 - INFO - - Available samples in source class: 955
2024-12-29 14:06:01,998 - INFO - - Requested samples to poison: 94
2024-12-29 14:06:01,998 - INFO - - Actual samples to flip: 94
2024-12-29 14:06:01,998 - INFO - - Samples remaining in source class: 861
2024-12-29 14:06:01,998 - INFO - Successfully flipped 94 labels from class 1 to 0
2024-12-29 14:06:01,998 - INFO - Total number of labels flipped: 94
2024-12-29 14:06:01,999 - INFO - Label flipping completed in 0.00s
2024-12-29 14:06:01,999 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:06:01,999 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:06:02,507 - INFO - Feature scaling completed in 0.51s
2024-12-29 14:06:02,507 - INFO - Starting feature selection (k=50)
2024-12-29 14:06:02,520 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:06:02,520 - INFO - Starting anomaly detection
2024-12-29 14:06:06,707 - INFO - Anomaly detection completed in 4.19s
2024-12-29 14:06:06,707 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:06:06,707 - INFO - Total fit_transform time: 4.71s
2024-12-29 14:06:06,707 - INFO - Training set processing completed in 4.71s
2024-12-29 14:06:06,707 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:06:06,708 - INFO - Memory usage at start_fit: CPU 2709.0 MB, GPU 106.0 MB
2024-12-29 14:06:06,708 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:06:06,904 - INFO - Fitted scaler and transformed data
2024-12-29 14:06:06,904 - INFO - Scaling time: 0.20s
2024-12-29 14:06:06,912 - INFO - Number of unique classes: 10
2024-12-29 14:06:10,357 - INFO - Epoch 1/10, Train Loss: 2.1883, Val Loss: 2.3014
2024-12-29 14:06:12,975 - INFO - Epoch 2/10, Train Loss: 2.1869, Val Loss: 2.3001
2024-12-29 14:06:15,794 - INFO - Epoch 3/10, Train Loss: 2.1856, Val Loss: 2.2988
2024-12-29 14:06:18,987 - INFO - Epoch 4/10, Train Loss: 2.1843, Val Loss: 2.2975
2024-12-29 14:06:18,987 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:06:18,987 - INFO - Training completed in 12.28s
2024-12-29 14:06:18,988 - INFO - Final memory usage: CPU 2709.0 MB, GPU 125.9 MB
2024-12-29 14:06:18,988 - INFO - Model training completed in 12.28s
2024-12-29 14:06:19,140 - INFO - Prediction completed in 0.15s
2024-12-29 14:06:19,149 - INFO - Poison rate 0.01 completed in 17.15s
2024-12-29 14:06:19,149 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:06:19,150 - INFO - Label flipping details:
2024-12-29 14:06:19,150 - INFO - - Source class: 1
2024-12-29 14:06:19,150 - INFO - - Target class: 0
2024-12-29 14:06:19,150 - INFO - - Available samples in source class: 955
2024-12-29 14:06:19,150 - INFO - - Requested samples to poison: 284
2024-12-29 14:06:19,150 - INFO - - Actual samples to flip: 284
2024-12-29 14:06:19,150 - INFO - - Samples remaining in source class: 671
2024-12-29 14:06:19,150 - INFO - Successfully flipped 284 labels from class 1 to 0
2024-12-29 14:06:19,150 - INFO - Total number of labels flipped: 284
2024-12-29 14:06:19,150 - INFO - Label flipping completed in 0.00s
2024-12-29 14:06:19,150 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:06:19,151 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:06:19,682 - INFO - Feature scaling completed in 0.53s
2024-12-29 14:06:19,682 - INFO - Starting feature selection (k=50)
2024-12-29 14:06:19,696 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:06:19,696 - INFO - Starting anomaly detection
2024-12-29 14:06:23,879 - INFO - Anomaly detection completed in 4.18s
2024-12-29 14:06:23,879 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:06:23,879 - INFO - Total fit_transform time: 4.73s
2024-12-29 14:06:23,880 - INFO - Training set processing completed in 4.73s
2024-12-29 14:06:23,880 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:06:23,881 - INFO - Memory usage at start_fit: CPU 2709.0 MB, GPU 106.0 MB
2024-12-29 14:06:23,881 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:06:24,084 - INFO - Fitted scaler and transformed data
2024-12-29 14:06:24,084 - INFO - Scaling time: 0.20s
2024-12-29 14:06:24,091 - INFO - Number of unique classes: 10
2024-12-29 14:06:26,756 - INFO - Epoch 1/10, Train Loss: 2.1870, Val Loss: 2.3013
2024-12-29 14:06:29,389 - INFO - Epoch 2/10, Train Loss: 2.1856, Val Loss: 2.3001
2024-12-29 14:06:33,444 - INFO - Epoch 3/10, Train Loss: 2.1843, Val Loss: 2.2988
2024-12-29 14:06:36,638 - INFO - Epoch 4/10, Train Loss: 2.1830, Val Loss: 2.2975
2024-12-29 14:06:36,639 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:06:36,639 - INFO - Training completed in 12.76s
2024-12-29 14:06:36,639 - INFO - Final memory usage: CPU 2709.0 MB, GPU 125.9 MB
2024-12-29 14:06:36,639 - INFO - Model training completed in 12.76s
2024-12-29 14:06:36,796 - INFO - Prediction completed in 0.16s
2024-12-29 14:06:36,804 - INFO - Poison rate 0.03 completed in 17.66s
2024-12-29 14:06:36,804 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:06:36,805 - INFO - Label flipping details:
2024-12-29 14:06:36,805 - INFO - - Source class: 1
2024-12-29 14:06:36,805 - INFO - - Target class: 0
2024-12-29 14:06:36,805 - INFO - - Available samples in source class: 955
2024-12-29 14:06:36,805 - INFO - - Requested samples to poison: 473
2024-12-29 14:06:36,805 - INFO - - Actual samples to flip: 473
2024-12-29 14:06:36,805 - INFO - - Samples remaining in source class: 482
2024-12-29 14:06:36,805 - INFO - Successfully flipped 473 labels from class 1 to 0
2024-12-29 14:06:36,806 - INFO - Total number of labels flipped: 473
2024-12-29 14:06:36,806 - INFO - Label flipping completed in 0.00s
2024-12-29 14:06:36,806 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:06:36,806 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:06:37,367 - INFO - Feature scaling completed in 0.56s
2024-12-29 14:06:37,368 - INFO - Starting feature selection (k=50)
2024-12-29 14:06:37,381 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:06:37,381 - INFO - Starting anomaly detection
2024-12-29 14:06:41,091 - INFO - Anomaly detection completed in 3.71s
2024-12-29 14:06:41,091 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:06:41,091 - INFO - Total fit_transform time: 4.29s
2024-12-29 14:06:41,091 - INFO - Training set processing completed in 4.29s
2024-12-29 14:06:41,091 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:06:41,092 - INFO - Memory usage at start_fit: CPU 2709.0 MB, GPU 106.0 MB
2024-12-29 14:06:41,092 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:06:41,274 - INFO - Fitted scaler and transformed data
2024-12-29 14:06:41,275 - INFO - Scaling time: 0.18s
2024-12-29 14:06:41,283 - INFO - Number of unique classes: 10
2024-12-29 14:06:45,115 - INFO - Epoch 1/10, Train Loss: 2.1863, Val Loss: 2.3013
2024-12-29 14:06:48,573 - INFO - Epoch 2/10, Train Loss: 2.1850, Val Loss: 2.3000
2024-12-29 14:06:51,519 - INFO - Epoch 3/10, Train Loss: 2.1837, Val Loss: 2.2987
2024-12-29 14:06:54,341 - INFO - Epoch 4/10, Train Loss: 2.1824, Val Loss: 2.2974
2024-12-29 14:06:54,342 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:06:54,342 - INFO - Training completed in 13.25s
2024-12-29 14:06:54,342 - INFO - Final memory usage: CPU 2709.0 MB, GPU 125.9 MB
2024-12-29 14:06:54,342 - INFO - Model training completed in 13.25s
2024-12-29 14:06:54,489 - INFO - Prediction completed in 0.15s
2024-12-29 14:06:54,499 - INFO - Poison rate 0.05 completed in 17.69s
2024-12-29 14:06:54,499 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:06:54,500 - INFO - Label flipping details:
2024-12-29 14:06:54,500 - INFO - - Source class: 1
2024-12-29 14:06:54,500 - INFO - - Target class: 0
2024-12-29 14:06:54,500 - INFO - - Available samples in source class: 955
2024-12-29 14:06:54,500 - INFO - - Requested samples to poison: 662
2024-12-29 14:06:54,500 - INFO - - Actual samples to flip: 662
2024-12-29 14:06:54,500 - INFO - - Samples remaining in source class: 293
2024-12-29 14:06:54,500 - INFO - Successfully flipped 662 labels from class 1 to 0
2024-12-29 14:06:54,500 - INFO - Total number of labels flipped: 662
2024-12-29 14:06:54,500 - INFO - Label flipping completed in 0.00s
2024-12-29 14:06:54,501 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:06:54,501 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:06:55,078 - INFO - Feature scaling completed in 0.58s
2024-12-29 14:06:55,078 - INFO - Starting feature selection (k=50)
2024-12-29 14:06:55,091 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:06:55,092 - INFO - Starting anomaly detection
2024-12-29 14:06:59,391 - INFO - Anomaly detection completed in 4.30s
2024-12-29 14:06:59,391 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:06:59,391 - INFO - Total fit_transform time: 4.89s
2024-12-29 14:06:59,391 - INFO - Training set processing completed in 4.89s
2024-12-29 14:06:59,391 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:06:59,392 - INFO - Memory usage at start_fit: CPU 2709.0 MB, GPU 106.0 MB
2024-12-29 14:06:59,393 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:06:59,573 - INFO - Fitted scaler and transformed data
2024-12-29 14:06:59,574 - INFO - Scaling time: 0.18s
2024-12-29 14:06:59,580 - INFO - Number of unique classes: 10
2024-12-29 14:07:02,673 - INFO - Epoch 1/10, Train Loss: 2.1869, Val Loss: 2.3014
2024-12-29 14:07:05,313 - INFO - Epoch 2/10, Train Loss: 2.1856, Val Loss: 2.3001
2024-12-29 14:07:07,940 - INFO - Epoch 3/10, Train Loss: 2.1843, Val Loss: 2.2989
2024-12-29 14:07:10,935 - INFO - Epoch 4/10, Train Loss: 2.1829, Val Loss: 2.2976
2024-12-29 14:07:10,936 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:07:10,936 - INFO - Training completed in 11.54s
2024-12-29 14:07:10,936 - INFO - Final memory usage: CPU 2709.0 MB, GPU 125.9 MB
2024-12-29 14:07:10,936 - INFO - Model training completed in 11.55s
2024-12-29 14:07:11,092 - INFO - Prediction completed in 0.16s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 14:07:11,101 - INFO - Poison rate 0.07 completed in 16.60s
2024-12-29 14:07:11,101 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:07:11,102 - INFO - Label flipping details:
2024-12-29 14:07:11,102 - INFO - - Source class: 1
2024-12-29 14:07:11,102 - INFO - - Target class: 0
2024-12-29 14:07:11,102 - INFO - - Available samples in source class: 955
2024-12-29 14:07:11,102 - INFO - - Requested samples to poison: 946
2024-12-29 14:07:11,102 - INFO - - Actual samples to flip: 946
2024-12-29 14:07:11,102 - INFO - - Samples remaining in source class: 9
2024-12-29 14:07:11,102 - INFO - Successfully flipped 946 labels from class 1 to 0
2024-12-29 14:07:11,102 - INFO - Total number of labels flipped: 946
2024-12-29 14:07:11,102 - INFO - Label flipping completed in 0.00s
2024-12-29 14:07:11,103 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:07:11,103 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:07:11,644 - INFO - Feature scaling completed in 0.54s
2024-12-29 14:07:11,644 - INFO - Starting feature selection (k=50)
2024-12-29 14:07:11,658 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:07:11,658 - INFO - Starting anomaly detection
2024-12-29 14:07:15,594 - INFO - Anomaly detection completed in 3.94s
2024-12-29 14:07:15,595 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:07:15,595 - INFO - Total fit_transform time: 4.49s
2024-12-29 14:07:15,595 - INFO - Training set processing completed in 4.49s
2024-12-29 14:07:15,595 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:07:15,596 - INFO - Memory usage at start_fit: CPU 2709.0 MB, GPU 106.0 MB
2024-12-29 14:07:15,596 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:07:15,810 - INFO - Fitted scaler and transformed data
2024-12-29 14:07:15,810 - INFO - Scaling time: 0.21s
2024-12-29 14:07:15,817 - INFO - Number of unique classes: 10
2024-12-29 14:07:19,205 - INFO - Epoch 1/10, Train Loss: 2.1875, Val Loss: 2.3012
2024-12-29 14:07:22,630 - INFO - Epoch 2/10, Train Loss: 2.1861, Val Loss: 2.2998
2024-12-29 14:07:25,634 - INFO - Epoch 3/10, Train Loss: 2.1847, Val Loss: 2.2984
2024-12-29 14:07:28,777 - INFO - Epoch 4/10, Train Loss: 2.1833, Val Loss: 2.2970
2024-12-29 14:07:28,778 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:07:28,778 - INFO - Training completed in 13.18s
2024-12-29 14:07:28,778 - INFO - Final memory usage: CPU 2709.0 MB, GPU 125.9 MB
2024-12-29 14:07:28,778 - INFO - Model training completed in 13.18s
2024-12-29 14:07:29,022 - INFO - Prediction completed in 0.24s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 14:07:29,031 - INFO - Poison rate 0.1 completed in 17.93s
2024-12-29 14:07:29,031 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:07:29,032 - INFO - Label flipping details:
2024-12-29 14:07:29,032 - INFO - - Source class: 1
2024-12-29 14:07:29,032 - INFO - - Target class: 0
2024-12-29 14:07:29,032 - INFO - - Available samples in source class: 955
2024-12-29 14:07:29,032 - INFO - - Requested samples to poison: 1893
2024-12-29 14:07:29,032 - INFO - - Actual samples to flip: 954
2024-12-29 14:07:29,032 - INFO - - Samples remaining in source class: 1
2024-12-29 14:07:29,032 - INFO - Successfully flipped 954 labels from class 1 to 0
2024-12-29 14:07:29,032 - INFO - Total number of labels flipped: 954
2024-12-29 14:07:29,032 - INFO - Label flipping completed in 0.00s
2024-12-29 14:07:29,032 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:07:29,033 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:07:29,600 - INFO - Feature scaling completed in 0.57s
2024-12-29 14:07:29,600 - INFO - Starting feature selection (k=50)
2024-12-29 14:07:29,613 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:07:29,614 - INFO - Starting anomaly detection
2024-12-29 14:07:33,254 - INFO - Anomaly detection completed in 3.64s
2024-12-29 14:07:33,255 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:07:33,255 - INFO - Total fit_transform time: 4.22s
2024-12-29 14:07:33,255 - INFO - Training set processing completed in 4.22s
2024-12-29 14:07:33,255 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:07:33,256 - INFO - Memory usage at start_fit: CPU 2709.0 MB, GPU 106.0 MB
2024-12-29 14:07:33,257 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:07:33,441 - INFO - Fitted scaler and transformed data
2024-12-29 14:07:33,441 - INFO - Scaling time: 0.18s
2024-12-29 14:07:33,448 - INFO - Number of unique classes: 10
2024-12-29 14:07:36,286 - INFO - Epoch 1/10, Train Loss: 2.1880, Val Loss: 2.3012
2024-12-29 14:07:40,027 - INFO - Epoch 2/10, Train Loss: 2.1866, Val Loss: 2.2999
2024-12-29 14:07:42,626 - INFO - Epoch 3/10, Train Loss: 2.1852, Val Loss: 2.2985
2024-12-29 14:07:45,514 - INFO - Epoch 4/10, Train Loss: 2.1838, Val Loss: 2.2972
2024-12-29 14:07:45,514 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:07:45,515 - INFO - Training completed in 12.26s
2024-12-29 14:07:45,515 - INFO - Final memory usage: CPU 2709.0 MB, GPU 125.9 MB
2024-12-29 14:07:45,515 - INFO - Model training completed in 12.26s
2024-12-29 14:07:45,673 - INFO - Prediction completed in 0.16s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 14:07:45,682 - INFO - Poison rate 0.2 completed in 16.65s
2024-12-29 14:07:45,689 - INFO - Loaded 371 existing results
2024-12-29 14:07:45,689 - INFO - Total results to save: 378
2024-12-29 14:07:45,690 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:07:45,702 - INFO - Saved 378 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:07:45,702 - INFO - Total evaluation time: 149.62s
2024-12-29 14:07:45,704 - INFO - 
Progress: 57.3% - Evaluating ImageNette with KNeighbors (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:07:45,887 - INFO - Loading datasets...
2024-12-29 14:07:45,908 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:07:45,908 - INFO - Extracting validation features...
2024-12-29 14:07:45,908 - INFO - Extracting features from 3925 samples...
2024-12-29 14:07:55,402 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:07:55,408 - INFO - Validation feature extraction completed in 9.50s
2024-12-29 14:07:55,408 - INFO - Extracting training features...
2024-12-29 14:07:55,409 - INFO - Extracting features from 9469 samples...
2024-12-29 14:08:17,635 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:08:17,640 - INFO - Training feature extraction completed in 22.23s
2024-12-29 14:08:17,640 - INFO - Creating model for classifier: KNeighbors
2024-12-29 14:08:17,641 - INFO - Using device: cuda
2024-12-29 14:08:17,641 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:08:17,641 - INFO - Training set processing completed in 0.00s
2024-12-29 14:08:17,641 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:08:17,643 - INFO - Memory usage at start_fit: CPU 2681.5 MB, GPU 104.6 MB
2024-12-29 14:08:17,643 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:08:17,858 - INFO - Fitted scaler and transformed data
2024-12-29 14:08:17,858 - INFO - Scaling time: 0.21s
2024-12-29 14:08:17,866 - INFO - Training completed in 0.22s
2024-12-29 14:08:17,866 - INFO - Final memory usage: CPU 2709.1 MB, GPU 123.2 MB
2024-12-29 14:08:17,867 - INFO - Model training completed in 0.23s
2024-12-29 14:08:17,941 - INFO - Prediction completed in 0.07s
2024-12-29 14:08:17,950 - INFO - Poison rate 0.0 completed in 0.31s
2024-12-29 14:08:17,950 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:08:17,951 - INFO - Label flipping details:
2024-12-29 14:08:17,951 - INFO - - Source class: 1
2024-12-29 14:08:17,951 - INFO - - Target class: 0
2024-12-29 14:08:17,951 - INFO - - Available samples in source class: 955
2024-12-29 14:08:17,951 - INFO - - Requested samples to poison: 94
2024-12-29 14:08:17,951 - INFO - - Actual samples to flip: 94
2024-12-29 14:08:17,951 - INFO - - Samples remaining in source class: 861
2024-12-29 14:08:17,952 - INFO - Successfully flipped 94 labels from class 1 to 0
2024-12-29 14:08:17,952 - INFO - Total number of labels flipped: 94
2024-12-29 14:08:17,952 - INFO - Label flipping completed in 0.00s
2024-12-29 14:08:17,952 - INFO - Training set processing completed in 0.00s
2024-12-29 14:08:17,952 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:08:17,953 - INFO - Memory usage at start_fit: CPU 2709.1 MB, GPU 123.2 MB
2024-12-29 14:08:17,953 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:08:18,127 - INFO - Fitted scaler and transformed data
2024-12-29 14:08:18,127 - INFO - Scaling time: 0.17s
2024-12-29 14:08:18,133 - INFO - Training completed in 0.18s
2024-12-29 14:08:18,134 - INFO - Final memory usage: CPU 2709.1 MB, GPU 123.2 MB
2024-12-29 14:08:18,134 - INFO - Model training completed in 0.18s
2024-12-29 14:08:18,208 - INFO - Prediction completed in 0.07s
2024-12-29 14:08:18,216 - INFO - Poison rate 0.01 completed in 0.27s
2024-12-29 14:08:18,217 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:08:18,217 - INFO - Label flipping details:
2024-12-29 14:08:18,217 - INFO - - Source class: 1
2024-12-29 14:08:18,217 - INFO - - Target class: 0
2024-12-29 14:08:18,217 - INFO - - Available samples in source class: 955
2024-12-29 14:08:18,217 - INFO - - Requested samples to poison: 284
2024-12-29 14:08:18,217 - INFO - - Actual samples to flip: 284
2024-12-29 14:08:18,218 - INFO - - Samples remaining in source class: 671
2024-12-29 14:08:18,218 - INFO - Successfully flipped 284 labels from class 1 to 0
2024-12-29 14:08:18,218 - INFO - Total number of labels flipped: 284
2024-12-29 14:08:18,218 - INFO - Label flipping completed in 0.00s
2024-12-29 14:08:18,218 - INFO - Training set processing completed in 0.00s
2024-12-29 14:08:18,218 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:08:18,219 - INFO - Memory usage at start_fit: CPU 2709.1 MB, GPU 123.2 MB
2024-12-29 14:08:18,219 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:08:18,399 - INFO - Fitted scaler and transformed data
2024-12-29 14:08:18,400 - INFO - Scaling time: 0.18s
2024-12-29 14:08:18,406 - INFO - Training completed in 0.19s
2024-12-29 14:08:18,406 - INFO - Final memory usage: CPU 2709.1 MB, GPU 123.2 MB
2024-12-29 14:08:18,407 - INFO - Model training completed in 0.19s
2024-12-29 14:08:18,509 - INFO - Prediction completed in 0.10s
2024-12-29 14:08:18,526 - INFO - Poison rate 0.03 completed in 0.31s
2024-12-29 14:08:18,526 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:08:18,528 - INFO - Label flipping details:
2024-12-29 14:08:18,528 - INFO - - Source class: 1
2024-12-29 14:08:18,528 - INFO - - Target class: 0
2024-12-29 14:08:18,528 - INFO - - Available samples in source class: 955
2024-12-29 14:08:18,528 - INFO - - Requested samples to poison: 473
2024-12-29 14:08:18,528 - INFO - - Actual samples to flip: 473
2024-12-29 14:08:18,528 - INFO - - Samples remaining in source class: 482
2024-12-29 14:08:18,528 - INFO - Successfully flipped 473 labels from class 1 to 0
2024-12-29 14:08:18,529 - INFO - Total number of labels flipped: 473
2024-12-29 14:08:18,529 - INFO - Label flipping completed in 0.00s
2024-12-29 14:08:18,529 - INFO - Training set processing completed in 0.00s
2024-12-29 14:08:18,529 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:08:18,530 - INFO - Memory usage at start_fit: CPU 2709.1 MB, GPU 123.2 MB
2024-12-29 14:08:18,530 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:08:18,701 - INFO - Fitted scaler and transformed data
2024-12-29 14:08:18,702 - INFO - Scaling time: 0.17s
2024-12-29 14:08:18,708 - INFO - Training completed in 0.18s
2024-12-29 14:08:18,708 - INFO - Final memory usage: CPU 2709.1 MB, GPU 123.2 MB
2024-12-29 14:08:18,709 - INFO - Model training completed in 0.18s
2024-12-29 14:08:18,783 - INFO - Prediction completed in 0.07s
2024-12-29 14:08:18,792 - INFO - Poison rate 0.05 completed in 0.27s
2024-12-29 14:08:18,792 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:08:18,793 - INFO - Label flipping details:
2024-12-29 14:08:18,793 - INFO - - Source class: 1
2024-12-29 14:08:18,793 - INFO - - Target class: 0
2024-12-29 14:08:18,793 - INFO - - Available samples in source class: 955
2024-12-29 14:08:18,793 - INFO - - Requested samples to poison: 662
2024-12-29 14:08:18,793 - INFO - - Actual samples to flip: 662
2024-12-29 14:08:18,793 - INFO - - Samples remaining in source class: 293
2024-12-29 14:08:18,793 - INFO - Successfully flipped 662 labels from class 1 to 0
2024-12-29 14:08:18,793 - INFO - Total number of labels flipped: 662
2024-12-29 14:08:18,793 - INFO - Label flipping completed in 0.00s
2024-12-29 14:08:18,793 - INFO - Training set processing completed in 0.00s
2024-12-29 14:08:18,793 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:08:18,794 - INFO - Memory usage at start_fit: CPU 2709.1 MB, GPU 123.2 MB
2024-12-29 14:08:18,794 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:08:19,008 - INFO - Fitted scaler and transformed data
2024-12-29 14:08:19,008 - INFO - Scaling time: 0.21s
2024-12-29 14:08:19,014 - INFO - Training completed in 0.22s
2024-12-29 14:08:19,015 - INFO - Final memory usage: CPU 2709.1 MB, GPU 123.2 MB
2024-12-29 14:08:19,015 - INFO - Model training completed in 0.22s
2024-12-29 14:08:19,127 - INFO - Prediction completed in 0.11s
2024-12-29 14:08:19,152 - INFO - Poison rate 0.07 completed in 0.36s
2024-12-29 14:08:19,152 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:08:19,153 - INFO - Label flipping details:
2024-12-29 14:08:19,154 - INFO - - Source class: 1
2024-12-29 14:08:19,154 - INFO - - Target class: 0
2024-12-29 14:08:19,154 - INFO - - Available samples in source class: 955
2024-12-29 14:08:19,154 - INFO - - Requested samples to poison: 946
2024-12-29 14:08:19,154 - INFO - - Actual samples to flip: 946
2024-12-29 14:08:19,154 - INFO - - Samples remaining in source class: 9
2024-12-29 14:08:19,155 - INFO - Successfully flipped 946 labels from class 1 to 0
2024-12-29 14:08:19,155 - INFO - Total number of labels flipped: 946
2024-12-29 14:08:19,155 - INFO - Label flipping completed in 0.00s
2024-12-29 14:08:19,155 - INFO - Training set processing completed in 0.00s
2024-12-29 14:08:19,155 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:08:19,156 - INFO - Memory usage at start_fit: CPU 2709.1 MB, GPU 123.2 MB
2024-12-29 14:08:19,156 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:08:19,330 - INFO - Fitted scaler and transformed data
2024-12-29 14:08:19,330 - INFO - Scaling time: 0.17s
2024-12-29 14:08:19,336 - INFO - Training completed in 0.18s
2024-12-29 14:08:19,337 - INFO - Final memory usage: CPU 2709.1 MB, GPU 123.2 MB
2024-12-29 14:08:19,337 - INFO - Model training completed in 0.18s
2024-12-29 14:08:19,410 - INFO - Prediction completed in 0.07s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 14:08:19,421 - INFO - Poison rate 0.1 completed in 0.27s
2024-12-29 14:08:19,421 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:08:19,421 - INFO - Label flipping details:
2024-12-29 14:08:19,422 - INFO - - Source class: 1
2024-12-29 14:08:19,422 - INFO - - Target class: 0
2024-12-29 14:08:19,422 - INFO - - Available samples in source class: 955
2024-12-29 14:08:19,422 - INFO - - Requested samples to poison: 1893
2024-12-29 14:08:19,422 - INFO - - Actual samples to flip: 954
2024-12-29 14:08:19,422 - INFO - - Samples remaining in source class: 1
2024-12-29 14:08:19,422 - INFO - Successfully flipped 954 labels from class 1 to 0
2024-12-29 14:08:19,422 - INFO - Total number of labels flipped: 954
2024-12-29 14:08:19,422 - INFO - Label flipping completed in 0.00s
2024-12-29 14:08:19,422 - INFO - Training set processing completed in 0.00s
2024-12-29 14:08:19,422 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:08:19,423 - INFO - Memory usage at start_fit: CPU 2709.1 MB, GPU 123.2 MB
2024-12-29 14:08:19,423 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:08:19,636 - INFO - Fitted scaler and transformed data
2024-12-29 14:08:19,636 - INFO - Scaling time: 0.21s
2024-12-29 14:08:19,642 - INFO - Training completed in 0.22s
2024-12-29 14:08:19,642 - INFO - Final memory usage: CPU 2709.1 MB, GPU 123.2 MB
2024-12-29 14:08:19,643 - INFO - Model training completed in 0.22s
2024-12-29 14:08:19,719 - INFO - Prediction completed in 0.08s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 14:08:19,729 - INFO - Poison rate 0.2 completed in 0.31s
2024-12-29 14:08:19,737 - INFO - Loaded 378 existing results
2024-12-29 14:08:19,737 - INFO - Total results to save: 385
2024-12-29 14:08:19,738 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:08:19,752 - INFO - Saved 385 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:08:19,753 - INFO - Total evaluation time: 33.87s
2024-12-29 14:08:19,754 - INFO - 
Progress: 58.3% - Evaluating ImageNette with KNeighbors (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:08:19,927 - INFO - Loading datasets...
2024-12-29 14:08:19,949 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:08:19,949 - INFO - Extracting validation features...
2024-12-29 14:08:19,949 - INFO - Extracting features from 3925 samples...
2024-12-29 14:08:29,425 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:08:29,431 - INFO - Validation feature extraction completed in 9.48s
2024-12-29 14:08:29,431 - INFO - Extracting training features...
2024-12-29 14:08:29,431 - INFO - Extracting features from 9469 samples...
2024-12-29 14:08:51,413 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:08:51,418 - INFO - Training feature extraction completed in 21.99s
2024-12-29 14:08:51,418 - INFO - Creating model for classifier: KNeighbors
2024-12-29 14:08:51,418 - INFO - Using device: cuda
2024-12-29 14:08:51,419 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:08:51,419 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:08:51,419 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:08:51,921 - INFO - Feature scaling completed in 0.50s
2024-12-29 14:08:51,922 - INFO - Starting feature selection (k=50)
2024-12-29 14:08:51,929 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:08:51,929 - INFO - Starting anomaly detection
2024-12-29 14:08:54,212 - INFO - Anomaly detection completed in 2.28s
2024-12-29 14:08:54,212 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:08:54,212 - INFO - Total fit_transform time: 2.79s
2024-12-29 14:08:54,212 - INFO - Training set processing completed in 2.79s
2024-12-29 14:08:54,213 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:08:54,214 - INFO - Memory usage at start_fit: CPU 2709.4 MB, GPU 104.0 MB
2024-12-29 14:08:54,215 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:08:54,400 - INFO - Fitted scaler and transformed data
2024-12-29 14:08:54,400 - INFO - Scaling time: 0.19s
2024-12-29 14:08:54,407 - INFO - Training completed in 0.19s
2024-12-29 14:08:54,407 - INFO - Final memory usage: CPU 2709.4 MB, GPU 122.6 MB
2024-12-29 14:08:54,408 - INFO - Model training completed in 0.19s
2024-12-29 14:08:54,503 - INFO - Prediction completed in 0.10s
2024-12-29 14:08:54,512 - INFO - Poison rate 0.0 completed in 3.09s
2024-12-29 14:08:54,512 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:08:54,513 - INFO - Label flipping details:
2024-12-29 14:08:54,513 - INFO - - Source class: 1
2024-12-29 14:08:54,513 - INFO - - Target class: 0
2024-12-29 14:08:54,513 - INFO - - Available samples in source class: 955
2024-12-29 14:08:54,513 - INFO - - Requested samples to poison: 94
2024-12-29 14:08:54,513 - INFO - - Actual samples to flip: 94
2024-12-29 14:08:54,513 - INFO - - Samples remaining in source class: 861
2024-12-29 14:08:54,513 - INFO - Successfully flipped 94 labels from class 1 to 0
2024-12-29 14:08:54,513 - INFO - Total number of labels flipped: 94
2024-12-29 14:08:54,513 - INFO - Label flipping completed in 0.00s
2024-12-29 14:08:54,513 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:08:54,513 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:08:55,046 - INFO - Feature scaling completed in 0.53s
2024-12-29 14:08:55,047 - INFO - Starting feature selection (k=50)
2024-12-29 14:08:55,054 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:08:55,054 - INFO - Starting anomaly detection
2024-12-29 14:08:58,797 - INFO - Anomaly detection completed in 3.74s
2024-12-29 14:08:58,797 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:08:58,798 - INFO - Total fit_transform time: 4.28s
2024-12-29 14:08:58,798 - INFO - Training set processing completed in 4.28s
2024-12-29 14:08:58,798 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:08:58,799 - INFO - Memory usage at start_fit: CPU 2709.4 MB, GPU 122.6 MB
2024-12-29 14:08:58,799 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:08:59,046 - INFO - Fitted scaler and transformed data
2024-12-29 14:08:59,046 - INFO - Scaling time: 0.25s
2024-12-29 14:08:59,053 - INFO - Training completed in 0.25s
2024-12-29 14:08:59,054 - INFO - Final memory usage: CPU 2709.4 MB, GPU 122.6 MB
2024-12-29 14:08:59,054 - INFO - Model training completed in 0.26s
2024-12-29 14:08:59,156 - INFO - Prediction completed in 0.10s
2024-12-29 14:08:59,164 - INFO - Poison rate 0.01 completed in 4.65s
2024-12-29 14:08:59,165 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:08:59,165 - INFO - Label flipping details:
2024-12-29 14:08:59,165 - INFO - - Source class: 1
2024-12-29 14:08:59,166 - INFO - - Target class: 0
2024-12-29 14:08:59,166 - INFO - - Available samples in source class: 955
2024-12-29 14:08:59,166 - INFO - - Requested samples to poison: 284
2024-12-29 14:08:59,166 - INFO - - Actual samples to flip: 284
2024-12-29 14:08:59,166 - INFO - - Samples remaining in source class: 671
2024-12-29 14:08:59,166 - INFO - Successfully flipped 284 labels from class 1 to 0
2024-12-29 14:08:59,166 - INFO - Total number of labels flipped: 284
2024-12-29 14:08:59,166 - INFO - Label flipping completed in 0.00s
2024-12-29 14:08:59,166 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:08:59,166 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:08:59,681 - INFO - Feature scaling completed in 0.52s
2024-12-29 14:08:59,682 - INFO - Starting feature selection (k=50)
2024-12-29 14:08:59,695 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:08:59,695 - INFO - Starting anomaly detection
2024-12-29 14:09:02,744 - INFO - Anomaly detection completed in 3.05s
2024-12-29 14:09:02,745 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:09:02,745 - INFO - Total fit_transform time: 3.58s
2024-12-29 14:09:02,745 - INFO - Training set processing completed in 3.58s
2024-12-29 14:09:02,745 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:09:02,746 - INFO - Memory usage at start_fit: CPU 2711.3 MB, GPU 122.6 MB
2024-12-29 14:09:02,746 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:09:02,922 - INFO - Fitted scaler and transformed data
2024-12-29 14:09:02,922 - INFO - Scaling time: 0.18s
2024-12-29 14:09:02,929 - INFO - Training completed in 0.18s
2024-12-29 14:09:02,930 - INFO - Final memory usage: CPU 2711.3 MB, GPU 122.6 MB
2024-12-29 14:09:02,930 - INFO - Model training completed in 0.19s
2024-12-29 14:09:03,029 - INFO - Prediction completed in 0.10s
2024-12-29 14:09:03,039 - INFO - Poison rate 0.03 completed in 3.87s
2024-12-29 14:09:03,039 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:09:03,040 - INFO - Label flipping details:
2024-12-29 14:09:03,040 - INFO - - Source class: 1
2024-12-29 14:09:03,040 - INFO - - Target class: 0
2024-12-29 14:09:03,040 - INFO - - Available samples in source class: 955
2024-12-29 14:09:03,040 - INFO - - Requested samples to poison: 473
2024-12-29 14:09:03,040 - INFO - - Actual samples to flip: 473
2024-12-29 14:09:03,040 - INFO - - Samples remaining in source class: 482
2024-12-29 14:09:03,040 - INFO - Successfully flipped 473 labels from class 1 to 0
2024-12-29 14:09:03,040 - INFO - Total number of labels flipped: 473
2024-12-29 14:09:03,040 - INFO - Label flipping completed in 0.00s
2024-12-29 14:09:03,040 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:09:03,040 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:09:03,551 - INFO - Feature scaling completed in 0.51s
2024-12-29 14:09:03,551 - INFO - Starting feature selection (k=50)
2024-12-29 14:09:03,558 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:09:03,559 - INFO - Starting anomaly detection
2024-12-29 14:09:07,457 - INFO - Anomaly detection completed in 3.90s
2024-12-29 14:09:07,458 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:09:07,458 - INFO - Total fit_transform time: 4.42s
2024-12-29 14:09:07,458 - INFO - Training set processing completed in 4.42s
2024-12-29 14:09:07,458 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:09:07,459 - INFO - Memory usage at start_fit: CPU 2711.3 MB, GPU 122.6 MB
2024-12-29 14:09:07,459 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:09:07,672 - INFO - Fitted scaler and transformed data
2024-12-29 14:09:07,672 - INFO - Scaling time: 0.21s
2024-12-29 14:09:07,679 - INFO - Training completed in 0.22s
2024-12-29 14:09:07,679 - INFO - Final memory usage: CPU 2711.3 MB, GPU 122.6 MB
2024-12-29 14:09:07,679 - INFO - Model training completed in 0.22s
2024-12-29 14:09:07,782 - INFO - Prediction completed in 0.10s
2024-12-29 14:09:07,790 - INFO - Poison rate 0.05 completed in 4.75s
2024-12-29 14:09:07,791 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:09:07,791 - INFO - Label flipping details:
2024-12-29 14:09:07,791 - INFO - - Source class: 1
2024-12-29 14:09:07,791 - INFO - - Target class: 0
2024-12-29 14:09:07,791 - INFO - - Available samples in source class: 955
2024-12-29 14:09:07,791 - INFO - - Requested samples to poison: 662
2024-12-29 14:09:07,791 - INFO - - Actual samples to flip: 662
2024-12-29 14:09:07,792 - INFO - - Samples remaining in source class: 293
2024-12-29 14:09:07,792 - INFO - Successfully flipped 662 labels from class 1 to 0
2024-12-29 14:09:07,792 - INFO - Total number of labels flipped: 662
2024-12-29 14:09:07,792 - INFO - Label flipping completed in 0.00s
2024-12-29 14:09:07,792 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:09:07,792 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:09:08,320 - INFO - Feature scaling completed in 0.53s
2024-12-29 14:09:08,321 - INFO - Starting feature selection (k=50)
2024-12-29 14:09:08,329 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:09:08,329 - INFO - Starting anomaly detection
2024-12-29 14:09:12,531 - INFO - Anomaly detection completed in 4.20s
2024-12-29 14:09:12,532 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:09:12,532 - INFO - Total fit_transform time: 4.74s
2024-12-29 14:09:12,532 - INFO - Training set processing completed in 4.74s
2024-12-29 14:09:12,532 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:09:12,533 - INFO - Memory usage at start_fit: CPU 2711.3 MB, GPU 122.6 MB
2024-12-29 14:09:12,533 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:09:12,715 - INFO - Fitted scaler and transformed data
2024-12-29 14:09:12,715 - INFO - Scaling time: 0.18s
2024-12-29 14:09:12,721 - INFO - Training completed in 0.19s
2024-12-29 14:09:12,722 - INFO - Final memory usage: CPU 2711.3 MB, GPU 122.6 MB
2024-12-29 14:09:12,722 - INFO - Model training completed in 0.19s
2024-12-29 14:09:12,795 - INFO - Prediction completed in 0.07s
2024-12-29 14:09:12,803 - INFO - Poison rate 0.07 completed in 5.01s
2024-12-29 14:09:12,803 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:09:12,804 - INFO - Label flipping details:
2024-12-29 14:09:12,804 - INFO - - Source class: 1
2024-12-29 14:09:12,804 - INFO - - Target class: 0
2024-12-29 14:09:12,804 - INFO - - Available samples in source class: 955
2024-12-29 14:09:12,804 - INFO - - Requested samples to poison: 946
2024-12-29 14:09:12,804 - INFO - - Actual samples to flip: 946
2024-12-29 14:09:12,804 - INFO - - Samples remaining in source class: 9
2024-12-29 14:09:12,804 - INFO - Successfully flipped 946 labels from class 1 to 0
2024-12-29 14:09:12,804 - INFO - Total number of labels flipped: 946
2024-12-29 14:09:12,805 - INFO - Label flipping completed in 0.00s
2024-12-29 14:09:12,805 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:09:12,805 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:09:13,373 - INFO - Feature scaling completed in 0.57s
2024-12-29 14:09:13,373 - INFO - Starting feature selection (k=50)
2024-12-29 14:09:13,381 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:09:13,382 - INFO - Starting anomaly detection
2024-12-29 14:09:17,249 - INFO - Anomaly detection completed in 3.87s
2024-12-29 14:09:17,249 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:09:17,250 - INFO - Total fit_transform time: 4.44s
2024-12-29 14:09:17,250 - INFO - Training set processing completed in 4.45s
2024-12-29 14:09:17,250 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:09:17,251 - INFO - Memory usage at start_fit: CPU 2711.3 MB, GPU 122.6 MB
2024-12-29 14:09:17,251 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:09:17,481 - INFO - Fitted scaler and transformed data
2024-12-29 14:09:17,482 - INFO - Scaling time: 0.23s
2024-12-29 14:09:17,488 - INFO - Training completed in 0.24s
2024-12-29 14:09:17,489 - INFO - Final memory usage: CPU 2711.3 MB, GPU 122.6 MB
2024-12-29 14:09:17,489 - INFO - Model training completed in 0.24s
2024-12-29 14:09:17,603 - INFO - Prediction completed in 0.11s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 14:09:17,613 - INFO - Poison rate 0.1 completed in 4.81s
2024-12-29 14:09:17,613 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:09:17,614 - INFO - Label flipping details:
2024-12-29 14:09:17,614 - INFO - - Source class: 1
2024-12-29 14:09:17,614 - INFO - - Target class: 0
2024-12-29 14:09:17,614 - INFO - - Available samples in source class: 955
2024-12-29 14:09:17,614 - INFO - - Requested samples to poison: 1893
2024-12-29 14:09:17,614 - INFO - - Actual samples to flip: 954
2024-12-29 14:09:17,614 - INFO - - Samples remaining in source class: 1
2024-12-29 14:09:17,614 - INFO - Successfully flipped 954 labels from class 1 to 0
2024-12-29 14:09:17,615 - INFO - Total number of labels flipped: 954
2024-12-29 14:09:17,615 - INFO - Label flipping completed in 0.00s
2024-12-29 14:09:17,615 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:09:17,615 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:09:18,149 - INFO - Feature scaling completed in 0.53s
2024-12-29 14:09:18,149 - INFO - Starting feature selection (k=50)
2024-12-29 14:09:18,161 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:09:18,162 - INFO - Starting anomaly detection
2024-12-29 14:09:21,991 - INFO - Anomaly detection completed in 3.83s
2024-12-29 14:09:21,992 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:09:21,992 - INFO - Total fit_transform time: 4.38s
2024-12-29 14:09:21,992 - INFO - Training set processing completed in 4.38s
2024-12-29 14:09:21,992 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:09:21,993 - INFO - Memory usage at start_fit: CPU 2711.3 MB, GPU 122.6 MB
2024-12-29 14:09:21,993 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:09:22,196 - INFO - Fitted scaler and transformed data
2024-12-29 14:09:22,196 - INFO - Scaling time: 0.20s
2024-12-29 14:09:22,203 - INFO - Training completed in 0.21s
2024-12-29 14:09:22,204 - INFO - Final memory usage: CPU 2711.3 MB, GPU 122.6 MB
2024-12-29 14:09:22,204 - INFO - Model training completed in 0.21s
2024-12-29 14:09:22,331 - INFO - Prediction completed in 0.13s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 14:09:22,342 - INFO - Poison rate 0.2 completed in 4.73s
2024-12-29 14:09:22,351 - INFO - Loaded 385 existing results
2024-12-29 14:09:22,351 - INFO - Total results to save: 392
2024-12-29 14:09:22,352 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:09:22,364 - INFO - Saved 392 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:09:22,365 - INFO - Total evaluation time: 62.44s
2024-12-29 14:09:22,366 - INFO - Completed evaluation for ImageNette
2024-12-29 14:09:22,367 - INFO - 
Processing dataset: ImageNette
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:09:22,567 - INFO - 
Progress: 59.4% - Evaluating ImageNette with SVM (standard mode, iteration 1/1)
2024-12-29 14:09:22,783 - INFO - Loading datasets...
2024-12-29 14:09:22,804 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:09:22,804 - INFO - Extracting validation features...
2024-12-29 14:09:22,804 - INFO - Extracting features from 3925 samples...
2024-12-29 14:09:32,131 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:09:32,137 - INFO - Validation feature extraction completed in 9.33s
2024-12-29 14:09:32,137 - INFO - Extracting training features...
2024-12-29 14:09:32,138 - INFO - Extracting features from 9469 samples...
2024-12-29 14:09:53,707 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:09:53,710 - INFO - Training feature extraction completed in 21.57s
2024-12-29 14:09:53,711 - INFO - Creating model for classifier: SVM
2024-12-29 14:09:53,711 - INFO - Using device: cuda
2024-12-29 14:09:53,711 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-29 14:09:53,711 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:09:53,711 - INFO - Training set processing completed in 0.00s
2024-12-29 14:09:53,711 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:09:53,712 - INFO - Memory usage at start_fit: CPU 2681.5 MB, GPU 104.6 MB
2024-12-29 14:09:53,712 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:09:53,715 - INFO - Number of unique classes: 10
2024-12-29 14:09:53,791 - INFO - Fitted scaler and transformed data
2024-12-29 14:09:53,792 - INFO - Scaling time: 0.07s
2024-12-29 14:09:54,163 - INFO - Epoch 1/500, Train Loss: 0.8352, Val Loss: 0.1355
2024-12-29 14:09:54,488 - INFO - Epoch 2/500, Train Loss: 0.0965, Val Loss: 0.1046
2024-12-29 14:09:54,804 - INFO - Epoch 3/500, Train Loss: 0.0640, Val Loss: 0.0864
2024-12-29 14:09:55,217 - INFO - Epoch 4/500, Train Loss: 0.0458, Val Loss: 0.0738
2024-12-29 14:09:55,576 - INFO - Epoch 5/500, Train Loss: 0.0354, Val Loss: 0.0695
2024-12-29 14:09:55,931 - INFO - Epoch 6/500, Train Loss: 0.0276, Val Loss: 0.0664
2024-12-29 14:09:56,252 - INFO - Epoch 7/500, Train Loss: 0.0229, Val Loss: 0.0605
2024-12-29 14:09:56,607 - INFO - Epoch 8/500, Train Loss: 0.0183, Val Loss: 0.0584
2024-12-29 14:09:56,931 - INFO - Epoch 9/500, Train Loss: 0.0155, Val Loss: 0.0576
2024-12-29 14:09:57,244 - INFO - Epoch 10/500, Train Loss: 0.0130, Val Loss: 0.0577
2024-12-29 14:09:57,609 - INFO - Epoch 11/500, Train Loss: 0.0111, Val Loss: 0.0554
2024-12-29 14:09:58,016 - INFO - Epoch 12/500, Train Loss: 0.0094, Val Loss: 0.0564
2024-12-29 14:09:58,360 - INFO - Epoch 13/500, Train Loss: 0.0088, Val Loss: 0.0557
2024-12-29 14:09:58,699 - INFO - Epoch 14/500, Train Loss: 0.0073, Val Loss: 0.0553
2024-12-29 14:09:59,102 - INFO - Epoch 15/500, Train Loss: 0.0066, Val Loss: 0.0552
2024-12-29 14:09:59,536 - INFO - Epoch 16/500, Train Loss: 0.0060, Val Loss: 0.0541
2024-12-29 14:09:59,940 - INFO - Epoch 17/500, Train Loss: 0.0053, Val Loss: 0.0568
2024-12-29 14:10:00,332 - INFO - Epoch 18/500, Train Loss: 0.0048, Val Loss: 0.0554
2024-12-29 14:10:00,675 - INFO - Epoch 19/500, Train Loss: 0.0044, Val Loss: 0.0569
2024-12-29 14:10:01,146 - INFO - Epoch 20/500, Train Loss: 0.0046, Val Loss: 0.0549
2024-12-29 14:10:01,521 - INFO - Epoch 21/500, Train Loss: 0.0039, Val Loss: 0.0553
2024-12-29 14:10:01,521 - INFO - Early stopping triggered at epoch 21
2024-12-29 14:10:01,521 - INFO - Training completed in 7.81s
2024-12-29 14:10:01,522 - INFO - Final memory usage: CPU 2718.8 MB, GPU 104.8 MB
2024-12-29 14:10:01,522 - INFO - Model training completed in 7.81s
2024-12-29 14:10:01,593 - INFO - Prediction completed in 0.07s
2024-12-29 14:10:01,602 - INFO - Poison rate 0.0 completed in 7.89s
2024-12-29 14:10:01,602 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:10:01,604 - INFO - Total number of labels flipped: 94
2024-12-29 14:10:01,604 - INFO - Label flipping completed in 0.00s
2024-12-29 14:10:01,604 - INFO - Training set processing completed in 0.00s
2024-12-29 14:10:01,604 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:10:01,605 - INFO - Memory usage at start_fit: CPU 2689.3 MB, GPU 104.7 MB
2024-12-29 14:10:01,605 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:10:01,609 - INFO - Number of unique classes: 10
2024-12-29 14:10:01,693 - INFO - Fitted scaler and transformed data
2024-12-29 14:10:01,694 - INFO - Scaling time: 0.08s
2024-12-29 14:10:02,052 - INFO - Epoch 1/500, Train Loss: 0.8784, Val Loss: 0.3207
2024-12-29 14:10:02,476 - INFO - Epoch 2/500, Train Loss: 0.2037, Val Loss: 0.3072
2024-12-29 14:10:02,895 - INFO - Epoch 3/500, Train Loss: 0.1590, Val Loss: 0.3084
2024-12-29 14:10:03,235 - INFO - Epoch 4/500, Train Loss: 0.1289, Val Loss: 0.3129
2024-12-29 14:10:03,563 - INFO - Epoch 5/500, Train Loss: 0.1087, Val Loss: 0.3224
2024-12-29 14:10:03,948 - INFO - Epoch 6/500, Train Loss: 0.0928, Val Loss: 0.3219
2024-12-29 14:10:04,309 - INFO - Epoch 7/500, Train Loss: 0.0824, Val Loss: 0.3228
2024-12-29 14:10:04,309 - INFO - Early stopping triggered at epoch 7
2024-12-29 14:10:04,309 - INFO - Training completed in 2.70s
2024-12-29 14:10:04,309 - INFO - Final memory usage: CPU 2718.5 MB, GPU 104.8 MB
2024-12-29 14:10:04,310 - INFO - Model training completed in 2.71s
2024-12-29 14:10:04,358 - INFO - Prediction completed in 0.05s
2024-12-29 14:10:04,367 - INFO - Poison rate 0.01 completed in 2.76s
2024-12-29 14:10:04,367 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:10:04,371 - INFO - Total number of labels flipped: 284
2024-12-29 14:10:04,371 - INFO - Label flipping completed in 0.00s
2024-12-29 14:10:04,371 - INFO - Training set processing completed in 0.00s
2024-12-29 14:10:04,372 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:10:04,372 - INFO - Memory usage at start_fit: CPU 2688.9 MB, GPU 104.7 MB
2024-12-29 14:10:04,372 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:10:04,376 - INFO - Number of unique classes: 10
2024-12-29 14:10:04,448 - INFO - Fitted scaler and transformed data
2024-12-29 14:10:04,449 - INFO - Scaling time: 0.07s
2024-12-29 14:10:04,790 - INFO - Epoch 1/500, Train Loss: 1.2734, Val Loss: 0.4522
2024-12-29 14:10:05,142 - INFO - Epoch 2/500, Train Loss: 0.4682, Val Loss: 0.4441
2024-12-29 14:10:05,479 - INFO - Epoch 3/500, Train Loss: 0.3911, Val Loss: 0.4406
2024-12-29 14:10:05,815 - INFO - Epoch 4/500, Train Loss: 0.3393, Val Loss: 0.4382
2024-12-29 14:10:06,154 - INFO - Epoch 5/500, Train Loss: 0.2974, Val Loss: 0.4354
2024-12-29 14:10:06,520 - INFO - Epoch 6/500, Train Loss: 0.2668, Val Loss: 0.4293
2024-12-29 14:10:06,866 - INFO - Epoch 7/500, Train Loss: 0.2434, Val Loss: 0.4304
2024-12-29 14:10:07,195 - INFO - Epoch 8/500, Train Loss: 0.2257, Val Loss: 0.4241
2024-12-29 14:10:07,508 - INFO - Epoch 9/500, Train Loss: 0.2119, Val Loss: 0.4186
2024-12-29 14:10:07,827 - INFO - Epoch 10/500, Train Loss: 0.1995, Val Loss: 0.4122
2024-12-29 14:10:08,160 - INFO - Epoch 11/500, Train Loss: 0.1877, Val Loss: 0.4024
2024-12-29 14:10:08,509 - INFO - Epoch 12/500, Train Loss: 0.1804, Val Loss: 0.4016
2024-12-29 14:10:08,825 - INFO - Epoch 13/500, Train Loss: 0.1730, Val Loss: 0.3978
2024-12-29 14:10:09,158 - INFO - Epoch 14/500, Train Loss: 0.1677, Val Loss: 0.4019
2024-12-29 14:10:09,549 - INFO - Epoch 15/500, Train Loss: 0.1606, Val Loss: 0.4050
2024-12-29 14:10:09,891 - INFO - Epoch 16/500, Train Loss: 0.1556, Val Loss: 0.4007
2024-12-29 14:10:10,256 - INFO - Epoch 17/500, Train Loss: 0.1520, Val Loss: 0.4108
2024-12-29 14:10:10,631 - INFO - Epoch 18/500, Train Loss: 0.1486, Val Loss: 0.3909
2024-12-29 14:10:10,956 - INFO - Epoch 19/500, Train Loss: 0.1459, Val Loss: 0.3988
2024-12-29 14:10:11,308 - INFO - Epoch 20/500, Train Loss: 0.1445, Val Loss: 0.4038
2024-12-29 14:10:11,649 - INFO - Epoch 21/500, Train Loss: 0.1402, Val Loss: 0.3960
2024-12-29 14:10:11,978 - INFO - Epoch 22/500, Train Loss: 0.1367, Val Loss: 0.4100
2024-12-29 14:10:12,284 - INFO - Epoch 23/500, Train Loss: 0.1351, Val Loss: 0.4045
2024-12-29 14:10:12,284 - INFO - Early stopping triggered at epoch 23
2024-12-29 14:10:12,284 - INFO - Training completed in 7.91s
2024-12-29 14:10:12,284 - INFO - Final memory usage: CPU 2718.7 MB, GPU 104.8 MB
2024-12-29 14:10:12,285 - INFO - Model training completed in 7.91s
2024-12-29 14:10:12,333 - INFO - Prediction completed in 0.05s
2024-12-29 14:10:12,351 - INFO - Poison rate 0.03 completed in 7.98s
2024-12-29 14:10:12,351 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:10:12,361 - INFO - Total number of labels flipped: 473
2024-12-29 14:10:12,361 - INFO - Label flipping completed in 0.01s
2024-12-29 14:10:12,361 - INFO - Training set processing completed in 0.00s
2024-12-29 14:10:12,361 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:10:12,362 - INFO - Memory usage at start_fit: CPU 2689.1 MB, GPU 104.7 MB
2024-12-29 14:10:12,363 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:10:12,366 - INFO - Number of unique classes: 10
2024-12-29 14:10:12,437 - INFO - Fitted scaler and transformed data
2024-12-29 14:10:12,437 - INFO - Scaling time: 0.07s
2024-12-29 14:10:12,787 - INFO - Epoch 1/500, Train Loss: 1.4425, Val Loss: 0.5479
2024-12-29 14:10:13,154 - INFO - Epoch 2/500, Train Loss: 0.7263, Val Loss: 0.5456
2024-12-29 14:10:13,468 - INFO - Epoch 3/500, Train Loss: 0.6166, Val Loss: 0.5646
2024-12-29 14:10:13,894 - INFO - Epoch 4/500, Train Loss: 0.5399, Val Loss: 0.5727
2024-12-29 14:10:14,249 - INFO - Epoch 5/500, Train Loss: 0.4913, Val Loss: 0.5820
2024-12-29 14:10:14,614 - INFO - Epoch 6/500, Train Loss: 0.4534, Val Loss: 0.5758
2024-12-29 14:10:14,953 - INFO - Epoch 7/500, Train Loss: 0.4242, Val Loss: 0.5766
2024-12-29 14:10:14,953 - INFO - Early stopping triggered at epoch 7
2024-12-29 14:10:14,953 - INFO - Training completed in 2.59s
2024-12-29 14:10:14,953 - INFO - Final memory usage: CPU 2718.6 MB, GPU 104.8 MB
2024-12-29 14:10:14,954 - INFO - Model training completed in 2.59s
2024-12-29 14:10:15,017 - INFO - Prediction completed in 0.06s
2024-12-29 14:10:15,026 - INFO - Poison rate 0.05 completed in 2.67s
2024-12-29 14:10:15,026 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:10:15,034 - INFO - Total number of labels flipped: 662
2024-12-29 14:10:15,034 - INFO - Label flipping completed in 0.01s
2024-12-29 14:10:15,034 - INFO - Training set processing completed in 0.00s
2024-12-29 14:10:15,034 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:10:15,035 - INFO - Memory usage at start_fit: CPU 2689.3 MB, GPU 104.7 MB
2024-12-29 14:10:15,036 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:10:15,041 - INFO - Number of unique classes: 10
2024-12-29 14:10:15,124 - INFO - Fitted scaler and transformed data
2024-12-29 14:10:15,124 - INFO - Scaling time: 0.08s
2024-12-29 14:10:15,491 - INFO - Epoch 1/500, Train Loss: 1.5126, Val Loss: 0.8339
2024-12-29 14:10:15,837 - INFO - Epoch 2/500, Train Loss: 0.9424, Val Loss: 0.8028
2024-12-29 14:10:16,182 - INFO - Epoch 3/500, Train Loss: 0.8269, Val Loss: 0.7721
2024-12-29 14:10:16,582 - INFO - Epoch 4/500, Train Loss: 0.7425, Val Loss: 0.7745
2024-12-29 14:10:16,922 - INFO - Epoch 5/500, Train Loss: 0.6846, Val Loss: 0.7739
2024-12-29 14:10:17,296 - INFO - Epoch 6/500, Train Loss: 0.6408, Val Loss: 0.7702
2024-12-29 14:10:17,681 - INFO - Epoch 7/500, Train Loss: 0.6067, Val Loss: 0.7837
2024-12-29 14:10:18,053 - INFO - Epoch 8/500, Train Loss: 0.5767, Val Loss: 0.7914
2024-12-29 14:10:18,401 - INFO - Epoch 9/500, Train Loss: 0.5485, Val Loss: 0.7872
2024-12-29 14:10:18,798 - INFO - Epoch 10/500, Train Loss: 0.5362, Val Loss: 0.7972
2024-12-29 14:10:19,197 - INFO - Epoch 11/500, Train Loss: 0.5164, Val Loss: 0.7805
2024-12-29 14:10:19,197 - INFO - Early stopping triggered at epoch 11
2024-12-29 14:10:19,197 - INFO - Training completed in 4.16s
2024-12-29 14:10:19,198 - INFO - Final memory usage: CPU 2718.8 MB, GPU 104.8 MB
2024-12-29 14:10:19,198 - INFO - Model training completed in 4.16s
2024-12-29 14:10:19,243 - INFO - Prediction completed in 0.04s
2024-12-29 14:10:19,251 - INFO - Poison rate 0.07 completed in 4.23s
2024-12-29 14:10:19,251 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:10:19,263 - INFO - Total number of labels flipped: 946
2024-12-29 14:10:19,263 - INFO - Label flipping completed in 0.01s
2024-12-29 14:10:19,263 - INFO - Training set processing completed in 0.00s
2024-12-29 14:10:19,263 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:10:19,264 - INFO - Memory usage at start_fit: CPU 2689.5 MB, GPU 104.7 MB
2024-12-29 14:10:19,264 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:10:19,267 - INFO - Number of unique classes: 10
2024-12-29 14:10:19,340 - INFO - Fitted scaler and transformed data
2024-12-29 14:10:19,340 - INFO - Scaling time: 0.07s
2024-12-29 14:10:19,733 - INFO - Epoch 1/500, Train Loss: 1.9752, Val Loss: 1.5292
2024-12-29 14:10:20,125 - INFO - Epoch 2/500, Train Loss: 1.2389, Val Loss: 1.4926
2024-12-29 14:10:20,480 - INFO - Epoch 3/500, Train Loss: 1.1110, Val Loss: 1.4832
2024-12-29 14:10:20,828 - INFO - Epoch 4/500, Train Loss: 1.0090, Val Loss: 1.4564
2024-12-29 14:10:21,241 - INFO - Epoch 5/500, Train Loss: 0.9362, Val Loss: 1.4809
2024-12-29 14:10:21,656 - INFO - Epoch 6/500, Train Loss: 0.8852, Val Loss: 1.4795
2024-12-29 14:10:22,005 - INFO - Epoch 7/500, Train Loss: 0.8364, Val Loss: 1.5096
2024-12-29 14:10:22,356 - INFO - Epoch 8/500, Train Loss: 0.8073, Val Loss: 1.5136
2024-12-29 14:10:22,732 - INFO - Epoch 9/500, Train Loss: 0.7751, Val Loss: 1.5078
2024-12-29 14:10:22,732 - INFO - Early stopping triggered at epoch 9
2024-12-29 14:10:22,732 - INFO - Training completed in 3.47s
2024-12-29 14:10:22,732 - INFO - Final memory usage: CPU 2718.8 MB, GPU 104.8 MB
2024-12-29 14:10:22,733 - INFO - Model training completed in 3.47s
2024-12-29 14:10:22,779 - INFO - Prediction completed in 0.05s
2024-12-29 14:10:22,787 - INFO - Poison rate 0.1 completed in 3.54s
2024-12-29 14:10:22,788 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:10:22,809 - INFO - Total number of labels flipped: 1893
2024-12-29 14:10:22,809 - INFO - Label flipping completed in 0.02s
2024-12-29 14:10:22,809 - INFO - Training set processing completed in 0.00s
2024-12-29 14:10:22,809 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:10:22,810 - INFO - Memory usage at start_fit: CPU 2689.4 MB, GPU 104.7 MB
2024-12-29 14:10:22,810 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:10:22,814 - INFO - Number of unique classes: 10
2024-12-29 14:10:22,883 - INFO - Fitted scaler and transformed data
2024-12-29 14:10:22,884 - INFO - Scaling time: 0.07s
2024-12-29 14:10:23,257 - INFO - Epoch 1/500, Train Loss: 3.0139, Val Loss: 2.8465
2024-12-29 14:10:23,656 - INFO - Epoch 2/500, Train Loss: 2.3033, Val Loss: 2.7721
2024-12-29 14:10:24,040 - INFO - Epoch 3/500, Train Loss: 2.1180, Val Loss: 2.7591
2024-12-29 14:10:24,392 - INFO - Epoch 4/500, Train Loss: 1.9831, Val Loss: 2.7553
2024-12-29 14:10:24,743 - INFO - Epoch 5/500, Train Loss: 1.8957, Val Loss: 2.8151
2024-12-29 14:10:25,173 - INFO - Epoch 6/500, Train Loss: 1.8150, Val Loss: 2.8046
2024-12-29 14:10:25,527 - INFO - Epoch 7/500, Train Loss: 1.7620, Val Loss: 2.8332
2024-12-29 14:10:25,872 - INFO - Epoch 8/500, Train Loss: 1.7117, Val Loss: 2.8444
2024-12-29 14:10:26,219 - INFO - Epoch 9/500, Train Loss: 1.6861, Val Loss: 2.8826
2024-12-29 14:10:26,219 - INFO - Early stopping triggered at epoch 9
2024-12-29 14:10:26,219 - INFO - Training completed in 3.41s
2024-12-29 14:10:26,219 - INFO - Final memory usage: CPU 2718.7 MB, GPU 104.8 MB
2024-12-29 14:10:26,220 - INFO - Model training completed in 3.41s
2024-12-29 14:10:26,264 - INFO - Prediction completed in 0.04s
2024-12-29 14:10:26,273 - INFO - Poison rate 0.2 completed in 3.49s
2024-12-29 14:10:26,281 - INFO - Loaded 392 existing results
2024-12-29 14:10:26,281 - INFO - Total results to save: 399
2024-12-29 14:10:26,282 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:10:26,294 - INFO - Saved 399 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:10:26,295 - INFO - Total evaluation time: 63.51s
2024-12-29 14:10:26,297 - INFO - 
Progress: 60.4% - Evaluating ImageNette with SVM (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:10:26,492 - INFO - Loading datasets...
2024-12-29 14:10:26,535 - INFO - Dataset loading completed in 0.04s
2024-12-29 14:10:26,535 - INFO - Extracting validation features...
2024-12-29 14:10:26,535 - INFO - Extracting features from 3925 samples...
2024-12-29 14:10:35,755 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:10:35,761 - INFO - Validation feature extraction completed in 9.23s
2024-12-29 14:10:35,761 - INFO - Extracting training features...
2024-12-29 14:10:35,761 - INFO - Extracting features from 9469 samples...
2024-12-29 14:10:57,447 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:10:57,452 - INFO - Training feature extraction completed in 21.69s
2024-12-29 14:10:57,453 - INFO - Creating model for classifier: SVM
2024-12-29 14:10:57,453 - INFO - Using device: cuda
2024-12-29 14:10:57,453 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-29 14:10:57,454 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:10:57,454 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:10:57,454 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:10:58,014 - INFO - Feature scaling completed in 0.56s
2024-12-29 14:10:58,014 - INFO - Starting feature selection (k=50)
2024-12-29 14:10:58,022 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:10:58,022 - INFO - Starting anomaly detection
2024-12-29 14:11:01,719 - INFO - Anomaly detection completed in 3.70s
2024-12-29 14:11:01,719 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:11:01,719 - INFO - Total fit_transform time: 4.26s
2024-12-29 14:11:01,719 - INFO - Training set processing completed in 4.27s
2024-12-29 14:11:01,719 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:11:01,721 - INFO - Memory usage at start_fit: CPU 2709.4 MB, GPU 104.0 MB
2024-12-29 14:11:01,721 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:11:01,724 - INFO - Number of unique classes: 10
2024-12-29 14:11:01,802 - INFO - Fitted scaler and transformed data
2024-12-29 14:11:01,802 - INFO - Scaling time: 0.08s
2024-12-29 14:11:02,143 - INFO - Epoch 1/500, Train Loss: 0.7458, Val Loss: 0.1377
2024-12-29 14:11:02,475 - INFO - Epoch 2/500, Train Loss: 0.0853, Val Loss: 0.0959
2024-12-29 14:11:02,872 - INFO - Epoch 3/500, Train Loss: 0.0583, Val Loss: 0.0816
2024-12-29 14:11:03,194 - INFO - Epoch 4/500, Train Loss: 0.0425, Val Loss: 0.0760
2024-12-29 14:11:03,529 - INFO - Epoch 5/500, Train Loss: 0.0328, Val Loss: 0.0712
2024-12-29 14:11:03,859 - INFO - Epoch 6/500, Train Loss: 0.0258, Val Loss: 0.0684
2024-12-29 14:11:04,171 - INFO - Epoch 7/500, Train Loss: 0.0206, Val Loss: 0.0660
2024-12-29 14:11:04,547 - INFO - Epoch 8/500, Train Loss: 0.0172, Val Loss: 0.0657
2024-12-29 14:11:04,864 - INFO - Epoch 9/500, Train Loss: 0.0145, Val Loss: 0.0633
2024-12-29 14:11:05,220 - INFO - Epoch 10/500, Train Loss: 0.0121, Val Loss: 0.0627
2024-12-29 14:11:05,562 - INFO - Epoch 11/500, Train Loss: 0.0109, Val Loss: 0.0632
2024-12-29 14:11:05,882 - INFO - Epoch 12/500, Train Loss: 0.0091, Val Loss: 0.0630
2024-12-29 14:11:06,202 - INFO - Epoch 13/500, Train Loss: 0.0080, Val Loss: 0.0648
2024-12-29 14:11:06,524 - INFO - Epoch 14/500, Train Loss: 0.0073, Val Loss: 0.0651
2024-12-29 14:11:06,524 - INFO - Early stopping triggered at epoch 14
2024-12-29 14:11:06,524 - INFO - Training completed in 4.80s
2024-12-29 14:11:06,525 - INFO - Final memory usage: CPU 2718.7 MB, GPU 104.2 MB
2024-12-29 14:11:06,526 - INFO - Model training completed in 4.81s
2024-12-29 14:11:06,578 - INFO - Prediction completed in 0.05s
2024-12-29 14:11:06,588 - INFO - Poison rate 0.0 completed in 9.13s
2024-12-29 14:11:06,588 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:11:06,590 - INFO - Total number of labels flipped: 94
2024-12-29 14:11:06,590 - INFO - Label flipping completed in 0.00s
2024-12-29 14:11:06,590 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:11:06,590 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:11:07,101 - INFO - Feature scaling completed in 0.51s
2024-12-29 14:11:07,101 - INFO - Starting feature selection (k=50)
2024-12-29 14:11:07,116 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:11:07,116 - INFO - Starting anomaly detection
2024-12-29 14:11:09,726 - INFO - Anomaly detection completed in 2.61s
2024-12-29 14:11:09,727 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:11:09,727 - INFO - Total fit_transform time: 3.14s
2024-12-29 14:11:09,727 - INFO - Training set processing completed in 3.14s
2024-12-29 14:11:09,727 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:11:09,728 - INFO - Memory usage at start_fit: CPU 2709.6 MB, GPU 104.1 MB
2024-12-29 14:11:09,728 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:11:09,730 - INFO - Number of unique classes: 10
2024-12-29 14:11:09,803 - INFO - Fitted scaler and transformed data
2024-12-29 14:11:09,804 - INFO - Scaling time: 0.07s
2024-12-29 14:11:10,129 - INFO - Epoch 1/500, Train Loss: 0.8842, Val Loss: 0.1971
2024-12-29 14:11:10,429 - INFO - Epoch 2/500, Train Loss: 0.2093, Val Loss: 0.1726
2024-12-29 14:11:10,748 - INFO - Epoch 3/500, Train Loss: 0.1603, Val Loss: 0.1649
2024-12-29 14:11:11,071 - INFO - Epoch 4/500, Train Loss: 0.1293, Val Loss: 0.1614
2024-12-29 14:11:11,420 - INFO - Epoch 5/500, Train Loss: 0.1068, Val Loss: 0.1613
2024-12-29 14:11:11,746 - INFO - Epoch 6/500, Train Loss: 0.0916, Val Loss: 0.1637
2024-12-29 14:11:12,079 - INFO - Epoch 7/500, Train Loss: 0.0816, Val Loss: 0.1626
2024-12-29 14:11:12,402 - INFO - Epoch 8/500, Train Loss: 0.0733, Val Loss: 0.1644
2024-12-29 14:11:12,741 - INFO - Epoch 9/500, Train Loss: 0.0676, Val Loss: 0.1626
2024-12-29 14:11:12,741 - INFO - Early stopping triggered at epoch 9
2024-12-29 14:11:12,741 - INFO - Training completed in 3.01s
2024-12-29 14:11:12,741 - INFO - Final memory usage: CPU 2718.6 MB, GPU 104.2 MB
2024-12-29 14:11:12,744 - INFO - Model training completed in 3.02s
2024-12-29 14:11:12,788 - INFO - Prediction completed in 0.04s
2024-12-29 14:11:12,797 - INFO - Poison rate 0.01 completed in 6.21s
2024-12-29 14:11:12,798 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:11:12,801 - INFO - Total number of labels flipped: 284
2024-12-29 14:11:12,802 - INFO - Label flipping completed in 0.00s
2024-12-29 14:11:12,802 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:11:12,802 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:11:13,432 - INFO - Feature scaling completed in 0.63s
2024-12-29 14:11:13,432 - INFO - Starting feature selection (k=50)
2024-12-29 14:11:13,443 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:11:13,443 - INFO - Starting anomaly detection
2024-12-29 14:11:17,213 - INFO - Anomaly detection completed in 3.77s
2024-12-29 14:11:17,214 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:11:17,214 - INFO - Total fit_transform time: 4.41s
2024-12-29 14:11:17,214 - INFO - Training set processing completed in 4.41s
2024-12-29 14:11:17,214 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:11:17,215 - INFO - Memory usage at start_fit: CPU 2709.5 MB, GPU 104.1 MB
2024-12-29 14:11:17,216 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:11:17,218 - INFO - Number of unique classes: 10
2024-12-29 14:11:17,303 - INFO - Fitted scaler and transformed data
2024-12-29 14:11:17,303 - INFO - Scaling time: 0.08s
2024-12-29 14:11:17,645 - INFO - Epoch 1/500, Train Loss: 1.1382, Val Loss: 0.4975
2024-12-29 14:11:17,961 - INFO - Epoch 2/500, Train Loss: 0.4435, Val Loss: 0.4701
2024-12-29 14:11:18,267 - INFO - Epoch 3/500, Train Loss: 0.3747, Val Loss: 0.4619
2024-12-29 14:11:18,594 - INFO - Epoch 4/500, Train Loss: 0.3254, Val Loss: 0.4498
2024-12-29 14:11:18,985 - INFO - Epoch 5/500, Train Loss: 0.2870, Val Loss: 0.4401
2024-12-29 14:11:19,364 - INFO - Epoch 6/500, Train Loss: 0.2655, Val Loss: 0.4444
2024-12-29 14:11:19,701 - INFO - Epoch 7/500, Train Loss: 0.2360, Val Loss: 0.4298
2024-12-29 14:11:20,063 - INFO - Epoch 8/500, Train Loss: 0.2179, Val Loss: 0.4296
2024-12-29 14:11:20,396 - INFO - Epoch 9/500, Train Loss: 0.2004, Val Loss: 0.4373
2024-12-29 14:11:20,726 - INFO - Epoch 10/500, Train Loss: 0.1903, Val Loss: 0.4405
2024-12-29 14:11:21,044 - INFO - Epoch 11/500, Train Loss: 0.1809, Val Loss: 0.4408
2024-12-29 14:11:21,427 - INFO - Epoch 12/500, Train Loss: 0.1716, Val Loss: 0.4403
2024-12-29 14:11:21,427 - INFO - Early stopping triggered at epoch 12
2024-12-29 14:11:21,427 - INFO - Training completed in 4.21s
2024-12-29 14:11:21,428 - INFO - Final memory usage: CPU 2718.6 MB, GPU 104.2 MB
2024-12-29 14:11:21,430 - INFO - Model training completed in 4.22s
2024-12-29 14:11:21,488 - INFO - Prediction completed in 0.06s
2024-12-29 14:11:21,497 - INFO - Poison rate 0.03 completed in 8.70s
2024-12-29 14:11:21,497 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:11:21,503 - INFO - Total number of labels flipped: 473
2024-12-29 14:11:21,503 - INFO - Label flipping completed in 0.01s
2024-12-29 14:11:21,503 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:11:21,503 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:11:22,060 - INFO - Feature scaling completed in 0.56s
2024-12-29 14:11:22,061 - INFO - Starting feature selection (k=50)
2024-12-29 14:11:22,075 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:11:22,076 - INFO - Starting anomaly detection
2024-12-29 14:11:26,288 - INFO - Anomaly detection completed in 4.21s
2024-12-29 14:11:26,288 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:11:26,289 - INFO - Total fit_transform time: 4.79s
2024-12-29 14:11:26,289 - INFO - Training set processing completed in 4.79s
2024-12-29 14:11:26,289 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:11:26,291 - INFO - Memory usage at start_fit: CPU 2709.2 MB, GPU 104.1 MB
2024-12-29 14:11:26,291 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:11:26,294 - INFO - Number of unique classes: 10
2024-12-29 14:11:26,376 - INFO - Fitted scaler and transformed data
2024-12-29 14:11:26,376 - INFO - Scaling time: 0.08s
2024-12-29 14:11:26,710 - INFO - Epoch 1/500, Train Loss: 1.3624, Val Loss: 0.8509
2024-12-29 14:11:27,035 - INFO - Epoch 2/500, Train Loss: 0.6698, Val Loss: 0.8449
2024-12-29 14:11:27,371 - INFO - Epoch 3/500, Train Loss: 0.5669, Val Loss: 0.8583
2024-12-29 14:11:27,683 - INFO - Epoch 4/500, Train Loss: 0.4989, Val Loss: 0.8713
2024-12-29 14:11:27,990 - INFO - Epoch 5/500, Train Loss: 0.4448, Val Loss: 0.8745
2024-12-29 14:11:28,335 - INFO - Epoch 6/500, Train Loss: 0.4089, Val Loss: 0.9037
2024-12-29 14:11:28,691 - INFO - Epoch 7/500, Train Loss: 0.3835, Val Loss: 0.8971
2024-12-29 14:11:28,692 - INFO - Early stopping triggered at epoch 7
2024-12-29 14:11:28,692 - INFO - Training completed in 2.40s
2024-12-29 14:11:28,693 - INFO - Final memory usage: CPU 2718.7 MB, GPU 104.2 MB
2024-12-29 14:11:28,695 - INFO - Model training completed in 2.41s
2024-12-29 14:11:28,754 - INFO - Prediction completed in 0.06s
2024-12-29 14:11:28,762 - INFO - Poison rate 0.05 completed in 7.27s
2024-12-29 14:11:28,762 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:11:28,771 - INFO - Total number of labels flipped: 662
2024-12-29 14:11:28,771 - INFO - Label flipping completed in 0.01s
2024-12-29 14:11:28,771 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:11:28,771 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:11:29,352 - INFO - Feature scaling completed in 0.58s
2024-12-29 14:11:29,352 - INFO - Starting feature selection (k=50)
2024-12-29 14:11:29,366 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:11:29,366 - INFO - Starting anomaly detection
2024-12-29 14:11:33,693 - INFO - Anomaly detection completed in 4.33s
2024-12-29 14:11:33,693 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:11:33,693 - INFO - Total fit_transform time: 4.92s
2024-12-29 14:11:33,693 - INFO - Training set processing completed in 4.92s
2024-12-29 14:11:33,693 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:11:33,694 - INFO - Memory usage at start_fit: CPU 2709.2 MB, GPU 104.1 MB
2024-12-29 14:11:33,694 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:11:33,697 - INFO - Number of unique classes: 10
2024-12-29 14:11:33,775 - INFO - Fitted scaler and transformed data
2024-12-29 14:11:33,775 - INFO - Scaling time: 0.08s
2024-12-29 14:11:34,124 - INFO - Epoch 1/500, Train Loss: 1.5432, Val Loss: 1.0980
2024-12-29 14:11:34,425 - INFO - Epoch 2/500, Train Loss: 0.8743, Val Loss: 1.0484
2024-12-29 14:11:34,773 - INFO - Epoch 3/500, Train Loss: 0.7641, Val Loss: 1.0375
2024-12-29 14:11:35,104 - INFO - Epoch 4/500, Train Loss: 0.6876, Val Loss: 1.0379
2024-12-29 14:11:35,428 - INFO - Epoch 5/500, Train Loss: 0.6300, Val Loss: 1.0514
2024-12-29 14:11:35,758 - INFO - Epoch 6/500, Train Loss: 0.5863, Val Loss: 1.0430
2024-12-29 14:11:36,086 - INFO - Epoch 7/500, Train Loss: 0.5505, Val Loss: 1.0353
2024-12-29 14:11:36,458 - INFO - Epoch 8/500, Train Loss: 0.5271, Val Loss: 1.0253
2024-12-29 14:11:36,796 - INFO - Epoch 9/500, Train Loss: 0.5061, Val Loss: 1.0463
2024-12-29 14:11:37,143 - INFO - Epoch 10/500, Train Loss: 0.4860, Val Loss: 1.0243
2024-12-29 14:11:37,525 - INFO - Epoch 11/500, Train Loss: 0.4688, Val Loss: 1.0527
2024-12-29 14:11:37,926 - INFO - Epoch 12/500, Train Loss: 0.4569, Val Loss: 1.0646
2024-12-29 14:11:38,311 - INFO - Epoch 13/500, Train Loss: 0.4443, Val Loss: 1.0379
2024-12-29 14:11:38,311 - INFO - Early stopping triggered at epoch 13
2024-12-29 14:11:38,312 - INFO - Training completed in 4.62s
2024-12-29 14:11:38,312 - INFO - Final memory usage: CPU 2718.7 MB, GPU 104.2 MB
2024-12-29 14:11:38,313 - INFO - Model training completed in 4.62s
2024-12-29 14:11:38,395 - INFO - Prediction completed in 0.08s
2024-12-29 14:11:38,404 - INFO - Poison rate 0.07 completed in 9.64s
2024-12-29 14:11:38,404 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:11:38,415 - INFO - Total number of labels flipped: 946
2024-12-29 14:11:38,416 - INFO - Label flipping completed in 0.01s
2024-12-29 14:11:38,416 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:11:38,416 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:11:38,963 - INFO - Feature scaling completed in 0.55s
2024-12-29 14:11:38,963 - INFO - Starting feature selection (k=50)
2024-12-29 14:11:38,980 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 14:11:38,980 - INFO - Starting anomaly detection
2024-12-29 14:11:43,210 - INFO - Anomaly detection completed in 4.23s
2024-12-29 14:11:43,210 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:11:43,211 - INFO - Total fit_transform time: 4.79s
2024-12-29 14:11:43,211 - INFO - Training set processing completed in 4.80s
2024-12-29 14:11:43,211 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:11:43,212 - INFO - Memory usage at start_fit: CPU 2709.2 MB, GPU 104.1 MB
2024-12-29 14:11:43,212 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:11:43,214 - INFO - Number of unique classes: 10
2024-12-29 14:11:43,283 - INFO - Fitted scaler and transformed data
2024-12-29 14:11:43,283 - INFO - Scaling time: 0.07s
2024-12-29 14:11:43,670 - INFO - Epoch 1/500, Train Loss: 2.0595, Val Loss: 1.1974
2024-12-29 14:11:43,999 - INFO - Epoch 2/500, Train Loss: 1.2112, Val Loss: 1.2108
2024-12-29 14:11:44,337 - INFO - Epoch 3/500, Train Loss: 1.0795, Val Loss: 1.2167
2024-12-29 14:11:44,705 - INFO - Epoch 4/500, Train Loss: 0.9882, Val Loss: 1.2178
2024-12-29 14:11:45,014 - INFO - Epoch 5/500, Train Loss: 0.9225, Val Loss: 1.2545
2024-12-29 14:11:45,358 - INFO - Epoch 6/500, Train Loss: 0.8725, Val Loss: 1.2621
2024-12-29 14:11:45,358 - INFO - Early stopping triggered at epoch 6
2024-12-29 14:11:45,358 - INFO - Training completed in 2.15s
2024-12-29 14:11:45,359 - INFO - Final memory usage: CPU 2718.7 MB, GPU 104.2 MB
2024-12-29 14:11:45,359 - INFO - Model training completed in 2.15s
2024-12-29 14:11:45,422 - INFO - Prediction completed in 0.06s
2024-12-29 14:11:45,430 - INFO - Poison rate 0.1 completed in 7.03s
2024-12-29 14:11:45,431 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:11:45,452 - INFO - Total number of labels flipped: 1893
2024-12-29 14:11:45,452 - INFO - Label flipping completed in 0.02s
2024-12-29 14:11:45,453 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:11:45,453 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:11:46,042 - INFO - Feature scaling completed in 0.59s
2024-12-29 14:11:46,042 - INFO - Starting feature selection (k=50)
2024-12-29 14:11:46,056 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:11:46,057 - INFO - Starting anomaly detection
2024-12-29 14:11:49,936 - INFO - Anomaly detection completed in 3.88s
2024-12-29 14:11:49,937 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:11:49,937 - INFO - Total fit_transform time: 4.48s
2024-12-29 14:11:49,937 - INFO - Training set processing completed in 4.48s
2024-12-29 14:11:49,938 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:11:49,939 - INFO - Memory usage at start_fit: CPU 2709.2 MB, GPU 104.1 MB
2024-12-29 14:11:49,939 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:11:49,942 - INFO - Number of unique classes: 10
2024-12-29 14:11:50,021 - INFO - Fitted scaler and transformed data
2024-12-29 14:11:50,021 - INFO - Scaling time: 0.08s
2024-12-29 14:11:50,366 - INFO - Epoch 1/500, Train Loss: 2.9738, Val Loss: 2.5288
2024-12-29 14:11:50,706 - INFO - Epoch 2/500, Train Loss: 2.2496, Val Loss: 2.5038
2024-12-29 14:11:51,078 - INFO - Epoch 3/500, Train Loss: 2.0640, Val Loss: 2.4616
2024-12-29 14:11:51,416 - INFO - Epoch 4/500, Train Loss: 1.9427, Val Loss: 2.4645
2024-12-29 14:11:51,741 - INFO - Epoch 5/500, Train Loss: 1.8425, Val Loss: 2.5055
2024-12-29 14:11:52,097 - INFO - Epoch 6/500, Train Loss: 1.7785, Val Loss: 2.5019
2024-12-29 14:11:52,499 - INFO - Epoch 7/500, Train Loss: 1.7234, Val Loss: 2.5250
2024-12-29 14:11:52,859 - INFO - Epoch 8/500, Train Loss: 1.6813, Val Loss: 2.5417
2024-12-29 14:11:52,859 - INFO - Early stopping triggered at epoch 8
2024-12-29 14:11:52,860 - INFO - Training completed in 2.92s
2024-12-29 14:11:52,861 - INFO - Final memory usage: CPU 2718.7 MB, GPU 104.2 MB
2024-12-29 14:11:52,863 - INFO - Model training completed in 2.93s
2024-12-29 14:11:52,924 - INFO - Prediction completed in 0.06s
2024-12-29 14:11:52,932 - INFO - Poison rate 0.2 completed in 7.50s
2024-12-29 14:11:52,940 - INFO - Loaded 399 existing results
2024-12-29 14:11:52,941 - INFO - Total results to save: 406
2024-12-29 14:11:52,942 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:11:52,954 - INFO - Saved 406 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:11:52,955 - INFO - Total evaluation time: 86.46s
2024-12-29 14:11:52,956 - INFO - 
Progress: 61.5% - Evaluating ImageNette with LogisticRegression (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:11:53,171 - INFO - Loading datasets...
2024-12-29 14:11:53,198 - INFO - Dataset loading completed in 0.03s
2024-12-29 14:11:53,198 - INFO - Extracting validation features...
2024-12-29 14:11:53,198 - INFO - Extracting features from 3925 samples...
2024-12-29 14:12:02,381 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:12:02,386 - INFO - Validation feature extraction completed in 9.19s
2024-12-29 14:12:02,386 - INFO - Extracting training features...
2024-12-29 14:12:02,386 - INFO - Extracting features from 9469 samples...
2024-12-29 14:12:24,137 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:12:24,142 - INFO - Training feature extraction completed in 21.76s
2024-12-29 14:12:24,143 - INFO - Creating model for classifier: LogisticRegression
2024-12-29 14:12:24,143 - INFO - Using device: cuda
2024-12-29 14:12:24,144 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:12:24,144 - INFO - Training set processing completed in 0.00s
2024-12-29 14:12:24,144 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:12:24,146 - INFO - Memory usage at start_fit: CPU 2681.7 MB, GPU 104.6 MB
2024-12-29 14:12:24,146 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:12:24,151 - INFO - Number of unique classes: 10
2024-12-29 14:12:24,222 - INFO - Fitted scaler and transformed data
2024-12-29 14:12:24,222 - INFO - Scaling time: 0.07s
2024-12-29 14:12:24,540 - INFO - Epoch 1/1000, Train Loss: 0.5000, Val Loss: 0.1046
2024-12-29 14:12:24,895 - INFO - Epoch 2/1000, Train Loss: 0.0965, Val Loss: 0.0682
2024-12-29 14:12:25,278 - INFO - Epoch 3/1000, Train Loss: 0.0696, Val Loss: 0.0552
2024-12-29 14:12:25,638 - INFO - Epoch 4/1000, Train Loss: 0.0567, Val Loss: 0.0478
2024-12-29 14:12:26,045 - INFO - Epoch 5/1000, Train Loss: 0.0488, Val Loss: 0.0443
2024-12-29 14:12:26,467 - INFO - Epoch 6/1000, Train Loss: 0.0437, Val Loss: 0.0416
2024-12-29 14:12:26,832 - INFO - Epoch 7/1000, Train Loss: 0.0403, Val Loss: 0.0401
2024-12-29 14:12:27,194 - INFO - Epoch 8/1000, Train Loss: 0.0376, Val Loss: 0.0389
2024-12-29 14:12:27,510 - INFO - Epoch 9/1000, Train Loss: 0.0357, Val Loss: 0.0382
2024-12-29 14:12:27,765 - INFO - Epoch 10/1000, Train Loss: 0.0344, Val Loss: 0.0379
2024-12-29 14:12:28,073 - INFO - Epoch 11/1000, Train Loss: 0.0332, Val Loss: 0.0373
2024-12-29 14:12:28,468 - INFO - Epoch 12/1000, Train Loss: 0.0323, Val Loss: 0.0368
2024-12-29 14:12:28,859 - INFO - Epoch 13/1000, Train Loss: 0.0319, Val Loss: 0.0367
2024-12-29 14:12:29,245 - INFO - Epoch 14/1000, Train Loss: 0.0310, Val Loss: 0.0366
2024-12-29 14:12:29,657 - INFO - Epoch 15/1000, Train Loss: 0.0307, Val Loss: 0.0364
2024-12-29 14:12:30,067 - INFO - Epoch 16/1000, Train Loss: 0.0305, Val Loss: 0.0367
2024-12-29 14:12:30,067 - INFO - Early stopping triggered at epoch 16
2024-12-29 14:12:30,067 - INFO - Training completed in 5.92s
2024-12-29 14:12:30,068 - INFO - Final memory usage: CPU 2718.8 MB, GPU 104.8 MB
2024-12-29 14:12:30,069 - INFO - Model training completed in 5.92s
2024-12-29 14:12:30,118 - INFO - Prediction completed in 0.05s
2024-12-29 14:12:30,127 - INFO - Poison rate 0.0 completed in 5.98s
2024-12-29 14:12:30,128 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:12:30,130 - INFO - Total number of labels flipped: 94
2024-12-29 14:12:30,130 - INFO - Label flipping completed in 0.00s
2024-12-29 14:12:30,130 - INFO - Training set processing completed in 0.00s
2024-12-29 14:12:30,130 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:12:30,131 - INFO - Memory usage at start_fit: CPU 2693.4 MB, GPU 104.7 MB
2024-12-29 14:12:30,131 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:12:30,138 - INFO - Number of unique classes: 10
2024-12-29 14:12:30,214 - INFO - Fitted scaler and transformed data
2024-12-29 14:12:30,215 - INFO - Scaling time: 0.07s
2024-12-29 14:12:30,498 - INFO - Epoch 1/1000, Train Loss: 0.5161, Val Loss: 0.1915
2024-12-29 14:12:30,876 - INFO - Epoch 2/1000, Train Loss: 0.1644, Val Loss: 0.1627
2024-12-29 14:12:31,111 - INFO - Epoch 3/1000, Train Loss: 0.1404, Val Loss: 0.1536
2024-12-29 14:12:31,328 - INFO - Epoch 4/1000, Train Loss: 0.1280, Val Loss: 0.1492
2024-12-29 14:12:31,569 - INFO - Epoch 5/1000, Train Loss: 0.1212, Val Loss: 0.1466
2024-12-29 14:12:31,771 - INFO - Epoch 6/1000, Train Loss: 0.1137, Val Loss: 0.1472
2024-12-29 14:12:31,970 - INFO - Epoch 7/1000, Train Loss: 0.1095, Val Loss: 0.1458
2024-12-29 14:12:32,196 - INFO - Epoch 8/1000, Train Loss: 0.1054, Val Loss: 0.1461
2024-12-29 14:12:32,400 - INFO - Epoch 9/1000, Train Loss: 0.1032, Val Loss: 0.1456
2024-12-29 14:12:32,626 - INFO - Epoch 10/1000, Train Loss: 0.1006, Val Loss: 0.1468
2024-12-29 14:12:32,854 - INFO - Epoch 11/1000, Train Loss: 0.0979, Val Loss: 0.1478
2024-12-29 14:12:33,061 - INFO - Epoch 12/1000, Train Loss: 0.0964, Val Loss: 0.1464
2024-12-29 14:12:33,268 - INFO - Epoch 13/1000, Train Loss: 0.0952, Val Loss: 0.1475
2024-12-29 14:12:33,474 - INFO - Epoch 14/1000, Train Loss: 0.0946, Val Loss: 0.1473
2024-12-29 14:12:33,474 - INFO - Early stopping triggered at epoch 14
2024-12-29 14:12:33,475 - INFO - Training completed in 3.34s
2024-12-29 14:12:33,475 - INFO - Final memory usage: CPU 2718.6 MB, GPU 104.8 MB
2024-12-29 14:12:33,478 - INFO - Model training completed in 3.35s
2024-12-29 14:12:33,565 - INFO - Prediction completed in 0.09s
2024-12-29 14:12:33,574 - INFO - Poison rate 0.01 completed in 3.45s
2024-12-29 14:12:33,574 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:12:33,578 - INFO - Total number of labels flipped: 284
2024-12-29 14:12:33,579 - INFO - Label flipping completed in 0.00s
2024-12-29 14:12:33,579 - INFO - Training set processing completed in 0.00s
2024-12-29 14:12:33,579 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:12:33,580 - INFO - Memory usage at start_fit: CPU 2693.1 MB, GPU 104.7 MB
2024-12-29 14:12:33,580 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:12:33,585 - INFO - Number of unique classes: 10
2024-12-29 14:12:33,671 - INFO - Fitted scaler and transformed data
2024-12-29 14:12:33,671 - INFO - Scaling time: 0.09s
2024-12-29 14:12:33,880 - INFO - Epoch 1/1000, Train Loss: 0.6211, Val Loss: 0.3214
2024-12-29 14:12:34,101 - INFO - Epoch 2/1000, Train Loss: 0.2980, Val Loss: 0.3022
2024-12-29 14:12:34,306 - INFO - Epoch 3/1000, Train Loss: 0.2769, Val Loss: 0.2964
2024-12-29 14:12:34,547 - INFO - Epoch 4/1000, Train Loss: 0.2617, Val Loss: 0.2931
2024-12-29 14:12:34,756 - INFO - Epoch 5/1000, Train Loss: 0.2523, Val Loss: 0.2928
2024-12-29 14:12:34,981 - INFO - Epoch 6/1000, Train Loss: 0.2445, Val Loss: 0.2911
2024-12-29 14:12:35,226 - INFO - Epoch 7/1000, Train Loss: 0.2373, Val Loss: 0.2916
2024-12-29 14:12:35,477 - INFO - Epoch 8/1000, Train Loss: 0.2314, Val Loss: 0.2914
2024-12-29 14:12:35,743 - INFO - Epoch 9/1000, Train Loss: 0.2267, Val Loss: 0.2960
2024-12-29 14:12:36,102 - INFO - Epoch 10/1000, Train Loss: 0.2239, Val Loss: 0.2933
2024-12-29 14:12:36,512 - INFO - Epoch 11/1000, Train Loss: 0.2195, Val Loss: 0.2932
2024-12-29 14:12:36,512 - INFO - Early stopping triggered at epoch 11
2024-12-29 14:12:36,512 - INFO - Training completed in 2.93s
2024-12-29 14:12:36,512 - INFO - Final memory usage: CPU 2718.4 MB, GPU 104.8 MB
2024-12-29 14:12:36,514 - INFO - Model training completed in 2.94s
2024-12-29 14:12:36,560 - INFO - Prediction completed in 0.05s
2024-12-29 14:12:36,569 - INFO - Poison rate 0.03 completed in 2.99s
2024-12-29 14:12:36,570 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:12:36,576 - INFO - Total number of labels flipped: 473
2024-12-29 14:12:36,576 - INFO - Label flipping completed in 0.01s
2024-12-29 14:12:36,576 - INFO - Training set processing completed in 0.00s
2024-12-29 14:12:36,576 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:12:36,577 - INFO - Memory usage at start_fit: CPU 2692.9 MB, GPU 104.7 MB
2024-12-29 14:12:36,577 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:12:36,581 - INFO - Number of unique classes: 10
2024-12-29 14:12:36,658 - INFO - Fitted scaler and transformed data
2024-12-29 14:12:36,658 - INFO - Scaling time: 0.08s
2024-12-29 14:12:36,964 - INFO - Epoch 1/1000, Train Loss: 0.7575, Val Loss: 0.4048
2024-12-29 14:12:37,371 - INFO - Epoch 2/1000, Train Loss: 0.4142, Val Loss: 0.3892
2024-12-29 14:12:37,745 - INFO - Epoch 3/1000, Train Loss: 0.3917, Val Loss: 0.3831
2024-12-29 14:12:38,146 - INFO - Epoch 4/1000, Train Loss: 0.3776, Val Loss: 0.3780
2024-12-29 14:12:38,560 - INFO - Epoch 5/1000, Train Loss: 0.3654, Val Loss: 0.3759
2024-12-29 14:12:38,922 - INFO - Epoch 6/1000, Train Loss: 0.3564, Val Loss: 0.3750
2024-12-29 14:12:39,325 - INFO - Epoch 7/1000, Train Loss: 0.3489, Val Loss: 0.3735
2024-12-29 14:12:39,745 - INFO - Epoch 8/1000, Train Loss: 0.3426, Val Loss: 0.3734
2024-12-29 14:12:40,056 - INFO - Epoch 9/1000, Train Loss: 0.3372, Val Loss: 0.3721
2024-12-29 14:12:40,471 - INFO - Epoch 10/1000, Train Loss: 0.3333, Val Loss: 0.3708
2024-12-29 14:12:40,851 - INFO - Epoch 11/1000, Train Loss: 0.3290, Val Loss: 0.3722
2024-12-29 14:12:41,254 - INFO - Epoch 12/1000, Train Loss: 0.3263, Val Loss: 0.3767
2024-12-29 14:12:41,579 - INFO - Epoch 13/1000, Train Loss: 0.3227, Val Loss: 0.3706
2024-12-29 14:12:42,001 - INFO - Epoch 14/1000, Train Loss: 0.3204, Val Loss: 0.3740
2024-12-29 14:12:42,338 - INFO - Epoch 15/1000, Train Loss: 0.3188, Val Loss: 0.3743
2024-12-29 14:12:42,339 - INFO - Early stopping triggered at epoch 15
2024-12-29 14:12:42,339 - INFO - Training completed in 5.76s
2024-12-29 14:12:42,339 - INFO - Final memory usage: CPU 2718.8 MB, GPU 104.8 MB
2024-12-29 14:12:42,341 - INFO - Model training completed in 5.77s
2024-12-29 14:12:42,394 - INFO - Prediction completed in 0.05s
2024-12-29 14:12:42,403 - INFO - Poison rate 0.05 completed in 5.83s
2024-12-29 14:12:42,403 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:12:42,412 - INFO - Total number of labels flipped: 662
2024-12-29 14:12:42,412 - INFO - Label flipping completed in 0.01s
2024-12-29 14:12:42,412 - INFO - Training set processing completed in 0.00s
2024-12-29 14:12:42,412 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:12:42,413 - INFO - Memory usage at start_fit: CPU 2693.0 MB, GPU 104.7 MB
2024-12-29 14:12:42,413 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:12:42,416 - INFO - Number of unique classes: 10
2024-12-29 14:12:42,495 - INFO - Fitted scaler and transformed data
2024-12-29 14:12:42,495 - INFO - Scaling time: 0.08s
2024-12-29 14:12:42,832 - INFO - Epoch 1/1000, Train Loss: 0.7824, Val Loss: 0.6081
2024-12-29 14:12:43,168 - INFO - Epoch 2/1000, Train Loss: 0.5150, Val Loss: 0.6021
2024-12-29 14:12:43,584 - INFO - Epoch 3/1000, Train Loss: 0.4882, Val Loss: 0.5998
2024-12-29 14:12:43,980 - INFO - Epoch 4/1000, Train Loss: 0.4707, Val Loss: 0.6004
2024-12-29 14:12:44,402 - INFO - Epoch 5/1000, Train Loss: 0.4584, Val Loss: 0.6002
2024-12-29 14:12:44,767 - INFO - Epoch 6/1000, Train Loss: 0.4495, Val Loss: 0.6091
2024-12-29 14:12:45,163 - INFO - Epoch 7/1000, Train Loss: 0.4421, Val Loss: 0.6051
2024-12-29 14:12:45,577 - INFO - Epoch 8/1000, Train Loss: 0.4344, Val Loss: 0.6063
2024-12-29 14:12:45,577 - INFO - Early stopping triggered at epoch 8
2024-12-29 14:12:45,577 - INFO - Training completed in 3.16s
2024-12-29 14:12:45,578 - INFO - Final memory usage: CPU 2718.6 MB, GPU 104.8 MB
2024-12-29 14:12:45,580 - INFO - Model training completed in 3.17s
2024-12-29 14:12:45,632 - INFO - Prediction completed in 0.05s
2024-12-29 14:12:45,642 - INFO - Poison rate 0.07 completed in 3.24s
2024-12-29 14:12:45,642 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:12:45,654 - INFO - Total number of labels flipped: 946
2024-12-29 14:12:45,654 - INFO - Label flipping completed in 0.01s
2024-12-29 14:12:45,654 - INFO - Training set processing completed in 0.00s
2024-12-29 14:12:45,654 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:12:45,655 - INFO - Memory usage at start_fit: CPU 2692.6 MB, GPU 104.7 MB
2024-12-29 14:12:45,655 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:12:45,659 - INFO - Number of unique classes: 10
2024-12-29 14:12:45,731 - INFO - Fitted scaler and transformed data
2024-12-29 14:12:45,732 - INFO - Scaling time: 0.07s
2024-12-29 14:12:46,150 - INFO - Epoch 1/1000, Train Loss: 0.9465, Val Loss: 0.6611
2024-12-29 14:12:46,570 - INFO - Epoch 2/1000, Train Loss: 0.6749, Val Loss: 0.6468
2024-12-29 14:12:46,985 - INFO - Epoch 3/1000, Train Loss: 0.6440, Val Loss: 0.6460
2024-12-29 14:12:47,341 - INFO - Epoch 4/1000, Train Loss: 0.6235, Val Loss: 0.6451
2024-12-29 14:12:47,739 - INFO - Epoch 5/1000, Train Loss: 0.6093, Val Loss: 0.6427
2024-12-29 14:12:48,085 - INFO - Epoch 6/1000, Train Loss: 0.5961, Val Loss: 0.6487
2024-12-29 14:12:48,507 - INFO - Epoch 7/1000, Train Loss: 0.5870, Val Loss: 0.6447
2024-12-29 14:12:48,889 - INFO - Epoch 8/1000, Train Loss: 0.5815, Val Loss: 0.6495
2024-12-29 14:12:49,181 - INFO - Epoch 9/1000, Train Loss: 0.5738, Val Loss: 0.6548
2024-12-29 14:12:49,532 - INFO - Epoch 10/1000, Train Loss: 0.5683, Val Loss: 0.6507
2024-12-29 14:12:49,533 - INFO - Early stopping triggered at epoch 10
2024-12-29 14:12:49,533 - INFO - Training completed in 3.88s
2024-12-29 14:12:49,533 - INFO - Final memory usage: CPU 2718.5 MB, GPU 104.8 MB
2024-12-29 14:12:49,535 - INFO - Model training completed in 3.88s
2024-12-29 14:12:49,588 - INFO - Prediction completed in 0.05s
2024-12-29 14:12:49,596 - INFO - Poison rate 0.1 completed in 3.95s
2024-12-29 14:12:49,597 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:12:49,618 - INFO - Total number of labels flipped: 1893
2024-12-29 14:12:49,619 - INFO - Label flipping completed in 0.02s
2024-12-29 14:12:49,619 - INFO - Training set processing completed in 0.00s
2024-12-29 14:12:49,619 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:12:49,620 - INFO - Memory usage at start_fit: CPU 2692.9 MB, GPU 104.7 MB
2024-12-29 14:12:49,620 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:12:49,623 - INFO - Number of unique classes: 10
2024-12-29 14:12:49,697 - INFO - Fitted scaler and transformed data
2024-12-29 14:12:49,697 - INFO - Scaling time: 0.07s
2024-12-29 14:12:50,020 - INFO - Epoch 1/1000, Train Loss: 1.2626, Val Loss: 0.9842
2024-12-29 14:12:50,344 - INFO - Epoch 2/1000, Train Loss: 1.0587, Val Loss: 0.9705
2024-12-29 14:12:50,632 - INFO - Epoch 3/1000, Train Loss: 1.0263, Val Loss: 0.9646
2024-12-29 14:12:50,919 - INFO - Epoch 4/1000, Train Loss: 1.0033, Val Loss: 0.9750
2024-12-29 14:12:51,220 - INFO - Epoch 5/1000, Train Loss: 0.9882, Val Loss: 0.9676
2024-12-29 14:12:51,480 - INFO - Epoch 6/1000, Train Loss: 0.9755, Val Loss: 0.9803
2024-12-29 14:12:51,759 - INFO - Epoch 7/1000, Train Loss: 0.9647, Val Loss: 0.9842
2024-12-29 14:12:52,104 - INFO - Epoch 8/1000, Train Loss: 0.9569, Val Loss: 0.9812
2024-12-29 14:12:52,104 - INFO - Early stopping triggered at epoch 8
2024-12-29 14:12:52,105 - INFO - Training completed in 2.49s
2024-12-29 14:12:52,105 - INFO - Final memory usage: CPU 2718.3 MB, GPU 104.8 MB
2024-12-29 14:12:52,107 - INFO - Model training completed in 2.49s
2024-12-29 14:12:52,186 - INFO - Prediction completed in 0.08s
2024-12-29 14:12:52,196 - INFO - Poison rate 0.2 completed in 2.60s
2024-12-29 14:12:52,206 - INFO - Loaded 406 existing results
2024-12-29 14:12:52,206 - INFO - Total results to save: 413
2024-12-29 14:12:52,207 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:12:52,220 - INFO - Saved 413 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:12:52,220 - INFO - Total evaluation time: 59.05s
2024-12-29 14:12:52,222 - INFO - 
Progress: 62.5% - Evaluating ImageNette with LogisticRegression (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:12:52,410 - INFO - Loading datasets...
2024-12-29 14:12:52,431 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:12:52,431 - INFO - Extracting validation features...
2024-12-29 14:12:52,431 - INFO - Extracting features from 3925 samples...
2024-12-29 14:13:01,700 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:13:01,706 - INFO - Validation feature extraction completed in 9.27s
2024-12-29 14:13:01,706 - INFO - Extracting training features...
2024-12-29 14:13:01,707 - INFO - Extracting features from 9469 samples...
2024-12-29 14:13:23,478 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:13:23,482 - INFO - Training feature extraction completed in 21.78s
2024-12-29 14:13:23,482 - INFO - Creating model for classifier: LogisticRegression
2024-12-29 14:13:23,483 - INFO - Using device: cuda
2024-12-29 14:13:23,483 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:13:23,483 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:13:23,483 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:13:24,039 - INFO - Feature scaling completed in 0.56s
2024-12-29 14:13:24,039 - INFO - Starting feature selection (k=50)
2024-12-29 14:13:24,047 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:13:24,048 - INFO - Starting anomaly detection
2024-12-29 14:13:27,661 - INFO - Anomaly detection completed in 3.61s
2024-12-29 14:13:27,661 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:13:27,661 - INFO - Total fit_transform time: 4.18s
2024-12-29 14:13:27,661 - INFO - Training set processing completed in 4.18s
2024-12-29 14:13:27,661 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:13:27,663 - INFO - Memory usage at start_fit: CPU 2709.2 MB, GPU 104.0 MB
2024-12-29 14:13:27,663 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:13:27,667 - INFO - Number of unique classes: 10
2024-12-29 14:13:27,738 - INFO - Fitted scaler and transformed data
2024-12-29 14:13:27,738 - INFO - Scaling time: 0.07s
2024-12-29 14:13:27,994 - INFO - Epoch 1/1000, Train Loss: 0.4754, Val Loss: 0.1028
2024-12-29 14:13:28,270 - INFO - Epoch 2/1000, Train Loss: 0.0926, Val Loss: 0.0689
2024-12-29 14:13:28,552 - INFO - Epoch 3/1000, Train Loss: 0.0672, Val Loss: 0.0566
2024-12-29 14:13:28,803 - INFO - Epoch 4/1000, Train Loss: 0.0544, Val Loss: 0.0508
2024-12-29 14:13:29,112 - INFO - Epoch 5/1000, Train Loss: 0.0468, Val Loss: 0.0475
2024-12-29 14:13:29,442 - INFO - Epoch 6/1000, Train Loss: 0.0420, Val Loss: 0.0455
2024-12-29 14:13:29,863 - INFO - Epoch 7/1000, Train Loss: 0.0386, Val Loss: 0.0439
2024-12-29 14:13:30,098 - INFO - Epoch 8/1000, Train Loss: 0.0360, Val Loss: 0.0431
2024-12-29 14:13:30,336 - INFO - Epoch 9/1000, Train Loss: 0.0342, Val Loss: 0.0432
2024-12-29 14:13:30,551 - INFO - Epoch 10/1000, Train Loss: 0.0332, Val Loss: 0.0422
2024-12-29 14:13:30,771 - INFO - Epoch 11/1000, Train Loss: 0.0320, Val Loss: 0.0422
2024-12-29 14:13:31,006 - INFO - Epoch 12/1000, Train Loss: 0.0312, Val Loss: 0.0413
2024-12-29 14:13:31,220 - INFO - Epoch 13/1000, Train Loss: 0.0306, Val Loss: 0.0409
2024-12-29 14:13:31,454 - INFO - Epoch 14/1000, Train Loss: 0.0301, Val Loss: 0.0411
2024-12-29 14:13:31,657 - INFO - Epoch 15/1000, Train Loss: 0.0299, Val Loss: 0.0408
2024-12-29 14:13:31,889 - INFO - Epoch 16/1000, Train Loss: 0.0294, Val Loss: 0.0407
2024-12-29 14:13:32,087 - INFO - Epoch 17/1000, Train Loss: 0.0294, Val Loss: 0.0405
2024-12-29 14:13:32,280 - INFO - Epoch 18/1000, Train Loss: 0.0290, Val Loss: 0.0401
2024-12-29 14:13:32,281 - INFO - Early stopping triggered at epoch 18
2024-12-29 14:13:32,281 - INFO - Training completed in 4.62s
2024-12-29 14:13:32,281 - INFO - Final memory usage: CPU 2718.5 MB, GPU 104.2 MB
2024-12-29 14:13:32,283 - INFO - Model training completed in 4.62s
2024-12-29 14:13:32,349 - INFO - Prediction completed in 0.07s
2024-12-29 14:13:32,358 - INFO - Poison rate 0.0 completed in 8.88s
2024-12-29 14:13:32,358 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:13:32,361 - INFO - Total number of labels flipped: 94
2024-12-29 14:13:32,361 - INFO - Label flipping completed in 0.00s
2024-12-29 14:13:32,361 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:13:32,362 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:13:32,863 - INFO - Feature scaling completed in 0.50s
2024-12-29 14:13:32,863 - INFO - Starting feature selection (k=50)
2024-12-29 14:13:32,880 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 14:13:32,880 - INFO - Starting anomaly detection
2024-12-29 14:13:37,044 - INFO - Anomaly detection completed in 4.16s
2024-12-29 14:13:37,045 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:13:37,045 - INFO - Total fit_transform time: 4.68s
2024-12-29 14:13:37,045 - INFO - Training set processing completed in 4.68s
2024-12-29 14:13:37,046 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:13:37,047 - INFO - Memory usage at start_fit: CPU 2709.3 MB, GPU 104.1 MB
2024-12-29 14:13:37,047 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:13:37,050 - INFO - Number of unique classes: 10
2024-12-29 14:13:37,131 - INFO - Fitted scaler and transformed data
2024-12-29 14:13:37,131 - INFO - Scaling time: 0.08s
2024-12-29 14:13:37,337 - INFO - Epoch 1/1000, Train Loss: 0.5244, Val Loss: 0.2253
2024-12-29 14:13:37,545 - INFO - Epoch 2/1000, Train Loss: 0.1586, Val Loss: 0.2012
2024-12-29 14:13:37,755 - INFO - Epoch 3/1000, Train Loss: 0.1361, Val Loss: 0.1932
2024-12-29 14:13:37,944 - INFO - Epoch 4/1000, Train Loss: 0.1244, Val Loss: 0.1889
2024-12-29 14:13:38,128 - INFO - Epoch 5/1000, Train Loss: 0.1171, Val Loss: 0.1861
2024-12-29 14:13:38,338 - INFO - Epoch 6/1000, Train Loss: 0.1106, Val Loss: 0.1860
2024-12-29 14:13:38,540 - INFO - Epoch 7/1000, Train Loss: 0.1059, Val Loss: 0.1854
2024-12-29 14:13:38,733 - INFO - Epoch 8/1000, Train Loss: 0.1022, Val Loss: 0.1845
2024-12-29 14:13:38,926 - INFO - Epoch 9/1000, Train Loss: 0.0990, Val Loss: 0.1847
2024-12-29 14:13:39,118 - INFO - Epoch 10/1000, Train Loss: 0.0972, Val Loss: 0.1844
2024-12-29 14:13:39,317 - INFO - Epoch 11/1000, Train Loss: 0.0942, Val Loss: 0.1857
2024-12-29 14:13:39,505 - INFO - Epoch 12/1000, Train Loss: 0.0926, Val Loss: 0.1866
2024-12-29 14:13:39,726 - INFO - Epoch 13/1000, Train Loss: 0.0906, Val Loss: 0.1846
2024-12-29 14:13:39,726 - INFO - Early stopping triggered at epoch 13
2024-12-29 14:13:39,726 - INFO - Training completed in 2.68s
2024-12-29 14:13:39,727 - INFO - Final memory usage: CPU 2718.4 MB, GPU 104.2 MB
2024-12-29 14:13:39,728 - INFO - Model training completed in 2.68s
2024-12-29 14:13:39,797 - INFO - Prediction completed in 0.07s
2024-12-29 14:13:39,806 - INFO - Poison rate 0.01 completed in 7.45s
2024-12-29 14:13:39,806 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:13:39,810 - INFO - Total number of labels flipped: 284
2024-12-29 14:13:39,810 - INFO - Label flipping completed in 0.00s
2024-12-29 14:13:39,810 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:13:39,810 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:13:40,391 - INFO - Feature scaling completed in 0.58s
2024-12-29 14:13:40,391 - INFO - Starting feature selection (k=50)
2024-12-29 14:13:40,405 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:13:40,405 - INFO - Starting anomaly detection
2024-12-29 14:13:42,811 - INFO - Anomaly detection completed in 2.41s
2024-12-29 14:13:42,811 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:13:42,811 - INFO - Total fit_transform time: 3.00s
2024-12-29 14:13:42,811 - INFO - Training set processing completed in 3.00s
2024-12-29 14:13:42,811 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:13:42,813 - INFO - Memory usage at start_fit: CPU 2709.2 MB, GPU 104.1 MB
2024-12-29 14:13:42,813 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:13:42,816 - INFO - Number of unique classes: 10
2024-12-29 14:13:42,886 - INFO - Fitted scaler and transformed data
2024-12-29 14:13:42,886 - INFO - Scaling time: 0.07s
2024-12-29 14:13:43,114 - INFO - Epoch 1/1000, Train Loss: 0.6166, Val Loss: 0.3558
2024-12-29 14:13:43,326 - INFO - Epoch 2/1000, Train Loss: 0.2873, Val Loss: 0.3420
2024-12-29 14:13:43,529 - INFO - Epoch 3/1000, Train Loss: 0.2666, Val Loss: 0.3371
2024-12-29 14:13:43,722 - INFO - Epoch 4/1000, Train Loss: 0.2525, Val Loss: 0.3357
2024-12-29 14:13:43,901 - INFO - Epoch 5/1000, Train Loss: 0.2440, Val Loss: 0.3344
2024-12-29 14:13:44,110 - INFO - Epoch 6/1000, Train Loss: 0.2351, Val Loss: 0.3337
2024-12-29 14:13:44,340 - INFO - Epoch 7/1000, Train Loss: 0.2280, Val Loss: 0.3359
2024-12-29 14:13:44,540 - INFO - Epoch 8/1000, Train Loss: 0.2222, Val Loss: 0.3361
2024-12-29 14:13:44,730 - INFO - Epoch 9/1000, Train Loss: 0.2170, Val Loss: 0.3385
2024-12-29 14:13:44,955 - INFO - Epoch 10/1000, Train Loss: 0.2139, Val Loss: 0.3373
2024-12-29 14:13:44,955 - INFO - Early stopping triggered at epoch 10
2024-12-29 14:13:44,955 - INFO - Training completed in 2.14s
2024-12-29 14:13:44,956 - INFO - Final memory usage: CPU 2718.5 MB, GPU 104.2 MB
2024-12-29 14:13:44,957 - INFO - Model training completed in 2.15s
2024-12-29 14:13:45,005 - INFO - Prediction completed in 0.05s
2024-12-29 14:13:45,026 - INFO - Poison rate 0.03 completed in 5.22s
2024-12-29 14:13:45,026 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:13:45,034 - INFO - Total number of labels flipped: 473
2024-12-29 14:13:45,035 - INFO - Label flipping completed in 0.01s
2024-12-29 14:13:45,035 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:13:45,035 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:13:45,632 - INFO - Feature scaling completed in 0.60s
2024-12-29 14:13:45,632 - INFO - Starting feature selection (k=50)
2024-12-29 14:13:45,641 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:13:45,642 - INFO - Starting anomaly detection
2024-12-29 14:13:49,707 - INFO - Anomaly detection completed in 4.06s
2024-12-29 14:13:49,707 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:13:49,707 - INFO - Total fit_transform time: 4.67s
2024-12-29 14:13:49,707 - INFO - Training set processing completed in 4.67s
2024-12-29 14:13:49,707 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:13:49,708 - INFO - Memory usage at start_fit: CPU 2709.2 MB, GPU 104.1 MB
2024-12-29 14:13:49,708 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:13:49,710 - INFO - Number of unique classes: 10
2024-12-29 14:13:49,787 - INFO - Fitted scaler and transformed data
2024-12-29 14:13:49,787 - INFO - Scaling time: 0.08s
2024-12-29 14:13:49,990 - INFO - Epoch 1/1000, Train Loss: 0.7043, Val Loss: 0.3812
2024-12-29 14:13:50,190 - INFO - Epoch 2/1000, Train Loss: 0.4148, Val Loss: 0.3708
2024-12-29 14:13:50,384 - INFO - Epoch 3/1000, Train Loss: 0.3928, Val Loss: 0.3676
2024-12-29 14:13:50,580 - INFO - Epoch 4/1000, Train Loss: 0.3763, Val Loss: 0.3654
2024-12-29 14:13:50,777 - INFO - Epoch 5/1000, Train Loss: 0.3648, Val Loss: 0.3651
2024-12-29 14:13:50,975 - INFO - Epoch 6/1000, Train Loss: 0.3557, Val Loss: 0.3642
2024-12-29 14:13:51,178 - INFO - Epoch 7/1000, Train Loss: 0.3479, Val Loss: 0.3680
2024-12-29 14:13:51,377 - INFO - Epoch 8/1000, Train Loss: 0.3415, Val Loss: 0.3726
2024-12-29 14:13:51,580 - INFO - Epoch 9/1000, Train Loss: 0.3353, Val Loss: 0.3670
2024-12-29 14:13:51,793 - INFO - Epoch 10/1000, Train Loss: 0.3304, Val Loss: 0.3694
2024-12-29 14:13:51,989 - INFO - Epoch 11/1000, Train Loss: 0.3275, Val Loss: 0.3678
2024-12-29 14:13:51,989 - INFO - Early stopping triggered at epoch 11
2024-12-29 14:13:51,989 - INFO - Training completed in 2.28s
2024-12-29 14:13:51,990 - INFO - Final memory usage: CPU 2718.8 MB, GPU 104.2 MB
2024-12-29 14:13:51,991 - INFO - Model training completed in 2.28s
2024-12-29 14:13:52,056 - INFO - Prediction completed in 0.06s
2024-12-29 14:13:52,065 - INFO - Poison rate 0.05 completed in 7.04s
2024-12-29 14:13:52,065 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:13:52,073 - INFO - Total number of labels flipped: 662
2024-12-29 14:13:52,073 - INFO - Label flipping completed in 0.01s
2024-12-29 14:13:52,073 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:13:52,073 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:13:52,631 - INFO - Feature scaling completed in 0.56s
2024-12-29 14:13:52,632 - INFO - Starting feature selection (k=50)
2024-12-29 14:13:52,647 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:13:52,647 - INFO - Starting anomaly detection
2024-12-29 14:13:56,666 - INFO - Anomaly detection completed in 4.02s
2024-12-29 14:13:56,666 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:13:56,666 - INFO - Total fit_transform time: 4.59s
2024-12-29 14:13:56,666 - INFO - Training set processing completed in 4.59s
2024-12-29 14:13:56,666 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:13:56,667 - INFO - Memory usage at start_fit: CPU 2709.0 MB, GPU 104.1 MB
2024-12-29 14:13:56,668 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:13:56,671 - INFO - Number of unique classes: 10
2024-12-29 14:13:56,743 - INFO - Fitted scaler and transformed data
2024-12-29 14:13:56,743 - INFO - Scaling time: 0.07s
2024-12-29 14:13:56,952 - INFO - Epoch 1/1000, Train Loss: 0.7733, Val Loss: 0.5130
2024-12-29 14:13:57,142 - INFO - Epoch 2/1000, Train Loss: 0.5170, Val Loss: 0.5141
2024-12-29 14:13:57,330 - INFO - Epoch 3/1000, Train Loss: 0.4907, Val Loss: 0.5120
2024-12-29 14:13:57,515 - INFO - Epoch 4/1000, Train Loss: 0.4693, Val Loss: 0.5114
2024-12-29 14:13:57,700 - INFO - Epoch 5/1000, Train Loss: 0.4571, Val Loss: 0.5143
2024-12-29 14:13:57,904 - INFO - Epoch 6/1000, Train Loss: 0.4470, Val Loss: 0.5215
2024-12-29 14:13:58,139 - INFO - Epoch 7/1000, Train Loss: 0.4399, Val Loss: 0.5165
2024-12-29 14:13:58,376 - INFO - Epoch 8/1000, Train Loss: 0.4304, Val Loss: 0.5177
2024-12-29 14:13:58,592 - INFO - Epoch 9/1000, Train Loss: 0.4278, Val Loss: 0.5223
2024-12-29 14:13:58,592 - INFO - Early stopping triggered at epoch 9
2024-12-29 14:13:58,592 - INFO - Training completed in 1.92s
2024-12-29 14:13:58,592 - INFO - Final memory usage: CPU 2718.5 MB, GPU 104.2 MB
2024-12-29 14:13:58,594 - INFO - Model training completed in 1.93s
2024-12-29 14:13:58,661 - INFO - Prediction completed in 0.07s
2024-12-29 14:13:58,669 - INFO - Poison rate 0.07 completed in 6.60s
2024-12-29 14:13:58,669 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:13:58,681 - INFO - Total number of labels flipped: 946
2024-12-29 14:13:58,681 - INFO - Label flipping completed in 0.01s
2024-12-29 14:13:58,681 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:13:58,681 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:13:59,271 - INFO - Feature scaling completed in 0.59s
2024-12-29 14:13:59,271 - INFO - Starting feature selection (k=50)
2024-12-29 14:13:59,285 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:13:59,285 - INFO - Starting anomaly detection
2024-12-29 14:14:02,217 - INFO - Anomaly detection completed in 2.93s
2024-12-29 14:14:02,218 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:14:02,218 - INFO - Total fit_transform time: 3.54s
2024-12-29 14:14:02,218 - INFO - Training set processing completed in 3.54s
2024-12-29 14:14:02,218 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:14:02,219 - INFO - Memory usage at start_fit: CPU 2709.2 MB, GPU 104.1 MB
2024-12-29 14:14:02,219 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:14:02,221 - INFO - Number of unique classes: 10
2024-12-29 14:14:02,310 - INFO - Fitted scaler and transformed data
2024-12-29 14:14:02,311 - INFO - Scaling time: 0.09s
2024-12-29 14:14:02,537 - INFO - Epoch 1/1000, Train Loss: 0.9134, Val Loss: 0.6524
2024-12-29 14:14:02,754 - INFO - Epoch 2/1000, Train Loss: 0.6605, Val Loss: 0.6420
2024-12-29 14:14:02,961 - INFO - Epoch 3/1000, Train Loss: 0.6318, Val Loss: 0.6387
2024-12-29 14:14:03,170 - INFO - Epoch 4/1000, Train Loss: 0.6118, Val Loss: 0.6420
2024-12-29 14:14:03,355 - INFO - Epoch 5/1000, Train Loss: 0.6001, Val Loss: 0.6424
2024-12-29 14:14:03,550 - INFO - Epoch 6/1000, Train Loss: 0.5875, Val Loss: 0.6494
2024-12-29 14:14:03,748 - INFO - Epoch 7/1000, Train Loss: 0.5789, Val Loss: 0.6454
2024-12-29 14:14:03,945 - INFO - Epoch 8/1000, Train Loss: 0.5705, Val Loss: 0.6482
2024-12-29 14:14:03,946 - INFO - Early stopping triggered at epoch 8
2024-12-29 14:14:03,946 - INFO - Training completed in 1.73s
2024-12-29 14:14:03,946 - INFO - Final memory usage: CPU 2718.7 MB, GPU 104.2 MB
2024-12-29 14:14:03,947 - INFO - Model training completed in 1.73s
2024-12-29 14:14:04,005 - INFO - Prediction completed in 0.06s
2024-12-29 14:14:04,014 - INFO - Poison rate 0.1 completed in 5.34s
2024-12-29 14:14:04,014 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:14:04,035 - INFO - Total number of labels flipped: 1893
2024-12-29 14:14:04,036 - INFO - Label flipping completed in 0.02s
2024-12-29 14:14:04,036 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:14:04,036 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:14:04,568 - INFO - Feature scaling completed in 0.53s
2024-12-29 14:14:04,568 - INFO - Starting feature selection (k=50)
2024-12-29 14:14:04,581 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:14:04,581 - INFO - Starting anomaly detection
2024-12-29 14:14:07,448 - INFO - Anomaly detection completed in 2.87s
2024-12-29 14:14:07,448 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:14:07,449 - INFO - Total fit_transform time: 3.41s
2024-12-29 14:14:07,449 - INFO - Training set processing completed in 3.41s
2024-12-29 14:14:07,449 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:14:07,450 - INFO - Memory usage at start_fit: CPU 2709.1 MB, GPU 104.1 MB
2024-12-29 14:14:07,450 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:14:07,452 - INFO - Number of unique classes: 10
2024-12-29 14:14:07,525 - INFO - Fitted scaler and transformed data
2024-12-29 14:14:07,525 - INFO - Scaling time: 0.07s
2024-12-29 14:14:07,848 - INFO - Epoch 1/1000, Train Loss: 1.2485, Val Loss: 1.1843
2024-12-29 14:14:08,145 - INFO - Epoch 2/1000, Train Loss: 1.0398, Val Loss: 1.1738
2024-12-29 14:14:08,377 - INFO - Epoch 3/1000, Train Loss: 1.0048, Val Loss: 1.1751
2024-12-29 14:14:08,587 - INFO - Epoch 4/1000, Train Loss: 0.9806, Val Loss: 1.1801
2024-12-29 14:14:08,795 - INFO - Epoch 5/1000, Train Loss: 0.9651, Val Loss: 1.1799
2024-12-29 14:14:08,998 - INFO - Epoch 6/1000, Train Loss: 0.9526, Val Loss: 1.1769
2024-12-29 14:14:09,224 - INFO - Epoch 7/1000, Train Loss: 0.9451, Val Loss: 1.1809
2024-12-29 14:14:09,225 - INFO - Early stopping triggered at epoch 7
2024-12-29 14:14:09,225 - INFO - Training completed in 1.78s
2024-12-29 14:14:09,226 - INFO - Final memory usage: CPU 2718.6 MB, GPU 104.2 MB
2024-12-29 14:14:09,228 - INFO - Model training completed in 1.78s
2024-12-29 14:14:09,286 - INFO - Prediction completed in 0.06s
2024-12-29 14:14:09,295 - INFO - Poison rate 0.2 completed in 5.28s
2024-12-29 14:14:09,303 - INFO - Loaded 413 existing results
2024-12-29 14:14:09,303 - INFO - Total results to save: 420
2024-12-29 14:14:09,304 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:14:09,318 - INFO - Saved 420 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:14:09,319 - INFO - Total evaluation time: 76.91s
2024-12-29 14:14:09,321 - INFO - 
Progress: 63.5% - Evaluating ImageNette with RandomForest (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:14:09,577 - INFO - Loading datasets...
2024-12-29 14:14:09,598 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:14:09,598 - INFO - Extracting validation features...
2024-12-29 14:14:09,598 - INFO - Extracting features from 3925 samples...
2024-12-29 14:14:19,093 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:14:19,099 - INFO - Validation feature extraction completed in 9.50s
2024-12-29 14:14:19,099 - INFO - Extracting training features...
2024-12-29 14:14:19,099 - INFO - Extracting features from 9469 samples...
2024-12-29 14:14:41,027 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:14:41,033 - INFO - Training feature extraction completed in 21.93s
2024-12-29 14:14:41,033 - INFO - Creating model for classifier: RandomForest
2024-12-29 14:14:41,033 - INFO - Using device: cuda
2024-12-29 14:14:41,034 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:14:41,034 - INFO - Training set processing completed in 0.00s
2024-12-29 14:14:41,035 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:14:41,036 - INFO - Memory usage at start_fit: CPU 2681.6 MB, GPU 104.6 MB
2024-12-29 14:14:41,037 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:14:41,262 - INFO - Fitted scaler and transformed data
2024-12-29 14:14:41,262 - INFO - Scaling time: 0.22s
2024-12-29 14:14:41,269 - INFO - Number of unique classes: 10
2024-12-29 14:14:44,138 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3013
2024-12-29 14:14:46,784 - INFO - Epoch 2/10, Train Loss: 2.3006, Val Loss: 2.3001
2024-12-29 14:14:49,707 - INFO - Epoch 3/10, Train Loss: 2.2992, Val Loss: 2.2988
2024-12-29 14:14:53,065 - INFO - Epoch 4/10, Train Loss: 2.2978, Val Loss: 2.2975
2024-12-29 14:14:53,065 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:14:53,065 - INFO - Training completed in 12.03s
2024-12-29 14:14:53,065 - INFO - Final memory usage: CPU 2709.3 MB, GPU 126.5 MB
2024-12-29 14:14:53,066 - INFO - Model training completed in 12.03s
2024-12-29 14:14:53,216 - INFO - Prediction completed in 0.15s
2024-12-29 14:14:53,225 - INFO - Poison rate 0.0 completed in 12.19s
2024-12-29 14:14:53,225 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:14:53,227 - INFO - Total number of labels flipped: 94
2024-12-29 14:14:53,227 - INFO - Label flipping completed in 0.00s
2024-12-29 14:14:53,228 - INFO - Training set processing completed in 0.00s
2024-12-29 14:14:53,228 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:14:53,228 - INFO - Memory usage at start_fit: CPU 2709.3 MB, GPU 106.7 MB
2024-12-29 14:14:53,229 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:14:53,403 - INFO - Fitted scaler and transformed data
2024-12-29 14:14:53,403 - INFO - Scaling time: 0.17s
2024-12-29 14:14:53,414 - INFO - Number of unique classes: 10
2024-12-29 14:14:56,084 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3013
2024-12-29 14:14:59,039 - INFO - Epoch 2/10, Train Loss: 2.3006, Val Loss: 2.3001
2024-12-29 14:15:01,963 - INFO - Epoch 3/10, Train Loss: 2.2992, Val Loss: 2.2988
2024-12-29 14:15:05,214 - INFO - Epoch 4/10, Train Loss: 2.2978, Val Loss: 2.2975
2024-12-29 14:15:05,215 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:15:05,215 - INFO - Training completed in 11.99s
2024-12-29 14:15:05,215 - INFO - Final memory usage: CPU 2709.3 MB, GPU 126.5 MB
2024-12-29 14:15:05,215 - INFO - Model training completed in 11.99s
2024-12-29 14:15:05,480 - INFO - Prediction completed in 0.26s
2024-12-29 14:15:05,489 - INFO - Poison rate 0.01 completed in 12.26s
2024-12-29 14:15:05,490 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:15:05,493 - INFO - Total number of labels flipped: 284
2024-12-29 14:15:05,494 - INFO - Label flipping completed in 0.00s
2024-12-29 14:15:05,494 - INFO - Training set processing completed in 0.00s
2024-12-29 14:15:05,494 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:15:05,495 - INFO - Memory usage at start_fit: CPU 2709.3 MB, GPU 106.7 MB
2024-12-29 14:15:05,495 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:15:05,692 - INFO - Fitted scaler and transformed data
2024-12-29 14:15:05,693 - INFO - Scaling time: 0.20s
2024-12-29 14:15:05,704 - INFO - Number of unique classes: 10
2024-12-29 14:15:08,888 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3014
2024-12-29 14:15:11,680 - INFO - Epoch 2/10, Train Loss: 2.3007, Val Loss: 2.3002
2024-12-29 14:15:14,584 - INFO - Epoch 3/10, Train Loss: 2.2993, Val Loss: 2.2990
2024-12-29 14:15:17,277 - INFO - Epoch 4/10, Train Loss: 2.2979, Val Loss: 2.2978
2024-12-29 14:15:17,278 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:15:17,278 - INFO - Training completed in 11.78s
2024-12-29 14:15:17,278 - INFO - Final memory usage: CPU 2709.3 MB, GPU 126.5 MB
2024-12-29 14:15:17,278 - INFO - Model training completed in 11.78s
2024-12-29 14:15:17,547 - INFO - Prediction completed in 0.27s
2024-12-29 14:15:17,558 - INFO - Poison rate 0.03 completed in 12.07s
2024-12-29 14:15:17,558 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:15:17,564 - INFO - Total number of labels flipped: 473
2024-12-29 14:15:17,565 - INFO - Label flipping completed in 0.01s
2024-12-29 14:15:17,565 - INFO - Training set processing completed in 0.00s
2024-12-29 14:15:17,565 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:15:17,566 - INFO - Memory usage at start_fit: CPU 2709.3 MB, GPU 106.7 MB
2024-12-29 14:15:17,566 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:15:17,770 - INFO - Fitted scaler and transformed data
2024-12-29 14:15:17,771 - INFO - Scaling time: 0.20s
2024-12-29 14:15:17,784 - INFO - Number of unique classes: 10
2024-12-29 14:15:20,986 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3014
2024-12-29 14:15:24,571 - INFO - Epoch 2/10, Train Loss: 2.3007, Val Loss: 2.3002
2024-12-29 14:15:27,301 - INFO - Epoch 3/10, Train Loss: 2.2994, Val Loss: 2.2990
2024-12-29 14:15:29,986 - INFO - Epoch 4/10, Train Loss: 2.2980, Val Loss: 2.2978
2024-12-29 14:15:29,986 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:15:29,986 - INFO - Training completed in 12.42s
2024-12-29 14:15:29,987 - INFO - Final memory usage: CPU 2709.3 MB, GPU 126.5 MB
2024-12-29 14:15:29,987 - INFO - Model training completed in 12.42s
2024-12-29 14:15:30,229 - INFO - Prediction completed in 0.24s
2024-12-29 14:15:30,238 - INFO - Poison rate 0.05 completed in 12.68s
2024-12-29 14:15:30,238 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:15:30,247 - INFO - Total number of labels flipped: 662
2024-12-29 14:15:30,247 - INFO - Label flipping completed in 0.01s
2024-12-29 14:15:30,247 - INFO - Training set processing completed in 0.00s
2024-12-29 14:15:30,247 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:15:30,248 - INFO - Memory usage at start_fit: CPU 2709.3 MB, GPU 106.7 MB
2024-12-29 14:15:30,248 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:15:30,422 - INFO - Fitted scaler and transformed data
2024-12-29 14:15:30,422 - INFO - Scaling time: 0.17s
2024-12-29 14:15:30,432 - INFO - Number of unique classes: 10
2024-12-29 14:15:33,225 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3015
2024-12-29 14:15:36,005 - INFO - Epoch 2/10, Train Loss: 2.3008, Val Loss: 2.3004
2024-12-29 14:15:39,374 - INFO - Epoch 3/10, Train Loss: 2.2995, Val Loss: 2.2992
2024-12-29 14:15:42,943 - INFO - Epoch 4/10, Train Loss: 2.2982, Val Loss: 2.2981
2024-12-29 14:15:42,943 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:15:42,943 - INFO - Training completed in 12.70s
2024-12-29 14:15:42,943 - INFO - Final memory usage: CPU 2709.3 MB, GPU 126.5 MB
2024-12-29 14:15:42,944 - INFO - Model training completed in 12.70s
2024-12-29 14:15:43,094 - INFO - Prediction completed in 0.15s
2024-12-29 14:15:43,103 - INFO - Poison rate 0.07 completed in 12.86s
2024-12-29 14:15:43,103 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:15:43,115 - INFO - Total number of labels flipped: 946
2024-12-29 14:15:43,115 - INFO - Label flipping completed in 0.01s
2024-12-29 14:15:43,115 - INFO - Training set processing completed in 0.00s
2024-12-29 14:15:43,116 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:15:43,117 - INFO - Memory usage at start_fit: CPU 2709.3 MB, GPU 106.7 MB
2024-12-29 14:15:43,117 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:15:43,297 - INFO - Fitted scaler and transformed data
2024-12-29 14:15:43,298 - INFO - Scaling time: 0.18s
2024-12-29 14:15:43,308 - INFO - Number of unique classes: 10
2024-12-29 14:15:46,452 - INFO - Epoch 1/10, Train Loss: 2.3021, Val Loss: 2.3015
2024-12-29 14:15:49,477 - INFO - Epoch 2/10, Train Loss: 2.3009, Val Loss: 2.3005
2024-12-29 14:15:52,828 - INFO - Epoch 3/10, Train Loss: 2.2997, Val Loss: 2.2994
2024-12-29 14:15:56,203 - INFO - Epoch 4/10, Train Loss: 2.2985, Val Loss: 2.2984
2024-12-29 14:15:56,203 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:15:56,204 - INFO - Training completed in 13.09s
2024-12-29 14:15:56,204 - INFO - Final memory usage: CPU 2709.3 MB, GPU 126.5 MB
2024-12-29 14:15:56,204 - INFO - Model training completed in 13.09s
2024-12-29 14:15:56,408 - INFO - Prediction completed in 0.20s
2024-12-29 14:15:56,417 - INFO - Poison rate 0.1 completed in 13.31s
2024-12-29 14:15:56,418 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:15:56,458 - INFO - Total number of labels flipped: 1893
2024-12-29 14:15:56,458 - INFO - Label flipping completed in 0.04s
2024-12-29 14:15:56,459 - INFO - Training set processing completed in 0.00s
2024-12-29 14:15:56,459 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:15:56,460 - INFO - Memory usage at start_fit: CPU 2709.3 MB, GPU 106.7 MB
2024-12-29 14:15:56,460 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:15:56,685 - INFO - Fitted scaler and transformed data
2024-12-29 14:15:56,685 - INFO - Scaling time: 0.22s
2024-12-29 14:15:56,696 - INFO - Number of unique classes: 10
2024-12-29 14:15:59,581 - INFO - Epoch 1/10, Train Loss: 2.3022, Val Loss: 2.3017
2024-12-29 14:16:02,513 - INFO - Epoch 2/10, Train Loss: 2.3012, Val Loss: 2.3009
2024-12-29 14:16:05,904 - INFO - Epoch 3/10, Train Loss: 2.3002, Val Loss: 2.3000
2024-12-29 14:16:09,653 - INFO - Epoch 4/10, Train Loss: 2.2992, Val Loss: 2.2991
2024-12-29 14:16:09,653 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:16:09,653 - INFO - Training completed in 13.19s
2024-12-29 14:16:09,654 - INFO - Final memory usage: CPU 2709.3 MB, GPU 126.5 MB
2024-12-29 14:16:09,654 - INFO - Model training completed in 13.20s
2024-12-29 14:16:09,814 - INFO - Prediction completed in 0.16s
2024-12-29 14:16:09,822 - INFO - Poison rate 0.2 completed in 13.40s
2024-12-29 14:16:09,830 - INFO - Loaded 420 existing results
2024-12-29 14:16:09,830 - INFO - Total results to save: 427
2024-12-29 14:16:09,832 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:16:09,845 - INFO - Saved 427 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:16:09,845 - INFO - Total evaluation time: 120.27s
2024-12-29 14:16:09,847 - INFO - 
Progress: 64.6% - Evaluating ImageNette with RandomForest (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:16:10,033 - INFO - Loading datasets...
2024-12-29 14:16:10,054 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:16:10,054 - INFO - Extracting validation features...
2024-12-29 14:16:10,054 - INFO - Extracting features from 3925 samples...
2024-12-29 14:16:19,302 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:16:19,308 - INFO - Validation feature extraction completed in 9.25s
2024-12-29 14:16:19,308 - INFO - Extracting training features...
2024-12-29 14:16:19,308 - INFO - Extracting features from 9469 samples...
2024-12-29 14:16:41,024 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:16:41,027 - INFO - Training feature extraction completed in 21.72s
2024-12-29 14:16:41,028 - INFO - Creating model for classifier: RandomForest
2024-12-29 14:16:41,028 - INFO - Using device: cuda
2024-12-29 14:16:41,028 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:16:41,028 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:16:41,028 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:16:41,578 - INFO - Feature scaling completed in 0.55s
2024-12-29 14:16:41,578 - INFO - Starting feature selection (k=50)
2024-12-29 14:16:41,590 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:16:41,590 - INFO - Starting anomaly detection
2024-12-29 14:16:44,575 - INFO - Anomaly detection completed in 2.98s
2024-12-29 14:16:44,575 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:16:44,576 - INFO - Total fit_transform time: 3.55s
2024-12-29 14:16:44,576 - INFO - Training set processing completed in 3.55s
2024-12-29 14:16:44,576 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:16:44,578 - INFO - Memory usage at start_fit: CPU 2709.4 MB, GPU 104.0 MB
2024-12-29 14:16:44,578 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:16:44,750 - INFO - Fitted scaler and transformed data
2024-12-29 14:16:44,751 - INFO - Scaling time: 0.17s
2024-12-29 14:16:44,760 - INFO - Number of unique classes: 10
2024-12-29 14:16:48,839 - INFO - Epoch 1/10, Train Loss: 2.1860, Val Loss: 2.3013
2024-12-29 14:16:51,586 - INFO - Epoch 2/10, Train Loss: 2.1847, Val Loss: 2.3000
2024-12-29 14:16:54,862 - INFO - Epoch 3/10, Train Loss: 2.1833, Val Loss: 2.2987
2024-12-29 14:16:58,006 - INFO - Epoch 4/10, Train Loss: 2.1820, Val Loss: 2.2973
2024-12-29 14:16:58,007 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:16:58,007 - INFO - Training completed in 13.43s
2024-12-29 14:16:58,007 - INFO - Final memory usage: CPU 2709.4 MB, GPU 125.9 MB
2024-12-29 14:16:58,007 - INFO - Model training completed in 13.43s
2024-12-29 14:16:58,211 - INFO - Prediction completed in 0.20s
2024-12-29 14:16:58,220 - INFO - Poison rate 0.0 completed in 17.19s
2024-12-29 14:16:58,220 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:16:58,222 - INFO - Total number of labels flipped: 94
2024-12-29 14:16:58,222 - INFO - Label flipping completed in 0.00s
2024-12-29 14:16:58,222 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:16:58,222 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:16:58,754 - INFO - Feature scaling completed in 0.53s
2024-12-29 14:16:58,754 - INFO - Starting feature selection (k=50)
2024-12-29 14:16:58,767 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:16:58,768 - INFO - Starting anomaly detection
2024-12-29 14:17:03,059 - INFO - Anomaly detection completed in 4.29s
2024-12-29 14:17:03,059 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:17:03,059 - INFO - Total fit_transform time: 4.84s
2024-12-29 14:17:03,059 - INFO - Training set processing completed in 4.84s
2024-12-29 14:17:03,059 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:17:03,061 - INFO - Memory usage at start_fit: CPU 2709.4 MB, GPU 106.0 MB
2024-12-29 14:17:03,061 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:17:03,244 - INFO - Fitted scaler and transformed data
2024-12-29 14:17:03,245 - INFO - Scaling time: 0.18s
2024-12-29 14:17:03,251 - INFO - Number of unique classes: 10
2024-12-29 14:17:06,063 - INFO - Epoch 1/10, Train Loss: 2.1865, Val Loss: 2.3014
2024-12-29 14:17:08,813 - INFO - Epoch 2/10, Train Loss: 2.1851, Val Loss: 2.3001
2024-12-29 14:17:11,508 - INFO - Epoch 3/10, Train Loss: 2.1838, Val Loss: 2.2988
2024-12-29 14:17:14,664 - INFO - Epoch 4/10, Train Loss: 2.1825, Val Loss: 2.2975
2024-12-29 14:17:14,664 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:17:14,664 - INFO - Training completed in 11.60s
2024-12-29 14:17:14,664 - INFO - Final memory usage: CPU 2709.4 MB, GPU 125.9 MB
2024-12-29 14:17:14,665 - INFO - Model training completed in 11.61s
2024-12-29 14:17:14,829 - INFO - Prediction completed in 0.16s
2024-12-29 14:17:14,838 - INFO - Poison rate 0.01 completed in 16.62s
2024-12-29 14:17:14,839 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:17:14,843 - INFO - Total number of labels flipped: 284
2024-12-29 14:17:14,843 - INFO - Label flipping completed in 0.00s
2024-12-29 14:17:14,843 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:17:14,843 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:17:15,409 - INFO - Feature scaling completed in 0.57s
2024-12-29 14:17:15,410 - INFO - Starting feature selection (k=50)
2024-12-29 14:17:15,425 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 14:17:15,425 - INFO - Starting anomaly detection
2024-12-29 14:17:19,251 - INFO - Anomaly detection completed in 3.83s
2024-12-29 14:17:19,252 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:17:19,252 - INFO - Total fit_transform time: 4.41s
2024-12-29 14:17:19,252 - INFO - Training set processing completed in 4.41s
2024-12-29 14:17:19,252 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:17:19,254 - INFO - Memory usage at start_fit: CPU 2709.4 MB, GPU 106.0 MB
2024-12-29 14:17:19,254 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:17:19,431 - INFO - Fitted scaler and transformed data
2024-12-29 14:17:19,431 - INFO - Scaling time: 0.18s
2024-12-29 14:17:19,438 - INFO - Number of unique classes: 10
2024-12-29 14:17:22,648 - INFO - Epoch 1/10, Train Loss: 2.1863, Val Loss: 2.3013
2024-12-29 14:17:26,075 - INFO - Epoch 2/10, Train Loss: 2.1850, Val Loss: 2.3001
2024-12-29 14:17:29,062 - INFO - Epoch 3/10, Train Loss: 2.1837, Val Loss: 2.2989
2024-12-29 14:17:31,622 - INFO - Epoch 4/10, Train Loss: 2.1824, Val Loss: 2.2976
2024-12-29 14:17:31,622 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:17:31,622 - INFO - Training completed in 12.37s
2024-12-29 14:17:31,623 - INFO - Final memory usage: CPU 2709.4 MB, GPU 125.9 MB
2024-12-29 14:17:31,623 - INFO - Model training completed in 12.37s
2024-12-29 14:17:31,807 - INFO - Prediction completed in 0.18s
2024-12-29 14:17:31,815 - INFO - Poison rate 0.03 completed in 16.98s
2024-12-29 14:17:31,815 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:17:31,821 - INFO - Total number of labels flipped: 473
2024-12-29 14:17:31,822 - INFO - Label flipping completed in 0.01s
2024-12-29 14:17:31,822 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:17:31,822 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:17:32,421 - INFO - Feature scaling completed in 0.60s
2024-12-29 14:17:32,422 - INFO - Starting feature selection (k=50)
2024-12-29 14:17:32,435 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:17:32,435 - INFO - Starting anomaly detection
2024-12-29 14:17:34,722 - INFO - Anomaly detection completed in 2.29s
2024-12-29 14:17:34,723 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:17:34,723 - INFO - Total fit_transform time: 2.90s
2024-12-29 14:17:34,723 - INFO - Training set processing completed in 2.90s
2024-12-29 14:17:34,723 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:17:34,724 - INFO - Memory usage at start_fit: CPU 2709.4 MB, GPU 106.0 MB
2024-12-29 14:17:34,724 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:17:34,898 - INFO - Fitted scaler and transformed data
2024-12-29 14:17:34,899 - INFO - Scaling time: 0.17s
2024-12-29 14:17:34,908 - INFO - Number of unique classes: 10
2024-12-29 14:17:38,090 - INFO - Epoch 1/10, Train Loss: 2.1872, Val Loss: 2.3014
2024-12-29 14:17:41,793 - INFO - Epoch 2/10, Train Loss: 2.1860, Val Loss: 2.3002
2024-12-29 14:17:45,379 - INFO - Epoch 3/10, Train Loss: 2.1847, Val Loss: 2.2990
2024-12-29 14:17:48,288 - INFO - Epoch 4/10, Train Loss: 2.1835, Val Loss: 2.2978
2024-12-29 14:17:48,288 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:17:48,288 - INFO - Training completed in 13.56s
2024-12-29 14:17:48,289 - INFO - Final memory usage: CPU 2709.4 MB, GPU 125.9 MB
2024-12-29 14:17:48,289 - INFO - Model training completed in 13.57s
2024-12-29 14:17:48,540 - INFO - Prediction completed in 0.25s
2024-12-29 14:17:48,551 - INFO - Poison rate 0.05 completed in 16.74s
2024-12-29 14:17:48,551 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:17:48,559 - INFO - Total number of labels flipped: 662
2024-12-29 14:17:48,560 - INFO - Label flipping completed in 0.01s
2024-12-29 14:17:48,560 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:17:48,560 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:17:49,141 - INFO - Feature scaling completed in 0.58s
2024-12-29 14:17:49,141 - INFO - Starting feature selection (k=50)
2024-12-29 14:17:49,154 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:17:49,154 - INFO - Starting anomaly detection
2024-12-29 14:17:53,240 - INFO - Anomaly detection completed in 4.09s
2024-12-29 14:17:53,240 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:17:53,240 - INFO - Total fit_transform time: 4.68s
2024-12-29 14:17:53,241 - INFO - Training set processing completed in 4.68s
2024-12-29 14:17:53,241 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:17:53,242 - INFO - Memory usage at start_fit: CPU 2709.4 MB, GPU 106.0 MB
2024-12-29 14:17:53,242 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:17:53,416 - INFO - Fitted scaler and transformed data
2024-12-29 14:17:53,416 - INFO - Scaling time: 0.17s
2024-12-29 14:17:53,423 - INFO - Number of unique classes: 10
2024-12-29 14:17:56,169 - INFO - Epoch 1/10, Train Loss: 2.1873, Val Loss: 2.3016
2024-12-29 14:17:59,394 - INFO - Epoch 2/10, Train Loss: 2.1860, Val Loss: 2.3005
2024-12-29 14:18:01,915 - INFO - Epoch 3/10, Train Loss: 2.1848, Val Loss: 2.2994
2024-12-29 14:18:04,926 - INFO - Epoch 4/10, Train Loss: 2.1836, Val Loss: 2.2983
2024-12-29 14:18:04,927 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:18:04,927 - INFO - Training completed in 11.69s
2024-12-29 14:18:04,927 - INFO - Final memory usage: CPU 2709.4 MB, GPU 125.9 MB
2024-12-29 14:18:04,927 - INFO - Model training completed in 11.69s
2024-12-29 14:18:05,080 - INFO - Prediction completed in 0.15s
2024-12-29 14:18:05,089 - INFO - Poison rate 0.07 completed in 16.54s
2024-12-29 14:18:05,089 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:18:05,100 - INFO - Total number of labels flipped: 946
2024-12-29 14:18:05,100 - INFO - Label flipping completed in 0.01s
2024-12-29 14:18:05,101 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:18:05,101 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:18:05,631 - INFO - Feature scaling completed in 0.53s
2024-12-29 14:18:05,632 - INFO - Starting feature selection (k=50)
2024-12-29 14:18:05,644 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:18:05,645 - INFO - Starting anomaly detection
2024-12-29 14:18:09,783 - INFO - Anomaly detection completed in 4.14s
2024-12-29 14:18:09,783 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:18:09,783 - INFO - Total fit_transform time: 4.68s
2024-12-29 14:18:09,783 - INFO - Training set processing completed in 4.68s
2024-12-29 14:18:09,783 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:18:09,784 - INFO - Memory usage at start_fit: CPU 2709.4 MB, GPU 106.0 MB
2024-12-29 14:18:09,785 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:18:09,977 - INFO - Fitted scaler and transformed data
2024-12-29 14:18:09,977 - INFO - Scaling time: 0.19s
2024-12-29 14:18:09,985 - INFO - Number of unique classes: 10
2024-12-29 14:18:13,413 - INFO - Epoch 1/10, Train Loss: 2.1866, Val Loss: 2.3016
2024-12-29 14:18:16,153 - INFO - Epoch 2/10, Train Loss: 2.1855, Val Loss: 2.3005
2024-12-29 14:18:19,212 - INFO - Epoch 3/10, Train Loss: 2.1843, Val Loss: 2.2995
2024-12-29 14:18:22,480 - INFO - Epoch 4/10, Train Loss: 2.1832, Val Loss: 2.2984
2024-12-29 14:18:22,480 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:18:22,480 - INFO - Training completed in 12.70s
2024-12-29 14:18:22,480 - INFO - Final memory usage: CPU 2709.4 MB, GPU 125.9 MB
2024-12-29 14:18:22,481 - INFO - Model training completed in 12.70s
2024-12-29 14:18:22,639 - INFO - Prediction completed in 0.16s
2024-12-29 14:18:22,648 - INFO - Poison rate 0.1 completed in 17.56s
2024-12-29 14:18:22,648 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:18:22,668 - INFO - Total number of labels flipped: 1893
2024-12-29 14:18:22,668 - INFO - Label flipping completed in 0.02s
2024-12-29 14:18:22,668 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:18:22,668 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:18:23,185 - INFO - Feature scaling completed in 0.52s
2024-12-29 14:18:23,185 - INFO - Starting feature selection (k=50)
2024-12-29 14:18:23,198 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:18:23,199 - INFO - Starting anomaly detection
2024-12-29 14:18:26,956 - INFO - Anomaly detection completed in 3.76s
2024-12-29 14:18:26,956 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:18:26,956 - INFO - Total fit_transform time: 4.29s
2024-12-29 14:18:26,956 - INFO - Training set processing completed in 4.29s
2024-12-29 14:18:26,956 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:18:26,957 - INFO - Memory usage at start_fit: CPU 2709.4 MB, GPU 106.0 MB
2024-12-29 14:18:26,958 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:18:27,152 - INFO - Fitted scaler and transformed data
2024-12-29 14:18:27,152 - INFO - Scaling time: 0.19s
2024-12-29 14:18:27,158 - INFO - Number of unique classes: 10
2024-12-29 14:18:29,828 - INFO - Epoch 1/10, Train Loss: 2.1866, Val Loss: 2.3017
2024-12-29 14:18:33,307 - INFO - Epoch 2/10, Train Loss: 2.1857, Val Loss: 2.3009
2024-12-29 14:18:37,222 - INFO - Epoch 3/10, Train Loss: 2.1847, Val Loss: 2.3000
2024-12-29 14:18:40,489 - INFO - Epoch 4/10, Train Loss: 2.1837, Val Loss: 2.2991
2024-12-29 14:18:40,490 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:18:40,490 - INFO - Training completed in 13.53s
2024-12-29 14:18:40,490 - INFO - Final memory usage: CPU 2709.4 MB, GPU 125.9 MB
2024-12-29 14:18:40,490 - INFO - Model training completed in 13.53s
2024-12-29 14:18:40,692 - INFO - Prediction completed in 0.20s
2024-12-29 14:18:40,700 - INFO - Poison rate 0.2 completed in 18.05s
2024-12-29 14:18:40,708 - INFO - Loaded 427 existing results
2024-12-29 14:18:40,708 - INFO - Total results to save: 434
2024-12-29 14:18:40,709 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:18:40,723 - INFO - Saved 434 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:18:40,723 - INFO - Total evaluation time: 150.69s
2024-12-29 14:18:40,725 - INFO - 
Progress: 65.6% - Evaluating ImageNette with KNeighbors (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:18:40,910 - INFO - Loading datasets...
2024-12-29 14:18:40,930 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:18:40,930 - INFO - Extracting validation features...
2024-12-29 14:18:40,930 - INFO - Extracting features from 3925 samples...
2024-12-29 14:18:50,441 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:18:50,447 - INFO - Validation feature extraction completed in 9.52s
2024-12-29 14:18:50,447 - INFO - Extracting training features...
2024-12-29 14:18:50,447 - INFO - Extracting features from 9469 samples...
2024-12-29 14:19:11,972 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:19:11,980 - INFO - Training feature extraction completed in 21.53s
2024-12-29 14:19:11,981 - INFO - Creating model for classifier: KNeighbors
2024-12-29 14:19:11,981 - INFO - Using device: cuda
2024-12-29 14:19:11,981 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:19:11,981 - INFO - Training set processing completed in 0.00s
2024-12-29 14:19:11,981 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:19:11,983 - INFO - Memory usage at start_fit: CPU 2681.8 MB, GPU 104.6 MB
2024-12-29 14:19:11,983 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:19:12,222 - INFO - Fitted scaler and transformed data
2024-12-29 14:19:12,223 - INFO - Scaling time: 0.24s
2024-12-29 14:19:12,231 - INFO - Training completed in 0.25s
2024-12-29 14:19:12,231 - INFO - Final memory usage: CPU 2709.5 MB, GPU 123.2 MB
2024-12-29 14:19:12,231 - INFO - Model training completed in 0.25s
2024-12-29 14:19:12,307 - INFO - Prediction completed in 0.07s
2024-12-29 14:19:12,316 - INFO - Poison rate 0.0 completed in 0.33s
2024-12-29 14:19:12,316 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:19:12,318 - INFO - Total number of labels flipped: 94
2024-12-29 14:19:12,318 - INFO - Label flipping completed in 0.00s
2024-12-29 14:19:12,318 - INFO - Training set processing completed in 0.00s
2024-12-29 14:19:12,318 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:19:12,319 - INFO - Memory usage at start_fit: CPU 2709.7 MB, GPU 123.2 MB
2024-12-29 14:19:12,319 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:19:12,534 - INFO - Fitted scaler and transformed data
2024-12-29 14:19:12,534 - INFO - Scaling time: 0.21s
2024-12-29 14:19:12,545 - INFO - Training completed in 0.23s
2024-12-29 14:19:12,546 - INFO - Final memory usage: CPU 2711.6 MB, GPU 123.2 MB
2024-12-29 14:19:12,547 - INFO - Model training completed in 0.23s
2024-12-29 14:19:12,648 - INFO - Prediction completed in 0.10s
2024-12-29 14:19:12,657 - INFO - Poison rate 0.01 completed in 0.34s
2024-12-29 14:19:12,657 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:19:12,661 - INFO - Total number of labels flipped: 284
2024-12-29 14:19:12,661 - INFO - Label flipping completed in 0.00s
2024-12-29 14:19:12,662 - INFO - Training set processing completed in 0.00s
2024-12-29 14:19:12,662 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:19:12,663 - INFO - Memory usage at start_fit: CPU 2711.6 MB, GPU 123.2 MB
2024-12-29 14:19:12,663 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:19:12,859 - INFO - Fitted scaler and transformed data
2024-12-29 14:19:12,859 - INFO - Scaling time: 0.20s
2024-12-29 14:19:12,865 - INFO - Training completed in 0.20s
2024-12-29 14:19:12,866 - INFO - Final memory usage: CPU 2711.6 MB, GPU 123.2 MB
2024-12-29 14:19:12,866 - INFO - Model training completed in 0.20s
2024-12-29 14:19:12,935 - INFO - Prediction completed in 0.07s
2024-12-29 14:19:12,944 - INFO - Poison rate 0.03 completed in 0.29s
2024-12-29 14:19:12,944 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:19:12,950 - INFO - Total number of labels flipped: 473
2024-12-29 14:19:12,950 - INFO - Label flipping completed in 0.01s
2024-12-29 14:19:12,951 - INFO - Training set processing completed in 0.00s
2024-12-29 14:19:12,951 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:19:12,951 - INFO - Memory usage at start_fit: CPU 2711.6 MB, GPU 123.2 MB
2024-12-29 14:19:12,952 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:19:13,126 - INFO - Fitted scaler and transformed data
2024-12-29 14:19:13,126 - INFO - Scaling time: 0.17s
2024-12-29 14:19:13,132 - INFO - Training completed in 0.18s
2024-12-29 14:19:13,133 - INFO - Final memory usage: CPU 2711.6 MB, GPU 123.2 MB
2024-12-29 14:19:13,133 - INFO - Model training completed in 0.18s
2024-12-29 14:19:13,216 - INFO - Prediction completed in 0.08s
2024-12-29 14:19:13,224 - INFO - Poison rate 0.05 completed in 0.28s
2024-12-29 14:19:13,225 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:19:13,233 - INFO - Total number of labels flipped: 662
2024-12-29 14:19:13,233 - INFO - Label flipping completed in 0.01s
2024-12-29 14:19:13,233 - INFO - Training set processing completed in 0.00s
2024-12-29 14:19:13,233 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:19:13,234 - INFO - Memory usage at start_fit: CPU 2711.6 MB, GPU 123.2 MB
2024-12-29 14:19:13,235 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:19:13,410 - INFO - Fitted scaler and transformed data
2024-12-29 14:19:13,410 - INFO - Scaling time: 0.18s
2024-12-29 14:19:13,418 - INFO - Training completed in 0.18s
2024-12-29 14:19:13,418 - INFO - Final memory usage: CPU 2711.6 MB, GPU 123.2 MB
2024-12-29 14:19:13,419 - INFO - Model training completed in 0.19s
2024-12-29 14:19:13,507 - INFO - Prediction completed in 0.09s
2024-12-29 14:19:13,515 - INFO - Poison rate 0.07 completed in 0.29s
2024-12-29 14:19:13,516 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:19:13,527 - INFO - Total number of labels flipped: 946
2024-12-29 14:19:13,527 - INFO - Label flipping completed in 0.01s
2024-12-29 14:19:13,527 - INFO - Training set processing completed in 0.00s
2024-12-29 14:19:13,527 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:19:13,528 - INFO - Memory usage at start_fit: CPU 2711.6 MB, GPU 123.2 MB
2024-12-29 14:19:13,528 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:19:13,728 - INFO - Fitted scaler and transformed data
2024-12-29 14:19:13,728 - INFO - Scaling time: 0.20s
2024-12-29 14:19:13,734 - INFO - Training completed in 0.21s
2024-12-29 14:19:13,735 - INFO - Final memory usage: CPU 2711.6 MB, GPU 123.2 MB
2024-12-29 14:19:13,735 - INFO - Model training completed in 0.21s
2024-12-29 14:19:13,810 - INFO - Prediction completed in 0.07s
2024-12-29 14:19:13,818 - INFO - Poison rate 0.1 completed in 0.30s
2024-12-29 14:19:13,818 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:19:13,840 - INFO - Total number of labels flipped: 1893
2024-12-29 14:19:13,840 - INFO - Label flipping completed in 0.02s
2024-12-29 14:19:13,840 - INFO - Training set processing completed in 0.00s
2024-12-29 14:19:13,840 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:19:13,841 - INFO - Memory usage at start_fit: CPU 2711.6 MB, GPU 123.2 MB
2024-12-29 14:19:13,841 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:19:14,019 - INFO - Fitted scaler and transformed data
2024-12-29 14:19:14,020 - INFO - Scaling time: 0.18s
2024-12-29 14:19:14,026 - INFO - Training completed in 0.19s
2024-12-29 14:19:14,026 - INFO - Final memory usage: CPU 2711.6 MB, GPU 123.2 MB
2024-12-29 14:19:14,027 - INFO - Model training completed in 0.19s
2024-12-29 14:19:14,134 - INFO - Prediction completed in 0.11s
2024-12-29 14:19:14,143 - INFO - Poison rate 0.2 completed in 0.32s
2024-12-29 14:19:14,151 - INFO - Loaded 434 existing results
2024-12-29 14:19:14,151 - INFO - Total results to save: 441
2024-12-29 14:19:14,153 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:19:14,166 - INFO - Saved 441 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:19:14,167 - INFO - Total evaluation time: 33.26s
2024-12-29 14:19:14,168 - INFO - 
Progress: 66.7% - Evaluating ImageNette with KNeighbors (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:19:14,378 - INFO - Loading datasets...
2024-12-29 14:19:14,399 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:19:14,399 - INFO - Extracting validation features...
2024-12-29 14:19:14,399 - INFO - Extracting features from 3925 samples...
2024-12-29 14:19:23,438 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:19:23,444 - INFO - Validation feature extraction completed in 9.04s
2024-12-29 14:19:23,444 - INFO - Extracting training features...
2024-12-29 14:19:23,444 - INFO - Extracting features from 9469 samples...
2024-12-29 14:19:44,714 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:19:44,718 - INFO - Training feature extraction completed in 21.27s
2024-12-29 14:19:44,719 - INFO - Creating model for classifier: KNeighbors
2024-12-29 14:19:44,719 - INFO - Using device: cuda
2024-12-29 14:19:44,719 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:19:44,719 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:19:44,719 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:19:45,255 - INFO - Feature scaling completed in 0.54s
2024-12-29 14:19:45,255 - INFO - Starting feature selection (k=50)
2024-12-29 14:19:45,263 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:19:45,263 - INFO - Starting anomaly detection
2024-12-29 14:19:48,850 - INFO - Anomaly detection completed in 3.59s
2024-12-29 14:19:48,850 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:19:48,851 - INFO - Total fit_transform time: 4.13s
2024-12-29 14:19:48,851 - INFO - Training set processing completed in 4.13s
2024-12-29 14:19:48,851 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:19:48,852 - INFO - Memory usage at start_fit: CPU 2762.7 MB, GPU 104.0 MB
2024-12-29 14:19:48,853 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:19:49,049 - INFO - Fitted scaler and transformed data
2024-12-29 14:19:49,050 - INFO - Scaling time: 0.20s
2024-12-29 14:19:49,057 - INFO - Training completed in 0.21s
2024-12-29 14:19:49,057 - INFO - Final memory usage: CPU 2762.7 MB, GPU 122.6 MB
2024-12-29 14:19:49,057 - INFO - Model training completed in 0.21s
2024-12-29 14:19:49,199 - INFO - Prediction completed in 0.14s
2024-12-29 14:19:49,208 - INFO - Poison rate 0.0 completed in 4.49s
2024-12-29 14:19:49,208 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:19:49,210 - INFO - Total number of labels flipped: 94
2024-12-29 14:19:49,210 - INFO - Label flipping completed in 0.00s
2024-12-29 14:19:49,210 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:19:49,210 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:19:49,730 - INFO - Feature scaling completed in 0.52s
2024-12-29 14:19:49,730 - INFO - Starting feature selection (k=50)
2024-12-29 14:19:49,742 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:19:49,742 - INFO - Starting anomaly detection
2024-12-29 14:19:54,003 - INFO - Anomaly detection completed in 4.26s
2024-12-29 14:19:54,003 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:19:54,003 - INFO - Total fit_transform time: 4.79s
2024-12-29 14:19:54,003 - INFO - Training set processing completed in 4.79s
2024-12-29 14:19:54,003 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:19:54,004 - INFO - Memory usage at start_fit: CPU 2762.7 MB, GPU 122.6 MB
2024-12-29 14:19:54,004 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:19:54,182 - INFO - Fitted scaler and transformed data
2024-12-29 14:19:54,182 - INFO - Scaling time: 0.18s
2024-12-29 14:19:54,189 - INFO - Training completed in 0.18s
2024-12-29 14:19:54,190 - INFO - Final memory usage: CPU 2762.7 MB, GPU 122.6 MB
2024-12-29 14:19:54,190 - INFO - Model training completed in 0.19s
2024-12-29 14:19:54,287 - INFO - Prediction completed in 0.10s
2024-12-29 14:19:54,296 - INFO - Poison rate 0.01 completed in 5.09s
2024-12-29 14:19:54,296 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:19:54,300 - INFO - Total number of labels flipped: 284
2024-12-29 14:19:54,300 - INFO - Label flipping completed in 0.00s
2024-12-29 14:19:54,300 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:19:54,300 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:19:54,810 - INFO - Feature scaling completed in 0.51s
2024-12-29 14:19:54,811 - INFO - Starting feature selection (k=50)
2024-12-29 14:19:54,819 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:19:54,819 - INFO - Starting anomaly detection
2024-12-29 14:19:58,482 - INFO - Anomaly detection completed in 3.66s
2024-12-29 14:19:58,482 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:19:58,482 - INFO - Total fit_transform time: 4.18s
2024-12-29 14:19:58,482 - INFO - Training set processing completed in 4.18s
2024-12-29 14:19:58,482 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:19:58,483 - INFO - Memory usage at start_fit: CPU 2762.7 MB, GPU 122.6 MB
2024-12-29 14:19:58,484 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:19:58,676 - INFO - Fitted scaler and transformed data
2024-12-29 14:19:58,676 - INFO - Scaling time: 0.19s
2024-12-29 14:19:58,685 - INFO - Training completed in 0.20s
2024-12-29 14:19:58,685 - INFO - Final memory usage: CPU 2762.7 MB, GPU 122.6 MB
2024-12-29 14:19:58,686 - INFO - Model training completed in 0.20s
2024-12-29 14:19:58,787 - INFO - Prediction completed in 0.10s
2024-12-29 14:19:58,796 - INFO - Poison rate 0.03 completed in 4.50s
2024-12-29 14:19:58,796 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:19:58,802 - INFO - Total number of labels flipped: 473
2024-12-29 14:19:58,802 - INFO - Label flipping completed in 0.01s
2024-12-29 14:19:58,802 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:19:58,802 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:19:59,357 - INFO - Feature scaling completed in 0.55s
2024-12-29 14:19:59,357 - INFO - Starting feature selection (k=50)
2024-12-29 14:19:59,371 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:19:59,371 - INFO - Starting anomaly detection
2024-12-29 14:20:03,485 - INFO - Anomaly detection completed in 4.11s
2024-12-29 14:20:03,486 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:20:03,486 - INFO - Total fit_transform time: 4.68s
2024-12-29 14:20:03,486 - INFO - Training set processing completed in 4.68s
2024-12-29 14:20:03,486 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:20:03,487 - INFO - Memory usage at start_fit: CPU 2762.7 MB, GPU 122.6 MB
2024-12-29 14:20:03,488 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:20:03,684 - INFO - Fitted scaler and transformed data
2024-12-29 14:20:03,684 - INFO - Scaling time: 0.20s
2024-12-29 14:20:03,691 - INFO - Training completed in 0.20s
2024-12-29 14:20:03,692 - INFO - Final memory usage: CPU 2762.7 MB, GPU 122.6 MB
2024-12-29 14:20:03,692 - INFO - Model training completed in 0.21s
2024-12-29 14:20:03,793 - INFO - Prediction completed in 0.10s
2024-12-29 14:20:03,802 - INFO - Poison rate 0.05 completed in 5.01s
2024-12-29 14:20:03,802 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:20:03,810 - INFO - Total number of labels flipped: 662
2024-12-29 14:20:03,811 - INFO - Label flipping completed in 0.01s
2024-12-29 14:20:03,811 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:20:03,811 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:20:04,347 - INFO - Feature scaling completed in 0.54s
2024-12-29 14:20:04,347 - INFO - Starting feature selection (k=50)
2024-12-29 14:20:04,355 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:20:04,355 - INFO - Starting anomaly detection
2024-12-29 14:20:08,096 - INFO - Anomaly detection completed in 3.74s
2024-12-29 14:20:08,096 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:20:08,096 - INFO - Total fit_transform time: 4.29s
2024-12-29 14:20:08,097 - INFO - Training set processing completed in 4.29s
2024-12-29 14:20:08,097 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:20:08,098 - INFO - Memory usage at start_fit: CPU 2762.7 MB, GPU 122.6 MB
2024-12-29 14:20:08,098 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:20:08,273 - INFO - Fitted scaler and transformed data
2024-12-29 14:20:08,273 - INFO - Scaling time: 0.18s
2024-12-29 14:20:08,281 - INFO - Training completed in 0.18s
2024-12-29 14:20:08,281 - INFO - Final memory usage: CPU 2762.7 MB, GPU 122.6 MB
2024-12-29 14:20:08,282 - INFO - Model training completed in 0.18s
2024-12-29 14:20:08,406 - INFO - Prediction completed in 0.12s
2024-12-29 14:20:08,414 - INFO - Poison rate 0.07 completed in 4.61s
2024-12-29 14:20:08,414 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:20:08,425 - INFO - Total number of labels flipped: 946
2024-12-29 14:20:08,426 - INFO - Label flipping completed in 0.01s
2024-12-29 14:20:08,426 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:20:08,426 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:20:08,965 - INFO - Feature scaling completed in 0.54s
2024-12-29 14:20:08,965 - INFO - Starting feature selection (k=50)
2024-12-29 14:20:08,979 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:20:08,979 - INFO - Starting anomaly detection
2024-12-29 14:20:12,861 - INFO - Anomaly detection completed in 3.88s
2024-12-29 14:20:12,862 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:20:12,862 - INFO - Total fit_transform time: 4.44s
2024-12-29 14:20:12,862 - INFO - Training set processing completed in 4.44s
2024-12-29 14:20:12,862 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:20:12,863 - INFO - Memory usage at start_fit: CPU 2762.7 MB, GPU 122.6 MB
2024-12-29 14:20:12,863 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:20:13,031 - INFO - Fitted scaler and transformed data
2024-12-29 14:20:13,031 - INFO - Scaling time: 0.17s
2024-12-29 14:20:13,038 - INFO - Training completed in 0.18s
2024-12-29 14:20:13,039 - INFO - Final memory usage: CPU 2762.7 MB, GPU 122.6 MB
2024-12-29 14:20:13,039 - INFO - Model training completed in 0.18s
2024-12-29 14:20:13,156 - INFO - Prediction completed in 0.12s
2024-12-29 14:20:13,165 - INFO - Poison rate 0.1 completed in 4.75s
2024-12-29 14:20:13,166 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:20:13,188 - INFO - Total number of labels flipped: 1893
2024-12-29 14:20:13,189 - INFO - Label flipping completed in 0.02s
2024-12-29 14:20:13,189 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:20:13,189 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:20:13,726 - INFO - Feature scaling completed in 0.54s
2024-12-29 14:20:13,726 - INFO - Starting feature selection (k=50)
2024-12-29 14:20:13,738 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:20:13,738 - INFO - Starting anomaly detection
2024-12-29 14:20:17,007 - INFO - Anomaly detection completed in 3.27s
2024-12-29 14:20:17,008 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:20:17,008 - INFO - Total fit_transform time: 3.82s
2024-12-29 14:20:17,008 - INFO - Training set processing completed in 3.82s
2024-12-29 14:20:17,008 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:20:17,009 - INFO - Memory usage at start_fit: CPU 2762.7 MB, GPU 122.6 MB
2024-12-29 14:20:17,009 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:20:17,223 - INFO - Fitted scaler and transformed data
2024-12-29 14:20:17,224 - INFO - Scaling time: 0.21s
2024-12-29 14:20:17,231 - INFO - Training completed in 0.22s
2024-12-29 14:20:17,232 - INFO - Final memory usage: CPU 2762.7 MB, GPU 122.6 MB
2024-12-29 14:20:17,232 - INFO - Model training completed in 0.22s
2024-12-29 14:20:17,374 - INFO - Prediction completed in 0.14s
2024-12-29 14:20:17,391 - INFO - Poison rate 0.2 completed in 4.23s
2024-12-29 14:20:17,400 - INFO - Loaded 441 existing results
2024-12-29 14:20:17,400 - INFO - Total results to save: 448
2024-12-29 14:20:17,401 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:20:17,415 - INFO - Saved 448 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:20:17,416 - INFO - Total evaluation time: 63.04s
2024-12-29 14:20:17,417 - INFO - Completed evaluation for ImageNette
2024-12-29 14:20:17,418 - INFO - 
Processing dataset: CIFAR100
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:20:17,599 - INFO - 
Progress: 67.7% - Evaluating CIFAR100 with SVM (standard mode, iteration 1/1)
2024-12-29 14:20:17,772 - INFO - Loading datasets...
2024-12-29 14:20:17,793 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:20:17,793 - INFO - Extracting validation features...
2024-12-29 14:20:17,793 - INFO - Extracting features from 3925 samples...
2024-12-29 14:20:27,199 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:20:27,205 - INFO - Validation feature extraction completed in 9.41s
2024-12-29 14:20:27,205 - INFO - Extracting training features...
2024-12-29 14:20:27,205 - INFO - Extracting features from 9469 samples...
2024-12-29 14:20:48,579 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:20:48,584 - INFO - Training feature extraction completed in 21.38s
2024-12-29 14:20:48,585 - INFO - Creating model for classifier: SVM
2024-12-29 14:20:48,585 - INFO - Using device: cuda
2024-12-29 14:20:48,586 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-29 14:20:48,586 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:20:48,586 - INFO - Training set processing completed in 0.00s
2024-12-29 14:20:48,586 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:20:48,588 - INFO - Memory usage at start_fit: CPU 2764.7 MB, GPU 104.6 MB
2024-12-29 14:20:48,588 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:20:48,593 - INFO - Number of unique classes: 10
2024-12-29 14:20:48,665 - INFO - Fitted scaler and transformed data
2024-12-29 14:20:48,665 - INFO - Scaling time: 0.07s
2024-12-29 14:20:49,054 - INFO - Epoch 1/500, Train Loss: 0.7665, Val Loss: 0.1064
2024-12-29 14:20:49,428 - INFO - Epoch 2/500, Train Loss: 0.0814, Val Loss: 0.0821
2024-12-29 14:20:49,775 - INFO - Epoch 3/500, Train Loss: 0.0531, Val Loss: 0.0742
2024-12-29 14:20:50,106 - INFO - Epoch 4/500, Train Loss: 0.0389, Val Loss: 0.0682
2024-12-29 14:20:50,413 - INFO - Epoch 5/500, Train Loss: 0.0309, Val Loss: 0.0645
2024-12-29 14:20:50,726 - INFO - Epoch 6/500, Train Loss: 0.0242, Val Loss: 0.0641
2024-12-29 14:20:51,130 - INFO - Epoch 7/500, Train Loss: 0.0198, Val Loss: 0.0606
2024-12-29 14:20:51,498 - INFO - Epoch 8/500, Train Loss: 0.0162, Val Loss: 0.0606
2024-12-29 14:20:51,825 - INFO - Epoch 9/500, Train Loss: 0.0136, Val Loss: 0.0593
2024-12-29 14:20:52,227 - INFO - Epoch 10/500, Train Loss: 0.0112, Val Loss: 0.0594
2024-12-29 14:20:52,648 - INFO - Epoch 11/500, Train Loss: 0.0099, Val Loss: 0.0571
2024-12-29 14:20:53,008 - INFO - Epoch 12/500, Train Loss: 0.0085, Val Loss: 0.0562
2024-12-29 14:20:53,349 - INFO - Epoch 13/500, Train Loss: 0.0077, Val Loss: 0.0558
2024-12-29 14:20:53,694 - INFO - Epoch 14/500, Train Loss: 0.0067, Val Loss: 0.0569
2024-12-29 14:20:54,074 - INFO - Epoch 15/500, Train Loss: 0.0059, Val Loss: 0.0571
2024-12-29 14:20:54,444 - INFO - Epoch 16/500, Train Loss: 0.0053, Val Loss: 0.0582
2024-12-29 14:20:54,827 - INFO - Epoch 17/500, Train Loss: 0.0052, Val Loss: 0.0580
2024-12-29 14:20:55,176 - INFO - Epoch 18/500, Train Loss: 0.0047, Val Loss: 0.0574
2024-12-29 14:20:55,176 - INFO - Early stopping triggered at epoch 18
2024-12-29 14:20:55,176 - INFO - Training completed in 6.59s
2024-12-29 14:20:55,177 - INFO - Final memory usage: CPU 2765.2 MB, GPU 104.8 MB
2024-12-29 14:20:55,181 - INFO - Model training completed in 6.60s
2024-12-29 14:20:55,227 - INFO - Prediction completed in 0.04s
2024-12-29 14:20:55,251 - INFO - Poison rate 0.0 completed in 6.66s
2024-12-29 14:20:55,251 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:20:55,254 - INFO - Total number of labels flipped: 94
2024-12-29 14:20:55,254 - INFO - Label flipping completed in 0.00s
2024-12-29 14:20:55,254 - INFO - Training set processing completed in 0.00s
2024-12-29 14:20:55,254 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:20:55,255 - INFO - Memory usage at start_fit: CPU 2689.7 MB, GPU 104.7 MB
2024-12-29 14:20:55,256 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:20:55,259 - INFO - Number of unique classes: 10
2024-12-29 14:20:55,325 - INFO - Fitted scaler and transformed data
2024-12-29 14:20:55,326 - INFO - Scaling time: 0.07s
2024-12-29 14:20:55,687 - INFO - Epoch 1/500, Train Loss: 1.0972, Val Loss: 0.2634
2024-12-29 14:20:56,018 - INFO - Epoch 2/500, Train Loss: 0.2168, Val Loss: 0.2400
2024-12-29 14:20:56,336 - INFO - Epoch 3/500, Train Loss: 0.1672, Val Loss: 0.2285
2024-12-29 14:20:56,710 - INFO - Epoch 4/500, Train Loss: 0.1340, Val Loss: 0.2218
2024-12-29 14:20:57,040 - INFO - Epoch 5/500, Train Loss: 0.1109, Val Loss: 0.2209
2024-12-29 14:20:57,452 - INFO - Epoch 6/500, Train Loss: 0.0965, Val Loss: 0.2191
2024-12-29 14:20:57,781 - INFO - Epoch 7/500, Train Loss: 0.0836, Val Loss: 0.2165
2024-12-29 14:20:58,141 - INFO - Epoch 8/500, Train Loss: 0.0747, Val Loss: 0.2188
2024-12-29 14:20:58,530 - INFO - Epoch 9/500, Train Loss: 0.0683, Val Loss: 0.2175
2024-12-29 14:20:58,886 - INFO - Epoch 10/500, Train Loss: 0.0627, Val Loss: 0.2204
2024-12-29 14:20:59,202 - INFO - Epoch 11/500, Train Loss: 0.0583, Val Loss: 0.2185
2024-12-29 14:20:59,532 - INFO - Epoch 12/500, Train Loss: 0.0542, Val Loss: 0.2206
2024-12-29 14:20:59,533 - INFO - Early stopping triggered at epoch 12
2024-12-29 14:20:59,533 - INFO - Training completed in 4.28s
2024-12-29 14:20:59,533 - INFO - Final memory usage: CPU 2718.7 MB, GPU 104.8 MB
2024-12-29 14:20:59,534 - INFO - Model training completed in 4.28s
2024-12-29 14:20:59,589 - INFO - Prediction completed in 0.05s
2024-12-29 14:20:59,598 - INFO - Poison rate 0.01 completed in 4.35s
2024-12-29 14:20:59,598 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:20:59,602 - INFO - Total number of labels flipped: 284
2024-12-29 14:20:59,602 - INFO - Label flipping completed in 0.00s
2024-12-29 14:20:59,602 - INFO - Training set processing completed in 0.00s
2024-12-29 14:20:59,602 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:20:59,603 - INFO - Memory usage at start_fit: CPU 2689.3 MB, GPU 104.7 MB
2024-12-29 14:20:59,604 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:20:59,608 - INFO - Number of unique classes: 10
2024-12-29 14:20:59,692 - INFO - Fitted scaler and transformed data
2024-12-29 14:20:59,692 - INFO - Scaling time: 0.08s
2024-12-29 14:21:00,029 - INFO - Epoch 1/500, Train Loss: 1.3026, Val Loss: 0.4749
2024-12-29 14:21:00,357 - INFO - Epoch 2/500, Train Loss: 0.4741, Val Loss: 0.4470
2024-12-29 14:21:00,691 - INFO - Epoch 3/500, Train Loss: 0.3893, Val Loss: 0.4377
2024-12-29 14:21:01,015 - INFO - Epoch 4/500, Train Loss: 0.3354, Val Loss: 0.4440
2024-12-29 14:21:01,349 - INFO - Epoch 5/500, Train Loss: 0.2928, Val Loss: 0.4442
2024-12-29 14:21:01,730 - INFO - Epoch 6/500, Train Loss: 0.2599, Val Loss: 0.4573
2024-12-29 14:21:02,082 - INFO - Epoch 7/500, Train Loss: 0.2360, Val Loss: 0.4576
2024-12-29 14:21:02,422 - INFO - Epoch 8/500, Train Loss: 0.2177, Val Loss: 0.4582
2024-12-29 14:21:02,423 - INFO - Early stopping triggered at epoch 8
2024-12-29 14:21:02,423 - INFO - Training completed in 2.82s
2024-12-29 14:21:02,423 - INFO - Final memory usage: CPU 2718.6 MB, GPU 104.8 MB
2024-12-29 14:21:02,424 - INFO - Model training completed in 2.82s
2024-12-29 14:21:02,482 - INFO - Prediction completed in 0.06s
2024-12-29 14:21:02,491 - INFO - Poison rate 0.03 completed in 2.89s
2024-12-29 14:21:02,492 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:21:02,498 - INFO - Total number of labels flipped: 473
2024-12-29 14:21:02,498 - INFO - Label flipping completed in 0.01s
2024-12-29 14:21:02,498 - INFO - Training set processing completed in 0.00s
2024-12-29 14:21:02,498 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:21:02,499 - INFO - Memory usage at start_fit: CPU 2689.2 MB, GPU 104.7 MB
2024-12-29 14:21:02,499 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:21:02,502 - INFO - Number of unique classes: 10
2024-12-29 14:21:02,573 - INFO - Fitted scaler and transformed data
2024-12-29 14:21:02,573 - INFO - Scaling time: 0.07s
2024-12-29 14:21:02,927 - INFO - Epoch 1/500, Train Loss: 1.4365, Val Loss: 0.8825
2024-12-29 14:21:03,261 - INFO - Epoch 2/500, Train Loss: 0.6838, Val Loss: 0.8717
2024-12-29 14:21:03,597 - INFO - Epoch 3/500, Train Loss: 0.5951, Val Loss: 0.8802
2024-12-29 14:21:03,938 - INFO - Epoch 4/500, Train Loss: 0.5264, Val Loss: 0.8992
2024-12-29 14:21:04,294 - INFO - Epoch 5/500, Train Loss: 0.4775, Val Loss: 0.8915
2024-12-29 14:21:04,627 - INFO - Epoch 6/500, Train Loss: 0.4406, Val Loss: 0.9135
2024-12-29 14:21:04,970 - INFO - Epoch 7/500, Train Loss: 0.4116, Val Loss: 0.9133
2024-12-29 14:21:04,971 - INFO - Early stopping triggered at epoch 7
2024-12-29 14:21:04,971 - INFO - Training completed in 2.47s
2024-12-29 14:21:04,971 - INFO - Final memory usage: CPU 2718.8 MB, GPU 104.8 MB
2024-12-29 14:21:04,972 - INFO - Model training completed in 2.47s
2024-12-29 14:21:05,019 - INFO - Prediction completed in 0.05s
2024-12-29 14:21:05,035 - INFO - Poison rate 0.05 completed in 2.54s
2024-12-29 14:21:05,035 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:21:05,045 - INFO - Total number of labels flipped: 662
2024-12-29 14:21:05,045 - INFO - Label flipping completed in 0.01s
2024-12-29 14:21:05,045 - INFO - Training set processing completed in 0.00s
2024-12-29 14:21:05,045 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:21:05,046 - INFO - Memory usage at start_fit: CPU 2689.4 MB, GPU 104.7 MB
2024-12-29 14:21:05,046 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:21:05,050 - INFO - Number of unique classes: 10
2024-12-29 14:21:05,127 - INFO - Fitted scaler and transformed data
2024-12-29 14:21:05,127 - INFO - Scaling time: 0.08s
2024-12-29 14:21:05,504 - INFO - Epoch 1/500, Train Loss: 1.5357, Val Loss: 1.1239
2024-12-29 14:21:05,862 - INFO - Epoch 2/500, Train Loss: 0.8895, Val Loss: 1.1049
2024-12-29 14:21:06,222 - INFO - Epoch 3/500, Train Loss: 0.7766, Val Loss: 1.1160
2024-12-29 14:21:06,574 - INFO - Epoch 4/500, Train Loss: 0.6982, Val Loss: 1.1511
2024-12-29 14:21:06,959 - INFO - Epoch 5/500, Train Loss: 0.6440, Val Loss: 1.1413
2024-12-29 14:21:07,298 - INFO - Epoch 6/500, Train Loss: 0.6009, Val Loss: 1.1469
2024-12-29 14:21:07,714 - INFO - Epoch 7/500, Train Loss: 0.5646, Val Loss: 1.1479
2024-12-29 14:21:07,715 - INFO - Early stopping triggered at epoch 7
2024-12-29 14:21:07,715 - INFO - Training completed in 2.67s
2024-12-29 14:21:07,716 - INFO - Final memory usage: CPU 2718.7 MB, GPU 104.8 MB
2024-12-29 14:21:07,717 - INFO - Model training completed in 2.67s
2024-12-29 14:21:07,777 - INFO - Prediction completed in 0.06s
2024-12-29 14:21:07,786 - INFO - Poison rate 0.07 completed in 2.75s
2024-12-29 14:21:07,786 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:21:07,797 - INFO - Total number of labels flipped: 946
2024-12-29 14:21:07,798 - INFO - Label flipping completed in 0.01s
2024-12-29 14:21:07,798 - INFO - Training set processing completed in 0.00s
2024-12-29 14:21:07,798 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:21:07,799 - INFO - Memory usage at start_fit: CPU 2689.4 MB, GPU 104.7 MB
2024-12-29 14:21:07,799 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:21:07,802 - INFO - Number of unique classes: 10
2024-12-29 14:21:07,887 - INFO - Fitted scaler and transformed data
2024-12-29 14:21:07,887 - INFO - Scaling time: 0.08s
2024-12-29 14:21:08,217 - INFO - Epoch 1/500, Train Loss: 1.9625, Val Loss: 1.6095
2024-12-29 14:21:08,559 - INFO - Epoch 2/500, Train Loss: 1.2365, Val Loss: 1.5883
2024-12-29 14:21:08,936 - INFO - Epoch 3/500, Train Loss: 1.0996, Val Loss: 1.6043
2024-12-29 14:21:09,291 - INFO - Epoch 4/500, Train Loss: 1.0004, Val Loss: 1.6308
2024-12-29 14:21:09,678 - INFO - Epoch 5/500, Train Loss: 0.9363, Val Loss: 1.6525
2024-12-29 14:21:10,031 - INFO - Epoch 6/500, Train Loss: 0.8811, Val Loss: 1.6575
2024-12-29 14:21:10,405 - INFO - Epoch 7/500, Train Loss: 0.8418, Val Loss: 1.7020
2024-12-29 14:21:10,405 - INFO - Early stopping triggered at epoch 7
2024-12-29 14:21:10,405 - INFO - Training completed in 2.61s
2024-12-29 14:21:10,405 - INFO - Final memory usage: CPU 2718.6 MB, GPU 104.8 MB
2024-12-29 14:21:10,406 - INFO - Model training completed in 2.61s
2024-12-29 14:21:10,451 - INFO - Prediction completed in 0.04s
2024-12-29 14:21:10,460 - INFO - Poison rate 0.1 completed in 2.67s
2024-12-29 14:21:10,460 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:21:10,482 - INFO - Total number of labels flipped: 1893
2024-12-29 14:21:10,482 - INFO - Label flipping completed in 0.02s
2024-12-29 14:21:10,482 - INFO - Training set processing completed in 0.00s
2024-12-29 14:21:10,482 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:21:10,483 - INFO - Memory usage at start_fit: CPU 2689.3 MB, GPU 104.7 MB
2024-12-29 14:21:10,483 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:21:10,487 - INFO - Number of unique classes: 10
2024-12-29 14:21:10,558 - INFO - Fitted scaler and transformed data
2024-12-29 14:21:10,559 - INFO - Scaling time: 0.07s
2024-12-29 14:21:10,914 - INFO - Epoch 1/500, Train Loss: 3.0473, Val Loss: 2.5044
2024-12-29 14:21:11,316 - INFO - Epoch 2/500, Train Loss: 2.3364, Val Loss: 2.4402
2024-12-29 14:21:11,659 - INFO - Epoch 3/500, Train Loss: 2.1386, Val Loss: 2.4250
2024-12-29 14:21:12,018 - INFO - Epoch 4/500, Train Loss: 2.0056, Val Loss: 2.4278
2024-12-29 14:21:12,405 - INFO - Epoch 5/500, Train Loss: 1.9107, Val Loss: 2.4327
2024-12-29 14:21:12,789 - INFO - Epoch 6/500, Train Loss: 1.8438, Val Loss: 2.4774
2024-12-29 14:21:13,130 - INFO - Epoch 7/500, Train Loss: 1.7804, Val Loss: 2.4776
2024-12-29 14:21:13,479 - INFO - Epoch 8/500, Train Loss: 1.7289, Val Loss: 2.5132
2024-12-29 14:21:13,480 - INFO - Early stopping triggered at epoch 8
2024-12-29 14:21:13,480 - INFO - Training completed in 3.00s
2024-12-29 14:21:13,481 - INFO - Final memory usage: CPU 2718.6 MB, GPU 104.8 MB
2024-12-29 14:21:13,483 - INFO - Model training completed in 3.00s
2024-12-29 14:21:13,538 - INFO - Prediction completed in 0.05s
2024-12-29 14:21:13,547 - INFO - Poison rate 0.2 completed in 3.09s
2024-12-29 14:21:13,556 - INFO - Loaded 448 existing results
2024-12-29 14:21:13,556 - INFO - Total results to save: 455
2024-12-29 14:21:13,557 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:21:13,571 - INFO - Saved 455 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:21:13,571 - INFO - Total evaluation time: 55.80s
2024-12-29 14:21:13,573 - INFO - 
Progress: 68.8% - Evaluating CIFAR100 with SVM (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:21:13,759 - INFO - Loading datasets...
2024-12-29 14:21:13,780 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:21:13,780 - INFO - Extracting validation features...
2024-12-29 14:21:13,780 - INFO - Extracting features from 3925 samples...
2024-12-29 14:21:23,251 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:21:23,257 - INFO - Validation feature extraction completed in 9.48s
2024-12-29 14:21:23,258 - INFO - Extracting training features...
2024-12-29 14:21:23,258 - INFO - Extracting features from 9469 samples...
2024-12-29 14:21:45,141 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:21:45,146 - INFO - Training feature extraction completed in 21.89s
2024-12-29 14:21:45,146 - INFO - Creating model for classifier: SVM
2024-12-29 14:21:45,147 - INFO - Using device: cuda
2024-12-29 14:21:45,147 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-29 14:21:45,147 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:21:45,148 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:21:45,148 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:21:45,732 - INFO - Feature scaling completed in 0.58s
2024-12-29 14:21:45,733 - INFO - Starting feature selection (k=50)
2024-12-29 14:21:45,741 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:21:45,741 - INFO - Starting anomaly detection
2024-12-29 14:21:47,903 - INFO - Anomaly detection completed in 2.16s
2024-12-29 14:21:47,903 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:21:47,904 - INFO - Total fit_transform time: 2.76s
2024-12-29 14:21:47,904 - INFO - Training set processing completed in 2.76s
2024-12-29 14:21:47,904 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:21:47,906 - INFO - Memory usage at start_fit: CPU 2709.2 MB, GPU 104.0 MB
2024-12-29 14:21:47,907 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:21:47,909 - INFO - Number of unique classes: 10
2024-12-29 14:21:47,992 - INFO - Fitted scaler and transformed data
2024-12-29 14:21:47,992 - INFO - Scaling time: 0.08s
2024-12-29 14:21:48,388 - INFO - Epoch 1/500, Train Loss: 0.7025, Val Loss: 0.1345
2024-12-29 14:21:48,778 - INFO - Epoch 2/500, Train Loss: 0.0879, Val Loss: 0.1054
2024-12-29 14:21:49,117 - INFO - Epoch 3/500, Train Loss: 0.0582, Val Loss: 0.0941
2024-12-29 14:21:49,495 - INFO - Epoch 4/500, Train Loss: 0.0412, Val Loss: 0.0890
2024-12-29 14:21:49,816 - INFO - Epoch 5/500, Train Loss: 0.0304, Val Loss: 0.0857
2024-12-29 14:21:50,192 - INFO - Epoch 6/500, Train Loss: 0.0237, Val Loss: 0.0865
2024-12-29 14:21:50,633 - INFO - Epoch 7/500, Train Loss: 0.0186, Val Loss: 0.0839
2024-12-29 14:21:51,053 - INFO - Epoch 8/500, Train Loss: 0.0152, Val Loss: 0.0832
2024-12-29 14:21:51,430 - INFO - Epoch 9/500, Train Loss: 0.0126, Val Loss: 0.0830
2024-12-29 14:21:51,785 - INFO - Epoch 10/500, Train Loss: 0.0105, Val Loss: 0.0809
2024-12-29 14:21:52,123 - INFO - Epoch 11/500, Train Loss: 0.0091, Val Loss: 0.0820
2024-12-29 14:21:52,475 - INFO - Epoch 12/500, Train Loss: 0.0078, Val Loss: 0.0796
2024-12-29 14:21:52,857 - INFO - Epoch 13/500, Train Loss: 0.0066, Val Loss: 0.0802
2024-12-29 14:21:53,212 - INFO - Epoch 14/500, Train Loss: 0.0058, Val Loss: 0.0829
2024-12-29 14:21:53,558 - INFO - Epoch 15/500, Train Loss: 0.0054, Val Loss: 0.0802
2024-12-29 14:21:53,878 - INFO - Epoch 16/500, Train Loss: 0.0049, Val Loss: 0.0828
2024-12-29 14:21:54,214 - INFO - Epoch 17/500, Train Loss: 0.0048, Val Loss: 0.0833
2024-12-29 14:21:54,214 - INFO - Early stopping triggered at epoch 17
2024-12-29 14:21:54,214 - INFO - Training completed in 6.31s
2024-12-29 14:21:54,214 - INFO - Final memory usage: CPU 2718.6 MB, GPU 104.2 MB
2024-12-29 14:21:54,215 - INFO - Model training completed in 6.31s
2024-12-29 14:21:54,281 - INFO - Prediction completed in 0.07s
2024-12-29 14:21:54,291 - INFO - Poison rate 0.0 completed in 9.14s
2024-12-29 14:21:54,291 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:21:54,293 - INFO - Total number of labels flipped: 94
2024-12-29 14:21:54,293 - INFO - Label flipping completed in 0.00s
2024-12-29 14:21:54,293 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:21:54,293 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:21:54,814 - INFO - Feature scaling completed in 0.52s
2024-12-29 14:21:54,814 - INFO - Starting feature selection (k=50)
2024-12-29 14:21:54,829 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:21:54,829 - INFO - Starting anomaly detection
2024-12-29 14:21:59,088 - INFO - Anomaly detection completed in 4.26s
2024-12-29 14:21:59,088 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:21:59,089 - INFO - Total fit_transform time: 4.80s
2024-12-29 14:21:59,089 - INFO - Training set processing completed in 4.80s
2024-12-29 14:21:59,089 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:21:59,090 - INFO - Memory usage at start_fit: CPU 2709.2 MB, GPU 104.1 MB
2024-12-29 14:21:59,091 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:21:59,093 - INFO - Number of unique classes: 10
2024-12-29 14:21:59,177 - INFO - Fitted scaler and transformed data
2024-12-29 14:21:59,178 - INFO - Scaling time: 0.08s
2024-12-29 14:21:59,503 - INFO - Epoch 1/500, Train Loss: 0.9564, Val Loss: 0.2218
2024-12-29 14:21:59,886 - INFO - Epoch 2/500, Train Loss: 0.2104, Val Loss: 0.2010
2024-12-29 14:22:00,203 - INFO - Epoch 3/500, Train Loss: 0.1578, Val Loss: 0.1967
2024-12-29 14:22:00,531 - INFO - Epoch 4/500, Train Loss: 0.1284, Val Loss: 0.1933
2024-12-29 14:22:00,860 - INFO - Epoch 5/500, Train Loss: 0.1058, Val Loss: 0.1941
2024-12-29 14:22:01,180 - INFO - Epoch 6/500, Train Loss: 0.0911, Val Loss: 0.1986
2024-12-29 14:22:01,511 - INFO - Epoch 7/500, Train Loss: 0.0800, Val Loss: 0.1983
2024-12-29 14:22:01,879 - INFO - Epoch 8/500, Train Loss: 0.0714, Val Loss: 0.2011
2024-12-29 14:22:02,257 - INFO - Epoch 9/500, Train Loss: 0.0660, Val Loss: 0.2030
2024-12-29 14:22:02,257 - INFO - Early stopping triggered at epoch 9
2024-12-29 14:22:02,257 - INFO - Training completed in 3.17s
2024-12-29 14:22:02,257 - INFO - Final memory usage: CPU 2718.5 MB, GPU 104.2 MB
2024-12-29 14:22:02,258 - INFO - Model training completed in 3.17s
2024-12-29 14:22:02,303 - INFO - Prediction completed in 0.04s
2024-12-29 14:22:02,311 - INFO - Poison rate 0.01 completed in 8.02s
2024-12-29 14:22:02,311 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:22:02,315 - INFO - Total number of labels flipped: 284
2024-12-29 14:22:02,315 - INFO - Label flipping completed in 0.00s
2024-12-29 14:22:02,315 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:22:02,315 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:22:02,885 - INFO - Feature scaling completed in 0.57s
2024-12-29 14:22:02,885 - INFO - Starting feature selection (k=50)
2024-12-29 14:22:02,900 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:22:02,900 - INFO - Starting anomaly detection
2024-12-29 14:22:06,351 - INFO - Anomaly detection completed in 3.45s
2024-12-29 14:22:06,351 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:22:06,351 - INFO - Total fit_transform time: 4.04s
2024-12-29 14:22:06,351 - INFO - Training set processing completed in 4.04s
2024-12-29 14:22:06,352 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:22:06,353 - INFO - Memory usage at start_fit: CPU 2709.4 MB, GPU 104.1 MB
2024-12-29 14:22:06,353 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:22:06,356 - INFO - Number of unique classes: 10
2024-12-29 14:22:06,446 - INFO - Fitted scaler and transformed data
2024-12-29 14:22:06,446 - INFO - Scaling time: 0.09s
2024-12-29 14:22:06,844 - INFO - Epoch 1/500, Train Loss: 1.3010, Val Loss: 0.5443
2024-12-29 14:22:07,238 - INFO - Epoch 2/500, Train Loss: 0.4532, Val Loss: 0.5095
2024-12-29 14:22:07,595 - INFO - Epoch 3/500, Train Loss: 0.3777, Val Loss: 0.4917
2024-12-29 14:22:07,937 - INFO - Epoch 4/500, Train Loss: 0.3218, Val Loss: 0.4946
2024-12-29 14:22:08,303 - INFO - Epoch 5/500, Train Loss: 0.2847, Val Loss: 0.4916
2024-12-29 14:22:08,640 - INFO - Epoch 6/500, Train Loss: 0.2563, Val Loss: 0.5010
2024-12-29 14:22:08,998 - INFO - Epoch 7/500, Train Loss: 0.2336, Val Loss: 0.5027
2024-12-29 14:22:09,356 - INFO - Epoch 8/500, Train Loss: 0.2152, Val Loss: 0.4977
2024-12-29 14:22:09,356 - INFO - Early stopping triggered at epoch 8
2024-12-29 14:22:09,356 - INFO - Training completed in 3.00s
2024-12-29 14:22:09,356 - INFO - Final memory usage: CPU 2718.7 MB, GPU 104.2 MB
2024-12-29 14:22:09,357 - INFO - Model training completed in 3.01s
2024-12-29 14:22:09,402 - INFO - Prediction completed in 0.04s
2024-12-29 14:22:09,416 - INFO - Poison rate 0.03 completed in 7.10s
2024-12-29 14:22:09,416 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:22:09,427 - INFO - Total number of labels flipped: 473
2024-12-29 14:22:09,427 - INFO - Label flipping completed in 0.01s
2024-12-29 14:22:09,427 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:22:09,427 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:22:09,964 - INFO - Feature scaling completed in 0.54s
2024-12-29 14:22:09,965 - INFO - Starting feature selection (k=50)
2024-12-29 14:22:09,979 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:22:09,979 - INFO - Starting anomaly detection
2024-12-29 14:22:14,163 - INFO - Anomaly detection completed in 4.18s
2024-12-29 14:22:14,163 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:22:14,164 - INFO - Total fit_transform time: 4.74s
2024-12-29 14:22:14,164 - INFO - Training set processing completed in 4.74s
2024-12-29 14:22:14,164 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:22:14,165 - INFO - Memory usage at start_fit: CPU 2709.7 MB, GPU 104.1 MB
2024-12-29 14:22:14,166 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:22:14,168 - INFO - Number of unique classes: 10
2024-12-29 14:22:14,238 - INFO - Fitted scaler and transformed data
2024-12-29 14:22:14,238 - INFO - Scaling time: 0.07s
2024-12-29 14:22:14,593 - INFO - Epoch 1/500, Train Loss: 1.4493, Val Loss: 0.9779
2024-12-29 14:22:14,944 - INFO - Epoch 2/500, Train Loss: 0.6589, Val Loss: 0.9494
2024-12-29 14:22:15,258 - INFO - Epoch 3/500, Train Loss: 0.5652, Val Loss: 0.9385
2024-12-29 14:22:15,581 - INFO - Epoch 4/500, Train Loss: 0.5018, Val Loss: 0.9517
2024-12-29 14:22:15,915 - INFO - Epoch 5/500, Train Loss: 0.4484, Val Loss: 0.9551
2024-12-29 14:22:16,232 - INFO - Epoch 6/500, Train Loss: 0.4132, Val Loss: 0.9692
2024-12-29 14:22:16,579 - INFO - Epoch 7/500, Train Loss: 0.3820, Val Loss: 0.9667
2024-12-29 14:22:16,917 - INFO - Epoch 8/500, Train Loss: 0.3597, Val Loss: 0.9686
2024-12-29 14:22:16,917 - INFO - Early stopping triggered at epoch 8
2024-12-29 14:22:16,917 - INFO - Training completed in 2.75s
2024-12-29 14:22:16,918 - INFO - Final memory usage: CPU 2718.8 MB, GPU 104.2 MB
2024-12-29 14:22:16,919 - INFO - Model training completed in 2.75s
2024-12-29 14:22:16,984 - INFO - Prediction completed in 0.07s
2024-12-29 14:22:16,994 - INFO - Poison rate 0.05 completed in 7.58s
2024-12-29 14:22:16,995 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:22:17,003 - INFO - Total number of labels flipped: 662
2024-12-29 14:22:17,003 - INFO - Label flipping completed in 0.01s
2024-12-29 14:22:17,004 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:22:17,004 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:22:17,553 - INFO - Feature scaling completed in 0.55s
2024-12-29 14:22:17,554 - INFO - Starting feature selection (k=50)
2024-12-29 14:22:17,569 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 14:22:17,569 - INFO - Starting anomaly detection
2024-12-29 14:22:20,850 - INFO - Anomaly detection completed in 3.28s
2024-12-29 14:22:20,851 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:22:20,851 - INFO - Total fit_transform time: 3.85s
2024-12-29 14:22:20,851 - INFO - Training set processing completed in 3.85s
2024-12-29 14:22:20,851 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:22:20,852 - INFO - Memory usage at start_fit: CPU 2709.5 MB, GPU 104.1 MB
2024-12-29 14:22:20,852 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:22:20,854 - INFO - Number of unique classes: 10
2024-12-29 14:22:20,924 - INFO - Fitted scaler and transformed data
2024-12-29 14:22:20,924 - INFO - Scaling time: 0.07s
2024-12-29 14:22:21,293 - INFO - Epoch 1/500, Train Loss: 1.5401, Val Loss: 1.1315
2024-12-29 14:22:21,645 - INFO - Epoch 2/500, Train Loss: 0.8724, Val Loss: 1.1078
2024-12-29 14:22:21,982 - INFO - Epoch 3/500, Train Loss: 0.7594, Val Loss: 1.0937
2024-12-29 14:22:22,338 - INFO - Epoch 4/500, Train Loss: 0.6798, Val Loss: 1.1008
2024-12-29 14:22:22,720 - INFO - Epoch 5/500, Train Loss: 0.6287, Val Loss: 1.1094
2024-12-29 14:22:23,143 - INFO - Epoch 6/500, Train Loss: 0.5887, Val Loss: 1.1177
2024-12-29 14:22:23,538 - INFO - Epoch 7/500, Train Loss: 0.5483, Val Loss: 1.1219
2024-12-29 14:22:23,936 - INFO - Epoch 8/500, Train Loss: 0.5185, Val Loss: 1.1369
2024-12-29 14:22:23,936 - INFO - Early stopping triggered at epoch 8
2024-12-29 14:22:23,936 - INFO - Training completed in 3.08s
2024-12-29 14:22:23,936 - INFO - Final memory usage: CPU 2719.1 MB, GPU 104.2 MB
2024-12-29 14:22:23,938 - INFO - Model training completed in 3.09s
2024-12-29 14:22:23,987 - INFO - Prediction completed in 0.05s
2024-12-29 14:22:23,996 - INFO - Poison rate 0.07 completed in 7.00s
2024-12-29 14:22:23,996 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:22:24,008 - INFO - Total number of labels flipped: 946
2024-12-29 14:22:24,008 - INFO - Label flipping completed in 0.01s
2024-12-29 14:22:24,008 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:22:24,008 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:22:24,532 - INFO - Feature scaling completed in 0.52s
2024-12-29 14:22:24,532 - INFO - Starting feature selection (k=50)
2024-12-29 14:22:24,547 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:22:24,547 - INFO - Starting anomaly detection
2024-12-29 14:22:28,409 - INFO - Anomaly detection completed in 3.86s
2024-12-29 14:22:28,409 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:22:28,409 - INFO - Total fit_transform time: 4.40s
2024-12-29 14:22:28,410 - INFO - Training set processing completed in 4.40s
2024-12-29 14:22:28,410 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:22:28,411 - INFO - Memory usage at start_fit: CPU 2709.4 MB, GPU 104.1 MB
2024-12-29 14:22:28,411 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:22:28,413 - INFO - Number of unique classes: 10
2024-12-29 14:22:28,484 - INFO - Fitted scaler and transformed data
2024-12-29 14:22:28,484 - INFO - Scaling time: 0.07s
2024-12-29 14:22:28,867 - INFO - Epoch 1/500, Train Loss: 1.8451, Val Loss: 1.3084
2024-12-29 14:22:29,223 - INFO - Epoch 2/500, Train Loss: 1.1878, Val Loss: 1.2596
2024-12-29 14:22:29,586 - INFO - Epoch 3/500, Train Loss: 1.0519, Val Loss: 1.2496
2024-12-29 14:22:29,987 - INFO - Epoch 4/500, Train Loss: 0.9537, Val Loss: 1.2690
2024-12-29 14:22:30,349 - INFO - Epoch 5/500, Train Loss: 0.8923, Val Loss: 1.2830
2024-12-29 14:22:30,705 - INFO - Epoch 6/500, Train Loss: 0.8407, Val Loss: 1.3042
2024-12-29 14:22:31,118 - INFO - Epoch 7/500, Train Loss: 0.8002, Val Loss: 1.3359
2024-12-29 14:22:31,531 - INFO - Epoch 8/500, Train Loss: 0.7696, Val Loss: 1.3211
2024-12-29 14:22:31,531 - INFO - Early stopping triggered at epoch 8
2024-12-29 14:22:31,531 - INFO - Training completed in 3.12s
2024-12-29 14:22:31,531 - INFO - Final memory usage: CPU 2718.9 MB, GPU 104.2 MB
2024-12-29 14:22:31,532 - INFO - Model training completed in 3.12s
2024-12-29 14:22:31,596 - INFO - Prediction completed in 0.06s
2024-12-29 14:22:31,613 - INFO - Poison rate 0.1 completed in 7.62s
2024-12-29 14:22:31,614 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:22:31,637 - INFO - Total number of labels flipped: 1893
2024-12-29 14:22:31,637 - INFO - Label flipping completed in 0.02s
2024-12-29 14:22:31,637 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:22:31,637 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:22:32,188 - INFO - Feature scaling completed in 0.55s
2024-12-29 14:22:32,188 - INFO - Starting feature selection (k=50)
2024-12-29 14:22:32,206 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 14:22:32,207 - INFO - Starting anomaly detection
2024-12-29 14:22:36,020 - INFO - Anomaly detection completed in 3.81s
2024-12-29 14:22:36,020 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:22:36,021 - INFO - Total fit_transform time: 4.38s
2024-12-29 14:22:36,021 - INFO - Training set processing completed in 4.38s
2024-12-29 14:22:36,021 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:22:36,023 - INFO - Memory usage at start_fit: CPU 2709.9 MB, GPU 104.1 MB
2024-12-29 14:22:36,023 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:22:36,025 - INFO - Number of unique classes: 10
2024-12-29 14:22:36,108 - INFO - Fitted scaler and transformed data
2024-12-29 14:22:36,109 - INFO - Scaling time: 0.08s
2024-12-29 14:22:36,449 - INFO - Epoch 1/500, Train Loss: 2.9255, Val Loss: 2.3038
2024-12-29 14:22:36,796 - INFO - Epoch 2/500, Train Loss: 2.2176, Val Loss: 2.2666
2024-12-29 14:22:37,183 - INFO - Epoch 3/500, Train Loss: 2.0372, Val Loss: 2.2635
2024-12-29 14:22:37,519 - INFO - Epoch 4/500, Train Loss: 1.9132, Val Loss: 2.2483
2024-12-29 14:22:37,925 - INFO - Epoch 5/500, Train Loss: 1.8293, Val Loss: 2.2593
2024-12-29 14:22:38,263 - INFO - Epoch 6/500, Train Loss: 1.7650, Val Loss: 2.2857
2024-12-29 14:22:38,657 - INFO - Epoch 7/500, Train Loss: 1.7066, Val Loss: 2.3059
2024-12-29 14:22:39,001 - INFO - Epoch 8/500, Train Loss: 1.6707, Val Loss: 2.3224
2024-12-29 14:22:39,319 - INFO - Epoch 9/500, Train Loss: 1.6347, Val Loss: 2.3310
2024-12-29 14:22:39,320 - INFO - Early stopping triggered at epoch 9
2024-12-29 14:22:39,320 - INFO - Training completed in 3.30s
2024-12-29 14:22:39,320 - INFO - Final memory usage: CPU 2719.4 MB, GPU 104.2 MB
2024-12-29 14:22:39,321 - INFO - Model training completed in 3.30s
2024-12-29 14:22:39,381 - INFO - Prediction completed in 0.06s
2024-12-29 14:22:39,390 - INFO - Poison rate 0.2 completed in 7.78s
2024-12-29 14:22:39,399 - INFO - Loaded 455 existing results
2024-12-29 14:22:39,399 - INFO - Total results to save: 462
2024-12-29 14:22:39,400 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:22:39,414 - INFO - Saved 462 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:22:39,415 - INFO - Total evaluation time: 85.66s
2024-12-29 14:22:39,416 - INFO - 
Progress: 69.8% - Evaluating CIFAR100 with LogisticRegression (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:22:39,601 - INFO - Loading datasets...
2024-12-29 14:22:39,622 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:22:39,622 - INFO - Extracting validation features...
2024-12-29 14:22:39,622 - INFO - Extracting features from 3925 samples...
2024-12-29 14:22:49,119 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:22:49,125 - INFO - Validation feature extraction completed in 9.50s
2024-12-29 14:22:49,126 - INFO - Extracting training features...
2024-12-29 14:22:49,126 - INFO - Extracting features from 9469 samples...
2024-12-29 14:23:10,802 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:23:10,806 - INFO - Training feature extraction completed in 21.68s
2024-12-29 14:23:10,807 - INFO - Creating model for classifier: LogisticRegression
2024-12-29 14:23:10,807 - INFO - Using device: cuda
2024-12-29 14:23:10,808 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:23:10,808 - INFO - Training set processing completed in 0.00s
2024-12-29 14:23:10,809 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:23:10,811 - INFO - Memory usage at start_fit: CPU 2685.9 MB, GPU 104.6 MB
2024-12-29 14:23:10,811 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:23:10,818 - INFO - Number of unique classes: 10
2024-12-29 14:23:10,899 - INFO - Fitted scaler and transformed data
2024-12-29 14:23:10,900 - INFO - Scaling time: 0.08s
2024-12-29 14:23:11,122 - INFO - Epoch 1/1000, Train Loss: 0.4706, Val Loss: 0.1070
2024-12-29 14:23:11,324 - INFO - Epoch 2/1000, Train Loss: 0.0941, Val Loss: 0.0748
2024-12-29 14:23:11,517 - INFO - Epoch 3/1000, Train Loss: 0.0675, Val Loss: 0.0627
2024-12-29 14:23:11,715 - INFO - Epoch 4/1000, Train Loss: 0.0543, Val Loss: 0.0576
2024-12-29 14:23:11,919 - INFO - Epoch 5/1000, Train Loss: 0.0469, Val Loss: 0.0543
2024-12-29 14:23:12,146 - INFO - Epoch 6/1000, Train Loss: 0.0417, Val Loss: 0.0529
2024-12-29 14:23:12,334 - INFO - Epoch 7/1000, Train Loss: 0.0383, Val Loss: 0.0515
2024-12-29 14:23:12,521 - INFO - Epoch 8/1000, Train Loss: 0.0359, Val Loss: 0.0503
2024-12-29 14:23:12,699 - INFO - Epoch 9/1000, Train Loss: 0.0339, Val Loss: 0.0502
2024-12-29 14:23:12,901 - INFO - Epoch 10/1000, Train Loss: 0.0324, Val Loss: 0.0496
2024-12-29 14:23:13,169 - INFO - Epoch 11/1000, Train Loss: 0.0319, Val Loss: 0.0488
2024-12-29 14:23:13,522 - INFO - Epoch 12/1000, Train Loss: 0.0310, Val Loss: 0.0490
2024-12-29 14:23:13,927 - INFO - Epoch 13/1000, Train Loss: 0.0302, Val Loss: 0.0488
2024-12-29 14:23:14,255 - INFO - Epoch 14/1000, Train Loss: 0.0298, Val Loss: 0.0484
2024-12-29 14:23:14,658 - INFO - Epoch 15/1000, Train Loss: 0.0292, Val Loss: 0.0486
2024-12-29 14:23:15,066 - INFO - Epoch 16/1000, Train Loss: 0.0290, Val Loss: 0.0482
2024-12-29 14:23:15,067 - INFO - Early stopping triggered at epoch 16
2024-12-29 14:23:15,067 - INFO - Training completed in 4.26s
2024-12-29 14:23:15,067 - INFO - Final memory usage: CPU 2723.3 MB, GPU 104.8 MB
2024-12-29 14:23:15,068 - INFO - Model training completed in 4.26s
2024-12-29 14:23:15,114 - INFO - Prediction completed in 0.05s
2024-12-29 14:23:15,124 - INFO - Poison rate 0.0 completed in 4.32s
2024-12-29 14:23:15,125 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:23:15,127 - INFO - Total number of labels flipped: 94
2024-12-29 14:23:15,127 - INFO - Label flipping completed in 0.00s
2024-12-29 14:23:15,127 - INFO - Training set processing completed in 0.00s
2024-12-29 14:23:15,127 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:23:15,128 - INFO - Memory usage at start_fit: CPU 2694.1 MB, GPU 104.7 MB
2024-12-29 14:23:15,128 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:23:15,132 - INFO - Number of unique classes: 10
2024-12-29 14:23:15,215 - INFO - Fitted scaler and transformed data
2024-12-29 14:23:15,216 - INFO - Scaling time: 0.08s
2024-12-29 14:23:15,614 - INFO - Epoch 1/1000, Train Loss: 0.4877, Val Loss: 0.1794
2024-12-29 14:23:15,999 - INFO - Epoch 2/1000, Train Loss: 0.1696, Val Loss: 0.1495
2024-12-29 14:23:16,304 - INFO - Epoch 3/1000, Train Loss: 0.1486, Val Loss: 0.1406
2024-12-29 14:23:16,686 - INFO - Epoch 4/1000, Train Loss: 0.1388, Val Loss: 0.1372
2024-12-29 14:23:17,065 - INFO - Epoch 5/1000, Train Loss: 0.1299, Val Loss: 0.1356
2024-12-29 14:23:17,471 - INFO - Epoch 6/1000, Train Loss: 0.1234, Val Loss: 0.1339
2024-12-29 14:23:17,887 - INFO - Epoch 7/1000, Train Loss: 0.1197, Val Loss: 0.1346
2024-12-29 14:23:18,312 - INFO - Epoch 8/1000, Train Loss: 0.1165, Val Loss: 0.1332
2024-12-29 14:23:18,726 - INFO - Epoch 9/1000, Train Loss: 0.1128, Val Loss: 0.1339
2024-12-29 14:23:19,033 - INFO - Epoch 10/1000, Train Loss: 0.1108, Val Loss: 0.1337
2024-12-29 14:23:19,372 - INFO - Epoch 11/1000, Train Loss: 0.1099, Val Loss: 0.1333
2024-12-29 14:23:19,372 - INFO - Early stopping triggered at epoch 11
2024-12-29 14:23:19,372 - INFO - Training completed in 4.24s
2024-12-29 14:23:19,373 - INFO - Final memory usage: CPU 2723.1 MB, GPU 104.8 MB
2024-12-29 14:23:19,375 - INFO - Model training completed in 4.25s
2024-12-29 14:23:19,460 - INFO - Prediction completed in 0.08s
2024-12-29 14:23:19,469 - INFO - Poison rate 0.01 completed in 4.34s
2024-12-29 14:23:19,469 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:23:19,473 - INFO - Total number of labels flipped: 284
2024-12-29 14:23:19,473 - INFO - Label flipping completed in 0.00s
2024-12-29 14:23:19,474 - INFO - Training set processing completed in 0.00s
2024-12-29 14:23:19,474 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:23:19,475 - INFO - Memory usage at start_fit: CPU 2693.8 MB, GPU 104.7 MB
2024-12-29 14:23:19,475 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:23:19,480 - INFO - Number of unique classes: 10
2024-12-29 14:23:19,568 - INFO - Fitted scaler and transformed data
2024-12-29 14:23:19,569 - INFO - Scaling time: 0.09s
2024-12-29 14:23:19,804 - INFO - Epoch 1/1000, Train Loss: 0.6413, Val Loss: 0.3461
2024-12-29 14:23:19,996 - INFO - Epoch 2/1000, Train Loss: 0.2913, Val Loss: 0.3260
2024-12-29 14:23:20,270 - INFO - Epoch 3/1000, Train Loss: 0.2684, Val Loss: 0.3165
2024-12-29 14:23:20,602 - INFO - Epoch 4/1000, Train Loss: 0.2546, Val Loss: 0.3140
2024-12-29 14:23:20,995 - INFO - Epoch 5/1000, Train Loss: 0.2455, Val Loss: 0.3104
2024-12-29 14:23:21,423 - INFO - Epoch 6/1000, Train Loss: 0.2381, Val Loss: 0.3097
2024-12-29 14:23:21,802 - INFO - Epoch 7/1000, Train Loss: 0.2308, Val Loss: 0.3137
2024-12-29 14:23:22,209 - INFO - Epoch 8/1000, Train Loss: 0.2272, Val Loss: 0.3127
2024-12-29 14:23:22,620 - INFO - Epoch 9/1000, Train Loss: 0.2212, Val Loss: 0.3154
2024-12-29 14:23:23,034 - INFO - Epoch 10/1000, Train Loss: 0.2176, Val Loss: 0.3137
2024-12-29 14:23:23,035 - INFO - Early stopping triggered at epoch 10
2024-12-29 14:23:23,035 - INFO - Training completed in 3.56s
2024-12-29 14:23:23,035 - INFO - Final memory usage: CPU 2723.1 MB, GPU 104.8 MB
2024-12-29 14:23:23,036 - INFO - Model training completed in 3.56s
2024-12-29 14:23:23,084 - INFO - Prediction completed in 0.05s
2024-12-29 14:23:23,108 - INFO - Poison rate 0.03 completed in 3.64s
2024-12-29 14:23:23,108 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:23:23,121 - INFO - Total number of labels flipped: 473
2024-12-29 14:23:23,121 - INFO - Label flipping completed in 0.01s
2024-12-29 14:23:23,121 - INFO - Training set processing completed in 0.00s
2024-12-29 14:23:23,122 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:23:23,122 - INFO - Memory usage at start_fit: CPU 2693.7 MB, GPU 104.7 MB
2024-12-29 14:23:23,123 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:23:23,127 - INFO - Number of unique classes: 10
2024-12-29 14:23:23,206 - INFO - Fitted scaler and transformed data
2024-12-29 14:23:23,206 - INFO - Scaling time: 0.08s
2024-12-29 14:23:23,595 - INFO - Epoch 1/1000, Train Loss: 0.7012, Val Loss: 0.4098
2024-12-29 14:23:23,998 - INFO - Epoch 2/1000, Train Loss: 0.4190, Val Loss: 0.3964
2024-12-29 14:23:24,390 - INFO - Epoch 3/1000, Train Loss: 0.3952, Val Loss: 0.3919
2024-12-29 14:23:24,809 - INFO - Epoch 4/1000, Train Loss: 0.3790, Val Loss: 0.3916
2024-12-29 14:23:25,222 - INFO - Epoch 5/1000, Train Loss: 0.3663, Val Loss: 0.3941
2024-12-29 14:23:25,615 - INFO - Epoch 6/1000, Train Loss: 0.3586, Val Loss: 0.3958
2024-12-29 14:23:25,914 - INFO - Epoch 7/1000, Train Loss: 0.3492, Val Loss: 0.3970
2024-12-29 14:23:26,213 - INFO - Epoch 8/1000, Train Loss: 0.3437, Val Loss: 0.3972
2024-12-29 14:23:26,213 - INFO - Early stopping triggered at epoch 8
2024-12-29 14:23:26,214 - INFO - Training completed in 3.09s
2024-12-29 14:23:26,214 - INFO - Final memory usage: CPU 2724.9 MB, GPU 104.8 MB
2024-12-29 14:23:26,216 - INFO - Model training completed in 3.09s
2024-12-29 14:23:26,276 - INFO - Prediction completed in 0.06s
2024-12-29 14:23:26,285 - INFO - Poison rate 0.05 completed in 3.18s
2024-12-29 14:23:26,285 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:23:26,293 - INFO - Total number of labels flipped: 662
2024-12-29 14:23:26,293 - INFO - Label flipping completed in 0.01s
2024-12-29 14:23:26,293 - INFO - Training set processing completed in 0.00s
2024-12-29 14:23:26,293 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:23:26,294 - INFO - Memory usage at start_fit: CPU 2695.6 MB, GPU 104.7 MB
2024-12-29 14:23:26,294 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:23:26,298 - INFO - Number of unique classes: 10
2024-12-29 14:23:26,373 - INFO - Fitted scaler and transformed data
2024-12-29 14:23:26,374 - INFO - Scaling time: 0.07s
2024-12-29 14:23:26,650 - INFO - Epoch 1/1000, Train Loss: 0.7971, Val Loss: 0.5076
2024-12-29 14:23:26,977 - INFO - Epoch 2/1000, Train Loss: 0.5204, Val Loss: 0.4949
2024-12-29 14:23:27,255 - INFO - Epoch 3/1000, Train Loss: 0.4924, Val Loss: 0.4927
2024-12-29 14:23:27,513 - INFO - Epoch 4/1000, Train Loss: 0.4761, Val Loss: 0.4939
2024-12-29 14:23:27,750 - INFO - Epoch 5/1000, Train Loss: 0.4633, Val Loss: 0.4956
2024-12-29 14:23:28,019 - INFO - Epoch 6/1000, Train Loss: 0.4531, Val Loss: 0.4999
2024-12-29 14:23:28,331 - INFO - Epoch 7/1000, Train Loss: 0.4437, Val Loss: 0.5047
2024-12-29 14:23:28,530 - INFO - Epoch 8/1000, Train Loss: 0.4355, Val Loss: 0.5065
2024-12-29 14:23:28,531 - INFO - Early stopping triggered at epoch 8
2024-12-29 14:23:28,531 - INFO - Training completed in 2.24s
2024-12-29 14:23:28,531 - INFO - Final memory usage: CPU 2724.9 MB, GPU 104.8 MB
2024-12-29 14:23:28,532 - INFO - Model training completed in 2.24s
2024-12-29 14:23:28,594 - INFO - Prediction completed in 0.06s
2024-12-29 14:23:28,602 - INFO - Poison rate 0.07 completed in 2.32s
2024-12-29 14:23:28,603 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:23:28,624 - INFO - Total number of labels flipped: 946
2024-12-29 14:23:28,624 - INFO - Label flipping completed in 0.02s
2024-12-29 14:23:28,625 - INFO - Training set processing completed in 0.00s
2024-12-29 14:23:28,625 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:23:28,626 - INFO - Memory usage at start_fit: CPU 2695.5 MB, GPU 104.7 MB
2024-12-29 14:23:28,626 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:23:28,629 - INFO - Number of unique classes: 10
2024-12-29 14:23:28,709 - INFO - Fitted scaler and transformed data
2024-12-29 14:23:28,709 - INFO - Scaling time: 0.08s
2024-12-29 14:23:28,943 - INFO - Epoch 1/1000, Train Loss: 0.9084, Val Loss: 0.7692
2024-12-29 14:23:29,181 - INFO - Epoch 2/1000, Train Loss: 0.6470, Val Loss: 0.7516
2024-12-29 14:23:29,405 - INFO - Epoch 3/1000, Train Loss: 0.6193, Val Loss: 0.7478
2024-12-29 14:23:29,615 - INFO - Epoch 4/1000, Train Loss: 0.5982, Val Loss: 0.7521
2024-12-29 14:23:29,817 - INFO - Epoch 5/1000, Train Loss: 0.5836, Val Loss: 0.7529
2024-12-29 14:23:30,028 - INFO - Epoch 6/1000, Train Loss: 0.5764, Val Loss: 0.7487
2024-12-29 14:23:30,230 - INFO - Epoch 7/1000, Train Loss: 0.5643, Val Loss: 0.7520
2024-12-29 14:23:30,423 - INFO - Epoch 8/1000, Train Loss: 0.5569, Val Loss: 0.7563
2024-12-29 14:23:30,424 - INFO - Early stopping triggered at epoch 8
2024-12-29 14:23:30,424 - INFO - Training completed in 1.80s
2024-12-29 14:23:30,424 - INFO - Final memory usage: CPU 2724.8 MB, GPU 104.8 MB
2024-12-29 14:23:30,425 - INFO - Model training completed in 1.80s
2024-12-29 14:23:30,518 - INFO - Prediction completed in 0.09s
2024-12-29 14:23:30,532 - INFO - Poison rate 0.1 completed in 1.93s
2024-12-29 14:23:30,532 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:23:30,560 - INFO - Total number of labels flipped: 1893
2024-12-29 14:23:30,560 - INFO - Label flipping completed in 0.03s
2024-12-29 14:23:30,560 - INFO - Training set processing completed in 0.00s
2024-12-29 14:23:30,561 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:23:30,561 - INFO - Memory usage at start_fit: CPU 2699.2 MB, GPU 104.7 MB
2024-12-29 14:23:30,562 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:23:30,565 - INFO - Number of unique classes: 10
2024-12-29 14:23:30,636 - INFO - Fitted scaler and transformed data
2024-12-29 14:23:30,636 - INFO - Scaling time: 0.07s
2024-12-29 14:23:30,857 - INFO - Epoch 1/1000, Train Loss: 1.2685, Val Loss: 1.1032
2024-12-29 14:23:31,096 - INFO - Epoch 2/1000, Train Loss: 1.0559, Val Loss: 1.0888
2024-12-29 14:23:31,305 - INFO - Epoch 3/1000, Train Loss: 1.0271, Val Loss: 1.0855
2024-12-29 14:23:31,517 - INFO - Epoch 4/1000, Train Loss: 1.0027, Val Loss: 1.0881
2024-12-29 14:23:31,726 - INFO - Epoch 5/1000, Train Loss: 0.9854, Val Loss: 1.0885
2024-12-29 14:23:31,936 - INFO - Epoch 6/1000, Train Loss: 0.9771, Val Loss: 1.0923
2024-12-29 14:23:32,156 - INFO - Epoch 7/1000, Train Loss: 0.9658, Val Loss: 1.0995
2024-12-29 14:23:32,400 - INFO - Epoch 8/1000, Train Loss: 0.9595, Val Loss: 1.0981
2024-12-29 14:23:32,400 - INFO - Early stopping triggered at epoch 8
2024-12-29 14:23:32,401 - INFO - Training completed in 1.84s
2024-12-29 14:23:32,402 - INFO - Final memory usage: CPU 2724.8 MB, GPU 104.8 MB
2024-12-29 14:23:32,404 - INFO - Model training completed in 1.84s
2024-12-29 14:23:32,481 - INFO - Prediction completed in 0.08s
2024-12-29 14:23:32,490 - INFO - Poison rate 0.2 completed in 1.96s
2024-12-29 14:23:32,499 - INFO - Loaded 462 existing results
2024-12-29 14:23:32,499 - INFO - Total results to save: 469
2024-12-29 14:23:32,500 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:23:32,514 - INFO - Saved 469 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:23:32,515 - INFO - Total evaluation time: 52.91s
2024-12-29 14:23:32,517 - INFO - 
Progress: 70.8% - Evaluating CIFAR100 with LogisticRegression (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:23:32,708 - INFO - Loading datasets...
2024-12-29 14:23:32,728 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:23:32,729 - INFO - Extracting validation features...
2024-12-29 14:23:32,729 - INFO - Extracting features from 3925 samples...
2024-12-29 14:23:41,908 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:23:41,914 - INFO - Validation feature extraction completed in 9.19s
2024-12-29 14:23:41,914 - INFO - Extracting training features...
2024-12-29 14:23:41,914 - INFO - Extracting features from 9469 samples...
2024-12-29 14:24:03,524 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:24:03,527 - INFO - Training feature extraction completed in 21.61s
2024-12-29 14:24:03,527 - INFO - Creating model for classifier: LogisticRegression
2024-12-29 14:24:03,527 - INFO - Using device: cuda
2024-12-29 14:24:03,527 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:24:03,527 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:24:03,527 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:24:04,104 - INFO - Feature scaling completed in 0.58s
2024-12-29 14:24:04,104 - INFO - Starting feature selection (k=50)
2024-12-29 14:24:04,116 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:24:04,116 - INFO - Starting anomaly detection
2024-12-29 14:24:07,064 - INFO - Anomaly detection completed in 2.95s
2024-12-29 14:24:07,064 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:24:07,065 - INFO - Total fit_transform time: 3.54s
2024-12-29 14:24:07,065 - INFO - Training set processing completed in 3.54s
2024-12-29 14:24:07,065 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:24:07,067 - INFO - Memory usage at start_fit: CPU 2720.0 MB, GPU 104.0 MB
2024-12-29 14:24:07,067 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:24:07,070 - INFO - Number of unique classes: 10
2024-12-29 14:24:07,140 - INFO - Fitted scaler and transformed data
2024-12-29 14:24:07,141 - INFO - Scaling time: 0.07s
2024-12-29 14:24:07,349 - INFO - Epoch 1/1000, Train Loss: 0.4730, Val Loss: 0.1167
2024-12-29 14:24:07,541 - INFO - Epoch 2/1000, Train Loss: 0.0926, Val Loss: 0.0773
2024-12-29 14:24:07,747 - INFO - Epoch 3/1000, Train Loss: 0.0674, Val Loss: 0.0623
2024-12-29 14:24:07,952 - INFO - Epoch 4/1000, Train Loss: 0.0548, Val Loss: 0.0550
2024-12-29 14:24:08,188 - INFO - Epoch 5/1000, Train Loss: 0.0473, Val Loss: 0.0507
2024-12-29 14:24:08,490 - INFO - Epoch 6/1000, Train Loss: 0.0423, Val Loss: 0.0481
2024-12-29 14:24:08,891 - INFO - Epoch 7/1000, Train Loss: 0.0390, Val Loss: 0.0468
2024-12-29 14:24:09,286 - INFO - Epoch 8/1000, Train Loss: 0.0365, Val Loss: 0.0454
2024-12-29 14:24:09,571 - INFO - Epoch 9/1000, Train Loss: 0.0347, Val Loss: 0.0446
2024-12-29 14:24:09,812 - INFO - Epoch 10/1000, Train Loss: 0.0334, Val Loss: 0.0440
2024-12-29 14:24:10,021 - INFO - Epoch 11/1000, Train Loss: 0.0325, Val Loss: 0.0438
2024-12-29 14:24:10,204 - INFO - Epoch 12/1000, Train Loss: 0.0314, Val Loss: 0.0433
2024-12-29 14:24:10,414 - INFO - Epoch 13/1000, Train Loss: 0.0307, Val Loss: 0.0427
2024-12-29 14:24:10,614 - INFO - Epoch 14/1000, Train Loss: 0.0303, Val Loss: 0.0427
2024-12-29 14:24:10,825 - INFO - Epoch 15/1000, Train Loss: 0.0299, Val Loss: 0.0423
2024-12-29 14:24:11,062 - INFO - Epoch 16/1000, Train Loss: 0.0296, Val Loss: 0.0419
2024-12-29 14:24:11,279 - INFO - Epoch 17/1000, Train Loss: 0.0294, Val Loss: 0.0420
2024-12-29 14:24:11,502 - INFO - Epoch 18/1000, Train Loss: 0.0290, Val Loss: 0.0417
2024-12-29 14:24:11,858 - INFO - Epoch 19/1000, Train Loss: 0.0287, Val Loss: 0.0414
2024-12-29 14:24:12,142 - INFO - Epoch 20/1000, Train Loss: 0.0285, Val Loss: 0.0417
2024-12-29 14:24:12,569 - INFO - Epoch 21/1000, Train Loss: 0.0285, Val Loss: 0.0415
2024-12-29 14:24:12,974 - INFO - Epoch 22/1000, Train Loss: 0.0283, Val Loss: 0.0414
2024-12-29 14:24:13,309 - INFO - Epoch 23/1000, Train Loss: 0.0287, Val Loss: 0.0412
2024-12-29 14:24:13,309 - INFO - Early stopping triggered at epoch 23
2024-12-29 14:24:13,310 - INFO - Training completed in 6.24s
2024-12-29 14:24:13,310 - INFO - Final memory usage: CPU 2729.1 MB, GPU 104.2 MB
2024-12-29 14:24:13,312 - INFO - Model training completed in 6.25s
2024-12-29 14:24:13,365 - INFO - Prediction completed in 0.05s
2024-12-29 14:24:13,374 - INFO - Poison rate 0.0 completed in 9.85s
2024-12-29 14:24:13,374 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:24:13,376 - INFO - Total number of labels flipped: 94
2024-12-29 14:24:13,376 - INFO - Label flipping completed in 0.00s
2024-12-29 14:24:13,376 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:24:13,376 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:24:13,954 - INFO - Feature scaling completed in 0.58s
2024-12-29 14:24:13,955 - INFO - Starting feature selection (k=50)
2024-12-29 14:24:13,971 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 14:24:13,971 - INFO - Starting anomaly detection
2024-12-29 14:24:18,250 - INFO - Anomaly detection completed in 4.28s
2024-12-29 14:24:18,250 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:24:18,250 - INFO - Total fit_transform time: 4.87s
2024-12-29 14:24:18,251 - INFO - Training set processing completed in 4.87s
2024-12-29 14:24:18,251 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:24:18,252 - INFO - Memory usage at start_fit: CPU 2721.6 MB, GPU 104.1 MB
2024-12-29 14:24:18,252 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:24:18,254 - INFO - Number of unique classes: 10
2024-12-29 14:24:18,326 - INFO - Fitted scaler and transformed data
2024-12-29 14:24:18,327 - INFO - Scaling time: 0.07s
2024-12-29 14:24:18,620 - INFO - Epoch 1/1000, Train Loss: 0.5833, Val Loss: 0.1858
2024-12-29 14:24:18,814 - INFO - Epoch 2/1000, Train Loss: 0.1739, Val Loss: 0.1497
2024-12-29 14:24:19,081 - INFO - Epoch 3/1000, Train Loss: 0.1513, Val Loss: 0.1386
2024-12-29 14:24:19,349 - INFO - Epoch 4/1000, Train Loss: 0.1376, Val Loss: 0.1352
2024-12-29 14:24:19,718 - INFO - Epoch 5/1000, Train Loss: 0.1282, Val Loss: 0.1340
2024-12-29 14:24:20,068 - INFO - Epoch 6/1000, Train Loss: 0.1234, Val Loss: 0.1326
2024-12-29 14:24:20,434 - INFO - Epoch 7/1000, Train Loss: 0.1177, Val Loss: 0.1340
2024-12-29 14:24:20,840 - INFO - Epoch 8/1000, Train Loss: 0.1135, Val Loss: 0.1334
2024-12-29 14:24:21,240 - INFO - Epoch 9/1000, Train Loss: 0.1099, Val Loss: 0.1333
2024-12-29 14:24:21,622 - INFO - Epoch 10/1000, Train Loss: 0.1073, Val Loss: 0.1339
2024-12-29 14:24:21,872 - INFO - Epoch 11/1000, Train Loss: 0.1053, Val Loss: 0.1350
2024-12-29 14:24:21,872 - INFO - Early stopping triggered at epoch 11
2024-12-29 14:24:21,872 - INFO - Training completed in 3.62s
2024-12-29 14:24:21,873 - INFO - Final memory usage: CPU 2730.9 MB, GPU 104.2 MB
2024-12-29 14:24:21,874 - INFO - Model training completed in 3.62s
2024-12-29 14:24:21,933 - INFO - Prediction completed in 0.06s
2024-12-29 14:24:21,942 - INFO - Poison rate 0.01 completed in 8.57s
2024-12-29 14:24:21,942 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:24:21,946 - INFO - Total number of labels flipped: 284
2024-12-29 14:24:21,946 - INFO - Label flipping completed in 0.00s
2024-12-29 14:24:21,947 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:24:21,947 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:24:22,536 - INFO - Feature scaling completed in 0.59s
2024-12-29 14:24:22,536 - INFO - Starting feature selection (k=50)
2024-12-29 14:24:22,551 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:24:22,551 - INFO - Starting anomaly detection
2024-12-29 14:24:26,753 - INFO - Anomaly detection completed in 4.20s
2024-12-29 14:24:26,754 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:24:26,754 - INFO - Total fit_transform time: 4.81s
2024-12-29 14:24:26,754 - INFO - Training set processing completed in 4.81s
2024-12-29 14:24:26,754 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:24:26,755 - INFO - Memory usage at start_fit: CPU 2725.1 MB, GPU 104.1 MB
2024-12-29 14:24:26,756 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:24:26,759 - INFO - Number of unique classes: 10
2024-12-29 14:24:26,827 - INFO - Fitted scaler and transformed data
2024-12-29 14:24:26,827 - INFO - Scaling time: 0.07s
2024-12-29 14:24:27,090 - INFO - Epoch 1/1000, Train Loss: 0.6162, Val Loss: 0.3386
2024-12-29 14:24:27,440 - INFO - Epoch 2/1000, Train Loss: 0.3033, Val Loss: 0.3245
2024-12-29 14:24:27,868 - INFO - Epoch 3/1000, Train Loss: 0.2824, Val Loss: 0.3205
2024-12-29 14:24:28,229 - INFO - Epoch 4/1000, Train Loss: 0.2702, Val Loss: 0.3211
2024-12-29 14:24:28,473 - INFO - Epoch 5/1000, Train Loss: 0.2585, Val Loss: 0.3216
2024-12-29 14:24:28,747 - INFO - Epoch 6/1000, Train Loss: 0.2492, Val Loss: 0.3198
2024-12-29 14:24:29,005 - INFO - Epoch 7/1000, Train Loss: 0.2441, Val Loss: 0.3209
2024-12-29 14:24:29,208 - INFO - Epoch 8/1000, Train Loss: 0.2371, Val Loss: 0.3234
2024-12-29 14:24:29,208 - INFO - Early stopping triggered at epoch 8
2024-12-29 14:24:29,208 - INFO - Training completed in 2.45s
2024-12-29 14:24:29,208 - INFO - Final memory usage: CPU 2745.6 MB, GPU 104.2 MB
2024-12-29 14:24:29,211 - INFO - Model training completed in 2.46s
2024-12-29 14:24:29,274 - INFO - Prediction completed in 0.06s
2024-12-29 14:24:29,283 - INFO - Poison rate 0.03 completed in 7.34s
2024-12-29 14:24:29,283 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:24:29,289 - INFO - Total number of labels flipped: 473
2024-12-29 14:24:29,289 - INFO - Label flipping completed in 0.01s
2024-12-29 14:24:29,289 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:24:29,290 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:24:29,921 - INFO - Feature scaling completed in 0.63s
2024-12-29 14:24:29,921 - INFO - Starting feature selection (k=50)
2024-12-29 14:24:29,935 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:24:29,936 - INFO - Starting anomaly detection
2024-12-29 14:24:34,152 - INFO - Anomaly detection completed in 4.22s
2024-12-29 14:24:34,152 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:24:34,152 - INFO - Total fit_transform time: 4.86s
2024-12-29 14:24:34,152 - INFO - Training set processing completed in 4.86s
2024-12-29 14:24:34,152 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:24:34,153 - INFO - Memory usage at start_fit: CPU 2725.3 MB, GPU 104.1 MB
2024-12-29 14:24:34,153 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:24:34,156 - INFO - Number of unique classes: 10
2024-12-29 14:24:34,227 - INFO - Fitted scaler and transformed data
2024-12-29 14:24:34,227 - INFO - Scaling time: 0.07s
2024-12-29 14:24:34,443 - INFO - Epoch 1/1000, Train Loss: 0.6912, Val Loss: 0.5308
2024-12-29 14:24:34,663 - INFO - Epoch 2/1000, Train Loss: 0.3974, Val Loss: 0.5124
2024-12-29 14:24:34,879 - INFO - Epoch 3/1000, Train Loss: 0.3762, Val Loss: 0.5062
2024-12-29 14:24:35,167 - INFO - Epoch 4/1000, Train Loss: 0.3591, Val Loss: 0.5040
2024-12-29 14:24:35,367 - INFO - Epoch 5/1000, Train Loss: 0.3486, Val Loss: 0.5022
2024-12-29 14:24:35,567 - INFO - Epoch 6/1000, Train Loss: 0.3410, Val Loss: 0.5005
2024-12-29 14:24:35,763 - INFO - Epoch 7/1000, Train Loss: 0.3316, Val Loss: 0.4987
2024-12-29 14:24:35,970 - INFO - Epoch 8/1000, Train Loss: 0.3254, Val Loss: 0.4985
2024-12-29 14:24:36,180 - INFO - Epoch 9/1000, Train Loss: 0.3227, Val Loss: 0.5028
2024-12-29 14:24:36,382 - INFO - Epoch 10/1000, Train Loss: 0.3180, Val Loss: 0.5070
2024-12-29 14:24:36,590 - INFO - Epoch 11/1000, Train Loss: 0.3131, Val Loss: 0.5017
2024-12-29 14:24:36,792 - INFO - Epoch 12/1000, Train Loss: 0.3095, Val Loss: 0.5037
2024-12-29 14:24:36,793 - INFO - Early stopping triggered at epoch 12
2024-12-29 14:24:36,793 - INFO - Training completed in 2.64s
2024-12-29 14:24:36,794 - INFO - Final memory usage: CPU 2735.3 MB, GPU 104.2 MB
2024-12-29 14:24:36,796 - INFO - Model training completed in 2.64s
2024-12-29 14:24:36,853 - INFO - Prediction completed in 0.06s
2024-12-29 14:24:36,862 - INFO - Poison rate 0.05 completed in 7.58s
2024-12-29 14:24:36,862 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:24:36,870 - INFO - Total number of labels flipped: 662
2024-12-29 14:24:36,870 - INFO - Label flipping completed in 0.01s
2024-12-29 14:24:36,870 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:24:36,870 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:24:37,398 - INFO - Feature scaling completed in 0.53s
2024-12-29 14:24:37,398 - INFO - Starting feature selection (k=50)
2024-12-29 14:24:37,413 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:24:37,414 - INFO - Starting anomaly detection
2024-12-29 14:24:40,171 - INFO - Anomaly detection completed in 2.76s
2024-12-29 14:24:40,171 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:24:40,171 - INFO - Total fit_transform time: 3.30s
2024-12-29 14:24:40,172 - INFO - Training set processing completed in 3.30s
2024-12-29 14:24:40,172 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:24:40,173 - INFO - Memory usage at start_fit: CPU 2725.8 MB, GPU 104.1 MB
2024-12-29 14:24:40,173 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:24:40,177 - INFO - Number of unique classes: 10
2024-12-29 14:24:40,249 - INFO - Fitted scaler and transformed data
2024-12-29 14:24:40,249 - INFO - Scaling time: 0.07s
2024-12-29 14:24:40,462 - INFO - Epoch 1/1000, Train Loss: 0.8178, Val Loss: 0.5667
2024-12-29 14:24:40,694 - INFO - Epoch 2/1000, Train Loss: 0.5118, Val Loss: 0.5565
2024-12-29 14:24:41,066 - INFO - Epoch 3/1000, Train Loss: 0.4897, Val Loss: 0.5553
2024-12-29 14:24:41,438 - INFO - Epoch 4/1000, Train Loss: 0.4693, Val Loss: 0.5529
2024-12-29 14:24:41,818 - INFO - Epoch 5/1000, Train Loss: 0.4599, Val Loss: 0.5569
2024-12-29 14:24:42,236 - INFO - Epoch 6/1000, Train Loss: 0.4478, Val Loss: 0.5536
2024-12-29 14:24:42,503 - INFO - Epoch 7/1000, Train Loss: 0.4396, Val Loss: 0.5573
2024-12-29 14:24:42,716 - INFO - Epoch 8/1000, Train Loss: 0.4318, Val Loss: 0.5602
2024-12-29 14:24:42,924 - INFO - Epoch 9/1000, Train Loss: 0.4277, Val Loss: 0.5636
2024-12-29 14:24:42,924 - INFO - Early stopping triggered at epoch 9
2024-12-29 14:24:42,924 - INFO - Training completed in 2.75s
2024-12-29 14:24:42,925 - INFO - Final memory usage: CPU 2746.1 MB, GPU 104.2 MB
2024-12-29 14:24:42,926 - INFO - Model training completed in 2.75s
2024-12-29 14:24:42,989 - INFO - Prediction completed in 0.06s
2024-12-29 14:24:43,003 - INFO - Poison rate 0.07 completed in 6.14s
2024-12-29 14:24:43,003 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:24:43,016 - INFO - Total number of labels flipped: 946
2024-12-29 14:24:43,016 - INFO - Label flipping completed in 0.01s
2024-12-29 14:24:43,016 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:24:43,016 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:24:43,563 - INFO - Feature scaling completed in 0.55s
2024-12-29 14:24:43,563 - INFO - Starting feature selection (k=50)
2024-12-29 14:24:43,573 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:24:43,573 - INFO - Starting anomaly detection
2024-12-29 14:24:47,447 - INFO - Anomaly detection completed in 3.87s
2024-12-29 14:24:47,447 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:24:47,447 - INFO - Total fit_transform time: 4.43s
2024-12-29 14:24:47,447 - INFO - Training set processing completed in 4.43s
2024-12-29 14:24:47,447 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:24:47,448 - INFO - Memory usage at start_fit: CPU 2728.7 MB, GPU 104.1 MB
2024-12-29 14:24:47,449 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:24:47,453 - INFO - Number of unique classes: 10
2024-12-29 14:24:47,529 - INFO - Fitted scaler and transformed data
2024-12-29 14:24:47,530 - INFO - Scaling time: 0.08s
2024-12-29 14:24:47,747 - INFO - Epoch 1/1000, Train Loss: 0.9145, Val Loss: 0.6744
2024-12-29 14:24:47,949 - INFO - Epoch 2/1000, Train Loss: 0.6636, Val Loss: 0.6590
2024-12-29 14:24:48,156 - INFO - Epoch 3/1000, Train Loss: 0.6357, Val Loss: 0.6520
2024-12-29 14:24:48,378 - INFO - Epoch 4/1000, Train Loss: 0.6159, Val Loss: 0.6491
2024-12-29 14:24:48,561 - INFO - Epoch 5/1000, Train Loss: 0.6017, Val Loss: 0.6559
2024-12-29 14:24:48,751 - INFO - Epoch 6/1000, Train Loss: 0.5918, Val Loss: 0.6568
2024-12-29 14:24:48,967 - INFO - Epoch 7/1000, Train Loss: 0.5841, Val Loss: 0.6511
2024-12-29 14:24:49,181 - INFO - Epoch 8/1000, Train Loss: 0.5732, Val Loss: 0.6581
2024-12-29 14:24:49,382 - INFO - Epoch 9/1000, Train Loss: 0.5676, Val Loss: 0.6645
2024-12-29 14:24:49,382 - INFO - Early stopping triggered at epoch 9
2024-12-29 14:24:49,382 - INFO - Training completed in 1.93s
2024-12-29 14:24:49,382 - INFO - Final memory usage: CPU 2749.2 MB, GPU 104.2 MB
2024-12-29 14:24:49,383 - INFO - Model training completed in 1.94s
2024-12-29 14:24:49,430 - INFO - Prediction completed in 0.05s
2024-12-29 14:24:49,443 - INFO - Poison rate 0.1 completed in 6.44s
2024-12-29 14:24:49,443 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:24:49,465 - INFO - Total number of labels flipped: 1893
2024-12-29 14:24:49,465 - INFO - Label flipping completed in 0.02s
2024-12-29 14:24:49,465 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:24:49,465 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:24:49,995 - INFO - Feature scaling completed in 0.53s
2024-12-29 14:24:49,995 - INFO - Starting feature selection (k=50)
2024-12-29 14:24:50,010 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:24:50,010 - INFO - Starting anomaly detection
2024-12-29 14:24:53,927 - INFO - Anomaly detection completed in 3.92s
2024-12-29 14:24:53,928 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:24:53,928 - INFO - Total fit_transform time: 4.46s
2024-12-29 14:24:53,928 - INFO - Training set processing completed in 4.46s
2024-12-29 14:24:53,929 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:24:53,930 - INFO - Memory usage at start_fit: CPU 2730.3 MB, GPU 104.1 MB
2024-12-29 14:24:53,930 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:24:53,933 - INFO - Number of unique classes: 10
2024-12-29 14:24:54,013 - INFO - Fitted scaler and transformed data
2024-12-29 14:24:54,013 - INFO - Scaling time: 0.08s
2024-12-29 14:24:54,239 - INFO - Epoch 1/1000, Train Loss: 1.2576, Val Loss: 1.0509
2024-12-29 14:24:54,437 - INFO - Epoch 2/1000, Train Loss: 1.0449, Val Loss: 1.0398
2024-12-29 14:24:54,644 - INFO - Epoch 3/1000, Train Loss: 1.0111, Val Loss: 1.0374
2024-12-29 14:24:54,855 - INFO - Epoch 4/1000, Train Loss: 0.9891, Val Loss: 1.0304
2024-12-29 14:24:55,065 - INFO - Epoch 5/1000, Train Loss: 0.9740, Val Loss: 1.0358
2024-12-29 14:24:55,280 - INFO - Epoch 6/1000, Train Loss: 0.9626, Val Loss: 1.0424
2024-12-29 14:24:55,525 - INFO - Epoch 7/1000, Train Loss: 0.9527, Val Loss: 1.0465
2024-12-29 14:24:55,729 - INFO - Epoch 8/1000, Train Loss: 0.9418, Val Loss: 1.0445
2024-12-29 14:24:55,936 - INFO - Epoch 9/1000, Train Loss: 0.9388, Val Loss: 1.0454
2024-12-29 14:24:55,937 - INFO - Early stopping triggered at epoch 9
2024-12-29 14:24:55,937 - INFO - Training completed in 2.01s
2024-12-29 14:24:55,937 - INFO - Final memory usage: CPU 2748.9 MB, GPU 104.2 MB
2024-12-29 14:24:55,938 - INFO - Model training completed in 2.01s
2024-12-29 14:24:56,018 - INFO - Prediction completed in 0.08s
2024-12-29 14:24:56,027 - INFO - Poison rate 0.2 completed in 6.58s
2024-12-29 14:24:56,036 - INFO - Loaded 469 existing results
2024-12-29 14:24:56,037 - INFO - Total results to save: 476
2024-12-29 14:24:56,038 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:24:56,054 - INFO - Saved 476 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:24:56,055 - INFO - Total evaluation time: 83.35s
2024-12-29 14:24:56,057 - INFO - 
Progress: 71.9% - Evaluating CIFAR100 with RandomForest (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:24:56,231 - INFO - Loading datasets...
2024-12-29 14:24:56,253 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:24:56,253 - INFO - Extracting validation features...
2024-12-29 14:24:56,253 - INFO - Extracting features from 3925 samples...
2024-12-29 14:25:05,321 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:25:05,325 - INFO - Validation feature extraction completed in 9.07s
2024-12-29 14:25:05,325 - INFO - Extracting training features...
2024-12-29 14:25:05,326 - INFO - Extracting features from 9469 samples...
2024-12-29 14:25:26,935 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:25:26,940 - INFO - Training feature extraction completed in 21.61s
2024-12-29 14:25:26,941 - INFO - Creating model for classifier: RandomForest
2024-12-29 14:25:26,941 - INFO - Using device: cuda
2024-12-29 14:25:26,942 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:25:26,942 - INFO - Training set processing completed in 0.00s
2024-12-29 14:25:26,943 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:25:26,944 - INFO - Memory usage at start_fit: CPU 2786.5 MB, GPU 104.6 MB
2024-12-29 14:25:26,945 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:25:27,124 - INFO - Fitted scaler and transformed data
2024-12-29 14:25:27,124 - INFO - Scaling time: 0.18s
2024-12-29 14:25:27,131 - INFO - Number of unique classes: 10
2024-12-29 14:25:30,000 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3013
2024-12-29 14:25:32,296 - INFO - Epoch 2/10, Train Loss: 2.3006, Val Loss: 2.3000
2024-12-29 14:25:35,011 - INFO - Epoch 3/10, Train Loss: 2.2992, Val Loss: 2.2987
2024-12-29 14:25:37,680 - INFO - Epoch 4/10, Train Loss: 2.2978, Val Loss: 2.2973
2024-12-29 14:25:37,680 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:25:37,680 - INFO - Training completed in 10.74s
2024-12-29 14:25:37,680 - INFO - Final memory usage: CPU 2734.5 MB, GPU 126.5 MB
2024-12-29 14:25:37,681 - INFO - Model training completed in 10.74s
2024-12-29 14:25:37,831 - INFO - Prediction completed in 0.15s
2024-12-29 14:25:37,841 - INFO - Poison rate 0.0 completed in 10.90s
2024-12-29 14:25:37,841 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:25:37,843 - INFO - Total number of labels flipped: 94
2024-12-29 14:25:37,843 - INFO - Label flipping completed in 0.00s
2024-12-29 14:25:37,843 - INFO - Training set processing completed in 0.00s
2024-12-29 14:25:37,843 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:25:37,844 - INFO - Memory usage at start_fit: CPU 2734.5 MB, GPU 106.7 MB
2024-12-29 14:25:37,844 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:25:38,067 - INFO - Fitted scaler and transformed data
2024-12-29 14:25:38,067 - INFO - Scaling time: 0.22s
2024-12-29 14:25:38,077 - INFO - Number of unique classes: 10
2024-12-29 14:25:40,911 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3013
2024-12-29 14:25:43,959 - INFO - Epoch 2/10, Train Loss: 2.3006, Val Loss: 2.3001
2024-12-29 14:25:47,327 - INFO - Epoch 3/10, Train Loss: 2.2992, Val Loss: 2.2988
2024-12-29 14:25:50,404 - INFO - Epoch 4/10, Train Loss: 2.2978, Val Loss: 2.2975
2024-12-29 14:25:50,404 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:25:50,404 - INFO - Training completed in 12.56s
2024-12-29 14:25:50,405 - INFO - Final memory usage: CPU 2736.5 MB, GPU 126.5 MB
2024-12-29 14:25:50,405 - INFO - Model training completed in 12.56s
2024-12-29 14:25:50,665 - INFO - Prediction completed in 0.26s
2024-12-29 14:25:50,687 - INFO - Poison rate 0.01 completed in 12.85s
2024-12-29 14:25:50,688 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:25:50,694 - INFO - Total number of labels flipped: 284
2024-12-29 14:25:50,694 - INFO - Label flipping completed in 0.01s
2024-12-29 14:25:50,694 - INFO - Training set processing completed in 0.00s
2024-12-29 14:25:50,694 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:25:50,695 - INFO - Memory usage at start_fit: CPU 2736.5 MB, GPU 106.7 MB
2024-12-29 14:25:50,695 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:25:50,896 - INFO - Fitted scaler and transformed data
2024-12-29 14:25:50,897 - INFO - Scaling time: 0.20s
2024-12-29 14:25:50,907 - INFO - Number of unique classes: 10
2024-12-29 14:25:53,780 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3013
2024-12-29 14:25:57,274 - INFO - Epoch 2/10, Train Loss: 2.3006, Val Loss: 2.3001
2024-12-29 14:26:00,935 - INFO - Epoch 3/10, Train Loss: 2.2992, Val Loss: 2.2988
2024-12-29 14:26:03,844 - INFO - Epoch 4/10, Train Loss: 2.2979, Val Loss: 2.2975
2024-12-29 14:26:03,844 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:26:03,844 - INFO - Training completed in 13.15s
2024-12-29 14:26:03,844 - INFO - Final memory usage: CPU 2738.8 MB, GPU 126.5 MB
2024-12-29 14:26:03,845 - INFO - Model training completed in 13.15s
2024-12-29 14:26:03,988 - INFO - Prediction completed in 0.14s
2024-12-29 14:26:03,997 - INFO - Poison rate 0.03 completed in 13.31s
2024-12-29 14:26:03,997 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:26:04,003 - INFO - Total number of labels flipped: 473
2024-12-29 14:26:04,003 - INFO - Label flipping completed in 0.01s
2024-12-29 14:26:04,003 - INFO - Training set processing completed in 0.00s
2024-12-29 14:26:04,004 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:26:04,004 - INFO - Memory usage at start_fit: CPU 2738.8 MB, GPU 106.7 MB
2024-12-29 14:26:04,005 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:26:04,184 - INFO - Fitted scaler and transformed data
2024-12-29 14:26:04,185 - INFO - Scaling time: 0.18s
2024-12-29 14:26:04,195 - INFO - Number of unique classes: 10
2024-12-29 14:26:06,885 - INFO - Epoch 1/10, Train Loss: 2.3021, Val Loss: 2.3014
2024-12-29 14:26:10,080 - INFO - Epoch 2/10, Train Loss: 2.3008, Val Loss: 2.3003
2024-12-29 14:26:14,150 - INFO - Epoch 3/10, Train Loss: 2.2995, Val Loss: 2.2991
2024-12-29 14:26:17,276 - INFO - Epoch 4/10, Train Loss: 2.2982, Val Loss: 2.2978
2024-12-29 14:26:17,276 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:26:17,276 - INFO - Training completed in 13.27s
2024-12-29 14:26:17,276 - INFO - Final memory usage: CPU 2741.7 MB, GPU 126.5 MB
2024-12-29 14:26:17,277 - INFO - Model training completed in 13.27s
2024-12-29 14:26:17,500 - INFO - Prediction completed in 0.22s
2024-12-29 14:26:17,509 - INFO - Poison rate 0.05 completed in 13.51s
2024-12-29 14:26:17,509 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:26:17,518 - INFO - Total number of labels flipped: 662
2024-12-29 14:26:17,518 - INFO - Label flipping completed in 0.01s
2024-12-29 14:26:17,518 - INFO - Training set processing completed in 0.00s
2024-12-29 14:26:17,518 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:26:17,519 - INFO - Memory usage at start_fit: CPU 2741.7 MB, GPU 106.7 MB
2024-12-29 14:26:17,519 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:26:17,716 - INFO - Fitted scaler and transformed data
2024-12-29 14:26:17,716 - INFO - Scaling time: 0.20s
2024-12-29 14:26:17,727 - INFO - Number of unique classes: 10
2024-12-29 14:26:20,820 - INFO - Epoch 1/10, Train Loss: 2.3021, Val Loss: 2.3015
2024-12-29 14:26:24,489 - INFO - Epoch 2/10, Train Loss: 2.3008, Val Loss: 2.3003
2024-12-29 14:26:27,637 - INFO - Epoch 3/10, Train Loss: 2.2995, Val Loss: 2.2992
2024-12-29 14:26:30,886 - INFO - Epoch 4/10, Train Loss: 2.2982, Val Loss: 2.2980
2024-12-29 14:26:30,887 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:26:30,887 - INFO - Training completed in 13.37s
2024-12-29 14:26:30,887 - INFO - Final memory usage: CPU 2743.7 MB, GPU 126.5 MB
2024-12-29 14:26:30,887 - INFO - Model training completed in 13.37s
2024-12-29 14:26:31,055 - INFO - Prediction completed in 0.17s
2024-12-29 14:26:31,064 - INFO - Poison rate 0.07 completed in 13.56s
2024-12-29 14:26:31,064 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:26:31,076 - INFO - Total number of labels flipped: 946
2024-12-29 14:26:31,076 - INFO - Label flipping completed in 0.01s
2024-12-29 14:26:31,076 - INFO - Training set processing completed in 0.00s
2024-12-29 14:26:31,076 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:26:31,077 - INFO - Memory usage at start_fit: CPU 2743.7 MB, GPU 106.7 MB
2024-12-29 14:26:31,077 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:26:31,260 - INFO - Fitted scaler and transformed data
2024-12-29 14:26:31,260 - INFO - Scaling time: 0.18s
2024-12-29 14:26:31,271 - INFO - Number of unique classes: 10
2024-12-29 14:26:34,288 - INFO - Epoch 1/10, Train Loss: 2.3021, Val Loss: 2.3016
2024-12-29 14:26:36,988 - INFO - Epoch 2/10, Train Loss: 2.3009, Val Loss: 2.3006
2024-12-29 14:26:39,416 - INFO - Epoch 3/10, Train Loss: 2.2996, Val Loss: 2.2996
2024-12-29 14:26:43,204 - INFO - Epoch 4/10, Train Loss: 2.2984, Val Loss: 2.2986
2024-12-29 14:26:43,205 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:26:43,205 - INFO - Training completed in 12.13s
2024-12-29 14:26:43,205 - INFO - Final memory usage: CPU 2746.3 MB, GPU 126.5 MB
2024-12-29 14:26:43,205 - INFO - Model training completed in 12.13s
2024-12-29 14:26:43,354 - INFO - Prediction completed in 0.15s
2024-12-29 14:26:43,363 - INFO - Poison rate 0.1 completed in 12.30s
2024-12-29 14:26:43,363 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:26:43,385 - INFO - Total number of labels flipped: 1893
2024-12-29 14:26:43,385 - INFO - Label flipping completed in 0.02s
2024-12-29 14:26:43,385 - INFO - Training set processing completed in 0.00s
2024-12-29 14:26:43,385 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:26:43,386 - INFO - Memory usage at start_fit: CPU 2746.3 MB, GPU 106.7 MB
2024-12-29 14:26:43,386 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:26:43,559 - INFO - Fitted scaler and transformed data
2024-12-29 14:26:43,560 - INFO - Scaling time: 0.17s
2024-12-29 14:26:43,570 - INFO - Number of unique classes: 10
2024-12-29 14:26:46,270 - INFO - Epoch 1/10, Train Loss: 2.3022, Val Loss: 2.3017
2024-12-29 14:26:48,915 - INFO - Epoch 2/10, Train Loss: 2.3012, Val Loss: 2.3008
2024-12-29 14:26:51,651 - INFO - Epoch 3/10, Train Loss: 2.3002, Val Loss: 2.3000
2024-12-29 14:26:54,291 - INFO - Epoch 4/10, Train Loss: 2.2991, Val Loss: 2.2991
2024-12-29 14:26:54,291 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:26:54,291 - INFO - Training completed in 10.91s
2024-12-29 14:26:54,292 - INFO - Final memory usage: CPU 2746.3 MB, GPU 126.5 MB
2024-12-29 14:26:54,292 - INFO - Model training completed in 10.91s
2024-12-29 14:26:54,446 - INFO - Prediction completed in 0.15s
2024-12-29 14:26:54,455 - INFO - Poison rate 0.2 completed in 11.09s
2024-12-29 14:26:54,464 - INFO - Loaded 476 existing results
2024-12-29 14:26:54,464 - INFO - Total results to save: 483
2024-12-29 14:26:54,466 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:26:54,480 - INFO - Saved 483 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:26:54,481 - INFO - Total evaluation time: 118.25s
2024-12-29 14:26:54,482 - INFO - 
Progress: 72.9% - Evaluating CIFAR100 with RandomForest (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:26:54,673 - INFO - Loading datasets...
2024-12-29 14:26:54,694 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:26:54,694 - INFO - Extracting validation features...
2024-12-29 14:26:54,694 - INFO - Extracting features from 3925 samples...
2024-12-29 14:27:03,953 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:27:03,958 - INFO - Validation feature extraction completed in 9.26s
2024-12-29 14:27:03,959 - INFO - Extracting training features...
2024-12-29 14:27:03,959 - INFO - Extracting features from 9469 samples...
2024-12-29 14:27:25,180 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:27:25,182 - INFO - Training feature extraction completed in 21.22s
2024-12-29 14:27:25,182 - INFO - Creating model for classifier: RandomForest
2024-12-29 14:27:25,183 - INFO - Using device: cuda
2024-12-29 14:27:25,183 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:27:25,183 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:27:25,183 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:27:25,758 - INFO - Feature scaling completed in 0.58s
2024-12-29 14:27:25,758 - INFO - Starting feature selection (k=50)
2024-12-29 14:27:25,771 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:27:25,771 - INFO - Starting anomaly detection
2024-12-29 14:27:29,321 - INFO - Anomaly detection completed in 3.55s
2024-12-29 14:27:29,321 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:27:29,321 - INFO - Total fit_transform time: 4.14s
2024-12-29 14:27:29,321 - INFO - Training set processing completed in 4.14s
2024-12-29 14:27:29,322 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:27:29,322 - INFO - Memory usage at start_fit: CPU 2744.6 MB, GPU 104.0 MB
2024-12-29 14:27:29,323 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:27:29,506 - INFO - Fitted scaler and transformed data
2024-12-29 14:27:29,506 - INFO - Scaling time: 0.18s
2024-12-29 14:27:29,514 - INFO - Number of unique classes: 10
2024-12-29 14:27:32,641 - INFO - Epoch 1/10, Train Loss: 2.1867, Val Loss: 2.3013
2024-12-29 14:27:36,301 - INFO - Epoch 2/10, Train Loss: 2.1853, Val Loss: 2.2999
2024-12-29 14:27:39,457 - INFO - Epoch 3/10, Train Loss: 2.1840, Val Loss: 2.2986
2024-12-29 14:27:42,517 - INFO - Epoch 4/10, Train Loss: 2.1826, Val Loss: 2.2972
2024-12-29 14:27:42,518 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:27:42,518 - INFO - Training completed in 13.20s
2024-12-29 14:27:42,519 - INFO - Final memory usage: CPU 2747.9 MB, GPU 125.9 MB
2024-12-29 14:27:42,519 - INFO - Model training completed in 13.20s
2024-12-29 14:27:42,695 - INFO - Prediction completed in 0.17s
2024-12-29 14:27:42,704 - INFO - Poison rate 0.0 completed in 17.52s
2024-12-29 14:27:42,704 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:27:42,706 - INFO - Total number of labels flipped: 94
2024-12-29 14:27:42,706 - INFO - Label flipping completed in 0.00s
2024-12-29 14:27:42,707 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:27:42,707 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:27:43,278 - INFO - Feature scaling completed in 0.57s
2024-12-29 14:27:43,279 - INFO - Starting feature selection (k=50)
2024-12-29 14:27:43,292 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:27:43,292 - INFO - Starting anomaly detection
2024-12-29 14:27:46,888 - INFO - Anomaly detection completed in 3.60s
2024-12-29 14:27:46,888 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:27:46,888 - INFO - Total fit_transform time: 4.18s
2024-12-29 14:27:46,889 - INFO - Training set processing completed in 4.18s
2024-12-29 14:27:46,889 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:27:46,889 - INFO - Memory usage at start_fit: CPU 2747.9 MB, GPU 106.0 MB
2024-12-29 14:27:46,890 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:27:47,072 - INFO - Fitted scaler and transformed data
2024-12-29 14:27:47,073 - INFO - Scaling time: 0.18s
2024-12-29 14:27:47,079 - INFO - Number of unique classes: 10
2024-12-29 14:27:50,248 - INFO - Epoch 1/10, Train Loss: 2.1886, Val Loss: 2.3013
2024-12-29 14:27:53,428 - INFO - Epoch 2/10, Train Loss: 2.1872, Val Loss: 2.3000
2024-12-29 14:27:56,820 - INFO - Epoch 3/10, Train Loss: 2.1859, Val Loss: 2.2988
2024-12-29 14:28:00,013 - INFO - Epoch 4/10, Train Loss: 2.1845, Val Loss: 2.2974
2024-12-29 14:28:00,013 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:28:00,013 - INFO - Training completed in 13.12s
2024-12-29 14:28:00,013 - INFO - Final memory usage: CPU 2748.6 MB, GPU 125.9 MB
2024-12-29 14:28:00,014 - INFO - Model training completed in 13.12s
2024-12-29 14:28:00,167 - INFO - Prediction completed in 0.15s
2024-12-29 14:28:00,176 - INFO - Poison rate 0.01 completed in 17.47s
2024-12-29 14:28:00,176 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:28:00,180 - INFO - Total number of labels flipped: 284
2024-12-29 14:28:00,180 - INFO - Label flipping completed in 0.00s
2024-12-29 14:28:00,180 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:28:00,180 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:28:00,694 - INFO - Feature scaling completed in 0.51s
2024-12-29 14:28:00,694 - INFO - Starting feature selection (k=50)
2024-12-29 14:28:00,707 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:28:00,707 - INFO - Starting anomaly detection
2024-12-29 14:28:04,881 - INFO - Anomaly detection completed in 4.17s
2024-12-29 14:28:04,881 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:28:04,881 - INFO - Total fit_transform time: 4.70s
2024-12-29 14:28:04,881 - INFO - Training set processing completed in 4.70s
2024-12-29 14:28:04,882 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:28:04,882 - INFO - Memory usage at start_fit: CPU 2748.6 MB, GPU 106.0 MB
2024-12-29 14:28:04,882 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:28:05,109 - INFO - Fitted scaler and transformed data
2024-12-29 14:28:05,109 - INFO - Scaling time: 0.23s
2024-12-29 14:28:05,117 - INFO - Number of unique classes: 10
2024-12-29 14:28:08,241 - INFO - Epoch 1/10, Train Loss: 2.1874, Val Loss: 2.3014
2024-12-29 14:28:10,995 - INFO - Epoch 2/10, Train Loss: 2.1861, Val Loss: 2.3002
2024-12-29 14:28:14,079 - INFO - Epoch 3/10, Train Loss: 2.1848, Val Loss: 2.2989
2024-12-29 14:28:16,951 - INFO - Epoch 4/10, Train Loss: 2.1835, Val Loss: 2.2976
2024-12-29 14:28:16,951 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:28:16,951 - INFO - Training completed in 12.07s
2024-12-29 14:28:16,952 - INFO - Final memory usage: CPU 2750.4 MB, GPU 125.9 MB
2024-12-29 14:28:16,952 - INFO - Model training completed in 12.07s
2024-12-29 14:28:17,098 - INFO - Prediction completed in 0.15s
2024-12-29 14:28:17,107 - INFO - Poison rate 0.03 completed in 16.93s
2024-12-29 14:28:17,107 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:28:17,113 - INFO - Total number of labels flipped: 473
2024-12-29 14:28:17,114 - INFO - Label flipping completed in 0.01s
2024-12-29 14:28:17,114 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:28:17,114 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:28:17,624 - INFO - Feature scaling completed in 0.51s
2024-12-29 14:28:17,624 - INFO - Starting feature selection (k=50)
2024-12-29 14:28:17,637 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:28:17,638 - INFO - Starting anomaly detection
2024-12-29 14:28:21,863 - INFO - Anomaly detection completed in 4.23s
2024-12-29 14:28:21,863 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:28:21,863 - INFO - Total fit_transform time: 4.75s
2024-12-29 14:28:21,863 - INFO - Training set processing completed in 4.75s
2024-12-29 14:28:21,863 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:28:21,865 - INFO - Memory usage at start_fit: CPU 2750.4 MB, GPU 106.0 MB
2024-12-29 14:28:21,865 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:28:22,038 - INFO - Fitted scaler and transformed data
2024-12-29 14:28:22,039 - INFO - Scaling time: 0.17s
2024-12-29 14:28:22,045 - INFO - Number of unique classes: 10
2024-12-29 14:28:25,614 - INFO - Epoch 1/10, Train Loss: 2.1867, Val Loss: 2.3014
2024-12-29 14:28:28,767 - INFO - Epoch 2/10, Train Loss: 2.1855, Val Loss: 2.3003
2024-12-29 14:28:31,650 - INFO - Epoch 3/10, Train Loss: 2.1842, Val Loss: 2.2991
2024-12-29 14:28:34,762 - INFO - Epoch 4/10, Train Loss: 2.1830, Val Loss: 2.2979
2024-12-29 14:28:34,762 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:28:34,762 - INFO - Training completed in 12.90s
2024-12-29 14:28:34,763 - INFO - Final memory usage: CPU 2750.4 MB, GPU 125.9 MB
2024-12-29 14:28:34,763 - INFO - Model training completed in 12.90s
2024-12-29 14:28:34,915 - INFO - Prediction completed in 0.15s
2024-12-29 14:28:34,924 - INFO - Poison rate 0.05 completed in 17.82s
2024-12-29 14:28:34,924 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:28:34,932 - INFO - Total number of labels flipped: 662
2024-12-29 14:28:34,932 - INFO - Label flipping completed in 0.01s
2024-12-29 14:28:34,932 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:28:34,932 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:28:35,444 - INFO - Feature scaling completed in 0.51s
2024-12-29 14:28:35,444 - INFO - Starting feature selection (k=50)
2024-12-29 14:28:35,457 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:28:35,457 - INFO - Starting anomaly detection
2024-12-29 14:28:39,684 - INFO - Anomaly detection completed in 4.23s
2024-12-29 14:28:39,684 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:28:39,684 - INFO - Total fit_transform time: 4.75s
2024-12-29 14:28:39,684 - INFO - Training set processing completed in 4.75s
2024-12-29 14:28:39,684 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:28:39,685 - INFO - Memory usage at start_fit: CPU 2750.4 MB, GPU 106.0 MB
2024-12-29 14:28:39,685 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:28:39,861 - INFO - Fitted scaler and transformed data
2024-12-29 14:28:39,861 - INFO - Scaling time: 0.18s
2024-12-29 14:28:39,868 - INFO - Number of unique classes: 10
2024-12-29 14:28:43,344 - INFO - Epoch 1/10, Train Loss: 2.1860, Val Loss: 2.3015
2024-12-29 14:28:46,660 - INFO - Epoch 2/10, Train Loss: 2.1848, Val Loss: 2.3004
2024-12-29 14:28:50,154 - INFO - Epoch 3/10, Train Loss: 2.1836, Val Loss: 2.2992
2024-12-29 14:28:53,840 - INFO - Epoch 4/10, Train Loss: 2.1824, Val Loss: 2.2981
2024-12-29 14:28:53,840 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:28:53,840 - INFO - Training completed in 14.16s
2024-12-29 14:28:53,840 - INFO - Final memory usage: CPU 2750.4 MB, GPU 125.9 MB
2024-12-29 14:28:53,841 - INFO - Model training completed in 14.16s
2024-12-29 14:28:54,082 - INFO - Prediction completed in 0.24s
2024-12-29 14:28:54,091 - INFO - Poison rate 0.07 completed in 19.17s
2024-12-29 14:28:54,091 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:28:54,102 - INFO - Total number of labels flipped: 946
2024-12-29 14:28:54,102 - INFO - Label flipping completed in 0.01s
2024-12-29 14:28:54,102 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:28:54,103 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:28:54,642 - INFO - Feature scaling completed in 0.54s
2024-12-29 14:28:54,642 - INFO - Starting feature selection (k=50)
2024-12-29 14:28:54,655 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:28:54,655 - INFO - Starting anomaly detection
2024-12-29 14:28:58,285 - INFO - Anomaly detection completed in 3.63s
2024-12-29 14:28:58,286 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:28:58,286 - INFO - Total fit_transform time: 4.18s
2024-12-29 14:28:58,286 - INFO - Training set processing completed in 4.18s
2024-12-29 14:28:58,286 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:28:58,287 - INFO - Memory usage at start_fit: CPU 2750.4 MB, GPU 106.0 MB
2024-12-29 14:28:58,287 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:28:58,458 - INFO - Fitted scaler and transformed data
2024-12-29 14:28:58,458 - INFO - Scaling time: 0.17s
2024-12-29 14:28:58,465 - INFO - Number of unique classes: 10
2024-12-29 14:29:02,346 - INFO - Epoch 1/10, Train Loss: 2.1888, Val Loss: 2.3016
2024-12-29 14:29:05,769 - INFO - Epoch 2/10, Train Loss: 2.1876, Val Loss: 2.3005
2024-12-29 14:29:08,859 - INFO - Epoch 3/10, Train Loss: 2.1865, Val Loss: 2.2995
2024-12-29 14:29:11,636 - INFO - Epoch 4/10, Train Loss: 2.1853, Val Loss: 2.2984
2024-12-29 14:29:11,637 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:29:11,637 - INFO - Training completed in 13.35s
2024-12-29 14:29:11,637 - INFO - Final memory usage: CPU 2753.6 MB, GPU 125.9 MB
2024-12-29 14:29:11,637 - INFO - Model training completed in 13.35s
2024-12-29 14:29:11,804 - INFO - Prediction completed in 0.17s
2024-12-29 14:29:11,813 - INFO - Poison rate 0.1 completed in 17.72s
2024-12-29 14:29:11,813 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:29:11,845 - INFO - Total number of labels flipped: 1893
2024-12-29 14:29:11,845 - INFO - Label flipping completed in 0.03s
2024-12-29 14:29:11,845 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:29:11,846 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:29:12,337 - INFO - Feature scaling completed in 0.49s
2024-12-29 14:29:12,337 - INFO - Starting feature selection (k=50)
2024-12-29 14:29:12,349 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:29:12,350 - INFO - Starting anomaly detection
2024-12-29 14:29:15,575 - INFO - Anomaly detection completed in 3.22s
2024-12-29 14:29:15,575 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:29:15,575 - INFO - Total fit_transform time: 3.73s
2024-12-29 14:29:15,575 - INFO - Training set processing completed in 3.73s
2024-12-29 14:29:15,575 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:29:15,576 - INFO - Memory usage at start_fit: CPU 2753.6 MB, GPU 106.0 MB
2024-12-29 14:29:15,576 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:29:15,763 - INFO - Fitted scaler and transformed data
2024-12-29 14:29:15,764 - INFO - Scaling time: 0.19s
2024-12-29 14:29:15,771 - INFO - Number of unique classes: 10
2024-12-29 14:29:19,243 - INFO - Epoch 1/10, Train Loss: 2.1868, Val Loss: 2.3017
2024-12-29 14:29:22,310 - INFO - Epoch 2/10, Train Loss: 2.1858, Val Loss: 2.3009
2024-12-29 14:29:25,570 - INFO - Epoch 3/10, Train Loss: 2.1849, Val Loss: 2.3000
2024-12-29 14:29:28,559 - INFO - Epoch 4/10, Train Loss: 2.1839, Val Loss: 2.2992
2024-12-29 14:29:28,560 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:29:28,560 - INFO - Training completed in 12.98s
2024-12-29 14:29:28,560 - INFO - Final memory usage: CPU 2753.6 MB, GPU 125.9 MB
2024-12-29 14:29:28,560 - INFO - Model training completed in 12.99s
2024-12-29 14:29:28,766 - INFO - Prediction completed in 0.21s
2024-12-29 14:29:28,789 - INFO - Poison rate 0.2 completed in 16.98s
2024-12-29 14:29:28,805 - INFO - Loaded 483 existing results
2024-12-29 14:29:28,805 - INFO - Total results to save: 490
2024-12-29 14:29:28,807 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:29:28,821 - INFO - Saved 490 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:29:28,822 - INFO - Total evaluation time: 154.15s
2024-12-29 14:29:28,824 - INFO - 
Progress: 74.0% - Evaluating CIFAR100 with KNeighbors (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:29:29,022 - INFO - Loading datasets...
2024-12-29 14:29:29,043 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:29:29,043 - INFO - Extracting validation features...
2024-12-29 14:29:29,043 - INFO - Extracting features from 3925 samples...
2024-12-29 14:29:38,478 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:29:38,481 - INFO - Validation feature extraction completed in 9.44s
2024-12-29 14:29:38,481 - INFO - Extracting training features...
2024-12-29 14:29:38,481 - INFO - Extracting features from 9469 samples...
2024-12-29 14:30:00,219 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:30:00,224 - INFO - Training feature extraction completed in 21.74s
2024-12-29 14:30:00,224 - INFO - Creating model for classifier: KNeighbors
2024-12-29 14:30:00,225 - INFO - Using device: cuda
2024-12-29 14:30:00,225 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:30:00,225 - INFO - Training set processing completed in 0.00s
2024-12-29 14:30:00,226 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:30:00,228 - INFO - Memory usage at start_fit: CPU 2725.8 MB, GPU 104.6 MB
2024-12-29 14:30:00,228 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:30:00,454 - INFO - Fitted scaler and transformed data
2024-12-29 14:30:00,454 - INFO - Scaling time: 0.23s
2024-12-29 14:30:00,461 - INFO - Training completed in 0.23s
2024-12-29 14:30:00,462 - INFO - Final memory usage: CPU 2753.5 MB, GPU 123.2 MB
2024-12-29 14:30:00,462 - INFO - Model training completed in 0.24s
2024-12-29 14:30:00,533 - INFO - Prediction completed in 0.07s
2024-12-29 14:30:00,543 - INFO - Poison rate 0.0 completed in 0.32s
2024-12-29 14:30:00,543 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:30:00,545 - INFO - Total number of labels flipped: 94
2024-12-29 14:30:00,545 - INFO - Label flipping completed in 0.00s
2024-12-29 14:30:00,546 - INFO - Training set processing completed in 0.00s
2024-12-29 14:30:00,546 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:30:00,546 - INFO - Memory usage at start_fit: CPU 2753.7 MB, GPU 123.2 MB
2024-12-29 14:30:00,546 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:30:00,727 - INFO - Fitted scaler and transformed data
2024-12-29 14:30:00,727 - INFO - Scaling time: 0.18s
2024-12-29 14:30:00,735 - INFO - Training completed in 0.19s
2024-12-29 14:30:00,736 - INFO - Final memory usage: CPU 2753.7 MB, GPU 123.2 MB
2024-12-29 14:30:00,736 - INFO - Model training completed in 0.19s
2024-12-29 14:30:00,826 - INFO - Prediction completed in 0.09s
2024-12-29 14:30:00,834 - INFO - Poison rate 0.01 completed in 0.29s
2024-12-29 14:30:00,835 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:30:00,839 - INFO - Total number of labels flipped: 284
2024-12-29 14:30:00,839 - INFO - Label flipping completed in 0.00s
2024-12-29 14:30:00,839 - INFO - Training set processing completed in 0.00s
2024-12-29 14:30:00,839 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:30:00,840 - INFO - Memory usage at start_fit: CPU 2753.7 MB, GPU 123.2 MB
2024-12-29 14:30:00,840 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:30:01,028 - INFO - Fitted scaler and transformed data
2024-12-29 14:30:01,029 - INFO - Scaling time: 0.19s
2024-12-29 14:30:01,035 - INFO - Training completed in 0.20s
2024-12-29 14:30:01,036 - INFO - Final memory usage: CPU 2753.7 MB, GPU 123.2 MB
2024-12-29 14:30:01,036 - INFO - Model training completed in 0.20s
2024-12-29 14:30:01,137 - INFO - Prediction completed in 0.10s
2024-12-29 14:30:01,145 - INFO - Poison rate 0.03 completed in 0.31s
2024-12-29 14:30:01,146 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:30:01,152 - INFO - Total number of labels flipped: 473
2024-12-29 14:30:01,152 - INFO - Label flipping completed in 0.01s
2024-12-29 14:30:01,152 - INFO - Training set processing completed in 0.00s
2024-12-29 14:30:01,152 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:30:01,153 - INFO - Memory usage at start_fit: CPU 2753.7 MB, GPU 123.2 MB
2024-12-29 14:30:01,153 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:30:01,351 - INFO - Fitted scaler and transformed data
2024-12-29 14:30:01,352 - INFO - Scaling time: 0.20s
2024-12-29 14:30:01,358 - INFO - Training completed in 0.21s
2024-12-29 14:30:01,359 - INFO - Final memory usage: CPU 2753.7 MB, GPU 123.2 MB
2024-12-29 14:30:01,359 - INFO - Model training completed in 0.21s
2024-12-29 14:30:01,449 - INFO - Prediction completed in 0.09s
2024-12-29 14:30:01,458 - INFO - Poison rate 0.05 completed in 0.31s
2024-12-29 14:30:01,458 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:30:01,466 - INFO - Total number of labels flipped: 662
2024-12-29 14:30:01,466 - INFO - Label flipping completed in 0.01s
2024-12-29 14:30:01,466 - INFO - Training set processing completed in 0.00s
2024-12-29 14:30:01,466 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:30:01,467 - INFO - Memory usage at start_fit: CPU 2753.7 MB, GPU 123.2 MB
2024-12-29 14:30:01,467 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:30:01,664 - INFO - Fitted scaler and transformed data
2024-12-29 14:30:01,664 - INFO - Scaling time: 0.20s
2024-12-29 14:30:01,670 - INFO - Training completed in 0.20s
2024-12-29 14:30:01,671 - INFO - Final memory usage: CPU 2753.7 MB, GPU 123.2 MB
2024-12-29 14:30:01,671 - INFO - Model training completed in 0.20s
2024-12-29 14:30:01,743 - INFO - Prediction completed in 0.07s
2024-12-29 14:30:01,751 - INFO - Poison rate 0.07 completed in 0.29s
2024-12-29 14:30:01,751 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:30:01,763 - INFO - Total number of labels flipped: 946
2024-12-29 14:30:01,763 - INFO - Label flipping completed in 0.01s
2024-12-29 14:30:01,763 - INFO - Training set processing completed in 0.00s
2024-12-29 14:30:01,763 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:30:01,764 - INFO - Memory usage at start_fit: CPU 2753.7 MB, GPU 123.2 MB
2024-12-29 14:30:01,764 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:30:01,932 - INFO - Fitted scaler and transformed data
2024-12-29 14:30:01,932 - INFO - Scaling time: 0.17s
2024-12-29 14:30:01,938 - INFO - Training completed in 0.17s
2024-12-29 14:30:01,939 - INFO - Final memory usage: CPU 2753.7 MB, GPU 123.2 MB
2024-12-29 14:30:01,939 - INFO - Model training completed in 0.18s
2024-12-29 14:30:02,013 - INFO - Prediction completed in 0.07s
2024-12-29 14:30:02,022 - INFO - Poison rate 0.1 completed in 0.27s
2024-12-29 14:30:02,022 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:30:02,042 - INFO - Total number of labels flipped: 1893
2024-12-29 14:30:02,043 - INFO - Label flipping completed in 0.02s
2024-12-29 14:30:02,043 - INFO - Training set processing completed in 0.00s
2024-12-29 14:30:02,043 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:30:02,043 - INFO - Memory usage at start_fit: CPU 2753.7 MB, GPU 123.2 MB
2024-12-29 14:30:02,044 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:30:02,212 - INFO - Fitted scaler and transformed data
2024-12-29 14:30:02,212 - INFO - Scaling time: 0.17s
2024-12-29 14:30:02,218 - INFO - Training completed in 0.18s
2024-12-29 14:30:02,219 - INFO - Final memory usage: CPU 2753.7 MB, GPU 123.2 MB
2024-12-29 14:30:02,219 - INFO - Model training completed in 0.18s
2024-12-29 14:30:02,318 - INFO - Prediction completed in 0.10s
2024-12-29 14:30:02,326 - INFO - Poison rate 0.2 completed in 0.30s
2024-12-29 14:30:02,336 - INFO - Loaded 490 existing results
2024-12-29 14:30:02,336 - INFO - Total results to save: 497
2024-12-29 14:30:02,337 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:30:02,352 - INFO - Saved 497 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:30:02,353 - INFO - Total evaluation time: 33.33s
2024-12-29 14:30:02,355 - INFO - 
Progress: 75.0% - Evaluating CIFAR100 with KNeighbors (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:30:02,575 - INFO - Loading datasets...
2024-12-29 14:30:02,596 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:30:02,596 - INFO - Extracting validation features...
2024-12-29 14:30:02,596 - INFO - Extracting features from 3925 samples...
2024-12-29 14:30:11,956 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:30:11,961 - INFO - Validation feature extraction completed in 9.36s
2024-12-29 14:30:11,961 - INFO - Extracting training features...
2024-12-29 14:30:11,961 - INFO - Extracting features from 9469 samples...
2024-12-29 14:30:33,716 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:30:33,721 - INFO - Training feature extraction completed in 21.76s
2024-12-29 14:30:33,722 - INFO - Creating model for classifier: KNeighbors
2024-12-29 14:30:33,722 - INFO - Using device: cuda
2024-12-29 14:30:33,722 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:30:33,723 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:30:33,723 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:30:34,305 - INFO - Feature scaling completed in 0.58s
2024-12-29 14:30:34,305 - INFO - Starting feature selection (k=50)
2024-12-29 14:30:34,313 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:30:34,314 - INFO - Starting anomaly detection
2024-12-29 14:30:37,862 - INFO - Anomaly detection completed in 3.55s
2024-12-29 14:30:37,863 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:30:37,863 - INFO - Total fit_transform time: 4.14s
2024-12-29 14:30:37,863 - INFO - Training set processing completed in 4.14s
2024-12-29 14:30:37,863 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:30:37,865 - INFO - Memory usage at start_fit: CPU 2758.0 MB, GPU 104.0 MB
2024-12-29 14:30:37,865 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:30:38,062 - INFO - Fitted scaler and transformed data
2024-12-29 14:30:38,062 - INFO - Scaling time: 0.20s
2024-12-29 14:30:38,069 - INFO - Training completed in 0.20s
2024-12-29 14:30:38,069 - INFO - Final memory usage: CPU 2758.0 MB, GPU 122.6 MB
2024-12-29 14:30:38,069 - INFO - Model training completed in 0.21s
2024-12-29 14:30:38,195 - INFO - Prediction completed in 0.12s
2024-12-29 14:30:38,205 - INFO - Poison rate 0.0 completed in 4.48s
2024-12-29 14:30:38,205 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:30:38,209 - INFO - Total number of labels flipped: 94
2024-12-29 14:30:38,210 - INFO - Label flipping completed in 0.00s
2024-12-29 14:30:38,210 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:30:38,210 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:30:38,747 - INFO - Feature scaling completed in 0.54s
2024-12-29 14:30:38,748 - INFO - Starting feature selection (k=50)
2024-12-29 14:30:38,760 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:30:38,760 - INFO - Starting anomaly detection
2024-12-29 14:30:42,693 - INFO - Anomaly detection completed in 3.93s
2024-12-29 14:30:42,693 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:30:42,694 - INFO - Total fit_transform time: 4.48s
2024-12-29 14:30:42,694 - INFO - Training set processing completed in 4.48s
2024-12-29 14:30:42,695 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:30:42,696 - INFO - Memory usage at start_fit: CPU 2758.0 MB, GPU 122.6 MB
2024-12-29 14:30:42,696 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:30:42,898 - INFO - Fitted scaler and transformed data
2024-12-29 14:30:42,898 - INFO - Scaling time: 0.20s
2024-12-29 14:30:42,906 - INFO - Training completed in 0.21s
2024-12-29 14:30:42,907 - INFO - Final memory usage: CPU 2758.0 MB, GPU 122.6 MB
2024-12-29 14:30:42,907 - INFO - Model training completed in 0.21s
2024-12-29 14:30:43,005 - INFO - Prediction completed in 0.10s
2024-12-29 14:30:43,013 - INFO - Poison rate 0.01 completed in 4.81s
2024-12-29 14:30:43,013 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:30:43,017 - INFO - Total number of labels flipped: 284
2024-12-29 14:30:43,017 - INFO - Label flipping completed in 0.00s
2024-12-29 14:30:43,018 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:30:43,018 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:30:43,545 - INFO - Feature scaling completed in 0.53s
2024-12-29 14:30:43,545 - INFO - Starting feature selection (k=50)
2024-12-29 14:30:43,554 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:30:43,554 - INFO - Starting anomaly detection
2024-12-29 14:30:47,399 - INFO - Anomaly detection completed in 3.84s
2024-12-29 14:30:47,399 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:30:47,399 - INFO - Total fit_transform time: 4.38s
2024-12-29 14:30:47,400 - INFO - Training set processing completed in 4.38s
2024-12-29 14:30:47,400 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:30:47,401 - INFO - Memory usage at start_fit: CPU 2758.0 MB, GPU 122.6 MB
2024-12-29 14:30:47,401 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:30:47,629 - INFO - Fitted scaler and transformed data
2024-12-29 14:30:47,629 - INFO - Scaling time: 0.23s
2024-12-29 14:30:47,636 - INFO - Training completed in 0.24s
2024-12-29 14:30:47,637 - INFO - Final memory usage: CPU 2758.0 MB, GPU 122.6 MB
2024-12-29 14:30:47,637 - INFO - Model training completed in 0.24s
2024-12-29 14:30:47,735 - INFO - Prediction completed in 0.10s
2024-12-29 14:30:47,744 - INFO - Poison rate 0.03 completed in 4.73s
2024-12-29 14:30:47,744 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:30:47,750 - INFO - Total number of labels flipped: 473
2024-12-29 14:30:47,750 - INFO - Label flipping completed in 0.01s
2024-12-29 14:30:47,750 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:30:47,750 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:30:48,293 - INFO - Feature scaling completed in 0.54s
2024-12-29 14:30:48,293 - INFO - Starting feature selection (k=50)
2024-12-29 14:30:48,301 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:30:48,301 - INFO - Starting anomaly detection
2024-12-29 14:30:52,433 - INFO - Anomaly detection completed in 4.13s
2024-12-29 14:30:52,433 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:30:52,434 - INFO - Total fit_transform time: 4.68s
2024-12-29 14:30:52,434 - INFO - Training set processing completed in 4.68s
2024-12-29 14:30:52,434 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:30:52,435 - INFO - Memory usage at start_fit: CPU 2758.0 MB, GPU 122.6 MB
2024-12-29 14:30:52,435 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:30:52,658 - INFO - Fitted scaler and transformed data
2024-12-29 14:30:52,658 - INFO - Scaling time: 0.22s
2024-12-29 14:30:52,665 - INFO - Training completed in 0.23s
2024-12-29 14:30:52,665 - INFO - Final memory usage: CPU 2758.0 MB, GPU 122.6 MB
2024-12-29 14:30:52,665 - INFO - Model training completed in 0.23s
2024-12-29 14:30:52,771 - INFO - Prediction completed in 0.11s
2024-12-29 14:30:52,780 - INFO - Poison rate 0.05 completed in 5.04s
2024-12-29 14:30:52,781 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:30:52,789 - INFO - Total number of labels flipped: 662
2024-12-29 14:30:52,789 - INFO - Label flipping completed in 0.01s
2024-12-29 14:30:52,789 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:30:52,789 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:30:53,354 - INFO - Feature scaling completed in 0.56s
2024-12-29 14:30:53,354 - INFO - Starting feature selection (k=50)
2024-12-29 14:30:53,365 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:30:53,366 - INFO - Starting anomaly detection
2024-12-29 14:30:56,528 - INFO - Anomaly detection completed in 3.16s
2024-12-29 14:30:56,529 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:30:56,529 - INFO - Total fit_transform time: 3.74s
2024-12-29 14:30:56,529 - INFO - Training set processing completed in 3.74s
2024-12-29 14:30:56,530 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:30:56,531 - INFO - Memory usage at start_fit: CPU 2758.0 MB, GPU 122.6 MB
2024-12-29 14:30:56,532 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:30:56,721 - INFO - Fitted scaler and transformed data
2024-12-29 14:30:56,721 - INFO - Scaling time: 0.19s
2024-12-29 14:30:56,730 - INFO - Training completed in 0.20s
2024-12-29 14:30:56,730 - INFO - Final memory usage: CPU 2758.0 MB, GPU 122.6 MB
2024-12-29 14:30:56,731 - INFO - Model training completed in 0.20s
2024-12-29 14:30:56,857 - INFO - Prediction completed in 0.13s
2024-12-29 14:30:56,867 - INFO - Poison rate 0.07 completed in 4.09s
2024-12-29 14:30:56,867 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:30:56,879 - INFO - Total number of labels flipped: 946
2024-12-29 14:30:56,879 - INFO - Label flipping completed in 0.01s
2024-12-29 14:30:56,879 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:30:56,879 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:30:57,395 - INFO - Feature scaling completed in 0.52s
2024-12-29 14:30:57,395 - INFO - Starting feature selection (k=50)
2024-12-29 14:30:57,404 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:30:57,404 - INFO - Starting anomaly detection
2024-12-29 14:30:59,609 - INFO - Anomaly detection completed in 2.20s
2024-12-29 14:30:59,609 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:30:59,609 - INFO - Total fit_transform time: 2.73s
2024-12-29 14:30:59,609 - INFO - Training set processing completed in 2.73s
2024-12-29 14:30:59,609 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:30:59,610 - INFO - Memory usage at start_fit: CPU 2758.0 MB, GPU 122.6 MB
2024-12-29 14:30:59,610 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:30:59,808 - INFO - Fitted scaler and transformed data
2024-12-29 14:30:59,809 - INFO - Scaling time: 0.20s
2024-12-29 14:30:59,816 - INFO - Training completed in 0.21s
2024-12-29 14:30:59,817 - INFO - Final memory usage: CPU 2758.0 MB, GPU 122.6 MB
2024-12-29 14:30:59,817 - INFO - Model training completed in 0.21s
2024-12-29 14:30:59,922 - INFO - Prediction completed in 0.10s
2024-12-29 14:30:59,930 - INFO - Poison rate 0.1 completed in 3.06s
2024-12-29 14:30:59,930 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:30:59,952 - INFO - Total number of labels flipped: 1893
2024-12-29 14:30:59,952 - INFO - Label flipping completed in 0.02s
2024-12-29 14:30:59,952 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:30:59,952 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:31:00,545 - INFO - Feature scaling completed in 0.59s
2024-12-29 14:31:00,546 - INFO - Starting feature selection (k=50)
2024-12-29 14:31:00,553 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:31:00,553 - INFO - Starting anomaly detection
2024-12-29 14:31:04,404 - INFO - Anomaly detection completed in 3.85s
2024-12-29 14:31:04,404 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:31:04,404 - INFO - Total fit_transform time: 4.45s
2024-12-29 14:31:04,404 - INFO - Training set processing completed in 4.45s
2024-12-29 14:31:04,404 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:31:04,406 - INFO - Memory usage at start_fit: CPU 2758.0 MB, GPU 122.6 MB
2024-12-29 14:31:04,406 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:31:04,614 - INFO - Fitted scaler and transformed data
2024-12-29 14:31:04,614 - INFO - Scaling time: 0.21s
2024-12-29 14:31:04,621 - INFO - Training completed in 0.22s
2024-12-29 14:31:04,622 - INFO - Final memory usage: CPU 2758.0 MB, GPU 122.6 MB
2024-12-29 14:31:04,622 - INFO - Model training completed in 0.22s
2024-12-29 14:31:04,721 - INFO - Prediction completed in 0.10s
2024-12-29 14:31:04,731 - INFO - Poison rate 0.2 completed in 4.80s
2024-12-29 14:31:04,741 - INFO - Loaded 497 existing results
2024-12-29 14:31:04,741 - INFO - Total results to save: 504
2024-12-29 14:31:04,743 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:31:04,758 - INFO - Saved 504 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:31:04,759 - INFO - Total evaluation time: 62.18s
2024-12-29 14:31:04,761 - INFO - Completed evaluation for CIFAR100
2024-12-29 14:31:04,761 - INFO - 
Processing dataset: CIFAR100
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:31:04,935 - INFO - 
Progress: 76.0% - Evaluating CIFAR100 with SVM (standard mode, iteration 1/1)
2024-12-29 14:31:05,112 - INFO - Loading datasets...
2024-12-29 14:31:05,134 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:31:05,134 - INFO - Extracting validation features...
2024-12-29 14:31:05,134 - INFO - Extracting features from 3925 samples...
2024-12-29 14:31:14,522 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:31:14,528 - INFO - Validation feature extraction completed in 9.39s
2024-12-29 14:31:14,529 - INFO - Extracting training features...
2024-12-29 14:31:14,529 - INFO - Extracting features from 9469 samples...
2024-12-29 14:31:36,543 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:31:36,546 - INFO - Training feature extraction completed in 22.02s
2024-12-29 14:31:36,546 - INFO - Creating model for classifier: SVM
2024-12-29 14:31:36,547 - INFO - Using device: cuda
2024-12-29 14:31:36,547 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-29 14:31:36,547 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:31:36,547 - INFO - Training set processing completed in 0.00s
2024-12-29 14:31:36,547 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:31:36,548 - INFO - Memory usage at start_fit: CPU 2730.4 MB, GPU 104.6 MB
2024-12-29 14:31:36,548 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:31:36,551 - INFO - Number of unique classes: 10
2024-12-29 14:31:36,647 - INFO - Fitted scaler and transformed data
2024-12-29 14:31:36,647 - INFO - Scaling time: 0.09s
2024-12-29 14:31:36,995 - INFO - Epoch 1/500, Train Loss: 0.7884, Val Loss: 0.1572
2024-12-29 14:31:37,327 - INFO - Epoch 2/500, Train Loss: 0.0909, Val Loss: 0.1205
2024-12-29 14:31:37,646 - INFO - Epoch 3/500, Train Loss: 0.0587, Val Loss: 0.1035
2024-12-29 14:31:38,038 - INFO - Epoch 4/500, Train Loss: 0.0414, Val Loss: 0.0936
2024-12-29 14:31:38,408 - INFO - Epoch 5/500, Train Loss: 0.0311, Val Loss: 0.0882
2024-12-29 14:31:38,746 - INFO - Epoch 6/500, Train Loss: 0.0241, Val Loss: 0.0865
2024-12-29 14:31:39,142 - INFO - Epoch 7/500, Train Loss: 0.0194, Val Loss: 0.0867
2024-12-29 14:31:39,543 - INFO - Epoch 8/500, Train Loss: 0.0165, Val Loss: 0.0841
2024-12-29 14:31:39,895 - INFO - Epoch 9/500, Train Loss: 0.0134, Val Loss: 0.0838
2024-12-29 14:31:40,266 - INFO - Epoch 10/500, Train Loss: 0.0117, Val Loss: 0.0846
2024-12-29 14:31:40,645 - INFO - Epoch 11/500, Train Loss: 0.0098, Val Loss: 0.0832
2024-12-29 14:31:41,004 - INFO - Epoch 12/500, Train Loss: 0.0085, Val Loss: 0.0868
2024-12-29 14:31:41,377 - INFO - Epoch 13/500, Train Loss: 0.0074, Val Loss: 0.0881
2024-12-29 14:31:41,377 - INFO - Early stopping triggered at epoch 13
2024-12-29 14:31:41,378 - INFO - Training completed in 4.83s
2024-12-29 14:31:41,378 - INFO - Final memory usage: CPU 2767.5 MB, GPU 104.8 MB
2024-12-29 14:31:41,379 - INFO - Model training completed in 4.83s
2024-12-29 14:31:41,431 - INFO - Prediction completed in 0.05s
2024-12-29 14:31:41,441 - INFO - Poison rate 0.0 completed in 4.89s
2024-12-29 14:31:41,441 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:31:41,442 - INFO - Total number of labels flipped: 82
2024-12-29 14:31:41,442 - INFO - Label flipping completed in 0.00s
2024-12-29 14:31:41,442 - INFO - Training set processing completed in 0.00s
2024-12-29 14:31:41,442 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:31:41,443 - INFO - Memory usage at start_fit: CPU 2738.3 MB, GPU 104.7 MB
2024-12-29 14:31:41,443 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:31:41,446 - INFO - Number of unique classes: 10
2024-12-29 14:31:41,537 - INFO - Fitted scaler and transformed data
2024-12-29 14:31:41,537 - INFO - Scaling time: 0.09s
2024-12-29 14:31:41,857 - INFO - Epoch 1/500, Train Loss: 1.0268, Val Loss: 0.2818
2024-12-29 14:31:42,177 - INFO - Epoch 2/500, Train Loss: 0.1948, Val Loss: 0.2706
2024-12-29 14:31:42,496 - INFO - Epoch 3/500, Train Loss: 0.1446, Val Loss: 0.2675
2024-12-29 14:31:42,826 - INFO - Epoch 4/500, Train Loss: 0.1131, Val Loss: 0.2686
2024-12-29 14:31:43,178 - INFO - Epoch 5/500, Train Loss: 0.0936, Val Loss: 0.2663
2024-12-29 14:31:43,568 - INFO - Epoch 6/500, Train Loss: 0.0802, Val Loss: 0.2728
2024-12-29 14:31:43,946 - INFO - Epoch 7/500, Train Loss: 0.0712, Val Loss: 0.2741
2024-12-29 14:31:44,269 - INFO - Epoch 8/500, Train Loss: 0.0641, Val Loss: 0.2715
2024-12-29 14:31:44,639 - INFO - Epoch 9/500, Train Loss: 0.0585, Val Loss: 0.2639
2024-12-29 14:31:44,975 - INFO - Epoch 10/500, Train Loss: 0.0539, Val Loss: 0.2741
2024-12-29 14:31:45,351 - INFO - Epoch 11/500, Train Loss: 0.0504, Val Loss: 0.2710
2024-12-29 14:31:45,702 - INFO - Epoch 12/500, Train Loss: 0.0460, Val Loss: 0.2732
2024-12-29 14:31:46,068 - INFO - Epoch 13/500, Train Loss: 0.0440, Val Loss: 0.2716
2024-12-29 14:31:46,422 - INFO - Epoch 14/500, Train Loss: 0.0413, Val Loss: 0.2775
2024-12-29 14:31:46,423 - INFO - Early stopping triggered at epoch 14
2024-12-29 14:31:46,423 - INFO - Training completed in 4.98s
2024-12-29 14:31:46,423 - INFO - Final memory usage: CPU 2767.3 MB, GPU 104.8 MB
2024-12-29 14:31:46,424 - INFO - Model training completed in 4.98s
2024-12-29 14:31:46,485 - INFO - Prediction completed in 0.06s
2024-12-29 14:31:46,493 - INFO - Poison rate 0.01 completed in 5.05s
2024-12-29 14:31:46,494 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:31:46,495 - INFO - Total number of labels flipped: 262
2024-12-29 14:31:46,495 - INFO - Label flipping completed in 0.00s
2024-12-29 14:31:46,495 - INFO - Training set processing completed in 0.00s
2024-12-29 14:31:46,495 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:31:46,496 - INFO - Memory usage at start_fit: CPU 2738.0 MB, GPU 104.7 MB
2024-12-29 14:31:46,496 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:31:46,500 - INFO - Number of unique classes: 10
2024-12-29 14:31:46,580 - INFO - Fitted scaler and transformed data
2024-12-29 14:31:46,580 - INFO - Scaling time: 0.08s
2024-12-29 14:31:46,942 - INFO - Epoch 1/500, Train Loss: 1.0461, Val Loss: 0.3895
2024-12-29 14:31:47,288 - INFO - Epoch 2/500, Train Loss: 0.4136, Val Loss: 0.3702
2024-12-29 14:31:47,631 - INFO - Epoch 3/500, Train Loss: 0.3381, Val Loss: 0.3451
2024-12-29 14:31:48,013 - INFO - Epoch 4/500, Train Loss: 0.2914, Val Loss: 0.3317
2024-12-29 14:31:48,355 - INFO - Epoch 5/500, Train Loss: 0.2523, Val Loss: 0.3151
2024-12-29 14:31:48,684 - INFO - Epoch 6/500, Train Loss: 0.2225, Val Loss: 0.3133
2024-12-29 14:31:49,016 - INFO - Epoch 7/500, Train Loss: 0.2004, Val Loss: 0.3127
2024-12-29 14:31:49,362 - INFO - Epoch 8/500, Train Loss: 0.1834, Val Loss: 0.2887
2024-12-29 14:31:49,690 - INFO - Epoch 9/500, Train Loss: 0.1714, Val Loss: 0.2892
2024-12-29 14:31:50,033 - INFO - Epoch 10/500, Train Loss: 0.1594, Val Loss: 0.2862
2024-12-29 14:31:50,346 - INFO - Epoch 11/500, Train Loss: 0.1508, Val Loss: 0.2727
2024-12-29 14:31:50,761 - INFO - Epoch 12/500, Train Loss: 0.1405, Val Loss: 0.2668
2024-12-29 14:31:51,089 - INFO - Epoch 13/500, Train Loss: 0.1330, Val Loss: 0.2621
2024-12-29 14:31:51,432 - INFO - Epoch 14/500, Train Loss: 0.1288, Val Loss: 0.2601
2024-12-29 14:31:51,781 - INFO - Epoch 15/500, Train Loss: 0.1241, Val Loss: 0.2570
2024-12-29 14:31:52,111 - INFO - Epoch 16/500, Train Loss: 0.1185, Val Loss: 0.2517
2024-12-29 14:31:52,462 - INFO - Epoch 17/500, Train Loss: 0.1146, Val Loss: 0.2470
2024-12-29 14:31:52,808 - INFO - Epoch 18/500, Train Loss: 0.1116, Val Loss: 0.2440
2024-12-29 14:31:53,140 - INFO - Epoch 19/500, Train Loss: 0.1086, Val Loss: 0.2451
2024-12-29 14:31:53,461 - INFO - Epoch 20/500, Train Loss: 0.1067, Val Loss: 0.2448
2024-12-29 14:31:53,783 - INFO - Epoch 21/500, Train Loss: 0.1042, Val Loss: 0.2433
2024-12-29 14:31:54,160 - INFO - Epoch 22/500, Train Loss: 0.1028, Val Loss: 0.2451
2024-12-29 14:31:54,519 - INFO - Epoch 23/500, Train Loss: 0.1011, Val Loss: 0.2423
2024-12-29 14:31:54,908 - INFO - Epoch 24/500, Train Loss: 0.0982, Val Loss: 0.2501
2024-12-29 14:31:55,240 - INFO - Epoch 25/500, Train Loss: 0.0965, Val Loss: 0.2444
2024-12-29 14:31:55,611 - INFO - Epoch 26/500, Train Loss: 0.0951, Val Loss: 0.2425
2024-12-29 14:31:56,055 - INFO - Epoch 27/500, Train Loss: 0.0957, Val Loss: 0.2509
2024-12-29 14:31:56,430 - INFO - Epoch 28/500, Train Loss: 0.0936, Val Loss: 0.2500
2024-12-29 14:31:56,430 - INFO - Early stopping triggered at epoch 28
2024-12-29 14:31:56,430 - INFO - Training completed in 9.93s
2024-12-29 14:31:56,430 - INFO - Final memory usage: CPU 2767.2 MB, GPU 104.8 MB
2024-12-29 14:31:56,431 - INFO - Model training completed in 9.94s
2024-12-29 14:31:56,476 - INFO - Prediction completed in 0.04s
2024-12-29 14:31:56,485 - INFO - Poison rate 0.03 completed in 9.99s
2024-12-29 14:31:56,485 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:31:56,486 - INFO - Total number of labels flipped: 431
2024-12-29 14:31:56,486 - INFO - Label flipping completed in 0.00s
2024-12-29 14:31:56,487 - INFO - Training set processing completed in 0.00s
2024-12-29 14:31:56,487 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:31:56,487 - INFO - Memory usage at start_fit: CPU 2737.9 MB, GPU 104.7 MB
2024-12-29 14:31:56,487 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:31:56,492 - INFO - Number of unique classes: 10
2024-12-29 14:31:56,579 - INFO - Fitted scaler and transformed data
2024-12-29 14:31:56,580 - INFO - Scaling time: 0.09s
2024-12-29 14:31:56,952 - INFO - Epoch 1/500, Train Loss: 1.2241, Val Loss: 0.6408
2024-12-29 14:31:57,323 - INFO - Epoch 2/500, Train Loss: 0.5778, Val Loss: 0.5814
2024-12-29 14:31:57,710 - INFO - Epoch 3/500, Train Loss: 0.4926, Val Loss: 0.5616
2024-12-29 14:31:58,049 - INFO - Epoch 4/500, Train Loss: 0.4155, Val Loss: 0.5003
2024-12-29 14:31:58,377 - INFO - Epoch 5/500, Train Loss: 0.3651, Val Loss: 0.4818
2024-12-29 14:31:58,699 - INFO - Epoch 6/500, Train Loss: 0.3258, Val Loss: 0.4609
2024-12-29 14:31:59,048 - INFO - Epoch 7/500, Train Loss: 0.2930, Val Loss: 0.4331
2024-12-29 14:31:59,379 - INFO - Epoch 8/500, Train Loss: 0.2674, Val Loss: 0.4194
2024-12-29 14:31:59,696 - INFO - Epoch 9/500, Train Loss: 0.2467, Val Loss: 0.3866
2024-12-29 14:32:00,035 - INFO - Epoch 10/500, Train Loss: 0.2291, Val Loss: 0.3838
2024-12-29 14:32:00,402 - INFO - Epoch 11/500, Train Loss: 0.2123, Val Loss: 0.3589
2024-12-29 14:32:00,825 - INFO - Epoch 12/500, Train Loss: 0.2041, Val Loss: 0.3753
2024-12-29 14:32:01,209 - INFO - Epoch 13/500, Train Loss: 0.1929, Val Loss: 0.3595
2024-12-29 14:32:01,555 - INFO - Epoch 14/500, Train Loss: 0.1849, Val Loss: 0.3482
2024-12-29 14:32:01,930 - INFO - Epoch 15/500, Train Loss: 0.1793, Val Loss: 0.3461
2024-12-29 14:32:02,284 - INFO - Epoch 16/500, Train Loss: 0.1750, Val Loss: 0.3454
2024-12-29 14:32:02,687 - INFO - Epoch 17/500, Train Loss: 0.1680, Val Loss: 0.3458
2024-12-29 14:32:03,080 - INFO - Epoch 18/500, Train Loss: 0.1670, Val Loss: 0.3310
2024-12-29 14:32:03,439 - INFO - Epoch 19/500, Train Loss: 0.1612, Val Loss: 0.3439
2024-12-29 14:32:03,774 - INFO - Epoch 20/500, Train Loss: 0.1577, Val Loss: 0.3340
2024-12-29 14:32:04,121 - INFO - Epoch 21/500, Train Loss: 0.1563, Val Loss: 0.3438
2024-12-29 14:32:04,462 - INFO - Epoch 22/500, Train Loss: 0.1539, Val Loss: 0.3393
2024-12-29 14:32:04,831 - INFO - Epoch 23/500, Train Loss: 0.1514, Val Loss: 0.3314
2024-12-29 14:32:04,831 - INFO - Early stopping triggered at epoch 23
2024-12-29 14:32:04,831 - INFO - Training completed in 8.34s
2024-12-29 14:32:04,832 - INFO - Final memory usage: CPU 2767.4 MB, GPU 104.8 MB
2024-12-29 14:32:04,832 - INFO - Model training completed in 8.35s
2024-12-29 14:32:04,880 - INFO - Prediction completed in 0.05s
2024-12-29 14:32:04,889 - INFO - Poison rate 0.05 completed in 8.40s
2024-12-29 14:32:04,889 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:32:04,891 - INFO - Total number of labels flipped: 598
2024-12-29 14:32:04,891 - INFO - Label flipping completed in 0.00s
2024-12-29 14:32:04,891 - INFO - Training set processing completed in 0.00s
2024-12-29 14:32:04,891 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:32:04,892 - INFO - Memory usage at start_fit: CPU 2737.8 MB, GPU 104.7 MB
2024-12-29 14:32:04,892 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:32:04,896 - INFO - Number of unique classes: 10
2024-12-29 14:32:04,964 - INFO - Fitted scaler and transformed data
2024-12-29 14:32:04,964 - INFO - Scaling time: 0.07s
2024-12-29 14:32:05,318 - INFO - Epoch 1/500, Train Loss: 1.4138, Val Loss: 0.8214
2024-12-29 14:32:05,650 - INFO - Epoch 2/500, Train Loss: 0.7361, Val Loss: 0.7305
2024-12-29 14:32:06,011 - INFO - Epoch 3/500, Train Loss: 0.6117, Val Loss: 0.6736
2024-12-29 14:32:06,366 - INFO - Epoch 4/500, Train Loss: 0.5252, Val Loss: 0.6398
2024-12-29 14:32:06,693 - INFO - Epoch 5/500, Train Loss: 0.4538, Val Loss: 0.5951
2024-12-29 14:32:07,074 - INFO - Epoch 6/500, Train Loss: 0.3978, Val Loss: 0.5498
2024-12-29 14:32:07,506 - INFO - Epoch 7/500, Train Loss: 0.3629, Val Loss: 0.5175
2024-12-29 14:32:07,866 - INFO - Epoch 8/500, Train Loss: 0.3271, Val Loss: 0.4859
2024-12-29 14:32:08,259 - INFO - Epoch 9/500, Train Loss: 0.3053, Val Loss: 0.4663
2024-12-29 14:32:08,611 - INFO - Epoch 10/500, Train Loss: 0.2856, Val Loss: 0.4665
2024-12-29 14:32:08,996 - INFO - Epoch 11/500, Train Loss: 0.2704, Val Loss: 0.4452
2024-12-29 14:32:09,395 - INFO - Epoch 12/500, Train Loss: 0.2606, Val Loss: 0.4320
2024-12-29 14:32:09,743 - INFO - Epoch 13/500, Train Loss: 0.2484, Val Loss: 0.4164
2024-12-29 14:32:10,111 - INFO - Epoch 14/500, Train Loss: 0.2424, Val Loss: 0.4168
2024-12-29 14:32:10,443 - INFO - Epoch 15/500, Train Loss: 0.2359, Val Loss: 0.4022
2024-12-29 14:32:10,816 - INFO - Epoch 16/500, Train Loss: 0.2305, Val Loss: 0.3949
2024-12-29 14:32:11,159 - INFO - Epoch 17/500, Train Loss: 0.2257, Val Loss: 0.3917
2024-12-29 14:32:11,509 - INFO - Epoch 18/500, Train Loss: 0.2224, Val Loss: 0.3987
2024-12-29 14:32:11,828 - INFO - Epoch 19/500, Train Loss: 0.2178, Val Loss: 0.3884
2024-12-29 14:32:12,178 - INFO - Epoch 20/500, Train Loss: 0.2152, Val Loss: 0.3934
2024-12-29 14:32:12,509 - INFO - Epoch 21/500, Train Loss: 0.2143, Val Loss: 0.3842
2024-12-29 14:32:12,884 - INFO - Epoch 22/500, Train Loss: 0.2081, Val Loss: 0.3799
2024-12-29 14:32:13,209 - INFO - Epoch 23/500, Train Loss: 0.2081, Val Loss: 0.3692
2024-12-29 14:32:13,604 - INFO - Epoch 24/500, Train Loss: 0.2041, Val Loss: 0.3745
2024-12-29 14:32:13,995 - INFO - Epoch 25/500, Train Loss: 0.2013, Val Loss: 0.3684
2024-12-29 14:32:14,359 - INFO - Epoch 26/500, Train Loss: 0.2002, Val Loss: 0.3824
2024-12-29 14:32:14,784 - INFO - Epoch 27/500, Train Loss: 0.2002, Val Loss: 0.3728
2024-12-29 14:32:15,138 - INFO - Epoch 28/500, Train Loss: 0.1981, Val Loss: 0.3816
2024-12-29 14:32:15,138 - INFO - Early stopping triggered at epoch 28
2024-12-29 14:32:15,138 - INFO - Training completed in 10.25s
2024-12-29 14:32:15,139 - INFO - Final memory usage: CPU 2767.1 MB, GPU 104.8 MB
2024-12-29 14:32:15,140 - INFO - Model training completed in 10.25s
2024-12-29 14:32:15,204 - INFO - Prediction completed in 0.06s
2024-12-29 14:32:15,213 - INFO - Poison rate 0.07 completed in 10.32s
2024-12-29 14:32:15,213 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:32:15,215 - INFO - Total number of labels flipped: 853
2024-12-29 14:32:15,215 - INFO - Label flipping completed in 0.00s
2024-12-29 14:32:15,215 - INFO - Training set processing completed in 0.00s
2024-12-29 14:32:15,215 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:32:15,216 - INFO - Memory usage at start_fit: CPU 2737.8 MB, GPU 104.7 MB
2024-12-29 14:32:15,216 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:32:15,220 - INFO - Number of unique classes: 10
2024-12-29 14:32:15,292 - INFO - Fitted scaler and transformed data
2024-12-29 14:32:15,292 - INFO - Scaling time: 0.07s
2024-12-29 14:32:15,664 - INFO - Epoch 1/500, Train Loss: 1.7572, Val Loss: 1.1823
2024-12-29 14:32:16,016 - INFO - Epoch 2/500, Train Loss: 0.9549, Val Loss: 1.0719
2024-12-29 14:32:16,346 - INFO - Epoch 3/500, Train Loss: 0.8051, Val Loss: 0.9522
2024-12-29 14:32:16,706 - INFO - Epoch 4/500, Train Loss: 0.6872, Val Loss: 0.8766
2024-12-29 14:32:17,037 - INFO - Epoch 5/500, Train Loss: 0.5961, Val Loss: 0.7835
2024-12-29 14:32:17,393 - INFO - Epoch 6/500, Train Loss: 0.5239, Val Loss: 0.7298
2024-12-29 14:32:17,720 - INFO - Epoch 7/500, Train Loss: 0.4665, Val Loss: 0.6805
2024-12-29 14:32:18,068 - INFO - Epoch 8/500, Train Loss: 0.4264, Val Loss: 0.6310
2024-12-29 14:32:18,394 - INFO - Epoch 9/500, Train Loss: 0.3927, Val Loss: 0.5910
2024-12-29 14:32:18,745 - INFO - Epoch 10/500, Train Loss: 0.3668, Val Loss: 0.5737
2024-12-29 14:32:19,106 - INFO - Epoch 11/500, Train Loss: 0.3495, Val Loss: 0.5538
2024-12-29 14:32:19,458 - INFO - Epoch 12/500, Train Loss: 0.3356, Val Loss: 0.5392
2024-12-29 14:32:19,789 - INFO - Epoch 13/500, Train Loss: 0.3250, Val Loss: 0.5246
2024-12-29 14:32:20,168 - INFO - Epoch 14/500, Train Loss: 0.3145, Val Loss: 0.5261
2024-12-29 14:32:20,492 - INFO - Epoch 15/500, Train Loss: 0.3075, Val Loss: 0.5161
2024-12-29 14:32:20,840 - INFO - Epoch 16/500, Train Loss: 0.3001, Val Loss: 0.5086
2024-12-29 14:32:21,199 - INFO - Epoch 17/500, Train Loss: 0.2937, Val Loss: 0.5058
2024-12-29 14:32:21,511 - INFO - Epoch 18/500, Train Loss: 0.2882, Val Loss: 0.4935
2024-12-29 14:32:21,845 - INFO - Epoch 19/500, Train Loss: 0.2861, Val Loss: 0.5066
2024-12-29 14:32:22,171 - INFO - Epoch 20/500, Train Loss: 0.2815, Val Loss: 0.4996
2024-12-29 14:32:22,487 - INFO - Epoch 21/500, Train Loss: 0.2783, Val Loss: 0.4941
2024-12-29 14:32:22,813 - INFO - Epoch 22/500, Train Loss: 0.2744, Val Loss: 0.4905
2024-12-29 14:32:23,138 - INFO - Epoch 23/500, Train Loss: 0.2725, Val Loss: 0.4911
2024-12-29 14:32:23,458 - INFO - Epoch 24/500, Train Loss: 0.2674, Val Loss: 0.4918
2024-12-29 14:32:23,801 - INFO - Epoch 25/500, Train Loss: 0.2675, Val Loss: 0.4877
2024-12-29 14:32:24,166 - INFO - Epoch 26/500, Train Loss: 0.2632, Val Loss: 0.4961
2024-12-29 14:32:24,532 - INFO - Epoch 27/500, Train Loss: 0.2622, Val Loss: 0.4893
2024-12-29 14:32:24,861 - INFO - Epoch 28/500, Train Loss: 0.2618, Val Loss: 0.4944
2024-12-29 14:32:25,234 - INFO - Epoch 29/500, Train Loss: 0.2605, Val Loss: 0.4889
2024-12-29 14:32:25,572 - INFO - Epoch 30/500, Train Loss: 0.2560, Val Loss: 0.4953
2024-12-29 14:32:25,573 - INFO - Early stopping triggered at epoch 30
2024-12-29 14:32:25,573 - INFO - Training completed in 10.36s
2024-12-29 14:32:25,573 - INFO - Final memory usage: CPU 2767.0 MB, GPU 104.8 MB
2024-12-29 14:32:25,574 - INFO - Model training completed in 10.36s
2024-12-29 14:32:25,618 - INFO - Prediction completed in 0.04s
2024-12-29 14:32:25,636 - INFO - Poison rate 0.1 completed in 10.42s
2024-12-29 14:32:25,636 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:32:25,640 - INFO - Total number of labels flipped: 1699
2024-12-29 14:32:25,640 - INFO - Label flipping completed in 0.00s
2024-12-29 14:32:25,640 - INFO - Training set processing completed in 0.00s
2024-12-29 14:32:25,641 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:32:25,642 - INFO - Memory usage at start_fit: CPU 2737.7 MB, GPU 104.7 MB
2024-12-29 14:32:25,642 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:32:25,646 - INFO - Number of unique classes: 10
2024-12-29 14:32:25,717 - INFO - Fitted scaler and transformed data
2024-12-29 14:32:25,717 - INFO - Scaling time: 0.07s
2024-12-29 14:32:26,044 - INFO - Epoch 1/500, Train Loss: 2.6103, Val Loss: 1.8779
2024-12-29 14:32:26,381 - INFO - Epoch 2/500, Train Loss: 1.6822, Val Loss: 1.6332
2024-12-29 14:32:26,702 - INFO - Epoch 3/500, Train Loss: 1.4034, Val Loss: 1.4297
2024-12-29 14:32:27,038 - INFO - Epoch 4/500, Train Loss: 1.1818, Val Loss: 1.2840
2024-12-29 14:32:27,386 - INFO - Epoch 5/500, Train Loss: 1.0116, Val Loss: 1.1156
2024-12-29 14:32:27,732 - INFO - Epoch 6/500, Train Loss: 0.8631, Val Loss: 0.9786
2024-12-29 14:32:28,064 - INFO - Epoch 7/500, Train Loss: 0.7711, Val Loss: 0.8845
2024-12-29 14:32:28,388 - INFO - Epoch 8/500, Train Loss: 0.6966, Val Loss: 0.8191
2024-12-29 14:32:28,719 - INFO - Epoch 9/500, Train Loss: 0.6534, Val Loss: 0.7741
2024-12-29 14:32:29,079 - INFO - Epoch 10/500, Train Loss: 0.6115, Val Loss: 0.7532
2024-12-29 14:32:29,433 - INFO - Epoch 11/500, Train Loss: 0.5859, Val Loss: 0.7248
2024-12-29 14:32:29,807 - INFO - Epoch 12/500, Train Loss: 0.5699, Val Loss: 0.7070
2024-12-29 14:32:30,124 - INFO - Epoch 13/500, Train Loss: 0.5533, Val Loss: 0.6947
2024-12-29 14:32:30,519 - INFO - Epoch 14/500, Train Loss: 0.5397, Val Loss: 0.6898
2024-12-29 14:32:30,854 - INFO - Epoch 15/500, Train Loss: 0.5331, Val Loss: 0.6859
2024-12-29 14:32:31,198 - INFO - Epoch 16/500, Train Loss: 0.5226, Val Loss: 0.6850
2024-12-29 14:32:31,586 - INFO - Epoch 17/500, Train Loss: 0.5181, Val Loss: 0.6795
2024-12-29 14:32:31,984 - INFO - Epoch 18/500, Train Loss: 0.5110, Val Loss: 0.6778
2024-12-29 14:32:32,315 - INFO - Epoch 19/500, Train Loss: 0.5045, Val Loss: 0.6763
2024-12-29 14:32:32,706 - INFO - Epoch 20/500, Train Loss: 0.5014, Val Loss: 0.6758
2024-12-29 14:32:33,109 - INFO - Epoch 21/500, Train Loss: 0.4965, Val Loss: 0.6614
2024-12-29 14:32:33,482 - INFO - Epoch 22/500, Train Loss: 0.4922, Val Loss: 0.6702
2024-12-29 14:32:33,825 - INFO - Epoch 23/500, Train Loss: 0.4876, Val Loss: 0.6726
2024-12-29 14:32:34,254 - INFO - Epoch 24/500, Train Loss: 0.4844, Val Loss: 0.6514
2024-12-29 14:32:34,610 - INFO - Epoch 25/500, Train Loss: 0.4799, Val Loss: 0.6682
2024-12-29 14:32:35,020 - INFO - Epoch 26/500, Train Loss: 0.4767, Val Loss: 0.6767
2024-12-29 14:32:35,386 - INFO - Epoch 27/500, Train Loss: 0.4745, Val Loss: 0.6810
2024-12-29 14:32:35,738 - INFO - Epoch 28/500, Train Loss: 0.4757, Val Loss: 0.6730
2024-12-29 14:32:36,060 - INFO - Epoch 29/500, Train Loss: 0.4686, Val Loss: 0.6721
2024-12-29 14:32:36,060 - INFO - Early stopping triggered at epoch 29
2024-12-29 14:32:36,060 - INFO - Training completed in 10.42s
2024-12-29 14:32:36,061 - INFO - Final memory usage: CPU 2767.1 MB, GPU 104.8 MB
2024-12-29 14:32:36,062 - INFO - Model training completed in 10.42s
2024-12-29 14:32:36,120 - INFO - Prediction completed in 0.06s
2024-12-29 14:32:36,129 - INFO - Poison rate 0.2 completed in 10.49s
2024-12-29 14:32:36,139 - INFO - Loaded 504 existing results
2024-12-29 14:32:36,139 - INFO - Total results to save: 511
2024-12-29 14:32:36,140 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:32:36,164 - INFO - Saved 511 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:32:36,166 - INFO - Total evaluation time: 91.05s
2024-12-29 14:32:36,170 - INFO - 
Progress: 77.1% - Evaluating CIFAR100 with SVM (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:32:36,378 - INFO - Loading datasets...
2024-12-29 14:32:36,399 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:32:36,399 - INFO - Extracting validation features...
2024-12-29 14:32:36,400 - INFO - Extracting features from 3925 samples...
2024-12-29 14:32:45,835 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:32:45,841 - INFO - Validation feature extraction completed in 9.44s
2024-12-29 14:32:45,841 - INFO - Extracting training features...
2024-12-29 14:32:45,841 - INFO - Extracting features from 9469 samples...
2024-12-29 14:33:07,957 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:33:07,960 - INFO - Training feature extraction completed in 22.12s
2024-12-29 14:33:07,960 - INFO - Creating model for classifier: SVM
2024-12-29 14:33:07,960 - INFO - Using device: cuda
2024-12-29 14:33:07,960 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-29 14:33:07,961 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:33:07,961 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:33:07,961 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:33:08,567 - INFO - Feature scaling completed in 0.61s
2024-12-29 14:33:08,567 - INFO - Starting feature selection (k=50)
2024-12-29 14:33:08,576 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:33:08,576 - INFO - Starting anomaly detection
2024-12-29 14:33:11,551 - INFO - Anomaly detection completed in 2.98s
2024-12-29 14:33:11,552 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:33:11,552 - INFO - Total fit_transform time: 3.59s
2024-12-29 14:33:11,552 - INFO - Training set processing completed in 3.59s
2024-12-29 14:33:11,552 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:33:11,553 - INFO - Memory usage at start_fit: CPU 2758.0 MB, GPU 104.0 MB
2024-12-29 14:33:11,553 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:33:11,555 - INFO - Number of unique classes: 10
2024-12-29 14:33:11,626 - INFO - Fitted scaler and transformed data
2024-12-29 14:33:11,626 - INFO - Scaling time: 0.07s
2024-12-29 14:33:11,956 - INFO - Epoch 1/500, Train Loss: 0.8135, Val Loss: 0.1536
2024-12-29 14:33:12,295 - INFO - Epoch 2/500, Train Loss: 0.0933, Val Loss: 0.1215
2024-12-29 14:33:12,630 - INFO - Epoch 3/500, Train Loss: 0.0593, Val Loss: 0.1084
2024-12-29 14:33:12,951 - INFO - Epoch 4/500, Train Loss: 0.0407, Val Loss: 0.1016
2024-12-29 14:33:13,290 - INFO - Epoch 5/500, Train Loss: 0.0309, Val Loss: 0.0993
2024-12-29 14:33:13,630 - INFO - Epoch 6/500, Train Loss: 0.0245, Val Loss: 0.0997
2024-12-29 14:33:13,944 - INFO - Epoch 7/500, Train Loss: 0.0201, Val Loss: 0.0974
2024-12-29 14:33:14,263 - INFO - Epoch 8/500, Train Loss: 0.0169, Val Loss: 0.0973
2024-12-29 14:33:14,575 - INFO - Epoch 9/500, Train Loss: 0.0141, Val Loss: 0.0953
2024-12-29 14:33:14,915 - INFO - Epoch 10/500, Train Loss: 0.0118, Val Loss: 0.0989
2024-12-29 14:33:15,236 - INFO - Epoch 11/500, Train Loss: 0.0102, Val Loss: 0.0968
2024-12-29 14:33:15,628 - INFO - Epoch 12/500, Train Loss: 0.0087, Val Loss: 0.0968
2024-12-29 14:33:15,972 - INFO - Epoch 13/500, Train Loss: 0.0075, Val Loss: 0.0960
2024-12-29 14:33:16,328 - INFO - Epoch 14/500, Train Loss: 0.0066, Val Loss: 0.0967
2024-12-29 14:33:16,328 - INFO - Early stopping triggered at epoch 14
2024-12-29 14:33:16,328 - INFO - Training completed in 4.78s
2024-12-29 14:33:16,328 - INFO - Final memory usage: CPU 2767.3 MB, GPU 104.2 MB
2024-12-29 14:33:16,329 - INFO - Model training completed in 4.78s
2024-12-29 14:33:16,376 - INFO - Prediction completed in 0.05s
2024-12-29 14:33:16,385 - INFO - Poison rate 0.0 completed in 8.42s
2024-12-29 14:33:16,386 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:33:16,386 - INFO - Total number of labels flipped: 84
2024-12-29 14:33:16,387 - INFO - Label flipping completed in 0.00s
2024-12-29 14:33:16,387 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:33:16,387 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:33:16,956 - INFO - Feature scaling completed in 0.57s
2024-12-29 14:33:16,956 - INFO - Starting feature selection (k=50)
2024-12-29 14:33:16,971 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:33:16,971 - INFO - Starting anomaly detection
2024-12-29 14:33:21,291 - INFO - Anomaly detection completed in 4.32s
2024-12-29 14:33:21,291 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:33:21,291 - INFO - Total fit_transform time: 4.90s
2024-12-29 14:33:21,291 - INFO - Training set processing completed in 4.90s
2024-12-29 14:33:21,291 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:33:21,292 - INFO - Memory usage at start_fit: CPU 2758.0 MB, GPU 104.1 MB
2024-12-29 14:33:21,292 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:33:21,295 - INFO - Number of unique classes: 10
2024-12-29 14:33:21,365 - INFO - Fitted scaler and transformed data
2024-12-29 14:33:21,365 - INFO - Scaling time: 0.07s
2024-12-29 14:33:21,705 - INFO - Epoch 1/500, Train Loss: 0.9886, Val Loss: 0.2670
2024-12-29 14:33:22,051 - INFO - Epoch 2/500, Train Loss: 0.1892, Val Loss: 0.2316
2024-12-29 14:33:22,356 - INFO - Epoch 3/500, Train Loss: 0.1444, Val Loss: 0.2229
2024-12-29 14:33:22,729 - INFO - Epoch 4/500, Train Loss: 0.1188, Val Loss: 0.2069
2024-12-29 14:33:23,057 - INFO - Epoch 5/500, Train Loss: 0.1005, Val Loss: 0.2017
2024-12-29 14:33:23,408 - INFO - Epoch 6/500, Train Loss: 0.0883, Val Loss: 0.1941
2024-12-29 14:33:23,730 - INFO - Epoch 7/500, Train Loss: 0.0775, Val Loss: 0.1941
2024-12-29 14:33:24,067 - INFO - Epoch 8/500, Train Loss: 0.0688, Val Loss: 0.1916
2024-12-29 14:33:24,431 - INFO - Epoch 9/500, Train Loss: 0.0630, Val Loss: 0.1938
2024-12-29 14:33:24,762 - INFO - Epoch 10/500, Train Loss: 0.0578, Val Loss: 0.1894
2024-12-29 14:33:25,080 - INFO - Epoch 11/500, Train Loss: 0.0534, Val Loss: 0.1945
2024-12-29 14:33:25,403 - INFO - Epoch 12/500, Train Loss: 0.0502, Val Loss: 0.1899
2024-12-29 14:33:25,775 - INFO - Epoch 13/500, Train Loss: 0.0468, Val Loss: 0.1942
2024-12-29 14:33:26,106 - INFO - Epoch 14/500, Train Loss: 0.0442, Val Loss: 0.1900
2024-12-29 14:33:26,424 - INFO - Epoch 15/500, Train Loss: 0.0421, Val Loss: 0.1920
2024-12-29 14:33:26,425 - INFO - Early stopping triggered at epoch 15
2024-12-29 14:33:26,425 - INFO - Training completed in 5.13s
2024-12-29 14:33:26,425 - INFO - Final memory usage: CPU 2767.4 MB, GPU 104.2 MB
2024-12-29 14:33:26,426 - INFO - Model training completed in 5.13s
2024-12-29 14:33:26,472 - INFO - Prediction completed in 0.05s
2024-12-29 14:33:26,481 - INFO - Poison rate 0.01 completed in 10.10s
2024-12-29 14:33:26,481 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:33:26,482 - INFO - Total number of labels flipped: 247
2024-12-29 14:33:26,482 - INFO - Label flipping completed in 0.00s
2024-12-29 14:33:26,482 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:33:26,482 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:33:26,986 - INFO - Feature scaling completed in 0.50s
2024-12-29 14:33:26,986 - INFO - Starting feature selection (k=50)
2024-12-29 14:33:27,001 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 14:33:27,001 - INFO - Starting anomaly detection
2024-12-29 14:33:30,232 - INFO - Anomaly detection completed in 3.23s
2024-12-29 14:33:30,232 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:33:30,232 - INFO - Total fit_transform time: 3.75s
2024-12-29 14:33:30,232 - INFO - Training set processing completed in 3.75s
2024-12-29 14:33:30,233 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:33:30,234 - INFO - Memory usage at start_fit: CPU 2757.8 MB, GPU 104.1 MB
2024-12-29 14:33:30,234 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:33:30,236 - INFO - Number of unique classes: 10
2024-12-29 14:33:30,305 - INFO - Fitted scaler and transformed data
2024-12-29 14:33:30,306 - INFO - Scaling time: 0.07s
2024-12-29 14:33:30,662 - INFO - Epoch 1/500, Train Loss: 0.9085, Val Loss: 0.4347
2024-12-29 14:33:30,965 - INFO - Epoch 2/500, Train Loss: 0.3486, Val Loss: 0.3962
2024-12-29 14:33:31,316 - INFO - Epoch 3/500, Train Loss: 0.2853, Val Loss: 0.3794
2024-12-29 14:33:31,647 - INFO - Epoch 4/500, Train Loss: 0.2441, Val Loss: 0.3680
2024-12-29 14:33:31,976 - INFO - Epoch 5/500, Train Loss: 0.2111, Val Loss: 0.3553
2024-12-29 14:33:32,320 - INFO - Epoch 6/500, Train Loss: 0.1868, Val Loss: 0.3488
2024-12-29 14:33:32,644 - INFO - Epoch 7/500, Train Loss: 0.1699, Val Loss: 0.3392
2024-12-29 14:33:32,956 - INFO - Epoch 8/500, Train Loss: 0.1554, Val Loss: 0.3282
2024-12-29 14:33:33,348 - INFO - Epoch 9/500, Train Loss: 0.1433, Val Loss: 0.3268
2024-12-29 14:33:33,686 - INFO - Epoch 10/500, Train Loss: 0.1375, Val Loss: 0.3145
2024-12-29 14:33:34,038 - INFO - Epoch 11/500, Train Loss: 0.1265, Val Loss: 0.2997
2024-12-29 14:33:34,363 - INFO - Epoch 12/500, Train Loss: 0.1205, Val Loss: 0.2941
2024-12-29 14:33:34,682 - INFO - Epoch 13/500, Train Loss: 0.1167, Val Loss: 0.2994
2024-12-29 14:33:35,042 - INFO - Epoch 14/500, Train Loss: 0.1104, Val Loss: 0.2960
2024-12-29 14:33:35,365 - INFO - Epoch 15/500, Train Loss: 0.1068, Val Loss: 0.2851
2024-12-29 14:33:35,727 - INFO - Epoch 16/500, Train Loss: 0.1030, Val Loss: 0.2776
2024-12-29 14:33:36,049 - INFO - Epoch 17/500, Train Loss: 0.1014, Val Loss: 0.2787
2024-12-29 14:33:36,406 - INFO - Epoch 18/500, Train Loss: 0.0987, Val Loss: 0.2756
2024-12-29 14:33:36,766 - INFO - Epoch 19/500, Train Loss: 0.0953, Val Loss: 0.2744
2024-12-29 14:33:37,110 - INFO - Epoch 20/500, Train Loss: 0.0942, Val Loss: 0.2822
2024-12-29 14:33:37,456 - INFO - Epoch 21/500, Train Loss: 0.0922, Val Loss: 0.2805
2024-12-29 14:33:37,785 - INFO - Epoch 22/500, Train Loss: 0.0909, Val Loss: 0.2770
2024-12-29 14:33:38,128 - INFO - Epoch 23/500, Train Loss: 0.0895, Val Loss: 0.2646
2024-12-29 14:33:38,528 - INFO - Epoch 24/500, Train Loss: 0.0878, Val Loss: 0.2619
2024-12-29 14:33:38,882 - INFO - Epoch 25/500, Train Loss: 0.0867, Val Loss: 0.2666
2024-12-29 14:33:39,203 - INFO - Epoch 26/500, Train Loss: 0.0861, Val Loss: 0.2650
2024-12-29 14:33:39,543 - INFO - Epoch 27/500, Train Loss: 0.0850, Val Loss: 0.2765
2024-12-29 14:33:39,887 - INFO - Epoch 28/500, Train Loss: 0.0841, Val Loss: 0.2764
2024-12-29 14:33:40,214 - INFO - Epoch 29/500, Train Loss: 0.0822, Val Loss: 0.2623
2024-12-29 14:33:40,214 - INFO - Early stopping triggered at epoch 29
2024-12-29 14:33:40,214 - INFO - Training completed in 9.98s
2024-12-29 14:33:40,214 - INFO - Final memory usage: CPU 2767.4 MB, GPU 104.2 MB
2024-12-29 14:33:40,215 - INFO - Model training completed in 9.98s
2024-12-29 14:33:40,288 - INFO - Prediction completed in 0.07s
2024-12-29 14:33:40,296 - INFO - Poison rate 0.03 completed in 13.82s
2024-12-29 14:33:40,296 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:33:40,297 - INFO - Total number of labels flipped: 425
2024-12-29 14:33:40,298 - INFO - Label flipping completed in 0.00s
2024-12-29 14:33:40,298 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:33:40,298 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:33:40,832 - INFO - Feature scaling completed in 0.53s
2024-12-29 14:33:40,832 - INFO - Starting feature selection (k=50)
2024-12-29 14:33:40,848 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 14:33:40,848 - INFO - Starting anomaly detection
2024-12-29 14:33:43,506 - INFO - Anomaly detection completed in 2.66s
2024-12-29 14:33:43,506 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:33:43,506 - INFO - Total fit_transform time: 3.21s
2024-12-29 14:33:43,507 - INFO - Training set processing completed in 3.21s
2024-12-29 14:33:43,507 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:33:43,508 - INFO - Memory usage at start_fit: CPU 2757.8 MB, GPU 104.1 MB
2024-12-29 14:33:43,508 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:33:43,512 - INFO - Number of unique classes: 10
2024-12-29 14:33:43,581 - INFO - Fitted scaler and transformed data
2024-12-29 14:33:43,581 - INFO - Scaling time: 0.07s
2024-12-29 14:33:43,943 - INFO - Epoch 1/500, Train Loss: 1.1989, Val Loss: 0.5382
2024-12-29 14:33:44,291 - INFO - Epoch 2/500, Train Loss: 0.5302, Val Loss: 0.4809
2024-12-29 14:33:44,618 - INFO - Epoch 3/500, Train Loss: 0.4460, Val Loss: 0.4504
2024-12-29 14:33:44,920 - INFO - Epoch 4/500, Train Loss: 0.3753, Val Loss: 0.4169
2024-12-29 14:33:45,268 - INFO - Epoch 5/500, Train Loss: 0.3318, Val Loss: 0.4059
2024-12-29 14:33:45,595 - INFO - Epoch 6/500, Train Loss: 0.2955, Val Loss: 0.3784
2024-12-29 14:33:45,917 - INFO - Epoch 7/500, Train Loss: 0.2683, Val Loss: 0.3737
2024-12-29 14:33:46,235 - INFO - Epoch 8/500, Train Loss: 0.2451, Val Loss: 0.3537
2024-12-29 14:33:46,582 - INFO - Epoch 9/500, Train Loss: 0.2283, Val Loss: 0.3441
2024-12-29 14:33:46,943 - INFO - Epoch 10/500, Train Loss: 0.2149, Val Loss: 0.3344
2024-12-29 14:33:47,286 - INFO - Epoch 11/500, Train Loss: 0.2021, Val Loss: 0.3144
2024-12-29 14:33:47,629 - INFO - Epoch 12/500, Train Loss: 0.1923, Val Loss: 0.3190
2024-12-29 14:33:47,980 - INFO - Epoch 13/500, Train Loss: 0.1850, Val Loss: 0.3108
2024-12-29 14:33:48,308 - INFO - Epoch 14/500, Train Loss: 0.1762, Val Loss: 0.3059
2024-12-29 14:33:48,634 - INFO - Epoch 15/500, Train Loss: 0.1707, Val Loss: 0.2983
2024-12-29 14:33:49,000 - INFO - Epoch 16/500, Train Loss: 0.1658, Val Loss: 0.3018
2024-12-29 14:33:49,328 - INFO - Epoch 17/500, Train Loss: 0.1629, Val Loss: 0.3024
2024-12-29 14:33:49,672 - INFO - Epoch 18/500, Train Loss: 0.1600, Val Loss: 0.2968
2024-12-29 14:33:50,004 - INFO - Epoch 19/500, Train Loss: 0.1551, Val Loss: 0.2974
2024-12-29 14:33:50,363 - INFO - Epoch 20/500, Train Loss: 0.1521, Val Loss: 0.3004
2024-12-29 14:33:50,732 - INFO - Epoch 21/500, Train Loss: 0.1482, Val Loss: 0.2958
2024-12-29 14:33:51,085 - INFO - Epoch 22/500, Train Loss: 0.1461, Val Loss: 0.2884
2024-12-29 14:33:51,470 - INFO - Epoch 23/500, Train Loss: 0.1442, Val Loss: 0.2859
2024-12-29 14:33:51,851 - INFO - Epoch 24/500, Train Loss: 0.1425, Val Loss: 0.2849
2024-12-29 14:33:52,184 - INFO - Epoch 25/500, Train Loss: 0.1409, Val Loss: 0.2845
2024-12-29 14:33:52,493 - INFO - Epoch 26/500, Train Loss: 0.1398, Val Loss: 0.2845
2024-12-29 14:33:52,798 - INFO - Epoch 27/500, Train Loss: 0.1371, Val Loss: 0.2942
2024-12-29 14:33:53,162 - INFO - Epoch 28/500, Train Loss: 0.1365, Val Loss: 0.2905
2024-12-29 14:33:53,512 - INFO - Epoch 29/500, Train Loss: 0.1340, Val Loss: 0.2855
2024-12-29 14:33:53,512 - INFO - Early stopping triggered at epoch 29
2024-12-29 14:33:53,512 - INFO - Training completed in 10.00s
2024-12-29 14:33:53,512 - INFO - Final memory usage: CPU 2767.4 MB, GPU 104.2 MB
2024-12-29 14:33:53,513 - INFO - Model training completed in 10.01s
2024-12-29 14:33:53,559 - INFO - Prediction completed in 0.05s
2024-12-29 14:33:53,567 - INFO - Poison rate 0.05 completed in 13.27s
2024-12-29 14:33:53,568 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:33:53,569 - INFO - Total number of labels flipped: 598
2024-12-29 14:33:53,569 - INFO - Label flipping completed in 0.00s
2024-12-29 14:33:53,569 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:33:53,569 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:33:54,084 - INFO - Feature scaling completed in 0.52s
2024-12-29 14:33:54,084 - INFO - Starting feature selection (k=50)
2024-12-29 14:33:54,099 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:33:54,100 - INFO - Starting anomaly detection
2024-12-29 14:33:58,411 - INFO - Anomaly detection completed in 4.31s
2024-12-29 14:33:58,412 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:33:58,412 - INFO - Total fit_transform time: 4.84s
2024-12-29 14:33:58,412 - INFO - Training set processing completed in 4.84s
2024-12-29 14:33:58,412 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:33:58,414 - INFO - Memory usage at start_fit: CPU 2757.9 MB, GPU 104.1 MB
2024-12-29 14:33:58,414 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:33:58,416 - INFO - Number of unique classes: 10
2024-12-29 14:33:58,487 - INFO - Fitted scaler and transformed data
2024-12-29 14:33:58,488 - INFO - Scaling time: 0.07s
2024-12-29 14:33:58,788 - INFO - Epoch 1/500, Train Loss: 1.4229, Val Loss: 0.9061
2024-12-29 14:33:59,104 - INFO - Epoch 2/500, Train Loss: 0.6811, Val Loss: 0.8094
2024-12-29 14:33:59,406 - INFO - Epoch 3/500, Train Loss: 0.5654, Val Loss: 0.7744
2024-12-29 14:33:59,716 - INFO - Epoch 4/500, Train Loss: 0.4787, Val Loss: 0.7311
2024-12-29 14:34:00,077 - INFO - Epoch 5/500, Train Loss: 0.4199, Val Loss: 0.6769
2024-12-29 14:34:00,435 - INFO - Epoch 6/500, Train Loss: 0.3764, Val Loss: 0.6343
2024-12-29 14:34:00,751 - INFO - Epoch 7/500, Train Loss: 0.3377, Val Loss: 0.5883
2024-12-29 14:34:01,105 - INFO - Epoch 8/500, Train Loss: 0.3087, Val Loss: 0.5636
2024-12-29 14:34:01,417 - INFO - Epoch 9/500, Train Loss: 0.2846, Val Loss: 0.5466
2024-12-29 14:34:01,771 - INFO - Epoch 10/500, Train Loss: 0.2685, Val Loss: 0.5121
2024-12-29 14:34:02,095 - INFO - Epoch 11/500, Train Loss: 0.2541, Val Loss: 0.4931
2024-12-29 14:34:02,474 - INFO - Epoch 12/500, Train Loss: 0.2422, Val Loss: 0.4883
2024-12-29 14:34:02,816 - INFO - Epoch 13/500, Train Loss: 0.2324, Val Loss: 0.4777
2024-12-29 14:34:03,167 - INFO - Epoch 14/500, Train Loss: 0.2256, Val Loss: 0.4685
2024-12-29 14:34:03,545 - INFO - Epoch 15/500, Train Loss: 0.2192, Val Loss: 0.4458
2024-12-29 14:34:03,936 - INFO - Epoch 16/500, Train Loss: 0.2127, Val Loss: 0.4570
2024-12-29 14:34:04,321 - INFO - Epoch 17/500, Train Loss: 0.2104, Val Loss: 0.4487
2024-12-29 14:34:04,706 - INFO - Epoch 18/500, Train Loss: 0.2061, Val Loss: 0.4481
2024-12-29 14:34:05,070 - INFO - Epoch 19/500, Train Loss: 0.2024, Val Loss: 0.4445
2024-12-29 14:34:05,434 - INFO - Epoch 20/500, Train Loss: 0.1992, Val Loss: 0.4391
2024-12-29 14:34:05,783 - INFO - Epoch 21/500, Train Loss: 0.1972, Val Loss: 0.4296
2024-12-29 14:34:06,114 - INFO - Epoch 22/500, Train Loss: 0.1948, Val Loss: 0.4405
2024-12-29 14:34:06,445 - INFO - Epoch 23/500, Train Loss: 0.1920, Val Loss: 0.4404
2024-12-29 14:34:06,763 - INFO - Epoch 24/500, Train Loss: 0.1918, Val Loss: 0.4335
2024-12-29 14:34:07,089 - INFO - Epoch 25/500, Train Loss: 0.1900, Val Loss: 0.4344
2024-12-29 14:34:07,445 - INFO - Epoch 26/500, Train Loss: 0.1886, Val Loss: 0.4212
2024-12-29 14:34:07,796 - INFO - Epoch 27/500, Train Loss: 0.1863, Val Loss: 0.4264
2024-12-29 14:34:08,188 - INFO - Epoch 28/500, Train Loss: 0.1839, Val Loss: 0.4320
2024-12-29 14:34:08,547 - INFO - Epoch 29/500, Train Loss: 0.1822, Val Loss: 0.4417
2024-12-29 14:34:08,895 - INFO - Epoch 30/500, Train Loss: 0.1801, Val Loss: 0.4261
2024-12-29 14:34:09,231 - INFO - Epoch 31/500, Train Loss: 0.1809, Val Loss: 0.4349
2024-12-29 14:34:09,231 - INFO - Early stopping triggered at epoch 31
2024-12-29 14:34:09,231 - INFO - Training completed in 10.82s
2024-12-29 14:34:09,232 - INFO - Final memory usage: CPU 2767.4 MB, GPU 104.2 MB
2024-12-29 14:34:09,233 - INFO - Model training completed in 10.82s
2024-12-29 14:34:09,286 - INFO - Prediction completed in 0.05s
2024-12-29 14:34:09,294 - INFO - Poison rate 0.07 completed in 15.73s
2024-12-29 14:34:09,294 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:34:09,296 - INFO - Total number of labels flipped: 850
2024-12-29 14:34:09,296 - INFO - Label flipping completed in 0.00s
2024-12-29 14:34:09,296 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:34:09,296 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:34:09,849 - INFO - Feature scaling completed in 0.55s
2024-12-29 14:34:09,849 - INFO - Starting feature selection (k=50)
2024-12-29 14:34:09,864 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:34:09,864 - INFO - Starting anomaly detection
2024-12-29 14:34:13,370 - INFO - Anomaly detection completed in 3.51s
2024-12-29 14:34:13,370 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:34:13,370 - INFO - Total fit_transform time: 4.07s
2024-12-29 14:34:13,371 - INFO - Training set processing completed in 4.07s
2024-12-29 14:34:13,371 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:34:13,372 - INFO - Memory usage at start_fit: CPU 2757.8 MB, GPU 104.1 MB
2024-12-29 14:34:13,372 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:34:13,374 - INFO - Number of unique classes: 10
2024-12-29 14:34:13,451 - INFO - Fitted scaler and transformed data
2024-12-29 14:34:13,452 - INFO - Scaling time: 0.08s
2024-12-29 14:34:13,802 - INFO - Epoch 1/500, Train Loss: 1.6996, Val Loss: 1.3627
2024-12-29 14:34:14,107 - INFO - Epoch 2/500, Train Loss: 0.9354, Val Loss: 1.2004
2024-12-29 14:34:14,441 - INFO - Epoch 3/500, Train Loss: 0.7664, Val Loss: 1.0812
2024-12-29 14:34:14,778 - INFO - Epoch 4/500, Train Loss: 0.6546, Val Loss: 0.9889
2024-12-29 14:34:15,163 - INFO - Epoch 5/500, Train Loss: 0.5709, Val Loss: 0.9092
2024-12-29 14:34:15,587 - INFO - Epoch 6/500, Train Loss: 0.4990, Val Loss: 0.8492
2024-12-29 14:34:15,924 - INFO - Epoch 7/500, Train Loss: 0.4438, Val Loss: 0.7842
2024-12-29 14:34:16,265 - INFO - Epoch 8/500, Train Loss: 0.4040, Val Loss: 0.7398
2024-12-29 14:34:16,673 - INFO - Epoch 9/500, Train Loss: 0.3728, Val Loss: 0.6864
2024-12-29 14:34:17,047 - INFO - Epoch 10/500, Train Loss: 0.3501, Val Loss: 0.6531
2024-12-29 14:34:17,369 - INFO - Epoch 11/500, Train Loss: 0.3323, Val Loss: 0.6273
2024-12-29 14:34:17,712 - INFO - Epoch 12/500, Train Loss: 0.3146, Val Loss: 0.6255
2024-12-29 14:34:18,085 - INFO - Epoch 13/500, Train Loss: 0.3049, Val Loss: 0.6112
2024-12-29 14:34:18,451 - INFO - Epoch 14/500, Train Loss: 0.2965, Val Loss: 0.5821
2024-12-29 14:34:18,792 - INFO - Epoch 15/500, Train Loss: 0.2898, Val Loss: 0.5783
2024-12-29 14:34:19,190 - INFO - Epoch 16/500, Train Loss: 0.2816, Val Loss: 0.5748
2024-12-29 14:34:19,561 - INFO - Epoch 17/500, Train Loss: 0.2748, Val Loss: 0.5678
2024-12-29 14:34:19,936 - INFO - Epoch 18/500, Train Loss: 0.2705, Val Loss: 0.5588
2024-12-29 14:34:20,285 - INFO - Epoch 19/500, Train Loss: 0.2666, Val Loss: 0.5605
2024-12-29 14:34:20,701 - INFO - Epoch 20/500, Train Loss: 0.2629, Val Loss: 0.5506
2024-12-29 14:34:21,073 - INFO - Epoch 21/500, Train Loss: 0.2592, Val Loss: 0.5434
2024-12-29 14:34:21,433 - INFO - Epoch 22/500, Train Loss: 0.2585, Val Loss: 0.5462
2024-12-29 14:34:21,787 - INFO - Epoch 23/500, Train Loss: 0.2525, Val Loss: 0.5391
2024-12-29 14:34:22,154 - INFO - Epoch 24/500, Train Loss: 0.2523, Val Loss: 0.5490
2024-12-29 14:34:22,525 - INFO - Epoch 25/500, Train Loss: 0.2509, Val Loss: 0.5357
2024-12-29 14:34:22,858 - INFO - Epoch 26/500, Train Loss: 0.2469, Val Loss: 0.5414
2024-12-29 14:34:23,184 - INFO - Epoch 27/500, Train Loss: 0.2458, Val Loss: 0.5326
2024-12-29 14:34:23,541 - INFO - Epoch 28/500, Train Loss: 0.2424, Val Loss: 0.5381
2024-12-29 14:34:23,893 - INFO - Epoch 29/500, Train Loss: 0.2423, Val Loss: 0.5440
2024-12-29 14:34:24,262 - INFO - Epoch 30/500, Train Loss: 0.2404, Val Loss: 0.5455
2024-12-29 14:34:24,609 - INFO - Epoch 31/500, Train Loss: 0.2390, Val Loss: 0.5403
2024-12-29 14:34:24,943 - INFO - Epoch 32/500, Train Loss: 0.2383, Val Loss: 0.5415
2024-12-29 14:34:24,943 - INFO - Early stopping triggered at epoch 32
2024-12-29 14:34:24,943 - INFO - Training completed in 11.57s
2024-12-29 14:34:24,943 - INFO - Final memory usage: CPU 2767.4 MB, GPU 104.2 MB
2024-12-29 14:34:24,944 - INFO - Model training completed in 11.57s
2024-12-29 14:34:24,992 - INFO - Prediction completed in 0.05s
2024-12-29 14:34:25,001 - INFO - Poison rate 0.1 completed in 15.71s
2024-12-29 14:34:25,001 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:34:25,002 - INFO - Total number of labels flipped: 1705
2024-12-29 14:34:25,003 - INFO - Label flipping completed in 0.00s
2024-12-29 14:34:25,003 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:34:25,003 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:34:25,566 - INFO - Feature scaling completed in 0.56s
2024-12-29 14:34:25,566 - INFO - Starting feature selection (k=50)
2024-12-29 14:34:25,582 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 14:34:25,582 - INFO - Starting anomaly detection
2024-12-29 14:34:30,046 - INFO - Anomaly detection completed in 4.46s
2024-12-29 14:34:30,047 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:34:30,047 - INFO - Total fit_transform time: 5.04s
2024-12-29 14:34:30,047 - INFO - Training set processing completed in 5.04s
2024-12-29 14:34:30,047 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:34:30,048 - INFO - Memory usage at start_fit: CPU 2757.8 MB, GPU 104.1 MB
2024-12-29 14:34:30,048 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:34:30,050 - INFO - Number of unique classes: 10
2024-12-29 14:34:30,122 - INFO - Fitted scaler and transformed data
2024-12-29 14:34:30,122 - INFO - Scaling time: 0.07s
2024-12-29 14:34:30,472 - INFO - Epoch 1/500, Train Loss: 2.6412, Val Loss: 1.8938
2024-12-29 14:34:30,801 - INFO - Epoch 2/500, Train Loss: 1.7278, Val Loss: 1.6685
2024-12-29 14:34:31,112 - INFO - Epoch 3/500, Train Loss: 1.4646, Val Loss: 1.4969
2024-12-29 14:34:31,422 - INFO - Epoch 4/500, Train Loss: 1.2372, Val Loss: 1.3137
2024-12-29 14:34:31,739 - INFO - Epoch 5/500, Train Loss: 1.0498, Val Loss: 1.1680
2024-12-29 14:34:32,058 - INFO - Epoch 6/500, Train Loss: 0.9046, Val Loss: 1.0554
2024-12-29 14:34:32,429 - INFO - Epoch 7/500, Train Loss: 0.7960, Val Loss: 0.9387
2024-12-29 14:34:32,784 - INFO - Epoch 8/500, Train Loss: 0.7102, Val Loss: 0.8781
2024-12-29 14:34:33,174 - INFO - Epoch 9/500, Train Loss: 0.6433, Val Loss: 0.7987
2024-12-29 14:34:33,519 - INFO - Epoch 10/500, Train Loss: 0.6024, Val Loss: 0.7747
2024-12-29 14:34:33,889 - INFO - Epoch 11/500, Train Loss: 0.5712, Val Loss: 0.7486
2024-12-29 14:34:34,276 - INFO - Epoch 12/500, Train Loss: 0.5480, Val Loss: 0.7261
2024-12-29 14:34:34,699 - INFO - Epoch 13/500, Train Loss: 0.5338, Val Loss: 0.7212
2024-12-29 14:34:35,140 - INFO - Epoch 14/500, Train Loss: 0.5185, Val Loss: 0.7044
2024-12-29 14:34:35,523 - INFO - Epoch 15/500, Train Loss: 0.5079, Val Loss: 0.7045
2024-12-29 14:34:35,876 - INFO - Epoch 16/500, Train Loss: 0.5000, Val Loss: 0.7008
2024-12-29 14:34:36,281 - INFO - Epoch 17/500, Train Loss: 0.4939, Val Loss: 0.6902
2024-12-29 14:34:36,659 - INFO - Epoch 18/500, Train Loss: 0.4870, Val Loss: 0.6905
2024-12-29 14:34:37,032 - INFO - Epoch 19/500, Train Loss: 0.4805, Val Loss: 0.6882
2024-12-29 14:34:37,362 - INFO - Epoch 20/500, Train Loss: 0.4756, Val Loss: 0.6866
2024-12-29 14:34:37,690 - INFO - Epoch 21/500, Train Loss: 0.4704, Val Loss: 0.6870
2024-12-29 14:34:38,112 - INFO - Epoch 22/500, Train Loss: 0.4671, Val Loss: 0.6904
2024-12-29 14:34:38,449 - INFO - Epoch 23/500, Train Loss: 0.4602, Val Loss: 0.6854
2024-12-29 14:34:38,825 - INFO - Epoch 24/500, Train Loss: 0.4588, Val Loss: 0.6976
2024-12-29 14:34:39,226 - INFO - Epoch 25/500, Train Loss: 0.4537, Val Loss: 0.6974
2024-12-29 14:34:39,629 - INFO - Epoch 26/500, Train Loss: 0.4535, Val Loss: 0.6865
2024-12-29 14:34:40,009 - INFO - Epoch 27/500, Train Loss: 0.4508, Val Loss: 0.6906
2024-12-29 14:34:40,375 - INFO - Epoch 28/500, Train Loss: 0.4479, Val Loss: 0.6906
2024-12-29 14:34:40,375 - INFO - Early stopping triggered at epoch 28
2024-12-29 14:34:40,375 - INFO - Training completed in 10.33s
2024-12-29 14:34:40,375 - INFO - Final memory usage: CPU 2767.0 MB, GPU 104.2 MB
2024-12-29 14:34:40,376 - INFO - Model training completed in 10.33s
2024-12-29 14:34:40,421 - INFO - Prediction completed in 0.04s
2024-12-29 14:34:40,429 - INFO - Poison rate 0.2 completed in 15.43s
2024-12-29 14:34:40,439 - INFO - Loaded 511 existing results
2024-12-29 14:34:40,439 - INFO - Total results to save: 518
2024-12-29 14:34:40,440 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:34:40,456 - INFO - Saved 518 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:34:40,456 - INFO - Total evaluation time: 124.08s
2024-12-29 14:34:40,458 - INFO - 
Progress: 78.1% - Evaluating CIFAR100 with LogisticRegression (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:34:40,643 - INFO - Loading datasets...
2024-12-29 14:34:40,664 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:34:40,664 - INFO - Extracting validation features...
2024-12-29 14:34:40,664 - INFO - Extracting features from 3925 samples...
2024-12-29 14:34:49,981 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:34:49,984 - INFO - Validation feature extraction completed in 9.32s
2024-12-29 14:34:49,984 - INFO - Extracting training features...
2024-12-29 14:34:49,985 - INFO - Extracting features from 9469 samples...
2024-12-29 14:35:11,813 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:35:11,816 - INFO - Training feature extraction completed in 21.83s
2024-12-29 14:35:11,816 - INFO - Creating model for classifier: LogisticRegression
2024-12-29 14:35:11,816 - INFO - Using device: cuda
2024-12-29 14:35:11,816 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:35:11,816 - INFO - Training set processing completed in 0.00s
2024-12-29 14:35:11,817 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:35:11,818 - INFO - Memory usage at start_fit: CPU 2730.3 MB, GPU 104.6 MB
2024-12-29 14:35:11,819 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:35:11,824 - INFO - Number of unique classes: 10
2024-12-29 14:35:11,902 - INFO - Fitted scaler and transformed data
2024-12-29 14:35:11,902 - INFO - Scaling time: 0.08s
2024-12-29 14:35:12,195 - INFO - Epoch 1/1000, Train Loss: 0.5117, Val Loss: 0.1071
2024-12-29 14:35:12,496 - INFO - Epoch 2/1000, Train Loss: 0.0974, Val Loss: 0.0696
2024-12-29 14:35:12,763 - INFO - Epoch 3/1000, Train Loss: 0.0696, Val Loss: 0.0552
2024-12-29 14:35:13,036 - INFO - Epoch 4/1000, Train Loss: 0.0566, Val Loss: 0.0481
2024-12-29 14:35:13,247 - INFO - Epoch 5/1000, Train Loss: 0.0491, Val Loss: 0.0442
2024-12-29 14:35:13,478 - INFO - Epoch 6/1000, Train Loss: 0.0436, Val Loss: 0.0416
2024-12-29 14:35:13,715 - INFO - Epoch 7/1000, Train Loss: 0.0399, Val Loss: 0.0396
2024-12-29 14:35:13,983 - INFO - Epoch 8/1000, Train Loss: 0.0376, Val Loss: 0.0389
2024-12-29 14:35:14,276 - INFO - Epoch 9/1000, Train Loss: 0.0357, Val Loss: 0.0381
2024-12-29 14:35:14,484 - INFO - Epoch 10/1000, Train Loss: 0.0343, Val Loss: 0.0376
2024-12-29 14:35:14,713 - INFO - Epoch 11/1000, Train Loss: 0.0329, Val Loss: 0.0372
2024-12-29 14:35:14,974 - INFO - Epoch 12/1000, Train Loss: 0.0324, Val Loss: 0.0368
2024-12-29 14:35:15,288 - INFO - Epoch 13/1000, Train Loss: 0.0318, Val Loss: 0.0362
2024-12-29 14:35:15,595 - INFO - Epoch 14/1000, Train Loss: 0.0309, Val Loss: 0.0365
2024-12-29 14:35:15,825 - INFO - Epoch 15/1000, Train Loss: 0.0307, Val Loss: 0.0361
2024-12-29 14:35:16,104 - INFO - Epoch 16/1000, Train Loss: 0.0302, Val Loss: 0.0362
2024-12-29 14:35:16,366 - INFO - Epoch 17/1000, Train Loss: 0.0301, Val Loss: 0.0360
2024-12-29 14:35:16,366 - INFO - Early stopping triggered at epoch 17
2024-12-29 14:35:16,366 - INFO - Training completed in 4.55s
2024-12-29 14:35:16,367 - INFO - Final memory usage: CPU 2767.3 MB, GPU 104.8 MB
2024-12-29 14:35:16,369 - INFO - Model training completed in 4.55s
2024-12-29 14:35:16,457 - INFO - Prediction completed in 0.09s
2024-12-29 14:35:16,471 - INFO - Poison rate 0.0 completed in 4.65s
2024-12-29 14:35:16,471 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:35:16,472 - INFO - Total number of labels flipped: 78
2024-12-29 14:35:16,472 - INFO - Label flipping completed in 0.00s
2024-12-29 14:35:16,472 - INFO - Training set processing completed in 0.00s
2024-12-29 14:35:16,472 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:35:16,473 - INFO - Memory usage at start_fit: CPU 2737.8 MB, GPU 104.7 MB
2024-12-29 14:35:16,474 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:35:16,478 - INFO - Number of unique classes: 10
2024-12-29 14:35:16,552 - INFO - Fitted scaler and transformed data
2024-12-29 14:35:16,552 - INFO - Scaling time: 0.07s
2024-12-29 14:35:16,804 - INFO - Epoch 1/1000, Train Loss: 0.4853, Val Loss: 0.2040
2024-12-29 14:35:17,026 - INFO - Epoch 2/1000, Train Loss: 0.1463, Val Loss: 0.1776
2024-12-29 14:35:17,256 - INFO - Epoch 3/1000, Train Loss: 0.1241, Val Loss: 0.1714
2024-12-29 14:35:17,488 - INFO - Epoch 4/1000, Train Loss: 0.1128, Val Loss: 0.1667
2024-12-29 14:35:17,748 - INFO - Epoch 5/1000, Train Loss: 0.1051, Val Loss: 0.1651
2024-12-29 14:35:17,987 - INFO - Epoch 6/1000, Train Loss: 0.0994, Val Loss: 0.1641
2024-12-29 14:35:18,195 - INFO - Epoch 7/1000, Train Loss: 0.0954, Val Loss: 0.1636
2024-12-29 14:35:18,454 - INFO - Epoch 8/1000, Train Loss: 0.0915, Val Loss: 0.1631
2024-12-29 14:35:18,683 - INFO - Epoch 9/1000, Train Loss: 0.0902, Val Loss: 0.1613
2024-12-29 14:35:18,905 - INFO - Epoch 10/1000, Train Loss: 0.0866, Val Loss: 0.1622
2024-12-29 14:35:19,115 - INFO - Epoch 11/1000, Train Loss: 0.0861, Val Loss: 0.1626
2024-12-29 14:35:19,362 - INFO - Epoch 12/1000, Train Loss: 0.0834, Val Loss: 0.1612
2024-12-29 14:35:19,567 - INFO - Epoch 13/1000, Train Loss: 0.0821, Val Loss: 0.1622
2024-12-29 14:35:19,789 - INFO - Epoch 14/1000, Train Loss: 0.0814, Val Loss: 0.1619
2024-12-29 14:35:19,790 - INFO - Early stopping triggered at epoch 14
2024-12-29 14:35:19,790 - INFO - Training completed in 3.32s
2024-12-29 14:35:19,791 - INFO - Final memory usage: CPU 2766.9 MB, GPU 104.8 MB
2024-12-29 14:35:19,792 - INFO - Model training completed in 3.32s
2024-12-29 14:35:19,846 - INFO - Prediction completed in 0.05s
2024-12-29 14:35:19,855 - INFO - Poison rate 0.01 completed in 3.38s
2024-12-29 14:35:19,855 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:35:19,856 - INFO - Total number of labels flipped: 251
2024-12-29 14:35:19,856 - INFO - Label flipping completed in 0.00s
2024-12-29 14:35:19,856 - INFO - Training set processing completed in 0.00s
2024-12-29 14:35:19,856 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:35:19,857 - INFO - Memory usage at start_fit: CPU 2741.5 MB, GPU 104.7 MB
2024-12-29 14:35:19,857 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:35:19,860 - INFO - Number of unique classes: 10
2024-12-29 14:35:19,944 - INFO - Fitted scaler and transformed data
2024-12-29 14:35:19,944 - INFO - Scaling time: 0.08s
2024-12-29 14:35:20,179 - INFO - Epoch 1/1000, Train Loss: 0.5684, Val Loss: 0.3289
2024-12-29 14:35:20,375 - INFO - Epoch 2/1000, Train Loss: 0.2663, Val Loss: 0.3118
2024-12-29 14:35:20,571 - INFO - Epoch 3/1000, Train Loss: 0.2444, Val Loss: 0.3058
2024-12-29 14:35:20,782 - INFO - Epoch 4/1000, Train Loss: 0.2316, Val Loss: 0.3015
2024-12-29 14:35:20,991 - INFO - Epoch 5/1000, Train Loss: 0.2227, Val Loss: 0.2977
2024-12-29 14:35:21,187 - INFO - Epoch 6/1000, Train Loss: 0.2145, Val Loss: 0.2950
2024-12-29 14:35:21,433 - INFO - Epoch 7/1000, Train Loss: 0.2075, Val Loss: 0.2926
2024-12-29 14:35:21,650 - INFO - Epoch 8/1000, Train Loss: 0.2008, Val Loss: 0.2933
2024-12-29 14:35:21,848 - INFO - Epoch 9/1000, Train Loss: 0.1954, Val Loss: 0.2881
2024-12-29 14:35:22,069 - INFO - Epoch 10/1000, Train Loss: 0.1922, Val Loss: 0.2892
2024-12-29 14:35:22,280 - INFO - Epoch 11/1000, Train Loss: 0.1874, Val Loss: 0.2876
2024-12-29 14:35:22,507 - INFO - Epoch 12/1000, Train Loss: 0.1847, Val Loss: 0.2844
2024-12-29 14:35:22,715 - INFO - Epoch 13/1000, Train Loss: 0.1832, Val Loss: 0.2853
2024-12-29 14:35:22,950 - INFO - Epoch 14/1000, Train Loss: 0.1805, Val Loss: 0.2819
2024-12-29 14:35:23,160 - INFO - Epoch 15/1000, Train Loss: 0.1769, Val Loss: 0.2792
2024-12-29 14:35:23,391 - INFO - Epoch 16/1000, Train Loss: 0.1769, Val Loss: 0.2798
2024-12-29 14:35:23,578 - INFO - Epoch 17/1000, Train Loss: 0.1744, Val Loss: 0.2790
2024-12-29 14:35:23,774 - INFO - Epoch 18/1000, Train Loss: 0.1725, Val Loss: 0.2777
2024-12-29 14:35:23,986 - INFO - Epoch 19/1000, Train Loss: 0.1713, Val Loss: 0.2752
2024-12-29 14:35:24,197 - INFO - Epoch 20/1000, Train Loss: 0.1705, Val Loss: 0.2789
2024-12-29 14:35:24,399 - INFO - Epoch 21/1000, Train Loss: 0.1683, Val Loss: 0.2746
2024-12-29 14:35:24,589 - INFO - Epoch 22/1000, Train Loss: 0.1671, Val Loss: 0.2706
2024-12-29 14:35:24,791 - INFO - Epoch 23/1000, Train Loss: 0.1663, Val Loss: 0.2729
2024-12-29 14:35:25,007 - INFO - Epoch 24/1000, Train Loss: 0.1664, Val Loss: 0.2740
2024-12-29 14:35:25,206 - INFO - Epoch 25/1000, Train Loss: 0.1658, Val Loss: 0.2722
2024-12-29 14:35:25,426 - INFO - Epoch 26/1000, Train Loss: 0.1641, Val Loss: 0.2719
2024-12-29 14:35:25,656 - INFO - Epoch 27/1000, Train Loss: 0.1634, Val Loss: 0.2719
2024-12-29 14:35:25,656 - INFO - Early stopping triggered at epoch 27
2024-12-29 14:35:25,656 - INFO - Training completed in 5.80s
2024-12-29 14:35:25,657 - INFO - Final memory usage: CPU 2767.2 MB, GPU 104.8 MB
2024-12-29 14:35:25,659 - INFO - Model training completed in 5.80s
2024-12-29 14:35:25,719 - INFO - Prediction completed in 0.06s
2024-12-29 14:35:25,727 - INFO - Poison rate 0.03 completed in 5.87s
2024-12-29 14:35:25,728 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:35:25,729 - INFO - Total number of labels flipped: 435
2024-12-29 14:35:25,729 - INFO - Label flipping completed in 0.00s
2024-12-29 14:35:25,729 - INFO - Training set processing completed in 0.00s
2024-12-29 14:35:25,729 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:35:25,730 - INFO - Memory usage at start_fit: CPU 2741.6 MB, GPU 104.7 MB
2024-12-29 14:35:25,730 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:35:25,733 - INFO - Number of unique classes: 10
2024-12-29 14:35:25,803 - INFO - Fitted scaler and transformed data
2024-12-29 14:35:25,803 - INFO - Scaling time: 0.07s
2024-12-29 14:35:26,021 - INFO - Epoch 1/1000, Train Loss: 0.6720, Val Loss: 0.3901
2024-12-29 14:35:26,268 - INFO - Epoch 2/1000, Train Loss: 0.3889, Val Loss: 0.3750
2024-12-29 14:35:26,462 - INFO - Epoch 3/1000, Train Loss: 0.3631, Val Loss: 0.3628
2024-12-29 14:35:26,678 - INFO - Epoch 4/1000, Train Loss: 0.3453, Val Loss: 0.3636
2024-12-29 14:35:26,920 - INFO - Epoch 5/1000, Train Loss: 0.3330, Val Loss: 0.3532
2024-12-29 14:35:27,118 - INFO - Epoch 6/1000, Train Loss: 0.3214, Val Loss: 0.3528
2024-12-29 14:35:27,323 - INFO - Epoch 7/1000, Train Loss: 0.3117, Val Loss: 0.3523
2024-12-29 14:35:27,529 - INFO - Epoch 8/1000, Train Loss: 0.3036, Val Loss: 0.3452
2024-12-29 14:35:27,730 - INFO - Epoch 9/1000, Train Loss: 0.2974, Val Loss: 0.3451
2024-12-29 14:35:27,947 - INFO - Epoch 10/1000, Train Loss: 0.2907, Val Loss: 0.3451
2024-12-29 14:35:28,157 - INFO - Epoch 11/1000, Train Loss: 0.2865, Val Loss: 0.3416
2024-12-29 14:35:28,360 - INFO - Epoch 12/1000, Train Loss: 0.2815, Val Loss: 0.3397
2024-12-29 14:35:28,581 - INFO - Epoch 13/1000, Train Loss: 0.2779, Val Loss: 0.3344
2024-12-29 14:35:28,805 - INFO - Epoch 14/1000, Train Loss: 0.2743, Val Loss: 0.3365
2024-12-29 14:35:29,000 - INFO - Epoch 15/1000, Train Loss: 0.2701, Val Loss: 0.3295
2024-12-29 14:35:29,201 - INFO - Epoch 16/1000, Train Loss: 0.2668, Val Loss: 0.3314
2024-12-29 14:35:29,405 - INFO - Epoch 17/1000, Train Loss: 0.2644, Val Loss: 0.3305
2024-12-29 14:35:29,615 - INFO - Epoch 18/1000, Train Loss: 0.2614, Val Loss: 0.3304
2024-12-29 14:35:29,870 - INFO - Epoch 19/1000, Train Loss: 0.2600, Val Loss: 0.3238
2024-12-29 14:35:30,094 - INFO - Epoch 20/1000, Train Loss: 0.2581, Val Loss: 0.3240
2024-12-29 14:35:30,374 - INFO - Epoch 21/1000, Train Loss: 0.2557, Val Loss: 0.3283
2024-12-29 14:35:30,633 - INFO - Epoch 22/1000, Train Loss: 0.2533, Val Loss: 0.3245
2024-12-29 14:35:30,875 - INFO - Epoch 23/1000, Train Loss: 0.2518, Val Loss: 0.3232
2024-12-29 14:35:31,168 - INFO - Epoch 24/1000, Train Loss: 0.2504, Val Loss: 0.3218
2024-12-29 14:35:31,518 - INFO - Epoch 25/1000, Train Loss: 0.2489, Val Loss: 0.3198
2024-12-29 14:35:31,742 - INFO - Epoch 26/1000, Train Loss: 0.2484, Val Loss: 0.3190
2024-12-29 14:35:31,960 - INFO - Epoch 27/1000, Train Loss: 0.2456, Val Loss: 0.3164
2024-12-29 14:35:32,153 - INFO - Epoch 28/1000, Train Loss: 0.2440, Val Loss: 0.3220
2024-12-29 14:35:32,355 - INFO - Epoch 29/1000, Train Loss: 0.2433, Val Loss: 0.3184
2024-12-29 14:35:32,557 - INFO - Epoch 30/1000, Train Loss: 0.2428, Val Loss: 0.3177
2024-12-29 14:35:32,774 - INFO - Epoch 31/1000, Train Loss: 0.2426, Val Loss: 0.3216
2024-12-29 14:35:33,039 - INFO - Epoch 32/1000, Train Loss: 0.2427, Val Loss: 0.3111
2024-12-29 14:35:33,248 - INFO - Epoch 33/1000, Train Loss: 0.2406, Val Loss: 0.3139
2024-12-29 14:35:33,457 - INFO - Epoch 34/1000, Train Loss: 0.2389, Val Loss: 0.3150
2024-12-29 14:35:33,672 - INFO - Epoch 35/1000, Train Loss: 0.2387, Val Loss: 0.3132
2024-12-29 14:35:33,875 - INFO - Epoch 36/1000, Train Loss: 0.2360, Val Loss: 0.3121
2024-12-29 14:35:34,111 - INFO - Epoch 37/1000, Train Loss: 0.2378, Val Loss: 0.3127
2024-12-29 14:35:34,112 - INFO - Early stopping triggered at epoch 37
2024-12-29 14:35:34,112 - INFO - Training completed in 8.38s
2024-12-29 14:35:34,112 - INFO - Final memory usage: CPU 2767.3 MB, GPU 104.8 MB
2024-12-29 14:35:34,113 - INFO - Model training completed in 8.38s
2024-12-29 14:35:34,177 - INFO - Prediction completed in 0.06s
2024-12-29 14:35:34,186 - INFO - Poison rate 0.05 completed in 8.46s
2024-12-29 14:35:34,186 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:35:34,187 - INFO - Total number of labels flipped: 581
2024-12-29 14:35:34,187 - INFO - Label flipping completed in 0.00s
2024-12-29 14:35:34,188 - INFO - Training set processing completed in 0.00s
2024-12-29 14:35:34,188 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:35:34,188 - INFO - Memory usage at start_fit: CPU 2741.5 MB, GPU 104.7 MB
2024-12-29 14:35:34,189 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:35:34,193 - INFO - Number of unique classes: 10
2024-12-29 14:35:34,265 - INFO - Fitted scaler and transformed data
2024-12-29 14:35:34,265 - INFO - Scaling time: 0.07s
2024-12-29 14:35:34,491 - INFO - Epoch 1/1000, Train Loss: 0.7624, Val Loss: 0.5348
2024-12-29 14:35:34,739 - INFO - Epoch 2/1000, Train Loss: 0.4612, Val Loss: 0.5192
2024-12-29 14:35:35,028 - INFO - Epoch 3/1000, Train Loss: 0.4335, Val Loss: 0.5139
2024-12-29 14:35:35,238 - INFO - Epoch 4/1000, Train Loss: 0.4137, Val Loss: 0.5042
2024-12-29 14:35:35,445 - INFO - Epoch 5/1000, Train Loss: 0.3976, Val Loss: 0.4997
2024-12-29 14:35:35,640 - INFO - Epoch 6/1000, Train Loss: 0.3861, Val Loss: 0.4934
2024-12-29 14:35:35,837 - INFO - Epoch 7/1000, Train Loss: 0.3731, Val Loss: 0.4925
2024-12-29 14:35:36,057 - INFO - Epoch 8/1000, Train Loss: 0.3637, Val Loss: 0.4892
2024-12-29 14:35:36,290 - INFO - Epoch 9/1000, Train Loss: 0.3553, Val Loss: 0.4847
2024-12-29 14:35:36,484 - INFO - Epoch 10/1000, Train Loss: 0.3483, Val Loss: 0.4816
2024-12-29 14:35:36,690 - INFO - Epoch 11/1000, Train Loss: 0.3408, Val Loss: 0.4768
2024-12-29 14:35:36,911 - INFO - Epoch 12/1000, Train Loss: 0.3355, Val Loss: 0.4760
2024-12-29 14:35:37,144 - INFO - Epoch 13/1000, Train Loss: 0.3306, Val Loss: 0.4714
2024-12-29 14:35:37,385 - INFO - Epoch 14/1000, Train Loss: 0.3256, Val Loss: 0.4699
2024-12-29 14:35:37,587 - INFO - Epoch 15/1000, Train Loss: 0.3212, Val Loss: 0.4665
2024-12-29 14:35:37,837 - INFO - Epoch 16/1000, Train Loss: 0.3177, Val Loss: 0.4647
2024-12-29 14:35:38,071 - INFO - Epoch 17/1000, Train Loss: 0.3146, Val Loss: 0.4586
2024-12-29 14:35:38,284 - INFO - Epoch 18/1000, Train Loss: 0.3097, Val Loss: 0.4589
2024-12-29 14:35:38,485 - INFO - Epoch 19/1000, Train Loss: 0.3067, Val Loss: 0.4577
2024-12-29 14:35:38,687 - INFO - Epoch 20/1000, Train Loss: 0.3046, Val Loss: 0.4549
2024-12-29 14:35:38,894 - INFO - Epoch 21/1000, Train Loss: 0.3008, Val Loss: 0.4522
2024-12-29 14:35:39,089 - INFO - Epoch 22/1000, Train Loss: 0.2993, Val Loss: 0.4508
2024-12-29 14:35:39,298 - INFO - Epoch 23/1000, Train Loss: 0.2980, Val Loss: 0.4465
2024-12-29 14:35:39,495 - INFO - Epoch 24/1000, Train Loss: 0.2944, Val Loss: 0.4452
2024-12-29 14:35:39,702 - INFO - Epoch 25/1000, Train Loss: 0.2931, Val Loss: 0.4429
2024-12-29 14:35:39,917 - INFO - Epoch 26/1000, Train Loss: 0.2930, Val Loss: 0.4409
2024-12-29 14:35:40,132 - INFO - Epoch 27/1000, Train Loss: 0.2894, Val Loss: 0.4390
2024-12-29 14:35:40,348 - INFO - Epoch 28/1000, Train Loss: 0.2878, Val Loss: 0.4396
2024-12-29 14:35:40,551 - INFO - Epoch 29/1000, Train Loss: 0.2858, Val Loss: 0.4377
2024-12-29 14:35:40,755 - INFO - Epoch 30/1000, Train Loss: 0.2831, Val Loss: 0.4410
2024-12-29 14:35:40,955 - INFO - Epoch 31/1000, Train Loss: 0.2842, Val Loss: 0.4335
2024-12-29 14:35:41,169 - INFO - Epoch 32/1000, Train Loss: 0.2825, Val Loss: 0.4371
2024-12-29 14:35:41,374 - INFO - Epoch 33/1000, Train Loss: 0.2820, Val Loss: 0.4313
2024-12-29 14:35:41,585 - INFO - Epoch 34/1000, Train Loss: 0.2799, Val Loss: 0.4324
2024-12-29 14:35:41,787 - INFO - Epoch 35/1000, Train Loss: 0.2802, Val Loss: 0.4336
2024-12-29 14:35:41,980 - INFO - Epoch 36/1000, Train Loss: 0.2780, Val Loss: 0.4294
2024-12-29 14:35:42,175 - INFO - Epoch 37/1000, Train Loss: 0.2767, Val Loss: 0.4284
2024-12-29 14:35:42,382 - INFO - Epoch 38/1000, Train Loss: 0.2747, Val Loss: 0.4289
2024-12-29 14:35:42,593 - INFO - Epoch 39/1000, Train Loss: 0.2749, Val Loss: 0.4277
2024-12-29 14:35:42,791 - INFO - Epoch 40/1000, Train Loss: 0.2732, Val Loss: 0.4254
2024-12-29 14:35:43,015 - INFO - Epoch 41/1000, Train Loss: 0.2737, Val Loss: 0.4291
2024-12-29 14:35:43,211 - INFO - Epoch 42/1000, Train Loss: 0.2727, Val Loss: 0.4259
2024-12-29 14:35:43,429 - INFO - Epoch 43/1000, Train Loss: 0.2717, Val Loss: 0.4271
2024-12-29 14:35:43,622 - INFO - Epoch 44/1000, Train Loss: 0.2715, Val Loss: 0.4253
2024-12-29 14:35:43,814 - INFO - Epoch 45/1000, Train Loss: 0.2703, Val Loss: 0.4235
2024-12-29 14:35:44,016 - INFO - Epoch 46/1000, Train Loss: 0.2689, Val Loss: 0.4238
2024-12-29 14:35:44,213 - INFO - Epoch 47/1000, Train Loss: 0.2724, Val Loss: 0.4266
2024-12-29 14:35:44,441 - INFO - Epoch 48/1000, Train Loss: 0.2681, Val Loss: 0.4227
2024-12-29 14:35:44,666 - INFO - Epoch 49/1000, Train Loss: 0.2685, Val Loss: 0.4211
2024-12-29 14:35:44,879 - INFO - Epoch 50/1000, Train Loss: 0.2681, Val Loss: 0.4193
2024-12-29 14:35:45,085 - INFO - Epoch 51/1000, Train Loss: 0.2669, Val Loss: 0.4187
2024-12-29 14:35:45,317 - INFO - Epoch 52/1000, Train Loss: 0.2682, Val Loss: 0.4196
2024-12-29 14:35:45,530 - INFO - Epoch 53/1000, Train Loss: 0.2675, Val Loss: 0.4250
2024-12-29 14:35:45,757 - INFO - Epoch 54/1000, Train Loss: 0.2664, Val Loss: 0.4171
2024-12-29 14:35:45,989 - INFO - Epoch 55/1000, Train Loss: 0.2656, Val Loss: 0.4181
2024-12-29 14:35:46,212 - INFO - Epoch 56/1000, Train Loss: 0.2665, Val Loss: 0.4169
2024-12-29 14:35:46,460 - INFO - Epoch 57/1000, Train Loss: 0.2663, Val Loss: 0.4161
2024-12-29 14:35:46,678 - INFO - Epoch 58/1000, Train Loss: 0.2654, Val Loss: 0.4179
2024-12-29 14:35:46,887 - INFO - Epoch 59/1000, Train Loss: 0.2645, Val Loss: 0.4173
2024-12-29 14:35:47,135 - INFO - Epoch 60/1000, Train Loss: 0.2666, Val Loss: 0.4169
2024-12-29 14:35:47,329 - INFO - Epoch 61/1000, Train Loss: 0.2645, Val Loss: 0.4173
2024-12-29 14:35:47,528 - INFO - Epoch 62/1000, Train Loss: 0.2637, Val Loss: 0.4167
2024-12-29 14:35:47,528 - INFO - Early stopping triggered at epoch 62
2024-12-29 14:35:47,529 - INFO - Training completed in 13.34s
2024-12-29 14:35:47,529 - INFO - Final memory usage: CPU 2767.3 MB, GPU 104.8 MB
2024-12-29 14:35:47,532 - INFO - Model training completed in 13.34s
2024-12-29 14:35:47,592 - INFO - Prediction completed in 0.06s
2024-12-29 14:35:47,601 - INFO - Poison rate 0.07 completed in 13.41s
2024-12-29 14:35:47,601 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:35:47,602 - INFO - Total number of labels flipped: 840
2024-12-29 14:35:47,603 - INFO - Label flipping completed in 0.00s
2024-12-29 14:35:47,603 - INFO - Training set processing completed in 0.00s
2024-12-29 14:35:47,603 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:35:47,604 - INFO - Memory usage at start_fit: CPU 2741.6 MB, GPU 104.7 MB
2024-12-29 14:35:47,604 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:35:47,608 - INFO - Number of unique classes: 10
2024-12-29 14:35:47,686 - INFO - Fitted scaler and transformed data
2024-12-29 14:35:47,686 - INFO - Scaling time: 0.08s
2024-12-29 14:35:47,898 - INFO - Epoch 1/1000, Train Loss: 0.8670, Val Loss: 0.6731
2024-12-29 14:35:48,142 - INFO - Epoch 2/1000, Train Loss: 0.5933, Val Loss: 0.6539
2024-12-29 14:35:48,350 - INFO - Epoch 3/1000, Train Loss: 0.5586, Val Loss: 0.6450
2024-12-29 14:35:48,541 - INFO - Epoch 4/1000, Train Loss: 0.5359, Val Loss: 0.6431
2024-12-29 14:35:48,754 - INFO - Epoch 5/1000, Train Loss: 0.5150, Val Loss: 0.6295
2024-12-29 14:35:48,995 - INFO - Epoch 6/1000, Train Loss: 0.5014, Val Loss: 0.6262
2024-12-29 14:35:49,198 - INFO - Epoch 7/1000, Train Loss: 0.4844, Val Loss: 0.6206
2024-12-29 14:35:49,385 - INFO - Epoch 8/1000, Train Loss: 0.4722, Val Loss: 0.6122
2024-12-29 14:35:49,614 - INFO - Epoch 9/1000, Train Loss: 0.4621, Val Loss: 0.6067
2024-12-29 14:35:49,833 - INFO - Epoch 10/1000, Train Loss: 0.4525, Val Loss: 0.6001
2024-12-29 14:35:50,037 - INFO - Epoch 11/1000, Train Loss: 0.4447, Val Loss: 0.5940
2024-12-29 14:35:50,230 - INFO - Epoch 12/1000, Train Loss: 0.4393, Val Loss: 0.5880
2024-12-29 14:35:50,427 - INFO - Epoch 13/1000, Train Loss: 0.4293, Val Loss: 0.5826
2024-12-29 14:35:50,630 - INFO - Epoch 14/1000, Train Loss: 0.4204, Val Loss: 0.5746
2024-12-29 14:35:50,813 - INFO - Epoch 15/1000, Train Loss: 0.4155, Val Loss: 0.5680
2024-12-29 14:35:51,000 - INFO - Epoch 16/1000, Train Loss: 0.4106, Val Loss: 0.5729
2024-12-29 14:35:51,195 - INFO - Epoch 17/1000, Train Loss: 0.4058, Val Loss: 0.5672
2024-12-29 14:35:51,400 - INFO - Epoch 18/1000, Train Loss: 0.3994, Val Loss: 0.5572
2024-12-29 14:35:51,620 - INFO - Epoch 19/1000, Train Loss: 0.3960, Val Loss: 0.5563
2024-12-29 14:35:51,842 - INFO - Epoch 20/1000, Train Loss: 0.3914, Val Loss: 0.5512
2024-12-29 14:35:52,054 - INFO - Epoch 21/1000, Train Loss: 0.3864, Val Loss: 0.5464
2024-12-29 14:35:52,301 - INFO - Epoch 22/1000, Train Loss: 0.3834, Val Loss: 0.5436
2024-12-29 14:35:52,521 - INFO - Epoch 23/1000, Train Loss: 0.3799, Val Loss: 0.5384
2024-12-29 14:35:52,747 - INFO - Epoch 24/1000, Train Loss: 0.3777, Val Loss: 0.5434
2024-12-29 14:35:52,963 - INFO - Epoch 25/1000, Train Loss: 0.3747, Val Loss: 0.5360
2024-12-29 14:35:53,155 - INFO - Epoch 26/1000, Train Loss: 0.3721, Val Loss: 0.5334
2024-12-29 14:35:53,362 - INFO - Epoch 27/1000, Train Loss: 0.3692, Val Loss: 0.5243
2024-12-29 14:35:53,556 - INFO - Epoch 28/1000, Train Loss: 0.3677, Val Loss: 0.5323
2024-12-29 14:35:53,768 - INFO - Epoch 29/1000, Train Loss: 0.3650, Val Loss: 0.5259
2024-12-29 14:35:53,985 - INFO - Epoch 30/1000, Train Loss: 0.3612, Val Loss: 0.5229
2024-12-29 14:35:54,189 - INFO - Epoch 31/1000, Train Loss: 0.3616, Val Loss: 0.5246
2024-12-29 14:35:54,399 - INFO - Epoch 32/1000, Train Loss: 0.3603, Val Loss: 0.5243
2024-12-29 14:35:54,598 - INFO - Epoch 33/1000, Train Loss: 0.3561, Val Loss: 0.5111
2024-12-29 14:35:54,798 - INFO - Epoch 34/1000, Train Loss: 0.3546, Val Loss: 0.5137
2024-12-29 14:35:55,023 - INFO - Epoch 35/1000, Train Loss: 0.3531, Val Loss: 0.5140
2024-12-29 14:35:55,228 - INFO - Epoch 36/1000, Train Loss: 0.3519, Val Loss: 0.5166
2024-12-29 14:35:55,429 - INFO - Epoch 37/1000, Train Loss: 0.3505, Val Loss: 0.5167
2024-12-29 14:35:55,639 - INFO - Epoch 38/1000, Train Loss: 0.3495, Val Loss: 0.5146
2024-12-29 14:35:55,639 - INFO - Early stopping triggered at epoch 38
2024-12-29 14:35:55,639 - INFO - Training completed in 8.04s
2024-12-29 14:35:55,639 - INFO - Final memory usage: CPU 2767.2 MB, GPU 104.8 MB
2024-12-29 14:35:55,640 - INFO - Model training completed in 8.04s
2024-12-29 14:35:55,729 - INFO - Prediction completed in 0.09s
2024-12-29 14:35:55,737 - INFO - Poison rate 0.1 completed in 8.14s
2024-12-29 14:35:55,738 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:35:55,739 - INFO - Total number of labels flipped: 1718
2024-12-29 14:35:55,739 - INFO - Label flipping completed in 0.00s
2024-12-29 14:35:55,739 - INFO - Training set processing completed in 0.00s
2024-12-29 14:35:55,739 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:35:55,740 - INFO - Memory usage at start_fit: CPU 2741.7 MB, GPU 104.7 MB
2024-12-29 14:35:55,740 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:35:55,744 - INFO - Number of unique classes: 10
2024-12-29 14:35:55,814 - INFO - Fitted scaler and transformed data
2024-12-29 14:35:55,815 - INFO - Scaling time: 0.07s
2024-12-29 14:35:56,042 - INFO - Epoch 1/1000, Train Loss: 1.1848, Val Loss: 1.0593
2024-12-29 14:35:56,259 - INFO - Epoch 2/1000, Train Loss: 0.9515, Val Loss: 1.0183
2024-12-29 14:35:56,468 - INFO - Epoch 3/1000, Train Loss: 0.9013, Val Loss: 0.9990
2024-12-29 14:35:56,708 - INFO - Epoch 4/1000, Train Loss: 0.8676, Val Loss: 0.9804
2024-12-29 14:35:56,910 - INFO - Epoch 5/1000, Train Loss: 0.8360, Val Loss: 0.9611
2024-12-29 14:35:57,153 - INFO - Epoch 6/1000, Train Loss: 0.8098, Val Loss: 0.9363
2024-12-29 14:35:57,344 - INFO - Epoch 7/1000, Train Loss: 0.7841, Val Loss: 0.9324
2024-12-29 14:35:57,536 - INFO - Epoch 8/1000, Train Loss: 0.7654, Val Loss: 0.9105
2024-12-29 14:35:57,731 - INFO - Epoch 9/1000, Train Loss: 0.7456, Val Loss: 0.8957
2024-12-29 14:35:57,939 - INFO - Epoch 10/1000, Train Loss: 0.7273, Val Loss: 0.8797
2024-12-29 14:35:58,156 - INFO - Epoch 11/1000, Train Loss: 0.7119, Val Loss: 0.8738
2024-12-29 14:35:58,356 - INFO - Epoch 12/1000, Train Loss: 0.6984, Val Loss: 0.8488
2024-12-29 14:35:58,581 - INFO - Epoch 13/1000, Train Loss: 0.6834, Val Loss: 0.8415
2024-12-29 14:35:58,787 - INFO - Epoch 14/1000, Train Loss: 0.6706, Val Loss: 0.8376
2024-12-29 14:35:58,985 - INFO - Epoch 15/1000, Train Loss: 0.6610, Val Loss: 0.8256
2024-12-29 14:35:59,191 - INFO - Epoch 16/1000, Train Loss: 0.6476, Val Loss: 0.8171
2024-12-29 14:35:59,401 - INFO - Epoch 17/1000, Train Loss: 0.6371, Val Loss: 0.8015
2024-12-29 14:35:59,609 - INFO - Epoch 18/1000, Train Loss: 0.6278, Val Loss: 0.7954
2024-12-29 14:35:59,814 - INFO - Epoch 19/1000, Train Loss: 0.6205, Val Loss: 0.7843
2024-12-29 14:36:00,034 - INFO - Epoch 20/1000, Train Loss: 0.6127, Val Loss: 0.7804
2024-12-29 14:36:00,245 - INFO - Epoch 21/1000, Train Loss: 0.6046, Val Loss: 0.7791
2024-12-29 14:36:00,447 - INFO - Epoch 22/1000, Train Loss: 0.5994, Val Loss: 0.7698
2024-12-29 14:36:00,650 - INFO - Epoch 23/1000, Train Loss: 0.5918, Val Loss: 0.7618
2024-12-29 14:36:00,860 - INFO - Epoch 24/1000, Train Loss: 0.5863, Val Loss: 0.7628
2024-12-29 14:36:01,078 - INFO - Epoch 25/1000, Train Loss: 0.5804, Val Loss: 0.7495
2024-12-29 14:36:01,313 - INFO - Epoch 26/1000, Train Loss: 0.5753, Val Loss: 0.7527
2024-12-29 14:36:01,510 - INFO - Epoch 27/1000, Train Loss: 0.5713, Val Loss: 0.7473
2024-12-29 14:36:01,711 - INFO - Epoch 28/1000, Train Loss: 0.5654, Val Loss: 0.7368
2024-12-29 14:36:01,916 - INFO - Epoch 29/1000, Train Loss: 0.5614, Val Loss: 0.7337
2024-12-29 14:36:02,116 - INFO - Epoch 30/1000, Train Loss: 0.5569, Val Loss: 0.7370
2024-12-29 14:36:02,328 - INFO - Epoch 31/1000, Train Loss: 0.5542, Val Loss: 0.7328
2024-12-29 14:36:02,553 - INFO - Epoch 32/1000, Train Loss: 0.5483, Val Loss: 0.7331
2024-12-29 14:36:02,749 - INFO - Epoch 33/1000, Train Loss: 0.5470, Val Loss: 0.7216
2024-12-29 14:36:02,952 - INFO - Epoch 34/1000, Train Loss: 0.5430, Val Loss: 0.7238
2024-12-29 14:36:03,171 - INFO - Epoch 35/1000, Train Loss: 0.5422, Val Loss: 0.7252
2024-12-29 14:36:03,397 - INFO - Epoch 36/1000, Train Loss: 0.5373, Val Loss: 0.7116
2024-12-29 14:36:03,599 - INFO - Epoch 37/1000, Train Loss: 0.5361, Val Loss: 0.7161
2024-12-29 14:36:03,806 - INFO - Epoch 38/1000, Train Loss: 0.5313, Val Loss: 0.7122
2024-12-29 14:36:04,016 - INFO - Epoch 39/1000, Train Loss: 0.5317, Val Loss: 0.7097
2024-12-29 14:36:04,231 - INFO - Epoch 40/1000, Train Loss: 0.5294, Val Loss: 0.7141
2024-12-29 14:36:04,441 - INFO - Epoch 41/1000, Train Loss: 0.5263, Val Loss: 0.7048
2024-12-29 14:36:04,619 - INFO - Epoch 42/1000, Train Loss: 0.5244, Val Loss: 0.7128
2024-12-29 14:36:04,824 - INFO - Epoch 43/1000, Train Loss: 0.5235, Val Loss: 0.7108
2024-12-29 14:36:05,069 - INFO - Epoch 44/1000, Train Loss: 0.5216, Val Loss: 0.7068
2024-12-29 14:36:05,294 - INFO - Epoch 45/1000, Train Loss: 0.5189, Val Loss: 0.6980
2024-12-29 14:36:05,486 - INFO - Epoch 46/1000, Train Loss: 0.5192, Val Loss: 0.6997
2024-12-29 14:36:05,677 - INFO - Epoch 47/1000, Train Loss: 0.5168, Val Loss: 0.6970
2024-12-29 14:36:05,877 - INFO - Epoch 48/1000, Train Loss: 0.5147, Val Loss: 0.6952
2024-12-29 14:36:06,097 - INFO - Epoch 49/1000, Train Loss: 0.5137, Val Loss: 0.7007
2024-12-29 14:36:06,296 - INFO - Epoch 50/1000, Train Loss: 0.5116, Val Loss: 0.7050
2024-12-29 14:36:06,504 - INFO - Epoch 51/1000, Train Loss: 0.5116, Val Loss: 0.6977
2024-12-29 14:36:06,726 - INFO - Epoch 52/1000, Train Loss: 0.5110, Val Loss: 0.6910
2024-12-29 14:36:06,923 - INFO - Epoch 53/1000, Train Loss: 0.5117, Val Loss: 0.6925
2024-12-29 14:36:07,120 - INFO - Epoch 54/1000, Train Loss: 0.5068, Val Loss: 0.6952
2024-12-29 14:36:07,340 - INFO - Epoch 55/1000, Train Loss: 0.5075, Val Loss: 0.6980
2024-12-29 14:36:07,558 - INFO - Epoch 56/1000, Train Loss: 0.5074, Val Loss: 0.6868
2024-12-29 14:36:07,747 - INFO - Epoch 57/1000, Train Loss: 0.5054, Val Loss: 0.6957
2024-12-29 14:36:07,961 - INFO - Epoch 58/1000, Train Loss: 0.5042, Val Loss: 0.6912
2024-12-29 14:36:08,176 - INFO - Epoch 59/1000, Train Loss: 0.5040, Val Loss: 0.6879
2024-12-29 14:36:08,423 - INFO - Epoch 60/1000, Train Loss: 0.5032, Val Loss: 0.6931
2024-12-29 14:36:08,677 - INFO - Epoch 61/1000, Train Loss: 0.5007, Val Loss: 0.6891
2024-12-29 14:36:08,678 - INFO - Early stopping triggered at epoch 61
2024-12-29 14:36:08,678 - INFO - Training completed in 12.94s
2024-12-29 14:36:08,679 - INFO - Final memory usage: CPU 2767.3 MB, GPU 104.8 MB
2024-12-29 14:36:08,681 - INFO - Model training completed in 12.94s
2024-12-29 14:36:08,739 - INFO - Prediction completed in 0.06s
2024-12-29 14:36:08,747 - INFO - Poison rate 0.2 completed in 13.01s
2024-12-29 14:36:08,757 - INFO - Loaded 518 existing results
2024-12-29 14:36:08,758 - INFO - Total results to save: 525
2024-12-29 14:36:08,759 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:36:08,775 - INFO - Saved 525 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:36:08,776 - INFO - Total evaluation time: 88.13s
2024-12-29 14:36:08,778 - INFO - 
Progress: 79.2% - Evaluating CIFAR100 with LogisticRegression (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:36:08,972 - INFO - Loading datasets...
2024-12-29 14:36:08,993 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:36:08,994 - INFO - Extracting validation features...
2024-12-29 14:36:08,994 - INFO - Extracting features from 3925 samples...
2024-12-29 14:36:18,457 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:36:18,460 - INFO - Validation feature extraction completed in 9.47s
2024-12-29 14:36:18,460 - INFO - Extracting training features...
2024-12-29 14:36:18,461 - INFO - Extracting features from 9469 samples...
2024-12-29 14:36:40,388 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:36:40,395 - INFO - Training feature extraction completed in 21.93s
2024-12-29 14:36:40,395 - INFO - Creating model for classifier: LogisticRegression
2024-12-29 14:36:40,395 - INFO - Using device: cuda
2024-12-29 14:36:40,395 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:36:40,395 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:36:40,395 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:36:40,928 - INFO - Feature scaling completed in 0.53s
2024-12-29 14:36:40,928 - INFO - Starting feature selection (k=50)
2024-12-29 14:36:40,940 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:36:40,940 - INFO - Starting anomaly detection
2024-12-29 14:36:44,742 - INFO - Anomaly detection completed in 3.80s
2024-12-29 14:36:44,742 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:36:44,742 - INFO - Total fit_transform time: 4.35s
2024-12-29 14:36:44,742 - INFO - Training set processing completed in 4.35s
2024-12-29 14:36:44,742 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:36:44,744 - INFO - Memory usage at start_fit: CPU 2761.9 MB, GPU 104.0 MB
2024-12-29 14:36:44,745 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:36:44,748 - INFO - Number of unique classes: 10
2024-12-29 14:36:44,824 - INFO - Fitted scaler and transformed data
2024-12-29 14:36:44,824 - INFO - Scaling time: 0.07s
2024-12-29 14:36:45,046 - INFO - Epoch 1/1000, Train Loss: 0.4649, Val Loss: 0.1170
2024-12-29 14:36:45,253 - INFO - Epoch 2/1000, Train Loss: 0.0927, Val Loss: 0.0801
2024-12-29 14:36:45,448 - INFO - Epoch 3/1000, Train Loss: 0.0669, Val Loss: 0.0664
2024-12-29 14:36:45,634 - INFO - Epoch 4/1000, Train Loss: 0.0543, Val Loss: 0.0594
2024-12-29 14:36:45,824 - INFO - Epoch 5/1000, Train Loss: 0.0467, Val Loss: 0.0555
2024-12-29 14:36:46,027 - INFO - Epoch 6/1000, Train Loss: 0.0419, Val Loss: 0.0530
2024-12-29 14:36:46,210 - INFO - Epoch 7/1000, Train Loss: 0.0387, Val Loss: 0.0516
2024-12-29 14:36:46,401 - INFO - Epoch 8/1000, Train Loss: 0.0362, Val Loss: 0.0505
2024-12-29 14:36:46,607 - INFO - Epoch 9/1000, Train Loss: 0.0343, Val Loss: 0.0497
2024-12-29 14:36:46,818 - INFO - Epoch 10/1000, Train Loss: 0.0332, Val Loss: 0.0494
2024-12-29 14:36:47,034 - INFO - Epoch 11/1000, Train Loss: 0.0319, Val Loss: 0.0487
2024-12-29 14:36:47,227 - INFO - Epoch 12/1000, Train Loss: 0.0311, Val Loss: 0.0487
2024-12-29 14:36:47,407 - INFO - Epoch 13/1000, Train Loss: 0.0309, Val Loss: 0.0490
2024-12-29 14:36:47,591 - INFO - Epoch 14/1000, Train Loss: 0.0300, Val Loss: 0.0487
2024-12-29 14:36:47,774 - INFO - Epoch 15/1000, Train Loss: 0.0297, Val Loss: 0.0481
2024-12-29 14:36:47,986 - INFO - Epoch 16/1000, Train Loss: 0.0295, Val Loss: 0.0480
2024-12-29 14:36:48,190 - INFO - Epoch 17/1000, Train Loss: 0.0291, Val Loss: 0.0480
2024-12-29 14:36:48,391 - INFO - Epoch 18/1000, Train Loss: 0.0290, Val Loss: 0.0479
2024-12-29 14:36:48,587 - INFO - Epoch 19/1000, Train Loss: 0.0286, Val Loss: 0.0486
2024-12-29 14:36:48,789 - INFO - Epoch 20/1000, Train Loss: 0.0288, Val Loss: 0.0478
2024-12-29 14:36:48,790 - INFO - Early stopping triggered at epoch 20
2024-12-29 14:36:48,790 - INFO - Training completed in 4.05s
2024-12-29 14:36:48,790 - INFO - Final memory usage: CPU 2771.2 MB, GPU 104.2 MB
2024-12-29 14:36:48,791 - INFO - Model training completed in 4.05s
2024-12-29 14:36:48,889 - INFO - Prediction completed in 0.10s
2024-12-29 14:36:48,905 - INFO - Poison rate 0.0 completed in 8.51s
2024-12-29 14:36:48,905 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:36:48,906 - INFO - Total number of labels flipped: 84
2024-12-29 14:36:48,906 - INFO - Label flipping completed in 0.00s
2024-12-29 14:36:48,906 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:36:48,906 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:36:49,425 - INFO - Feature scaling completed in 0.52s
2024-12-29 14:36:49,425 - INFO - Starting feature selection (k=50)
2024-12-29 14:36:49,439 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:36:49,440 - INFO - Starting anomaly detection
2024-12-29 14:36:53,263 - INFO - Anomaly detection completed in 3.82s
2024-12-29 14:36:53,264 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:36:53,264 - INFO - Total fit_transform time: 4.36s
2024-12-29 14:36:53,264 - INFO - Training set processing completed in 4.36s
2024-12-29 14:36:53,264 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:36:53,265 - INFO - Memory usage at start_fit: CPU 2761.8 MB, GPU 104.1 MB
2024-12-29 14:36:53,265 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:36:53,268 - INFO - Number of unique classes: 10
2024-12-29 14:36:53,340 - INFO - Fitted scaler and transformed data
2024-12-29 14:36:53,340 - INFO - Scaling time: 0.07s
2024-12-29 14:36:53,550 - INFO - Epoch 1/1000, Train Loss: 0.5174, Val Loss: 0.2263
2024-12-29 14:36:53,797 - INFO - Epoch 2/1000, Train Loss: 0.1523, Val Loss: 0.2085
2024-12-29 14:36:54,104 - INFO - Epoch 3/1000, Train Loss: 0.1291, Val Loss: 0.2033
2024-12-29 14:36:54,324 - INFO - Epoch 4/1000, Train Loss: 0.1169, Val Loss: 0.2016
2024-12-29 14:36:54,507 - INFO - Epoch 5/1000, Train Loss: 0.1103, Val Loss: 0.1995
2024-12-29 14:36:54,697 - INFO - Epoch 6/1000, Train Loss: 0.1030, Val Loss: 0.1979
2024-12-29 14:36:54,891 - INFO - Epoch 7/1000, Train Loss: 0.0978, Val Loss: 0.1976
2024-12-29 14:36:55,088 - INFO - Epoch 8/1000, Train Loss: 0.0951, Val Loss: 0.1975
2024-12-29 14:36:55,288 - INFO - Epoch 9/1000, Train Loss: 0.0912, Val Loss: 0.1972
2024-12-29 14:36:55,489 - INFO - Epoch 10/1000, Train Loss: 0.0893, Val Loss: 0.1961
2024-12-29 14:36:55,696 - INFO - Epoch 11/1000, Train Loss: 0.0867, Val Loss: 0.1956
2024-12-29 14:36:55,910 - INFO - Epoch 12/1000, Train Loss: 0.0849, Val Loss: 0.1964
2024-12-29 14:36:56,156 - INFO - Epoch 13/1000, Train Loss: 0.0845, Val Loss: 0.1945
2024-12-29 14:36:56,348 - INFO - Epoch 14/1000, Train Loss: 0.0830, Val Loss: 0.1964
2024-12-29 14:36:56,550 - INFO - Epoch 15/1000, Train Loss: 0.0812, Val Loss: 0.1948
2024-12-29 14:36:56,758 - INFO - Epoch 16/1000, Train Loss: 0.0811, Val Loss: 0.1955
2024-12-29 14:36:56,979 - INFO - Epoch 17/1000, Train Loss: 0.0809, Val Loss: 0.1957
2024-12-29 14:36:57,184 - INFO - Epoch 18/1000, Train Loss: 0.0793, Val Loss: 0.1943
2024-12-29 14:36:57,185 - INFO - Early stopping triggered at epoch 18
2024-12-29 14:36:57,185 - INFO - Training completed in 3.92s
2024-12-29 14:36:57,186 - INFO - Final memory usage: CPU 2771.2 MB, GPU 104.2 MB
2024-12-29 14:36:57,188 - INFO - Model training completed in 3.92s
2024-12-29 14:36:57,265 - INFO - Prediction completed in 0.08s
2024-12-29 14:36:57,273 - INFO - Poison rate 0.01 completed in 8.37s
2024-12-29 14:36:57,273 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:36:57,274 - INFO - Total number of labels flipped: 254
2024-12-29 14:36:57,275 - INFO - Label flipping completed in 0.00s
2024-12-29 14:36:57,275 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:36:57,275 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:36:57,779 - INFO - Feature scaling completed in 0.50s
2024-12-29 14:36:57,779 - INFO - Starting feature selection (k=50)
2024-12-29 14:36:57,793 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:36:57,794 - INFO - Starting anomaly detection
2024-12-29 14:37:01,585 - INFO - Anomaly detection completed in 3.79s
2024-12-29 14:37:01,585 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:37:01,585 - INFO - Total fit_transform time: 4.31s
2024-12-29 14:37:01,585 - INFO - Training set processing completed in 4.31s
2024-12-29 14:37:01,586 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:37:01,587 - INFO - Memory usage at start_fit: CPU 2761.6 MB, GPU 104.1 MB
2024-12-29 14:37:01,587 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:37:01,589 - INFO - Number of unique classes: 10
2024-12-29 14:37:01,672 - INFO - Fitted scaler and transformed data
2024-12-29 14:37:01,672 - INFO - Scaling time: 0.08s
2024-12-29 14:37:01,994 - INFO - Epoch 1/1000, Train Loss: 0.6249, Val Loss: 0.3598
2024-12-29 14:37:02,300 - INFO - Epoch 2/1000, Train Loss: 0.2665, Val Loss: 0.3355
2024-12-29 14:37:02,510 - INFO - Epoch 3/1000, Train Loss: 0.2451, Val Loss: 0.3232
2024-12-29 14:37:02,840 - INFO - Epoch 4/1000, Train Loss: 0.2296, Val Loss: 0.3182
2024-12-29 14:37:03,149 - INFO - Epoch 5/1000, Train Loss: 0.2222, Val Loss: 0.3136
2024-12-29 14:37:03,453 - INFO - Epoch 6/1000, Train Loss: 0.2116, Val Loss: 0.3065
2024-12-29 14:37:03,734 - INFO - Epoch 7/1000, Train Loss: 0.2043, Val Loss: 0.3112
2024-12-29 14:37:03,969 - INFO - Epoch 8/1000, Train Loss: 0.1984, Val Loss: 0.3040
2024-12-29 14:37:04,162 - INFO - Epoch 9/1000, Train Loss: 0.1948, Val Loss: 0.3057
2024-12-29 14:37:04,366 - INFO - Epoch 10/1000, Train Loss: 0.1904, Val Loss: 0.2988
2024-12-29 14:37:04,562 - INFO - Epoch 11/1000, Train Loss: 0.1863, Val Loss: 0.3009
2024-12-29 14:37:04,766 - INFO - Epoch 12/1000, Train Loss: 0.1820, Val Loss: 0.3018
2024-12-29 14:37:04,958 - INFO - Epoch 13/1000, Train Loss: 0.1806, Val Loss: 0.3024
2024-12-29 14:37:05,181 - INFO - Epoch 14/1000, Train Loss: 0.1775, Val Loss: 0.2994
2024-12-29 14:37:05,407 - INFO - Epoch 15/1000, Train Loss: 0.1745, Val Loss: 0.2960
2024-12-29 14:37:05,611 - INFO - Epoch 16/1000, Train Loss: 0.1727, Val Loss: 0.3028
2024-12-29 14:37:05,795 - INFO - Epoch 17/1000, Train Loss: 0.1702, Val Loss: 0.2965
2024-12-29 14:37:05,996 - INFO - Epoch 18/1000, Train Loss: 0.1705, Val Loss: 0.2951
2024-12-29 14:37:06,244 - INFO - Epoch 19/1000, Train Loss: 0.1680, Val Loss: 0.2996
2024-12-29 14:37:06,435 - INFO - Epoch 20/1000, Train Loss: 0.1680, Val Loss: 0.2990
2024-12-29 14:37:06,436 - INFO - Early stopping triggered at epoch 20
2024-12-29 14:37:06,436 - INFO - Training completed in 4.85s
2024-12-29 14:37:06,436 - INFO - Final memory usage: CPU 2770.9 MB, GPU 104.2 MB
2024-12-29 14:37:06,437 - INFO - Model training completed in 4.85s
2024-12-29 14:37:06,490 - INFO - Prediction completed in 0.05s
2024-12-29 14:37:06,499 - INFO - Poison rate 0.03 completed in 9.23s
2024-12-29 14:37:06,499 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:37:06,500 - INFO - Total number of labels flipped: 420
2024-12-29 14:37:06,500 - INFO - Label flipping completed in 0.00s
2024-12-29 14:37:06,500 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:37:06,500 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:37:06,994 - INFO - Feature scaling completed in 0.49s
2024-12-29 14:37:06,995 - INFO - Starting feature selection (k=50)
2024-12-29 14:37:07,011 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 14:37:07,011 - INFO - Starting anomaly detection
2024-12-29 14:37:09,404 - INFO - Anomaly detection completed in 2.39s
2024-12-29 14:37:09,404 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:37:09,404 - INFO - Total fit_transform time: 2.90s
2024-12-29 14:37:09,404 - INFO - Training set processing completed in 2.90s
2024-12-29 14:37:09,404 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:37:09,406 - INFO - Memory usage at start_fit: CPU 2761.6 MB, GPU 104.1 MB
2024-12-29 14:37:09,406 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:37:09,412 - INFO - Number of unique classes: 10
2024-12-29 14:37:09,483 - INFO - Fitted scaler and transformed data
2024-12-29 14:37:09,483 - INFO - Scaling time: 0.07s
2024-12-29 14:37:09,716 - INFO - Epoch 1/1000, Train Loss: 0.6935, Val Loss: 0.4728
2024-12-29 14:37:09,919 - INFO - Epoch 2/1000, Train Loss: 0.3772, Val Loss: 0.4527
2024-12-29 14:37:10,126 - INFO - Epoch 3/1000, Train Loss: 0.3510, Val Loss: 0.4404
2024-12-29 14:37:10,337 - INFO - Epoch 4/1000, Train Loss: 0.3340, Val Loss: 0.4336
2024-12-29 14:37:10,524 - INFO - Epoch 5/1000, Train Loss: 0.3204, Val Loss: 0.4299
2024-12-29 14:37:10,723 - INFO - Epoch 6/1000, Train Loss: 0.3103, Val Loss: 0.4269
2024-12-29 14:37:10,928 - INFO - Epoch 7/1000, Train Loss: 0.3007, Val Loss: 0.4219
2024-12-29 14:37:11,129 - INFO - Epoch 8/1000, Train Loss: 0.2931, Val Loss: 0.4135
2024-12-29 14:37:11,316 - INFO - Epoch 9/1000, Train Loss: 0.2873, Val Loss: 0.4140
2024-12-29 14:37:11,546 - INFO - Epoch 10/1000, Train Loss: 0.2804, Val Loss: 0.4083
2024-12-29 14:37:11,729 - INFO - Epoch 11/1000, Train Loss: 0.2765, Val Loss: 0.4113
2024-12-29 14:37:11,923 - INFO - Epoch 12/1000, Train Loss: 0.2702, Val Loss: 0.4019
2024-12-29 14:37:12,129 - INFO - Epoch 13/1000, Train Loss: 0.2672, Val Loss: 0.4066
2024-12-29 14:37:12,325 - INFO - Epoch 14/1000, Train Loss: 0.2648, Val Loss: 0.3994
2024-12-29 14:37:12,530 - INFO - Epoch 15/1000, Train Loss: 0.2605, Val Loss: 0.3952
2024-12-29 14:37:12,729 - INFO - Epoch 16/1000, Train Loss: 0.2574, Val Loss: 0.3959
2024-12-29 14:37:12,919 - INFO - Epoch 17/1000, Train Loss: 0.2544, Val Loss: 0.3959
2024-12-29 14:37:13,124 - INFO - Epoch 18/1000, Train Loss: 0.2506, Val Loss: 0.3931
2024-12-29 14:37:13,324 - INFO - Epoch 19/1000, Train Loss: 0.2485, Val Loss: 0.3880
2024-12-29 14:37:13,520 - INFO - Epoch 20/1000, Train Loss: 0.2472, Val Loss: 0.3832
2024-12-29 14:37:13,711 - INFO - Epoch 21/1000, Train Loss: 0.2449, Val Loss: 0.3848
2024-12-29 14:37:13,902 - INFO - Epoch 22/1000, Train Loss: 0.2432, Val Loss: 0.3834
2024-12-29 14:37:14,105 - INFO - Epoch 23/1000, Train Loss: 0.2420, Val Loss: 0.3790
2024-12-29 14:37:14,308 - INFO - Epoch 24/1000, Train Loss: 0.2401, Val Loss: 0.3851
2024-12-29 14:37:14,506 - INFO - Epoch 25/1000, Train Loss: 0.2382, Val Loss: 0.3776
2024-12-29 14:37:14,698 - INFO - Epoch 26/1000, Train Loss: 0.2376, Val Loss: 0.3743
2024-12-29 14:37:14,889 - INFO - Epoch 27/1000, Train Loss: 0.2374, Val Loss: 0.3725
2024-12-29 14:37:15,102 - INFO - Epoch 28/1000, Train Loss: 0.2343, Val Loss: 0.3713
2024-12-29 14:37:15,321 - INFO - Epoch 29/1000, Train Loss: 0.2339, Val Loss: 0.3709
2024-12-29 14:37:15,520 - INFO - Epoch 30/1000, Train Loss: 0.2311, Val Loss: 0.3688
2024-12-29 14:37:15,709 - INFO - Epoch 31/1000, Train Loss: 0.2309, Val Loss: 0.3698
2024-12-29 14:37:15,918 - INFO - Epoch 32/1000, Train Loss: 0.2318, Val Loss: 0.3643
2024-12-29 14:37:16,117 - INFO - Epoch 33/1000, Train Loss: 0.2299, Val Loss: 0.3640
2024-12-29 14:37:16,344 - INFO - Epoch 34/1000, Train Loss: 0.2309, Val Loss: 0.3641
2024-12-29 14:37:16,555 - INFO - Epoch 35/1000, Train Loss: 0.2283, Val Loss: 0.3621
2024-12-29 14:37:16,769 - INFO - Epoch 36/1000, Train Loss: 0.2278, Val Loss: 0.3627
2024-12-29 14:37:16,965 - INFO - Epoch 37/1000, Train Loss: 0.2276, Val Loss: 0.3620
2024-12-29 14:37:17,181 - INFO - Epoch 38/1000, Train Loss: 0.2261, Val Loss: 0.3605
2024-12-29 14:37:17,381 - INFO - Epoch 39/1000, Train Loss: 0.2261, Val Loss: 0.3618
2024-12-29 14:37:17,612 - INFO - Epoch 40/1000, Train Loss: 0.2244, Val Loss: 0.3613
2024-12-29 14:37:17,803 - INFO - Epoch 41/1000, Train Loss: 0.2253, Val Loss: 0.3626
2024-12-29 14:37:17,993 - INFO - Epoch 42/1000, Train Loss: 0.2239, Val Loss: 0.3607
2024-12-29 14:37:18,193 - INFO - Epoch 43/1000, Train Loss: 0.2226, Val Loss: 0.3565
2024-12-29 14:37:18,397 - INFO - Epoch 44/1000, Train Loss: 0.2229, Val Loss: 0.3546
2024-12-29 14:37:18,604 - INFO - Epoch 45/1000, Train Loss: 0.2229, Val Loss: 0.3604
2024-12-29 14:37:18,794 - INFO - Epoch 46/1000, Train Loss: 0.2245, Val Loss: 0.3660
2024-12-29 14:37:18,983 - INFO - Epoch 47/1000, Train Loss: 0.2213, Val Loss: 0.3543
2024-12-29 14:37:19,175 - INFO - Epoch 48/1000, Train Loss: 0.2220, Val Loss: 0.3551
2024-12-29 14:37:19,366 - INFO - Epoch 49/1000, Train Loss: 0.2215, Val Loss: 0.3598
2024-12-29 14:37:19,367 - INFO - Early stopping triggered at epoch 49
2024-12-29 14:37:19,367 - INFO - Training completed in 9.96s
2024-12-29 14:37:19,367 - INFO - Final memory usage: CPU 2771.0 MB, GPU 104.2 MB
2024-12-29 14:37:19,368 - INFO - Model training completed in 9.96s
2024-12-29 14:37:19,437 - INFO - Prediction completed in 0.07s
2024-12-29 14:37:19,446 - INFO - Poison rate 0.05 completed in 12.95s
2024-12-29 14:37:19,446 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:37:19,447 - INFO - Total number of labels flipped: 604
2024-12-29 14:37:19,447 - INFO - Label flipping completed in 0.00s
2024-12-29 14:37:19,447 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:37:19,447 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:37:19,977 - INFO - Feature scaling completed in 0.53s
2024-12-29 14:37:19,977 - INFO - Starting feature selection (k=50)
2024-12-29 14:37:19,995 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 14:37:19,995 - INFO - Starting anomaly detection
2024-12-29 14:37:23,697 - INFO - Anomaly detection completed in 3.70s
2024-12-29 14:37:23,697 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:37:23,698 - INFO - Total fit_transform time: 4.25s
2024-12-29 14:37:23,698 - INFO - Training set processing completed in 4.25s
2024-12-29 14:37:23,698 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:37:23,700 - INFO - Memory usage at start_fit: CPU 2761.5 MB, GPU 104.1 MB
2024-12-29 14:37:23,700 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:37:23,703 - INFO - Number of unique classes: 10
2024-12-29 14:37:23,781 - INFO - Fitted scaler and transformed data
2024-12-29 14:37:23,781 - INFO - Scaling time: 0.08s
2024-12-29 14:37:23,976 - INFO - Epoch 1/1000, Train Loss: 0.7624, Val Loss: 0.5068
2024-12-29 14:37:24,188 - INFO - Epoch 2/1000, Train Loss: 0.4766, Val Loss: 0.4849
2024-12-29 14:37:24,379 - INFO - Epoch 3/1000, Train Loss: 0.4495, Val Loss: 0.4716
2024-12-29 14:37:24,571 - INFO - Epoch 4/1000, Train Loss: 0.4284, Val Loss: 0.4638
2024-12-29 14:37:24,759 - INFO - Epoch 5/1000, Train Loss: 0.4134, Val Loss: 0.4577
2024-12-29 14:37:24,945 - INFO - Epoch 6/1000, Train Loss: 0.3993, Val Loss: 0.4522
2024-12-29 14:37:25,150 - INFO - Epoch 7/1000, Train Loss: 0.3860, Val Loss: 0.4501
2024-12-29 14:37:25,375 - INFO - Epoch 8/1000, Train Loss: 0.3767, Val Loss: 0.4460
2024-12-29 14:37:25,589 - INFO - Epoch 9/1000, Train Loss: 0.3714, Val Loss: 0.4406
2024-12-29 14:37:25,783 - INFO - Epoch 10/1000, Train Loss: 0.3622, Val Loss: 0.4363
2024-12-29 14:37:26,018 - INFO - Epoch 11/1000, Train Loss: 0.3570, Val Loss: 0.4351
2024-12-29 14:37:26,214 - INFO - Epoch 12/1000, Train Loss: 0.3497, Val Loss: 0.4368
2024-12-29 14:37:26,449 - INFO - Epoch 13/1000, Train Loss: 0.3449, Val Loss: 0.4280
2024-12-29 14:37:26,635 - INFO - Epoch 14/1000, Train Loss: 0.3388, Val Loss: 0.4238
2024-12-29 14:37:26,819 - INFO - Epoch 15/1000, Train Loss: 0.3349, Val Loss: 0.4270
2024-12-29 14:37:27,019 - INFO - Epoch 16/1000, Train Loss: 0.3296, Val Loss: 0.4318
2024-12-29 14:37:27,257 - INFO - Epoch 17/1000, Train Loss: 0.3283, Val Loss: 0.4201
2024-12-29 14:37:27,458 - INFO - Epoch 18/1000, Train Loss: 0.3242, Val Loss: 0.4196
2024-12-29 14:37:27,654 - INFO - Epoch 19/1000, Train Loss: 0.3197, Val Loss: 0.4149
2024-12-29 14:37:27,859 - INFO - Epoch 20/1000, Train Loss: 0.3169, Val Loss: 0.4173
2024-12-29 14:37:28,054 - INFO - Epoch 21/1000, Train Loss: 0.3152, Val Loss: 0.4145
2024-12-29 14:37:28,243 - INFO - Epoch 22/1000, Train Loss: 0.3110, Val Loss: 0.4124
2024-12-29 14:37:28,436 - INFO - Epoch 23/1000, Train Loss: 0.3095, Val Loss: 0.4086
2024-12-29 14:37:28,630 - INFO - Epoch 24/1000, Train Loss: 0.3078, Val Loss: 0.4079
2024-12-29 14:37:28,824 - INFO - Epoch 25/1000, Train Loss: 0.3038, Val Loss: 0.4060
2024-12-29 14:37:29,022 - INFO - Epoch 26/1000, Train Loss: 0.3033, Val Loss: 0.4042
2024-12-29 14:37:29,223 - INFO - Epoch 27/1000, Train Loss: 0.3017, Val Loss: 0.4020
2024-12-29 14:37:29,417 - INFO - Epoch 28/1000, Train Loss: 0.3000, Val Loss: 0.4067
2024-12-29 14:37:29,628 - INFO - Epoch 29/1000, Train Loss: 0.2995, Val Loss: 0.4017
2024-12-29 14:37:29,845 - INFO - Epoch 30/1000, Train Loss: 0.2953, Val Loss: 0.3992
2024-12-29 14:37:30,061 - INFO - Epoch 31/1000, Train Loss: 0.2959, Val Loss: 0.4035
2024-12-29 14:37:30,270 - INFO - Epoch 32/1000, Train Loss: 0.2944, Val Loss: 0.3990
2024-12-29 14:37:30,477 - INFO - Epoch 33/1000, Train Loss: 0.2944, Val Loss: 0.3980
2024-12-29 14:37:30,714 - INFO - Epoch 34/1000, Train Loss: 0.2910, Val Loss: 0.3962
2024-12-29 14:37:30,908 - INFO - Epoch 35/1000, Train Loss: 0.2903, Val Loss: 0.3997
2024-12-29 14:37:31,113 - INFO - Epoch 36/1000, Train Loss: 0.2887, Val Loss: 0.3998
2024-12-29 14:37:31,322 - INFO - Epoch 37/1000, Train Loss: 0.2882, Val Loss: 0.4001
2024-12-29 14:37:31,536 - INFO - Epoch 38/1000, Train Loss: 0.2875, Val Loss: 0.3966
2024-12-29 14:37:31,759 - INFO - Epoch 39/1000, Train Loss: 0.2861, Val Loss: 0.3901
2024-12-29 14:37:31,962 - INFO - Epoch 40/1000, Train Loss: 0.2852, Val Loss: 0.3922
2024-12-29 14:37:32,192 - INFO - Epoch 41/1000, Train Loss: 0.2853, Val Loss: 0.3886
2024-12-29 14:37:32,390 - INFO - Epoch 42/1000, Train Loss: 0.2830, Val Loss: 0.3873
2024-12-29 14:37:32,609 - INFO - Epoch 43/1000, Train Loss: 0.2829, Val Loss: 0.3972
2024-12-29 14:37:32,805 - INFO - Epoch 44/1000, Train Loss: 0.2835, Val Loss: 0.3851
2024-12-29 14:37:32,996 - INFO - Epoch 45/1000, Train Loss: 0.2819, Val Loss: 0.3851
2024-12-29 14:37:33,203 - INFO - Epoch 46/1000, Train Loss: 0.2790, Val Loss: 0.3871
2024-12-29 14:37:33,419 - INFO - Epoch 47/1000, Train Loss: 0.2808, Val Loss: 0.3915
2024-12-29 14:37:33,617 - INFO - Epoch 48/1000, Train Loss: 0.2785, Val Loss: 0.3836
2024-12-29 14:37:33,819 - INFO - Epoch 49/1000, Train Loss: 0.2798, Val Loss: 0.3903
2024-12-29 14:37:34,011 - INFO - Epoch 50/1000, Train Loss: 0.2780, Val Loss: 0.3800
2024-12-29 14:37:34,203 - INFO - Epoch 51/1000, Train Loss: 0.2799, Val Loss: 0.3823
2024-12-29 14:37:34,407 - INFO - Epoch 52/1000, Train Loss: 0.2791, Val Loss: 0.3865
2024-12-29 14:37:34,612 - INFO - Epoch 53/1000, Train Loss: 0.2780, Val Loss: 0.3841
2024-12-29 14:37:34,813 - INFO - Epoch 54/1000, Train Loss: 0.2772, Val Loss: 0.3819
2024-12-29 14:37:35,001 - INFO - Epoch 55/1000, Train Loss: 0.2770, Val Loss: 0.3804
2024-12-29 14:37:35,002 - INFO - Early stopping triggered at epoch 55
2024-12-29 14:37:35,002 - INFO - Training completed in 11.30s
2024-12-29 14:37:35,003 - INFO - Final memory usage: CPU 2770.9 MB, GPU 104.2 MB
2024-12-29 14:37:35,005 - INFO - Model training completed in 11.31s
2024-12-29 14:37:35,090 - INFO - Prediction completed in 0.08s
2024-12-29 14:37:35,099 - INFO - Poison rate 0.07 completed in 15.65s
2024-12-29 14:37:35,099 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:37:35,100 - INFO - Total number of labels flipped: 841
2024-12-29 14:37:35,101 - INFO - Label flipping completed in 0.00s
2024-12-29 14:37:35,101 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:37:35,101 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:37:35,668 - INFO - Feature scaling completed in 0.57s
2024-12-29 14:37:35,668 - INFO - Starting feature selection (k=50)
2024-12-29 14:37:35,683 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 14:37:35,684 - INFO - Starting anomaly detection
2024-12-29 14:37:39,941 - INFO - Anomaly detection completed in 4.26s
2024-12-29 14:37:39,941 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:37:39,942 - INFO - Total fit_transform time: 4.84s
2024-12-29 14:37:39,942 - INFO - Training set processing completed in 4.84s
2024-12-29 14:37:39,942 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:37:39,943 - INFO - Memory usage at start_fit: CPU 2761.6 MB, GPU 104.1 MB
2024-12-29 14:37:39,943 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:37:39,947 - INFO - Number of unique classes: 10
2024-12-29 14:37:40,027 - INFO - Fitted scaler and transformed data
2024-12-29 14:37:40,028 - INFO - Scaling time: 0.08s
2024-12-29 14:37:40,255 - INFO - Epoch 1/1000, Train Loss: 0.8740, Val Loss: 0.6530
2024-12-29 14:37:40,459 - INFO - Epoch 2/1000, Train Loss: 0.6015, Val Loss: 0.6368
2024-12-29 14:37:40,648 - INFO - Epoch 3/1000, Train Loss: 0.5667, Val Loss: 0.6325
2024-12-29 14:37:40,880 - INFO - Epoch 4/1000, Train Loss: 0.5370, Val Loss: 0.6243
2024-12-29 14:37:41,093 - INFO - Epoch 5/1000, Train Loss: 0.5189, Val Loss: 0.6232
2024-12-29 14:37:41,336 - INFO - Epoch 6/1000, Train Loss: 0.5029, Val Loss: 0.6169
2024-12-29 14:37:41,535 - INFO - Epoch 7/1000, Train Loss: 0.4889, Val Loss: 0.6105
2024-12-29 14:37:41,741 - INFO - Epoch 8/1000, Train Loss: 0.4778, Val Loss: 0.6082
2024-12-29 14:37:41,961 - INFO - Epoch 9/1000, Train Loss: 0.4648, Val Loss: 0.5974
2024-12-29 14:37:42,206 - INFO - Epoch 10/1000, Train Loss: 0.4557, Val Loss: 0.5946
2024-12-29 14:37:42,416 - INFO - Epoch 11/1000, Train Loss: 0.4455, Val Loss: 0.5889
2024-12-29 14:37:42,605 - INFO - Epoch 12/1000, Train Loss: 0.4353, Val Loss: 0.5843
2024-12-29 14:37:42,802 - INFO - Epoch 13/1000, Train Loss: 0.4318, Val Loss: 0.5787
2024-12-29 14:37:42,992 - INFO - Epoch 14/1000, Train Loss: 0.4236, Val Loss: 0.5773
2024-12-29 14:37:43,205 - INFO - Epoch 15/1000, Train Loss: 0.4190, Val Loss: 0.5748
2024-12-29 14:37:43,400 - INFO - Epoch 16/1000, Train Loss: 0.4109, Val Loss: 0.5678
2024-12-29 14:37:43,633 - INFO - Epoch 17/1000, Train Loss: 0.4069, Val Loss: 0.5729
2024-12-29 14:37:43,830 - INFO - Epoch 18/1000, Train Loss: 0.4028, Val Loss: 0.5581
2024-12-29 14:37:44,054 - INFO - Epoch 19/1000, Train Loss: 0.3987, Val Loss: 0.5599
2024-12-29 14:37:44,273 - INFO - Epoch 20/1000, Train Loss: 0.3939, Val Loss: 0.5549
2024-12-29 14:37:44,490 - INFO - Epoch 21/1000, Train Loss: 0.3886, Val Loss: 0.5458
2024-12-29 14:37:44,683 - INFO - Epoch 22/1000, Train Loss: 0.3852, Val Loss: 0.5469
2024-12-29 14:37:44,904 - INFO - Epoch 23/1000, Train Loss: 0.3814, Val Loss: 0.5401
2024-12-29 14:37:45,111 - INFO - Epoch 24/1000, Train Loss: 0.3804, Val Loss: 0.5353
2024-12-29 14:37:45,402 - INFO - Epoch 25/1000, Train Loss: 0.3766, Val Loss: 0.5346
2024-12-29 14:37:45,809 - INFO - Epoch 26/1000, Train Loss: 0.3743, Val Loss: 0.5344
2024-12-29 14:37:46,120 - INFO - Epoch 27/1000, Train Loss: 0.3722, Val Loss: 0.5347
2024-12-29 14:37:46,385 - INFO - Epoch 28/1000, Train Loss: 0.3701, Val Loss: 0.5301
2024-12-29 14:37:46,688 - INFO - Epoch 29/1000, Train Loss: 0.3666, Val Loss: 0.5452
2024-12-29 14:37:46,972 - INFO - Epoch 30/1000, Train Loss: 0.3664, Val Loss: 0.5246
2024-12-29 14:37:47,236 - INFO - Epoch 31/1000, Train Loss: 0.3633, Val Loss: 0.5251
2024-12-29 14:37:47,551 - INFO - Epoch 32/1000, Train Loss: 0.3613, Val Loss: 0.5230
2024-12-29 14:37:47,853 - INFO - Epoch 33/1000, Train Loss: 0.3593, Val Loss: 0.5287
2024-12-29 14:37:48,221 - INFO - Epoch 34/1000, Train Loss: 0.3602, Val Loss: 0.5219
2024-12-29 14:37:48,550 - INFO - Epoch 35/1000, Train Loss: 0.3586, Val Loss: 0.5287
2024-12-29 14:37:48,814 - INFO - Epoch 36/1000, Train Loss: 0.3550, Val Loss: 0.5183
2024-12-29 14:37:49,046 - INFO - Epoch 37/1000, Train Loss: 0.3543, Val Loss: 0.5173
2024-12-29 14:37:49,237 - INFO - Epoch 38/1000, Train Loss: 0.3520, Val Loss: 0.5139
2024-12-29 14:37:49,444 - INFO - Epoch 39/1000, Train Loss: 0.3516, Val Loss: 0.5050
2024-12-29 14:37:49,661 - INFO - Epoch 40/1000, Train Loss: 0.3492, Val Loss: 0.5186
2024-12-29 14:37:49,976 - INFO - Epoch 41/1000, Train Loss: 0.3474, Val Loss: 0.5150
2024-12-29 14:37:50,183 - INFO - Epoch 42/1000, Train Loss: 0.3471, Val Loss: 0.5143
2024-12-29 14:37:50,492 - INFO - Epoch 43/1000, Train Loss: 0.3480, Val Loss: 0.5080
2024-12-29 14:37:50,822 - INFO - Epoch 44/1000, Train Loss: 0.3473, Val Loss: 0.5204
2024-12-29 14:37:50,822 - INFO - Early stopping triggered at epoch 44
2024-12-29 14:37:50,823 - INFO - Training completed in 10.88s
2024-12-29 14:37:50,823 - INFO - Final memory usage: CPU 2771.0 MB, GPU 104.2 MB
2024-12-29 14:37:50,825 - INFO - Model training completed in 10.88s
2024-12-29 14:37:50,911 - INFO - Prediction completed in 0.08s
2024-12-29 14:37:50,920 - INFO - Poison rate 0.1 completed in 15.82s
2024-12-29 14:37:50,920 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:37:50,922 - INFO - Total number of labels flipped: 1686
2024-12-29 14:37:50,922 - INFO - Label flipping completed in 0.00s
2024-12-29 14:37:50,922 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:37:50,922 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:37:51,549 - INFO - Feature scaling completed in 0.63s
2024-12-29 14:37:51,549 - INFO - Starting feature selection (k=50)
2024-12-29 14:37:51,564 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:37:51,565 - INFO - Starting anomaly detection
2024-12-29 14:37:55,755 - INFO - Anomaly detection completed in 4.19s
2024-12-29 14:37:55,755 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:37:55,756 - INFO - Total fit_transform time: 4.83s
2024-12-29 14:37:55,756 - INFO - Training set processing completed in 4.83s
2024-12-29 14:37:55,756 - INFO - Fitting LogisticRegressionWrapper model with data shape: (9469, 512)
2024-12-29 14:37:55,757 - INFO - Memory usage at start_fit: CPU 2761.7 MB, GPU 104.1 MB
2024-12-29 14:37:55,757 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:37:55,759 - INFO - Number of unique classes: 10
2024-12-29 14:37:55,827 - INFO - Fitted scaler and transformed data
2024-12-29 14:37:55,827 - INFO - Scaling time: 0.07s
2024-12-29 14:37:56,033 - INFO - Epoch 1/1000, Train Loss: 1.1725, Val Loss: 1.0761
2024-12-29 14:37:56,216 - INFO - Epoch 2/1000, Train Loss: 0.9530, Val Loss: 1.0413
2024-12-29 14:37:56,404 - INFO - Epoch 3/1000, Train Loss: 0.9039, Val Loss: 1.0209
2024-12-29 14:37:56,601 - INFO - Epoch 4/1000, Train Loss: 0.8692, Val Loss: 0.9962
2024-12-29 14:37:56,797 - INFO - Epoch 5/1000, Train Loss: 0.8398, Val Loss: 0.9751
2024-12-29 14:37:56,981 - INFO - Epoch 6/1000, Train Loss: 0.8121, Val Loss: 0.9607
2024-12-29 14:37:57,195 - INFO - Epoch 7/1000, Train Loss: 0.7884, Val Loss: 0.9393
2024-12-29 14:37:57,439 - INFO - Epoch 8/1000, Train Loss: 0.7677, Val Loss: 0.9260
2024-12-29 14:37:57,627 - INFO - Epoch 9/1000, Train Loss: 0.7509, Val Loss: 0.9071
2024-12-29 14:37:57,819 - INFO - Epoch 10/1000, Train Loss: 0.7338, Val Loss: 0.8972
2024-12-29 14:37:58,013 - INFO - Epoch 11/1000, Train Loss: 0.7175, Val Loss: 0.8804
2024-12-29 14:37:58,220 - INFO - Epoch 12/1000, Train Loss: 0.7008, Val Loss: 0.8685
2024-12-29 14:37:58,425 - INFO - Epoch 13/1000, Train Loss: 0.6853, Val Loss: 0.8467
2024-12-29 14:37:58,616 - INFO - Epoch 14/1000, Train Loss: 0.6744, Val Loss: 0.8488
2024-12-29 14:37:58,822 - INFO - Epoch 15/1000, Train Loss: 0.6628, Val Loss: 0.8281
2024-12-29 14:37:59,052 - INFO - Epoch 16/1000, Train Loss: 0.6510, Val Loss: 0.8125
2024-12-29 14:37:59,232 - INFO - Epoch 17/1000, Train Loss: 0.6385, Val Loss: 0.8062
2024-12-29 14:37:59,424 - INFO - Epoch 18/1000, Train Loss: 0.6334, Val Loss: 0.8023
2024-12-29 14:37:59,620 - INFO - Epoch 19/1000, Train Loss: 0.6210, Val Loss: 0.7920
2024-12-29 14:37:59,818 - INFO - Epoch 20/1000, Train Loss: 0.6117, Val Loss: 0.7804
2024-12-29 14:38:00,019 - INFO - Epoch 21/1000, Train Loss: 0.6077, Val Loss: 0.7800
2024-12-29 14:38:00,232 - INFO - Epoch 22/1000, Train Loss: 0.6012, Val Loss: 0.7707
2024-12-29 14:38:00,457 - INFO - Epoch 23/1000, Train Loss: 0.5920, Val Loss: 0.7655
2024-12-29 14:38:00,709 - INFO - Epoch 24/1000, Train Loss: 0.5866, Val Loss: 0.7547
2024-12-29 14:38:00,930 - INFO - Epoch 25/1000, Train Loss: 0.5789, Val Loss: 0.7547
2024-12-29 14:38:01,133 - INFO - Epoch 26/1000, Train Loss: 0.5765, Val Loss: 0.7452
2024-12-29 14:38:01,334 - INFO - Epoch 27/1000, Train Loss: 0.5700, Val Loss: 0.7420
2024-12-29 14:38:01,554 - INFO - Epoch 28/1000, Train Loss: 0.5660, Val Loss: 0.7427
2024-12-29 14:38:01,816 - INFO - Epoch 29/1000, Train Loss: 0.5624, Val Loss: 0.7335
2024-12-29 14:38:02,020 - INFO - Epoch 30/1000, Train Loss: 0.5555, Val Loss: 0.7280
2024-12-29 14:38:02,220 - INFO - Epoch 31/1000, Train Loss: 0.5533, Val Loss: 0.7278
2024-12-29 14:38:02,423 - INFO - Epoch 32/1000, Train Loss: 0.5482, Val Loss: 0.7276
2024-12-29 14:38:02,639 - INFO - Epoch 33/1000, Train Loss: 0.5475, Val Loss: 0.7229
2024-12-29 14:38:02,862 - INFO - Epoch 34/1000, Train Loss: 0.5415, Val Loss: 0.7307
2024-12-29 14:38:03,075 - INFO - Epoch 35/1000, Train Loss: 0.5405, Val Loss: 0.7232
2024-12-29 14:38:03,278 - INFO - Epoch 36/1000, Train Loss: 0.5374, Val Loss: 0.7152
2024-12-29 14:38:03,487 - INFO - Epoch 37/1000, Train Loss: 0.5357, Val Loss: 0.7077
2024-12-29 14:38:03,695 - INFO - Epoch 38/1000, Train Loss: 0.5320, Val Loss: 0.7060
2024-12-29 14:38:03,897 - INFO - Epoch 39/1000, Train Loss: 0.5296, Val Loss: 0.7138
2024-12-29 14:38:04,106 - INFO - Epoch 40/1000, Train Loss: 0.5292, Val Loss: 0.7098
2024-12-29 14:38:04,298 - INFO - Epoch 41/1000, Train Loss: 0.5273, Val Loss: 0.7002
2024-12-29 14:38:04,492 - INFO - Epoch 42/1000, Train Loss: 0.5235, Val Loss: 0.7025
2024-12-29 14:38:04,694 - INFO - Epoch 43/1000, Train Loss: 0.5221, Val Loss: 0.6995
2024-12-29 14:38:04,891 - INFO - Epoch 44/1000, Train Loss: 0.5219, Val Loss: 0.6950
2024-12-29 14:38:05,085 - INFO - Epoch 45/1000, Train Loss: 0.5170, Val Loss: 0.7029
2024-12-29 14:38:05,286 - INFO - Epoch 46/1000, Train Loss: 0.5181, Val Loss: 0.6913
2024-12-29 14:38:05,474 - INFO - Epoch 47/1000, Train Loss: 0.5156, Val Loss: 0.6919
2024-12-29 14:38:05,674 - INFO - Epoch 48/1000, Train Loss: 0.5169, Val Loss: 0.6945
2024-12-29 14:38:05,876 - INFO - Epoch 49/1000, Train Loss: 0.5128, Val Loss: 0.6990
2024-12-29 14:38:06,072 - INFO - Epoch 50/1000, Train Loss: 0.5110, Val Loss: 0.6931
2024-12-29 14:38:06,274 - INFO - Epoch 51/1000, Train Loss: 0.5102, Val Loss: 0.6896
2024-12-29 14:38:06,468 - INFO - Epoch 52/1000, Train Loss: 0.5088, Val Loss: 0.6856
2024-12-29 14:38:06,657 - INFO - Epoch 53/1000, Train Loss: 0.5107, Val Loss: 0.6884
2024-12-29 14:38:06,856 - INFO - Epoch 54/1000, Train Loss: 0.5063, Val Loss: 0.6800
2024-12-29 14:38:07,057 - INFO - Epoch 55/1000, Train Loss: 0.5039, Val Loss: 0.6823
2024-12-29 14:38:07,273 - INFO - Epoch 56/1000, Train Loss: 0.5061, Val Loss: 0.6855
2024-12-29 14:38:07,485 - INFO - Epoch 57/1000, Train Loss: 0.5025, Val Loss: 0.6858
2024-12-29 14:38:07,688 - INFO - Epoch 58/1000, Train Loss: 0.5029, Val Loss: 0.6816
2024-12-29 14:38:07,894 - INFO - Epoch 59/1000, Train Loss: 0.5012, Val Loss: 0.6838
2024-12-29 14:38:07,895 - INFO - Early stopping triggered at epoch 59
2024-12-29 14:38:07,895 - INFO - Training completed in 12.14s
2024-12-29 14:38:07,896 - INFO - Final memory usage: CPU 2771.1 MB, GPU 104.2 MB
2024-12-29 14:38:07,898 - INFO - Model training completed in 12.14s
2024-12-29 14:38:07,956 - INFO - Prediction completed in 0.06s
2024-12-29 14:38:07,964 - INFO - Poison rate 0.2 completed in 17.04s
2024-12-29 14:38:07,974 - INFO - Loaded 525 existing results
2024-12-29 14:38:07,974 - INFO - Total results to save: 532
2024-12-29 14:38:07,976 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:38:08,003 - INFO - Saved 532 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:38:08,004 - INFO - Total evaluation time: 119.03s
2024-12-29 14:38:08,006 - INFO - 
Progress: 80.2% - Evaluating CIFAR100 with RandomForest (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:38:08,233 - INFO - Loading datasets...
2024-12-29 14:38:08,255 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:38:08,255 - INFO - Extracting validation features...
2024-12-29 14:38:08,255 - INFO - Extracting features from 3925 samples...
2024-12-29 14:38:17,452 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:38:17,458 - INFO - Validation feature extraction completed in 9.20s
2024-12-29 14:38:17,458 - INFO - Extracting training features...
2024-12-29 14:38:17,458 - INFO - Extracting features from 9469 samples...
2024-12-29 14:38:39,074 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:38:39,079 - INFO - Training feature extraction completed in 21.62s
2024-12-29 14:38:39,080 - INFO - Creating model for classifier: RandomForest
2024-12-29 14:38:39,080 - INFO - Using device: cuda
2024-12-29 14:38:39,080 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:38:39,081 - INFO - Training set processing completed in 0.00s
2024-12-29 14:38:39,081 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:38:39,082 - INFO - Memory usage at start_fit: CPU 2734.1 MB, GPU 104.6 MB
2024-12-29 14:38:39,083 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:38:39,302 - INFO - Fitted scaler and transformed data
2024-12-29 14:38:39,302 - INFO - Scaling time: 0.22s
2024-12-29 14:38:39,310 - INFO - Number of unique classes: 10
2024-12-29 14:38:43,124 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3013
2024-12-29 14:38:46,733 - INFO - Epoch 2/10, Train Loss: 2.3006, Val Loss: 2.3001
2024-12-29 14:38:49,872 - INFO - Epoch 3/10, Train Loss: 2.2991, Val Loss: 2.2988
2024-12-29 14:38:53,071 - INFO - Epoch 4/10, Train Loss: 2.2977, Val Loss: 2.2974
2024-12-29 14:38:53,071 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:38:53,071 - INFO - Training completed in 13.99s
2024-12-29 14:38:53,072 - INFO - Final memory usage: CPU 2758.0 MB, GPU 126.5 MB
2024-12-29 14:38:53,072 - INFO - Model training completed in 13.99s
2024-12-29 14:38:53,225 - INFO - Prediction completed in 0.15s
2024-12-29 14:38:53,234 - INFO - Poison rate 0.0 completed in 14.15s
2024-12-29 14:38:53,234 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:38:53,235 - INFO - Total number of labels flipped: 83
2024-12-29 14:38:53,235 - INFO - Label flipping completed in 0.00s
2024-12-29 14:38:53,235 - INFO - Training set processing completed in 0.00s
2024-12-29 14:38:53,235 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:38:53,236 - INFO - Memory usage at start_fit: CPU 2758.0 MB, GPU 106.7 MB
2024-12-29 14:38:53,236 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:38:53,419 - INFO - Fitted scaler and transformed data
2024-12-29 14:38:53,419 - INFO - Scaling time: 0.18s
2024-12-29 14:38:53,429 - INFO - Number of unique classes: 10
2024-12-29 14:38:57,196 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3013
2024-12-29 14:39:00,154 - INFO - Epoch 2/10, Train Loss: 2.3006, Val Loss: 2.3001
2024-12-29 14:39:03,146 - INFO - Epoch 3/10, Train Loss: 2.2992, Val Loss: 2.2988
2024-12-29 14:39:06,684 - INFO - Epoch 4/10, Train Loss: 2.2978, Val Loss: 2.2975
2024-12-29 14:39:06,684 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:39:06,684 - INFO - Training completed in 13.45s
2024-12-29 14:39:06,684 - INFO - Final memory usage: CPU 2758.0 MB, GPU 126.5 MB
2024-12-29 14:39:06,685 - INFO - Model training completed in 13.45s
2024-12-29 14:39:06,852 - INFO - Prediction completed in 0.17s
2024-12-29 14:39:06,861 - INFO - Poison rate 0.01 completed in 13.63s
2024-12-29 14:39:06,861 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:39:06,862 - INFO - Total number of labels flipped: 257
2024-12-29 14:39:06,862 - INFO - Label flipping completed in 0.00s
2024-12-29 14:39:06,862 - INFO - Training set processing completed in 0.00s
2024-12-29 14:39:06,862 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:39:06,863 - INFO - Memory usage at start_fit: CPU 2758.0 MB, GPU 106.7 MB
2024-12-29 14:39:06,863 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:39:07,054 - INFO - Fitted scaler and transformed data
2024-12-29 14:39:07,054 - INFO - Scaling time: 0.19s
2024-12-29 14:39:07,064 - INFO - Number of unique classes: 10
2024-12-29 14:39:10,475 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3013
2024-12-29 14:39:13,413 - INFO - Epoch 2/10, Train Loss: 2.3006, Val Loss: 2.3001
2024-12-29 14:39:16,240 - INFO - Epoch 3/10, Train Loss: 2.2993, Val Loss: 2.2988
2024-12-29 14:39:19,300 - INFO - Epoch 4/10, Train Loss: 2.2979, Val Loss: 2.2975
2024-12-29 14:39:19,300 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:39:19,300 - INFO - Training completed in 12.44s
2024-12-29 14:39:19,300 - INFO - Final memory usage: CPU 2758.0 MB, GPU 126.5 MB
2024-12-29 14:39:19,301 - INFO - Model training completed in 12.44s
2024-12-29 14:39:19,460 - INFO - Prediction completed in 0.16s
2024-12-29 14:39:19,469 - INFO - Poison rate 0.03 completed in 12.61s
2024-12-29 14:39:19,469 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:39:19,471 - INFO - Total number of labels flipped: 423
2024-12-29 14:39:19,471 - INFO - Label flipping completed in 0.00s
2024-12-29 14:39:19,471 - INFO - Training set processing completed in 0.00s
2024-12-29 14:39:19,471 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:39:19,472 - INFO - Memory usage at start_fit: CPU 2758.0 MB, GPU 106.7 MB
2024-12-29 14:39:19,472 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:39:19,656 - INFO - Fitted scaler and transformed data
2024-12-29 14:39:19,656 - INFO - Scaling time: 0.18s
2024-12-29 14:39:19,666 - INFO - Number of unique classes: 10
2024-12-29 14:39:22,425 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3014
2024-12-29 14:39:25,126 - INFO - Epoch 2/10, Train Loss: 2.3007, Val Loss: 2.3002
2024-12-29 14:39:27,879 - INFO - Epoch 3/10, Train Loss: 2.2994, Val Loss: 2.2990
2024-12-29 14:39:31,470 - INFO - Epoch 4/10, Train Loss: 2.2980, Val Loss: 2.2977
2024-12-29 14:39:31,470 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:39:31,470 - INFO - Training completed in 12.00s
2024-12-29 14:39:31,471 - INFO - Final memory usage: CPU 2758.0 MB, GPU 126.5 MB
2024-12-29 14:39:31,471 - INFO - Model training completed in 12.00s
2024-12-29 14:39:31,665 - INFO - Prediction completed in 0.19s
2024-12-29 14:39:31,675 - INFO - Poison rate 0.05 completed in 12.21s
2024-12-29 14:39:31,675 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:39:31,676 - INFO - Total number of labels flipped: 595
2024-12-29 14:39:31,677 - INFO - Label flipping completed in 0.00s
2024-12-29 14:39:31,677 - INFO - Training set processing completed in 0.00s
2024-12-29 14:39:31,677 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:39:31,678 - INFO - Memory usage at start_fit: CPU 2758.0 MB, GPU 106.7 MB
2024-12-29 14:39:31,678 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:39:31,863 - INFO - Fitted scaler and transformed data
2024-12-29 14:39:31,864 - INFO - Scaling time: 0.19s
2024-12-29 14:39:31,876 - INFO - Number of unique classes: 10
2024-12-29 14:39:35,349 - INFO - Epoch 1/10, Train Loss: 2.3021, Val Loss: 2.3014
2024-12-29 14:39:38,229 - INFO - Epoch 2/10, Train Loss: 2.3007, Val Loss: 2.3002
2024-12-29 14:39:41,443 - INFO - Epoch 3/10, Train Loss: 2.2994, Val Loss: 2.2990
2024-12-29 14:39:44,265 - INFO - Epoch 4/10, Train Loss: 2.2981, Val Loss: 2.2978
2024-12-29 14:39:44,265 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:39:44,265 - INFO - Training completed in 12.59s
2024-12-29 14:39:44,266 - INFO - Final memory usage: CPU 2758.0 MB, GPU 126.5 MB
2024-12-29 14:39:44,266 - INFO - Model training completed in 12.59s
2024-12-29 14:39:44,428 - INFO - Prediction completed in 0.16s
2024-12-29 14:39:44,437 - INFO - Poison rate 0.07 completed in 12.76s
2024-12-29 14:39:44,437 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:39:44,439 - INFO - Total number of labels flipped: 835
2024-12-29 14:39:44,439 - INFO - Label flipping completed in 0.00s
2024-12-29 14:39:44,439 - INFO - Training set processing completed in 0.00s
2024-12-29 14:39:44,439 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:39:44,440 - INFO - Memory usage at start_fit: CPU 2758.0 MB, GPU 106.7 MB
2024-12-29 14:39:44,440 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:39:44,615 - INFO - Fitted scaler and transformed data
2024-12-29 14:39:44,615 - INFO - Scaling time: 0.18s
2024-12-29 14:39:44,629 - INFO - Number of unique classes: 10
2024-12-29 14:39:47,701 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3014
2024-12-29 14:39:50,448 - INFO - Epoch 2/10, Train Loss: 2.3007, Val Loss: 2.3002
2024-12-29 14:39:53,107 - INFO - Epoch 3/10, Train Loss: 2.2995, Val Loss: 2.2990
2024-12-29 14:39:55,963 - INFO - Epoch 4/10, Train Loss: 2.2982, Val Loss: 2.2978
2024-12-29 14:39:55,963 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:39:55,963 - INFO - Training completed in 11.52s
2024-12-29 14:39:55,963 - INFO - Final memory usage: CPU 2758.0 MB, GPU 126.5 MB
2024-12-29 14:39:55,964 - INFO - Model training completed in 11.52s
2024-12-29 14:39:56,168 - INFO - Prediction completed in 0.20s
2024-12-29 14:39:56,193 - INFO - Poison rate 0.1 completed in 11.76s
2024-12-29 14:39:56,193 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:39:56,196 - INFO - Total number of labels flipped: 1722
2024-12-29 14:39:56,196 - INFO - Label flipping completed in 0.00s
2024-12-29 14:39:56,197 - INFO - Training set processing completed in 0.00s
2024-12-29 14:39:56,197 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:39:56,198 - INFO - Memory usage at start_fit: CPU 2758.0 MB, GPU 106.7 MB
2024-12-29 14:39:56,198 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:39:56,381 - INFO - Fitted scaler and transformed data
2024-12-29 14:39:56,381 - INFO - Scaling time: 0.18s
2024-12-29 14:39:56,391 - INFO - Number of unique classes: 10
2024-12-29 14:39:59,659 - INFO - Epoch 1/10, Train Loss: 2.3020, Val Loss: 2.3014
2024-12-29 14:40:03,143 - INFO - Epoch 2/10, Train Loss: 2.3007, Val Loss: 2.3002
2024-12-29 14:40:06,144 - INFO - Epoch 3/10, Train Loss: 2.2994, Val Loss: 2.2990
2024-12-29 14:40:09,279 - INFO - Epoch 4/10, Train Loss: 2.2981, Val Loss: 2.2978
2024-12-29 14:40:09,279 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:40:09,279 - INFO - Training completed in 13.08s
2024-12-29 14:40:09,279 - INFO - Final memory usage: CPU 2758.0 MB, GPU 126.5 MB
2024-12-29 14:40:09,280 - INFO - Model training completed in 13.08s
2024-12-29 14:40:09,574 - INFO - Prediction completed in 0.29s
2024-12-29 14:40:09,586 - INFO - Poison rate 0.2 completed in 13.39s
2024-12-29 14:40:09,596 - INFO - Loaded 532 existing results
2024-12-29 14:40:09,596 - INFO - Total results to save: 539
2024-12-29 14:40:09,597 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:40:09,614 - INFO - Saved 539 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:40:09,614 - INFO - Total evaluation time: 121.38s
2024-12-29 14:40:09,616 - INFO - 
Progress: 81.2% - Evaluating CIFAR100 with RandomForest (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:40:09,818 - INFO - Loading datasets...
2024-12-29 14:40:09,839 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:40:09,839 - INFO - Extracting validation features...
2024-12-29 14:40:09,839 - INFO - Extracting features from 3925 samples...
2024-12-29 14:40:19,449 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:40:19,455 - INFO - Validation feature extraction completed in 9.62s
2024-12-29 14:40:19,456 - INFO - Extracting training features...
2024-12-29 14:40:19,456 - INFO - Extracting features from 9469 samples...
2024-12-29 14:40:41,220 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:40:41,225 - INFO - Training feature extraction completed in 21.77s
2024-12-29 14:40:41,225 - INFO - Creating model for classifier: RandomForest
2024-12-29 14:40:41,226 - INFO - Using device: cuda
2024-12-29 14:40:41,226 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:40:41,226 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:40:41,227 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:40:41,764 - INFO - Feature scaling completed in 0.54s
2024-12-29 14:40:41,764 - INFO - Starting feature selection (k=50)
2024-12-29 14:40:41,774 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:40:41,774 - INFO - Starting anomaly detection
2024-12-29 14:40:45,754 - INFO - Anomaly detection completed in 3.98s
2024-12-29 14:40:45,754 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:40:45,754 - INFO - Total fit_transform time: 4.53s
2024-12-29 14:40:45,755 - INFO - Training set processing completed in 4.53s
2024-12-29 14:40:45,755 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:40:45,756 - INFO - Memory usage at start_fit: CPU 2758.0 MB, GPU 104.0 MB
2024-12-29 14:40:45,757 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:40:45,958 - INFO - Fitted scaler and transformed data
2024-12-29 14:40:45,958 - INFO - Scaling time: 0.20s
2024-12-29 14:40:45,967 - INFO - Number of unique classes: 10
2024-12-29 14:40:49,768 - INFO - Epoch 1/10, Train Loss: 2.1849, Val Loss: 2.3013
2024-12-29 14:40:52,555 - INFO - Epoch 2/10, Train Loss: 2.1836, Val Loss: 2.3000
2024-12-29 14:40:55,799 - INFO - Epoch 3/10, Train Loss: 2.1822, Val Loss: 2.2987
2024-12-29 14:40:58,915 - INFO - Epoch 4/10, Train Loss: 2.1808, Val Loss: 2.2973
2024-12-29 14:40:58,916 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:40:58,916 - INFO - Training completed in 13.16s
2024-12-29 14:40:58,916 - INFO - Final memory usage: CPU 2758.0 MB, GPU 125.9 MB
2024-12-29 14:40:58,916 - INFO - Model training completed in 13.16s
2024-12-29 14:40:59,090 - INFO - Prediction completed in 0.17s
2024-12-29 14:40:59,099 - INFO - Poison rate 0.0 completed in 17.87s
2024-12-29 14:40:59,099 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:40:59,100 - INFO - Total number of labels flipped: 88
2024-12-29 14:40:59,100 - INFO - Label flipping completed in 0.00s
2024-12-29 14:40:59,100 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:40:59,100 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:40:59,666 - INFO - Feature scaling completed in 0.57s
2024-12-29 14:40:59,666 - INFO - Starting feature selection (k=50)
2024-12-29 14:40:59,680 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:40:59,681 - INFO - Starting anomaly detection
2024-12-29 14:41:03,804 - INFO - Anomaly detection completed in 4.12s
2024-12-29 14:41:03,804 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:41:03,804 - INFO - Total fit_transform time: 4.70s
2024-12-29 14:41:03,804 - INFO - Training set processing completed in 4.70s
2024-12-29 14:41:03,804 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:41:03,806 - INFO - Memory usage at start_fit: CPU 2758.0 MB, GPU 106.0 MB
2024-12-29 14:41:03,806 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:41:04,009 - INFO - Fitted scaler and transformed data
2024-12-29 14:41:04,009 - INFO - Scaling time: 0.20s
2024-12-29 14:41:04,017 - INFO - Number of unique classes: 10
2024-12-29 14:41:06,862 - INFO - Epoch 1/10, Train Loss: 2.1862, Val Loss: 2.3013
2024-12-29 14:41:09,942 - INFO - Epoch 2/10, Train Loss: 2.1849, Val Loss: 2.3000
2024-12-29 14:41:13,246 - INFO - Epoch 3/10, Train Loss: 2.1835, Val Loss: 2.2987
2024-12-29 14:41:16,494 - INFO - Epoch 4/10, Train Loss: 2.1822, Val Loss: 2.2974
2024-12-29 14:41:16,494 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:41:16,494 - INFO - Training completed in 12.69s
2024-12-29 14:41:16,495 - INFO - Final memory usage: CPU 2758.0 MB, GPU 125.9 MB
2024-12-29 14:41:16,495 - INFO - Model training completed in 12.69s
2024-12-29 14:41:16,641 - INFO - Prediction completed in 0.15s
2024-12-29 14:41:16,649 - INFO - Poison rate 0.01 completed in 17.55s
2024-12-29 14:41:16,649 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:41:16,650 - INFO - Total number of labels flipped: 256
2024-12-29 14:41:16,650 - INFO - Label flipping completed in 0.00s
2024-12-29 14:41:16,650 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:41:16,650 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:41:17,149 - INFO - Feature scaling completed in 0.50s
2024-12-29 14:41:17,150 - INFO - Starting feature selection (k=50)
2024-12-29 14:41:17,162 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:41:17,162 - INFO - Starting anomaly detection
2024-12-29 14:41:19,589 - INFO - Anomaly detection completed in 2.43s
2024-12-29 14:41:19,589 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:41:19,589 - INFO - Total fit_transform time: 2.94s
2024-12-29 14:41:19,589 - INFO - Training set processing completed in 2.94s
2024-12-29 14:41:19,589 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:41:19,590 - INFO - Memory usage at start_fit: CPU 2758.0 MB, GPU 106.0 MB
2024-12-29 14:41:19,591 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:41:19,779 - INFO - Fitted scaler and transformed data
2024-12-29 14:41:19,779 - INFO - Scaling time: 0.19s
2024-12-29 14:41:19,786 - INFO - Number of unique classes: 10
2024-12-29 14:41:22,764 - INFO - Epoch 1/10, Train Loss: 2.1857, Val Loss: 2.3014
2024-12-29 14:41:26,429 - INFO - Epoch 2/10, Train Loss: 2.1844, Val Loss: 2.3001
2024-12-29 14:41:30,582 - INFO - Epoch 3/10, Train Loss: 2.1831, Val Loss: 2.2989
2024-12-29 14:41:33,735 - INFO - Epoch 4/10, Train Loss: 2.1818, Val Loss: 2.2976
2024-12-29 14:41:33,736 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:41:33,736 - INFO - Training completed in 14.15s
2024-12-29 14:41:33,736 - INFO - Final memory usage: CPU 2758.0 MB, GPU 125.9 MB
2024-12-29 14:41:33,736 - INFO - Model training completed in 14.15s
2024-12-29 14:41:33,899 - INFO - Prediction completed in 0.16s
2024-12-29 14:41:33,908 - INFO - Poison rate 0.03 completed in 17.26s
2024-12-29 14:41:33,908 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:41:33,909 - INFO - Total number of labels flipped: 426
2024-12-29 14:41:33,909 - INFO - Label flipping completed in 0.00s
2024-12-29 14:41:33,909 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:41:33,909 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:41:34,469 - INFO - Feature scaling completed in 0.56s
2024-12-29 14:41:34,469 - INFO - Starting feature selection (k=50)
2024-12-29 14:41:34,483 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:41:34,484 - INFO - Starting anomaly detection
2024-12-29 14:41:36,864 - INFO - Anomaly detection completed in 2.38s
2024-12-29 14:41:36,864 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:41:36,864 - INFO - Total fit_transform time: 2.96s
2024-12-29 14:41:36,864 - INFO - Training set processing completed in 2.96s
2024-12-29 14:41:36,864 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:41:36,865 - INFO - Memory usage at start_fit: CPU 2758.0 MB, GPU 106.0 MB
2024-12-29 14:41:36,865 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:41:37,039 - INFO - Fitted scaler and transformed data
2024-12-29 14:41:37,039 - INFO - Scaling time: 0.17s
2024-12-29 14:41:37,046 - INFO - Number of unique classes: 10
2024-12-29 14:41:39,923 - INFO - Epoch 1/10, Train Loss: 2.1878, Val Loss: 2.3014
2024-12-29 14:41:43,150 - INFO - Epoch 2/10, Train Loss: 2.1865, Val Loss: 2.3002
2024-12-29 14:41:45,875 - INFO - Epoch 3/10, Train Loss: 2.1853, Val Loss: 2.2990
2024-12-29 14:41:48,948 - INFO - Epoch 4/10, Train Loss: 2.1840, Val Loss: 2.2978
2024-12-29 14:41:48,948 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:41:48,948 - INFO - Training completed in 12.08s
2024-12-29 14:41:48,949 - INFO - Final memory usage: CPU 2758.0 MB, GPU 125.9 MB
2024-12-29 14:41:48,949 - INFO - Model training completed in 12.08s
2024-12-29 14:41:49,174 - INFO - Prediction completed in 0.23s
2024-12-29 14:41:49,183 - INFO - Poison rate 0.05 completed in 15.28s
2024-12-29 14:41:49,183 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:41:49,185 - INFO - Total number of labels flipped: 589
2024-12-29 14:41:49,185 - INFO - Label flipping completed in 0.00s
2024-12-29 14:41:49,185 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:41:49,185 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:41:49,730 - INFO - Feature scaling completed in 0.54s
2024-12-29 14:41:49,730 - INFO - Starting feature selection (k=50)
2024-12-29 14:41:49,743 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:41:49,743 - INFO - Starting anomaly detection
2024-12-29 14:41:53,861 - INFO - Anomaly detection completed in 4.12s
2024-12-29 14:41:53,861 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:41:53,861 - INFO - Total fit_transform time: 4.68s
2024-12-29 14:41:53,861 - INFO - Training set processing completed in 4.68s
2024-12-29 14:41:53,861 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:41:53,863 - INFO - Memory usage at start_fit: CPU 2758.0 MB, GPU 106.0 MB
2024-12-29 14:41:53,863 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:41:54,043 - INFO - Fitted scaler and transformed data
2024-12-29 14:41:54,044 - INFO - Scaling time: 0.18s
2024-12-29 14:41:54,050 - INFO - Number of unique classes: 10
2024-12-29 14:41:57,096 - INFO - Epoch 1/10, Train Loss: 2.1868, Val Loss: 2.3014
2024-12-29 14:42:00,090 - INFO - Epoch 2/10, Train Loss: 2.1855, Val Loss: 2.3003
2024-12-29 14:42:03,016 - INFO - Epoch 3/10, Train Loss: 2.1843, Val Loss: 2.2991
2024-12-29 14:42:05,773 - INFO - Epoch 4/10, Train Loss: 2.1830, Val Loss: 2.2979
2024-12-29 14:42:05,774 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:42:05,774 - INFO - Training completed in 11.91s
2024-12-29 14:42:05,774 - INFO - Final memory usage: CPU 2758.0 MB, GPU 125.9 MB
2024-12-29 14:42:05,774 - INFO - Model training completed in 11.91s
2024-12-29 14:42:05,929 - INFO - Prediction completed in 0.15s
2024-12-29 14:42:05,938 - INFO - Poison rate 0.07 completed in 16.75s
2024-12-29 14:42:05,938 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:42:05,939 - INFO - Total number of labels flipped: 857
2024-12-29 14:42:05,940 - INFO - Label flipping completed in 0.00s
2024-12-29 14:42:05,940 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:42:05,940 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:42:06,439 - INFO - Feature scaling completed in 0.50s
2024-12-29 14:42:06,440 - INFO - Starting feature selection (k=50)
2024-12-29 14:42:06,453 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:42:06,454 - INFO - Starting anomaly detection
2024-12-29 14:42:10,552 - INFO - Anomaly detection completed in 4.10s
2024-12-29 14:42:10,552 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:42:10,552 - INFO - Total fit_transform time: 4.61s
2024-12-29 14:42:10,552 - INFO - Training set processing completed in 4.61s
2024-12-29 14:42:10,553 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:42:10,553 - INFO - Memory usage at start_fit: CPU 2758.0 MB, GPU 106.0 MB
2024-12-29 14:42:10,553 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:42:10,727 - INFO - Fitted scaler and transformed data
2024-12-29 14:42:10,727 - INFO - Scaling time: 0.17s
2024-12-29 14:42:10,734 - INFO - Number of unique classes: 10
2024-12-29 14:42:13,955 - INFO - Epoch 1/10, Train Loss: 2.1885, Val Loss: 2.3015
2024-12-29 14:42:16,755 - INFO - Epoch 2/10, Train Loss: 2.1872, Val Loss: 2.3003
2024-12-29 14:42:19,691 - INFO - Epoch 3/10, Train Loss: 2.1860, Val Loss: 2.2992
2024-12-29 14:42:22,722 - INFO - Epoch 4/10, Train Loss: 2.1847, Val Loss: 2.2980
2024-12-29 14:42:22,722 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:42:22,722 - INFO - Training completed in 12.17s
2024-12-29 14:42:22,722 - INFO - Final memory usage: CPU 2758.0 MB, GPU 125.9 MB
2024-12-29 14:42:22,723 - INFO - Model training completed in 12.17s
2024-12-29 14:42:22,953 - INFO - Prediction completed in 0.23s
2024-12-29 14:42:22,962 - INFO - Poison rate 0.1 completed in 17.02s
2024-12-29 14:42:22,962 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:42:22,964 - INFO - Total number of labels flipped: 1704
2024-12-29 14:42:22,964 - INFO - Label flipping completed in 0.00s
2024-12-29 14:42:22,964 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:42:22,964 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:42:23,488 - INFO - Feature scaling completed in 0.52s
2024-12-29 14:42:23,488 - INFO - Starting feature selection (k=50)
2024-12-29 14:42:23,501 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:42:23,501 - INFO - Starting anomaly detection
2024-12-29 14:42:26,613 - INFO - Anomaly detection completed in 3.11s
2024-12-29 14:42:26,613 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:42:26,613 - INFO - Total fit_transform time: 3.65s
2024-12-29 14:42:26,613 - INFO - Training set processing completed in 3.65s
2024-12-29 14:42:26,613 - INFO - Fitting RandomForestWrapper model with data shape: (9469, 512)
2024-12-29 14:42:26,614 - INFO - Memory usage at start_fit: CPU 2758.0 MB, GPU 106.0 MB
2024-12-29 14:42:26,615 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:42:26,798 - INFO - Fitted scaler and transformed data
2024-12-29 14:42:26,799 - INFO - Scaling time: 0.18s
2024-12-29 14:42:26,805 - INFO - Number of unique classes: 10
2024-12-29 14:42:29,709 - INFO - Epoch 1/10, Train Loss: 2.1893, Val Loss: 2.3014
2024-12-29 14:42:32,551 - INFO - Epoch 2/10, Train Loss: 2.1880, Val Loss: 2.3002
2024-12-29 14:42:35,931 - INFO - Epoch 3/10, Train Loss: 2.1867, Val Loss: 2.2990
2024-12-29 14:42:39,153 - INFO - Epoch 4/10, Train Loss: 2.1855, Val Loss: 2.2978
2024-12-29 14:42:39,153 - INFO - Early stopping triggered at epoch 4
2024-12-29 14:42:39,154 - INFO - Training completed in 12.54s
2024-12-29 14:42:39,154 - INFO - Final memory usage: CPU 2758.0 MB, GPU 125.9 MB
2024-12-29 14:42:39,154 - INFO - Model training completed in 12.54s
2024-12-29 14:42:39,365 - INFO - Prediction completed in 0.21s
2024-12-29 14:42:39,380 - INFO - Poison rate 0.2 completed in 16.42s
2024-12-29 14:42:39,390 - INFO - Loaded 539 existing results
2024-12-29 14:42:39,391 - INFO - Total results to save: 546
2024-12-29 14:42:39,392 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:42:39,408 - INFO - Saved 546 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:42:39,409 - INFO - Total evaluation time: 149.59s
2024-12-29 14:42:39,411 - INFO - 
Progress: 82.3% - Evaluating CIFAR100 with KNeighbors (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:42:39,668 - INFO - Loading datasets...
2024-12-29 14:42:39,693 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:42:39,693 - INFO - Extracting validation features...
2024-12-29 14:42:39,693 - INFO - Extracting features from 3925 samples...
2024-12-29 14:42:48,971 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:42:48,977 - INFO - Validation feature extraction completed in 9.28s
2024-12-29 14:42:48,977 - INFO - Extracting training features...
2024-12-29 14:42:48,978 - INFO - Extracting features from 9469 samples...
2024-12-29 14:43:10,470 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:43:10,475 - INFO - Training feature extraction completed in 21.50s
2024-12-29 14:43:10,475 - INFO - Creating model for classifier: KNeighbors
2024-12-29 14:43:10,476 - INFO - Using device: cuda
2024-12-29 14:43:10,476 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:43:10,477 - INFO - Training set processing completed in 0.00s
2024-12-29 14:43:10,477 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:43:10,479 - INFO - Memory usage at start_fit: CPU 2730.6 MB, GPU 104.6 MB
2024-12-29 14:43:10,479 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:43:10,675 - INFO - Fitted scaler and transformed data
2024-12-29 14:43:10,675 - INFO - Scaling time: 0.20s
2024-12-29 14:43:10,685 - INFO - Training completed in 0.21s
2024-12-29 14:43:10,686 - INFO - Final memory usage: CPU 2758.1 MB, GPU 123.2 MB
2024-12-29 14:43:10,686 - INFO - Model training completed in 0.21s
2024-12-29 14:43:10,754 - INFO - Prediction completed in 0.07s
2024-12-29 14:43:10,763 - INFO - Poison rate 0.0 completed in 0.29s
2024-12-29 14:43:10,764 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:43:10,765 - INFO - Total number of labels flipped: 88
2024-12-29 14:43:10,765 - INFO - Label flipping completed in 0.00s
2024-12-29 14:43:10,765 - INFO - Training set processing completed in 0.00s
2024-12-29 14:43:10,765 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:43:10,766 - INFO - Memory usage at start_fit: CPU 2758.2 MB, GPU 123.2 MB
2024-12-29 14:43:10,766 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:43:10,995 - INFO - Fitted scaler and transformed data
2024-12-29 14:43:10,995 - INFO - Scaling time: 0.23s
2024-12-29 14:43:11,003 - INFO - Training completed in 0.24s
2024-12-29 14:43:11,003 - INFO - Final memory usage: CPU 2760.3 MB, GPU 123.2 MB
2024-12-29 14:43:11,003 - INFO - Model training completed in 0.24s
2024-12-29 14:43:11,075 - INFO - Prediction completed in 0.07s
2024-12-29 14:43:11,083 - INFO - Poison rate 0.01 completed in 0.32s
2024-12-29 14:43:11,083 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:43:11,084 - INFO - Total number of labels flipped: 260
2024-12-29 14:43:11,084 - INFO - Label flipping completed in 0.00s
2024-12-29 14:43:11,085 - INFO - Training set processing completed in 0.00s
2024-12-29 14:43:11,085 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:43:11,085 - INFO - Memory usage at start_fit: CPU 2760.3 MB, GPU 123.2 MB
2024-12-29 14:43:11,086 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:43:11,256 - INFO - Fitted scaler and transformed data
2024-12-29 14:43:11,256 - INFO - Scaling time: 0.17s
2024-12-29 14:43:11,263 - INFO - Training completed in 0.18s
2024-12-29 14:43:11,264 - INFO - Final memory usage: CPU 2768.0 MB, GPU 123.2 MB
2024-12-29 14:43:11,265 - INFO - Model training completed in 0.18s
2024-12-29 14:43:11,333 - INFO - Prediction completed in 0.07s
2024-12-29 14:43:11,342 - INFO - Poison rate 0.03 completed in 0.26s
2024-12-29 14:43:11,342 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:43:11,343 - INFO - Total number of labels flipped: 424
2024-12-29 14:43:11,343 - INFO - Label flipping completed in 0.00s
2024-12-29 14:43:11,343 - INFO - Training set processing completed in 0.00s
2024-12-29 14:43:11,343 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:43:11,344 - INFO - Memory usage at start_fit: CPU 2730.4 MB, GPU 123.2 MB
2024-12-29 14:43:11,344 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:43:11,531 - INFO - Fitted scaler and transformed data
2024-12-29 14:43:11,531 - INFO - Scaling time: 0.19s
2024-12-29 14:43:11,538 - INFO - Training completed in 0.19s
2024-12-29 14:43:11,539 - INFO - Final memory usage: CPU 2758.0 MB, GPU 123.2 MB
2024-12-29 14:43:11,539 - INFO - Model training completed in 0.20s
2024-12-29 14:43:11,607 - INFO - Prediction completed in 0.07s
2024-12-29 14:43:11,616 - INFO - Poison rate 0.05 completed in 0.27s
2024-12-29 14:43:11,616 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:43:11,617 - INFO - Total number of labels flipped: 600
2024-12-29 14:43:11,617 - INFO - Label flipping completed in 0.00s
2024-12-29 14:43:11,617 - INFO - Training set processing completed in 0.00s
2024-12-29 14:43:11,617 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:43:11,618 - INFO - Memory usage at start_fit: CPU 2758.0 MB, GPU 123.2 MB
2024-12-29 14:43:11,618 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:43:11,797 - INFO - Fitted scaler and transformed data
2024-12-29 14:43:11,797 - INFO - Scaling time: 0.18s
2024-12-29 14:43:11,804 - INFO - Training completed in 0.19s
2024-12-29 14:43:11,804 - INFO - Final memory usage: CPU 2758.1 MB, GPU 123.2 MB
2024-12-29 14:43:11,804 - INFO - Model training completed in 0.19s
2024-12-29 14:43:11,876 - INFO - Prediction completed in 0.07s
2024-12-29 14:43:11,884 - INFO - Poison rate 0.07 completed in 0.27s
2024-12-29 14:43:11,885 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:43:11,886 - INFO - Total number of labels flipped: 865
2024-12-29 14:43:11,886 - INFO - Label flipping completed in 0.00s
2024-12-29 14:43:11,886 - INFO - Training set processing completed in 0.00s
2024-12-29 14:43:11,886 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:43:11,887 - INFO - Memory usage at start_fit: CPU 2758.1 MB, GPU 123.2 MB
2024-12-29 14:43:11,887 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:43:12,056 - INFO - Fitted scaler and transformed data
2024-12-29 14:43:12,056 - INFO - Scaling time: 0.17s
2024-12-29 14:43:12,063 - INFO - Training completed in 0.18s
2024-12-29 14:43:12,063 - INFO - Final memory usage: CPU 2758.1 MB, GPU 123.2 MB
2024-12-29 14:43:12,063 - INFO - Model training completed in 0.18s
2024-12-29 14:43:12,161 - INFO - Prediction completed in 0.10s
2024-12-29 14:43:12,169 - INFO - Poison rate 0.1 completed in 0.28s
2024-12-29 14:43:12,169 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:43:12,171 - INFO - Total number of labels flipped: 1706
2024-12-29 14:43:12,171 - INFO - Label flipping completed in 0.00s
2024-12-29 14:43:12,171 - INFO - Training set processing completed in 0.00s
2024-12-29 14:43:12,171 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:43:12,172 - INFO - Memory usage at start_fit: CPU 2758.1 MB, GPU 123.2 MB
2024-12-29 14:43:12,172 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:43:12,340 - INFO - Fitted scaler and transformed data
2024-12-29 14:43:12,341 - INFO - Scaling time: 0.17s
2024-12-29 14:43:12,348 - INFO - Training completed in 0.18s
2024-12-29 14:43:12,349 - INFO - Final memory usage: CPU 2760.6 MB, GPU 123.2 MB
2024-12-29 14:43:12,349 - INFO - Model training completed in 0.18s
2024-12-29 14:43:12,421 - INFO - Prediction completed in 0.07s
2024-12-29 14:43:12,430 - INFO - Poison rate 0.2 completed in 0.26s
2024-12-29 14:43:12,441 - INFO - Loaded 546 existing results
2024-12-29 14:43:12,441 - INFO - Total results to save: 553
2024-12-29 14:43:12,442 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:43:12,459 - INFO - Saved 553 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:43:12,460 - INFO - Total evaluation time: 32.79s
2024-12-29 14:43:12,461 - INFO - 
Progress: 83.3% - Evaluating CIFAR100 with KNeighbors (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:43:12,629 - INFO - Loading datasets...
2024-12-29 14:43:12,650 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:43:12,650 - INFO - Extracting validation features...
2024-12-29 14:43:12,650 - INFO - Extracting features from 3925 samples...
2024-12-29 14:43:22,126 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:43:22,131 - INFO - Validation feature extraction completed in 9.48s
2024-12-29 14:43:22,131 - INFO - Extracting training features...
2024-12-29 14:43:22,131 - INFO - Extracting features from 9469 samples...
2024-12-29 14:43:44,594 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:43:44,599 - INFO - Training feature extraction completed in 22.47s
2024-12-29 14:43:44,600 - INFO - Creating model for classifier: KNeighbors
2024-12-29 14:43:44,600 - INFO - Using device: cuda
2024-12-29 14:43:44,600 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:43:44,601 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:43:44,601 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:43:45,108 - INFO - Feature scaling completed in 0.51s
2024-12-29 14:43:45,108 - INFO - Starting feature selection (k=50)
2024-12-29 14:43:45,123 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:43:45,123 - INFO - Starting anomaly detection
2024-12-29 14:43:48,723 - INFO - Anomaly detection completed in 3.60s
2024-12-29 14:43:48,723 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:43:48,723 - INFO - Total fit_transform time: 4.12s
2024-12-29 14:43:48,723 - INFO - Training set processing completed in 4.12s
2024-12-29 14:43:48,723 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:43:48,724 - INFO - Memory usage at start_fit: CPU 2758.2 MB, GPU 104.0 MB
2024-12-29 14:43:48,725 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:43:48,895 - INFO - Fitted scaler and transformed data
2024-12-29 14:43:48,896 - INFO - Scaling time: 0.17s
2024-12-29 14:43:48,903 - INFO - Training completed in 0.18s
2024-12-29 14:43:48,903 - INFO - Final memory usage: CPU 2758.2 MB, GPU 122.6 MB
2024-12-29 14:43:48,903 - INFO - Model training completed in 0.18s
2024-12-29 14:43:49,003 - INFO - Prediction completed in 0.10s
2024-12-29 14:43:49,012 - INFO - Poison rate 0.0 completed in 4.41s
2024-12-29 14:43:49,012 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:43:49,013 - INFO - Total number of labels flipped: 86
2024-12-29 14:43:49,013 - INFO - Label flipping completed in 0.00s
2024-12-29 14:43:49,013 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:43:49,013 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:43:49,523 - INFO - Feature scaling completed in 0.51s
2024-12-29 14:43:49,523 - INFO - Starting feature selection (k=50)
2024-12-29 14:43:49,535 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:43:49,535 - INFO - Starting anomaly detection
2024-12-29 14:43:53,124 - INFO - Anomaly detection completed in 3.59s
2024-12-29 14:43:53,124 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:43:53,124 - INFO - Total fit_transform time: 4.11s
2024-12-29 14:43:53,124 - INFO - Training set processing completed in 4.11s
2024-12-29 14:43:53,124 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:43:53,126 - INFO - Memory usage at start_fit: CPU 2758.2 MB, GPU 122.6 MB
2024-12-29 14:43:53,126 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:43:53,307 - INFO - Fitted scaler and transformed data
2024-12-29 14:43:53,307 - INFO - Scaling time: 0.18s
2024-12-29 14:43:53,314 - INFO - Training completed in 0.19s
2024-12-29 14:43:53,314 - INFO - Final memory usage: CPU 2758.2 MB, GPU 122.6 MB
2024-12-29 14:43:53,314 - INFO - Model training completed in 0.19s
2024-12-29 14:43:53,413 - INFO - Prediction completed in 0.10s
2024-12-29 14:43:53,422 - INFO - Poison rate 0.01 completed in 4.41s
2024-12-29 14:43:53,422 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:43:53,423 - INFO - Total number of labels flipped: 261
2024-12-29 14:43:53,423 - INFO - Label flipping completed in 0.00s
2024-12-29 14:43:53,423 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:43:53,423 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:43:53,971 - INFO - Feature scaling completed in 0.55s
2024-12-29 14:43:53,971 - INFO - Starting feature selection (k=50)
2024-12-29 14:43:53,982 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:43:53,982 - INFO - Starting anomaly detection
2024-12-29 14:43:56,102 - INFO - Anomaly detection completed in 2.12s
2024-12-29 14:43:56,102 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:43:56,102 - INFO - Total fit_transform time: 2.68s
2024-12-29 14:43:56,102 - INFO - Training set processing completed in 2.68s
2024-12-29 14:43:56,102 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:43:56,103 - INFO - Memory usage at start_fit: CPU 2760.5 MB, GPU 122.6 MB
2024-12-29 14:43:56,103 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:43:56,280 - INFO - Fitted scaler and transformed data
2024-12-29 14:43:56,281 - INFO - Scaling time: 0.18s
2024-12-29 14:43:56,288 - INFO - Training completed in 0.19s
2024-12-29 14:43:56,288 - INFO - Final memory usage: CPU 2760.5 MB, GPU 122.6 MB
2024-12-29 14:43:56,288 - INFO - Model training completed in 0.19s
2024-12-29 14:43:56,386 - INFO - Prediction completed in 0.10s
2024-12-29 14:43:56,394 - INFO - Poison rate 0.03 completed in 2.97s
2024-12-29 14:43:56,394 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:43:56,395 - INFO - Total number of labels flipped: 430
2024-12-29 14:43:56,396 - INFO - Label flipping completed in 0.00s
2024-12-29 14:43:56,396 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:43:56,396 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:43:56,963 - INFO - Feature scaling completed in 0.57s
2024-12-29 14:43:56,964 - INFO - Starting feature selection (k=50)
2024-12-29 14:43:56,972 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:43:56,972 - INFO - Starting anomaly detection
2024-12-29 14:43:59,302 - INFO - Anomaly detection completed in 2.33s
2024-12-29 14:43:59,302 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:43:59,303 - INFO - Total fit_transform time: 2.91s
2024-12-29 14:43:59,303 - INFO - Training set processing completed in 2.91s
2024-12-29 14:43:59,303 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:43:59,304 - INFO - Memory usage at start_fit: CPU 2760.5 MB, GPU 122.6 MB
2024-12-29 14:43:59,305 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:43:59,504 - INFO - Fitted scaler and transformed data
2024-12-29 14:43:59,504 - INFO - Scaling time: 0.20s
2024-12-29 14:43:59,511 - INFO - Training completed in 0.21s
2024-12-29 14:43:59,511 - INFO - Final memory usage: CPU 2760.5 MB, GPU 122.6 MB
2024-12-29 14:43:59,511 - INFO - Model training completed in 0.21s
2024-12-29 14:43:59,607 - INFO - Prediction completed in 0.10s
2024-12-29 14:43:59,615 - INFO - Poison rate 0.05 completed in 3.22s
2024-12-29 14:43:59,615 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:43:59,616 - INFO - Total number of labels flipped: 590
2024-12-29 14:43:59,617 - INFO - Label flipping completed in 0.00s
2024-12-29 14:43:59,617 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:43:59,617 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:44:00,167 - INFO - Feature scaling completed in 0.55s
2024-12-29 14:44:00,168 - INFO - Starting feature selection (k=50)
2024-12-29 14:44:00,175 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:44:00,176 - INFO - Starting anomaly detection
2024-12-29 14:44:03,943 - INFO - Anomaly detection completed in 3.77s
2024-12-29 14:44:03,943 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:44:03,944 - INFO - Total fit_transform time: 4.33s
2024-12-29 14:44:03,944 - INFO - Training set processing completed in 4.33s
2024-12-29 14:44:03,944 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:44:03,945 - INFO - Memory usage at start_fit: CPU 2760.5 MB, GPU 122.6 MB
2024-12-29 14:44:03,945 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:44:04,130 - INFO - Fitted scaler and transformed data
2024-12-29 14:44:04,130 - INFO - Scaling time: 0.18s
2024-12-29 14:44:04,138 - INFO - Training completed in 0.19s
2024-12-29 14:44:04,139 - INFO - Final memory usage: CPU 2760.5 MB, GPU 122.6 MB
2024-12-29 14:44:04,139 - INFO - Model training completed in 0.20s
2024-12-29 14:44:04,240 - INFO - Prediction completed in 0.10s
2024-12-29 14:44:04,248 - INFO - Poison rate 0.07 completed in 4.63s
2024-12-29 14:44:04,249 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:44:04,250 - INFO - Total number of labels flipped: 843
2024-12-29 14:44:04,250 - INFO - Label flipping completed in 0.00s
2024-12-29 14:44:04,250 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:44:04,250 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:44:04,789 - INFO - Feature scaling completed in 0.54s
2024-12-29 14:44:04,789 - INFO - Starting feature selection (k=50)
2024-12-29 14:44:04,798 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:44:04,798 - INFO - Starting anomaly detection
2024-12-29 14:44:08,491 - INFO - Anomaly detection completed in 3.69s
2024-12-29 14:44:08,491 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:44:08,491 - INFO - Total fit_transform time: 4.24s
2024-12-29 14:44:08,491 - INFO - Training set processing completed in 4.24s
2024-12-29 14:44:08,491 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:44:08,492 - INFO - Memory usage at start_fit: CPU 2760.5 MB, GPU 122.6 MB
2024-12-29 14:44:08,492 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:44:08,667 - INFO - Fitted scaler and transformed data
2024-12-29 14:44:08,667 - INFO - Scaling time: 0.18s
2024-12-29 14:44:08,674 - INFO - Training completed in 0.18s
2024-12-29 14:44:08,675 - INFO - Final memory usage: CPU 2760.5 MB, GPU 122.6 MB
2024-12-29 14:44:08,675 - INFO - Model training completed in 0.18s
2024-12-29 14:44:08,736 - INFO - Prediction completed in 0.06s
2024-12-29 14:44:08,745 - INFO - Poison rate 0.1 completed in 4.50s
2024-12-29 14:44:08,745 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:44:08,747 - INFO - Total number of labels flipped: 1719
2024-12-29 14:44:08,747 - INFO - Label flipping completed in 0.00s
2024-12-29 14:44:08,747 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:44:08,747 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:44:09,245 - INFO - Feature scaling completed in 0.50s
2024-12-29 14:44:09,245 - INFO - Starting feature selection (k=50)
2024-12-29 14:44:09,254 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:44:09,254 - INFO - Starting anomaly detection
2024-12-29 14:44:11,476 - INFO - Anomaly detection completed in 2.22s
2024-12-29 14:44:11,476 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:44:11,476 - INFO - Total fit_transform time: 2.73s
2024-12-29 14:44:11,476 - INFO - Training set processing completed in 2.73s
2024-12-29 14:44:11,476 - INFO - Fitting KNeighborsWrapper model with data shape: (9469, 512)
2024-12-29 14:44:11,477 - INFO - Memory usage at start_fit: CPU 2760.5 MB, GPU 122.6 MB
2024-12-29 14:44:11,477 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:44:11,662 - INFO - Fitted scaler and transformed data
2024-12-29 14:44:11,662 - INFO - Scaling time: 0.18s
2024-12-29 14:44:11,669 - INFO - Training completed in 0.19s
2024-12-29 14:44:11,669 - INFO - Final memory usage: CPU 2760.5 MB, GPU 122.6 MB
2024-12-29 14:44:11,669 - INFO - Model training completed in 0.19s
2024-12-29 14:44:11,771 - INFO - Prediction completed in 0.10s
2024-12-29 14:44:11,780 - INFO - Poison rate 0.2 completed in 3.04s
2024-12-29 14:44:11,791 - INFO - Loaded 553 existing results
2024-12-29 14:44:11,792 - INFO - Total results to save: 560
2024-12-29 14:44:11,793 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:44:11,810 - INFO - Saved 560 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:44:11,811 - INFO - Total evaluation time: 59.18s
2024-12-29 14:44:11,812 - INFO - Completed evaluation for CIFAR100
2024-12-29 14:44:11,812 - INFO - 
Processing dataset: CIFAR100
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:44:11,999 - INFO - 
Progress: 84.4% - Evaluating CIFAR100 with SVM (standard mode, iteration 1/1)
2024-12-29 14:44:12,171 - INFO - Loading datasets...
2024-12-29 14:44:12,193 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:44:12,193 - INFO - Extracting validation features...
2024-12-29 14:44:12,193 - INFO - Extracting features from 3925 samples...
2024-12-29 14:44:21,586 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:44:21,592 - INFO - Validation feature extraction completed in 9.40s
2024-12-29 14:44:21,593 - INFO - Extracting training features...
2024-12-29 14:44:21,593 - INFO - Extracting features from 9469 samples...
2024-12-29 14:44:43,287 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:44:43,292 - INFO - Training feature extraction completed in 21.70s
2024-12-29 14:44:43,292 - INFO - Creating model for classifier: SVM
2024-12-29 14:44:43,293 - INFO - Using device: cuda
2024-12-29 14:44:43,293 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-29 14:44:43,293 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:44:43,294 - INFO - Training set processing completed in 0.00s
2024-12-29 14:44:43,294 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:44:43,296 - INFO - Memory usage at start_fit: CPU 2730.6 MB, GPU 104.6 MB
2024-12-29 14:44:43,296 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:44:43,301 - INFO - Number of unique classes: 10
2024-12-29 14:44:43,372 - INFO - Fitted scaler and transformed data
2024-12-29 14:44:43,372 - INFO - Scaling time: 0.07s
2024-12-29 14:44:43,726 - INFO - Epoch 1/500, Train Loss: 0.8786, Val Loss: 0.1315
2024-12-29 14:44:44,043 - INFO - Epoch 2/500, Train Loss: 0.0960, Val Loss: 0.1043
2024-12-29 14:44:44,355 - INFO - Epoch 3/500, Train Loss: 0.0624, Val Loss: 0.0934
2024-12-29 14:44:44,665 - INFO - Epoch 4/500, Train Loss: 0.0445, Val Loss: 0.0873
2024-12-29 14:44:45,007 - INFO - Epoch 5/500, Train Loss: 0.0331, Val Loss: 0.0834
2024-12-29 14:44:45,291 - INFO - Epoch 6/500, Train Loss: 0.0263, Val Loss: 0.0830
2024-12-29 14:44:45,581 - INFO - Epoch 7/500, Train Loss: 0.0218, Val Loss: 0.0812
2024-12-29 14:44:45,898 - INFO - Epoch 8/500, Train Loss: 0.0178, Val Loss: 0.0806
2024-12-29 14:44:46,185 - INFO - Epoch 9/500, Train Loss: 0.0150, Val Loss: 0.0799
2024-12-29 14:44:46,510 - INFO - Epoch 10/500, Train Loss: 0.0126, Val Loss: 0.0800
2024-12-29 14:44:46,839 - INFO - Epoch 11/500, Train Loss: 0.0109, Val Loss: 0.0791
2024-12-29 14:44:47,167 - INFO - Epoch 12/500, Train Loss: 0.0094, Val Loss: 0.0810
2024-12-29 14:44:47,500 - INFO - Epoch 13/500, Train Loss: 0.0086, Val Loss: 0.0806
2024-12-29 14:44:47,820 - INFO - Epoch 14/500, Train Loss: 0.0073, Val Loss: 0.0800
2024-12-29 14:44:47,821 - INFO - Early stopping triggered at epoch 14
2024-12-29 14:44:47,821 - INFO - Training completed in 4.53s
2024-12-29 14:44:47,821 - INFO - Final memory usage: CPU 2767.5 MB, GPU 104.8 MB
2024-12-29 14:44:47,822 - INFO - Model training completed in 4.53s
2024-12-29 14:44:47,866 - INFO - Prediction completed in 0.04s
2024-12-29 14:44:47,876 - INFO - Poison rate 0.0 completed in 4.58s
2024-12-29 14:44:47,876 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:44:47,876 - INFO - Label flipping details:
2024-12-29 14:44:47,877 - INFO - - Source class: 1
2024-12-29 14:44:47,877 - INFO - - Target class: 0
2024-12-29 14:44:47,877 - INFO - - Available samples in source class: 955
2024-12-29 14:44:47,877 - INFO - - Requested samples to poison: 94
2024-12-29 14:44:47,877 - INFO - - Actual samples to flip: 94
2024-12-29 14:44:47,877 - INFO - - Samples remaining in source class: 861
2024-12-29 14:44:47,877 - INFO - Successfully flipped 94 labels from class 1 to 0
2024-12-29 14:44:47,877 - INFO - Total number of labels flipped: 94
2024-12-29 14:44:47,877 - INFO - Label flipping completed in 0.00s
2024-12-29 14:44:47,877 - INFO - Training set processing completed in 0.00s
2024-12-29 14:44:47,877 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:44:47,878 - INFO - Memory usage at start_fit: CPU 2738.3 MB, GPU 104.7 MB
2024-12-29 14:44:47,878 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:44:47,882 - INFO - Number of unique classes: 10
2024-12-29 14:44:47,951 - INFO - Fitted scaler and transformed data
2024-12-29 14:44:47,952 - INFO - Scaling time: 0.07s
2024-12-29 14:44:48,339 - INFO - Epoch 1/500, Train Loss: 1.0057, Val Loss: 0.1575
2024-12-29 14:44:48,701 - INFO - Epoch 2/500, Train Loss: 0.1315, Val Loss: 0.1123
2024-12-29 14:44:49,110 - INFO - Epoch 3/500, Train Loss: 0.0954, Val Loss: 0.0940
2024-12-29 14:44:49,509 - INFO - Epoch 4/500, Train Loss: 0.0751, Val Loss: 0.0866
2024-12-29 14:44:49,826 - INFO - Epoch 5/500, Train Loss: 0.0626, Val Loss: 0.0860
2024-12-29 14:44:50,145 - INFO - Epoch 6/500, Train Loss: 0.0544, Val Loss: 0.0813
2024-12-29 14:44:50,487 - INFO - Epoch 7/500, Train Loss: 0.0483, Val Loss: 0.0812
2024-12-29 14:44:50,874 - INFO - Epoch 8/500, Train Loss: 0.0441, Val Loss: 0.0816
2024-12-29 14:44:51,231 - INFO - Epoch 9/500, Train Loss: 0.0400, Val Loss: 0.0833
2024-12-29 14:44:51,571 - INFO - Epoch 10/500, Train Loss: 0.0376, Val Loss: 0.0834
2024-12-29 14:44:51,892 - INFO - Epoch 11/500, Train Loss: 0.0348, Val Loss: 0.0870
2024-12-29 14:44:51,892 - INFO - Early stopping triggered at epoch 11
2024-12-29 14:44:51,892 - INFO - Training completed in 4.01s
2024-12-29 14:44:51,893 - INFO - Final memory usage: CPU 2767.2 MB, GPU 104.8 MB
2024-12-29 14:44:51,894 - INFO - Model training completed in 4.02s
2024-12-29 14:44:51,938 - INFO - Prediction completed in 0.04s
2024-12-29 14:44:51,946 - INFO - Poison rate 0.01 completed in 4.07s
2024-12-29 14:44:51,947 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:44:51,947 - INFO - Label flipping details:
2024-12-29 14:44:51,947 - INFO - - Source class: 1
2024-12-29 14:44:51,947 - INFO - - Target class: 0
2024-12-29 14:44:51,947 - INFO - - Available samples in source class: 955
2024-12-29 14:44:51,947 - INFO - - Requested samples to poison: 284
2024-12-29 14:44:51,947 - INFO - - Actual samples to flip: 284
2024-12-29 14:44:51,947 - INFO - - Samples remaining in source class: 671
2024-12-29 14:44:51,948 - INFO - Successfully flipped 284 labels from class 1 to 0
2024-12-29 14:44:51,948 - INFO - Total number of labels flipped: 284
2024-12-29 14:44:51,948 - INFO - Label flipping completed in 0.00s
2024-12-29 14:44:51,948 - INFO - Training set processing completed in 0.00s
2024-12-29 14:44:51,948 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:44:51,949 - INFO - Memory usage at start_fit: CPU 2737.9 MB, GPU 104.7 MB
2024-12-29 14:44:51,949 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:44:51,952 - INFO - Number of unique classes: 10
2024-12-29 14:44:52,023 - INFO - Fitted scaler and transformed data
2024-12-29 14:44:52,023 - INFO - Scaling time: 0.07s
2024-12-29 14:44:52,364 - INFO - Epoch 1/500, Train Loss: 0.8896, Val Loss: 0.1400
2024-12-29 14:44:52,711 - INFO - Epoch 2/500, Train Loss: 0.1679, Val Loss: 0.1192
2024-12-29 14:44:53,039 - INFO - Epoch 3/500, Train Loss: 0.1342, Val Loss: 0.1118
2024-12-29 14:44:53,378 - INFO - Epoch 4/500, Train Loss: 0.1157, Val Loss: 0.1041
2024-12-29 14:44:53,735 - INFO - Epoch 5/500, Train Loss: 0.1031, Val Loss: 0.1019
2024-12-29 14:44:54,128 - INFO - Epoch 6/500, Train Loss: 0.0939, Val Loss: 0.1005
2024-12-29 14:44:54,454 - INFO - Epoch 7/500, Train Loss: 0.0887, Val Loss: 0.1017
2024-12-29 14:44:54,795 - INFO - Epoch 8/500, Train Loss: 0.0827, Val Loss: 0.0990
2024-12-29 14:44:55,136 - INFO - Epoch 9/500, Train Loss: 0.0791, Val Loss: 0.1023
2024-12-29 14:44:55,468 - INFO - Epoch 10/500, Train Loss: 0.0756, Val Loss: 0.1000
2024-12-29 14:44:55,799 - INFO - Epoch 11/500, Train Loss: 0.0731, Val Loss: 0.1050
2024-12-29 14:44:56,178 - INFO - Epoch 12/500, Train Loss: 0.0719, Val Loss: 0.0979
2024-12-29 14:44:56,526 - INFO - Epoch 13/500, Train Loss: 0.0678, Val Loss: 0.1031
2024-12-29 14:44:56,843 - INFO - Epoch 14/500, Train Loss: 0.0683, Val Loss: 0.1035
2024-12-29 14:44:57,210 - INFO - Epoch 15/500, Train Loss: 0.0655, Val Loss: 0.1048
2024-12-29 14:44:57,543 - INFO - Epoch 16/500, Train Loss: 0.0648, Val Loss: 0.1054
2024-12-29 14:44:57,887 - INFO - Epoch 17/500, Train Loss: 0.0636, Val Loss: 0.1071
2024-12-29 14:44:57,888 - INFO - Early stopping triggered at epoch 17
2024-12-29 14:44:57,888 - INFO - Training completed in 5.94s
2024-12-29 14:44:57,888 - INFO - Final memory usage: CPU 2767.4 MB, GPU 104.8 MB
2024-12-29 14:44:57,889 - INFO - Model training completed in 5.94s
2024-12-29 14:44:57,949 - INFO - Prediction completed in 0.06s
2024-12-29 14:44:57,972 - INFO - Poison rate 0.03 completed in 6.03s
2024-12-29 14:44:57,973 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:44:57,974 - INFO - Label flipping details:
2024-12-29 14:44:57,974 - INFO - - Source class: 1
2024-12-29 14:44:57,974 - INFO - - Target class: 0
2024-12-29 14:44:57,974 - INFO - - Available samples in source class: 955
2024-12-29 14:44:57,974 - INFO - - Requested samples to poison: 473
2024-12-29 14:44:57,974 - INFO - - Actual samples to flip: 473
2024-12-29 14:44:57,974 - INFO - - Samples remaining in source class: 482
2024-12-29 14:44:57,974 - INFO - Successfully flipped 473 labels from class 1 to 0
2024-12-29 14:44:57,975 - INFO - Total number of labels flipped: 473
2024-12-29 14:44:57,975 - INFO - Label flipping completed in 0.00s
2024-12-29 14:44:57,975 - INFO - Training set processing completed in 0.00s
2024-12-29 14:44:57,975 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:44:57,976 - INFO - Memory usage at start_fit: CPU 2738.3 MB, GPU 104.7 MB
2024-12-29 14:44:57,976 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:44:57,979 - INFO - Number of unique classes: 10
2024-12-29 14:44:58,047 - INFO - Fitted scaler and transformed data
2024-12-29 14:44:58,048 - INFO - Scaling time: 0.07s
2024-12-29 14:44:58,398 - INFO - Epoch 1/500, Train Loss: 0.7934, Val Loss: 0.1827
2024-12-29 14:44:58,717 - INFO - Epoch 2/500, Train Loss: 0.1891, Val Loss: 0.1625
2024-12-29 14:44:59,058 - INFO - Epoch 3/500, Train Loss: 0.1571, Val Loss: 0.1515
2024-12-29 14:44:59,384 - INFO - Epoch 4/500, Train Loss: 0.1354, Val Loss: 0.1489
2024-12-29 14:44:59,718 - INFO - Epoch 5/500, Train Loss: 0.1228, Val Loss: 0.1462
2024-12-29 14:45:00,044 - INFO - Epoch 6/500, Train Loss: 0.1132, Val Loss: 0.1512
2024-12-29 14:45:00,372 - INFO - Epoch 7/500, Train Loss: 0.1062, Val Loss: 0.1526
2024-12-29 14:45:00,721 - INFO - Epoch 8/500, Train Loss: 0.1003, Val Loss: 0.1548
2024-12-29 14:45:01,037 - INFO - Epoch 9/500, Train Loss: 0.0949, Val Loss: 0.1516
2024-12-29 14:45:01,382 - INFO - Epoch 10/500, Train Loss: 0.0919, Val Loss: 0.1539
2024-12-29 14:45:01,382 - INFO - Early stopping triggered at epoch 10
2024-12-29 14:45:01,382 - INFO - Training completed in 3.41s
2024-12-29 14:45:01,382 - INFO - Final memory usage: CPU 2767.8 MB, GPU 104.8 MB
2024-12-29 14:45:01,383 - INFO - Model training completed in 3.41s
2024-12-29 14:45:01,432 - INFO - Prediction completed in 0.05s
2024-12-29 14:45:01,440 - INFO - Poison rate 0.05 completed in 3.47s
2024-12-29 14:45:01,440 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:45:01,441 - INFO - Label flipping details:
2024-12-29 14:45:01,441 - INFO - - Source class: 1
2024-12-29 14:45:01,441 - INFO - - Target class: 0
2024-12-29 14:45:01,441 - INFO - - Available samples in source class: 955
2024-12-29 14:45:01,441 - INFO - - Requested samples to poison: 662
2024-12-29 14:45:01,441 - INFO - - Actual samples to flip: 662
2024-12-29 14:45:01,441 - INFO - - Samples remaining in source class: 293
2024-12-29 14:45:01,441 - INFO - Successfully flipped 662 labels from class 1 to 0
2024-12-29 14:45:01,441 - INFO - Total number of labels flipped: 662
2024-12-29 14:45:01,441 - INFO - Label flipping completed in 0.00s
2024-12-29 14:45:01,441 - INFO - Training set processing completed in 0.00s
2024-12-29 14:45:01,441 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:45:01,443 - INFO - Memory usage at start_fit: CPU 2738.5 MB, GPU 104.7 MB
2024-12-29 14:45:01,443 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:45:01,449 - INFO - Number of unique classes: 10
2024-12-29 14:45:01,548 - INFO - Fitted scaler and transformed data
2024-12-29 14:45:01,548 - INFO - Scaling time: 0.10s
2024-12-29 14:45:01,922 - INFO - Epoch 1/500, Train Loss: 0.9550, Val Loss: 0.2398
2024-12-29 14:45:02,249 - INFO - Epoch 2/500, Train Loss: 0.1701, Val Loss: 0.2090
2024-12-29 14:45:02,586 - INFO - Epoch 3/500, Train Loss: 0.1371, Val Loss: 0.1964
2024-12-29 14:45:02,916 - INFO - Epoch 4/500, Train Loss: 0.1178, Val Loss: 0.1832
2024-12-29 14:45:03,253 - INFO - Epoch 5/500, Train Loss: 0.1033, Val Loss: 0.1816
2024-12-29 14:45:03,617 - INFO - Epoch 6/500, Train Loss: 0.0953, Val Loss: 0.1813
2024-12-29 14:45:03,974 - INFO - Epoch 7/500, Train Loss: 0.0885, Val Loss: 0.1768
2024-12-29 14:45:04,320 - INFO - Epoch 8/500, Train Loss: 0.0842, Val Loss: 0.1738
2024-12-29 14:45:04,671 - INFO - Epoch 9/500, Train Loss: 0.0808, Val Loss: 0.1757
2024-12-29 14:45:05,027 - INFO - Epoch 10/500, Train Loss: 0.0766, Val Loss: 0.1751
2024-12-29 14:45:05,369 - INFO - Epoch 11/500, Train Loss: 0.0747, Val Loss: 0.1803
2024-12-29 14:45:05,696 - INFO - Epoch 12/500, Train Loss: 0.0738, Val Loss: 0.1809
2024-12-29 14:45:06,081 - INFO - Epoch 13/500, Train Loss: 0.0711, Val Loss: 0.1766
2024-12-29 14:45:06,081 - INFO - Early stopping triggered at epoch 13
2024-12-29 14:45:06,081 - INFO - Training completed in 4.64s
2024-12-29 14:45:06,082 - INFO - Final memory usage: CPU 2767.8 MB, GPU 104.8 MB
2024-12-29 14:45:06,084 - INFO - Model training completed in 4.64s
2024-12-29 14:45:06,147 - INFO - Prediction completed in 0.06s
2024-12-29 14:45:06,156 - INFO - Poison rate 0.07 completed in 4.72s
2024-12-29 14:45:06,157 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:45:06,157 - INFO - Label flipping details:
2024-12-29 14:45:06,157 - INFO - - Source class: 1
2024-12-29 14:45:06,157 - INFO - - Target class: 0
2024-12-29 14:45:06,157 - INFO - - Available samples in source class: 955
2024-12-29 14:45:06,157 - INFO - - Requested samples to poison: 946
2024-12-29 14:45:06,157 - INFO - - Actual samples to flip: 946
2024-12-29 14:45:06,158 - INFO - - Samples remaining in source class: 9
2024-12-29 14:45:06,158 - INFO - Successfully flipped 946 labels from class 1 to 0
2024-12-29 14:45:06,158 - INFO - Total number of labels flipped: 946
2024-12-29 14:45:06,158 - INFO - Label flipping completed in 0.00s
2024-12-29 14:45:06,158 - INFO - Training set processing completed in 0.00s
2024-12-29 14:45:06,158 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:45:06,159 - INFO - Memory usage at start_fit: CPU 2738.4 MB, GPU 104.7 MB
2024-12-29 14:45:06,159 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:45:06,162 - INFO - Number of unique classes: 10
2024-12-29 14:45:06,232 - INFO - Fitted scaler and transformed data
2024-12-29 14:45:06,232 - INFO - Scaling time: 0.07s
2024-12-29 14:45:06,605 - INFO - Epoch 1/500, Train Loss: 0.6903, Val Loss: 0.1293
2024-12-29 14:45:06,951 - INFO - Epoch 2/500, Train Loss: 0.0945, Val Loss: 0.1016
2024-12-29 14:45:07,280 - INFO - Epoch 3/500, Train Loss: 0.0623, Val Loss: 0.0900
2024-12-29 14:45:07,612 - INFO - Epoch 4/500, Train Loss: 0.0451, Val Loss: 0.0861
2024-12-29 14:45:07,989 - INFO - Epoch 5/500, Train Loss: 0.0344, Val Loss: 0.0859
2024-12-29 14:45:08,343 - INFO - Epoch 6/500, Train Loss: 0.0267, Val Loss: 0.0844
2024-12-29 14:45:09,058 - INFO - Epoch 7/500, Train Loss: 0.0217, Val Loss: 0.0849
2024-12-29 14:45:09,404 - INFO - Epoch 8/500, Train Loss: 0.0183, Val Loss: 0.0857
2024-12-29 14:45:09,832 - INFO - Epoch 9/500, Train Loss: 0.0159, Val Loss: 0.0858
2024-12-29 14:45:10,176 - INFO - Epoch 10/500, Train Loss: 0.0135, Val Loss: 0.0864
2024-12-29 14:45:10,510 - INFO - Epoch 11/500, Train Loss: 0.0121, Val Loss: 0.0864
2024-12-29 14:45:10,510 - INFO - Early stopping triggered at epoch 11
2024-12-29 14:45:10,510 - INFO - Training completed in 4.35s
2024-12-29 14:45:10,510 - INFO - Final memory usage: CPU 2767.7 MB, GPU 104.8 MB
2024-12-29 14:45:10,511 - INFO - Model training completed in 4.35s
2024-12-29 14:45:10,560 - INFO - Prediction completed in 0.05s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 14:45:10,569 - INFO - Poison rate 0.1 completed in 4.41s
2024-12-29 14:45:10,570 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:45:10,570 - INFO - Label flipping details:
2024-12-29 14:45:10,570 - INFO - - Source class: 1
2024-12-29 14:45:10,570 - INFO - - Target class: 0
2024-12-29 14:45:10,570 - INFO - - Available samples in source class: 955
2024-12-29 14:45:10,570 - INFO - - Requested samples to poison: 1893
2024-12-29 14:45:10,570 - INFO - - Actual samples to flip: 954
2024-12-29 14:45:10,571 - INFO - - Samples remaining in source class: 1
2024-12-29 14:45:10,571 - INFO - Successfully flipped 954 labels from class 1 to 0
2024-12-29 14:45:10,571 - INFO - Total number of labels flipped: 954
2024-12-29 14:45:10,571 - INFO - Label flipping completed in 0.00s
2024-12-29 14:45:10,571 - INFO - Training set processing completed in 0.00s
2024-12-29 14:45:10,571 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:45:10,572 - INFO - Memory usage at start_fit: CPU 2738.1 MB, GPU 104.7 MB
2024-12-29 14:45:10,572 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:45:10,575 - INFO - Number of unique classes: 10
2024-12-29 14:45:10,659 - INFO - Fitted scaler and transformed data
2024-12-29 14:45:10,659 - INFO - Scaling time: 0.08s
2024-12-29 14:45:11,005 - INFO - Epoch 1/500, Train Loss: 0.9081, Val Loss: 0.0995
2024-12-29 14:45:11,342 - INFO - Epoch 2/500, Train Loss: 0.0999, Val Loss: 0.0731
2024-12-29 14:45:11,707 - INFO - Epoch 3/500, Train Loss: 0.0682, Val Loss: 0.0601
2024-12-29 14:45:12,037 - INFO - Epoch 4/500, Train Loss: 0.0502, Val Loss: 0.0552
2024-12-29 14:45:12,371 - INFO - Epoch 5/500, Train Loss: 0.0390, Val Loss: 0.0495
2024-12-29 14:45:12,694 - INFO - Epoch 6/500, Train Loss: 0.0314, Val Loss: 0.0466
2024-12-29 14:45:13,020 - INFO - Epoch 7/500, Train Loss: 0.0250, Val Loss: 0.0444
2024-12-29 14:45:13,344 - INFO - Epoch 8/500, Train Loss: 0.0211, Val Loss: 0.0440
2024-12-29 14:45:13,672 - INFO - Epoch 9/500, Train Loss: 0.0175, Val Loss: 0.0414
2024-12-29 14:45:13,989 - INFO - Epoch 10/500, Train Loss: 0.0152, Val Loss: 0.0415
2024-12-29 14:45:14,322 - INFO - Epoch 11/500, Train Loss: 0.0128, Val Loss: 0.0426
2024-12-29 14:45:14,645 - INFO - Epoch 12/500, Train Loss: 0.0116, Val Loss: 0.0431
2024-12-29 14:45:14,993 - INFO - Epoch 13/500, Train Loss: 0.0104, Val Loss: 0.0432
2024-12-29 14:45:15,377 - INFO - Epoch 14/500, Train Loss: 0.0090, Val Loss: 0.0442
2024-12-29 14:45:15,378 - INFO - Early stopping triggered at epoch 14
2024-12-29 14:45:15,378 - INFO - Training completed in 4.81s
2024-12-29 14:45:15,378 - INFO - Final memory usage: CPU 2767.4 MB, GPU 104.8 MB
2024-12-29 14:45:15,380 - INFO - Model training completed in 4.81s
2024-12-29 14:45:15,430 - INFO - Prediction completed in 0.05s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 14:45:15,454 - INFO - Poison rate 0.2 completed in 4.88s
2024-12-29 14:45:15,468 - INFO - Loaded 560 existing results
2024-12-29 14:45:15,468 - INFO - Total results to save: 567
2024-12-29 14:45:15,470 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:45:15,487 - INFO - Saved 567 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:45:15,488 - INFO - Total evaluation time: 63.32s
2024-12-29 14:45:15,490 - INFO - 
Progress: 85.4% - Evaluating CIFAR100 with SVM (dynadetect mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:45:15,708 - INFO - Loading datasets...
2024-12-29 14:45:15,739 - INFO - Dataset loading completed in 0.03s
2024-12-29 14:45:15,739 - INFO - Extracting validation features...
2024-12-29 14:45:15,740 - INFO - Extracting features from 3925 samples...
2024-12-29 14:45:25,123 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:45:25,129 - INFO - Validation feature extraction completed in 9.39s
2024-12-29 14:45:25,129 - INFO - Extracting training features...
2024-12-29 14:45:25,130 - INFO - Extracting features from 9469 samples...
2024-12-29 14:45:47,098 - INFO - Feature extraction completed. Final feature shape: torch.Size([9469, 512])
2024-12-29 14:45:47,103 - INFO - Training feature extraction completed in 21.97s
2024-12-29 14:45:47,103 - INFO - Creating model for classifier: SVM
2024-12-29 14:45:47,103 - INFO - Using device: cuda
2024-12-29 14:45:47,103 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-29 14:45:47,104 - INFO - 
Processing poison rate: 0.0
2024-12-29 14:45:47,104 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:45:47,104 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:45:47,640 - INFO - Feature scaling completed in 0.54s
2024-12-29 14:45:47,640 - INFO - Starting feature selection (k=50)
2024-12-29 14:45:47,658 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 14:45:47,659 - INFO - Starting anomaly detection
2024-12-29 14:45:51,048 - INFO - Anomaly detection completed in 3.39s
2024-12-29 14:45:51,048 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:45:51,048 - INFO - Total fit_transform time: 3.94s
2024-12-29 14:45:51,048 - INFO - Training set processing completed in 3.94s
2024-12-29 14:45:51,048 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:45:51,049 - INFO - Memory usage at start_fit: CPU 2758.3 MB, GPU 104.0 MB
2024-12-29 14:45:51,049 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:45:51,052 - INFO - Number of unique classes: 10
2024-12-29 14:45:51,121 - INFO - Fitted scaler and transformed data
2024-12-29 14:45:51,121 - INFO - Scaling time: 0.07s
2024-12-29 14:45:51,483 - INFO - Epoch 1/500, Train Loss: 0.7411, Val Loss: 0.1144
2024-12-29 14:45:51,885 - INFO - Epoch 2/500, Train Loss: 0.0910, Val Loss: 0.0887
2024-12-29 14:45:52,201 - INFO - Epoch 3/500, Train Loss: 0.0594, Val Loss: 0.0752
2024-12-29 14:45:52,590 - INFO - Epoch 4/500, Train Loss: 0.0426, Val Loss: 0.0694
2024-12-29 14:45:52,942 - INFO - Epoch 5/500, Train Loss: 0.0325, Val Loss: 0.0662
2024-12-29 14:45:53,294 - INFO - Epoch 6/500, Train Loss: 0.0255, Val Loss: 0.0661
2024-12-29 14:45:53,622 - INFO - Epoch 7/500, Train Loss: 0.0206, Val Loss: 0.0612
2024-12-29 14:45:53,961 - INFO - Epoch 8/500, Train Loss: 0.0176, Val Loss: 0.0613
2024-12-29 14:45:54,294 - INFO - Epoch 9/500, Train Loss: 0.0147, Val Loss: 0.0617
2024-12-29 14:45:54,636 - INFO - Epoch 10/500, Train Loss: 0.0125, Val Loss: 0.0619
2024-12-29 14:45:54,969 - INFO - Epoch 11/500, Train Loss: 0.0108, Val Loss: 0.0596
2024-12-29 14:45:55,304 - INFO - Epoch 12/500, Train Loss: 0.0099, Val Loss: 0.0589
2024-12-29 14:45:55,635 - INFO - Epoch 13/500, Train Loss: 0.0085, Val Loss: 0.0582
2024-12-29 14:45:56,015 - INFO - Epoch 14/500, Train Loss: 0.0074, Val Loss: 0.0582
2024-12-29 14:45:56,382 - INFO - Epoch 15/500, Train Loss: 0.0069, Val Loss: 0.0572
2024-12-29 14:45:56,701 - INFO - Epoch 16/500, Train Loss: 0.0064, Val Loss: 0.0561
2024-12-29 14:45:57,022 - INFO - Epoch 17/500, Train Loss: 0.0055, Val Loss: 0.0594
2024-12-29 14:45:57,372 - INFO - Epoch 18/500, Train Loss: 0.0050, Val Loss: 0.0584
2024-12-29 14:45:57,710 - INFO - Epoch 19/500, Train Loss: 0.0046, Val Loss: 0.0593
2024-12-29 14:45:58,055 - INFO - Epoch 20/500, Train Loss: 0.0043, Val Loss: 0.0578
2024-12-29 14:45:58,415 - INFO - Epoch 21/500, Train Loss: 0.0045, Val Loss: 0.0580
2024-12-29 14:45:58,416 - INFO - Early stopping triggered at epoch 21
2024-12-29 14:45:58,416 - INFO - Training completed in 7.37s
2024-12-29 14:45:58,416 - INFO - Final memory usage: CPU 2767.6 MB, GPU 104.2 MB
2024-12-29 14:45:58,417 - INFO - Model training completed in 7.37s
2024-12-29 14:45:58,462 - INFO - Prediction completed in 0.04s
2024-12-29 14:45:58,482 - INFO - Poison rate 0.0 completed in 11.38s
2024-12-29 14:45:58,482 - INFO - 
Processing poison rate: 0.01
2024-12-29 14:45:58,483 - INFO - Label flipping details:
2024-12-29 14:45:58,483 - INFO - - Source class: 1
2024-12-29 14:45:58,483 - INFO - - Target class: 0
2024-12-29 14:45:58,483 - INFO - - Available samples in source class: 955
2024-12-29 14:45:58,483 - INFO - - Requested samples to poison: 94
2024-12-29 14:45:58,483 - INFO - - Actual samples to flip: 94
2024-12-29 14:45:58,483 - INFO - - Samples remaining in source class: 861
2024-12-29 14:45:58,483 - INFO - Successfully flipped 94 labels from class 1 to 0
2024-12-29 14:45:58,483 - INFO - Total number of labels flipped: 94
2024-12-29 14:45:58,483 - INFO - Label flipping completed in 0.00s
2024-12-29 14:45:58,483 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:45:58,484 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:45:59,046 - INFO - Feature scaling completed in 0.56s
2024-12-29 14:45:59,047 - INFO - Starting feature selection (k=50)
2024-12-29 14:45:59,062 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 14:45:59,063 - INFO - Starting anomaly detection
2024-12-29 14:46:03,193 - INFO - Anomaly detection completed in 4.13s
2024-12-29 14:46:03,194 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:46:03,194 - INFO - Total fit_transform time: 4.71s
2024-12-29 14:46:03,194 - INFO - Training set processing completed in 4.71s
2024-12-29 14:46:03,194 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:46:03,195 - INFO - Memory usage at start_fit: CPU 2758.3 MB, GPU 104.1 MB
2024-12-29 14:46:03,195 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:46:03,198 - INFO - Number of unique classes: 10
2024-12-29 14:46:03,265 - INFO - Fitted scaler and transformed data
2024-12-29 14:46:03,266 - INFO - Scaling time: 0.07s
2024-12-29 14:46:03,589 - INFO - Epoch 1/500, Train Loss: 0.8570, Val Loss: 0.1769
2024-12-29 14:46:03,905 - INFO - Epoch 2/500, Train Loss: 0.1173, Val Loss: 0.1403
2024-12-29 14:46:04,228 - INFO - Epoch 3/500, Train Loss: 0.0855, Val Loss: 0.1290
2024-12-29 14:46:04,556 - INFO - Epoch 4/500, Train Loss: 0.0679, Val Loss: 0.1242
2024-12-29 14:46:04,891 - INFO - Epoch 5/500, Train Loss: 0.0565, Val Loss: 0.1225
2024-12-29 14:46:05,230 - INFO - Epoch 6/500, Train Loss: 0.0491, Val Loss: 0.1247
2024-12-29 14:46:05,547 - INFO - Epoch 7/500, Train Loss: 0.0436, Val Loss: 0.1182
2024-12-29 14:46:05,876 - INFO - Epoch 8/500, Train Loss: 0.0396, Val Loss: 0.1211
2024-12-29 14:46:06,212 - INFO - Epoch 9/500, Train Loss: 0.0363, Val Loss: 0.1194
2024-12-29 14:46:06,555 - INFO - Epoch 10/500, Train Loss: 0.0339, Val Loss: 0.1202
2024-12-29 14:46:06,872 - INFO - Epoch 11/500, Train Loss: 0.0313, Val Loss: 0.1210
2024-12-29 14:46:07,195 - INFO - Epoch 12/500, Train Loss: 0.0301, Val Loss: 0.1186
2024-12-29 14:46:07,195 - INFO - Early stopping triggered at epoch 12
2024-12-29 14:46:07,195 - INFO - Training completed in 4.00s
2024-12-29 14:46:07,195 - INFO - Final memory usage: CPU 2767.6 MB, GPU 104.2 MB
2024-12-29 14:46:07,196 - INFO - Model training completed in 4.00s
2024-12-29 14:46:07,241 - INFO - Prediction completed in 0.04s
2024-12-29 14:46:07,249 - INFO - Poison rate 0.01 completed in 8.77s
2024-12-29 14:46:07,249 - INFO - 
Processing poison rate: 0.03
2024-12-29 14:46:07,250 - INFO - Label flipping details:
2024-12-29 14:46:07,250 - INFO - - Source class: 1
2024-12-29 14:46:07,250 - INFO - - Target class: 0
2024-12-29 14:46:07,250 - INFO - - Available samples in source class: 955
2024-12-29 14:46:07,250 - INFO - - Requested samples to poison: 284
2024-12-29 14:46:07,250 - INFO - - Actual samples to flip: 284
2024-12-29 14:46:07,250 - INFO - - Samples remaining in source class: 671
2024-12-29 14:46:07,250 - INFO - Successfully flipped 284 labels from class 1 to 0
2024-12-29 14:46:07,251 - INFO - Total number of labels flipped: 284
2024-12-29 14:46:07,251 - INFO - Label flipping completed in 0.00s
2024-12-29 14:46:07,251 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:46:07,251 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:46:07,818 - INFO - Feature scaling completed in 0.57s
2024-12-29 14:46:07,818 - INFO - Starting feature selection (k=50)
2024-12-29 14:46:07,834 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 14:46:07,834 - INFO - Starting anomaly detection
2024-12-29 14:46:11,999 - INFO - Anomaly detection completed in 4.17s
2024-12-29 14:46:12,000 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:46:12,000 - INFO - Total fit_transform time: 4.75s
2024-12-29 14:46:12,000 - INFO - Training set processing completed in 4.75s
2024-12-29 14:46:12,000 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:46:12,001 - INFO - Memory usage at start_fit: CPU 2758.1 MB, GPU 104.1 MB
2024-12-29 14:46:12,001 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:46:12,003 - INFO - Number of unique classes: 10
2024-12-29 14:46:12,073 - INFO - Fitted scaler and transformed data
2024-12-29 14:46:12,073 - INFO - Scaling time: 0.07s
2024-12-29 14:46:12,434 - INFO - Epoch 1/500, Train Loss: 0.8090, Val Loss: 0.1744
2024-12-29 14:46:12,747 - INFO - Epoch 2/500, Train Loss: 0.1565, Val Loss: 0.1503
2024-12-29 14:46:13,088 - INFO - Epoch 3/500, Train Loss: 0.1238, Val Loss: 0.1413
2024-12-29 14:46:13,396 - INFO - Epoch 4/500, Train Loss: 0.1057, Val Loss: 0.1397
2024-12-29 14:46:13,722 - INFO - Epoch 5/500, Train Loss: 0.0940, Val Loss: 0.1354
2024-12-29 14:46:14,063 - INFO - Epoch 6/500, Train Loss: 0.0872, Val Loss: 0.1364
2024-12-29 14:46:14,446 - INFO - Epoch 7/500, Train Loss: 0.0828, Val Loss: 0.1346
2024-12-29 14:46:14,794 - INFO - Epoch 8/500, Train Loss: 0.0778, Val Loss: 0.1368
2024-12-29 14:46:15,156 - INFO - Epoch 9/500, Train Loss: 0.0742, Val Loss: 0.1360
2024-12-29 14:46:15,490 - INFO - Epoch 10/500, Train Loss: 0.0718, Val Loss: 0.1366
2024-12-29 14:46:15,490 - INFO - Early stopping triggered at epoch 10
2024-12-29 14:46:15,490 - INFO - Training completed in 3.49s
2024-12-29 14:46:15,491 - INFO - Final memory usage: CPU 2767.6 MB, GPU 104.2 MB
2024-12-29 14:46:15,492 - INFO - Model training completed in 3.49s
2024-12-29 14:46:15,556 - INFO - Prediction completed in 0.06s
2024-12-29 14:46:15,564 - INFO - Poison rate 0.03 completed in 8.32s
2024-12-29 14:46:15,565 - INFO - 
Processing poison rate: 0.05
2024-12-29 14:46:15,565 - INFO - Label flipping details:
2024-12-29 14:46:15,565 - INFO - - Source class: 1
2024-12-29 14:46:15,565 - INFO - - Target class: 0
2024-12-29 14:46:15,565 - INFO - - Available samples in source class: 955
2024-12-29 14:46:15,566 - INFO - - Requested samples to poison: 473
2024-12-29 14:46:15,566 - INFO - - Actual samples to flip: 473
2024-12-29 14:46:15,566 - INFO - - Samples remaining in source class: 482
2024-12-29 14:46:15,566 - INFO - Successfully flipped 473 labels from class 1 to 0
2024-12-29 14:46:15,566 - INFO - Total number of labels flipped: 473
2024-12-29 14:46:15,566 - INFO - Label flipping completed in 0.00s
2024-12-29 14:46:15,566 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:46:15,566 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:46:16,106 - INFO - Feature scaling completed in 0.54s
2024-12-29 14:46:16,106 - INFO - Starting feature selection (k=50)
2024-12-29 14:46:16,121 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:46:16,121 - INFO - Starting anomaly detection
2024-12-29 14:46:20,455 - INFO - Anomaly detection completed in 4.33s
2024-12-29 14:46:20,455 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:46:20,456 - INFO - Total fit_transform time: 4.89s
2024-12-29 14:46:20,456 - INFO - Training set processing completed in 4.89s
2024-12-29 14:46:20,456 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:46:20,457 - INFO - Memory usage at start_fit: CPU 2758.3 MB, GPU 104.1 MB
2024-12-29 14:46:20,457 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:46:20,460 - INFO - Number of unique classes: 10
2024-12-29 14:46:20,534 - INFO - Fitted scaler and transformed data
2024-12-29 14:46:20,535 - INFO - Scaling time: 0.07s
2024-12-29 14:46:20,900 - INFO - Epoch 1/500, Train Loss: 0.9964, Val Loss: 0.1973
2024-12-29 14:46:21,267 - INFO - Epoch 2/500, Train Loss: 0.1937, Val Loss: 0.1777
2024-12-29 14:46:21,616 - INFO - Epoch 3/500, Train Loss: 0.1566, Val Loss: 0.1687
2024-12-29 14:46:21,917 - INFO - Epoch 4/500, Train Loss: 0.1370, Val Loss: 0.1661
2024-12-29 14:46:22,217 - INFO - Epoch 5/500, Train Loss: 0.1227, Val Loss: 0.1554
2024-12-29 14:46:22,579 - INFO - Epoch 6/500, Train Loss: 0.1149, Val Loss: 0.1581
2024-12-29 14:46:22,953 - INFO - Epoch 7/500, Train Loss: 0.1067, Val Loss: 0.1514
2024-12-29 14:46:23,326 - INFO - Epoch 8/500, Train Loss: 0.1034, Val Loss: 0.1545
2024-12-29 14:46:23,710 - INFO - Epoch 9/500, Train Loss: 0.0985, Val Loss: 0.1590
2024-12-29 14:46:24,052 - INFO - Epoch 10/500, Train Loss: 0.0941, Val Loss: 0.1588
2024-12-29 14:46:24,418 - INFO - Epoch 11/500, Train Loss: 0.0904, Val Loss: 0.1613
2024-12-29 14:46:24,756 - INFO - Epoch 12/500, Train Loss: 0.0871, Val Loss: 0.1656
2024-12-29 14:46:24,757 - INFO - Early stopping triggered at epoch 12
2024-12-29 14:46:24,757 - INFO - Training completed in 4.30s
2024-12-29 14:46:24,757 - INFO - Final memory usage: CPU 2767.7 MB, GPU 104.2 MB
2024-12-29 14:46:24,758 - INFO - Model training completed in 4.30s
2024-12-29 14:46:24,804 - INFO - Prediction completed in 0.05s
2024-12-29 14:46:24,812 - INFO - Poison rate 0.05 completed in 9.25s
2024-12-29 14:46:24,813 - INFO - 
Processing poison rate: 0.07
2024-12-29 14:46:24,813 - INFO - Label flipping details:
2024-12-29 14:46:24,813 - INFO - - Source class: 1
2024-12-29 14:46:24,813 - INFO - - Target class: 0
2024-12-29 14:46:24,813 - INFO - - Available samples in source class: 955
2024-12-29 14:46:24,813 - INFO - - Requested samples to poison: 662
2024-12-29 14:46:24,814 - INFO - - Actual samples to flip: 662
2024-12-29 14:46:24,814 - INFO - - Samples remaining in source class: 293
2024-12-29 14:46:24,814 - INFO - Successfully flipped 662 labels from class 1 to 0
2024-12-29 14:46:24,814 - INFO - Total number of labels flipped: 662
2024-12-29 14:46:24,814 - INFO - Label flipping completed in 0.00s
2024-12-29 14:46:24,814 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:46:24,814 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:46:25,399 - INFO - Feature scaling completed in 0.58s
2024-12-29 14:46:25,399 - INFO - Starting feature selection (k=50)
2024-12-29 14:46:25,415 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 14:46:25,415 - INFO - Starting anomaly detection
2024-12-29 14:46:29,092 - INFO - Anomaly detection completed in 3.68s
2024-12-29 14:46:29,092 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:46:29,093 - INFO - Total fit_transform time: 4.28s
2024-12-29 14:46:29,093 - INFO - Training set processing completed in 4.28s
2024-12-29 14:46:29,093 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:46:29,093 - INFO - Memory usage at start_fit: CPU 2758.4 MB, GPU 104.1 MB
2024-12-29 14:46:29,094 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:46:29,096 - INFO - Number of unique classes: 10
2024-12-29 14:46:29,164 - INFO - Fitted scaler and transformed data
2024-12-29 14:46:29,165 - INFO - Scaling time: 0.07s
2024-12-29 14:46:29,520 - INFO - Epoch 1/500, Train Loss: 0.9305, Val Loss: 0.2424
2024-12-29 14:46:29,833 - INFO - Epoch 2/500, Train Loss: 0.1724, Val Loss: 0.1968
2024-12-29 14:46:30,145 - INFO - Epoch 3/500, Train Loss: 0.1334, Val Loss: 0.1757
2024-12-29 14:46:30,447 - INFO - Epoch 4/500, Train Loss: 0.1135, Val Loss: 0.1682
2024-12-29 14:46:30,758 - INFO - Epoch 5/500, Train Loss: 0.1003, Val Loss: 0.1646
2024-12-29 14:46:31,070 - INFO - Epoch 6/500, Train Loss: 0.0914, Val Loss: 0.1592
2024-12-29 14:46:31,378 - INFO - Epoch 7/500, Train Loss: 0.0846, Val Loss: 0.1563
2024-12-29 14:46:31,722 - INFO - Epoch 8/500, Train Loss: 0.0790, Val Loss: 0.1492
2024-12-29 14:46:32,073 - INFO - Epoch 9/500, Train Loss: 0.0756, Val Loss: 0.1528
2024-12-29 14:46:32,447 - INFO - Epoch 10/500, Train Loss: 0.0721, Val Loss: 0.1507
2024-12-29 14:46:32,785 - INFO - Epoch 11/500, Train Loss: 0.0689, Val Loss: 0.1568
2024-12-29 14:46:33,117 - INFO - Epoch 12/500, Train Loss: 0.0672, Val Loss: 0.1523
2024-12-29 14:46:33,467 - INFO - Epoch 13/500, Train Loss: 0.0660, Val Loss: 0.1477
2024-12-29 14:46:33,793 - INFO - Epoch 14/500, Train Loss: 0.0634, Val Loss: 0.1553
2024-12-29 14:46:34,132 - INFO - Epoch 15/500, Train Loss: 0.0626, Val Loss: 0.1593
2024-12-29 14:46:34,466 - INFO - Epoch 16/500, Train Loss: 0.0623, Val Loss: 0.1563
2024-12-29 14:46:34,796 - INFO - Epoch 17/500, Train Loss: 0.0599, Val Loss: 0.1567
2024-12-29 14:46:35,152 - INFO - Epoch 18/500, Train Loss: 0.0592, Val Loss: 0.1556
2024-12-29 14:46:35,153 - INFO - Early stopping triggered at epoch 18
2024-12-29 14:46:35,153 - INFO - Training completed in 6.06s
2024-12-29 14:46:35,153 - INFO - Final memory usage: CPU 2767.9 MB, GPU 104.2 MB
2024-12-29 14:46:35,154 - INFO - Model training completed in 6.06s
2024-12-29 14:46:35,201 - INFO - Prediction completed in 0.05s
2024-12-29 14:46:35,218 - INFO - Poison rate 0.07 completed in 10.41s
2024-12-29 14:46:35,218 - INFO - 
Processing poison rate: 0.1
2024-12-29 14:46:35,219 - INFO - Label flipping details:
2024-12-29 14:46:35,219 - INFO - - Source class: 1
2024-12-29 14:46:35,219 - INFO - - Target class: 0
2024-12-29 14:46:35,219 - INFO - - Available samples in source class: 955
2024-12-29 14:46:35,219 - INFO - - Requested samples to poison: 946
2024-12-29 14:46:35,219 - INFO - - Actual samples to flip: 946
2024-12-29 14:46:35,219 - INFO - - Samples remaining in source class: 9
2024-12-29 14:46:35,219 - INFO - Successfully flipped 946 labels from class 1 to 0
2024-12-29 14:46:35,219 - INFO - Total number of labels flipped: 946
2024-12-29 14:46:35,220 - INFO - Label flipping completed in 0.00s
2024-12-29 14:46:35,220 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:46:35,220 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:46:35,805 - INFO - Feature scaling completed in 0.58s
2024-12-29 14:46:35,805 - INFO - Starting feature selection (k=50)
2024-12-29 14:46:35,820 - INFO - Feature selection completed in 0.01s. Output shape: (9469, 50)
2024-12-29 14:46:35,820 - INFO - Starting anomaly detection
2024-12-29 14:46:39,476 - INFO - Anomaly detection completed in 3.66s
2024-12-29 14:46:39,476 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:46:39,477 - INFO - Total fit_transform time: 4.26s
2024-12-29 14:46:39,477 - INFO - Training set processing completed in 4.26s
2024-12-29 14:46:39,477 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:46:39,478 - INFO - Memory usage at start_fit: CPU 2758.1 MB, GPU 104.1 MB
2024-12-29 14:46:39,478 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:46:39,480 - INFO - Number of unique classes: 10
2024-12-29 14:46:39,552 - INFO - Fitted scaler and transformed data
2024-12-29 14:46:39,552 - INFO - Scaling time: 0.07s
2024-12-29 14:46:39,902 - INFO - Epoch 1/500, Train Loss: 1.0248, Val Loss: 0.1184
2024-12-29 14:46:40,238 - INFO - Epoch 2/500, Train Loss: 0.1072, Val Loss: 0.0919
2024-12-29 14:46:40,541 - INFO - Epoch 3/500, Train Loss: 0.0710, Val Loss: 0.0790
2024-12-29 14:46:40,869 - INFO - Epoch 4/500, Train Loss: 0.0517, Val Loss: 0.0743
2024-12-29 14:46:41,176 - INFO - Epoch 5/500, Train Loss: 0.0406, Val Loss: 0.0707
2024-12-29 14:46:41,548 - INFO - Epoch 6/500, Train Loss: 0.0330, Val Loss: 0.0699
2024-12-29 14:46:41,879 - INFO - Epoch 7/500, Train Loss: 0.0272, Val Loss: 0.0704
2024-12-29 14:46:42,195 - INFO - Epoch 8/500, Train Loss: 0.0228, Val Loss: 0.0717
2024-12-29 14:46:42,507 - INFO - Epoch 9/500, Train Loss: 0.0197, Val Loss: 0.0711
2024-12-29 14:46:42,834 - INFO - Epoch 10/500, Train Loss: 0.0174, Val Loss: 0.0704
2024-12-29 14:46:42,834 - INFO - Early stopping triggered at epoch 10
2024-12-29 14:46:42,834 - INFO - Training completed in 3.36s
2024-12-29 14:46:42,835 - INFO - Final memory usage: CPU 2767.6 MB, GPU 104.2 MB
2024-12-29 14:46:42,836 - INFO - Model training completed in 3.36s
2024-12-29 14:46:42,881 - INFO - Prediction completed in 0.04s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 14:46:42,890 - INFO - Poison rate 0.1 completed in 7.67s
2024-12-29 14:46:42,890 - INFO - 
Processing poison rate: 0.2
2024-12-29 14:46:42,891 - INFO - Label flipping details:
2024-12-29 14:46:42,891 - INFO - - Source class: 1
2024-12-29 14:46:42,891 - INFO - - Target class: 0
2024-12-29 14:46:42,891 - INFO - - Available samples in source class: 955
2024-12-29 14:46:42,891 - INFO - - Requested samples to poison: 1893
2024-12-29 14:46:42,891 - INFO - - Actual samples to flip: 954
2024-12-29 14:46:42,891 - INFO - - Samples remaining in source class: 1
2024-12-29 14:46:42,891 - INFO - Successfully flipped 954 labels from class 1 to 0
2024-12-29 14:46:42,892 - INFO - Total number of labels flipped: 954
2024-12-29 14:46:42,892 - INFO - Label flipping completed in 0.00s
2024-12-29 14:46:42,892 - INFO - Initialized DynaDetect trainer on cuda
2024-12-29 14:46:42,892 - INFO - Starting feature scaling on shape (9469, 512)
2024-12-29 14:46:43,506 - INFO - Feature scaling completed in 0.61s
2024-12-29 14:46:43,506 - INFO - Starting feature selection (k=50)
2024-12-29 14:46:43,522 - INFO - Feature selection completed in 0.02s. Output shape: (9469, 50)
2024-12-29 14:46:43,522 - INFO - Starting anomaly detection
2024-12-29 14:46:47,610 - INFO - Anomaly detection completed in 4.09s
2024-12-29 14:46:47,610 - INFO - Found 947 outliers (10.0%)
2024-12-29 14:46:47,610 - INFO - Total fit_transform time: 4.72s
2024-12-29 14:46:47,610 - INFO - Training set processing completed in 4.72s
2024-12-29 14:46:47,610 - INFO - Fitting SVMWrapper model with data shape: (9469, 512)
2024-12-29 14:46:47,611 - INFO - Memory usage at start_fit: CPU 2758.3 MB, GPU 104.1 MB
2024-12-29 14:46:47,612 - INFO - Input data shape: (9469, 512), labels shape: (9469,)
2024-12-29 14:46:47,614 - INFO - Number of unique classes: 10
2024-12-29 14:46:47,689 - INFO - Fitted scaler and transformed data
2024-12-29 14:46:47,690 - INFO - Scaling time: 0.07s
2024-12-29 14:46:48,095 - INFO - Epoch 1/500, Train Loss: 0.8743, Val Loss: 0.1341
2024-12-29 14:46:48,408 - INFO - Epoch 2/500, Train Loss: 0.1030, Val Loss: 0.0973
2024-12-29 14:46:48,743 - INFO - Epoch 3/500, Train Loss: 0.0677, Val Loss: 0.0843
2024-12-29 14:46:49,096 - INFO - Epoch 4/500, Train Loss: 0.0486, Val Loss: 0.0729
2024-12-29 14:46:49,453 - INFO - Epoch 5/500, Train Loss: 0.0373, Val Loss: 0.0676
2024-12-29 14:46:49,773 - INFO - Epoch 6/500, Train Loss: 0.0300, Val Loss: 0.0660
2024-12-29 14:46:50,100 - INFO - Epoch 7/500, Train Loss: 0.0242, Val Loss: 0.0617
2024-12-29 14:46:50,431 - INFO - Epoch 8/500, Train Loss: 0.0203, Val Loss: 0.0625
2024-12-29 14:46:50,762 - INFO - Epoch 9/500, Train Loss: 0.0170, Val Loss: 0.0625
2024-12-29 14:46:51,094 - INFO - Epoch 10/500, Train Loss: 0.0147, Val Loss: 0.0621
2024-12-29 14:46:51,428 - INFO - Epoch 11/500, Train Loss: 0.0127, Val Loss: 0.0631
2024-12-29 14:46:51,761 - INFO - Epoch 12/500, Train Loss: 0.0115, Val Loss: 0.0618
2024-12-29 14:46:51,761 - INFO - Early stopping triggered at epoch 12
2024-12-29 14:46:51,762 - INFO - Training completed in 4.15s
2024-12-29 14:46:51,762 - INFO - Final memory usage: CPU 2767.6 MB, GPU 104.2 MB
2024-12-29 14:46:51,763 - INFO - Model training completed in 4.15s
2024-12-29 14:46:51,817 - INFO - Prediction completed in 0.05s
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2024-12-29 14:46:51,827 - INFO - Poison rate 0.2 completed in 8.94s
2024-12-29 14:46:51,838 - INFO - Loaded 567 existing results
2024-12-29 14:46:51,838 - INFO - Total results to save: 574
2024-12-29 14:46:51,839 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241229_124656.csv
2024-12-29 14:46:51,856 - INFO - Saved 574 results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241229_124656.csv
2024-12-29 14:46:51,857 - INFO - Total evaluation time: 96.15s
2024-12-29 14:46:51,859 - INFO - 
Progress: 86.5% - Evaluating CIFAR100 with LogisticRegression (standard mode, iteration 1/1)
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/brian/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-12-29 14:46:52,052 - INFO - Loading datasets...
2024-12-29 14:46:52,073 - INFO - Dataset loading completed in 0.02s
2024-12-29 14:46:52,073 - INFO - Extracting validation features...
2024-12-29 14:46:52,073 - INFO - Extracting features from 3925 samples...
2024-12-29 14:47:01,570 - INFO - Feature extraction completed. Final feature shape: torch.Size([3925, 512])
2024-12-29 14:47:01,574 - INFO - Validation feature extraction completed in 9.50s
2024-12-29 14:47:01,575 - INFO - Extracting training features...
2024-12-29 14:47:01,575 - INFO - Extracting features from 9469 samples...
