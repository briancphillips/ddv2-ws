nohup: ignoring input
2024-12-27 09:14:45,197 - INFO - Logging setup completed successfully
2024-12-27 09:14:45,198 - INFO - Log file created at: /home/brian/Notebooks/ddv2-ws/logs/experiment_20241227_091444.log
2024-12-27 09:14:45,198 - INFO - Starting experiment run
2024-12-27 09:14:45,198 - INFO - Test mode: True
2024-12-27 09:14:45,199 - INFO - 
Processing dataset: GTSRB
2024-12-27 09:14:45,199 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 09:14:45,200 - INFO - Dataset type: image
2024-12-27 09:14:45,200 - INFO - Sample size: 5000
2024-12-27 09:14:45,201 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 09:14:45,201 - INFO - 
Progress: 1.0% - Evaluating GTSRB with SVM (standard mode, iteration 1/1)
2024-12-27 09:14:45,202 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 09:14:45,202 - INFO - Dataset type: image
2024-12-27 09:14:45,203 - INFO - Sample size: 5000
2024-12-27 09:14:45,203 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 09:14:45,203 - INFO - Loading datasets...
2024-12-27 09:15:04,355 - INFO - Dataset loading completed in 19.15s
2024-12-27 09:15:04,355 - INFO - Extracting validation features...
2024-12-27 09:15:04,355 - INFO - Extracting features from 1000 samples...
2024-12-27 09:15:04,755 - INFO - Feature extraction completed. Final feature shape: (1000, 3072)
2024-12-27 09:15:04,756 - INFO - Validation feature extraction completed in 0.40s
2024-12-27 09:15:04,756 - INFO - Extracting training features...
2024-12-27 09:15:04,756 - INFO - Extracting features from 5000 samples...
2024-12-27 09:15:06,697 - INFO - Feature extraction completed. Final feature shape: (5000, 3072)
2024-12-27 09:15:06,697 - INFO - Training feature extraction completed in 1.94s
2024-12-27 09:15:06,697 - INFO - Creating model for classifier: SVM
2024-12-27 09:15:06,698 - INFO - Using device: cuda
2024-12-27 09:15:06,698 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-27 09:15:06,698 - INFO - 
Processing poison rate: 0.01
2024-12-27 09:15:06,699 - INFO - Total number of labels flipped: 50
2024-12-27 09:15:06,700 - INFO - Label flipping completed in 0.00s
2024-12-27 09:15:06,700 - INFO - Training set processing completed in 0.00s
2024-12-27 09:15:06,700 - INFO - Fitting SVMWrapper model with data shape: (5000, 3072)
2024-12-27 09:15:06,701 - INFO - Memory usage at start_fit: CPU 715.0 MB, GPU 0.0 MB
2024-12-27 09:15:06,701 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:15:06,701 - INFO - Number of unique classes: 43
2024-12-27 09:15:07,272 - INFO - Fitted scaler and transformed data
2024-12-27 09:15:07,273 - INFO - Scaling time: 0.28s
2024-12-27 09:15:07,787 - INFO - Epoch 1/25, Train Loss: 94.2128, Val Loss: 53.7007
2024-12-27 09:15:07,971 - INFO - Epoch 2/25, Train Loss: 21.5155, Val Loss: 30.9343
2024-12-27 09:15:08,153 - INFO - Epoch 3/25, Train Loss: 16.0817, Val Loss: 23.5120
2024-12-27 09:15:08,318 - INFO - Epoch 4/25, Train Loss: 7.5661, Val Loss: 15.9492
2024-12-27 09:15:08,486 - INFO - Epoch 5/25, Train Loss: 7.3160, Val Loss: 17.7893
2024-12-27 09:15:08,652 - INFO - Epoch 6/25, Train Loss: 7.4834, Val Loss: 20.6415
2024-12-27 09:15:08,652 - INFO - Early stopping triggered at epoch 6
2024-12-27 09:15:08,653 - INFO - Training completed in 1.95s
2024-12-27 09:15:08,653 - INFO - Final memory usage: CPU 1190.5 MB, GPU 19.8 MB
2024-12-27 09:15:08,654 - INFO - Model training completed in 1.95s
2024-12-27 09:15:08,677 - INFO - Prediction completed in 0.02s
2024-12-27 09:15:08,686 - INFO - Poison rate 0.01 completed in 1.99s
2024-12-27 09:15:08,686 - INFO - 
Processing poison rate: 0.03
2024-12-27 09:15:08,689 - INFO - Total number of labels flipped: 150
2024-12-27 09:15:08,689 - INFO - Label flipping completed in 0.00s
2024-12-27 09:15:08,689 - INFO - Training set processing completed in 0.00s
2024-12-27 09:15:08,689 - INFO - Fitting SVMWrapper model with data shape: (5000, 3072)
2024-12-27 09:15:08,690 - INFO - Memory usage at start_fit: CPU 1137.5 MB, GPU 18.3 MB
2024-12-27 09:15:08,690 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:15:08,691 - INFO - Number of unique classes: 43
2024-12-27 09:15:08,921 - INFO - Fitted scaler and transformed data
2024-12-27 09:15:08,921 - INFO - Scaling time: 0.23s
2024-12-27 09:15:09,103 - INFO - Epoch 1/25, Train Loss: 87.2648, Val Loss: 46.0090
2024-12-27 09:15:09,274 - INFO - Epoch 2/25, Train Loss: 26.6790, Val Loss: 34.3166
2024-12-27 09:15:09,482 - INFO - Epoch 3/25, Train Loss: 16.5804, Val Loss: 33.3336
2024-12-27 09:15:09,673 - INFO - Epoch 4/25, Train Loss: 11.3101, Val Loss: 28.8102
2024-12-27 09:15:09,851 - INFO - Epoch 5/25, Train Loss: 10.0330, Val Loss: 28.5773
2024-12-27 09:15:10,020 - INFO - Epoch 6/25, Train Loss: 10.2836, Val Loss: 29.2638
2024-12-27 09:15:10,181 - INFO - Epoch 7/25, Train Loss: 10.4414, Val Loss: 28.4880
2024-12-27 09:15:10,351 - INFO - Epoch 8/25, Train Loss: 8.8234, Val Loss: 33.0521
2024-12-27 09:15:10,521 - INFO - Epoch 9/25, Train Loss: 8.0639, Val Loss: 27.1757
2024-12-27 09:15:10,693 - INFO - Epoch 10/25, Train Loss: 5.4938, Val Loss: 34.7753
2024-12-27 09:15:10,859 - INFO - Epoch 11/25, Train Loss: 5.9752, Val Loss: 29.4349
2024-12-27 09:15:10,860 - INFO - Early stopping triggered at epoch 11
2024-12-27 09:15:10,860 - INFO - Training completed in 2.17s
2024-12-27 09:15:10,860 - INFO - Final memory usage: CPU 1202.2 MB, GPU 19.8 MB
2024-12-27 09:15:10,861 - INFO - Model training completed in 2.17s
2024-12-27 09:15:10,886 - INFO - Prediction completed in 0.03s
2024-12-27 09:15:10,899 - INFO - Poison rate 0.03 completed in 2.21s
2024-12-27 09:15:10,899 - INFO - 
Processing poison rate: 0.05
2024-12-27 09:15:10,904 - INFO - Total number of labels flipped: 250
2024-12-27 09:15:10,904 - INFO - Label flipping completed in 0.01s
2024-12-27 09:15:10,904 - INFO - Training set processing completed in 0.00s
2024-12-27 09:15:10,904 - INFO - Fitting SVMWrapper model with data shape: (5000, 3072)
2024-12-27 09:15:10,905 - INFO - Memory usage at start_fit: CPU 1152.5 MB, GPU 18.3 MB
2024-12-27 09:15:10,905 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:15:10,906 - INFO - Number of unique classes: 43
2024-12-27 09:15:11,119 - INFO - Fitted scaler and transformed data
2024-12-27 09:15:11,120 - INFO - Scaling time: 0.21s
2024-12-27 09:15:11,320 - INFO - Epoch 1/25, Train Loss: 99.2136, Val Loss: 47.6389
2024-12-27 09:15:11,499 - INFO - Epoch 2/25, Train Loss: 28.2097, Val Loss: 27.6002
2024-12-27 09:15:11,681 - INFO - Epoch 3/25, Train Loss: 23.0190, Val Loss: 34.8724
2024-12-27 09:15:11,848 - INFO - Epoch 4/25, Train Loss: 19.8300, Val Loss: 36.4812
2024-12-27 09:15:11,848 - INFO - Early stopping triggered at epoch 4
2024-12-27 09:15:11,848 - INFO - Training completed in 0.94s
2024-12-27 09:15:11,849 - INFO - Final memory usage: CPU 1214.2 MB, GPU 19.8 MB
2024-12-27 09:15:11,850 - INFO - Model training completed in 0.95s
2024-12-27 09:15:11,864 - INFO - Prediction completed in 0.01s
2024-12-27 09:15:11,872 - INFO - Poison rate 0.05 completed in 0.97s
2024-12-27 09:15:11,873 - INFO - 
Processing poison rate: 0.07
2024-12-27 09:15:11,879 - INFO - Total number of labels flipped: 350
2024-12-27 09:15:11,880 - INFO - Label flipping completed in 0.01s
2024-12-27 09:15:11,880 - INFO - Training set processing completed in 0.00s
2024-12-27 09:15:11,880 - INFO - Fitting SVMWrapper model with data shape: (5000, 3072)
2024-12-27 09:15:11,881 - INFO - Memory usage at start_fit: CPU 1155.6 MB, GPU 18.3 MB
2024-12-27 09:15:11,881 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:15:11,882 - INFO - Number of unique classes: 43
2024-12-27 09:15:12,102 - INFO - Fitted scaler and transformed data
2024-12-27 09:15:12,103 - INFO - Scaling time: 0.22s
2024-12-27 09:15:12,298 - INFO - Epoch 1/25, Train Loss: 102.8527, Val Loss: 50.3389
2024-12-27 09:15:12,474 - INFO - Epoch 2/25, Train Loss: 34.6267, Val Loss: 36.4092
2024-12-27 09:15:12,635 - INFO - Epoch 3/25, Train Loss: 22.9026, Val Loss: 33.7629
2024-12-27 09:15:12,821 - INFO - Epoch 4/25, Train Loss: 21.5595, Val Loss: 31.0288
2024-12-27 09:15:12,981 - INFO - Epoch 5/25, Train Loss: 15.0509, Val Loss: 31.4371
2024-12-27 09:15:13,144 - INFO - Epoch 6/25, Train Loss: 12.6064, Val Loss: 31.3449
2024-12-27 09:15:13,144 - INFO - Early stopping triggered at epoch 6
2024-12-27 09:15:13,144 - INFO - Training completed in 1.26s
2024-12-27 09:15:13,145 - INFO - Final memory usage: CPU 1214.0 MB, GPU 19.8 MB
2024-12-27 09:15:13,145 - INFO - Model training completed in 1.27s
2024-12-27 09:15:13,159 - INFO - Prediction completed in 0.01s
2024-12-27 09:15:13,167 - INFO - Poison rate 0.07 completed in 1.29s
2024-12-27 09:15:13,167 - INFO - 
Processing poison rate: 0.1
2024-12-27 09:15:13,183 - INFO - Total number of labels flipped: 500
2024-12-27 09:15:13,183 - INFO - Label flipping completed in 0.02s
2024-12-27 09:15:13,183 - INFO - Training set processing completed in 0.00s
2024-12-27 09:15:13,183 - INFO - Fitting SVMWrapper model with data shape: (5000, 3072)
2024-12-27 09:15:13,184 - INFO - Memory usage at start_fit: CPU 1155.4 MB, GPU 18.3 MB
2024-12-27 09:15:13,184 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:15:13,185 - INFO - Number of unique classes: 43
2024-12-27 09:15:13,411 - INFO - Fitted scaler and transformed data
2024-12-27 09:15:13,412 - INFO - Scaling time: 0.23s
2024-12-27 09:15:13,599 - INFO - Epoch 1/25, Train Loss: 107.2448, Val Loss: 77.5916
2024-12-27 09:15:13,768 - INFO - Epoch 2/25, Train Loss: 43.5491, Val Loss: 58.0933
2024-12-27 09:15:13,952 - INFO - Epoch 3/25, Train Loss: 27.2986, Val Loss: 56.6765
2024-12-27 09:15:14,124 - INFO - Epoch 4/25, Train Loss: 23.9878, Val Loss: 57.2715
2024-12-27 09:15:14,294 - INFO - Epoch 5/25, Train Loss: 24.3124, Val Loss: 64.4635
2024-12-27 09:15:14,294 - INFO - Early stopping triggered at epoch 5
2024-12-27 09:15:14,294 - INFO - Training completed in 1.11s
2024-12-27 09:15:14,294 - INFO - Final memory usage: CPU 1214.1 MB, GPU 19.8 MB
2024-12-27 09:15:14,295 - INFO - Model training completed in 1.11s
2024-12-27 09:15:14,309 - INFO - Prediction completed in 0.01s
2024-12-27 09:15:14,331 - INFO - Poison rate 0.1 completed in 1.16s
2024-12-27 09:15:14,331 - INFO - 
Processing poison rate: 0.2
2024-12-27 09:15:14,362 - INFO - Total number of labels flipped: 1000
2024-12-27 09:15:14,362 - INFO - Label flipping completed in 0.03s
2024-12-27 09:15:14,362 - INFO - Training set processing completed in 0.00s
2024-12-27 09:15:14,363 - INFO - Fitting SVMWrapper model with data shape: (5000, 3072)
2024-12-27 09:15:14,364 - INFO - Memory usage at start_fit: CPU 1155.5 MB, GPU 18.3 MB
2024-12-27 09:15:14,364 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:15:14,364 - INFO - Number of unique classes: 43
2024-12-27 09:15:14,571 - INFO - Fitted scaler and transformed data
2024-12-27 09:15:14,572 - INFO - Scaling time: 0.20s
2024-12-27 09:15:14,776 - INFO - Epoch 1/25, Train Loss: 147.0569, Val Loss: 122.6952
2024-12-27 09:15:15,027 - INFO - Epoch 2/25, Train Loss: 68.9635, Val Loss: 93.0252
2024-12-27 09:15:15,280 - INFO - Epoch 3/25, Train Loss: 46.3612, Val Loss: 82.7131
2024-12-27 09:15:15,515 - INFO - Epoch 4/25, Train Loss: 40.4794, Val Loss: 81.5894
2024-12-27 09:15:15,704 - INFO - Epoch 5/25, Train Loss: 33.9508, Val Loss: 95.1880
2024-12-27 09:15:15,896 - INFO - Epoch 6/25, Train Loss: 32.0534, Val Loss: 75.4209
2024-12-27 09:15:16,144 - INFO - Epoch 7/25, Train Loss: 26.1376, Val Loss: 81.2030
2024-12-27 09:15:16,395 - INFO - Epoch 8/25, Train Loss: 27.2971, Val Loss: 72.8811
2024-12-27 09:15:16,600 - INFO - Epoch 9/25, Train Loss: 26.9365, Val Loss: 81.4803
2024-12-27 09:15:16,833 - INFO - Epoch 10/25, Train Loss: 34.0552, Val Loss: 77.8188
2024-12-27 09:15:16,833 - INFO - Early stopping triggered at epoch 10
2024-12-27 09:15:16,833 - INFO - Training completed in 2.47s
2024-12-27 09:15:16,834 - INFO - Final memory usage: CPU 1214.1 MB, GPU 19.8 MB
2024-12-27 09:15:16,834 - INFO - Model training completed in 2.47s
2024-12-27 09:15:16,854 - INFO - Prediction completed in 0.02s
2024-12-27 09:15:16,871 - INFO - Poison rate 0.2 completed in 2.54s
2024-12-27 09:15:16,873 - INFO - Saved results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_091444.csv
2024-12-27 09:15:16,873 - INFO - Total evaluation time: 31.67s
2024-12-27 09:15:16,877 - INFO - 
Progress: 2.1% - Evaluating GTSRB with SVM (dynadetect mode, iteration 1/1)
2024-12-27 09:15:16,877 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 09:15:16,877 - INFO - Dataset type: image
2024-12-27 09:15:16,877 - INFO - Sample size: 5000
2024-12-27 09:15:16,878 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 09:15:16,878 - INFO - Loading datasets...
2024-12-27 09:15:35,296 - INFO - Dataset loading completed in 18.42s
2024-12-27 09:15:35,296 - INFO - Extracting validation features...
2024-12-27 09:15:35,296 - INFO - Extracting features from 1000 samples...
2024-12-27 09:15:35,690 - INFO - Feature extraction completed. Final feature shape: (1000, 3072)
2024-12-27 09:15:35,690 - INFO - Validation feature extraction completed in 0.39s
2024-12-27 09:15:35,690 - INFO - Extracting training features...
2024-12-27 09:15:35,690 - INFO - Extracting features from 5000 samples...
2024-12-27 09:15:37,646 - INFO - Feature extraction completed. Final feature shape: (5000, 3072)
2024-12-27 09:15:37,647 - INFO - Training feature extraction completed in 1.96s
2024-12-27 09:15:37,647 - INFO - Creating model for classifier: SVM
2024-12-27 09:15:37,647 - INFO - Using device: cuda
2024-12-27 09:15:37,647 - INFO - Created SVMWrapper instance: SVMWrapper
2024-12-27 09:15:37,647 - INFO - 
Processing poison rate: 0.01
2024-12-27 09:15:37,648 - INFO - Total number of labels flipped: 50
2024-12-27 09:15:37,649 - INFO - Label flipping completed in 0.00s
2024-12-27 09:15:37,649 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 09:15:37,649 - INFO - Starting feature scaling on shape (5000, 3072)
2024-12-27 09:15:39,111 - INFO - Feature scaling completed in 1.46s
2024-12-27 09:15:39,112 - INFO - Starting feature selection (k=50)
2024-12-27 09:15:39,326 - INFO - Feature selection completed in 0.21s. Output shape: (5000, 50)
2024-12-27 09:15:39,326 - INFO - Starting anomaly detection
2024-12-27 09:15:41,340 - INFO - Anomaly detection completed in 2.01s
2024-12-27 09:15:41,340 - INFO - Found 500 outliers (10.0%)
2024-12-27 09:15:41,340 - INFO - Total fit_transform time: 3.69s
2024-12-27 09:15:41,340 - INFO - Training set processing completed in 3.69s
2024-12-27 09:15:41,341 - INFO - Fitting SVMWrapper model with data shape: (5000, 3072)
2024-12-27 09:15:41,342 - INFO - Memory usage at start_fit: CPU 1459.0 MB, GPU 16.2 MB
2024-12-27 09:15:41,342 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:15:41,344 - INFO - Number of unique classes: 43
2024-12-27 09:15:41,596 - INFO - Fitted scaler and transformed data
2024-12-27 09:15:41,596 - INFO - Scaling time: 0.25s
2024-12-27 09:15:41,776 - INFO - Epoch 1/25, Train Loss: 79.1414, Val Loss: 32.7495
2024-12-27 09:15:41,957 - INFO - Epoch 2/25, Train Loss: 18.9348, Val Loss: 17.6259
2024-12-27 09:15:42,149 - INFO - Epoch 3/25, Train Loss: 11.0216, Val Loss: 14.3602
2024-12-27 09:15:42,316 - INFO - Epoch 4/25, Train Loss: 8.2844, Val Loss: 21.5818
2024-12-27 09:15:42,493 - INFO - Epoch 5/25, Train Loss: 7.9565, Val Loss: 21.7587
2024-12-27 09:15:42,493 - INFO - Early stopping triggered at epoch 5
2024-12-27 09:15:42,493 - INFO - Training completed in 1.15s
2024-12-27 09:15:42,493 - INFO - Final memory usage: CPU 1532.2 MB, GPU 19.8 MB
2024-12-27 09:15:42,494 - INFO - Model training completed in 1.15s
2024-12-27 09:15:42,509 - INFO - Prediction completed in 0.02s
2024-12-27 09:15:42,518 - INFO - Poison rate 0.01 completed in 4.87s
2024-12-27 09:15:42,518 - INFO - 
Processing poison rate: 0.03
2024-12-27 09:15:42,521 - INFO - Total number of labels flipped: 150
2024-12-27 09:15:42,521 - INFO - Label flipping completed in 0.00s
2024-12-27 09:15:42,521 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 09:15:42,521 - INFO - Starting feature scaling on shape (5000, 3072)
2024-12-27 09:15:43,992 - INFO - Feature scaling completed in 1.47s
2024-12-27 09:15:43,992 - INFO - Starting feature selection (k=50)
2024-12-27 09:15:44,021 - INFO - Feature selection completed in 0.03s. Output shape: (5000, 50)
2024-12-27 09:15:44,021 - INFO - Starting anomaly detection
2024-12-27 09:15:45,649 - INFO - Anomaly detection completed in 1.63s
2024-12-27 09:15:45,650 - INFO - Found 500 outliers (10.0%)
2024-12-27 09:15:45,650 - INFO - Total fit_transform time: 3.13s
2024-12-27 09:15:45,650 - INFO - Training set processing completed in 3.13s
2024-12-27 09:15:45,650 - INFO - Fitting SVMWrapper model with data shape: (5000, 3072)
2024-12-27 09:15:45,651 - INFO - Memory usage at start_fit: CPU 1473.6 MB, GPU 18.3 MB
2024-12-27 09:15:45,651 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:15:45,651 - INFO - Number of unique classes: 43
2024-12-27 09:15:45,860 - INFO - Fitted scaler and transformed data
2024-12-27 09:15:45,861 - INFO - Scaling time: 0.21s
2024-12-27 09:15:46,048 - INFO - Epoch 1/25, Train Loss: 80.4752, Val Loss: 43.0353
2024-12-27 09:15:46,220 - INFO - Epoch 2/25, Train Loss: 19.2617, Val Loss: 37.6998
2024-12-27 09:15:46,389 - INFO - Epoch 3/25, Train Loss: 17.3254, Val Loss: 35.1421
2024-12-27 09:15:46,563 - INFO - Epoch 4/25, Train Loss: 19.3330, Val Loss: 33.0504
2024-12-27 09:15:46,783 - INFO - Epoch 5/25, Train Loss: 12.3218, Val Loss: 28.5270
2024-12-27 09:15:46,967 - INFO - Epoch 6/25, Train Loss: 7.1920, Val Loss: 24.6415
2024-12-27 09:15:47,150 - INFO - Epoch 7/25, Train Loss: 5.6137, Val Loss: 23.5005
2024-12-27 09:15:47,347 - INFO - Epoch 8/25, Train Loss: 9.1038, Val Loss: 33.4697
2024-12-27 09:15:47,522 - INFO - Epoch 9/25, Train Loss: 11.5207, Val Loss: 38.6484
2024-12-27 09:15:47,522 - INFO - Early stopping triggered at epoch 9
2024-12-27 09:15:47,522 - INFO - Training completed in 1.87s
2024-12-27 09:15:47,523 - INFO - Final memory usage: CPU 1533.6 MB, GPU 19.8 MB
2024-12-27 09:15:47,523 - INFO - Model training completed in 1.87s
2024-12-27 09:15:47,538 - INFO - Prediction completed in 0.01s
2024-12-27 09:15:47,546 - INFO - Poison rate 0.03 completed in 5.03s
2024-12-27 09:15:47,547 - INFO - 
Processing poison rate: 0.05
2024-12-27 09:15:47,551 - INFO - Total number of labels flipped: 250
2024-12-27 09:15:47,552 - INFO - Label flipping completed in 0.00s
2024-12-27 09:15:47,552 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 09:15:47,552 - INFO - Starting feature scaling on shape (5000, 3072)
2024-12-27 09:15:49,003 - INFO - Feature scaling completed in 1.45s
2024-12-27 09:15:49,004 - INFO - Starting feature selection (k=50)
2024-12-27 09:15:49,033 - INFO - Feature selection completed in 0.03s. Output shape: (5000, 50)
2024-12-27 09:15:49,033 - INFO - Starting anomaly detection
2024-12-27 09:15:50,332 - INFO - Anomaly detection completed in 1.30s
2024-12-27 09:15:50,332 - INFO - Found 500 outliers (10.0%)
2024-12-27 09:15:50,333 - INFO - Total fit_transform time: 2.78s
2024-12-27 09:15:50,333 - INFO - Training set processing completed in 2.78s
2024-12-27 09:15:50,333 - INFO - Fitting SVMWrapper model with data shape: (5000, 3072)
2024-12-27 09:15:50,334 - INFO - Memory usage at start_fit: CPU 1475.0 MB, GPU 18.3 MB
2024-12-27 09:15:50,335 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:15:50,336 - INFO - Number of unique classes: 43
2024-12-27 09:15:50,586 - INFO - Fitted scaler and transformed data
2024-12-27 09:15:50,587 - INFO - Scaling time: 0.25s
2024-12-27 09:15:50,767 - INFO - Epoch 1/25, Train Loss: 94.0375, Val Loss: 50.7199
2024-12-27 09:15:50,954 - INFO - Epoch 2/25, Train Loss: 34.9513, Val Loss: 34.2299
2024-12-27 09:15:51,119 - INFO - Epoch 3/25, Train Loss: 20.6236, Val Loss: 34.8744
2024-12-27 09:15:51,296 - INFO - Epoch 4/25, Train Loss: 16.6583, Val Loss: 31.8963
2024-12-27 09:15:51,520 - INFO - Epoch 5/25, Train Loss: 13.5913, Val Loss: 30.1777
2024-12-27 09:15:51,691 - INFO - Epoch 6/25, Train Loss: 13.9895, Val Loss: 27.2263
2024-12-27 09:15:51,868 - INFO - Epoch 7/25, Train Loss: 13.5379, Val Loss: 28.9144
2024-12-27 09:15:52,069 - INFO - Epoch 8/25, Train Loss: 9.8479, Val Loss: 29.0068
2024-12-27 09:15:52,069 - INFO - Early stopping triggered at epoch 8
2024-12-27 09:15:52,069 - INFO - Training completed in 1.74s
2024-12-27 09:15:52,070 - INFO - Final memory usage: CPU 1533.6 MB, GPU 19.8 MB
2024-12-27 09:15:52,070 - INFO - Model training completed in 1.74s
2024-12-27 09:15:52,085 - INFO - Prediction completed in 0.01s
2024-12-27 09:15:52,093 - INFO - Poison rate 0.05 completed in 4.55s
2024-12-27 09:15:52,094 - INFO - 
Processing poison rate: 0.07
2024-12-27 09:15:52,100 - INFO - Total number of labels flipped: 350
2024-12-27 09:15:52,100 - INFO - Label flipping completed in 0.01s
2024-12-27 09:15:52,100 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 09:15:52,100 - INFO - Starting feature scaling on shape (5000, 3072)
2024-12-27 09:15:53,663 - INFO - Feature scaling completed in 1.56s
2024-12-27 09:15:53,663 - INFO - Starting feature selection (k=50)
2024-12-27 09:15:53,692 - INFO - Feature selection completed in 0.03s. Output shape: (5000, 50)
2024-12-27 09:15:53,692 - INFO - Starting anomaly detection
2024-12-27 09:15:55,277 - INFO - Anomaly detection completed in 1.59s
2024-12-27 09:15:55,278 - INFO - Found 500 outliers (10.0%)
2024-12-27 09:15:55,278 - INFO - Total fit_transform time: 3.18s
2024-12-27 09:15:55,278 - INFO - Training set processing completed in 3.18s
2024-12-27 09:15:55,278 - INFO - Fitting SVMWrapper model with data shape: (5000, 3072)
2024-12-27 09:15:55,279 - INFO - Memory usage at start_fit: CPU 1475.0 MB, GPU 18.3 MB
2024-12-27 09:15:55,279 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:15:55,279 - INFO - Number of unique classes: 43
2024-12-27 09:15:55,496 - INFO - Fitted scaler and transformed data
2024-12-27 09:15:55,496 - INFO - Scaling time: 0.22s
2024-12-27 09:15:55,674 - INFO - Epoch 1/25, Train Loss: 104.7216, Val Loss: 41.2870
2024-12-27 09:15:55,881 - INFO - Epoch 2/25, Train Loss: 36.1940, Val Loss: 54.0148
2024-12-27 09:15:56,080 - INFO - Epoch 3/25, Train Loss: 24.0607, Val Loss: 41.8785
2024-12-27 09:15:56,081 - INFO - Early stopping triggered at epoch 3
2024-12-27 09:15:56,081 - INFO - Training completed in 0.80s
2024-12-27 09:15:56,081 - INFO - Final memory usage: CPU 1533.7 MB, GPU 19.8 MB
2024-12-27 09:15:56,082 - INFO - Model training completed in 0.80s
2024-12-27 09:15:56,097 - INFO - Prediction completed in 0.01s
2024-12-27 09:15:56,105 - INFO - Poison rate 0.07 completed in 4.01s
2024-12-27 09:15:56,105 - INFO - 
Processing poison rate: 0.1
2024-12-27 09:15:56,116 - INFO - Total number of labels flipped: 500
2024-12-27 09:15:56,116 - INFO - Label flipping completed in 0.01s
2024-12-27 09:15:56,116 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 09:15:56,116 - INFO - Starting feature scaling on shape (5000, 3072)
2024-12-27 09:15:57,552 - INFO - Feature scaling completed in 1.44s
2024-12-27 09:15:57,552 - INFO - Starting feature selection (k=50)
2024-12-27 09:15:57,581 - INFO - Feature selection completed in 0.03s. Output shape: (5000, 50)
2024-12-27 09:15:57,582 - INFO - Starting anomaly detection
2024-12-27 09:15:58,905 - INFO - Anomaly detection completed in 1.32s
2024-12-27 09:15:58,905 - INFO - Found 500 outliers (10.0%)
2024-12-27 09:15:58,905 - INFO - Total fit_transform time: 2.79s
2024-12-27 09:15:58,906 - INFO - Training set processing completed in 2.79s
2024-12-27 09:15:58,906 - INFO - Fitting SVMWrapper model with data shape: (5000, 3072)
2024-12-27 09:15:58,907 - INFO - Memory usage at start_fit: CPU 1475.1 MB, GPU 18.3 MB
2024-12-27 09:15:58,907 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:15:58,908 - INFO - Number of unique classes: 43
2024-12-27 09:15:59,118 - INFO - Fitted scaler and transformed data
2024-12-27 09:15:59,119 - INFO - Scaling time: 0.21s
2024-12-27 09:15:59,297 - INFO - Epoch 1/25, Train Loss: 105.9614, Val Loss: 78.5612
2024-12-27 09:15:59,459 - INFO - Epoch 2/25, Train Loss: 42.3495, Val Loss: 62.1403
2024-12-27 09:15:59,625 - INFO - Epoch 3/25, Train Loss: 36.0143, Val Loss: 63.7492
2024-12-27 09:15:59,795 - INFO - Epoch 4/25, Train Loss: 25.8206, Val Loss: 44.0992
2024-12-27 09:15:59,994 - INFO - Epoch 5/25, Train Loss: 28.0686, Val Loss: 45.5419
2024-12-27 09:16:00,170 - INFO - Epoch 6/25, Train Loss: 21.4610, Val Loss: 45.9948
2024-12-27 09:16:00,170 - INFO - Early stopping triggered at epoch 6
2024-12-27 09:16:00,170 - INFO - Training completed in 1.26s
2024-12-27 09:16:00,170 - INFO - Final memory usage: CPU 1533.7 MB, GPU 19.8 MB
2024-12-27 09:16:00,171 - INFO - Model training completed in 1.27s
2024-12-27 09:16:00,199 - INFO - Prediction completed in 0.03s
2024-12-27 09:16:00,210 - INFO - Poison rate 0.1 completed in 4.10s
2024-12-27 09:16:00,210 - INFO - 
Processing poison rate: 0.2
2024-12-27 09:16:00,229 - INFO - Total number of labels flipped: 1000
2024-12-27 09:16:00,229 - INFO - Label flipping completed in 0.02s
2024-12-27 09:16:00,229 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 09:16:00,229 - INFO - Starting feature scaling on shape (5000, 3072)
2024-12-27 09:16:01,693 - INFO - Feature scaling completed in 1.46s
2024-12-27 09:16:01,694 - INFO - Starting feature selection (k=50)
2024-12-27 09:16:01,722 - INFO - Feature selection completed in 0.03s. Output shape: (5000, 50)
2024-12-27 09:16:01,722 - INFO - Starting anomaly detection
2024-12-27 09:16:03,250 - INFO - Anomaly detection completed in 1.53s
2024-12-27 09:16:03,251 - INFO - Found 500 outliers (10.0%)
2024-12-27 09:16:03,251 - INFO - Total fit_transform time: 3.02s
2024-12-27 09:16:03,251 - INFO - Training set processing completed in 3.02s
2024-12-27 09:16:03,251 - INFO - Fitting SVMWrapper model with data shape: (5000, 3072)
2024-12-27 09:16:03,253 - INFO - Memory usage at start_fit: CPU 1475.2 MB, GPU 18.3 MB
2024-12-27 09:16:03,253 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:16:03,254 - INFO - Number of unique classes: 43
2024-12-27 09:16:03,476 - INFO - Fitted scaler and transformed data
2024-12-27 09:16:03,476 - INFO - Scaling time: 0.22s
2024-12-27 09:16:03,729 - INFO - Epoch 1/25, Train Loss: 134.5548, Val Loss: 88.4862
2024-12-27 09:16:03,915 - INFO - Epoch 2/25, Train Loss: 60.7467, Val Loss: 89.3089
2024-12-27 09:16:04,136 - INFO - Epoch 3/25, Train Loss: 51.9872, Val Loss: 85.3563
2024-12-27 09:16:04,331 - INFO - Epoch 4/25, Train Loss: 37.8288, Val Loss: 79.2003
2024-12-27 09:16:04,522 - INFO - Epoch 5/25, Train Loss: 39.3595, Val Loss: 76.8559
2024-12-27 09:16:04,738 - INFO - Epoch 6/25, Train Loss: 29.3880, Val Loss: 80.2378
2024-12-27 09:16:04,934 - INFO - Epoch 7/25, Train Loss: 33.4108, Val Loss: 86.1465
2024-12-27 09:16:04,934 - INFO - Early stopping triggered at epoch 7
2024-12-27 09:16:04,934 - INFO - Training completed in 1.68s
2024-12-27 09:16:04,934 - INFO - Final memory usage: CPU 1533.6 MB, GPU 19.8 MB
2024-12-27 09:16:04,935 - INFO - Model training completed in 1.68s
2024-12-27 09:16:04,956 - INFO - Prediction completed in 0.02s
2024-12-27 09:16:04,966 - INFO - Poison rate 0.2 completed in 4.76s
2024-12-27 09:16:04,966 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241227_091444.csv
2024-12-27 09:16:04,967 - INFO - Saved results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_091444.csv
2024-12-27 09:16:04,967 - INFO - Total evaluation time: 48.09s
2024-12-27 09:16:04,970 - INFO - 
Progress: 3.1% - Evaluating GTSRB with LogisticRegression (standard mode, iteration 1/1)
2024-12-27 09:16:04,970 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 09:16:04,970 - INFO - Dataset type: image
2024-12-27 09:16:04,970 - INFO - Sample size: 5000
2024-12-27 09:16:04,970 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 09:16:04,971 - INFO - Loading datasets...
2024-12-27 09:16:23,234 - INFO - Dataset loading completed in 18.26s
2024-12-27 09:16:23,235 - INFO - Extracting validation features...
2024-12-27 09:16:23,235 - INFO - Extracting features from 1000 samples...
2024-12-27 09:16:23,617 - INFO - Feature extraction completed. Final feature shape: (1000, 3072)
2024-12-27 09:16:23,618 - INFO - Validation feature extraction completed in 0.38s
2024-12-27 09:16:23,618 - INFO - Extracting training features...
2024-12-27 09:16:23,618 - INFO - Extracting features from 5000 samples...
2024-12-27 09:16:25,606 - INFO - Feature extraction completed. Final feature shape: (5000, 3072)
2024-12-27 09:16:25,606 - INFO - Training feature extraction completed in 1.99s
2024-12-27 09:16:25,606 - INFO - Creating model for classifier: LogisticRegression
2024-12-27 09:16:25,606 - INFO - Using device: cuda
2024-12-27 09:16:25,606 - INFO - 
Processing poison rate: 0.01
2024-12-27 09:16:25,608 - INFO - Total number of labels flipped: 50
2024-12-27 09:16:25,608 - INFO - Label flipping completed in 0.00s
2024-12-27 09:16:25,608 - INFO - Training set processing completed in 0.00s
2024-12-27 09:16:25,608 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 3072)
2024-12-27 09:16:25,609 - INFO - Memory usage at start_fit: CPU 1517.9 MB, GPU 16.2 MB
2024-12-27 09:16:25,609 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:16:25,610 - INFO - Number of unique classes: 43
2024-12-27 09:16:25,854 - INFO - Fitted scaler and transformed data
2024-12-27 09:16:25,855 - INFO - Scaling time: 0.24s
2024-12-27 09:16:26,087 - INFO - Epoch 1/200, Train Loss: 12.0984, Val Loss: 5.2937
2024-12-27 09:16:26,281 - INFO - Epoch 2/200, Train Loss: 2.9637, Val Loss: 3.0457
2024-12-27 09:16:26,507 - INFO - Epoch 3/200, Train Loss: 1.9904, Val Loss: 2.5232
2024-12-27 09:16:26,699 - INFO - Epoch 4/200, Train Loss: 1.9335, Val Loss: 2.1829
2024-12-27 09:16:26,884 - INFO - Epoch 5/200, Train Loss: 2.0219, Val Loss: 3.4986
2024-12-27 09:16:27,052 - INFO - Epoch 6/200, Train Loss: 2.2907, Val Loss: 2.6916
2024-12-27 09:16:27,052 - INFO - Early stopping triggered at epoch 6
2024-12-27 09:16:27,053 - INFO - Training completed in 1.44s
2024-12-27 09:16:27,053 - INFO - Final memory usage: CPU 1591.4 MB, GPU 19.8 MB
2024-12-27 09:16:27,055 - INFO - Model training completed in 1.45s
2024-12-27 09:16:27,076 - INFO - Prediction completed in 0.02s
2024-12-27 09:16:27,085 - INFO - Poison rate 0.01 completed in 1.48s
2024-12-27 09:16:27,085 - INFO - 
Processing poison rate: 0.03
2024-12-27 09:16:27,088 - INFO - Total number of labels flipped: 150
2024-12-27 09:16:27,088 - INFO - Label flipping completed in 0.00s
2024-12-27 09:16:27,088 - INFO - Training set processing completed in 0.00s
2024-12-27 09:16:27,088 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 3072)
2024-12-27 09:16:27,089 - INFO - Memory usage at start_fit: CPU 1535.2 MB, GPU 18.3 MB
2024-12-27 09:16:27,089 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:16:27,090 - INFO - Number of unique classes: 43
2024-12-27 09:16:27,319 - INFO - Fitted scaler and transformed data
2024-12-27 09:16:27,320 - INFO - Scaling time: 0.23s
2024-12-27 09:16:27,540 - INFO - Epoch 1/200, Train Loss: 10.7268, Val Loss: 5.5937
2024-12-27 09:16:27,735 - INFO - Epoch 2/200, Train Loss: 4.1230, Val Loss: 4.5723
2024-12-27 09:16:27,921 - INFO - Epoch 3/200, Train Loss: 2.6547, Val Loss: 3.8670
2024-12-27 09:16:28,116 - INFO - Epoch 4/200, Train Loss: 2.3828, Val Loss: 2.6413
2024-12-27 09:16:28,292 - INFO - Epoch 5/200, Train Loss: 1.9138, Val Loss: 4.6354
2024-12-27 09:16:28,504 - INFO - Epoch 6/200, Train Loss: 2.2521, Val Loss: 3.1946
2024-12-27 09:16:28,504 - INFO - Early stopping triggered at epoch 6
2024-12-27 09:16:28,505 - INFO - Training completed in 1.42s
2024-12-27 09:16:28,505 - INFO - Final memory usage: CPU 1593.9 MB, GPU 19.8 MB
2024-12-27 09:16:28,507 - INFO - Model training completed in 1.42s
2024-12-27 09:16:28,531 - INFO - Prediction completed in 0.02s
2024-12-27 09:16:28,540 - INFO - Poison rate 0.03 completed in 1.45s
2024-12-27 09:16:28,540 - INFO - 
Processing poison rate: 0.05
2024-12-27 09:16:28,544 - INFO - Total number of labels flipped: 250
2024-12-27 09:16:28,545 - INFO - Label flipping completed in 0.00s
2024-12-27 09:16:28,545 - INFO - Training set processing completed in 0.00s
2024-12-27 09:16:28,545 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 3072)
2024-12-27 09:16:28,546 - INFO - Memory usage at start_fit: CPU 1535.3 MB, GPU 18.3 MB
2024-12-27 09:16:28,546 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:16:28,546 - INFO - Number of unique classes: 43
2024-12-27 09:16:28,780 - INFO - Fitted scaler and transformed data
2024-12-27 09:16:28,781 - INFO - Scaling time: 0.23s
2024-12-27 09:16:28,983 - INFO - Epoch 1/200, Train Loss: 11.6551, Val Loss: 5.9180
2024-12-27 09:16:29,206 - INFO - Epoch 2/200, Train Loss: 4.5081, Val Loss: 3.8800
2024-12-27 09:16:29,433 - INFO - Epoch 3/200, Train Loss: 3.3995, Val Loss: 3.2835
2024-12-27 09:16:29,616 - INFO - Epoch 4/200, Train Loss: 3.4506, Val Loss: 3.6552
2024-12-27 09:16:29,848 - INFO - Epoch 5/200, Train Loss: 2.3635, Val Loss: 3.7270
2024-12-27 09:16:29,849 - INFO - Early stopping triggered at epoch 5
2024-12-27 09:16:29,849 - INFO - Training completed in 1.30s
2024-12-27 09:16:29,849 - INFO - Final memory usage: CPU 1593.9 MB, GPU 19.8 MB
2024-12-27 09:16:29,850 - INFO - Model training completed in 1.31s
2024-12-27 09:16:29,869 - INFO - Prediction completed in 0.02s
2024-12-27 09:16:29,877 - INFO - Poison rate 0.05 completed in 1.34s
2024-12-27 09:16:29,877 - INFO - 
Processing poison rate: 0.07
2024-12-27 09:16:29,884 - INFO - Total number of labels flipped: 350
2024-12-27 09:16:29,884 - INFO - Label flipping completed in 0.01s
2024-12-27 09:16:29,884 - INFO - Training set processing completed in 0.00s
2024-12-27 09:16:29,884 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 3072)
2024-12-27 09:16:29,885 - INFO - Memory usage at start_fit: CPU 1535.3 MB, GPU 18.3 MB
2024-12-27 09:16:29,885 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:16:29,885 - INFO - Number of unique classes: 43
2024-12-27 09:16:30,100 - INFO - Fitted scaler and transformed data
2024-12-27 09:16:30,101 - INFO - Scaling time: 0.21s
2024-12-27 09:16:30,291 - INFO - Epoch 1/200, Train Loss: 12.8978, Val Loss: 8.1021
2024-12-27 09:16:30,483 - INFO - Epoch 2/200, Train Loss: 5.0653, Val Loss: 3.8970
2024-12-27 09:16:30,684 - INFO - Epoch 3/200, Train Loss: 3.1412, Val Loss: 3.4352
2024-12-27 09:16:30,922 - INFO - Epoch 4/200, Train Loss: 2.5155, Val Loss: 3.9477
2024-12-27 09:16:31,113 - INFO - Epoch 5/200, Train Loss: 3.2450, Val Loss: 5.3996
2024-12-27 09:16:31,114 - INFO - Early stopping triggered at epoch 5
2024-12-27 09:16:31,114 - INFO - Training completed in 1.23s
2024-12-27 09:16:31,115 - INFO - Final memory usage: CPU 1593.9 MB, GPU 19.8 MB
2024-12-27 09:16:31,116 - INFO - Model training completed in 1.23s
2024-12-27 09:16:31,143 - INFO - Prediction completed in 0.03s
2024-12-27 09:16:31,152 - INFO - Poison rate 0.07 completed in 1.27s
2024-12-27 09:16:31,152 - INFO - 
Processing poison rate: 0.1
2024-12-27 09:16:31,162 - INFO - Total number of labels flipped: 500
2024-12-27 09:16:31,162 - INFO - Label flipping completed in 0.01s
2024-12-27 09:16:31,162 - INFO - Training set processing completed in 0.00s
2024-12-27 09:16:31,162 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 3072)
2024-12-27 09:16:31,163 - INFO - Memory usage at start_fit: CPU 1535.3 MB, GPU 18.3 MB
2024-12-27 09:16:31,163 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:16:31,163 - INFO - Number of unique classes: 43
2024-12-27 09:16:31,372 - INFO - Fitted scaler and transformed data
2024-12-27 09:16:31,373 - INFO - Scaling time: 0.21s
2024-12-27 09:16:31,585 - INFO - Epoch 1/200, Train Loss: 13.9845, Val Loss: 8.2807
2024-12-27 09:16:31,797 - INFO - Epoch 2/200, Train Loss: 5.8933, Val Loss: 5.2544
2024-12-27 09:16:31,983 - INFO - Epoch 3/200, Train Loss: 4.2884, Val Loss: 4.0693
2024-12-27 09:16:32,167 - INFO - Epoch 4/200, Train Loss: 3.7950, Val Loss: 4.7186
2024-12-27 09:16:32,366 - INFO - Epoch 5/200, Train Loss: 3.3955, Val Loss: 4.8654
2024-12-27 09:16:32,366 - INFO - Early stopping triggered at epoch 5
2024-12-27 09:16:32,367 - INFO - Training completed in 1.20s
2024-12-27 09:16:32,368 - INFO - Final memory usage: CPU 1594.0 MB, GPU 19.8 MB
2024-12-27 09:16:32,369 - INFO - Model training completed in 1.21s
2024-12-27 09:16:32,400 - INFO - Prediction completed in 0.03s
2024-12-27 09:16:32,418 - INFO - Poison rate 0.1 completed in 1.27s
2024-12-27 09:16:32,419 - INFO - 
Processing poison rate: 0.2
2024-12-27 09:16:32,439 - INFO - Total number of labels flipped: 1000
2024-12-27 09:16:32,439 - INFO - Label flipping completed in 0.02s
2024-12-27 09:16:32,439 - INFO - Training set processing completed in 0.00s
2024-12-27 09:16:32,439 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 3072)
2024-12-27 09:16:32,440 - INFO - Memory usage at start_fit: CPU 1535.4 MB, GPU 18.3 MB
2024-12-27 09:16:32,441 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:16:32,442 - INFO - Number of unique classes: 43
2024-12-27 09:16:32,636 - INFO - Fitted scaler and transformed data
2024-12-27 09:16:32,637 - INFO - Scaling time: 0.19s
2024-12-27 09:16:32,856 - INFO - Epoch 1/200, Train Loss: 13.5390, Val Loss: 9.0615
2024-12-27 09:16:33,039 - INFO - Epoch 2/200, Train Loss: 6.6302, Val Loss: 7.3714
2024-12-27 09:16:33,270 - INFO - Epoch 3/200, Train Loss: 4.8854, Val Loss: 6.8953
2024-12-27 09:16:33,438 - INFO - Epoch 4/200, Train Loss: 4.6041, Val Loss: 6.7996
2024-12-27 09:16:33,620 - INFO - Epoch 5/200, Train Loss: 4.5016, Val Loss: 6.3405
2024-12-27 09:16:33,807 - INFO - Epoch 6/200, Train Loss: 4.4561, Val Loss: 7.0552
2024-12-27 09:16:33,988 - INFO - Epoch 7/200, Train Loss: 3.7516, Val Loss: 6.9734
2024-12-27 09:16:33,988 - INFO - Early stopping triggered at epoch 7
2024-12-27 09:16:33,988 - INFO - Training completed in 1.55s
2024-12-27 09:16:33,989 - INFO - Final memory usage: CPU 1594.0 MB, GPU 19.8 MB
2024-12-27 09:16:33,990 - INFO - Model training completed in 1.55s
2024-12-27 09:16:34,026 - INFO - Prediction completed in 0.03s
2024-12-27 09:16:34,036 - INFO - Poison rate 0.2 completed in 1.62s
2024-12-27 09:16:34,036 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241227_091444.csv
2024-12-27 09:16:34,037 - INFO - Saved results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_091444.csv
2024-12-27 09:16:34,037 - INFO - Total evaluation time: 29.07s
2024-12-27 09:16:34,040 - INFO - 
Progress: 4.2% - Evaluating GTSRB with LogisticRegression (dynadetect mode, iteration 1/1)
2024-12-27 09:16:34,040 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 09:16:34,040 - INFO - Dataset type: image
2024-12-27 09:16:34,040 - INFO - Sample size: 5000
2024-12-27 09:16:34,040 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 09:16:34,041 - INFO - Loading datasets...
2024-12-27 09:16:52,941 - INFO - Dataset loading completed in 18.90s
2024-12-27 09:16:52,942 - INFO - Extracting validation features...
2024-12-27 09:16:52,942 - INFO - Extracting features from 1000 samples...
2024-12-27 09:16:53,343 - INFO - Feature extraction completed. Final feature shape: (1000, 3072)
2024-12-27 09:16:53,344 - INFO - Validation feature extraction completed in 0.40s
2024-12-27 09:16:53,344 - INFO - Extracting training features...
2024-12-27 09:16:53,344 - INFO - Extracting features from 5000 samples...
2024-12-27 09:16:55,238 - INFO - Feature extraction completed. Final feature shape: (5000, 3072)
2024-12-27 09:16:55,238 - INFO - Training feature extraction completed in 1.89s
2024-12-27 09:16:55,238 - INFO - Creating model for classifier: LogisticRegression
2024-12-27 09:16:55,239 - INFO - Using device: cuda
2024-12-27 09:16:55,239 - INFO - 
Processing poison rate: 0.01
2024-12-27 09:16:55,240 - INFO - Total number of labels flipped: 50
2024-12-27 09:16:55,241 - INFO - Label flipping completed in 0.00s
2024-12-27 09:16:55,241 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 09:16:55,241 - INFO - Starting feature scaling on shape (5000, 3072)
2024-12-27 09:16:56,686 - INFO - Feature scaling completed in 1.45s
2024-12-27 09:16:56,687 - INFO - Starting feature selection (k=50)
2024-12-27 09:16:56,717 - INFO - Feature selection completed in 0.03s. Output shape: (5000, 50)
2024-12-27 09:16:56,717 - INFO - Starting anomaly detection
2024-12-27 09:16:58,700 - INFO - Anomaly detection completed in 1.98s
2024-12-27 09:16:58,700 - INFO - Found 500 outliers (10.0%)
2024-12-27 09:16:58,700 - INFO - Total fit_transform time: 3.46s
2024-12-27 09:16:58,701 - INFO - Training set processing completed in 3.46s
2024-12-27 09:16:58,701 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 3072)
2024-12-27 09:16:58,702 - INFO - Memory usage at start_fit: CPU 1557.0 MB, GPU 16.2 MB
2024-12-27 09:16:58,703 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:16:58,703 - INFO - Number of unique classes: 43
2024-12-27 09:16:58,931 - INFO - Fitted scaler and transformed data
2024-12-27 09:16:58,931 - INFO - Scaling time: 0.22s
2024-12-27 09:16:59,073 - INFO - Epoch 1/200, Train Loss: 10.8148, Val Loss: 4.6806
2024-12-27 09:16:59,197 - INFO - Epoch 2/200, Train Loss: 3.1517, Val Loss: 3.6987
2024-12-27 09:16:59,329 - INFO - Epoch 3/200, Train Loss: 2.6091, Val Loss: 3.1433
2024-12-27 09:16:59,461 - INFO - Epoch 4/200, Train Loss: 2.2213, Val Loss: 2.9276
2024-12-27 09:16:59,585 - INFO - Epoch 5/200, Train Loss: 2.6797, Val Loss: 3.1629
2024-12-27 09:16:59,730 - INFO - Epoch 6/200, Train Loss: 1.7427, Val Loss: 2.4788
2024-12-27 09:16:59,856 - INFO - Epoch 7/200, Train Loss: 1.7416, Val Loss: 2.7291
2024-12-27 09:16:59,982 - INFO - Epoch 8/200, Train Loss: 1.6202, Val Loss: 2.7013
2024-12-27 09:16:59,982 - INFO - Early stopping triggered at epoch 8
2024-12-27 09:16:59,983 - INFO - Training completed in 1.28s
2024-12-27 09:16:59,983 - INFO - Final memory usage: CPU 1615.7 MB, GPU 19.8 MB
2024-12-27 09:16:59,984 - INFO - Model training completed in 1.28s
2024-12-27 09:17:00,016 - INFO - Prediction completed in 0.03s
2024-12-27 09:17:00,033 - INFO - Poison rate 0.01 completed in 4.79s
2024-12-27 09:17:00,033 - INFO - 
Processing poison rate: 0.03
2024-12-27 09:17:00,037 - INFO - Total number of labels flipped: 150
2024-12-27 09:17:00,037 - INFO - Label flipping completed in 0.00s
2024-12-27 09:17:00,037 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 09:17:00,037 - INFO - Starting feature scaling on shape (5000, 3072)
2024-12-27 09:17:01,533 - INFO - Feature scaling completed in 1.50s
2024-12-27 09:17:01,534 - INFO - Starting feature selection (k=50)
2024-12-27 09:17:01,563 - INFO - Feature selection completed in 0.03s. Output shape: (5000, 50)
2024-12-27 09:17:01,563 - INFO - Starting anomaly detection
2024-12-27 09:17:03,689 - INFO - Anomaly detection completed in 2.13s
2024-12-27 09:17:03,690 - INFO - Found 500 outliers (10.0%)
2024-12-27 09:17:03,690 - INFO - Total fit_transform time: 3.65s
2024-12-27 09:17:03,690 - INFO - Training set processing completed in 3.65s
2024-12-27 09:17:03,690 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 3072)
2024-12-27 09:17:03,691 - INFO - Memory usage at start_fit: CPU 1557.1 MB, GPU 18.3 MB
2024-12-27 09:17:03,691 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:17:03,692 - INFO - Number of unique classes: 43
2024-12-27 09:17:03,932 - INFO - Fitted scaler and transformed data
2024-12-27 09:17:03,932 - INFO - Scaling time: 0.24s
2024-12-27 09:17:04,068 - INFO - Epoch 1/200, Train Loss: 10.1399, Val Loss: 5.3725
2024-12-27 09:17:04,193 - INFO - Epoch 2/200, Train Loss: 3.3682, Val Loss: 3.9215
2024-12-27 09:17:04,335 - INFO - Epoch 3/200, Train Loss: 2.7148, Val Loss: 3.8695
2024-12-27 09:17:04,489 - INFO - Epoch 4/200, Train Loss: 2.2376, Val Loss: 3.5801
2024-12-27 09:17:04,621 - INFO - Epoch 5/200, Train Loss: 2.0349, Val Loss: 3.7591
2024-12-27 09:17:04,786 - INFO - Epoch 6/200, Train Loss: 1.6461, Val Loss: 4.2609
2024-12-27 09:17:04,787 - INFO - Early stopping triggered at epoch 6
2024-12-27 09:17:04,787 - INFO - Training completed in 1.10s
2024-12-27 09:17:04,787 - INFO - Final memory usage: CPU 1615.6 MB, GPU 19.8 MB
2024-12-27 09:17:04,787 - INFO - Model training completed in 1.10s
2024-12-27 09:17:04,804 - INFO - Prediction completed in 0.02s
2024-12-27 09:17:04,826 - INFO - Poison rate 0.03 completed in 4.79s
2024-12-27 09:17:04,827 - INFO - 
Processing poison rate: 0.05
2024-12-27 09:17:04,836 - INFO - Total number of labels flipped: 250
2024-12-27 09:17:04,836 - INFO - Label flipping completed in 0.01s
2024-12-27 09:17:04,836 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 09:17:04,836 - INFO - Starting feature scaling on shape (5000, 3072)
2024-12-27 09:17:06,315 - INFO - Feature scaling completed in 1.48s
2024-12-27 09:17:06,315 - INFO - Starting feature selection (k=50)
2024-12-27 09:17:06,345 - INFO - Feature selection completed in 0.03s. Output shape: (5000, 50)
2024-12-27 09:17:06,345 - INFO - Starting anomaly detection
2024-12-27 09:17:07,887 - INFO - Anomaly detection completed in 1.54s
2024-12-27 09:17:07,887 - INFO - Found 500 outliers (10.0%)
2024-12-27 09:17:07,887 - INFO - Total fit_transform time: 3.05s
2024-12-27 09:17:07,888 - INFO - Training set processing completed in 3.05s
2024-12-27 09:17:07,888 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 3072)
2024-12-27 09:17:07,889 - INFO - Memory usage at start_fit: CPU 1557.0 MB, GPU 18.3 MB
2024-12-27 09:17:07,889 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:17:07,889 - INFO - Number of unique classes: 43
2024-12-27 09:17:08,105 - INFO - Fitted scaler and transformed data
2024-12-27 09:17:08,106 - INFO - Scaling time: 0.21s
2024-12-27 09:17:08,227 - INFO - Epoch 1/200, Train Loss: 10.7570, Val Loss: 5.5155
2024-12-27 09:17:08,349 - INFO - Epoch 2/200, Train Loss: 3.8227, Val Loss: 3.4454
2024-12-27 09:17:08,472 - INFO - Epoch 3/200, Train Loss: 2.5923, Val Loss: 4.2795
2024-12-27 09:17:08,594 - INFO - Epoch 4/200, Train Loss: 3.3741, Val Loss: 5.3224
2024-12-27 09:17:08,594 - INFO - Early stopping triggered at epoch 4
2024-12-27 09:17:08,594 - INFO - Training completed in 0.71s
2024-12-27 09:17:08,594 - INFO - Final memory usage: CPU 1615.7 MB, GPU 19.8 MB
2024-12-27 09:17:08,595 - INFO - Model training completed in 0.71s
2024-12-27 09:17:08,610 - INFO - Prediction completed in 0.01s
2024-12-27 09:17:08,630 - INFO - Poison rate 0.05 completed in 3.80s
2024-12-27 09:17:08,631 - INFO - 
Processing poison rate: 0.07
2024-12-27 09:17:08,646 - INFO - Total number of labels flipped: 350
2024-12-27 09:17:08,646 - INFO - Label flipping completed in 0.01s
2024-12-27 09:17:08,646 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 09:17:08,646 - INFO - Starting feature scaling on shape (5000, 3072)
2024-12-27 09:17:10,107 - INFO - Feature scaling completed in 1.46s
2024-12-27 09:17:10,107 - INFO - Starting feature selection (k=50)
2024-12-27 09:17:10,123 - INFO - Feature selection completed in 0.02s. Output shape: (5000, 50)
2024-12-27 09:17:10,123 - INFO - Starting anomaly detection
2024-12-27 09:17:11,728 - INFO - Anomaly detection completed in 1.61s
2024-12-27 09:17:11,729 - INFO - Found 500 outliers (10.0%)
2024-12-27 09:17:11,729 - INFO - Total fit_transform time: 3.08s
2024-12-27 09:17:11,729 - INFO - Training set processing completed in 3.08s
2024-12-27 09:17:11,729 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 3072)
2024-12-27 09:17:11,730 - INFO - Memory usage at start_fit: CPU 1557.1 MB, GPU 18.3 MB
2024-12-27 09:17:11,730 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:17:11,731 - INFO - Number of unique classes: 43
2024-12-27 09:17:11,937 - INFO - Fitted scaler and transformed data
2024-12-27 09:17:11,938 - INFO - Scaling time: 0.21s
2024-12-27 09:17:12,107 - INFO - Epoch 1/200, Train Loss: 10.5028, Val Loss: 5.9982
2024-12-27 09:17:12,288 - INFO - Epoch 2/200, Train Loss: 4.3168, Val Loss: 5.3418
2024-12-27 09:17:12,505 - INFO - Epoch 3/200, Train Loss: 4.0437, Val Loss: 4.6858
2024-12-27 09:17:12,688 - INFO - Epoch 4/200, Train Loss: 3.0854, Val Loss: 4.7102
2024-12-27 09:17:12,909 - INFO - Epoch 5/200, Train Loss: 3.3332, Val Loss: 5.8650
2024-12-27 09:17:12,910 - INFO - Early stopping triggered at epoch 5
2024-12-27 09:17:12,910 - INFO - Training completed in 1.18s
2024-12-27 09:17:12,910 - INFO - Final memory usage: CPU 1615.7 MB, GPU 19.8 MB
2024-12-27 09:17:12,911 - INFO - Model training completed in 1.18s
2024-12-27 09:17:12,936 - INFO - Prediction completed in 0.02s
2024-12-27 09:17:12,945 - INFO - Poison rate 0.07 completed in 4.31s
2024-12-27 09:17:12,945 - INFO - 
Processing poison rate: 0.1
2024-12-27 09:17:12,954 - INFO - Total number of labels flipped: 500
2024-12-27 09:17:12,954 - INFO - Label flipping completed in 0.01s
2024-12-27 09:17:12,954 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 09:17:12,954 - INFO - Starting feature scaling on shape (5000, 3072)
2024-12-27 09:17:14,360 - INFO - Feature scaling completed in 1.41s
2024-12-27 09:17:14,360 - INFO - Starting feature selection (k=50)
2024-12-27 09:17:14,390 - INFO - Feature selection completed in 0.03s. Output shape: (5000, 50)
2024-12-27 09:17:14,390 - INFO - Starting anomaly detection
2024-12-27 09:17:15,835 - INFO - Anomaly detection completed in 1.45s
2024-12-27 09:17:15,836 - INFO - Found 500 outliers (10.0%)
2024-12-27 09:17:15,836 - INFO - Total fit_transform time: 2.88s
2024-12-27 09:17:15,837 - INFO - Training set processing completed in 2.88s
2024-12-27 09:17:15,837 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 3072)
2024-12-27 09:17:15,839 - INFO - Memory usage at start_fit: CPU 1557.2 MB, GPU 18.3 MB
2024-12-27 09:17:15,839 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:17:15,840 - INFO - Number of unique classes: 43
2024-12-27 09:17:16,048 - INFO - Fitted scaler and transformed data
2024-12-27 09:17:16,049 - INFO - Scaling time: 0.21s
2024-12-27 09:17:16,215 - INFO - Epoch 1/200, Train Loss: 12.6043, Val Loss: 7.5455
2024-12-27 09:17:16,415 - INFO - Epoch 2/200, Train Loss: 5.0003, Val Loss: 4.5843
2024-12-27 09:17:16,635 - INFO - Epoch 3/200, Train Loss: 3.4771, Val Loss: 5.0597
2024-12-27 09:17:16,773 - INFO - Epoch 4/200, Train Loss: 3.2456, Val Loss: 4.4962
2024-12-27 09:17:16,897 - INFO - Epoch 5/200, Train Loss: 3.3438, Val Loss: 4.9108
2024-12-27 09:17:17,044 - INFO - Epoch 6/200, Train Loss: 3.4955, Val Loss: 5.7666
2024-12-27 09:17:17,044 - INFO - Early stopping triggered at epoch 6
2024-12-27 09:17:17,044 - INFO - Training completed in 1.21s
2024-12-27 09:17:17,044 - INFO - Final memory usage: CPU 1615.8 MB, GPU 19.8 MB
2024-12-27 09:17:17,045 - INFO - Model training completed in 1.21s
2024-12-27 09:17:17,073 - INFO - Prediction completed in 0.03s
2024-12-27 09:17:17,096 - INFO - Poison rate 0.1 completed in 4.15s
2024-12-27 09:17:17,096 - INFO - 
Processing poison rate: 0.2
2024-12-27 09:17:17,121 - INFO - Total number of labels flipped: 1000
2024-12-27 09:17:17,121 - INFO - Label flipping completed in 0.02s
2024-12-27 09:17:17,121 - INFO - Initialized DynaDetect trainer on cuda
2024-12-27 09:17:17,121 - INFO - Starting feature scaling on shape (5000, 3072)
2024-12-27 09:17:18,603 - INFO - Feature scaling completed in 1.48s
2024-12-27 09:17:18,603 - INFO - Starting feature selection (k=50)
2024-12-27 09:17:18,625 - INFO - Feature selection completed in 0.02s. Output shape: (5000, 50)
2024-12-27 09:17:18,626 - INFO - Starting anomaly detection
2024-12-27 09:17:19,814 - INFO - Anomaly detection completed in 1.19s
2024-12-27 09:17:19,815 - INFO - Found 500 outliers (10.0%)
2024-12-27 09:17:19,815 - INFO - Total fit_transform time: 2.69s
2024-12-27 09:17:19,815 - INFO - Training set processing completed in 2.69s
2024-12-27 09:17:19,815 - INFO - Fitting LogisticRegressionWrapper model with data shape: (5000, 3072)
2024-12-27 09:17:19,816 - INFO - Memory usage at start_fit: CPU 1557.2 MB, GPU 18.3 MB
2024-12-27 09:17:19,817 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:17:19,817 - INFO - Number of unique classes: 43
2024-12-27 09:17:20,022 - INFO - Fitted scaler and transformed data
2024-12-27 09:17:20,023 - INFO - Scaling time: 0.20s
2024-12-27 09:17:20,161 - INFO - Epoch 1/200, Train Loss: 14.5844, Val Loss: 8.3602
2024-12-27 09:17:20,285 - INFO - Epoch 2/200, Train Loss: 6.5027, Val Loss: 6.6219
2024-12-27 09:17:20,411 - INFO - Epoch 3/200, Train Loss: 5.2123, Val Loss: 6.0772
2024-12-27 09:17:20,534 - INFO - Epoch 4/200, Train Loss: 4.8182, Val Loss: 7.0469
2024-12-27 09:17:20,646 - INFO - Epoch 5/200, Train Loss: 4.6390, Val Loss: 5.9569
2024-12-27 09:17:20,762 - INFO - Epoch 6/200, Train Loss: 4.0695, Val Loss: 6.8083
2024-12-27 09:17:20,879 - INFO - Epoch 7/200, Train Loss: 4.4133, Val Loss: 6.6307
2024-12-27 09:17:20,879 - INFO - Early stopping triggered at epoch 7
2024-12-27 09:17:20,880 - INFO - Training completed in 1.06s
2024-12-27 09:17:20,881 - INFO - Final memory usage: CPU 1615.9 MB, GPU 19.8 MB
2024-12-27 09:17:20,882 - INFO - Model training completed in 1.07s
2024-12-27 09:17:20,909 - INFO - Prediction completed in 0.03s
2024-12-27 09:17:20,920 - INFO - Poison rate 0.2 completed in 3.82s
2024-12-27 09:17:20,921 - INFO - Archived existing results to /home/brian/Notebooks/ddv2-ws/results/archive/experiment_results_20241227_091444.csv
2024-12-27 09:17:20,922 - INFO - Saved results to /home/brian/Notebooks/ddv2-ws/results/experiment_results_20241227_091444.csv
2024-12-27 09:17:20,922 - INFO - Total evaluation time: 46.88s
2024-12-27 09:17:20,924 - INFO - 
Progress: 5.2% - Evaluating GTSRB with RandomForest (standard mode, iteration 1/1)
2024-12-27 09:17:20,924 - INFO - Initialized DatasetHandler for GTSRB
2024-12-27 09:17:20,925 - INFO - Dataset type: image
2024-12-27 09:17:20,925 - INFO - Sample size: 5000
2024-12-27 09:17:20,925 - INFO - GTSRB dataset will be downloaded through torchvision if needed
2024-12-27 09:17:20,925 - INFO - Loading datasets...
2024-12-27 09:17:39,709 - INFO - Dataset loading completed in 18.78s
2024-12-27 09:17:39,709 - INFO - Extracting validation features...
2024-12-27 09:17:39,709 - INFO - Extracting features from 1000 samples...
2024-12-27 09:17:40,120 - INFO - Feature extraction completed. Final feature shape: (1000, 3072)
2024-12-27 09:17:40,120 - INFO - Validation feature extraction completed in 0.41s
2024-12-27 09:17:40,120 - INFO - Extracting training features...
2024-12-27 09:17:40,120 - INFO - Extracting features from 5000 samples...
2024-12-27 09:17:42,224 - INFO - Feature extraction completed. Final feature shape: (5000, 3072)
2024-12-27 09:17:42,224 - INFO - Training feature extraction completed in 2.10s
2024-12-27 09:17:42,224 - INFO - Creating model for classifier: RandomForest
2024-12-27 09:17:42,224 - INFO - Using device: cuda
2024-12-27 09:17:42,225 - INFO - 
Processing poison rate: 0.01
2024-12-27 09:17:42,228 - INFO - Total number of labels flipped: 50
2024-12-27 09:17:42,228 - INFO - Label flipping completed in 0.00s
2024-12-27 09:17:42,228 - INFO - Training set processing completed in 0.00s
2024-12-27 09:17:42,228 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 3072)
2024-12-27 09:17:42,229 - INFO - Memory usage at start_fit: CPU 1557.4 MB, GPU 16.2 MB
2024-12-27 09:17:42,229 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:17:42,415 - INFO - Fitted scaler and transformed data
2024-12-27 09:17:42,416 - INFO - Scaling time: 0.19s
2024-12-27 09:17:42,444 - INFO - Number of unique classes: 43
2024-12-27 09:17:45,657 - INFO - Epoch 1/15, Train Loss: 3.7605, Val Loss: 3.7597
2024-12-27 09:17:48,915 - INFO - Epoch 2/15, Train Loss: 3.7579, Val Loss: 3.7579
2024-12-27 09:17:51,940 - INFO - Epoch 3/15, Train Loss: 3.7551, Val Loss: 3.7559
2024-12-27 09:17:51,940 - INFO - Early stopping triggered at epoch 3
2024-12-27 09:17:51,940 - INFO - Training completed in 9.71s
2024-12-27 09:17:51,941 - INFO - Final memory usage: CPU 1590.6 MB, GPU 89.3 MB
2024-12-27 09:17:51,941 - INFO - Model training completed in 9.71s
2024-12-27 09:17:52,057 - INFO - Prediction completed in 0.12s
2024-12-27 09:17:52,065 - INFO - Poison rate 0.01 completed in 9.84s
2024-12-27 09:17:52,065 - INFO - 
Processing poison rate: 0.03
2024-12-27 09:17:52,068 - INFO - Total number of labels flipped: 150
2024-12-27 09:17:52,068 - INFO - Label flipping completed in 0.00s
2024-12-27 09:17:52,068 - INFO - Training set processing completed in 0.00s
2024-12-27 09:17:52,068 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 3072)
2024-12-27 09:17:52,070 - INFO - Memory usage at start_fit: CPU 1602.7 MB, GPU 24.7 MB
2024-12-27 09:17:52,070 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:17:52,259 - INFO - Fitted scaler and transformed data
2024-12-27 09:17:52,259 - INFO - Scaling time: 0.19s
2024-12-27 09:17:52,282 - INFO - Number of unique classes: 43
2024-12-27 09:17:55,746 - INFO - Epoch 1/15, Train Loss: 3.7605, Val Loss: 3.7596
2024-12-27 09:17:59,490 - INFO - Epoch 2/15, Train Loss: 3.7579, Val Loss: 3.7578
2024-12-27 09:18:02,398 - INFO - Epoch 3/15, Train Loss: 3.7552, Val Loss: 3.7558
2024-12-27 09:18:02,398 - INFO - Early stopping triggered at epoch 3
2024-12-27 09:18:02,398 - INFO - Training completed in 10.33s
2024-12-27 09:18:02,399 - INFO - Final memory usage: CPU 1605.9 MB, GPU 89.3 MB
2024-12-27 09:18:02,399 - INFO - Model training completed in 10.33s
2024-12-27 09:18:02,558 - INFO - Prediction completed in 0.16s
2024-12-27 09:18:02,566 - INFO - Poison rate 0.03 completed in 10.50s
2024-12-27 09:18:02,567 - INFO - 
Processing poison rate: 0.05
2024-12-27 09:18:02,572 - INFO - Total number of labels flipped: 250
2024-12-27 09:18:02,572 - INFO - Label flipping completed in 0.01s
2024-12-27 09:18:02,572 - INFO - Training set processing completed in 0.00s
2024-12-27 09:18:02,572 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 3072)
2024-12-27 09:18:02,573 - INFO - Memory usage at start_fit: CPU 1605.9 MB, GPU 24.7 MB
2024-12-27 09:18:02,573 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:18:02,762 - INFO - Fitted scaler and transformed data
2024-12-27 09:18:02,762 - INFO - Scaling time: 0.19s
2024-12-27 09:18:02,785 - INFO - Number of unique classes: 43
2024-12-27 09:18:05,659 - INFO - Epoch 1/15, Train Loss: 3.7605, Val Loss: 3.7597
2024-12-27 09:18:09,426 - INFO - Epoch 2/15, Train Loss: 3.7580, Val Loss: 3.7579
2024-12-27 09:18:13,036 - INFO - Epoch 3/15, Train Loss: 3.7553, Val Loss: 3.7559
2024-12-27 09:18:13,036 - INFO - Early stopping triggered at epoch 3
2024-12-27 09:18:13,036 - INFO - Training completed in 10.46s
2024-12-27 09:18:13,037 - INFO - Final memory usage: CPU 1606.0 MB, GPU 89.3 MB
2024-12-27 09:18:13,037 - INFO - Model training completed in 10.46s
2024-12-27 09:18:13,226 - INFO - Prediction completed in 0.19s
2024-12-27 09:18:13,234 - INFO - Poison rate 0.05 completed in 10.67s
2024-12-27 09:18:13,234 - INFO - 
Processing poison rate: 0.07
2024-12-27 09:18:13,241 - INFO - Total number of labels flipped: 350
2024-12-27 09:18:13,241 - INFO - Label flipping completed in 0.01s
2024-12-27 09:18:13,241 - INFO - Training set processing completed in 0.00s
2024-12-27 09:18:13,241 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 3072)
2024-12-27 09:18:13,242 - INFO - Memory usage at start_fit: CPU 1606.0 MB, GPU 24.7 MB
2024-12-27 09:18:13,242 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:18:13,424 - INFO - Fitted scaler and transformed data
2024-12-27 09:18:13,424 - INFO - Scaling time: 0.18s
2024-12-27 09:18:13,447 - INFO - Number of unique classes: 43
2024-12-27 09:18:16,157 - INFO - Epoch 1/15, Train Loss: 3.7606, Val Loss: 3.7598
2024-12-27 09:18:19,325 - INFO - Epoch 2/15, Train Loss: 3.7581, Val Loss: 3.7581
2024-12-27 09:18:22,166 - INFO - Epoch 3/15, Train Loss: 3.7555, Val Loss: 3.7562
2024-12-27 09:18:22,166 - INFO - Early stopping triggered at epoch 3
2024-12-27 09:18:22,166 - INFO - Training completed in 8.93s
2024-12-27 09:18:22,167 - INFO - Final memory usage: CPU 1606.0 MB, GPU 89.3 MB
2024-12-27 09:18:22,167 - INFO - Model training completed in 8.93s
2024-12-27 09:18:22,287 - INFO - Prediction completed in 0.12s
2024-12-27 09:18:22,296 - INFO - Poison rate 0.07 completed in 9.06s
2024-12-27 09:18:22,296 - INFO - 
Processing poison rate: 0.1
2024-12-27 09:18:22,305 - INFO - Total number of labels flipped: 500
2024-12-27 09:18:22,305 - INFO - Label flipping completed in 0.01s
2024-12-27 09:18:22,306 - INFO - Training set processing completed in 0.00s
2024-12-27 09:18:22,306 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 3072)
2024-12-27 09:18:22,306 - INFO - Memory usage at start_fit: CPU 1606.0 MB, GPU 24.7 MB
2024-12-27 09:18:22,306 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
2024-12-27 09:18:22,472 - INFO - Fitted scaler and transformed data
2024-12-27 09:18:22,472 - INFO - Scaling time: 0.17s
2024-12-27 09:18:22,495 - INFO - Number of unique classes: 43
2024-12-27 09:18:25,468 - INFO - Epoch 1/15, Train Loss: 3.7606, Val Loss: 3.7599
2024-12-27 09:18:28,312 - INFO - Epoch 2/15, Train Loss: 3.7582, Val Loss: 3.7583
2024-12-27 09:18:31,103 - INFO - Epoch 3/15, Train Loss: 3.7557, Val Loss: 3.7566
2024-12-27 09:18:31,104 - INFO - Early stopping triggered at epoch 3
2024-12-27 09:18:31,104 - INFO - Training completed in 8.80s
2024-12-27 09:18:31,104 - INFO - Final memory usage: CPU 1606.0 MB, GPU 89.3 MB
2024-12-27 09:18:31,104 - INFO - Model training completed in 8.80s
2024-12-27 09:18:31,212 - INFO - Prediction completed in 0.11s
2024-12-27 09:18:31,220 - INFO - Poison rate 0.1 completed in 8.92s
2024-12-27 09:18:31,220 - INFO - 
Processing poison rate: 0.2
2024-12-27 09:18:31,238 - INFO - Total number of labels flipped: 1000
2024-12-27 09:18:31,238 - INFO - Label flipping completed in 0.02s
2024-12-27 09:18:31,238 - INFO - Training set processing completed in 0.00s
2024-12-27 09:18:31,238 - INFO - Fitting RandomForestWrapper model with data shape: (5000, 3072)
2024-12-27 09:18:31,239 - INFO - Memory usage at start_fit: CPU 1606.0 MB, GPU 24.7 MB
2024-12-27 09:18:31,239 - INFO - Input data shape: (5000, 3072), labels shape: (5000,)
